{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os,random\n",
    "import torchvision.transforms as T\n",
    "import csv\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "#my imports\n",
    "\n",
    "import train\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter #tensorboard --logdir log --bind_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径: /home/br-python/Documents/chen/boltpd\n",
      "2.0.0+cu117\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"当前路径:\", current_directory)\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# x = torch.tensor([1, 2, 3]).to(device)\n",
    "# print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def classify_force(force):\n",
    "        # 将轴力分为10个单位一类的标签，并确保标签在0-23之间\n",
    "        return min(int(force // 10), 23)\n",
    "\n",
    "label=classify_force(125)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def generate_dataset(dir):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    pathDir = os.listdir(dir)    #取图片的原始路径\n",
    "    filenumber=len(pathDir)\n",
    "    rate=1    #自定义抽取图片的比例，比方说100张抽10张，那就是0.1\n",
    "    picknumber=int(filenumber*rate) #按照rate比例从文件夹中取一定数量图片\n",
    "    sample = random.sample(pathDir, picknumber)  #随机选取picknumber数量的样本图片\n",
    "\n",
    "    file = pd.read_csv(r'./label/AI-bolt-color-202404-inkan.csv') # 读取csv数据\n",
    "    file=np.array(file)#注意数据会跳过第一行，第一行为索引标题\n",
    "    labels=[]\n",
    "    img_data = []\n",
    "    f0 = None\n",
    "    def classify_force(force):\n",
    "        # 将轴力分为10个单位一类的标签\n",
    "        return min((force // 10) ,23)\n",
    "\n",
    "    for file_name in sample:\n",
    "        if f0 is None:\n",
    "            f0 = os.path.join(dir, file_name)\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            if int(file_name[-9:-4]) > 2097 and int(file_name[-9:-4]) < 3597:\n",
    "                img_dir = os.path.join(dir, file_name)\n",
    "                img = cv2.imread(img_dir)\n",
    "                #ref_img = cv2.imread('database/202404-inkan/output-resize/DSC02098.JPG')\n",
    "                #img1 = cv2.absdiff(img, ref_img)\n",
    "                #img1 = cv2.subtract(img,cv2.imread(f0))\n",
    "                \n",
    "                #Edge detection\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "                canny = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "                pimg = Image.fromarray(canny)\n",
    "                img_data.append(pimg)\n",
    "                #img_data.append(file_name)\n",
    "                for item in file:       #add label, from 1row\n",
    "                    sh = item[1]\n",
    "                    if file_name[-9:-4] == sh[-9:-4]:\n",
    "                        force = item[0]\n",
    "                        label = classify_force(force)\n",
    "                        labels.append(label)\n",
    "    # 将标签转换为one-hot编码\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    #labels = torch.nn.functional.one_hot(labels, num_classes=24)  # 23类分类，外加1类(即24类)\n",
    "    return img_data, labels\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i]) #.to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Custom transform for adding Gaussian noise\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "        return tensor + noise\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(mean={self.mean}, std={self.std})'\n",
    "\n",
    "# Data augmentation transform\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Resize(1400),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(mean=0.0, std=0.1),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Original transform\n",
    "original_transform = transforms.Compose([\n",
    "    transforms.Resize(1400),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def generate_augmented_dataset(dir, csv_file, augment_times=5):\n",
    "    pathDir = os.listdir(dir)\n",
    "    filenumber = len(pathDir)\n",
    "    sample = random.sample(pathDir, filenumber)\n",
    "    \n",
    "    file = pd.read_csv(csv_file)\n",
    "    file = np.array(file)\n",
    "    labels = []\n",
    "    img_data = []\n",
    "\n",
    "    def classify_force(force):\n",
    "        return min((force // 10), 23)\n",
    "\n",
    "    for file_name in sample:\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            if int(file_name[-9:-4]) > 2097 and int(file_name[-9:-4]) < 3597:\n",
    "                img_dir = os.path.join(dir, file_name)\n",
    "                img = cv2.imread(img_dir)\n",
    "                ref_img = cv2.imread('database/202404-inkan/output-resize/DSC02098.JPG')\n",
    "                img1 = cv2.absdiff(img, ref_img)\n",
    "                img_pil = Image.fromarray(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                for _ in range(augment_times):\n",
    "                    augmented_img = augment_transform(img_pil)\n",
    "                    img_data.append(augmented_img)\n",
    "\n",
    "                original_img = original_transform(img_pil)\n",
    "                img_data.append(original_img)\n",
    "\n",
    "                for item in file:\n",
    "                    sh = item[1]\n",
    "                    if file_name[-9:-4] == sh[-9:-4]:\n",
    "                        force = item[0]\n",
    "                        label = classify_force(force)\n",
    "                        labels.extend([label] * (augment_times + 1))\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return img_data, labels\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.imgs = list(zip(data, labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "traindir = 'database/202404-inkan/output-resize/'\n",
    "validdir = 'database/202404-inkan/valid-or/'\n",
    "csv_file = './label/AI-bolt-color-202404-inkan.csv'\n",
    "\n",
    "train_rdata, train_label = generate_augmented_dataset(traindir, csv_file, augment_times=3)\n",
    "valid_rdata, valid_label = generate_augmented_dataset(validdir, csv_file, augment_times=1)\n",
    "\n",
    "train_data = MyDataset(train_rdata, train_label)\n",
    "valid_data = MyDataset(valid_rdata, valid_label)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776 4776\n",
      "610 610\n",
      "torch.Size([1, 1, 1400, 1400])\n",
      "tensor([4])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x77735a6a6790>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_rdata), len(train_label))\n",
    "print(len(valid_rdata), len(valid_label))\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "topic = T.ToPILImage()\n",
    "imm1 = topic(images[0])\n",
    "vimg, vlabels = dataiter.__next__()\n",
    "plt.imshow(topic(vimg[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        in_channel：残差块输入通道数\n",
    "        out_channel：残差块输出通道数\n",
    "        stride：卷积步长\n",
    "        downsample：在_make_layer函数中赋值，用于控制shortcut图片下采样 H/2 W/2\n",
    "    \"\"\"\n",
    "    expansion = 4   # 残差块第3个卷积层的通道膨胀倍率\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)   # H,W不变。C: in_channel -> out_channel\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, bias=False, padding=1)  # H/2，W/2。C不变\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*self.expansion, kernel_size=1, stride=1, bias=False)   # H,W不变。C: out_channel -> 4*out_channel\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Add SEBlock\n",
    "        self.seblock = SEBlock(out_channel*self.expansion)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x    # 将原始输入暂存为shortcut的输出\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)   # 如果需要下采样，那么shortcut后:H/2，W/2。C: out_channel -> 4*out_channel(见ResNet中的downsample实现)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        #Apply SEBlock\n",
    "        out = self.seblock(out)\n",
    "\n",
    "        out += identity     # 残差连接0 n\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ModResdic(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        block: 堆叠的基本模块\n",
    "        block_num: 基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        num_classes: 全连接之后的分类特征维度\n",
    "\n",
    "    _make_layer\n",
    "        block: 堆叠的基本模块\n",
    "        channel: 每个stage中堆叠模块的第一个卷积的卷积核个数，对resnet50分别是:64,128,256,512\n",
    "        block_num: 当期stage堆叠block个数\n",
    "        stride: 默认卷积步长\n",
    "    \"\"\"\n",
    "    def __init__(self, block, block_num, num_classes, num_attention_heads=4):\n",
    "        super(ModResdic, self).__init__()\n",
    "        self.in_channel = 64    # conv1的输出维度\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3, bias=False)     # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     # H/2,W/2。C不变\n",
    "        self.layer1 = self._make_layer(block=block, channel=64, block_num=block_num[0], stride=1)   # H,W不变。downsample控制的shortcut，out_channel=64x4=256\n",
    "        self.layer2 = self._make_layer(block=block, channel=128, block_num=block_num[1], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=128x4=512\n",
    "        self.layer3 = self._make_layer(block=block, channel=256, block_num=block_num[2], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=256x4=1024\n",
    "        self.layer4 = self._make_layer(block=block, channel=512, block_num=block_num[3], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=512x4=2048\n",
    "\n",
    "        # 添加自注意力层\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=2048, num_heads=num_attention_heads)\n",
    "\n",
    "        # Add SEBlocks after each residual block in the feature extraction layers\n",
    "        self.seblock1 = SEBlock(64 * block.expansion)\n",
    "        self.seblock2 = SEBlock(128 * block.expansion)\n",
    "        self.seblock3 = SEBlock(256 * block.expansion)\n",
    "        self.seblock4 = SEBlock(512 * block.expansion)\n",
    "\n",
    "        self.fusion4 = MultiScaleFusion(1024 * block.expansion)\n",
    "        self.fusion3 = MultiScaleFusion(512 * block.expansion)\n",
    "        self.fusion2 = MultiScaleFusion(256 * block.expansion)\n",
    "        self.fusion1 = MultiScaleFusion(128 * block.expansion)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc1 = nn.Linear(in_features=512*block.expansion, out_features=1024) #in=2048,out=1024\n",
    "        self.dropout = nn.Dropout(0.8) #dropout rate\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=1024) #in=1024, out=1\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=num_classes) #in=512, out=1\n",
    "        #self.fc4 = nn.Linear(in_features=64, out_features=num_classes) #in=128, out=1\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Upsampling layers for feature fusion\n",
    "        self.upsample = lambda x: nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=None).to(x.device)\n",
    "        #self.upsample = nn.functional.interpolate(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        for m in self.modules():    # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None   # 用于控制shorcut路的\n",
    "        if stride != 1 or self.in_channel != channel*block.expansion:   # 对resnet50：conv2中特征图尺寸H,W不需要下采样/2，但是通道数x4，因此shortcut通道数也需要x4。对其余conv3,4,5，既要特征图尺寸H,W/2，又要shortcut维度x4\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel*block.expansion, kernel_size=1, stride=stride, bias=False), # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel*block.expansion))\n",
    "\n",
    "        layers = []  # 每一个convi_x的结构保存在一个layers列表中，i={2,3,4,5}\n",
    "        layers.append(block(in_channel=self.in_channel, out_channel=channel, downsample=downsample, stride=stride)) # 定义convi_x中的第一个残差块，只有第一个需要设置downsample和stride\n",
    "        self.in_channel = channel*block.expansion   # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            layers.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "\n",
    "        return nn.Sequential(*layers)   # '*'的作用是将list转换为非关键字参数传入\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x1 = self.fusion1(x1)\n",
    "        x1 = self.seblock1(x1)\n",
    "        x2 = self.layer2(x1)\n",
    "        #x2 = self.seblock2(x2)\n",
    "        #x2 = self.fusion2(x2)\n",
    "        x3 = self.layer3(x2)\n",
    "        #x3 = self.seblock3(x3)\n",
    "        #x3 = self.fusion3(x3)\n",
    "        x4 = self.layer4(x3)\n",
    "        x4 = self.seblock4(x4)\n",
    "        x4 = self.fusion4(x4)\n",
    "\n",
    "        x = self.avgpool(x4)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 添加自注意力层\n",
    "        x, _ = self.self_attention(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))\n",
    "        x = x.squeeze(0)  # 移除添加的维度以适应全连接层的输入要求\n",
    "\n",
    "        #x = x.unsqueeze(0)  # 添加一个维度以适应自注意力层的输入要求\n",
    "        #x, _ = self.self_attention(x, x, x)\n",
    "        \n",
    "        #x = self.relu(self.fc1(x))\n",
    "        #x = self.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MultiScaleFusion(nn.Module):\n",
    "    def __init__(self,out_channels):\n",
    "        super(MultiScaleFusion, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义融合的卷积层\n",
    "        self.fusion_conv = nn.Conv2d(4*out_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        out = torch.cat([x,x1, x2, x3], dim=1)\n",
    "        # 对融合的特征图进行卷积操作\n",
    "        out = self.fusion_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ModResv2(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        block: 堆叠的基本模块\n",
    "        block_num: 基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        num_classes: 全连接之后的分类特征维度\n",
    "\n",
    "    _make_layer\n",
    "        block: 堆叠的基本模块\n",
    "        channel: 每个stage中堆叠模块的第一个卷积的卷积核个数，对resnet50分别是:64,128,256,512\n",
    "        block_num: 当期stage堆叠block个数\n",
    "        stride: 默认卷积步长\n",
    "    \"\"\"\n",
    "    def __init__(self, block, block_num, num_classes, num_attention_heads=4):\n",
    "        super(ModResv2, self).__init__()\n",
    "        self.in_channel = 64    # conv1的输出维度\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3, bias=False)     # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     # H/2,W/2。C不变\n",
    "        self.layer1 = self._make_layer(block=block, channel=64, block_num=block_num[0], stride=1)   # H,W不变。downsample控制的shortcut，out_channel=64x4=256\n",
    "        self.layer2 = self._make_layer(block=block, channel=128, block_num=block_num[1], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=128x4=512\n",
    "        self.layer3 = self._make_layer(block=block, channel=256, block_num=block_num[2], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=256x4=1024\n",
    "        self.layer4 = self._make_layer(block=block, channel=512, block_num=block_num[3], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=512x4=2048\n",
    "        \n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=2048, num_heads=num_attention_heads)\n",
    "\n",
    "        # Add SEBlocks after each residual block in the feature extraction layers\n",
    "        self.seblock1 = SEBlock(64 * block.expansion)\n",
    "        self.seblock2 = SEBlock(128 * block.expansion)\n",
    "        self.seblock3 = SEBlock(256 * block.expansion)\n",
    "        self.seblock4 = SEBlock(512 * block.expansion)\n",
    "\n",
    "        self.fusion4 = MultiScaleFusion(512 * block.expansion)\n",
    "        #self.fusion3 = MultiScaleFusion(256 * block.expansion)\n",
    "        #self.fusion2 = MultiScaleFusion(128 * block.expansion)\n",
    "        self.fusion1 = MultiScaleFusion(64 * block.expansion)\n",
    "\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc1 = nn.Linear(in_features=512*block.expansion, out_features=1024) #in=2048,out=1024\n",
    "        self.dropout = nn.Dropout(0.6) #dropout rate\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=num_classes) #in=1024, out=1\n",
    "        #self.fc3 = nn.Linear(in_features=512, out_features=num_classes) #in=512, out=1\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Upsampling layers for feature fusion\n",
    "        self.upsample = lambda x: nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=None).to(x.device)\n",
    "        #self.upsample = nn.functional.interpolate(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        for m in self.modules():    # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None   # 用于控制shorcut路的\n",
    "        if stride != 1 or self.in_channel != channel*block.expansion:   # 对resnet50：conv2中特征图尺寸H,W不需要下采样/2，但是通道数x4，因此shortcut通道数也需要x4。对其余conv3,4,5，既要特征图尺寸H,W/2，又要shortcut维度x4\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel*block.expansion, kernel_size=1, stride=stride, bias=False), # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel*block.expansion))\n",
    "\n",
    "        layers = []  # 每一个convi_x的结构保存在一个layers列表中，i={2,3,4,5}\n",
    "        layers.append(block(in_channel=self.in_channel, out_channel=channel, downsample=downsample, stride=stride)) # 定义convi_x中的第一个残差块，只有第一个需要设置downsample和stride\n",
    "        self.in_channel = channel*block.expansion   # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            layers.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "\n",
    "        return nn.Sequential(*layers)   # '*'的作用是将list转换为非关键字参数传入\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x1 = self.seblock1(x1)\n",
    "        x1 = self.fusion1(x1)\n",
    "        x2 = self.layer2(x1)\n",
    "        x2 = self.seblock2(x2)\n",
    "        x3 = self.layer3(x2)\n",
    "        x3 = self.seblock3(x3)\n",
    "        x4 = self.layer4(x3)\n",
    "        x4 = self.seblock4(x4)\n",
    "        x4 = self.fusion4(x4)\n",
    "\n",
    "        x = self.avgpool(x4)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 添加自注意力层\n",
    "        x, _ = self.self_attention(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))\n",
    "        x = x.squeeze(0) \n",
    "\n",
    "        #x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        #x = self.activation(self.fc2(x))\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy():\n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valid_loader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = accuracy / total\n",
    "    print('Accuracy: ', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def valid(model, device, valid_loader, classes):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # 计算各项指标\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=np.arange(24))\n",
    "    class_report = classification_report(all_labels, all_predictions, target_names=classes, labels=np.arange(24))\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print('\\nClassification Report:\\n', class_report)\n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, conf_matrix, class_report\n",
    "\n",
    "def train(num_epochs,device,net):\n",
    "    import time\n",
    "    start_time = time.process_time()\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    k=0\n",
    "    predata=[]\n",
    "    labeldata=[]\n",
    "    mseloss=[]\n",
    "    trainnum=[]\n",
    "    epochout=[]\n",
    "    epochV=[]\n",
    "    vloss=[]\n",
    "    vr2=[]\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    net.to(device)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            prediction = net(images)\n",
    "            loss = loss_func(prediction, labels)*100\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            running_corrects += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                avg_loss = running_loss / 10\n",
    "                avg_acc = running_corrects / total_samples\n",
    "                \n",
    "                print(f'[Epoch: {epoch+1}/{num_epochs}] - Step: {i+1}/{len(train_loader)} | Loss: {avg_loss:.3f} | Accuracy: {avg_acc:.3f}')\n",
    "\n",
    "                mseloss.append(running_loss/10)\n",
    "                trainnum.append(i+1)\n",
    "                epochout.append(epoch+1)\n",
    "                result=pd.DataFrame({'epoch':epochout,'trainnum':trainnum,'loss':mseloss})\n",
    "                result.to_csv(\"./result/\"+casename+\"/\"+casename+\"-result.csv\",index=False,sep=',')\n",
    "\n",
    "                # Tensorboard\n",
    "                writer.add_scalar('Training loss', avg_loss, epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('ACC', avg_acc, epoch * len(train_loader) + i)\n",
    "\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0.0\n",
    "                total_samples = 0\n",
    "\n",
    "            predata.append(prediction.data.cpu().numpy()[0])\n",
    "            labeldata.append(labels.data.cpu().numpy()[0])\n",
    "\n",
    "        valid_accuracy = testAccuracy()\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "            print('Model saved!')\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    print(\"Training completed in: \", (end_time - start_time) / 3600, \" hours\")\n",
    "\n",
    "def predict(net, device, dataloader):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModResv2(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.01)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=2048, out_features=2048, bias=True)\n",
      "  )\n",
      "  (seblock1): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock2): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock3): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock4): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (fusion4): MultiScaleFusion(\n",
      "    (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(2048, 2048, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (fusion_conv): Conv2d(8192, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (fusion1): MultiScaleFusion(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (fusion_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=24, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#from net import ResNet, Bottleneck\n",
    "#from SEBlock import SEBlock\n",
    "from loss_func import HuberLossPena\n",
    "\n",
    "classes = [f'{i*10}-{i*10+10}' for i in range(24)]\n",
    "    \n",
    "# 输入输出的数据维度，这里都是1维\n",
    "INPUT_FEATURE_DIM = 5000\n",
    "# 隐含层中神经元的个数\n",
    "#NEURON_NUM = 500\n",
    "#OUTPUT_FEATURE_DIM = 1\n",
    "# 学习率，越大学的越快，但也容易造成不稳定，准确率上下波动的情况\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# 定义模型\n",
    "net = ModResv2(block=Bottleneck, block_num=[3,4,6,3],num_classes=24) #152 (3,4,36,3)\n",
    "\n",
    "# 训练网络\n",
    "# 这里也可以使用其它的优化方法\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = torch.optim.SGD(net.parameters(),lr=LEARNING_RATE)\n",
    "# 定义一个误差计算方法\n",
    "#loss_func = HuberLossPena(delta=0.1, penalty_weight=5.0)\n",
    "#loss_func = nn.MSELoss()\n",
    "loss_func = nn.CrossEntropyLoss() #定义交叉熵损失函数 交叉熵损失函数是用来衡量两个概率分布之间的距离的#nn.MSELoss()\n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "\n",
    "\n",
    "casename='202406'\n",
    "writer = SummaryWriter(\"./log/\"+casename) #tensorboard\n",
    "\n",
    "print(net)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCUETE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1/200] - Step: 10/4776 | Loss: 312.648 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 20/4776 | Loss: 317.343 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 30/4776 | Loss: 320.375 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 40/4776 | Loss: 318.322 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 50/4776 | Loss: 310.671 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 60/4776 | Loss: 308.008 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 70/4776 | Loss: 309.195 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 80/4776 | Loss: 322.023 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 90/4776 | Loss: 334.014 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 100/4776 | Loss: 291.111 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 110/4776 | Loss: 305.661 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 120/4776 | Loss: 326.977 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 130/4776 | Loss: 312.877 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 140/4776 | Loss: 297.911 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 150/4776 | Loss: 305.618 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 160/4776 | Loss: 303.821 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 170/4776 | Loss: 323.583 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 180/4776 | Loss: 313.340 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 190/4776 | Loss: 302.737 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 200/4776 | Loss: 315.668 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 210/4776 | Loss: 324.667 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 220/4776 | Loss: 310.228 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 230/4776 | Loss: 327.663 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 240/4776 | Loss: 288.756 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 250/4776 | Loss: 303.629 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 260/4776 | Loss: 313.355 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 270/4776 | Loss: 296.120 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 280/4776 | Loss: 264.222 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 290/4776 | Loss: 323.841 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 300/4776 | Loss: 292.034 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 310/4776 | Loss: 327.271 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 320/4776 | Loss: 305.063 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 330/4776 | Loss: 317.743 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 340/4776 | Loss: 286.652 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 350/4776 | Loss: 281.817 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 360/4776 | Loss: 318.236 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 370/4776 | Loss: 296.896 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 380/4776 | Loss: 295.446 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 390/4776 | Loss: 293.977 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 400/4776 | Loss: 297.678 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 410/4776 | Loss: 312.353 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 420/4776 | Loss: 291.492 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 430/4776 | Loss: 297.604 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 440/4776 | Loss: 312.379 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 450/4776 | Loss: 310.825 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 460/4776 | Loss: 302.348 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 470/4776 | Loss: 298.447 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 480/4776 | Loss: 295.874 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 490/4776 | Loss: 300.566 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 500/4776 | Loss: 317.149 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 510/4776 | Loss: 320.317 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 520/4776 | Loss: 296.321 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 530/4776 | Loss: 335.721 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 540/4776 | Loss: 305.211 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 550/4776 | Loss: 294.883 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 560/4776 | Loss: 311.745 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 570/4776 | Loss: 298.349 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 580/4776 | Loss: 313.144 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 590/4776 | Loss: 298.573 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 600/4776 | Loss: 311.580 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 610/4776 | Loss: 304.721 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 620/4776 | Loss: 292.495 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 630/4776 | Loss: 292.650 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 640/4776 | Loss: 304.185 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 650/4776 | Loss: 304.263 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 660/4776 | Loss: 295.730 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 670/4776 | Loss: 289.395 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 680/4776 | Loss: 331.900 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 690/4776 | Loss: 304.827 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 700/4776 | Loss: 299.358 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 710/4776 | Loss: 302.290 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 720/4776 | Loss: 289.517 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 730/4776 | Loss: 318.725 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 740/4776 | Loss: 313.846 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 750/4776 | Loss: 288.763 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 760/4776 | Loss: 305.160 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 770/4776 | Loss: 280.746 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 780/4776 | Loss: 301.124 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 790/4776 | Loss: 298.981 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 800/4776 | Loss: 282.199 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 810/4776 | Loss: 308.720 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 820/4776 | Loss: 312.794 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 830/4776 | Loss: 282.169 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 840/4776 | Loss: 306.033 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 850/4776 | Loss: 308.840 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 860/4776 | Loss: 307.985 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 870/4776 | Loss: 332.194 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 880/4776 | Loss: 318.948 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 890/4776 | Loss: 301.379 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 900/4776 | Loss: 308.567 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 910/4776 | Loss: 296.984 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 920/4776 | Loss: 306.831 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 930/4776 | Loss: 292.914 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 940/4776 | Loss: 327.127 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 950/4776 | Loss: 286.705 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 960/4776 | Loss: 314.943 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 970/4776 | Loss: 311.925 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 980/4776 | Loss: 310.156 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 990/4776 | Loss: 283.295 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1000/4776 | Loss: 303.895 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1010/4776 | Loss: 300.196 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1020/4776 | Loss: 309.379 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1030/4776 | Loss: 305.560 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1040/4776 | Loss: 286.159 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1050/4776 | Loss: 300.355 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1060/4776 | Loss: 299.908 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1070/4776 | Loss: 304.058 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1080/4776 | Loss: 308.039 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1090/4776 | Loss: 298.400 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1100/4776 | Loss: 305.509 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1110/4776 | Loss: 301.314 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1120/4776 | Loss: 310.827 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1130/4776 | Loss: 284.434 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1140/4776 | Loss: 306.883 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1150/4776 | Loss: 313.622 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1160/4776 | Loss: 299.960 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1170/4776 | Loss: 287.834 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1180/4776 | Loss: 293.519 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1190/4776 | Loss: 300.164 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1200/4776 | Loss: 301.143 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1210/4776 | Loss: 283.192 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1220/4776 | Loss: 277.609 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1230/4776 | Loss: 299.766 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1240/4776 | Loss: 296.255 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1250/4776 | Loss: 312.539 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1260/4776 | Loss: 289.802 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1270/4776 | Loss: 305.541 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1280/4776 | Loss: 291.402 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1290/4776 | Loss: 308.885 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1300/4776 | Loss: 313.188 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1310/4776 | Loss: 297.023 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1320/4776 | Loss: 299.861 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1330/4776 | Loss: 280.781 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1340/4776 | Loss: 299.160 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1350/4776 | Loss: 264.241 | Accuracy: 0.400\n",
      "[Epoch: 1/200] - Step: 1360/4776 | Loss: 348.561 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1370/4776 | Loss: 292.395 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1380/4776 | Loss: 319.343 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1390/4776 | Loss: 306.132 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1400/4776 | Loss: 326.113 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1410/4776 | Loss: 288.821 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1420/4776 | Loss: 300.003 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1430/4776 | Loss: 305.695 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1440/4776 | Loss: 282.053 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1450/4776 | Loss: 279.862 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1460/4776 | Loss: 308.697 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1470/4776 | Loss: 275.826 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1480/4776 | Loss: 325.246 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1490/4776 | Loss: 308.924 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1500/4776 | Loss: 302.549 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1510/4776 | Loss: 294.608 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1520/4776 | Loss: 304.544 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1530/4776 | Loss: 288.095 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1540/4776 | Loss: 306.857 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1550/4776 | Loss: 284.205 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1560/4776 | Loss: 303.083 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1570/4776 | Loss: 252.158 | Accuracy: 0.400\n",
      "[Epoch: 1/200] - Step: 1580/4776 | Loss: 321.105 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1590/4776 | Loss: 316.775 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1600/4776 | Loss: 295.931 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1610/4776 | Loss: 304.707 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1620/4776 | Loss: 301.223 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1630/4776 | Loss: 300.244 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1640/4776 | Loss: 306.012 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1650/4776 | Loss: 299.888 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1660/4776 | Loss: 314.914 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1670/4776 | Loss: 317.282 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1680/4776 | Loss: 306.101 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1690/4776 | Loss: 302.824 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1700/4776 | Loss: 275.692 | Accuracy: 0.400\n",
      "[Epoch: 1/200] - Step: 1710/4776 | Loss: 297.712 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1720/4776 | Loss: 293.543 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1730/4776 | Loss: 292.663 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1740/4776 | Loss: 314.962 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1750/4776 | Loss: 303.190 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1760/4776 | Loss: 321.640 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1770/4776 | Loss: 309.516 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1780/4776 | Loss: 312.004 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1790/4776 | Loss: 285.541 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1800/4776 | Loss: 307.448 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1810/4776 | Loss: 277.999 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1820/4776 | Loss: 296.150 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1830/4776 | Loss: 303.273 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1840/4776 | Loss: 278.933 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1850/4776 | Loss: 312.842 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1860/4776 | Loss: 289.539 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1870/4776 | Loss: 286.269 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1880/4776 | Loss: 323.544 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1890/4776 | Loss: 329.760 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1900/4776 | Loss: 304.254 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1910/4776 | Loss: 307.513 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1920/4776 | Loss: 309.831 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1930/4776 | Loss: 312.359 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1940/4776 | Loss: 305.005 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1950/4776 | Loss: 292.958 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1960/4776 | Loss: 298.412 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1970/4776 | Loss: 295.727 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1980/4776 | Loss: 297.588 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1990/4776 | Loss: 312.484 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2000/4776 | Loss: 294.961 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2010/4776 | Loss: 302.142 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2020/4776 | Loss: 299.475 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2030/4776 | Loss: 307.164 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2040/4776 | Loss: 285.992 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2050/4776 | Loss: 314.574 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2060/4776 | Loss: 306.404 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2070/4776 | Loss: 317.811 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2080/4776 | Loss: 295.914 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2090/4776 | Loss: 299.893 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2100/4776 | Loss: 307.315 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2110/4776 | Loss: 294.435 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2120/4776 | Loss: 289.516 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2130/4776 | Loss: 298.218 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2140/4776 | Loss: 306.908 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2150/4776 | Loss: 289.101 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2160/4776 | Loss: 292.562 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2170/4776 | Loss: 315.468 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2180/4776 | Loss: 288.545 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2190/4776 | Loss: 298.783 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2200/4776 | Loss: 311.031 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2210/4776 | Loss: 305.430 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2220/4776 | Loss: 309.432 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2230/4776 | Loss: 304.920 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2240/4776 | Loss: 297.791 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2250/4776 | Loss: 296.100 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2260/4776 | Loss: 300.941 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2270/4776 | Loss: 309.693 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2280/4776 | Loss: 320.185 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2290/4776 | Loss: 298.715 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2300/4776 | Loss: 292.528 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2310/4776 | Loss: 310.519 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2320/4776 | Loss: 311.484 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2330/4776 | Loss: 301.692 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2340/4776 | Loss: 279.837 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 2350/4776 | Loss: 304.282 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2360/4776 | Loss: 309.687 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2370/4776 | Loss: 309.841 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2380/4776 | Loss: 301.494 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2390/4776 | Loss: 290.304 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2400/4776 | Loss: 296.019 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2410/4776 | Loss: 296.528 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2420/4776 | Loss: 305.363 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2430/4776 | Loss: 297.554 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2440/4776 | Loss: 295.390 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2450/4776 | Loss: 285.209 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2460/4776 | Loss: 275.225 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2470/4776 | Loss: 299.389 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2480/4776 | Loss: 291.865 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2490/4776 | Loss: 288.353 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2500/4776 | Loss: 300.568 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2510/4776 | Loss: 297.332 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2520/4776 | Loss: 301.359 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2530/4776 | Loss: 326.728 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2540/4776 | Loss: 318.549 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2550/4776 | Loss: 306.589 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2560/4776 | Loss: 299.825 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2570/4776 | Loss: 299.888 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2580/4776 | Loss: 294.066 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2590/4776 | Loss: 294.406 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2600/4776 | Loss: 317.230 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2610/4776 | Loss: 292.026 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2620/4776 | Loss: 302.637 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2630/4776 | Loss: 306.754 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2640/4776 | Loss: 298.927 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2650/4776 | Loss: 288.685 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 2660/4776 | Loss: 291.486 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2670/4776 | Loss: 298.742 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2680/4776 | Loss: 277.697 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2690/4776 | Loss: 278.523 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2700/4776 | Loss: 307.016 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2710/4776 | Loss: 312.901 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2720/4776 | Loss: 307.063 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2730/4776 | Loss: 276.826 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2740/4776 | Loss: 293.877 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2750/4776 | Loss: 320.918 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2760/4776 | Loss: 307.243 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2770/4776 | Loss: 286.747 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2780/4776 | Loss: 284.394 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 2790/4776 | Loss: 281.207 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2800/4776 | Loss: 292.184 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2810/4776 | Loss: 307.955 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2820/4776 | Loss: 288.971 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2830/4776 | Loss: 281.866 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2840/4776 | Loss: 297.161 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2850/4776 | Loss: 306.160 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2860/4776 | Loss: 317.394 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2870/4776 | Loss: 279.334 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2880/4776 | Loss: 342.232 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2890/4776 | Loss: 321.647 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2900/4776 | Loss: 312.351 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2910/4776 | Loss: 295.864 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2920/4776 | Loss: 293.610 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2930/4776 | Loss: 312.899 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 2940/4776 | Loss: 299.120 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2950/4776 | Loss: 288.114 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2960/4776 | Loss: 301.455 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2970/4776 | Loss: 313.345 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 2980/4776 | Loss: 291.594 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 2990/4776 | Loss: 294.950 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3000/4776 | Loss: 307.641 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3010/4776 | Loss: 281.208 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3020/4776 | Loss: 291.100 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3030/4776 | Loss: 284.890 | Accuracy: 0.400\n",
      "[Epoch: 1/200] - Step: 3040/4776 | Loss: 288.574 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3050/4776 | Loss: 287.499 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3060/4776 | Loss: 302.690 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3070/4776 | Loss: 293.082 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3080/4776 | Loss: 300.440 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3090/4776 | Loss: 311.528 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3100/4776 | Loss: 300.300 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3110/4776 | Loss: 295.541 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3120/4776 | Loss: 302.414 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3130/4776 | Loss: 297.156 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3140/4776 | Loss: 308.503 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3150/4776 | Loss: 282.368 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3160/4776 | Loss: 314.911 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3170/4776 | Loss: 276.655 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3180/4776 | Loss: 307.925 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3190/4776 | Loss: 278.820 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3200/4776 | Loss: 341.724 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3210/4776 | Loss: 282.984 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3220/4776 | Loss: 313.844 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3230/4776 | Loss: 306.974 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3240/4776 | Loss: 294.321 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3250/4776 | Loss: 303.098 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3260/4776 | Loss: 297.925 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3270/4776 | Loss: 310.568 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3280/4776 | Loss: 284.117 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3290/4776 | Loss: 286.567 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3300/4776 | Loss: 287.605 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3310/4776 | Loss: 301.966 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3320/4776 | Loss: 302.205 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3330/4776 | Loss: 298.628 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3340/4776 | Loss: 307.905 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3350/4776 | Loss: 340.288 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3360/4776 | Loss: 299.037 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3370/4776 | Loss: 284.265 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3380/4776 | Loss: 309.119 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3390/4776 | Loss: 277.541 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3400/4776 | Loss: 270.945 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 3410/4776 | Loss: 294.517 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3420/4776 | Loss: 306.815 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3430/4776 | Loss: 287.053 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3440/4776 | Loss: 310.933 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3450/4776 | Loss: 288.232 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3460/4776 | Loss: 277.102 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3470/4776 | Loss: 286.149 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3480/4776 | Loss: 307.562 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3490/4776 | Loss: 322.587 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3500/4776 | Loss: 307.418 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3510/4776 | Loss: 317.311 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3520/4776 | Loss: 301.127 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3530/4776 | Loss: 312.755 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3540/4776 | Loss: 301.129 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3550/4776 | Loss: 292.141 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 3560/4776 | Loss: 286.004 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3570/4776 | Loss: 301.513 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3580/4776 | Loss: 298.418 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3590/4776 | Loss: 294.032 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3600/4776 | Loss: 288.151 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3610/4776 | Loss: 302.818 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3620/4776 | Loss: 312.420 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3630/4776 | Loss: 325.201 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3640/4776 | Loss: 297.184 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3650/4776 | Loss: 301.954 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3660/4776 | Loss: 295.474 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3670/4776 | Loss: 287.764 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3680/4776 | Loss: 297.176 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3690/4776 | Loss: 296.215 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3700/4776 | Loss: 291.096 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3710/4776 | Loss: 300.756 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3720/4776 | Loss: 295.686 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3730/4776 | Loss: 307.464 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3740/4776 | Loss: 306.816 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3750/4776 | Loss: 288.681 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3760/4776 | Loss: 294.919 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3770/4776 | Loss: 305.964 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3780/4776 | Loss: 311.704 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3790/4776 | Loss: 287.336 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3800/4776 | Loss: 309.370 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3810/4776 | Loss: 301.601 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3820/4776 | Loss: 308.255 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3830/4776 | Loss: 298.205 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3840/4776 | Loss: 278.489 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 3850/4776 | Loss: 300.374 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3860/4776 | Loss: 288.258 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3870/4776 | Loss: 297.902 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3880/4776 | Loss: 314.583 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3890/4776 | Loss: 316.374 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3900/4776 | Loss: 266.751 | Accuracy: 0.500\n",
      "[Epoch: 1/200] - Step: 3910/4776 | Loss: 283.711 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 3920/4776 | Loss: 288.722 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3930/4776 | Loss: 297.451 | Accuracy: 0.400\n",
      "[Epoch: 1/200] - Step: 3940/4776 | Loss: 302.432 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3950/4776 | Loss: 210.186 | Accuracy: 0.500\n",
      "[Epoch: 1/200] - Step: 3960/4776 | Loss: 340.096 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3970/4776 | Loss: 313.644 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 3980/4776 | Loss: 325.127 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 3990/4776 | Loss: 318.971 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4000/4776 | Loss: 284.694 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4010/4776 | Loss: 303.426 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4020/4776 | Loss: 286.204 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 4030/4776 | Loss: 280.344 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4040/4776 | Loss: 294.857 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4050/4776 | Loss: 312.990 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4060/4776 | Loss: 327.491 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4070/4776 | Loss: 300.367 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4080/4776 | Loss: 292.954 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4090/4776 | Loss: 315.681 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4100/4776 | Loss: 305.784 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4110/4776 | Loss: 299.979 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4120/4776 | Loss: 313.222 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4130/4776 | Loss: 298.706 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4140/4776 | Loss: 309.359 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4150/4776 | Loss: 312.653 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4160/4776 | Loss: 311.587 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4170/4776 | Loss: 303.948 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4180/4776 | Loss: 324.575 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4190/4776 | Loss: 303.990 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4200/4776 | Loss: 291.022 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4210/4776 | Loss: 306.563 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4220/4776 | Loss: 302.183 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4230/4776 | Loss: 296.066 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4240/4776 | Loss: 284.087 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4250/4776 | Loss: 303.461 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4260/4776 | Loss: 292.417 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 4270/4776 | Loss: 295.567 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4280/4776 | Loss: 292.454 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4290/4776 | Loss: 304.892 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4300/4776 | Loss: 286.136 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 4310/4776 | Loss: 319.673 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4320/4776 | Loss: 285.321 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4330/4776 | Loss: 315.214 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4340/4776 | Loss: 289.155 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4350/4776 | Loss: 277.572 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4360/4776 | Loss: 305.376 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4370/4776 | Loss: 299.483 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4380/4776 | Loss: 306.269 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4390/4776 | Loss: 301.968 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4400/4776 | Loss: 293.940 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4410/4776 | Loss: 299.761 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4420/4776 | Loss: 306.581 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4430/4776 | Loss: 343.975 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4440/4776 | Loss: 309.729 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4450/4776 | Loss: 303.130 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4460/4776 | Loss: 305.334 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4470/4776 | Loss: 310.651 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4480/4776 | Loss: 304.064 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4490/4776 | Loss: 307.162 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4500/4776 | Loss: 290.589 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4510/4776 | Loss: 307.439 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4520/4776 | Loss: 303.207 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4530/4776 | Loss: 310.627 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4540/4776 | Loss: 299.832 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4550/4776 | Loss: 294.372 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4560/4776 | Loss: 294.104 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4570/4776 | Loss: 310.612 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4580/4776 | Loss: 301.879 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4590/4776 | Loss: 299.076 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4600/4776 | Loss: 294.911 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4610/4776 | Loss: 296.199 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4620/4776 | Loss: 292.850 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4630/4776 | Loss: 292.338 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4640/4776 | Loss: 300.795 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4650/4776 | Loss: 319.393 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4660/4776 | Loss: 281.450 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 4670/4776 | Loss: 304.578 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4680/4776 | Loss: 297.384 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4690/4776 | Loss: 299.761 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4700/4776 | Loss: 300.109 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4710/4776 | Loss: 264.075 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 4720/4776 | Loss: 301.431 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4730/4776 | Loss: 309.893 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 4740/4776 | Loss: 304.863 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4750/4776 | Loss: 294.460 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 4760/4776 | Loss: 284.546 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 4770/4776 | Loss: 294.831 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "Model saved!\n",
      "[Epoch: 2/200] - Step: 10/4776 | Loss: 308.407 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 20/4776 | Loss: 304.641 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 30/4776 | Loss: 306.223 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 40/4776 | Loss: 291.418 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 50/4776 | Loss: 293.126 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 60/4776 | Loss: 313.649 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 70/4776 | Loss: 311.994 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 80/4776 | Loss: 284.046 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 90/4776 | Loss: 316.656 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 100/4776 | Loss: 303.245 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 110/4776 | Loss: 286.599 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 120/4776 | Loss: 291.736 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 130/4776 | Loss: 302.650 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 140/4776 | Loss: 281.457 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 150/4776 | Loss: 299.690 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 160/4776 | Loss: 312.245 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 170/4776 | Loss: 316.606 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 180/4776 | Loss: 306.121 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 190/4776 | Loss: 314.905 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 200/4776 | Loss: 296.550 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 210/4776 | Loss: 308.958 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 220/4776 | Loss: 301.794 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 230/4776 | Loss: 314.925 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 240/4776 | Loss: 316.586 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 250/4776 | Loss: 292.031 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 260/4776 | Loss: 285.372 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 270/4776 | Loss: 291.589 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 280/4776 | Loss: 308.184 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 290/4776 | Loss: 310.797 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 300/4776 | Loss: 308.278 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 310/4776 | Loss: 293.230 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 320/4776 | Loss: 279.323 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 330/4776 | Loss: 303.252 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 340/4776 | Loss: 304.311 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 350/4776 | Loss: 345.398 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 360/4776 | Loss: 313.552 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 370/4776 | Loss: 296.360 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 380/4776 | Loss: 295.161 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 390/4776 | Loss: 316.845 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 400/4776 | Loss: 302.345 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 410/4776 | Loss: 313.745 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 420/4776 | Loss: 292.718 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 430/4776 | Loss: 298.659 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 440/4776 | Loss: 292.316 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 450/4776 | Loss: 298.699 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 460/4776 | Loss: 310.826 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 470/4776 | Loss: 275.995 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 480/4776 | Loss: 284.087 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 490/4776 | Loss: 321.116 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 500/4776 | Loss: 313.331 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 510/4776 | Loss: 296.241 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 520/4776 | Loss: 287.597 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 530/4776 | Loss: 290.096 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 540/4776 | Loss: 310.084 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 550/4776 | Loss: 308.316 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 560/4776 | Loss: 290.325 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 570/4776 | Loss: 302.750 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 580/4776 | Loss: 300.920 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 590/4776 | Loss: 311.849 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 600/4776 | Loss: 286.832 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 610/4776 | Loss: 331.005 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 620/4776 | Loss: 311.601 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 630/4776 | Loss: 304.439 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 640/4776 | Loss: 303.965 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 650/4776 | Loss: 302.779 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 660/4776 | Loss: 292.427 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 670/4776 | Loss: 301.605 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 680/4776 | Loss: 284.537 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 690/4776 | Loss: 303.687 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 700/4776 | Loss: 306.268 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 710/4776 | Loss: 297.156 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 720/4776 | Loss: 300.149 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 730/4776 | Loss: 300.967 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 740/4776 | Loss: 292.145 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 750/4776 | Loss: 286.331 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 760/4776 | Loss: 281.575 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 770/4776 | Loss: 314.619 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 780/4776 | Loss: 303.222 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 790/4776 | Loss: 293.349 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 800/4776 | Loss: 309.954 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 810/4776 | Loss: 280.803 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 820/4776 | Loss: 286.919 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 830/4776 | Loss: 277.911 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 840/4776 | Loss: 296.668 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 850/4776 | Loss: 284.958 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 860/4776 | Loss: 289.827 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 870/4776 | Loss: 300.000 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 880/4776 | Loss: 318.575 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 890/4776 | Loss: 301.791 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 900/4776 | Loss: 305.541 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 910/4776 | Loss: 299.551 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 920/4776 | Loss: 291.751 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 930/4776 | Loss: 319.081 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 940/4776 | Loss: 295.448 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 950/4776 | Loss: 304.024 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 960/4776 | Loss: 305.831 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 970/4776 | Loss: 308.142 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 980/4776 | Loss: 314.091 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 990/4776 | Loss: 302.485 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1000/4776 | Loss: 298.288 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1010/4776 | Loss: 303.204 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1020/4776 | Loss: 284.619 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1030/4776 | Loss: 297.506 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1040/4776 | Loss: 299.510 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1050/4776 | Loss: 291.807 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1060/4776 | Loss: 294.738 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1070/4776 | Loss: 317.386 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1080/4776 | Loss: 308.084 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1090/4776 | Loss: 301.306 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1100/4776 | Loss: 309.563 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1110/4776 | Loss: 323.191 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1120/4776 | Loss: 294.183 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1130/4776 | Loss: 290.507 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1140/4776 | Loss: 293.625 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1150/4776 | Loss: 308.227 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1160/4776 | Loss: 320.238 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1170/4776 | Loss: 287.355 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1180/4776 | Loss: 299.185 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1190/4776 | Loss: 306.648 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1200/4776 | Loss: 300.458 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1210/4776 | Loss: 293.709 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1220/4776 | Loss: 279.370 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1230/4776 | Loss: 303.567 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1240/4776 | Loss: 298.487 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1250/4776 | Loss: 302.363 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1260/4776 | Loss: 312.124 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1270/4776 | Loss: 288.624 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1280/4776 | Loss: 302.488 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1290/4776 | Loss: 294.276 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1300/4776 | Loss: 308.358 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1310/4776 | Loss: 300.049 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1320/4776 | Loss: 312.055 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1330/4776 | Loss: 319.114 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1340/4776 | Loss: 295.553 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1350/4776 | Loss: 296.823 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1360/4776 | Loss: 294.701 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1370/4776 | Loss: 298.219 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1380/4776 | Loss: 282.576 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1390/4776 | Loss: 294.042 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1400/4776 | Loss: 308.386 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1410/4776 | Loss: 296.354 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1420/4776 | Loss: 292.626 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1430/4776 | Loss: 306.516 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1440/4776 | Loss: 292.626 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1450/4776 | Loss: 277.404 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1460/4776 | Loss: 289.913 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1470/4776 | Loss: 305.993 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1480/4776 | Loss: 284.311 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1490/4776 | Loss: 312.820 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1500/4776 | Loss: 296.879 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1510/4776 | Loss: 285.239 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1520/4776 | Loss: 291.366 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1530/4776 | Loss: 320.473 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1540/4776 | Loss: 314.820 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1550/4776 | Loss: 292.990 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1560/4776 | Loss: 283.405 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1570/4776 | Loss: 293.409 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1580/4776 | Loss: 274.495 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1590/4776 | Loss: 342.334 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1600/4776 | Loss: 308.333 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1610/4776 | Loss: 302.229 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1620/4776 | Loss: 294.047 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1630/4776 | Loss: 295.247 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1640/4776 | Loss: 302.561 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1650/4776 | Loss: 299.408 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1660/4776 | Loss: 309.535 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1670/4776 | Loss: 296.173 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1680/4776 | Loss: 309.833 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1690/4776 | Loss: 292.007 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1700/4776 | Loss: 305.028 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1710/4776 | Loss: 307.370 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1720/4776 | Loss: 302.288 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1730/4776 | Loss: 292.263 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1740/4776 | Loss: 285.475 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1750/4776 | Loss: 321.236 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1760/4776 | Loss: 296.618 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1770/4776 | Loss: 298.990 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1780/4776 | Loss: 296.109 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1790/4776 | Loss: 300.317 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1800/4776 | Loss: 286.371 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1810/4776 | Loss: 294.469 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1820/4776 | Loss: 307.599 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1830/4776 | Loss: 299.020 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1840/4776 | Loss: 296.235 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1850/4776 | Loss: 297.433 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1860/4776 | Loss: 291.806 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1870/4776 | Loss: 296.386 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1880/4776 | Loss: 288.612 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1890/4776 | Loss: 295.671 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1900/4776 | Loss: 294.090 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1910/4776 | Loss: 287.512 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1920/4776 | Loss: 314.979 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1930/4776 | Loss: 308.976 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1940/4776 | Loss: 300.429 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1950/4776 | Loss: 303.345 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1960/4776 | Loss: 302.471 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1970/4776 | Loss: 302.096 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1980/4776 | Loss: 299.919 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1990/4776 | Loss: 289.189 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2000/4776 | Loss: 295.413 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2010/4776 | Loss: 281.279 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2020/4776 | Loss: 288.551 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2030/4776 | Loss: 279.713 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 2040/4776 | Loss: 296.568 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2050/4776 | Loss: 308.996 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2060/4776 | Loss: 297.434 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2070/4776 | Loss: 282.228 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 2080/4776 | Loss: 288.217 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2090/4776 | Loss: 286.106 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2100/4776 | Loss: 277.882 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2110/4776 | Loss: 301.360 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2120/4776 | Loss: 281.781 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2130/4776 | Loss: 326.843 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2140/4776 | Loss: 309.033 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2150/4776 | Loss: 302.365 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2160/4776 | Loss: 299.131 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2170/4776 | Loss: 293.199 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2180/4776 | Loss: 289.375 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2190/4776 | Loss: 293.944 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2200/4776 | Loss: 286.367 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2210/4776 | Loss: 301.422 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2220/4776 | Loss: 266.164 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2230/4776 | Loss: 310.633 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2240/4776 | Loss: 310.134 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2250/4776 | Loss: 312.812 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2260/4776 | Loss: 298.391 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2270/4776 | Loss: 313.668 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2280/4776 | Loss: 294.326 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2290/4776 | Loss: 281.896 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2300/4776 | Loss: 301.875 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2310/4776 | Loss: 308.833 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2320/4776 | Loss: 284.609 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2330/4776 | Loss: 273.566 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2340/4776 | Loss: 300.661 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2350/4776 | Loss: 291.980 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2360/4776 | Loss: 292.453 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2370/4776 | Loss: 308.786 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2380/4776 | Loss: 291.435 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2390/4776 | Loss: 308.550 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2400/4776 | Loss: 311.172 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2410/4776 | Loss: 289.692 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2420/4776 | Loss: 289.369 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2430/4776 | Loss: 293.449 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2440/4776 | Loss: 313.168 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2450/4776 | Loss: 286.317 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2460/4776 | Loss: 297.386 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2470/4776 | Loss: 288.518 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2480/4776 | Loss: 303.159 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2490/4776 | Loss: 308.014 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2500/4776 | Loss: 262.609 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2510/4776 | Loss: 275.818 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2520/4776 | Loss: 333.796 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2530/4776 | Loss: 319.352 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2540/4776 | Loss: 290.686 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2550/4776 | Loss: 308.852 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2560/4776 | Loss: 297.622 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2570/4776 | Loss: 312.962 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2580/4776 | Loss: 271.395 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2590/4776 | Loss: 291.869 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2600/4776 | Loss: 313.899 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2610/4776 | Loss: 292.867 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2620/4776 | Loss: 301.170 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2630/4776 | Loss: 297.299 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2640/4776 | Loss: 299.801 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2650/4776 | Loss: 301.826 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2660/4776 | Loss: 292.131 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2670/4776 | Loss: 290.313 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2680/4776 | Loss: 288.689 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2690/4776 | Loss: 343.050 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2700/4776 | Loss: 298.736 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2710/4776 | Loss: 310.559 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2720/4776 | Loss: 291.300 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2730/4776 | Loss: 317.484 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2740/4776 | Loss: 296.256 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2750/4776 | Loss: 311.071 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2760/4776 | Loss: 297.702 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2770/4776 | Loss: 293.856 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2780/4776 | Loss: 286.120 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 2790/4776 | Loss: 307.980 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2800/4776 | Loss: 299.755 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2810/4776 | Loss: 301.891 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2820/4776 | Loss: 311.279 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2830/4776 | Loss: 305.461 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2840/4776 | Loss: 306.512 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2850/4776 | Loss: 299.781 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2860/4776 | Loss: 301.374 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2870/4776 | Loss: 292.712 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2880/4776 | Loss: 299.064 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2890/4776 | Loss: 286.130 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2900/4776 | Loss: 288.819 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2910/4776 | Loss: 285.148 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2920/4776 | Loss: 302.791 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2930/4776 | Loss: 314.738 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2940/4776 | Loss: 288.022 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2950/4776 | Loss: 307.295 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2960/4776 | Loss: 307.372 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 2970/4776 | Loss: 293.915 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 2980/4776 | Loss: 293.394 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 2990/4776 | Loss: 295.256 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3000/4776 | Loss: 301.863 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3010/4776 | Loss: 294.486 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3020/4776 | Loss: 313.286 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3030/4776 | Loss: 292.615 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3040/4776 | Loss: 271.046 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3050/4776 | Loss: 279.301 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3060/4776 | Loss: 286.850 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3070/4776 | Loss: 298.252 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3080/4776 | Loss: 292.297 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3090/4776 | Loss: 303.940 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3100/4776 | Loss: 322.607 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3110/4776 | Loss: 300.465 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3120/4776 | Loss: 303.795 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3130/4776 | Loss: 283.111 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3140/4776 | Loss: 288.457 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3150/4776 | Loss: 291.792 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3160/4776 | Loss: 323.737 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3170/4776 | Loss: 303.962 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3180/4776 | Loss: 305.741 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3190/4776 | Loss: 296.604 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3200/4776 | Loss: 306.810 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3210/4776 | Loss: 291.616 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3220/4776 | Loss: 306.021 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3230/4776 | Loss: 298.061 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3240/4776 | Loss: 307.947 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3250/4776 | Loss: 294.792 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3260/4776 | Loss: 305.190 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3270/4776 | Loss: 280.347 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3280/4776 | Loss: 316.244 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3290/4776 | Loss: 294.704 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3300/4776 | Loss: 263.568 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3310/4776 | Loss: 321.820 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3320/4776 | Loss: 303.287 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3330/4776 | Loss: 294.431 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3340/4776 | Loss: 311.656 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3350/4776 | Loss: 294.095 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3360/4776 | Loss: 306.010 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3370/4776 | Loss: 287.183 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3380/4776 | Loss: 302.966 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3390/4776 | Loss: 301.762 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3400/4776 | Loss: 282.348 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3410/4776 | Loss: 331.031 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3420/4776 | Loss: 304.346 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3430/4776 | Loss: 307.137 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3440/4776 | Loss: 305.877 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3450/4776 | Loss: 304.329 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3460/4776 | Loss: 287.293 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3470/4776 | Loss: 289.157 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3480/4776 | Loss: 304.942 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3490/4776 | Loss: 287.855 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3500/4776 | Loss: 301.567 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3510/4776 | Loss: 312.300 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3520/4776 | Loss: 325.949 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3530/4776 | Loss: 294.864 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3540/4776 | Loss: 303.575 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3550/4776 | Loss: 297.997 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3560/4776 | Loss: 305.678 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3570/4776 | Loss: 305.800 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3580/4776 | Loss: 301.742 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3590/4776 | Loss: 296.099 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3600/4776 | Loss: 304.874 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3610/4776 | Loss: 293.003 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3620/4776 | Loss: 304.237 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3630/4776 | Loss: 296.181 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3640/4776 | Loss: 300.677 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3650/4776 | Loss: 297.483 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3660/4776 | Loss: 288.945 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3670/4776 | Loss: 296.004 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3680/4776 | Loss: 283.912 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3690/4776 | Loss: 298.884 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3700/4776 | Loss: 286.011 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3710/4776 | Loss: 280.633 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3720/4776 | Loss: 302.742 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3730/4776 | Loss: 280.538 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3740/4776 | Loss: 265.635 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3750/4776 | Loss: 326.719 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3760/4776 | Loss: 296.461 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3770/4776 | Loss: 297.838 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3780/4776 | Loss: 255.694 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 3790/4776 | Loss: 283.897 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3800/4776 | Loss: 264.737 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3810/4776 | Loss: 310.861 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3820/4776 | Loss: 303.699 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3830/4776 | Loss: 320.992 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3840/4776 | Loss: 291.213 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3850/4776 | Loss: 297.629 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3860/4776 | Loss: 286.943 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3870/4776 | Loss: 311.015 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3880/4776 | Loss: 319.616 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3890/4776 | Loss: 300.221 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3900/4776 | Loss: 297.782 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3910/4776 | Loss: 290.005 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3920/4776 | Loss: 295.080 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3930/4776 | Loss: 288.703 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 3940/4776 | Loss: 306.116 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3950/4776 | Loss: 295.746 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 3960/4776 | Loss: 312.601 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 3970/4776 | Loss: 302.553 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 3980/4776 | Loss: 279.568 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 3990/4776 | Loss: 274.535 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4000/4776 | Loss: 309.959 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4010/4776 | Loss: 309.269 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4020/4776 | Loss: 304.622 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4030/4776 | Loss: 298.141 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4040/4776 | Loss: 295.961 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4050/4776 | Loss: 273.146 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4060/4776 | Loss: 301.403 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4070/4776 | Loss: 298.056 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4080/4776 | Loss: 307.634 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4090/4776 | Loss: 302.124 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4100/4776 | Loss: 260.383 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 4110/4776 | Loss: 277.082 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4120/4776 | Loss: 286.055 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4130/4776 | Loss: 313.067 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4140/4776 | Loss: 285.422 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4150/4776 | Loss: 308.638 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4160/4776 | Loss: 288.975 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4170/4776 | Loss: 299.653 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4180/4776 | Loss: 276.561 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4190/4776 | Loss: 323.697 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4200/4776 | Loss: 373.814 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4210/4776 | Loss: 308.361 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4220/4776 | Loss: 306.284 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4230/4776 | Loss: 303.226 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4240/4776 | Loss: 309.871 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4250/4776 | Loss: 300.240 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4260/4776 | Loss: 284.900 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4270/4776 | Loss: 298.174 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4280/4776 | Loss: 296.527 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4290/4776 | Loss: 298.987 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4300/4776 | Loss: 293.927 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4310/4776 | Loss: 299.115 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4320/4776 | Loss: 300.224 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4330/4776 | Loss: 293.551 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4340/4776 | Loss: 319.785 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4350/4776 | Loss: 297.494 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4360/4776 | Loss: 312.594 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4370/4776 | Loss: 303.609 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4380/4776 | Loss: 297.229 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4390/4776 | Loss: 307.754 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4400/4776 | Loss: 287.940 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4410/4776 | Loss: 299.739 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4420/4776 | Loss: 297.750 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4430/4776 | Loss: 319.995 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4440/4776 | Loss: 305.321 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4450/4776 | Loss: 280.005 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 4460/4776 | Loss: 299.936 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4470/4776 | Loss: 312.644 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4480/4776 | Loss: 296.234 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4490/4776 | Loss: 303.397 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4500/4776 | Loss: 288.350 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4510/4776 | Loss: 304.864 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4520/4776 | Loss: 314.246 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4530/4776 | Loss: 264.606 | Accuracy: 0.500\n",
      "[Epoch: 2/200] - Step: 4540/4776 | Loss: 276.149 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4550/4776 | Loss: 288.270 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4560/4776 | Loss: 348.186 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4570/4776 | Loss: 275.791 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4580/4776 | Loss: 291.366 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4590/4776 | Loss: 300.057 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4600/4776 | Loss: 301.546 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4610/4776 | Loss: 304.854 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4620/4776 | Loss: 311.102 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4630/4776 | Loss: 303.584 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4640/4776 | Loss: 310.855 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4650/4776 | Loss: 297.193 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4660/4776 | Loss: 291.001 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4670/4776 | Loss: 282.297 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 4680/4776 | Loss: 283.118 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4690/4776 | Loss: 304.483 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4700/4776 | Loss: 295.758 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4710/4776 | Loss: 306.403 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4720/4776 | Loss: 288.217 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4730/4776 | Loss: 305.839 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4740/4776 | Loss: 293.404 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 4750/4776 | Loss: 308.543 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 4760/4776 | Loss: 283.578 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 4770/4776 | Loss: 282.429 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 3/200] - Step: 10/4776 | Loss: 274.607 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 20/4776 | Loss: 283.937 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 30/4776 | Loss: 262.917 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 40/4776 | Loss: 339.319 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 50/4776 | Loss: 291.837 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 60/4776 | Loss: 272.835 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 70/4776 | Loss: 312.025 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 80/4776 | Loss: 272.206 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 90/4776 | Loss: 311.543 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 100/4776 | Loss: 271.409 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 110/4776 | Loss: 293.067 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 120/4776 | Loss: 321.580 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 130/4776 | Loss: 291.761 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 140/4776 | Loss: 279.946 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 150/4776 | Loss: 277.915 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 160/4776 | Loss: 308.811 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 170/4776 | Loss: 302.695 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 180/4776 | Loss: 312.917 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 190/4776 | Loss: 305.304 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 200/4776 | Loss: 324.788 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 210/4776 | Loss: 294.671 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 220/4776 | Loss: 298.769 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 230/4776 | Loss: 314.007 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 240/4776 | Loss: 295.649 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 250/4776 | Loss: 275.076 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 260/4776 | Loss: 297.495 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 270/4776 | Loss: 289.171 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 280/4776 | Loss: 303.040 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 290/4776 | Loss: 282.580 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 300/4776 | Loss: 324.630 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 310/4776 | Loss: 312.756 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 320/4776 | Loss: 290.465 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 330/4776 | Loss: 291.146 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 340/4776 | Loss: 283.879 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 350/4776 | Loss: 314.953 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 360/4776 | Loss: 307.167 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 370/4776 | Loss: 307.548 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 380/4776 | Loss: 304.708 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 390/4776 | Loss: 303.444 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 400/4776 | Loss: 301.041 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 410/4776 | Loss: 297.275 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 420/4776 | Loss: 296.844 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 430/4776 | Loss: 317.807 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 440/4776 | Loss: 276.524 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 450/4776 | Loss: 292.338 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 460/4776 | Loss: 292.718 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 470/4776 | Loss: 306.837 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 480/4776 | Loss: 302.194 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 490/4776 | Loss: 297.984 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 500/4776 | Loss: 306.545 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 510/4776 | Loss: 294.116 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 520/4776 | Loss: 297.469 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 530/4776 | Loss: 274.505 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 540/4776 | Loss: 309.991 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 550/4776 | Loss: 297.102 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 560/4776 | Loss: 282.608 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 570/4776 | Loss: 307.030 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 580/4776 | Loss: 310.882 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 590/4776 | Loss: 305.633 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 600/4776 | Loss: 271.924 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 610/4776 | Loss: 307.322 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 620/4776 | Loss: 297.991 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 630/4776 | Loss: 305.600 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 640/4776 | Loss: 293.349 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 650/4776 | Loss: 306.245 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 660/4776 | Loss: 295.167 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 670/4776 | Loss: 285.967 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 680/4776 | Loss: 318.724 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 690/4776 | Loss: 318.710 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 700/4776 | Loss: 309.040 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 710/4776 | Loss: 303.326 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 720/4776 | Loss: 290.895 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 730/4776 | Loss: 281.888 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 740/4776 | Loss: 288.637 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 750/4776 | Loss: 303.351 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 760/4776 | Loss: 296.871 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 770/4776 | Loss: 298.533 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 780/4776 | Loss: 276.417 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 790/4776 | Loss: 301.364 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 800/4776 | Loss: 296.607 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 810/4776 | Loss: 306.775 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 820/4776 | Loss: 319.786 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 830/4776 | Loss: 309.831 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 840/4776 | Loss: 285.762 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 850/4776 | Loss: 289.105 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 860/4776 | Loss: 291.742 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 870/4776 | Loss: 295.896 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 880/4776 | Loss: 304.736 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 890/4776 | Loss: 297.931 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 900/4776 | Loss: 296.005 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 910/4776 | Loss: 286.555 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 920/4776 | Loss: 300.440 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 930/4776 | Loss: 292.214 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 940/4776 | Loss: 287.079 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 950/4776 | Loss: 284.851 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 960/4776 | Loss: 304.069 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 970/4776 | Loss: 301.790 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 980/4776 | Loss: 289.367 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 990/4776 | Loss: 302.182 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1000/4776 | Loss: 293.726 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1010/4776 | Loss: 301.721 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1020/4776 | Loss: 291.378 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1030/4776 | Loss: 307.931 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1040/4776 | Loss: 320.954 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1050/4776 | Loss: 309.261 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1060/4776 | Loss: 297.027 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1070/4776 | Loss: 306.282 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1080/4776 | Loss: 291.121 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1090/4776 | Loss: 287.573 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 1100/4776 | Loss: 298.861 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1110/4776 | Loss: 289.452 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1120/4776 | Loss: 283.746 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1130/4776 | Loss: 303.665 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1140/4776 | Loss: 310.283 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1150/4776 | Loss: 270.006 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1160/4776 | Loss: 288.473 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1170/4776 | Loss: 318.944 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1180/4776 | Loss: 287.438 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1190/4776 | Loss: 309.415 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1200/4776 | Loss: 302.666 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1210/4776 | Loss: 296.278 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1220/4776 | Loss: 293.729 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1230/4776 | Loss: 280.112 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1240/4776 | Loss: 303.029 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1250/4776 | Loss: 296.742 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1260/4776 | Loss: 308.579 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1270/4776 | Loss: 297.949 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1280/4776 | Loss: 300.445 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1290/4776 | Loss: 305.004 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1300/4776 | Loss: 295.272 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1310/4776 | Loss: 303.754 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1320/4776 | Loss: 269.466 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 1330/4776 | Loss: 281.531 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1340/4776 | Loss: 296.601 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1350/4776 | Loss: 268.879 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1360/4776 | Loss: 298.364 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1370/4776 | Loss: 319.683 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1380/4776 | Loss: 312.944 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1390/4776 | Loss: 292.085 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1400/4776 | Loss: 293.097 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1410/4776 | Loss: 301.757 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1420/4776 | Loss: 294.076 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1430/4776 | Loss: 294.599 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1440/4776 | Loss: 290.198 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1450/4776 | Loss: 293.450 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1460/4776 | Loss: 294.494 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1470/4776 | Loss: 299.840 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1480/4776 | Loss: 309.176 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1490/4776 | Loss: 292.000 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1500/4776 | Loss: 272.780 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1510/4776 | Loss: 306.332 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1520/4776 | Loss: 296.847 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1530/4776 | Loss: 305.076 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1540/4776 | Loss: 274.102 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1550/4776 | Loss: 323.282 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1560/4776 | Loss: 299.059 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1570/4776 | Loss: 283.955 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1580/4776 | Loss: 287.872 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1590/4776 | Loss: 284.996 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1600/4776 | Loss: 301.411 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1610/4776 | Loss: 319.284 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1620/4776 | Loss: 286.511 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 1630/4776 | Loss: 296.837 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1640/4776 | Loss: 308.405 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1650/4776 | Loss: 259.202 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 1660/4776 | Loss: 260.481 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1670/4776 | Loss: 279.003 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1680/4776 | Loss: 316.091 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1690/4776 | Loss: 318.296 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1700/4776 | Loss: 328.041 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1710/4776 | Loss: 274.504 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1720/4776 | Loss: 266.779 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1730/4776 | Loss: 289.692 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1740/4776 | Loss: 293.017 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1750/4776 | Loss: 336.156 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1760/4776 | Loss: 287.484 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1770/4776 | Loss: 291.854 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1780/4776 | Loss: 280.870 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1790/4776 | Loss: 290.055 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1800/4776 | Loss: 292.417 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1810/4776 | Loss: 321.208 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1820/4776 | Loss: 284.507 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1830/4776 | Loss: 306.019 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1840/4776 | Loss: 299.180 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1850/4776 | Loss: 307.709 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1860/4776 | Loss: 286.670 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1870/4776 | Loss: 288.389 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1880/4776 | Loss: 282.486 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1890/4776 | Loss: 288.581 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1900/4776 | Loss: 301.516 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1910/4776 | Loss: 297.306 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1920/4776 | Loss: 299.729 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1930/4776 | Loss: 296.037 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1940/4776 | Loss: 281.462 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1950/4776 | Loss: 275.347 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1960/4776 | Loss: 302.137 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1970/4776 | Loss: 285.338 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1980/4776 | Loss: 317.005 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1990/4776 | Loss: 296.860 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2000/4776 | Loss: 298.296 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2010/4776 | Loss: 283.280 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2020/4776 | Loss: 320.694 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2030/4776 | Loss: 295.016 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2040/4776 | Loss: 310.616 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2050/4776 | Loss: 298.378 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2060/4776 | Loss: 293.628 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2070/4776 | Loss: 323.837 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2080/4776 | Loss: 289.394 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2090/4776 | Loss: 297.274 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2100/4776 | Loss: 302.684 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2110/4776 | Loss: 289.355 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2120/4776 | Loss: 290.748 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2130/4776 | Loss: 269.622 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2140/4776 | Loss: 304.897 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2150/4776 | Loss: 272.007 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2160/4776 | Loss: 300.835 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2170/4776 | Loss: 308.350 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2180/4776 | Loss: 296.963 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2190/4776 | Loss: 301.251 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2200/4776 | Loss: 307.335 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2210/4776 | Loss: 290.458 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2220/4776 | Loss: 295.424 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2230/4776 | Loss: 310.738 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2240/4776 | Loss: 300.143 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2250/4776 | Loss: 330.679 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2260/4776 | Loss: 303.354 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2270/4776 | Loss: 307.011 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2280/4776 | Loss: 306.151 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2290/4776 | Loss: 303.720 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2300/4776 | Loss: 304.930 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2310/4776 | Loss: 311.280 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2320/4776 | Loss: 293.000 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2330/4776 | Loss: 296.020 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2340/4776 | Loss: 302.098 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2350/4776 | Loss: 291.507 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2360/4776 | Loss: 285.354 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2370/4776 | Loss: 289.657 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2380/4776 | Loss: 301.255 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2390/4776 | Loss: 299.892 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2400/4776 | Loss: 320.291 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2410/4776 | Loss: 295.277 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2420/4776 | Loss: 318.023 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2430/4776 | Loss: 302.635 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2440/4776 | Loss: 309.649 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2450/4776 | Loss: 302.498 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2460/4776 | Loss: 303.740 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2470/4776 | Loss: 285.074 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2480/4776 | Loss: 291.493 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2490/4776 | Loss: 282.850 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2500/4776 | Loss: 301.817 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2510/4776 | Loss: 297.807 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2520/4776 | Loss: 277.720 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2530/4776 | Loss: 299.040 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2540/4776 | Loss: 302.464 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2550/4776 | Loss: 310.385 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2560/4776 | Loss: 299.598 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2570/4776 | Loss: 278.502 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2580/4776 | Loss: 316.783 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2590/4776 | Loss: 298.161 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2600/4776 | Loss: 288.367 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2610/4776 | Loss: 287.378 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2620/4776 | Loss: 279.843 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2630/4776 | Loss: 296.955 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2640/4776 | Loss: 300.367 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2650/4776 | Loss: 296.052 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2660/4776 | Loss: 314.506 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2670/4776 | Loss: 296.180 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2680/4776 | Loss: 287.216 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2690/4776 | Loss: 292.521 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2700/4776 | Loss: 291.638 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2710/4776 | Loss: 292.645 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2720/4776 | Loss: 302.429 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2730/4776 | Loss: 295.864 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2740/4776 | Loss: 305.929 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2750/4776 | Loss: 305.346 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2760/4776 | Loss: 276.894 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2770/4776 | Loss: 303.141 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2780/4776 | Loss: 314.453 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2790/4776 | Loss: 283.319 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2800/4776 | Loss: 299.179 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2810/4776 | Loss: 288.115 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2820/4776 | Loss: 308.713 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2830/4776 | Loss: 300.078 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2840/4776 | Loss: 274.002 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2850/4776 | Loss: 288.859 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2860/4776 | Loss: 287.150 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2870/4776 | Loss: 291.977 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2880/4776 | Loss: 308.199 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2890/4776 | Loss: 302.870 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2900/4776 | Loss: 280.969 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2910/4776 | Loss: 297.154 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2920/4776 | Loss: 271.968 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2930/4776 | Loss: 302.298 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2940/4776 | Loss: 293.693 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2950/4776 | Loss: 279.903 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 2960/4776 | Loss: 287.139 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 2970/4776 | Loss: 306.223 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 2980/4776 | Loss: 300.101 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 2990/4776 | Loss: 310.414 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3000/4776 | Loss: 278.671 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 3010/4776 | Loss: 307.367 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3020/4776 | Loss: 280.120 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3030/4776 | Loss: 290.396 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3040/4776 | Loss: 303.445 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3050/4776 | Loss: 307.566 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3060/4776 | Loss: 302.801 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3070/4776 | Loss: 292.294 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3080/4776 | Loss: 279.161 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 3090/4776 | Loss: 285.213 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3100/4776 | Loss: 295.878 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3110/4776 | Loss: 299.019 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3120/4776 | Loss: 317.080 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3130/4776 | Loss: 290.218 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3140/4776 | Loss: 324.889 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3150/4776 | Loss: 270.982 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3160/4776 | Loss: 322.250 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3170/4776 | Loss: 281.535 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3180/4776 | Loss: 287.142 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3190/4776 | Loss: 305.799 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3200/4776 | Loss: 306.931 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3210/4776 | Loss: 297.204 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3220/4776 | Loss: 306.418 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3230/4776 | Loss: 302.462 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3240/4776 | Loss: 295.204 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3250/4776 | Loss: 290.586 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 3260/4776 | Loss: 290.667 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3270/4776 | Loss: 285.496 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3280/4776 | Loss: 314.430 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3290/4776 | Loss: 292.063 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3300/4776 | Loss: 302.113 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3310/4776 | Loss: 305.463 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3320/4776 | Loss: 292.652 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3330/4776 | Loss: 298.162 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3340/4776 | Loss: 296.179 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3350/4776 | Loss: 337.613 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3360/4776 | Loss: 299.862 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3370/4776 | Loss: 310.049 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3380/4776 | Loss: 295.618 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3390/4776 | Loss: 281.527 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3400/4776 | Loss: 302.362 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3410/4776 | Loss: 317.822 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3420/4776 | Loss: 312.370 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3430/4776 | Loss: 289.438 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3440/4776 | Loss: 293.266 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3450/4776 | Loss: 297.979 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3460/4776 | Loss: 296.719 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3470/4776 | Loss: 292.164 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3480/4776 | Loss: 306.073 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3490/4776 | Loss: 301.863 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3500/4776 | Loss: 330.274 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3510/4776 | Loss: 293.597 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3520/4776 | Loss: 300.171 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3530/4776 | Loss: 317.541 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3540/4776 | Loss: 286.798 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3550/4776 | Loss: 305.320 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3560/4776 | Loss: 286.658 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 3570/4776 | Loss: 285.019 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3580/4776 | Loss: 295.303 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3590/4776 | Loss: 303.691 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3600/4776 | Loss: 295.238 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3610/4776 | Loss: 309.027 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3620/4776 | Loss: 297.015 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3630/4776 | Loss: 304.754 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3640/4776 | Loss: 295.001 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3650/4776 | Loss: 293.336 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3660/4776 | Loss: 279.159 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3670/4776 | Loss: 309.810 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3680/4776 | Loss: 314.748 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3690/4776 | Loss: 319.450 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3700/4776 | Loss: 297.888 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3710/4776 | Loss: 304.854 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3720/4776 | Loss: 300.806 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3730/4776 | Loss: 298.196 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3740/4776 | Loss: 301.809 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3750/4776 | Loss: 308.309 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3760/4776 | Loss: 297.179 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3770/4776 | Loss: 289.662 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3780/4776 | Loss: 304.786 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3790/4776 | Loss: 294.002 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3800/4776 | Loss: 313.842 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3810/4776 | Loss: 308.436 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3820/4776 | Loss: 297.602 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3830/4776 | Loss: 305.781 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3840/4776 | Loss: 307.275 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3850/4776 | Loss: 295.583 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3860/4776 | Loss: 298.457 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3870/4776 | Loss: 298.003 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3880/4776 | Loss: 303.105 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3890/4776 | Loss: 302.526 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3900/4776 | Loss: 271.119 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 3910/4776 | Loss: 304.714 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3920/4776 | Loss: 304.058 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3930/4776 | Loss: 292.026 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 3940/4776 | Loss: 306.258 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3950/4776 | Loss: 314.217 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3960/4776 | Loss: 292.770 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 3970/4776 | Loss: 307.525 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 3980/4776 | Loss: 305.211 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 3990/4776 | Loss: 301.561 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4000/4776 | Loss: 306.794 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4010/4776 | Loss: 326.685 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4020/4776 | Loss: 294.854 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4030/4776 | Loss: 307.074 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4040/4776 | Loss: 306.603 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4050/4776 | Loss: 300.052 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4060/4776 | Loss: 295.760 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4070/4776 | Loss: 303.459 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4080/4776 | Loss: 308.769 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4090/4776 | Loss: 281.345 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 4100/4776 | Loss: 302.913 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4110/4776 | Loss: 308.550 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4120/4776 | Loss: 306.361 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4130/4776 | Loss: 281.919 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 4140/4776 | Loss: 308.846 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4150/4776 | Loss: 282.795 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4160/4776 | Loss: 292.957 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4170/4776 | Loss: 296.594 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4180/4776 | Loss: 305.224 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4190/4776 | Loss: 305.826 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4200/4776 | Loss: 294.206 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4210/4776 | Loss: 299.750 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4220/4776 | Loss: 295.471 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4230/4776 | Loss: 287.341 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4240/4776 | Loss: 289.556 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4250/4776 | Loss: 305.347 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4260/4776 | Loss: 312.912 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4270/4776 | Loss: 300.087 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4280/4776 | Loss: 311.786 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4290/4776 | Loss: 294.838 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4300/4776 | Loss: 294.964 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4310/4776 | Loss: 296.571 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4320/4776 | Loss: 303.221 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4330/4776 | Loss: 282.143 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4340/4776 | Loss: 294.049 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4350/4776 | Loss: 283.497 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 4360/4776 | Loss: 296.218 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4370/4776 | Loss: 295.020 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4380/4776 | Loss: 292.413 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4390/4776 | Loss: 296.332 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4400/4776 | Loss: 298.687 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4410/4776 | Loss: 314.049 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4420/4776 | Loss: 298.722 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4430/4776 | Loss: 290.593 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4440/4776 | Loss: 289.430 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4450/4776 | Loss: 293.788 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4460/4776 | Loss: 309.104 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4470/4776 | Loss: 297.849 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4480/4776 | Loss: 298.043 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4490/4776 | Loss: 303.709 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4500/4776 | Loss: 308.523 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4510/4776 | Loss: 303.291 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4520/4776 | Loss: 301.255 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4530/4776 | Loss: 307.242 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4540/4776 | Loss: 296.364 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4550/4776 | Loss: 282.967 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4560/4776 | Loss: 316.348 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4570/4776 | Loss: 335.471 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4580/4776 | Loss: 303.507 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4590/4776 | Loss: 298.624 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4600/4776 | Loss: 304.071 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4610/4776 | Loss: 294.870 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4620/4776 | Loss: 294.107 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4630/4776 | Loss: 288.599 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4640/4776 | Loss: 305.893 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4650/4776 | Loss: 303.995 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4660/4776 | Loss: 298.371 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4670/4776 | Loss: 300.525 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4680/4776 | Loss: 304.708 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4690/4776 | Loss: 319.591 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4700/4776 | Loss: 292.523 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 4710/4776 | Loss: 279.927 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 4720/4776 | Loss: 290.278 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4730/4776 | Loss: 310.977 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4740/4776 | Loss: 295.924 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4750/4776 | Loss: 304.128 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 4760/4776 | Loss: 301.420 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 4770/4776 | Loss: 296.594 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 4/200] - Step: 10/4776 | Loss: 314.581 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 20/4776 | Loss: 310.596 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 30/4776 | Loss: 301.378 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 40/4776 | Loss: 297.656 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 50/4776 | Loss: 329.477 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 60/4776 | Loss: 304.431 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 70/4776 | Loss: 283.442 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 80/4776 | Loss: 304.735 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 90/4776 | Loss: 290.655 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 100/4776 | Loss: 305.871 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 110/4776 | Loss: 290.093 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 120/4776 | Loss: 328.907 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 130/4776 | Loss: 289.070 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 140/4776 | Loss: 305.184 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 150/4776 | Loss: 296.244 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 160/4776 | Loss: 283.920 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 170/4776 | Loss: 279.268 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 180/4776 | Loss: 292.781 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 190/4776 | Loss: 281.246 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 200/4776 | Loss: 315.414 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 210/4776 | Loss: 309.457 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 220/4776 | Loss: 278.653 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 230/4776 | Loss: 296.656 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 240/4776 | Loss: 300.907 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 250/4776 | Loss: 298.730 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 260/4776 | Loss: 314.185 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 270/4776 | Loss: 310.756 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 280/4776 | Loss: 304.298 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 290/4776 | Loss: 289.896 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 300/4776 | Loss: 278.208 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 310/4776 | Loss: 282.072 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 320/4776 | Loss: 330.133 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 330/4776 | Loss: 291.864 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 340/4776 | Loss: 285.563 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 350/4776 | Loss: 289.254 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 360/4776 | Loss: 293.372 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 370/4776 | Loss: 297.086 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 380/4776 | Loss: 285.002 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 390/4776 | Loss: 301.309 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 400/4776 | Loss: 286.936 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 410/4776 | Loss: 300.730 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 420/4776 | Loss: 296.261 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 430/4776 | Loss: 294.055 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 440/4776 | Loss: 291.601 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 450/4776 | Loss: 297.505 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 460/4776 | Loss: 291.070 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 470/4776 | Loss: 308.994 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 480/4776 | Loss: 286.516 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 490/4776 | Loss: 305.333 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 500/4776 | Loss: 267.533 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 510/4776 | Loss: 289.085 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 520/4776 | Loss: 303.443 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 530/4776 | Loss: 279.631 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 540/4776 | Loss: 301.858 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 550/4776 | Loss: 297.791 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 560/4776 | Loss: 309.034 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 570/4776 | Loss: 296.322 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 580/4776 | Loss: 289.279 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 590/4776 | Loss: 293.232 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 600/4776 | Loss: 328.802 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 610/4776 | Loss: 308.217 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 620/4776 | Loss: 294.453 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 630/4776 | Loss: 271.127 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 640/4776 | Loss: 282.276 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 650/4776 | Loss: 301.837 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 660/4776 | Loss: 312.937 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 670/4776 | Loss: 271.030 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 680/4776 | Loss: 286.317 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 690/4776 | Loss: 310.286 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 700/4776 | Loss: 297.493 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 710/4776 | Loss: 288.848 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 720/4776 | Loss: 300.568 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 730/4776 | Loss: 310.439 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 740/4776 | Loss: 285.258 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 750/4776 | Loss: 313.286 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 760/4776 | Loss: 296.972 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 770/4776 | Loss: 310.523 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 780/4776 | Loss: 286.935 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 790/4776 | Loss: 291.907 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 800/4776 | Loss: 316.305 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 810/4776 | Loss: 284.284 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 820/4776 | Loss: 297.274 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 830/4776 | Loss: 282.887 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 840/4776 | Loss: 300.523 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 850/4776 | Loss: 294.558 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 860/4776 | Loss: 303.906 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 870/4776 | Loss: 313.110 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 880/4776 | Loss: 303.064 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 890/4776 | Loss: 287.076 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 900/4776 | Loss: 285.346 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 910/4776 | Loss: 305.424 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 920/4776 | Loss: 298.286 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 930/4776 | Loss: 322.861 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 940/4776 | Loss: 289.488 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 950/4776 | Loss: 303.187 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 960/4776 | Loss: 295.073 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 970/4776 | Loss: 286.431 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 980/4776 | Loss: 300.152 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 990/4776 | Loss: 295.175 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1000/4776 | Loss: 301.559 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1010/4776 | Loss: 298.866 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1020/4776 | Loss: 307.511 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1030/4776 | Loss: 299.947 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1040/4776 | Loss: 293.236 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1050/4776 | Loss: 296.436 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1060/4776 | Loss: 292.183 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1070/4776 | Loss: 294.196 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1080/4776 | Loss: 312.540 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1090/4776 | Loss: 312.589 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1100/4776 | Loss: 295.148 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1110/4776 | Loss: 300.451 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1120/4776 | Loss: 292.376 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1130/4776 | Loss: 303.136 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1140/4776 | Loss: 306.471 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1150/4776 | Loss: 298.643 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1160/4776 | Loss: 313.104 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1170/4776 | Loss: 307.875 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1180/4776 | Loss: 293.773 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1190/4776 | Loss: 294.040 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1200/4776 | Loss: 317.611 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1210/4776 | Loss: 287.749 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1220/4776 | Loss: 291.504 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1230/4776 | Loss: 299.419 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1240/4776 | Loss: 295.419 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1250/4776 | Loss: 292.651 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1260/4776 | Loss: 328.247 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1270/4776 | Loss: 280.070 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1280/4776 | Loss: 275.196 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1290/4776 | Loss: 266.702 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1300/4776 | Loss: 303.036 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1310/4776 | Loss: 304.788 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1320/4776 | Loss: 305.488 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1330/4776 | Loss: 291.775 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1340/4776 | Loss: 327.511 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1350/4776 | Loss: 291.417 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1360/4776 | Loss: 308.489 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1370/4776 | Loss: 315.434 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1380/4776 | Loss: 308.578 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1390/4776 | Loss: 300.299 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1400/4776 | Loss: 296.960 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1410/4776 | Loss: 307.525 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1420/4776 | Loss: 296.715 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1430/4776 | Loss: 313.322 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1440/4776 | Loss: 301.291 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1450/4776 | Loss: 293.387 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1460/4776 | Loss: 297.698 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1470/4776 | Loss: 302.738 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1480/4776 | Loss: 309.266 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1490/4776 | Loss: 300.123 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1500/4776 | Loss: 301.616 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1510/4776 | Loss: 295.987 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1520/4776 | Loss: 302.865 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1530/4776 | Loss: 309.163 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1540/4776 | Loss: 301.902 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1550/4776 | Loss: 310.854 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1560/4776 | Loss: 304.992 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1570/4776 | Loss: 308.658 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1580/4776 | Loss: 295.547 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1590/4776 | Loss: 290.606 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1600/4776 | Loss: 297.253 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1610/4776 | Loss: 310.589 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1620/4776 | Loss: 293.819 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1630/4776 | Loss: 296.611 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1640/4776 | Loss: 294.609 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1650/4776 | Loss: 282.625 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1660/4776 | Loss: 300.861 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1670/4776 | Loss: 316.781 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1680/4776 | Loss: 277.979 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1690/4776 | Loss: 289.968 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1700/4776 | Loss: 334.191 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1710/4776 | Loss: 293.068 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1720/4776 | Loss: 285.451 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1730/4776 | Loss: 303.247 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1740/4776 | Loss: 287.184 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1750/4776 | Loss: 286.521 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1760/4776 | Loss: 312.660 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1770/4776 | Loss: 282.020 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1780/4776 | Loss: 284.594 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1790/4776 | Loss: 335.360 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1800/4776 | Loss: 296.238 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1810/4776 | Loss: 288.046 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1820/4776 | Loss: 298.424 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1830/4776 | Loss: 301.671 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1840/4776 | Loss: 302.518 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1850/4776 | Loss: 306.116 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1860/4776 | Loss: 298.376 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1870/4776 | Loss: 291.692 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1880/4776 | Loss: 283.977 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1890/4776 | Loss: 279.142 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1900/4776 | Loss: 335.425 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1910/4776 | Loss: 296.660 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1920/4776 | Loss: 288.540 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1930/4776 | Loss: 292.583 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1940/4776 | Loss: 305.987 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1950/4776 | Loss: 286.758 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1960/4776 | Loss: 290.560 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1970/4776 | Loss: 284.784 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1980/4776 | Loss: 311.604 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1990/4776 | Loss: 302.079 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2000/4776 | Loss: 312.456 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2010/4776 | Loss: 295.930 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2020/4776 | Loss: 311.915 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2030/4776 | Loss: 297.642 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2040/4776 | Loss: 292.123 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2050/4776 | Loss: 307.371 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2060/4776 | Loss: 291.154 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2070/4776 | Loss: 294.536 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2080/4776 | Loss: 295.076 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2090/4776 | Loss: 275.866 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 2100/4776 | Loss: 297.227 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2110/4776 | Loss: 294.791 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2120/4776 | Loss: 305.260 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2130/4776 | Loss: 296.754 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2140/4776 | Loss: 288.326 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2150/4776 | Loss: 294.465 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2160/4776 | Loss: 272.708 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 2170/4776 | Loss: 303.195 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2180/4776 | Loss: 285.438 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2190/4776 | Loss: 274.529 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 2200/4776 | Loss: 354.331 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2210/4776 | Loss: 292.169 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2220/4776 | Loss: 307.136 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2230/4776 | Loss: 300.222 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2240/4776 | Loss: 305.911 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2250/4776 | Loss: 298.413 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2260/4776 | Loss: 295.332 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2270/4776 | Loss: 291.149 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2280/4776 | Loss: 310.550 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2290/4776 | Loss: 310.511 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2300/4776 | Loss: 303.784 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2310/4776 | Loss: 304.616 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2320/4776 | Loss: 300.386 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2330/4776 | Loss: 306.326 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2340/4776 | Loss: 299.800 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2350/4776 | Loss: 302.061 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2360/4776 | Loss: 300.140 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2370/4776 | Loss: 298.677 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2380/4776 | Loss: 312.529 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2390/4776 | Loss: 293.840 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2400/4776 | Loss: 305.925 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2410/4776 | Loss: 304.395 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2420/4776 | Loss: 279.458 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 2430/4776 | Loss: 301.662 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2440/4776 | Loss: 294.555 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2450/4776 | Loss: 293.217 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2460/4776 | Loss: 301.878 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2470/4776 | Loss: 284.772 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2480/4776 | Loss: 318.028 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2490/4776 | Loss: 292.648 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2500/4776 | Loss: 283.385 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2510/4776 | Loss: 294.821 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2520/4776 | Loss: 294.530 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2530/4776 | Loss: 292.727 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2540/4776 | Loss: 285.173 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2550/4776 | Loss: 294.152 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2560/4776 | Loss: 294.009 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2570/4776 | Loss: 299.731 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2580/4776 | Loss: 295.726 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2590/4776 | Loss: 327.383 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2600/4776 | Loss: 280.770 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2610/4776 | Loss: 291.388 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2620/4776 | Loss: 291.330 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2630/4776 | Loss: 300.808 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2640/4776 | Loss: 295.814 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2650/4776 | Loss: 300.836 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2660/4776 | Loss: 303.099 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2670/4776 | Loss: 299.273 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2680/4776 | Loss: 305.916 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2690/4776 | Loss: 300.668 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2700/4776 | Loss: 274.177 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 2710/4776 | Loss: 296.983 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2720/4776 | Loss: 295.006 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2730/4776 | Loss: 284.618 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2740/4776 | Loss: 261.332 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 2750/4776 | Loss: 316.985 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2760/4776 | Loss: 302.539 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2770/4776 | Loss: 292.752 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2780/4776 | Loss: 309.039 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2790/4776 | Loss: 321.422 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2800/4776 | Loss: 298.694 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2810/4776 | Loss: 287.666 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2820/4776 | Loss: 282.670 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 2830/4776 | Loss: 293.777 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2840/4776 | Loss: 287.987 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2850/4776 | Loss: 308.816 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2860/4776 | Loss: 314.955 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2870/4776 | Loss: 287.839 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2880/4776 | Loss: 314.127 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2890/4776 | Loss: 293.840 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2900/4776 | Loss: 301.234 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2910/4776 | Loss: 292.996 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2920/4776 | Loss: 302.662 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2930/4776 | Loss: 294.532 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2940/4776 | Loss: 293.828 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2950/4776 | Loss: 291.696 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2960/4776 | Loss: 289.123 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 2970/4776 | Loss: 285.891 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 2980/4776 | Loss: 308.608 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 2990/4776 | Loss: 299.847 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3000/4776 | Loss: 305.364 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3010/4776 | Loss: 298.909 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3020/4776 | Loss: 294.026 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3030/4776 | Loss: 303.323 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3040/4776 | Loss: 304.738 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3050/4776 | Loss: 301.764 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3060/4776 | Loss: 331.337 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3070/4776 | Loss: 304.089 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3080/4776 | Loss: 296.350 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3090/4776 | Loss: 295.571 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3100/4776 | Loss: 305.579 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3110/4776 | Loss: 300.976 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3120/4776 | Loss: 294.056 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3130/4776 | Loss: 283.207 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3140/4776 | Loss: 303.026 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3150/4776 | Loss: 285.835 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3160/4776 | Loss: 295.958 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3170/4776 | Loss: 269.245 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3180/4776 | Loss: 298.964 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3190/4776 | Loss: 293.298 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3200/4776 | Loss: 312.298 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3210/4776 | Loss: 294.414 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3220/4776 | Loss: 287.444 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3230/4776 | Loss: 291.928 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3240/4776 | Loss: 292.556 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3250/4776 | Loss: 297.610 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3260/4776 | Loss: 288.568 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3270/4776 | Loss: 309.518 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3280/4776 | Loss: 309.735 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3290/4776 | Loss: 302.148 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3300/4776 | Loss: 294.493 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3310/4776 | Loss: 302.056 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3320/4776 | Loss: 294.924 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3330/4776 | Loss: 313.124 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3340/4776 | Loss: 304.989 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3350/4776 | Loss: 299.331 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3360/4776 | Loss: 290.683 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3370/4776 | Loss: 283.611 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3380/4776 | Loss: 304.808 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3390/4776 | Loss: 303.977 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3400/4776 | Loss: 312.682 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3410/4776 | Loss: 286.671 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3420/4776 | Loss: 276.045 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3430/4776 | Loss: 303.690 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3440/4776 | Loss: 291.371 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3450/4776 | Loss: 300.226 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3460/4776 | Loss: 298.329 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3470/4776 | Loss: 309.049 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3480/4776 | Loss: 309.598 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3490/4776 | Loss: 302.250 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3500/4776 | Loss: 314.010 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3510/4776 | Loss: 309.984 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3520/4776 | Loss: 293.635 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3530/4776 | Loss: 297.929 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3540/4776 | Loss: 291.255 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3550/4776 | Loss: 295.308 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3560/4776 | Loss: 291.352 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3570/4776 | Loss: 290.948 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3580/4776 | Loss: 299.725 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3590/4776 | Loss: 303.925 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3600/4776 | Loss: 304.491 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3610/4776 | Loss: 278.284 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3620/4776 | Loss: 275.306 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3630/4776 | Loss: 282.718 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3640/4776 | Loss: 280.145 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3650/4776 | Loss: 319.572 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3660/4776 | Loss: 256.813 | Accuracy: 0.500\n",
      "[Epoch: 4/200] - Step: 3670/4776 | Loss: 311.174 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3680/4776 | Loss: 272.526 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 3690/4776 | Loss: 300.365 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3700/4776 | Loss: 313.614 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3710/4776 | Loss: 292.993 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3720/4776 | Loss: 296.578 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3730/4776 | Loss: 309.424 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3740/4776 | Loss: 292.879 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3750/4776 | Loss: 305.212 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3760/4776 | Loss: 314.342 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3770/4776 | Loss: 294.520 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3780/4776 | Loss: 292.420 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3790/4776 | Loss: 291.101 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3800/4776 | Loss: 295.661 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3810/4776 | Loss: 284.935 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3820/4776 | Loss: 294.842 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3830/4776 | Loss: 297.066 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3840/4776 | Loss: 317.995 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3850/4776 | Loss: 290.194 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3860/4776 | Loss: 294.701 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3870/4776 | Loss: 296.749 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3880/4776 | Loss: 296.498 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3890/4776 | Loss: 292.437 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3900/4776 | Loss: 293.944 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3910/4776 | Loss: 276.890 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3920/4776 | Loss: 301.233 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3930/4776 | Loss: 285.210 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3940/4776 | Loss: 284.500 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 3950/4776 | Loss: 288.904 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3960/4776 | Loss: 332.790 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3970/4776 | Loss: 309.950 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 3980/4776 | Loss: 328.626 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 3990/4776 | Loss: 301.347 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4000/4776 | Loss: 304.575 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4010/4776 | Loss: 282.458 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4020/4776 | Loss: 300.927 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4030/4776 | Loss: 299.829 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4040/4776 | Loss: 277.989 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4050/4776 | Loss: 306.230 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4060/4776 | Loss: 305.009 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4070/4776 | Loss: 305.023 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4080/4776 | Loss: 286.178 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4090/4776 | Loss: 279.550 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 4100/4776 | Loss: 291.824 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4110/4776 | Loss: 293.895 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4120/4776 | Loss: 299.583 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4130/4776 | Loss: 311.537 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4140/4776 | Loss: 302.828 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4150/4776 | Loss: 296.840 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4160/4776 | Loss: 309.437 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4170/4776 | Loss: 319.848 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4180/4776 | Loss: 299.299 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4190/4776 | Loss: 300.297 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4200/4776 | Loss: 307.023 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4210/4776 | Loss: 291.204 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4220/4776 | Loss: 325.524 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4230/4776 | Loss: 307.970 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4240/4776 | Loss: 299.602 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4250/4776 | Loss: 303.922 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4260/4776 | Loss: 289.378 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4270/4776 | Loss: 293.742 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4280/4776 | Loss: 291.554 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4290/4776 | Loss: 295.681 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4300/4776 | Loss: 304.710 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4310/4776 | Loss: 282.041 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4320/4776 | Loss: 295.416 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4330/4776 | Loss: 291.287 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4340/4776 | Loss: 286.732 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4350/4776 | Loss: 297.639 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4360/4776 | Loss: 290.291 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4370/4776 | Loss: 284.965 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4380/4776 | Loss: 287.910 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4390/4776 | Loss: 345.979 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4400/4776 | Loss: 295.372 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4410/4776 | Loss: 300.277 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4420/4776 | Loss: 308.670 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4430/4776 | Loss: 284.572 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4440/4776 | Loss: 301.602 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4450/4776 | Loss: 292.961 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4460/4776 | Loss: 303.550 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4470/4776 | Loss: 300.489 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4480/4776 | Loss: 298.020 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4490/4776 | Loss: 277.874 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4500/4776 | Loss: 303.004 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4510/4776 | Loss: 306.608 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4520/4776 | Loss: 286.472 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4530/4776 | Loss: 268.006 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 4540/4776 | Loss: 272.934 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4550/4776 | Loss: 254.356 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 4560/4776 | Loss: 322.146 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4570/4776 | Loss: 286.605 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4580/4776 | Loss: 311.142 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4590/4776 | Loss: 312.190 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4600/4776 | Loss: 291.980 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4610/4776 | Loss: 262.801 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 4620/4776 | Loss: 324.323 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 4630/4776 | Loss: 301.635 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4640/4776 | Loss: 278.409 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 4650/4776 | Loss: 285.174 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4660/4776 | Loss: 296.978 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4670/4776 | Loss: 303.920 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4680/4776 | Loss: 299.402 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4690/4776 | Loss: 298.853 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4700/4776 | Loss: 286.106 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4710/4776 | Loss: 329.257 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4720/4776 | Loss: 298.670 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4730/4776 | Loss: 291.385 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 4740/4776 | Loss: 315.118 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4750/4776 | Loss: 290.228 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4760/4776 | Loss: 294.017 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 4770/4776 | Loss: 301.017 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 5/200] - Step: 10/4776 | Loss: 298.420 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 20/4776 | Loss: 303.099 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 30/4776 | Loss: 302.029 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 40/4776 | Loss: 292.267 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 50/4776 | Loss: 281.235 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 60/4776 | Loss: 298.305 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 70/4776 | Loss: 294.539 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 80/4776 | Loss: 279.640 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 90/4776 | Loss: 294.997 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 100/4776 | Loss: 309.516 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 110/4776 | Loss: 301.759 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 120/4776 | Loss: 274.730 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 130/4776 | Loss: 280.224 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 140/4776 | Loss: 295.715 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 150/4776 | Loss: 308.833 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 160/4776 | Loss: 279.966 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 170/4776 | Loss: 292.043 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 180/4776 | Loss: 291.307 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 190/4776 | Loss: 282.775 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 200/4776 | Loss: 303.994 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 210/4776 | Loss: 307.218 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 220/4776 | Loss: 301.394 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 230/4776 | Loss: 296.512 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 240/4776 | Loss: 299.579 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 250/4776 | Loss: 287.703 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 260/4776 | Loss: 296.760 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 270/4776 | Loss: 316.163 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 280/4776 | Loss: 276.887 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 290/4776 | Loss: 284.027 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 300/4776 | Loss: 320.657 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 310/4776 | Loss: 306.580 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 320/4776 | Loss: 292.069 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 330/4776 | Loss: 322.427 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 340/4776 | Loss: 319.119 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 350/4776 | Loss: 281.053 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 360/4776 | Loss: 290.126 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 370/4776 | Loss: 278.413 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 380/4776 | Loss: 333.123 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 390/4776 | Loss: 305.619 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 400/4776 | Loss: 298.725 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 410/4776 | Loss: 289.195 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 420/4776 | Loss: 304.539 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 430/4776 | Loss: 307.077 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 440/4776 | Loss: 300.521 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 450/4776 | Loss: 307.945 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 460/4776 | Loss: 292.573 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 470/4776 | Loss: 304.440 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 480/4776 | Loss: 298.304 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 490/4776 | Loss: 298.469 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 500/4776 | Loss: 276.725 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 510/4776 | Loss: 281.107 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 520/4776 | Loss: 279.378 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 530/4776 | Loss: 283.023 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 540/4776 | Loss: 295.329 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 550/4776 | Loss: 318.038 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 560/4776 | Loss: 304.574 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 570/4776 | Loss: 289.077 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 580/4776 | Loss: 296.801 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 590/4776 | Loss: 295.126 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 600/4776 | Loss: 302.875 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 610/4776 | Loss: 294.152 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 620/4776 | Loss: 289.075 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 630/4776 | Loss: 271.903 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 640/4776 | Loss: 302.382 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 650/4776 | Loss: 287.481 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 660/4776 | Loss: 314.791 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 670/4776 | Loss: 301.078 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 680/4776 | Loss: 325.657 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 690/4776 | Loss: 288.235 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 700/4776 | Loss: 293.625 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 710/4776 | Loss: 299.803 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 720/4776 | Loss: 294.275 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 730/4776 | Loss: 310.477 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 740/4776 | Loss: 292.207 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 750/4776 | Loss: 274.176 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 760/4776 | Loss: 290.756 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 770/4776 | Loss: 313.743 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 780/4776 | Loss: 298.831 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 790/4776 | Loss: 300.425 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 800/4776 | Loss: 265.519 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 810/4776 | Loss: 302.994 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 820/4776 | Loss: 275.589 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 830/4776 | Loss: 320.942 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 840/4776 | Loss: 318.974 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 850/4776 | Loss: 298.977 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 860/4776 | Loss: 296.974 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 870/4776 | Loss: 292.016 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 880/4776 | Loss: 303.960 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 890/4776 | Loss: 301.291 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 900/4776 | Loss: 327.463 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 910/4776 | Loss: 304.870 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 920/4776 | Loss: 307.006 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 930/4776 | Loss: 295.881 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 940/4776 | Loss: 289.765 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 950/4776 | Loss: 307.627 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 960/4776 | Loss: 298.268 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 970/4776 | Loss: 307.483 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 980/4776 | Loss: 308.620 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 990/4776 | Loss: 299.805 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1000/4776 | Loss: 302.382 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1010/4776 | Loss: 293.315 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1020/4776 | Loss: 294.854 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1030/4776 | Loss: 293.817 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1040/4776 | Loss: 286.436 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1050/4776 | Loss: 305.660 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1060/4776 | Loss: 316.567 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1070/4776 | Loss: 294.543 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1080/4776 | Loss: 296.220 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1090/4776 | Loss: 296.790 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1100/4776 | Loss: 279.583 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1110/4776 | Loss: 309.660 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1120/4776 | Loss: 301.428 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1130/4776 | Loss: 300.338 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1140/4776 | Loss: 297.838 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1150/4776 | Loss: 309.083 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1160/4776 | Loss: 292.383 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1170/4776 | Loss: 301.621 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1180/4776 | Loss: 301.859 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1190/4776 | Loss: 300.388 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1200/4776 | Loss: 304.917 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1210/4776 | Loss: 286.803 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1220/4776 | Loss: 292.283 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1230/4776 | Loss: 298.401 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1240/4776 | Loss: 304.055 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1250/4776 | Loss: 294.259 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1260/4776 | Loss: 298.926 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1270/4776 | Loss: 295.753 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1280/4776 | Loss: 293.064 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1290/4776 | Loss: 293.275 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1300/4776 | Loss: 307.951 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1310/4776 | Loss: 296.495 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1320/4776 | Loss: 292.241 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1330/4776 | Loss: 294.357 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1340/4776 | Loss: 294.125 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1350/4776 | Loss: 322.843 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1360/4776 | Loss: 287.830 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1370/4776 | Loss: 316.969 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1380/4776 | Loss: 304.132 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1390/4776 | Loss: 300.973 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1400/4776 | Loss: 300.363 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1410/4776 | Loss: 279.101 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1420/4776 | Loss: 307.318 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1430/4776 | Loss: 297.287 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1440/4776 | Loss: 306.454 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1450/4776 | Loss: 290.046 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1460/4776 | Loss: 298.718 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1470/4776 | Loss: 294.483 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1480/4776 | Loss: 284.257 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1490/4776 | Loss: 279.083 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1500/4776 | Loss: 274.022 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1510/4776 | Loss: 291.414 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1520/4776 | Loss: 296.687 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1530/4776 | Loss: 303.991 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1540/4776 | Loss: 295.392 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1550/4776 | Loss: 308.888 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1560/4776 | Loss: 299.216 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1570/4776 | Loss: 305.573 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1580/4776 | Loss: 304.420 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1590/4776 | Loss: 298.927 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1600/4776 | Loss: 313.855 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1610/4776 | Loss: 295.359 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1620/4776 | Loss: 306.433 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1630/4776 | Loss: 301.465 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1640/4776 | Loss: 288.270 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1650/4776 | Loss: 274.165 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 1660/4776 | Loss: 299.381 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1670/4776 | Loss: 325.849 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1680/4776 | Loss: 302.258 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1690/4776 | Loss: 309.465 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1700/4776 | Loss: 301.355 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1710/4776 | Loss: 291.968 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1720/4776 | Loss: 287.752 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1730/4776 | Loss: 299.223 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1740/4776 | Loss: 311.928 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1750/4776 | Loss: 303.777 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1760/4776 | Loss: 297.798 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1770/4776 | Loss: 298.841 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1780/4776 | Loss: 292.787 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1790/4776 | Loss: 296.196 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1800/4776 | Loss: 289.525 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1810/4776 | Loss: 299.246 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1820/4776 | Loss: 306.479 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1830/4776 | Loss: 303.312 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1840/4776 | Loss: 267.598 | Accuracy: 0.500\n",
      "[Epoch: 5/200] - Step: 1850/4776 | Loss: 304.973 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1860/4776 | Loss: 281.331 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 1870/4776 | Loss: 301.390 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1880/4776 | Loss: 281.744 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1890/4776 | Loss: 314.051 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1900/4776 | Loss: 311.130 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1910/4776 | Loss: 287.427 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1920/4776 | Loss: 294.724 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1930/4776 | Loss: 303.645 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1940/4776 | Loss: 300.525 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1950/4776 | Loss: 307.562 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1960/4776 | Loss: 297.757 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1970/4776 | Loss: 307.350 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1980/4776 | Loss: 308.654 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1990/4776 | Loss: 300.713 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2000/4776 | Loss: 302.219 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2010/4776 | Loss: 298.989 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2020/4776 | Loss: 290.751 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2030/4776 | Loss: 288.313 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2040/4776 | Loss: 318.914 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2050/4776 | Loss: 290.291 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2060/4776 | Loss: 322.154 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2070/4776 | Loss: 297.417 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2080/4776 | Loss: 302.264 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2090/4776 | Loss: 291.640 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2100/4776 | Loss: 300.642 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2110/4776 | Loss: 284.360 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2120/4776 | Loss: 288.302 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2130/4776 | Loss: 272.808 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2140/4776 | Loss: 294.409 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2150/4776 | Loss: 297.704 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2160/4776 | Loss: 287.994 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2170/4776 | Loss: 295.819 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2180/4776 | Loss: 303.527 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2190/4776 | Loss: 296.691 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2200/4776 | Loss: 309.882 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2210/4776 | Loss: 272.620 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2220/4776 | Loss: 303.876 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2230/4776 | Loss: 282.864 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2240/4776 | Loss: 275.044 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2250/4776 | Loss: 312.064 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2260/4776 | Loss: 288.874 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2270/4776 | Loss: 316.477 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2280/4776 | Loss: 296.015 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2290/4776 | Loss: 291.676 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2300/4776 | Loss: 314.748 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2310/4776 | Loss: 292.557 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2320/4776 | Loss: 289.219 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2330/4776 | Loss: 296.895 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2340/4776 | Loss: 345.768 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2350/4776 | Loss: 292.576 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2360/4776 | Loss: 284.485 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2370/4776 | Loss: 287.692 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2380/4776 | Loss: 293.417 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2390/4776 | Loss: 311.850 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2400/4776 | Loss: 305.164 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2410/4776 | Loss: 298.682 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2420/4776 | Loss: 278.648 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2430/4776 | Loss: 281.488 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2440/4776 | Loss: 300.376 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2450/4776 | Loss: 307.906 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2460/4776 | Loss: 296.489 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2470/4776 | Loss: 306.102 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2480/4776 | Loss: 288.497 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2490/4776 | Loss: 306.199 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2500/4776 | Loss: 310.001 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2510/4776 | Loss: 299.049 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2520/4776 | Loss: 284.633 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2530/4776 | Loss: 290.667 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2540/4776 | Loss: 319.339 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2550/4776 | Loss: 283.683 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2560/4776 | Loss: 316.944 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2570/4776 | Loss: 303.657 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2580/4776 | Loss: 321.104 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2590/4776 | Loss: 303.287 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2600/4776 | Loss: 301.003 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2610/4776 | Loss: 282.074 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2620/4776 | Loss: 302.984 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2630/4776 | Loss: 285.794 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2640/4776 | Loss: 305.751 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2650/4776 | Loss: 313.114 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2660/4776 | Loss: 292.650 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2670/4776 | Loss: 293.374 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2680/4776 | Loss: 305.066 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2690/4776 | Loss: 297.015 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2700/4776 | Loss: 285.743 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2710/4776 | Loss: 292.158 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2720/4776 | Loss: 350.889 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2730/4776 | Loss: 280.138 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2740/4776 | Loss: 299.931 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2750/4776 | Loss: 293.969 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2760/4776 | Loss: 311.224 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2770/4776 | Loss: 282.864 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2780/4776 | Loss: 302.081 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2790/4776 | Loss: 290.217 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2800/4776 | Loss: 298.751 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2810/4776 | Loss: 316.241 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2820/4776 | Loss: 294.631 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2830/4776 | Loss: 285.280 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2840/4776 | Loss: 300.651 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2850/4776 | Loss: 306.713 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2860/4776 | Loss: 295.621 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2870/4776 | Loss: 281.814 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2880/4776 | Loss: 331.326 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2890/4776 | Loss: 260.184 | Accuracy: 0.500\n",
      "[Epoch: 5/200] - Step: 2900/4776 | Loss: 283.133 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2910/4776 | Loss: 306.258 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2920/4776 | Loss: 299.797 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2930/4776 | Loss: 305.190 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 2940/4776 | Loss: 283.902 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2950/4776 | Loss: 293.214 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 2960/4776 | Loss: 274.999 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 2970/4776 | Loss: 312.320 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2980/4776 | Loss: 289.489 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 2990/4776 | Loss: 302.895 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3000/4776 | Loss: 306.995 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3010/4776 | Loss: 307.225 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3020/4776 | Loss: 322.604 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3030/4776 | Loss: 298.628 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3040/4776 | Loss: 319.880 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3050/4776 | Loss: 272.820 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 3060/4776 | Loss: 295.026 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3070/4776 | Loss: 307.799 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3080/4776 | Loss: 308.496 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3090/4776 | Loss: 295.773 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3100/4776 | Loss: 329.499 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3110/4776 | Loss: 305.383 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3120/4776 | Loss: 286.532 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3130/4776 | Loss: 305.365 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3140/4776 | Loss: 296.735 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3150/4776 | Loss: 279.861 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3160/4776 | Loss: 298.841 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3170/4776 | Loss: 282.463 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3180/4776 | Loss: 301.844 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3190/4776 | Loss: 306.534 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3200/4776 | Loss: 296.943 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3210/4776 | Loss: 302.829 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3220/4776 | Loss: 291.430 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3230/4776 | Loss: 301.772 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3240/4776 | Loss: 289.236 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3250/4776 | Loss: 286.462 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3260/4776 | Loss: 302.574 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3270/4776 | Loss: 310.055 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3280/4776 | Loss: 295.639 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3290/4776 | Loss: 297.080 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3300/4776 | Loss: 290.144 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3310/4776 | Loss: 307.410 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3320/4776 | Loss: 300.193 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3330/4776 | Loss: 286.782 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3340/4776 | Loss: 284.183 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3350/4776 | Loss: 297.209 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3360/4776 | Loss: 296.598 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3370/4776 | Loss: 301.783 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3380/4776 | Loss: 302.833 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3390/4776 | Loss: 290.613 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3400/4776 | Loss: 342.890 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3410/4776 | Loss: 297.325 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3420/4776 | Loss: 309.584 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3430/4776 | Loss: 295.506 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3440/4776 | Loss: 297.235 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3450/4776 | Loss: 297.082 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3460/4776 | Loss: 296.958 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3470/4776 | Loss: 295.964 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3480/4776 | Loss: 290.786 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3490/4776 | Loss: 310.785 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3500/4776 | Loss: 306.139 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3510/4776 | Loss: 306.683 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3520/4776 | Loss: 298.025 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3530/4776 | Loss: 292.318 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3540/4776 | Loss: 294.953 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3550/4776 | Loss: 297.944 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3560/4776 | Loss: 288.457 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3570/4776 | Loss: 278.046 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3580/4776 | Loss: 269.050 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 3590/4776 | Loss: 281.723 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3600/4776 | Loss: 273.345 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3610/4776 | Loss: 313.097 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3620/4776 | Loss: 292.495 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3630/4776 | Loss: 311.155 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3640/4776 | Loss: 324.762 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3650/4776 | Loss: 293.877 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3660/4776 | Loss: 286.983 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3670/4776 | Loss: 307.529 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3680/4776 | Loss: 296.243 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3690/4776 | Loss: 312.293 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3700/4776 | Loss: 307.912 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3710/4776 | Loss: 293.784 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3720/4776 | Loss: 297.352 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3730/4776 | Loss: 302.455 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3740/4776 | Loss: 285.996 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3750/4776 | Loss: 303.540 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3760/4776 | Loss: 284.765 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3770/4776 | Loss: 314.194 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3780/4776 | Loss: 288.348 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3790/4776 | Loss: 293.461 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3800/4776 | Loss: 316.588 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3810/4776 | Loss: 274.479 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3820/4776 | Loss: 297.188 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3830/4776 | Loss: 277.193 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 3840/4776 | Loss: 289.757 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3850/4776 | Loss: 301.691 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3860/4776 | Loss: 271.381 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3870/4776 | Loss: 307.040 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3880/4776 | Loss: 302.534 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 3890/4776 | Loss: 314.880 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3900/4776 | Loss: 294.834 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3910/4776 | Loss: 288.794 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 3920/4776 | Loss: 303.965 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3930/4776 | Loss: 287.376 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3940/4776 | Loss: 293.032 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3950/4776 | Loss: 293.555 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3960/4776 | Loss: 285.924 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3970/4776 | Loss: 289.779 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3980/4776 | Loss: 293.344 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 3990/4776 | Loss: 294.655 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4000/4776 | Loss: 302.013 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4010/4776 | Loss: 292.153 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4020/4776 | Loss: 297.612 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4030/4776 | Loss: 308.614 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4040/4776 | Loss: 289.507 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4050/4776 | Loss: 287.396 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4060/4776 | Loss: 291.780 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4070/4776 | Loss: 284.954 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4080/4776 | Loss: 274.844 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 4090/4776 | Loss: 299.237 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4100/4776 | Loss: 298.215 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4110/4776 | Loss: 322.333 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4120/4776 | Loss: 282.285 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4130/4776 | Loss: 293.068 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4140/4776 | Loss: 313.977 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4150/4776 | Loss: 288.453 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4160/4776 | Loss: 302.325 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4170/4776 | Loss: 288.967 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 4180/4776 | Loss: 294.763 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4190/4776 | Loss: 301.778 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4200/4776 | Loss: 305.867 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4210/4776 | Loss: 294.608 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4220/4776 | Loss: 294.130 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4230/4776 | Loss: 283.765 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4240/4776 | Loss: 289.067 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4250/4776 | Loss: 309.546 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4260/4776 | Loss: 296.380 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4270/4776 | Loss: 298.819 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4280/4776 | Loss: 289.115 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4290/4776 | Loss: 284.812 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4300/4776 | Loss: 301.729 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4310/4776 | Loss: 300.075 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4320/4776 | Loss: 306.492 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4330/4776 | Loss: 296.243 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4340/4776 | Loss: 303.676 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4350/4776 | Loss: 297.669 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4360/4776 | Loss: 283.244 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4370/4776 | Loss: 307.297 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4380/4776 | Loss: 286.059 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4390/4776 | Loss: 323.696 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4400/4776 | Loss: 289.900 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4410/4776 | Loss: 288.374 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4420/4776 | Loss: 307.340 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4430/4776 | Loss: 288.560 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4440/4776 | Loss: 341.261 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4450/4776 | Loss: 292.523 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4460/4776 | Loss: 304.141 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4470/4776 | Loss: 304.049 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4480/4776 | Loss: 301.743 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4490/4776 | Loss: 310.432 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4500/4776 | Loss: 278.833 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 4510/4776 | Loss: 295.977 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4520/4776 | Loss: 271.222 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4530/4776 | Loss: 311.567 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4540/4776 | Loss: 301.527 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4550/4776 | Loss: 288.693 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4560/4776 | Loss: 279.797 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4570/4776 | Loss: 311.105 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4580/4776 | Loss: 287.461 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4590/4776 | Loss: 286.245 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 4600/4776 | Loss: 280.602 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4610/4776 | Loss: 308.741 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4620/4776 | Loss: 291.447 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4630/4776 | Loss: 293.489 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4640/4776 | Loss: 282.582 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4650/4776 | Loss: 290.126 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4660/4776 | Loss: 290.673 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4670/4776 | Loss: 279.413 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4680/4776 | Loss: 304.046 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4690/4776 | Loss: 307.667 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4700/4776 | Loss: 304.680 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4710/4776 | Loss: 317.206 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4720/4776 | Loss: 299.439 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4730/4776 | Loss: 300.127 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4740/4776 | Loss: 303.667 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 4750/4776 | Loss: 285.429 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 4760/4776 | Loss: 293.202 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 4770/4776 | Loss: 283.493 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 6/200] - Step: 10/4776 | Loss: 295.361 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 20/4776 | Loss: 341.457 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 30/4776 | Loss: 307.234 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 40/4776 | Loss: 298.173 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 50/4776 | Loss: 287.740 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 60/4776 | Loss: 297.503 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 70/4776 | Loss: 305.112 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 80/4776 | Loss: 292.106 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 90/4776 | Loss: 304.856 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 100/4776 | Loss: 305.742 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 110/4776 | Loss: 297.932 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 120/4776 | Loss: 298.339 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 130/4776 | Loss: 292.967 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 140/4776 | Loss: 295.835 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 150/4776 | Loss: 311.154 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 160/4776 | Loss: 310.195 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 170/4776 | Loss: 296.375 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 180/4776 | Loss: 290.831 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 190/4776 | Loss: 302.573 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 200/4776 | Loss: 308.939 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 210/4776 | Loss: 297.655 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 220/4776 | Loss: 305.201 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 230/4776 | Loss: 288.073 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 240/4776 | Loss: 284.322 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 250/4776 | Loss: 302.336 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 260/4776 | Loss: 288.782 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 270/4776 | Loss: 286.067 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 280/4776 | Loss: 290.189 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 290/4776 | Loss: 313.537 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 300/4776 | Loss: 288.537 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 310/4776 | Loss: 292.805 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 320/4776 | Loss: 272.323 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 330/4776 | Loss: 302.317 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 340/4776 | Loss: 292.890 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 350/4776 | Loss: 304.406 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 360/4776 | Loss: 309.099 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 370/4776 | Loss: 303.774 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 380/4776 | Loss: 289.853 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 390/4776 | Loss: 305.352 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 400/4776 | Loss: 289.828 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 410/4776 | Loss: 305.889 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 420/4776 | Loss: 291.439 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 430/4776 | Loss: 302.953 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 440/4776 | Loss: 293.019 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 450/4776 | Loss: 289.068 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 460/4776 | Loss: 297.168 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 470/4776 | Loss: 308.325 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 480/4776 | Loss: 304.215 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 490/4776 | Loss: 295.491 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 500/4776 | Loss: 291.688 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 510/4776 | Loss: 308.194 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 520/4776 | Loss: 285.254 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 530/4776 | Loss: 298.244 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 540/4776 | Loss: 292.044 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 550/4776 | Loss: 308.364 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 560/4776 | Loss: 287.580 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 570/4776 | Loss: 320.557 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 580/4776 | Loss: 305.180 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 590/4776 | Loss: 289.829 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 600/4776 | Loss: 282.023 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 610/4776 | Loss: 296.514 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 620/4776 | Loss: 292.079 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 630/4776 | Loss: 285.507 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 640/4776 | Loss: 297.000 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 650/4776 | Loss: 284.063 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 660/4776 | Loss: 320.518 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 670/4776 | Loss: 293.828 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 680/4776 | Loss: 269.513 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 690/4776 | Loss: 306.282 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 700/4776 | Loss: 293.300 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 710/4776 | Loss: 300.053 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 720/4776 | Loss: 309.812 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 730/4776 | Loss: 308.159 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 740/4776 | Loss: 314.532 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 750/4776 | Loss: 293.686 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 760/4776 | Loss: 280.932 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 770/4776 | Loss: 303.323 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 780/4776 | Loss: 297.367 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 790/4776 | Loss: 307.640 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 800/4776 | Loss: 301.784 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 810/4776 | Loss: 307.876 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 820/4776 | Loss: 286.595 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 830/4776 | Loss: 300.621 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 840/4776 | Loss: 280.090 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 850/4776 | Loss: 291.986 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 860/4776 | Loss: 301.425 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 870/4776 | Loss: 311.114 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 880/4776 | Loss: 297.334 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 890/4776 | Loss: 314.981 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 900/4776 | Loss: 298.342 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 910/4776 | Loss: 319.376 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 920/4776 | Loss: 301.010 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 930/4776 | Loss: 298.703 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 940/4776 | Loss: 292.754 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 950/4776 | Loss: 304.554 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 960/4776 | Loss: 299.829 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 970/4776 | Loss: 323.417 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 980/4776 | Loss: 299.517 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 990/4776 | Loss: 285.340 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1000/4776 | Loss: 303.892 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1010/4776 | Loss: 292.720 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1020/4776 | Loss: 288.601 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1030/4776 | Loss: 296.577 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1040/4776 | Loss: 305.857 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1050/4776 | Loss: 289.647 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1060/4776 | Loss: 309.736 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1070/4776 | Loss: 303.038 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1080/4776 | Loss: 287.560 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1090/4776 | Loss: 292.821 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1100/4776 | Loss: 282.674 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1110/4776 | Loss: 279.841 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1120/4776 | Loss: 278.728 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1130/4776 | Loss: 317.644 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1140/4776 | Loss: 282.933 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1150/4776 | Loss: 300.901 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1160/4776 | Loss: 275.891 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1170/4776 | Loss: 311.485 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1180/4776 | Loss: 274.929 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1190/4776 | Loss: 304.587 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1200/4776 | Loss: 312.281 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1210/4776 | Loss: 309.618 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1220/4776 | Loss: 298.041 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1230/4776 | Loss: 300.558 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1240/4776 | Loss: 308.011 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1250/4776 | Loss: 294.661 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1260/4776 | Loss: 297.185 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1270/4776 | Loss: 298.402 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1280/4776 | Loss: 299.771 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1290/4776 | Loss: 273.297 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1300/4776 | Loss: 300.894 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1310/4776 | Loss: 282.835 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1320/4776 | Loss: 292.948 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1330/4776 | Loss: 296.564 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1340/4776 | Loss: 298.922 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1350/4776 | Loss: 311.188 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1360/4776 | Loss: 296.949 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1370/4776 | Loss: 298.874 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1380/4776 | Loss: 288.655 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1390/4776 | Loss: 268.776 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 1400/4776 | Loss: 300.239 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1410/4776 | Loss: 301.979 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1420/4776 | Loss: 293.364 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1430/4776 | Loss: 342.121 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1440/4776 | Loss: 293.886 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1450/4776 | Loss: 284.052 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1460/4776 | Loss: 300.644 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1470/4776 | Loss: 286.845 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1480/4776 | Loss: 295.758 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1490/4776 | Loss: 286.042 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1500/4776 | Loss: 312.155 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1510/4776 | Loss: 301.755 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1520/4776 | Loss: 279.494 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1530/4776 | Loss: 300.684 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1540/4776 | Loss: 294.361 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1550/4776 | Loss: 300.404 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1560/4776 | Loss: 317.977 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1570/4776 | Loss: 303.916 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1580/4776 | Loss: 298.122 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1590/4776 | Loss: 318.436 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1600/4776 | Loss: 243.851 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1610/4776 | Loss: 1050.653 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1620/4776 | Loss: 301.191 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1630/4776 | Loss: 285.751 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 1640/4776 | Loss: 291.122 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1650/4776 | Loss: 297.362 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1660/4776 | Loss: 301.321 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1670/4776 | Loss: 312.061 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1680/4776 | Loss: 296.148 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1690/4776 | Loss: 306.216 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1700/4776 | Loss: 290.738 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1710/4776 | Loss: 301.938 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1720/4776 | Loss: 300.507 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1730/4776 | Loss: 304.013 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1740/4776 | Loss: 297.285 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1750/4776 | Loss: 283.102 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1760/4776 | Loss: 300.808 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1770/4776 | Loss: 304.132 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1780/4776 | Loss: 296.838 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1790/4776 | Loss: 280.503 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1800/4776 | Loss: 275.587 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1810/4776 | Loss: 289.214 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1820/4776 | Loss: 314.542 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1830/4776 | Loss: 314.749 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1840/4776 | Loss: 307.228 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1850/4776 | Loss: 293.412 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1860/4776 | Loss: 299.140 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1870/4776 | Loss: 303.328 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1880/4776 | Loss: 302.109 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1890/4776 | Loss: 314.330 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1900/4776 | Loss: 300.919 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1910/4776 | Loss: 297.904 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1920/4776 | Loss: 297.947 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1930/4776 | Loss: 299.436 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1940/4776 | Loss: 288.414 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1950/4776 | Loss: 295.080 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1960/4776 | Loss: 313.757 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1970/4776 | Loss: 285.113 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 1980/4776 | Loss: 298.285 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1990/4776 | Loss: 294.082 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2000/4776 | Loss: 280.993 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2010/4776 | Loss: 288.840 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2020/4776 | Loss: 326.665 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2030/4776 | Loss: 295.653 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2040/4776 | Loss: 260.537 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 2050/4776 | Loss: 272.471 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2060/4776 | Loss: 319.761 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2070/4776 | Loss: 256.265 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 2080/4776 | Loss: 301.499 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2090/4776 | Loss: 301.264 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2100/4776 | Loss: 287.810 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2110/4776 | Loss: 301.989 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2120/4776 | Loss: 323.692 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2130/4776 | Loss: 305.387 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2140/4776 | Loss: 294.417 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2150/4776 | Loss: 323.143 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2160/4776 | Loss: 307.987 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2170/4776 | Loss: 298.082 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2180/4776 | Loss: 309.507 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2190/4776 | Loss: 298.795 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2200/4776 | Loss: 297.044 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2210/4776 | Loss: 297.951 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2220/4776 | Loss: 282.085 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2230/4776 | Loss: 298.061 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2240/4776 | Loss: 308.135 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2250/4776 | Loss: 295.927 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2260/4776 | Loss: 301.139 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2270/4776 | Loss: 294.254 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2280/4776 | Loss: 295.887 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2290/4776 | Loss: 302.188 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2300/4776 | Loss: 290.884 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2310/4776 | Loss: 290.972 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2320/4776 | Loss: 296.760 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2330/4776 | Loss: 302.218 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2340/4776 | Loss: 295.835 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2350/4776 | Loss: 293.321 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2360/4776 | Loss: 300.029 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2370/4776 | Loss: 304.830 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2380/4776 | Loss: 289.058 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2390/4776 | Loss: 278.543 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2400/4776 | Loss: 287.872 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2410/4776 | Loss: 308.422 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2420/4776 | Loss: 284.069 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2430/4776 | Loss: 290.742 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2440/4776 | Loss: 329.452 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2450/4776 | Loss: 325.782 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2460/4776 | Loss: 286.126 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2470/4776 | Loss: 277.372 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2480/4776 | Loss: 303.520 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2490/4776 | Loss: 284.487 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2500/4776 | Loss: 296.667 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2510/4776 | Loss: 296.715 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2520/4776 | Loss: 292.201 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2530/4776 | Loss: 299.663 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2540/4776 | Loss: 293.954 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2550/4776 | Loss: 282.939 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2560/4776 | Loss: 305.728 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2570/4776 | Loss: 269.209 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 2580/4776 | Loss: 305.354 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2590/4776 | Loss: 291.324 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2600/4776 | Loss: 295.970 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2610/4776 | Loss: 301.350 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2620/4776 | Loss: 286.844 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2630/4776 | Loss: 314.902 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2640/4776 | Loss: 312.893 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2650/4776 | Loss: 289.029 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2660/4776 | Loss: 291.790 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2670/4776 | Loss: 307.309 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2680/4776 | Loss: 291.142 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2690/4776 | Loss: 321.713 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2700/4776 | Loss: 305.665 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2710/4776 | Loss: 297.706 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2720/4776 | Loss: 272.223 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2730/4776 | Loss: 271.146 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2740/4776 | Loss: 293.735 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2750/4776 | Loss: 311.521 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2760/4776 | Loss: 291.816 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2770/4776 | Loss: 301.455 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2780/4776 | Loss: 286.459 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2790/4776 | Loss: 289.388 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2800/4776 | Loss: 277.625 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2810/4776 | Loss: 319.828 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2820/4776 | Loss: 277.060 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2830/4776 | Loss: 298.485 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2840/4776 | Loss: 295.820 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2850/4776 | Loss: 302.163 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2860/4776 | Loss: 305.717 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2870/4776 | Loss: 283.148 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2880/4776 | Loss: 282.119 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2890/4776 | Loss: 297.819 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2900/4776 | Loss: 295.765 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2910/4776 | Loss: 259.098 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 2920/4776 | Loss: 286.519 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2930/4776 | Loss: 298.572 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2940/4776 | Loss: 334.942 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2950/4776 | Loss: 328.114 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 2960/4776 | Loss: 292.366 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2970/4776 | Loss: 288.426 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 2980/4776 | Loss: 302.168 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 2990/4776 | Loss: 306.499 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3000/4776 | Loss: 329.457 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3010/4776 | Loss: 299.055 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3020/4776 | Loss: 289.821 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3030/4776 | Loss: 290.133 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3040/4776 | Loss: 287.109 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3050/4776 | Loss: 303.297 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3060/4776 | Loss: 287.149 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3070/4776 | Loss: 325.828 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3080/4776 | Loss: 306.482 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3090/4776 | Loss: 312.359 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3100/4776 | Loss: 289.115 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3110/4776 | Loss: 286.608 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3120/4776 | Loss: 308.286 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3130/4776 | Loss: 300.179 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3140/4776 | Loss: 308.027 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3150/4776 | Loss: 307.321 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3160/4776 | Loss: 298.675 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3170/4776 | Loss: 296.843 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3180/4776 | Loss: 291.431 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3190/4776 | Loss: 297.229 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3200/4776 | Loss: 298.483 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3210/4776 | Loss: 281.419 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3220/4776 | Loss: 295.650 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3230/4776 | Loss: 298.564 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3240/4776 | Loss: 273.559 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 3250/4776 | Loss: 305.276 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3260/4776 | Loss: 271.391 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 3270/4776 | Loss: 278.086 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3280/4776 | Loss: 273.793 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3290/4776 | Loss: 291.832 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3300/4776 | Loss: 299.552 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3310/4776 | Loss: 299.603 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3320/4776 | Loss: 287.678 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3330/4776 | Loss: 286.150 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3340/4776 | Loss: 301.674 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3350/4776 | Loss: 284.706 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3360/4776 | Loss: 296.899 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3370/4776 | Loss: 304.310 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3380/4776 | Loss: 285.450 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3390/4776 | Loss: 305.224 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3400/4776 | Loss: 298.847 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3410/4776 | Loss: 292.200 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3420/4776 | Loss: 310.791 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3430/4776 | Loss: 310.833 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3440/4776 | Loss: 315.749 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3450/4776 | Loss: 304.461 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3460/4776 | Loss: 297.682 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3470/4776 | Loss: 283.394 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3480/4776 | Loss: 301.464 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3490/4776 | Loss: 307.080 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3500/4776 | Loss: 290.413 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3510/4776 | Loss: 295.031 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3520/4776 | Loss: 305.268 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3530/4776 | Loss: 307.322 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3540/4776 | Loss: 299.337 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3550/4776 | Loss: 302.139 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3560/4776 | Loss: 301.122 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3570/4776 | Loss: 300.172 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3580/4776 | Loss: 298.241 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3590/4776 | Loss: 293.425 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3600/4776 | Loss: 305.027 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3610/4776 | Loss: 305.611 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3620/4776 | Loss: 300.555 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3630/4776 | Loss: 288.270 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3640/4776 | Loss: 289.729 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3650/4776 | Loss: 294.964 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3660/4776 | Loss: 308.131 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3670/4776 | Loss: 309.364 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3680/4776 | Loss: 289.574 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3690/4776 | Loss: 277.347 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3700/4776 | Loss: 300.090 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3710/4776 | Loss: 294.358 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 3720/4776 | Loss: 307.707 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3730/4776 | Loss: 300.223 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3740/4776 | Loss: 285.533 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3750/4776 | Loss: 288.373 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3760/4776 | Loss: 302.998 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3770/4776 | Loss: 296.222 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3780/4776 | Loss: 308.872 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3790/4776 | Loss: 300.728 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3800/4776 | Loss: 295.611 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3810/4776 | Loss: 300.005 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3820/4776 | Loss: 306.713 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3830/4776 | Loss: 321.551 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3840/4776 | Loss: 294.337 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3850/4776 | Loss: 307.008 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3860/4776 | Loss: 307.617 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3870/4776 | Loss: 296.019 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3880/4776 | Loss: 302.535 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3890/4776 | Loss: 289.588 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3900/4776 | Loss: 319.049 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3910/4776 | Loss: 292.353 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 3920/4776 | Loss: 296.880 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3930/4776 | Loss: 322.885 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3940/4776 | Loss: 302.395 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3950/4776 | Loss: 327.746 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 3960/4776 | Loss: 287.796 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3970/4776 | Loss: 289.692 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3980/4776 | Loss: 298.159 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 3990/4776 | Loss: 297.268 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4000/4776 | Loss: 297.039 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4010/4776 | Loss: 309.707 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4020/4776 | Loss: 287.205 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4030/4776 | Loss: 300.963 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4040/4776 | Loss: 307.139 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4050/4776 | Loss: 291.333 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4060/4776 | Loss: 289.830 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4070/4776 | Loss: 302.708 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4080/4776 | Loss: 285.635 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4090/4776 | Loss: 306.534 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4100/4776 | Loss: 301.315 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4110/4776 | Loss: 313.692 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4120/4776 | Loss: 288.523 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4130/4776 | Loss: 298.855 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4140/4776 | Loss: 274.661 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 4150/4776 | Loss: 291.873 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4160/4776 | Loss: 288.461 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4170/4776 | Loss: 296.256 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4180/4776 | Loss: 284.545 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4190/4776 | Loss: 294.706 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4200/4776 | Loss: 317.266 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4210/4776 | Loss: 289.010 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4220/4776 | Loss: 271.578 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4230/4776 | Loss: 298.233 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4240/4776 | Loss: 303.603 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4250/4776 | Loss: 304.977 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4260/4776 | Loss: 270.263 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 4270/4776 | Loss: 316.048 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4280/4776 | Loss: 302.144 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4290/4776 | Loss: 312.917 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4300/4776 | Loss: 288.303 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4310/4776 | Loss: 307.172 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4320/4776 | Loss: 300.372 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4330/4776 | Loss: 294.206 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4340/4776 | Loss: 295.455 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4350/4776 | Loss: 285.150 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4360/4776 | Loss: 295.713 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4370/4776 | Loss: 297.507 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4380/4776 | Loss: 304.399 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4390/4776 | Loss: 290.596 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4400/4776 | Loss: 303.266 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4410/4776 | Loss: 317.109 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4420/4776 | Loss: 298.899 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4430/4776 | Loss: 298.912 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4440/4776 | Loss: 295.231 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4450/4776 | Loss: 303.040 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4460/4776 | Loss: 303.120 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4470/4776 | Loss: 277.639 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4480/4776 | Loss: 291.770 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4490/4776 | Loss: 301.463 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4500/4776 | Loss: 289.313 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4510/4776 | Loss: 291.278 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4520/4776 | Loss: 293.045 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4530/4776 | Loss: 295.281 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4540/4776 | Loss: 287.582 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4550/4776 | Loss: 294.479 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4560/4776 | Loss: 286.198 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4570/4776 | Loss: 290.760 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4580/4776 | Loss: 291.554 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4590/4776 | Loss: 281.252 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4600/4776 | Loss: 279.004 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4610/4776 | Loss: 294.817 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4620/4776 | Loss: 309.492 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4630/4776 | Loss: 275.588 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4640/4776 | Loss: 279.729 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 4650/4776 | Loss: 285.654 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4660/4776 | Loss: 358.589 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4670/4776 | Loss: 317.638 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4680/4776 | Loss: 289.933 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4690/4776 | Loss: 299.547 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4700/4776 | Loss: 290.389 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4710/4776 | Loss: 308.086 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4720/4776 | Loss: 282.726 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 4730/4776 | Loss: 297.388 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 4740/4776 | Loss: 270.385 | Accuracy: 0.400\n",
      "[Epoch: 6/200] - Step: 4750/4776 | Loss: 304.408 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4760/4776 | Loss: 306.245 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 4770/4776 | Loss: 309.705 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 7/200] - Step: 10/4776 | Loss: 303.264 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 20/4776 | Loss: 289.679 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 30/4776 | Loss: 276.565 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 40/4776 | Loss: 284.150 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 50/4776 | Loss: 274.342 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 60/4776 | Loss: 305.361 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 70/4776 | Loss: 349.126 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 80/4776 | Loss: 296.123 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 90/4776 | Loss: 285.428 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 100/4776 | Loss: 297.951 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 110/4776 | Loss: 312.349 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 120/4776 | Loss: 301.837 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 130/4776 | Loss: 296.543 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 140/4776 | Loss: 301.536 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 150/4776 | Loss: 293.197 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 160/4776 | Loss: 289.644 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 170/4776 | Loss: 296.032 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 180/4776 | Loss: 302.985 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 190/4776 | Loss: 282.338 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 200/4776 | Loss: 293.630 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 210/4776 | Loss: 307.242 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 220/4776 | Loss: 290.149 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 230/4776 | Loss: 306.831 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 240/4776 | Loss: 307.379 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 250/4776 | Loss: 299.383 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 260/4776 | Loss: 286.506 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 270/4776 | Loss: 298.570 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 280/4776 | Loss: 301.830 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 290/4776 | Loss: 297.353 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 300/4776 | Loss: 277.449 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 310/4776 | Loss: 349.779 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 320/4776 | Loss: 277.955 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 330/4776 | Loss: 291.016 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 340/4776 | Loss: 291.184 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 350/4776 | Loss: 297.809 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 360/4776 | Loss: 306.555 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 370/4776 | Loss: 293.993 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 380/4776 | Loss: 294.705 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 390/4776 | Loss: 297.059 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 400/4776 | Loss: 290.167 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 410/4776 | Loss: 324.347 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 420/4776 | Loss: 309.366 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 430/4776 | Loss: 303.588 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 440/4776 | Loss: 315.306 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 450/4776 | Loss: 306.951 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 460/4776 | Loss: 283.414 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 470/4776 | Loss: 292.227 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 480/4776 | Loss: 299.307 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 490/4776 | Loss: 300.374 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 500/4776 | Loss: 291.545 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 510/4776 | Loss: 295.607 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 520/4776 | Loss: 288.804 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 530/4776 | Loss: 313.834 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 540/4776 | Loss: 296.332 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 550/4776 | Loss: 300.208 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 560/4776 | Loss: 281.785 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 570/4776 | Loss: 285.611 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 580/4776 | Loss: 318.414 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 590/4776 | Loss: 302.099 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 600/4776 | Loss: 299.025 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 610/4776 | Loss: 334.825 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 620/4776 | Loss: 304.665 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 630/4776 | Loss: 294.114 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 640/4776 | Loss: 294.159 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 650/4776 | Loss: 294.011 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 660/4776 | Loss: 309.569 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 670/4776 | Loss: 299.538 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 680/4776 | Loss: 290.866 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 690/4776 | Loss: 293.448 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 700/4776 | Loss: 316.855 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 710/4776 | Loss: 296.905 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 720/4776 | Loss: 305.596 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 730/4776 | Loss: 299.571 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 740/4776 | Loss: 292.005 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 750/4776 | Loss: 285.178 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 760/4776 | Loss: 290.710 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 770/4776 | Loss: 301.382 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 780/4776 | Loss: 304.775 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 790/4776 | Loss: 298.202 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 800/4776 | Loss: 308.441 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 810/4776 | Loss: 277.861 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 820/4776 | Loss: 297.661 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 830/4776 | Loss: 323.416 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 840/4776 | Loss: 294.477 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 850/4776 | Loss: 300.433 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 860/4776 | Loss: 294.205 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 870/4776 | Loss: 304.981 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 880/4776 | Loss: 290.485 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 890/4776 | Loss: 285.489 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 900/4776 | Loss: 287.195 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 910/4776 | Loss: 298.913 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 920/4776 | Loss: 314.522 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 930/4776 | Loss: 308.229 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 940/4776 | Loss: 279.190 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 950/4776 | Loss: 289.554 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 960/4776 | Loss: 306.643 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 970/4776 | Loss: 277.828 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 980/4776 | Loss: 302.797 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 990/4776 | Loss: 284.324 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1000/4776 | Loss: 305.126 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1010/4776 | Loss: 301.462 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1020/4776 | Loss: 288.220 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1030/4776 | Loss: 288.713 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1040/4776 | Loss: 304.832 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1050/4776 | Loss: 297.584 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1060/4776 | Loss: 297.846 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1070/4776 | Loss: 294.317 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1080/4776 | Loss: 299.600 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1090/4776 | Loss: 305.082 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1100/4776 | Loss: 274.008 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1110/4776 | Loss: 275.169 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1120/4776 | Loss: 299.458 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1130/4776 | Loss: 275.981 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1140/4776 | Loss: 274.199 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1150/4776 | Loss: 300.203 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1160/4776 | Loss: 304.172 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1170/4776 | Loss: 302.170 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1180/4776 | Loss: 287.376 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1190/4776 | Loss: 287.817 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1200/4776 | Loss: 306.138 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1210/4776 | Loss: 288.499 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1220/4776 | Loss: 288.966 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1230/4776 | Loss: 296.520 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1240/4776 | Loss: 281.836 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1250/4776 | Loss: 312.092 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1260/4776 | Loss: 306.371 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1270/4776 | Loss: 310.210 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1280/4776 | Loss: 287.594 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1290/4776 | Loss: 273.691 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1300/4776 | Loss: 295.394 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1310/4776 | Loss: 283.978 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1320/4776 | Loss: 290.563 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1330/4776 | Loss: 279.049 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1340/4776 | Loss: 295.852 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1350/4776 | Loss: 306.316 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1360/4776 | Loss: 300.641 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1370/4776 | Loss: 316.176 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1380/4776 | Loss: 304.390 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1390/4776 | Loss: 290.872 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1400/4776 | Loss: 290.675 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1410/4776 | Loss: 303.473 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1420/4776 | Loss: 307.310 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1430/4776 | Loss: 315.878 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1440/4776 | Loss: 292.897 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1450/4776 | Loss: 287.241 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1460/4776 | Loss: 286.908 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1470/4776 | Loss: 297.945 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1480/4776 | Loss: 309.029 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1490/4776 | Loss: 284.528 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1500/4776 | Loss: 286.169 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1510/4776 | Loss: 308.544 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1520/4776 | Loss: 305.681 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1530/4776 | Loss: 289.165 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1540/4776 | Loss: 309.851 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1550/4776 | Loss: 295.224 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1560/4776 | Loss: 308.302 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1570/4776 | Loss: 298.148 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1580/4776 | Loss: 290.374 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1590/4776 | Loss: 316.900 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1600/4776 | Loss: 292.696 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1610/4776 | Loss: 297.421 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1620/4776 | Loss: 290.964 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1630/4776 | Loss: 289.508 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1640/4776 | Loss: 289.919 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1650/4776 | Loss: 298.788 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1660/4776 | Loss: 313.103 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1670/4776 | Loss: 290.494 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1680/4776 | Loss: 298.442 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1690/4776 | Loss: 315.515 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1700/4776 | Loss: 284.037 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1710/4776 | Loss: 282.056 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1720/4776 | Loss: 292.861 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1730/4776 | Loss: 304.009 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1740/4776 | Loss: 299.248 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1750/4776 | Loss: 293.300 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1760/4776 | Loss: 292.790 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1770/4776 | Loss: 306.012 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1780/4776 | Loss: 297.506 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1790/4776 | Loss: 270.608 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 1800/4776 | Loss: 297.545 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1810/4776 | Loss: 282.493 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1820/4776 | Loss: 277.076 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1830/4776 | Loss: 298.942 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1840/4776 | Loss: 305.432 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1850/4776 | Loss: 275.545 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1860/4776 | Loss: 267.725 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1870/4776 | Loss: 304.055 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1880/4776 | Loss: 301.980 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1890/4776 | Loss: 301.296 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1900/4776 | Loss: 281.772 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1910/4776 | Loss: 287.918 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1920/4776 | Loss: 273.580 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1930/4776 | Loss: 289.887 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1940/4776 | Loss: 318.926 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1950/4776 | Loss: 316.973 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1960/4776 | Loss: 318.792 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1970/4776 | Loss: 303.915 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1980/4776 | Loss: 293.227 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1990/4776 | Loss: 290.940 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2000/4776 | Loss: 292.682 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2010/4776 | Loss: 275.471 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 2020/4776 | Loss: 306.293 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2030/4776 | Loss: 312.099 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2040/4776 | Loss: 279.235 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2050/4776 | Loss: 307.408 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2060/4776 | Loss: 294.804 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2070/4776 | Loss: 297.903 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2080/4776 | Loss: 294.160 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2090/4776 | Loss: 306.718 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2100/4776 | Loss: 296.478 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2110/4776 | Loss: 277.294 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 2120/4776 | Loss: 297.047 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2130/4776 | Loss: 302.052 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2140/4776 | Loss: 294.882 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2150/4776 | Loss: 334.541 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2160/4776 | Loss: 301.303 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2170/4776 | Loss: 301.497 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2180/4776 | Loss: 290.235 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2190/4776 | Loss: 295.182 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2200/4776 | Loss: 308.605 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2210/4776 | Loss: 311.752 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2220/4776 | Loss: 296.099 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2230/4776 | Loss: 298.500 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2240/4776 | Loss: 282.356 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2250/4776 | Loss: 288.843 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2260/4776 | Loss: 286.895 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2270/4776 | Loss: 292.606 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2280/4776 | Loss: 302.048 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2290/4776 | Loss: 279.534 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 2300/4776 | Loss: 319.834 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2310/4776 | Loss: 302.424 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2320/4776 | Loss: 295.710 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2330/4776 | Loss: 320.604 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2340/4776 | Loss: 300.345 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2350/4776 | Loss: 282.328 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 2360/4776 | Loss: 294.837 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2370/4776 | Loss: 291.701 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2380/4776 | Loss: 307.330 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2390/4776 | Loss: 290.517 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2400/4776 | Loss: 295.110 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2410/4776 | Loss: 291.073 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2420/4776 | Loss: 315.073 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2430/4776 | Loss: 300.537 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2440/4776 | Loss: 292.469 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2450/4776 | Loss: 319.022 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2460/4776 | Loss: 304.559 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2470/4776 | Loss: 291.720 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2480/4776 | Loss: 318.519 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2490/4776 | Loss: 301.838 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2500/4776 | Loss: 296.857 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2510/4776 | Loss: 308.916 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2520/4776 | Loss: 285.888 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2530/4776 | Loss: 305.873 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2540/4776 | Loss: 275.983 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 2550/4776 | Loss: 323.744 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2560/4776 | Loss: 304.835 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2570/4776 | Loss: 281.437 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2580/4776 | Loss: 296.781 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2590/4776 | Loss: 289.720 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2600/4776 | Loss: 307.209 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2610/4776 | Loss: 286.940 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2620/4776 | Loss: 330.190 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2630/4776 | Loss: 291.304 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2640/4776 | Loss: 284.495 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2650/4776 | Loss: 285.918 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2660/4776 | Loss: 306.631 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2670/4776 | Loss: 284.940 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2680/4776 | Loss: 303.275 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2690/4776 | Loss: 308.239 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2700/4776 | Loss: 309.179 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2710/4776 | Loss: 284.955 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2720/4776 | Loss: 304.776 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2730/4776 | Loss: 295.625 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2740/4776 | Loss: 294.965 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2750/4776 | Loss: 295.500 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 2760/4776 | Loss: 306.312 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2770/4776 | Loss: 303.709 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2780/4776 | Loss: 298.187 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2790/4776 | Loss: 311.968 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2800/4776 | Loss: 311.781 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2810/4776 | Loss: 298.761 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2820/4776 | Loss: 301.226 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2830/4776 | Loss: 300.094 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2840/4776 | Loss: 294.491 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2850/4776 | Loss: 310.699 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2860/4776 | Loss: 297.432 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2870/4776 | Loss: 307.338 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2880/4776 | Loss: 307.407 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2890/4776 | Loss: 292.055 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2900/4776 | Loss: 297.452 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2910/4776 | Loss: 304.087 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2920/4776 | Loss: 295.823 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2930/4776 | Loss: 290.780 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2940/4776 | Loss: 290.508 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2950/4776 | Loss: 300.696 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 2960/4776 | Loss: 293.137 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 2970/4776 | Loss: 270.161 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 2980/4776 | Loss: 297.309 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 2990/4776 | Loss: 273.216 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3000/4776 | Loss: 287.990 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3010/4776 | Loss: 286.180 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3020/4776 | Loss: 297.307 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3030/4776 | Loss: 297.899 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3040/4776 | Loss: 307.823 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3050/4776 | Loss: 300.553 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3060/4776 | Loss: 304.988 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3070/4776 | Loss: 292.405 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3080/4776 | Loss: 297.688 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3090/4776 | Loss: 302.816 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3100/4776 | Loss: 291.034 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3110/4776 | Loss: 309.311 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3120/4776 | Loss: 317.221 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3130/4776 | Loss: 318.900 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3140/4776 | Loss: 296.888 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3150/4776 | Loss: 305.007 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3160/4776 | Loss: 283.620 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3170/4776 | Loss: 311.788 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3180/4776 | Loss: 292.303 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3190/4776 | Loss: 293.501 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3200/4776 | Loss: 273.391 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3210/4776 | Loss: 299.834 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3220/4776 | Loss: 296.899 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3230/4776 | Loss: 280.888 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3240/4776 | Loss: 290.732 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3250/4776 | Loss: 313.227 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3260/4776 | Loss: 295.890 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3270/4776 | Loss: 268.026 | Accuracy: 0.500\n",
      "[Epoch: 7/200] - Step: 3280/4776 | Loss: 305.055 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3290/4776 | Loss: 287.417 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3300/4776 | Loss: 310.917 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3310/4776 | Loss: 295.108 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3320/4776 | Loss: 284.142 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3330/4776 | Loss: 283.641 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3340/4776 | Loss: 297.596 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3350/4776 | Loss: 296.136 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3360/4776 | Loss: 303.153 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3370/4776 | Loss: 312.272 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3380/4776 | Loss: 289.985 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3390/4776 | Loss: 331.352 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3400/4776 | Loss: 288.820 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3410/4776 | Loss: 304.692 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3420/4776 | Loss: 309.175 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3430/4776 | Loss: 305.808 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3440/4776 | Loss: 298.394 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3450/4776 | Loss: 302.100 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3460/4776 | Loss: 289.589 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3470/4776 | Loss: 289.536 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3480/4776 | Loss: 305.374 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3490/4776 | Loss: 288.562 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3500/4776 | Loss: 324.920 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3510/4776 | Loss: 295.274 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3520/4776 | Loss: 294.944 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3530/4776 | Loss: 290.501 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3540/4776 | Loss: 305.555 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3550/4776 | Loss: 316.473 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3560/4776 | Loss: 300.313 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3570/4776 | Loss: 292.676 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3580/4776 | Loss: 293.108 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3590/4776 | Loss: 289.570 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3600/4776 | Loss: 337.671 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3610/4776 | Loss: 292.648 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3620/4776 | Loss: 285.886 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3630/4776 | Loss: 297.785 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3640/4776 | Loss: 310.019 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3650/4776 | Loss: 276.513 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3660/4776 | Loss: 308.982 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3670/4776 | Loss: 311.011 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3680/4776 | Loss: 283.243 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3690/4776 | Loss: 295.058 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3700/4776 | Loss: 291.567 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3710/4776 | Loss: 297.067 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3720/4776 | Loss: 277.619 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3730/4776 | Loss: 318.871 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3740/4776 | Loss: 293.580 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3750/4776 | Loss: 296.608 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3760/4776 | Loss: 312.037 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3770/4776 | Loss: 294.965 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3780/4776 | Loss: 306.367 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3790/4776 | Loss: 295.959 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3800/4776 | Loss: 285.592 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3810/4776 | Loss: 308.796 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3820/4776 | Loss: 291.770 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3830/4776 | Loss: 339.859 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3840/4776 | Loss: 300.336 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3850/4776 | Loss: 306.112 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3860/4776 | Loss: 312.919 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3870/4776 | Loss: 284.630 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3880/4776 | Loss: 302.925 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3890/4776 | Loss: 286.646 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 3900/4776 | Loss: 306.390 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 3910/4776 | Loss: 294.363 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3920/4776 | Loss: 292.676 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3930/4776 | Loss: 294.275 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3940/4776 | Loss: 285.777 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 3950/4776 | Loss: 298.390 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3960/4776 | Loss: 302.918 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3970/4776 | Loss: 292.060 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3980/4776 | Loss: 296.552 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 3990/4776 | Loss: 289.146 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4000/4776 | Loss: 288.455 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4010/4776 | Loss: 296.527 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4020/4776 | Loss: 308.046 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4030/4776 | Loss: 279.057 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4040/4776 | Loss: 293.096 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4050/4776 | Loss: 298.254 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4060/4776 | Loss: 295.162 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4070/4776 | Loss: 311.351 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4080/4776 | Loss: 298.177 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4090/4776 | Loss: 293.136 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4100/4776 | Loss: 280.551 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4110/4776 | Loss: 299.058 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4120/4776 | Loss: 281.722 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4130/4776 | Loss: 312.855 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4140/4776 | Loss: 305.518 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4150/4776 | Loss: 320.471 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4160/4776 | Loss: 272.081 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4170/4776 | Loss: 293.934 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4180/4776 | Loss: 298.548 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4190/4776 | Loss: 273.938 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4200/4776 | Loss: 272.339 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4210/4776 | Loss: 314.140 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4220/4776 | Loss: 278.962 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4230/4776 | Loss: 287.579 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4240/4776 | Loss: 310.533 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4250/4776 | Loss: 283.458 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4260/4776 | Loss: 295.042 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4270/4776 | Loss: 283.804 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4280/4776 | Loss: 319.904 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4290/4776 | Loss: 296.620 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4300/4776 | Loss: 282.538 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4310/4776 | Loss: 292.720 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4320/4776 | Loss: 310.370 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4330/4776 | Loss: 296.977 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4340/4776 | Loss: 304.627 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4350/4776 | Loss: 296.747 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4360/4776 | Loss: 284.895 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4370/4776 | Loss: 293.515 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4380/4776 | Loss: 284.712 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4390/4776 | Loss: 308.873 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4400/4776 | Loss: 275.915 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4410/4776 | Loss: 281.631 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4420/4776 | Loss: 287.624 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4430/4776 | Loss: 281.585 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4440/4776 | Loss: 318.887 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4450/4776 | Loss: 309.532 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4460/4776 | Loss: 287.096 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4470/4776 | Loss: 304.086 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4480/4776 | Loss: 303.809 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4490/4776 | Loss: 308.068 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4500/4776 | Loss: 292.343 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4510/4776 | Loss: 294.080 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4520/4776 | Loss: 308.204 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4530/4776 | Loss: 287.453 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4540/4776 | Loss: 280.839 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4550/4776 | Loss: 309.812 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4560/4776 | Loss: 295.127 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4570/4776 | Loss: 276.091 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4580/4776 | Loss: 297.476 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4590/4776 | Loss: 305.773 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4600/4776 | Loss: 301.963 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4610/4776 | Loss: 289.399 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4620/4776 | Loss: 323.142 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4630/4776 | Loss: 295.186 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4640/4776 | Loss: 301.478 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4650/4776 | Loss: 297.951 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4660/4776 | Loss: 285.067 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4670/4776 | Loss: 301.259 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4680/4776 | Loss: 313.099 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4690/4776 | Loss: 286.718 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4700/4776 | Loss: 285.665 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4710/4776 | Loss: 285.293 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 4720/4776 | Loss: 285.201 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4730/4776 | Loss: 307.636 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4740/4776 | Loss: 285.185 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 4750/4776 | Loss: 278.912 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 4760/4776 | Loss: 289.698 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 4770/4776 | Loss: 271.485 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 8/200] - Step: 10/4776 | Loss: 312.920 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 20/4776 | Loss: 283.758 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 30/4776 | Loss: 294.106 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 40/4776 | Loss: 304.816 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 50/4776 | Loss: 295.968 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 60/4776 | Loss: 293.768 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 70/4776 | Loss: 306.192 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 80/4776 | Loss: 297.358 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 90/4776 | Loss: 277.691 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 100/4776 | Loss: 285.864 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 110/4776 | Loss: 298.591 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 120/4776 | Loss: 266.331 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 130/4776 | Loss: 288.404 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 140/4776 | Loss: 285.838 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 150/4776 | Loss: 258.584 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 160/4776 | Loss: 285.916 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 170/4776 | Loss: 281.637 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 180/4776 | Loss: 266.780 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 190/4776 | Loss: 340.302 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 200/4776 | Loss: 326.057 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 210/4776 | Loss: 290.343 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 220/4776 | Loss: 274.668 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 230/4776 | Loss: 316.547 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 240/4776 | Loss: 279.250 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 250/4776 | Loss: 282.754 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 260/4776 | Loss: 297.000 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 270/4776 | Loss: 290.735 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 280/4776 | Loss: 279.593 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 290/4776 | Loss: 291.920 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 300/4776 | Loss: 279.535 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 310/4776 | Loss: 294.401 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 320/4776 | Loss: 288.229 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 330/4776 | Loss: 306.673 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 340/4776 | Loss: 313.257 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 350/4776 | Loss: 327.134 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 360/4776 | Loss: 280.133 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 370/4776 | Loss: 298.824 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 380/4776 | Loss: 291.259 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 390/4776 | Loss: 288.421 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 400/4776 | Loss: 299.363 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 410/4776 | Loss: 283.122 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 420/4776 | Loss: 295.820 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 430/4776 | Loss: 277.437 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 440/4776 | Loss: 288.126 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 450/4776 | Loss: 290.961 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 460/4776 | Loss: 297.783 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 470/4776 | Loss: 303.371 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 480/4776 | Loss: 314.339 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 490/4776 | Loss: 293.833 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 500/4776 | Loss: 294.576 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 510/4776 | Loss: 296.322 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 520/4776 | Loss: 273.095 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 530/4776 | Loss: 308.007 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 540/4776 | Loss: 311.608 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 550/4776 | Loss: 299.465 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 560/4776 | Loss: 295.718 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 570/4776 | Loss: 312.301 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 580/4776 | Loss: 283.287 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 590/4776 | Loss: 316.366 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 600/4776 | Loss: 290.746 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 610/4776 | Loss: 283.782 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 620/4776 | Loss: 292.240 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 630/4776 | Loss: 309.452 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 640/4776 | Loss: 297.301 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 650/4776 | Loss: 298.686 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 660/4776 | Loss: 318.430 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 670/4776 | Loss: 296.994 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 680/4776 | Loss: 308.699 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 690/4776 | Loss: 282.121 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 700/4776 | Loss: 304.778 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 710/4776 | Loss: 288.144 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 720/4776 | Loss: 290.371 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 730/4776 | Loss: 297.167 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 740/4776 | Loss: 302.613 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 750/4776 | Loss: 310.088 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 760/4776 | Loss: 298.134 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 770/4776 | Loss: 305.509 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 780/4776 | Loss: 286.958 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 790/4776 | Loss: 285.988 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 800/4776 | Loss: 299.741 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 810/4776 | Loss: 309.896 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 820/4776 | Loss: 299.639 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 830/4776 | Loss: 299.606 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 840/4776 | Loss: 293.335 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 850/4776 | Loss: 301.440 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 860/4776 | Loss: 306.720 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 870/4776 | Loss: 299.028 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 880/4776 | Loss: 290.705 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 890/4776 | Loss: 279.534 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 900/4776 | Loss: 308.662 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 910/4776 | Loss: 338.392 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 920/4776 | Loss: 303.313 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 930/4776 | Loss: 295.180 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 940/4776 | Loss: 296.433 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 950/4776 | Loss: 288.529 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 960/4776 | Loss: 298.746 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 970/4776 | Loss: 292.177 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 980/4776 | Loss: 300.656 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 990/4776 | Loss: 301.899 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1000/4776 | Loss: 308.902 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1010/4776 | Loss: 292.683 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1020/4776 | Loss: 303.852 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1030/4776 | Loss: 285.703 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1040/4776 | Loss: 288.741 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1050/4776 | Loss: 310.435 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1060/4776 | Loss: 305.420 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1070/4776 | Loss: 305.112 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1080/4776 | Loss: 291.984 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1090/4776 | Loss: 297.117 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1100/4776 | Loss: 283.643 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1110/4776 | Loss: 317.691 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1120/4776 | Loss: 299.951 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1130/4776 | Loss: 291.866 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1140/4776 | Loss: 294.536 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1150/4776 | Loss: 310.645 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1160/4776 | Loss: 270.522 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 1170/4776 | Loss: 277.528 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1180/4776 | Loss: 294.265 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1190/4776 | Loss: 294.108 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1200/4776 | Loss: 290.092 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1210/4776 | Loss: 323.779 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1220/4776 | Loss: 318.901 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1230/4776 | Loss: 298.619 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1240/4776 | Loss: 306.964 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1250/4776 | Loss: 310.923 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1260/4776 | Loss: 308.845 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1270/4776 | Loss: 298.516 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1280/4776 | Loss: 287.278 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1290/4776 | Loss: 289.299 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1300/4776 | Loss: 290.145 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1310/4776 | Loss: 291.745 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1320/4776 | Loss: 295.397 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1330/4776 | Loss: 284.206 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1340/4776 | Loss: 294.765 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1350/4776 | Loss: 286.376 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1360/4776 | Loss: 305.756 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1370/4776 | Loss: 299.007 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1380/4776 | Loss: 302.600 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1390/4776 | Loss: 303.115 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1400/4776 | Loss: 293.986 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1410/4776 | Loss: 295.013 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1420/4776 | Loss: 301.083 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1430/4776 | Loss: 294.168 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1440/4776 | Loss: 289.551 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1450/4776 | Loss: 318.810 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1460/4776 | Loss: 316.942 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1470/4776 | Loss: 292.765 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1480/4776 | Loss: 308.101 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1490/4776 | Loss: 292.647 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1500/4776 | Loss: 292.847 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1510/4776 | Loss: 293.176 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1520/4776 | Loss: 301.863 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1530/4776 | Loss: 287.636 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1540/4776 | Loss: 296.421 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1550/4776 | Loss: 302.419 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1560/4776 | Loss: 290.543 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1570/4776 | Loss: 306.586 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1580/4776 | Loss: 296.081 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1590/4776 | Loss: 298.148 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1600/4776 | Loss: 300.917 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1610/4776 | Loss: 279.281 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 1620/4776 | Loss: 313.078 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1630/4776 | Loss: 306.049 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1640/4776 | Loss: 307.083 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1650/4776 | Loss: 301.341 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1660/4776 | Loss: 291.471 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1670/4776 | Loss: 322.367 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1680/4776 | Loss: 285.204 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 1690/4776 | Loss: 295.567 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1700/4776 | Loss: 288.954 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1710/4776 | Loss: 315.179 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1720/4776 | Loss: 296.594 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1730/4776 | Loss: 282.347 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1740/4776 | Loss: 293.961 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1750/4776 | Loss: 287.750 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1760/4776 | Loss: 303.695 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1770/4776 | Loss: 291.366 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1780/4776 | Loss: 290.628 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1790/4776 | Loss: 310.727 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1800/4776 | Loss: 296.740 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1810/4776 | Loss: 295.996 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1820/4776 | Loss: 313.493 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1830/4776 | Loss: 290.557 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1840/4776 | Loss: 292.757 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1850/4776 | Loss: 291.859 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1860/4776 | Loss: 290.934 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1870/4776 | Loss: 282.611 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1880/4776 | Loss: 286.254 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1890/4776 | Loss: 303.271 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1900/4776 | Loss: 303.874 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1910/4776 | Loss: 287.024 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1920/4776 | Loss: 305.154 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1930/4776 | Loss: 293.401 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1940/4776 | Loss: 304.639 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1950/4776 | Loss: 297.818 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1960/4776 | Loss: 283.566 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1970/4776 | Loss: 275.693 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1980/4776 | Loss: 300.056 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1990/4776 | Loss: 284.061 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2000/4776 | Loss: 309.112 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2010/4776 | Loss: 317.764 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2020/4776 | Loss: 283.171 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2030/4776 | Loss: 302.634 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2040/4776 | Loss: 294.400 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2050/4776 | Loss: 312.692 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2060/4776 | Loss: 304.328 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2070/4776 | Loss: 295.089 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2080/4776 | Loss: 306.683 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2090/4776 | Loss: 301.461 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2100/4776 | Loss: 301.919 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2110/4776 | Loss: 295.858 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2120/4776 | Loss: 301.585 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2130/4776 | Loss: 300.232 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2140/4776 | Loss: 284.586 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2150/4776 | Loss: 299.337 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2160/4776 | Loss: 276.618 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2170/4776 | Loss: 283.152 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2180/4776 | Loss: 305.741 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2190/4776 | Loss: 290.558 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2200/4776 | Loss: 297.183 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2210/4776 | Loss: 341.570 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2220/4776 | Loss: 274.747 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2230/4776 | Loss: 295.299 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2240/4776 | Loss: 290.906 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2250/4776 | Loss: 287.881 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2260/4776 | Loss: 302.630 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2270/4776 | Loss: 298.984 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2280/4776 | Loss: 293.368 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2290/4776 | Loss: 297.365 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2300/4776 | Loss: 294.623 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2310/4776 | Loss: 282.457 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2320/4776 | Loss: 285.880 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2330/4776 | Loss: 273.997 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2340/4776 | Loss: 286.681 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2350/4776 | Loss: 325.358 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2360/4776 | Loss: 287.571 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2370/4776 | Loss: 290.968 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2380/4776 | Loss: 294.049 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2390/4776 | Loss: 280.719 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2400/4776 | Loss: 291.026 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2410/4776 | Loss: 313.815 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2420/4776 | Loss: 284.340 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2430/4776 | Loss: 295.792 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2440/4776 | Loss: 315.273 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2450/4776 | Loss: 277.980 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2460/4776 | Loss: 302.538 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2470/4776 | Loss: 288.125 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2480/4776 | Loss: 291.244 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2490/4776 | Loss: 310.953 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2500/4776 | Loss: 303.107 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2510/4776 | Loss: 281.649 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2520/4776 | Loss: 308.443 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2530/4776 | Loss: 287.146 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2540/4776 | Loss: 293.392 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2550/4776 | Loss: 307.471 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2560/4776 | Loss: 283.920 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2570/4776 | Loss: 303.588 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2580/4776 | Loss: 288.695 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2590/4776 | Loss: 299.517 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2600/4776 | Loss: 277.861 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2610/4776 | Loss: 305.635 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2620/4776 | Loss: 294.207 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2630/4776 | Loss: 285.501 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2640/4776 | Loss: 299.938 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2650/4776 | Loss: 281.718 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2660/4776 | Loss: 317.125 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2670/4776 | Loss: 310.915 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2680/4776 | Loss: 284.649 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2690/4776 | Loss: 316.032 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2700/4776 | Loss: 301.917 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2710/4776 | Loss: 321.429 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2720/4776 | Loss: 299.563 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2730/4776 | Loss: 297.067 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2740/4776 | Loss: 273.494 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2750/4776 | Loss: 292.252 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2760/4776 | Loss: 266.925 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2770/4776 | Loss: 281.063 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2780/4776 | Loss: 296.520 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2790/4776 | Loss: 311.792 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2800/4776 | Loss: 283.138 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2810/4776 | Loss: 303.191 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2820/4776 | Loss: 307.955 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2830/4776 | Loss: 269.157 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2840/4776 | Loss: 307.253 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2850/4776 | Loss: 316.220 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2860/4776 | Loss: 298.009 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2870/4776 | Loss: 291.388 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2880/4776 | Loss: 291.801 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 2890/4776 | Loss: 287.097 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2900/4776 | Loss: 293.088 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2910/4776 | Loss: 304.091 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2920/4776 | Loss: 308.176 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2930/4776 | Loss: 273.320 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 2940/4776 | Loss: 303.813 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2950/4776 | Loss: 282.356 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2960/4776 | Loss: 296.967 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2970/4776 | Loss: 317.248 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 2980/4776 | Loss: 308.486 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 2990/4776 | Loss: 302.667 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3000/4776 | Loss: 275.926 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3010/4776 | Loss: 319.523 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3020/4776 | Loss: 305.552 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3030/4776 | Loss: 307.665 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3040/4776 | Loss: 301.166 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3050/4776 | Loss: 286.992 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3060/4776 | Loss: 296.721 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3070/4776 | Loss: 288.522 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3080/4776 | Loss: 313.169 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3090/4776 | Loss: 297.417 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3100/4776 | Loss: 297.773 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3110/4776 | Loss: 284.489 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3120/4776 | Loss: 314.230 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3130/4776 | Loss: 296.063 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3140/4776 | Loss: 304.292 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3150/4776 | Loss: 292.530 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3160/4776 | Loss: 306.999 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3170/4776 | Loss: 297.318 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3180/4776 | Loss: 303.143 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3190/4776 | Loss: 294.456 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3200/4776 | Loss: 295.523 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3210/4776 | Loss: 310.293 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3220/4776 | Loss: 301.964 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3230/4776 | Loss: 298.204 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3240/4776 | Loss: 283.517 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3250/4776 | Loss: 293.052 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3260/4776 | Loss: 299.066 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3270/4776 | Loss: 291.366 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3280/4776 | Loss: 282.827 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3290/4776 | Loss: 286.222 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3300/4776 | Loss: 286.745 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3310/4776 | Loss: 292.601 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3320/4776 | Loss: 269.471 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 3330/4776 | Loss: 292.398 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3340/4776 | Loss: 313.222 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3350/4776 | Loss: 305.926 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3360/4776 | Loss: 310.120 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3370/4776 | Loss: 293.043 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3380/4776 | Loss: 311.280 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3390/4776 | Loss: 302.406 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3400/4776 | Loss: 286.769 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3410/4776 | Loss: 315.387 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3420/4776 | Loss: 297.489 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3430/4776 | Loss: 305.286 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3440/4776 | Loss: 293.889 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3450/4776 | Loss: 280.072 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3460/4776 | Loss: 294.488 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3470/4776 | Loss: 292.614 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3480/4776 | Loss: 297.717 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3490/4776 | Loss: 264.772 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 3500/4776 | Loss: 277.707 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3510/4776 | Loss: 297.164 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3520/4776 | Loss: 272.284 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3530/4776 | Loss: 287.313 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3540/4776 | Loss: 287.893 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3550/4776 | Loss: 311.983 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3560/4776 | Loss: 275.164 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3570/4776 | Loss: 317.196 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3580/4776 | Loss: 297.475 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3590/4776 | Loss: 295.049 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3600/4776 | Loss: 334.183 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3610/4776 | Loss: 288.959 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3620/4776 | Loss: 296.032 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3630/4776 | Loss: 317.756 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3640/4776 | Loss: 307.015 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3650/4776 | Loss: 284.433 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3660/4776 | Loss: 285.517 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 3670/4776 | Loss: 290.247 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3680/4776 | Loss: 289.439 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3690/4776 | Loss: 291.613 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3700/4776 | Loss: 306.116 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3710/4776 | Loss: 289.001 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3720/4776 | Loss: 287.470 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3730/4776 | Loss: 294.001 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3740/4776 | Loss: 308.540 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3750/4776 | Loss: 301.791 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3760/4776 | Loss: 298.630 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3770/4776 | Loss: 314.155 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3780/4776 | Loss: 309.235 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3790/4776 | Loss: 284.627 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3800/4776 | Loss: 307.499 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3810/4776 | Loss: 279.966 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 3820/4776 | Loss: 292.930 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3830/4776 | Loss: 290.723 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3840/4776 | Loss: 311.427 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3850/4776 | Loss: 298.641 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3860/4776 | Loss: 300.288 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3870/4776 | Loss: 272.746 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 3880/4776 | Loss: 309.633 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3890/4776 | Loss: 303.357 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3900/4776 | Loss: 296.386 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3910/4776 | Loss: 291.254 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3920/4776 | Loss: 297.625 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3930/4776 | Loss: 305.256 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3940/4776 | Loss: 294.790 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 3950/4776 | Loss: 308.204 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 3960/4776 | Loss: 278.701 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3970/4776 | Loss: 286.462 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3980/4776 | Loss: 295.942 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 3990/4776 | Loss: 276.336 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4000/4776 | Loss: 299.908 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4010/4776 | Loss: 312.259 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4020/4776 | Loss: 283.133 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4030/4776 | Loss: 290.168 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4040/4776 | Loss: 278.000 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4050/4776 | Loss: 319.892 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4060/4776 | Loss: 298.050 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4070/4776 | Loss: 293.654 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4080/4776 | Loss: 316.836 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4090/4776 | Loss: 304.412 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4100/4776 | Loss: 296.526 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4110/4776 | Loss: 300.299 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4120/4776 | Loss: 294.334 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4130/4776 | Loss: 287.924 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4140/4776 | Loss: 293.067 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4150/4776 | Loss: 290.644 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4160/4776 | Loss: 293.523 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4170/4776 | Loss: 295.956 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4180/4776 | Loss: 295.377 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4190/4776 | Loss: 291.303 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4200/4776 | Loss: 303.261 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4210/4776 | Loss: 291.058 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4220/4776 | Loss: 292.078 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4230/4776 | Loss: 307.990 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4240/4776 | Loss: 284.162 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4250/4776 | Loss: 272.617 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4260/4776 | Loss: 297.638 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4270/4776 | Loss: 311.127 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4280/4776 | Loss: 319.845 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4290/4776 | Loss: 292.498 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4300/4776 | Loss: 301.398 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4310/4776 | Loss: 305.986 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4320/4776 | Loss: 288.965 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4330/4776 | Loss: 306.537 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4340/4776 | Loss: 299.534 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4350/4776 | Loss: 284.332 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4360/4776 | Loss: 291.822 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4370/4776 | Loss: 275.949 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4380/4776 | Loss: 309.436 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4390/4776 | Loss: 296.522 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4400/4776 | Loss: 296.742 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4410/4776 | Loss: 306.845 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4420/4776 | Loss: 299.607 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4430/4776 | Loss: 301.468 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4440/4776 | Loss: 287.403 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4450/4776 | Loss: 295.310 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4460/4776 | Loss: 282.956 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4470/4776 | Loss: 291.250 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4480/4776 | Loss: 273.528 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4490/4776 | Loss: 290.420 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4500/4776 | Loss: 276.053 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4510/4776 | Loss: 312.262 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4520/4776 | Loss: 305.566 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4530/4776 | Loss: 299.266 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4540/4776 | Loss: 293.744 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4550/4776 | Loss: 298.378 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4560/4776 | Loss: 302.560 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4570/4776 | Loss: 298.291 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4580/4776 | Loss: 302.981 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4590/4776 | Loss: 288.267 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4600/4776 | Loss: 287.620 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4610/4776 | Loss: 302.712 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4620/4776 | Loss: 303.887 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4630/4776 | Loss: 276.894 | Accuracy: 0.400\n",
      "[Epoch: 8/200] - Step: 4640/4776 | Loss: 312.973 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4650/4776 | Loss: 300.948 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4660/4776 | Loss: 287.709 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4670/4776 | Loss: 318.495 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4680/4776 | Loss: 302.944 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4690/4776 | Loss: 296.684 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4700/4776 | Loss: 301.821 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4710/4776 | Loss: 290.468 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4720/4776 | Loss: 276.806 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4730/4776 | Loss: 310.095 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 4740/4776 | Loss: 287.784 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 4750/4776 | Loss: 284.964 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 4760/4776 | Loss: 306.718 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 4770/4776 | Loss: 298.527 | Accuracy: 0.100\n",
      "Accuracy:  0.10819672131147541\n",
      "Model saved!\n",
      "[Epoch: 9/200] - Step: 10/4776 | Loss: 259.370 | Accuracy: 0.500\n",
      "[Epoch: 9/200] - Step: 20/4776 | Loss: 297.114 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 30/4776 | Loss: 317.316 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 40/4776 | Loss: 300.479 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 50/4776 | Loss: 300.372 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 60/4776 | Loss: 303.045 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 70/4776 | Loss: 294.822 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 80/4776 | Loss: 295.884 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 90/4776 | Loss: 286.772 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 100/4776 | Loss: 283.147 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 110/4776 | Loss: 304.324 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 120/4776 | Loss: 306.935 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 130/4776 | Loss: 306.596 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 140/4776 | Loss: 291.504 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 150/4776 | Loss: 307.301 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 160/4776 | Loss: 314.928 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 170/4776 | Loss: 289.439 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 180/4776 | Loss: 294.617 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 190/4776 | Loss: 299.702 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 200/4776 | Loss: 278.726 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 210/4776 | Loss: 310.928 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 220/4776 | Loss: 295.179 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 230/4776 | Loss: 297.390 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 240/4776 | Loss: 293.932 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 250/4776 | Loss: 300.528 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 260/4776 | Loss: 299.339 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 270/4776 | Loss: 306.287 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 280/4776 | Loss: 303.885 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 290/4776 | Loss: 291.298 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 300/4776 | Loss: 301.185 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 310/4776 | Loss: 300.826 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 320/4776 | Loss: 329.345 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 330/4776 | Loss: 292.823 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 340/4776 | Loss: 301.247 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 350/4776 | Loss: 299.791 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 360/4776 | Loss: 295.777 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 370/4776 | Loss: 314.418 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 380/4776 | Loss: 293.658 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 390/4776 | Loss: 269.599 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 400/4776 | Loss: 287.226 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 410/4776 | Loss: 294.536 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 420/4776 | Loss: 324.413 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 430/4776 | Loss: 285.871 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 440/4776 | Loss: 283.889 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 450/4776 | Loss: 318.951 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 460/4776 | Loss: 286.933 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 470/4776 | Loss: 308.562 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 480/4776 | Loss: 271.022 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 490/4776 | Loss: 290.846 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 500/4776 | Loss: 303.539 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 510/4776 | Loss: 311.294 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 520/4776 | Loss: 296.737 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 530/4776 | Loss: 301.950 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 540/4776 | Loss: 304.678 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 550/4776 | Loss: 272.690 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 560/4776 | Loss: 306.351 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 570/4776 | Loss: 292.772 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 580/4776 | Loss: 294.137 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 590/4776 | Loss: 293.335 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 600/4776 | Loss: 279.116 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 610/4776 | Loss: 292.838 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 620/4776 | Loss: 266.840 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 630/4776 | Loss: 299.884 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 640/4776 | Loss: 298.876 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 650/4776 | Loss: 286.089 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 660/4776 | Loss: 273.045 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 670/4776 | Loss: 305.726 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 680/4776 | Loss: 300.235 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 690/4776 | Loss: 301.692 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 700/4776 | Loss: 310.151 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 710/4776 | Loss: 301.679 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 720/4776 | Loss: 307.608 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 730/4776 | Loss: 288.606 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 740/4776 | Loss: 293.105 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 750/4776 | Loss: 288.143 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 760/4776 | Loss: 270.279 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 770/4776 | Loss: 297.615 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 780/4776 | Loss: 286.072 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 790/4776 | Loss: 277.708 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 800/4776 | Loss: 294.932 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 810/4776 | Loss: 285.290 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 820/4776 | Loss: 306.594 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 830/4776 | Loss: 279.764 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 840/4776 | Loss: 299.482 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 850/4776 | Loss: 316.641 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 860/4776 | Loss: 292.887 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 870/4776 | Loss: 288.224 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 880/4776 | Loss: 305.366 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 890/4776 | Loss: 324.934 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 900/4776 | Loss: 299.375 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 910/4776 | Loss: 294.181 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 920/4776 | Loss: 299.542 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 930/4776 | Loss: 297.142 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 940/4776 | Loss: 288.879 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 950/4776 | Loss: 286.849 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 960/4776 | Loss: 302.939 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 970/4776 | Loss: 280.054 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 980/4776 | Loss: 291.245 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 990/4776 | Loss: 296.270 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1000/4776 | Loss: 292.070 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1010/4776 | Loss: 281.183 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1020/4776 | Loss: 292.450 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1030/4776 | Loss: 290.308 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1040/4776 | Loss: 293.058 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1050/4776 | Loss: 281.849 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1060/4776 | Loss: 349.126 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1070/4776 | Loss: 294.356 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1080/4776 | Loss: 296.749 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1090/4776 | Loss: 314.355 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1100/4776 | Loss: 289.456 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1110/4776 | Loss: 280.853 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1120/4776 | Loss: 299.836 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1130/4776 | Loss: 333.875 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1140/4776 | Loss: 308.971 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1150/4776 | Loss: 289.166 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1160/4776 | Loss: 300.568 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1170/4776 | Loss: 297.257 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1180/4776 | Loss: 297.028 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1190/4776 | Loss: 291.253 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1200/4776 | Loss: 305.003 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1210/4776 | Loss: 291.220 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1220/4776 | Loss: 297.315 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1230/4776 | Loss: 308.192 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1240/4776 | Loss: 295.725 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1250/4776 | Loss: 286.787 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1260/4776 | Loss: 296.552 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1270/4776 | Loss: 311.418 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1280/4776 | Loss: 292.185 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1290/4776 | Loss: 291.065 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1300/4776 | Loss: 298.426 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1310/4776 | Loss: 300.901 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1320/4776 | Loss: 304.842 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1330/4776 | Loss: 296.400 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1340/4776 | Loss: 292.187 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1350/4776 | Loss: 292.509 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1360/4776 | Loss: 297.792 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1370/4776 | Loss: 313.282 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1380/4776 | Loss: 295.875 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1390/4776 | Loss: 303.216 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1400/4776 | Loss: 303.690 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1410/4776 | Loss: 295.742 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1420/4776 | Loss: 314.713 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1430/4776 | Loss: 285.958 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1440/4776 | Loss: 289.668 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1450/4776 | Loss: 292.986 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1460/4776 | Loss: 304.862 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1470/4776 | Loss: 295.877 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1480/4776 | Loss: 301.452 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1490/4776 | Loss: 291.893 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1500/4776 | Loss: 295.583 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1510/4776 | Loss: 290.731 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1520/4776 | Loss: 298.353 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1530/4776 | Loss: 275.282 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1540/4776 | Loss: 313.058 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1550/4776 | Loss: 285.893 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1560/4776 | Loss: 271.072 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1570/4776 | Loss: 270.991 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1580/4776 | Loss: 303.797 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1590/4776 | Loss: 279.180 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1600/4776 | Loss: 297.758 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1610/4776 | Loss: 276.152 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1620/4776 | Loss: 300.487 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1630/4776 | Loss: 257.436 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 1640/4776 | Loss: 301.802 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1650/4776 | Loss: 298.255 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1660/4776 | Loss: 314.529 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1670/4776 | Loss: 287.470 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1680/4776 | Loss: 286.527 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1690/4776 | Loss: 291.880 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1700/4776 | Loss: 307.089 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1710/4776 | Loss: 289.892 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1720/4776 | Loss: 341.728 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1730/4776 | Loss: 290.640 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1740/4776 | Loss: 300.277 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1750/4776 | Loss: 300.899 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1760/4776 | Loss: 292.752 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1770/4776 | Loss: 304.340 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1780/4776 | Loss: 308.115 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1790/4776 | Loss: 303.959 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1800/4776 | Loss: 301.055 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1810/4776 | Loss: 306.976 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1820/4776 | Loss: 297.121 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1830/4776 | Loss: 287.981 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1840/4776 | Loss: 299.263 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 1850/4776 | Loss: 299.839 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1860/4776 | Loss: 283.943 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1870/4776 | Loss: 294.422 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1880/4776 | Loss: 308.056 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1890/4776 | Loss: 291.450 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1900/4776 | Loss: 276.514 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1910/4776 | Loss: 290.674 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1920/4776 | Loss: 287.200 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1930/4776 | Loss: 282.670 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1940/4776 | Loss: 282.617 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1950/4776 | Loss: 317.283 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1960/4776 | Loss: 258.576 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1970/4776 | Loss: 285.554 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1980/4776 | Loss: 297.242 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1990/4776 | Loss: 323.948 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2000/4776 | Loss: 305.175 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2010/4776 | Loss: 293.151 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2020/4776 | Loss: 291.547 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2030/4776 | Loss: 287.798 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2040/4776 | Loss: 298.772 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2050/4776 | Loss: 313.085 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2060/4776 | Loss: 299.765 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2070/4776 | Loss: 293.659 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2080/4776 | Loss: 274.824 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2090/4776 | Loss: 303.762 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2100/4776 | Loss: 314.027 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2110/4776 | Loss: 298.873 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2120/4776 | Loss: 293.958 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2130/4776 | Loss: 298.417 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2140/4776 | Loss: 298.609 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2150/4776 | Loss: 307.865 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2160/4776 | Loss: 296.303 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2170/4776 | Loss: 301.885 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2180/4776 | Loss: 301.518 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2190/4776 | Loss: 279.387 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2200/4776 | Loss: 281.481 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2210/4776 | Loss: 296.656 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2220/4776 | Loss: 293.275 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2230/4776 | Loss: 332.802 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2240/4776 | Loss: 301.060 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2250/4776 | Loss: 301.059 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2260/4776 | Loss: 280.049 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2270/4776 | Loss: 294.339 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2280/4776 | Loss: 300.652 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2290/4776 | Loss: 298.675 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2300/4776 | Loss: 304.028 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2310/4776 | Loss: 298.622 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2320/4776 | Loss: 294.867 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2330/4776 | Loss: 277.900 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 2340/4776 | Loss: 292.959 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2350/4776 | Loss: 291.688 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2360/4776 | Loss: 320.499 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2370/4776 | Loss: 295.508 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2380/4776 | Loss: 289.889 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2390/4776 | Loss: 290.348 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2400/4776 | Loss: 302.525 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2410/4776 | Loss: 282.130 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2420/4776 | Loss: 309.625 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2430/4776 | Loss: 281.210 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2440/4776 | Loss: 297.652 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2450/4776 | Loss: 284.722 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2460/4776 | Loss: 290.738 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2470/4776 | Loss: 274.729 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2480/4776 | Loss: 282.052 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2490/4776 | Loss: 305.140 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2500/4776 | Loss: 304.774 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2510/4776 | Loss: 280.596 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2520/4776 | Loss: 296.918 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2530/4776 | Loss: 300.029 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2540/4776 | Loss: 309.186 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2550/4776 | Loss: 298.053 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2560/4776 | Loss: 283.137 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2570/4776 | Loss: 285.545 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2580/4776 | Loss: 301.197 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2590/4776 | Loss: 291.511 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2600/4776 | Loss: 292.262 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2610/4776 | Loss: 277.083 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2620/4776 | Loss: 290.446 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2630/4776 | Loss: 309.285 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2640/4776 | Loss: 280.368 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2650/4776 | Loss: 302.982 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2660/4776 | Loss: 292.516 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2670/4776 | Loss: 272.253 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2680/4776 | Loss: 291.404 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2690/4776 | Loss: 291.680 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2700/4776 | Loss: 307.072 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2710/4776 | Loss: 298.173 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2720/4776 | Loss: 305.653 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2730/4776 | Loss: 301.082 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2740/4776 | Loss: 286.750 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2750/4776 | Loss: 303.908 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2760/4776 | Loss: 282.837 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2770/4776 | Loss: 287.870 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2780/4776 | Loss: 302.505 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2790/4776 | Loss: 298.257 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2800/4776 | Loss: 298.005 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2810/4776 | Loss: 305.258 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2820/4776 | Loss: 308.372 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2830/4776 | Loss: 294.139 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2840/4776 | Loss: 300.123 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2850/4776 | Loss: 290.825 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2860/4776 | Loss: 272.843 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 2870/4776 | Loss: 293.368 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2880/4776 | Loss: 291.341 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2890/4776 | Loss: 289.801 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2900/4776 | Loss: 311.495 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2910/4776 | Loss: 259.471 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 2920/4776 | Loss: 306.613 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 2930/4776 | Loss: 298.102 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2940/4776 | Loss: 315.328 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2950/4776 | Loss: 265.142 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2960/4776 | Loss: 300.455 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 2970/4776 | Loss: 282.022 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 2980/4776 | Loss: 281.162 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 2990/4776 | Loss: 308.746 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3000/4776 | Loss: 304.933 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3010/4776 | Loss: 316.572 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3020/4776 | Loss: 312.213 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3030/4776 | Loss: 303.751 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3040/4776 | Loss: 299.947 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3050/4776 | Loss: 285.545 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3060/4776 | Loss: 304.785 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3070/4776 | Loss: 302.053 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3080/4776 | Loss: 305.275 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3090/4776 | Loss: 290.366 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3100/4776 | Loss: 277.637 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 3110/4776 | Loss: 288.774 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3120/4776 | Loss: 293.639 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3130/4776 | Loss: 287.306 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3140/4776 | Loss: 288.112 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3150/4776 | Loss: 301.662 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3160/4776 | Loss: 281.207 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3170/4776 | Loss: 293.056 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3180/4776 | Loss: 293.700 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3190/4776 | Loss: 290.793 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3200/4776 | Loss: 309.223 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3210/4776 | Loss: 312.796 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3220/4776 | Loss: 286.107 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3230/4776 | Loss: 283.484 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3240/4776 | Loss: 283.422 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3250/4776 | Loss: 292.954 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3260/4776 | Loss: 296.054 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3270/4776 | Loss: 300.242 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3280/4776 | Loss: 299.827 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3290/4776 | Loss: 310.983 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3300/4776 | Loss: 298.608 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3310/4776 | Loss: 282.451 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3320/4776 | Loss: 278.410 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3330/4776 | Loss: 306.473 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3340/4776 | Loss: 278.968 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3350/4776 | Loss: 282.963 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3360/4776 | Loss: 291.609 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3370/4776 | Loss: 299.107 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3380/4776 | Loss: 308.856 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3390/4776 | Loss: 292.161 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3400/4776 | Loss: 299.384 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3410/4776 | Loss: 306.142 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3420/4776 | Loss: 316.965 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3430/4776 | Loss: 291.484 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3440/4776 | Loss: 301.738 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3450/4776 | Loss: 273.717 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 3460/4776 | Loss: 312.996 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3470/4776 | Loss: 321.347 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3480/4776 | Loss: 284.826 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3490/4776 | Loss: 310.042 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3500/4776 | Loss: 293.527 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3510/4776 | Loss: 306.551 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3520/4776 | Loss: 298.488 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3530/4776 | Loss: 302.240 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3540/4776 | Loss: 311.259 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3550/4776 | Loss: 301.181 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3560/4776 | Loss: 329.522 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3570/4776 | Loss: 307.277 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3580/4776 | Loss: 295.326 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3590/4776 | Loss: 286.515 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3600/4776 | Loss: 302.141 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3610/4776 | Loss: 301.348 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3620/4776 | Loss: 295.211 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3630/4776 | Loss: 299.656 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3640/4776 | Loss: 295.846 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3650/4776 | Loss: 300.501 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3660/4776 | Loss: 294.160 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3670/4776 | Loss: 297.468 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3680/4776 | Loss: 278.391 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 3690/4776 | Loss: 292.103 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 3700/4776 | Loss: 287.688 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 3710/4776 | Loss: 286.440 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3720/4776 | Loss: 294.781 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3730/4776 | Loss: 344.053 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3740/4776 | Loss: 292.242 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3750/4776 | Loss: 294.648 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3760/4776 | Loss: 303.735 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3770/4776 | Loss: 305.805 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3780/4776 | Loss: 302.618 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3790/4776 | Loss: 278.375 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 3800/4776 | Loss: 304.838 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3810/4776 | Loss: 297.210 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3820/4776 | Loss: 307.795 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3830/4776 | Loss: 295.613 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3840/4776 | Loss: 305.743 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3850/4776 | Loss: 285.957 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3860/4776 | Loss: 294.654 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3870/4776 | Loss: 296.228 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3880/4776 | Loss: 307.026 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3890/4776 | Loss: 269.025 | Accuracy: 0.500\n",
      "[Epoch: 9/200] - Step: 3900/4776 | Loss: 288.131 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3910/4776 | Loss: 300.144 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3920/4776 | Loss: 290.894 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3930/4776 | Loss: 297.670 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3940/4776 | Loss: 288.566 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 3950/4776 | Loss: 297.719 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3960/4776 | Loss: 304.497 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 3970/4776 | Loss: 299.583 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 3980/4776 | Loss: 273.340 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 3990/4776 | Loss: 265.279 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4000/4776 | Loss: 308.553 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4010/4776 | Loss: 279.820 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 4020/4776 | Loss: 320.536 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4030/4776 | Loss: 299.356 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4040/4776 | Loss: 299.461 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4050/4776 | Loss: 315.001 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4060/4776 | Loss: 310.363 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4070/4776 | Loss: 299.247 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4080/4776 | Loss: 288.135 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4090/4776 | Loss: 304.751 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4100/4776 | Loss: 296.662 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4110/4776 | Loss: 293.284 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4120/4776 | Loss: 304.134 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4130/4776 | Loss: 304.634 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4140/4776 | Loss: 303.252 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4150/4776 | Loss: 298.561 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4160/4776 | Loss: 295.137 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4170/4776 | Loss: 308.956 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4180/4776 | Loss: 283.796 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4190/4776 | Loss: 287.044 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4200/4776 | Loss: 293.174 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4210/4776 | Loss: 302.636 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4220/4776 | Loss: 285.002 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4230/4776 | Loss: 306.156 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4240/4776 | Loss: 286.989 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4250/4776 | Loss: 311.333 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4260/4776 | Loss: 274.953 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4270/4776 | Loss: 320.757 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4280/4776 | Loss: 292.089 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4290/4776 | Loss: 331.535 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4300/4776 | Loss: 302.119 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4310/4776 | Loss: 279.006 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4320/4776 | Loss: 285.992 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4330/4776 | Loss: 298.794 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4340/4776 | Loss: 342.858 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4350/4776 | Loss: 292.261 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4360/4776 | Loss: 288.449 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4370/4776 | Loss: 300.595 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4380/4776 | Loss: 293.766 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4390/4776 | Loss: 288.521 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4400/4776 | Loss: 330.151 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4410/4776 | Loss: 294.029 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4420/4776 | Loss: 300.074 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4430/4776 | Loss: 296.688 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4440/4776 | Loss: 289.459 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4450/4776 | Loss: 299.049 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4460/4776 | Loss: 291.955 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4470/4776 | Loss: 307.406 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4480/4776 | Loss: 301.936 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4490/4776 | Loss: 305.715 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4500/4776 | Loss: 282.796 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4510/4776 | Loss: 276.881 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4520/4776 | Loss: 298.804 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4530/4776 | Loss: 293.198 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4540/4776 | Loss: 281.546 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4550/4776 | Loss: 295.769 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4560/4776 | Loss: 317.178 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4570/4776 | Loss: 281.468 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4580/4776 | Loss: 267.519 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 4590/4776 | Loss: 287.339 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4600/4776 | Loss: 278.475 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4610/4776 | Loss: 291.767 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4620/4776 | Loss: 302.727 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4630/4776 | Loss: 315.165 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4640/4776 | Loss: 291.713 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4650/4776 | Loss: 300.393 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4660/4776 | Loss: 281.437 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 4670/4776 | Loss: 307.783 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4680/4776 | Loss: 293.613 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4690/4776 | Loss: 309.860 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4700/4776 | Loss: 312.946 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4710/4776 | Loss: 283.279 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4720/4776 | Loss: 335.269 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4730/4776 | Loss: 306.652 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 4740/4776 | Loss: 292.929 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4750/4776 | Loss: 300.075 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 4760/4776 | Loss: 301.091 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 4770/4776 | Loss: 297.289 | Accuracy: 0.100\n",
      "Accuracy:  0.10819672131147541\n",
      "[Epoch: 10/200] - Step: 10/4776 | Loss: 300.922 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 20/4776 | Loss: 304.628 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 30/4776 | Loss: 307.705 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 40/4776 | Loss: 295.430 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 50/4776 | Loss: 306.850 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 60/4776 | Loss: 288.988 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 70/4776 | Loss: 295.564 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 80/4776 | Loss: 322.615 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 90/4776 | Loss: 289.909 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 100/4776 | Loss: 295.225 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 110/4776 | Loss: 304.964 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 120/4776 | Loss: 297.838 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 130/4776 | Loss: 306.225 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 140/4776 | Loss: 284.299 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 150/4776 | Loss: 297.133 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 160/4776 | Loss: 316.657 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 170/4776 | Loss: 299.901 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 180/4776 | Loss: 289.365 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 190/4776 | Loss: 300.789 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 200/4776 | Loss: 281.476 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 210/4776 | Loss: 312.954 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 220/4776 | Loss: 285.444 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 230/4776 | Loss: 286.206 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 240/4776 | Loss: 289.308 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 250/4776 | Loss: 281.287 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 260/4776 | Loss: 293.677 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 270/4776 | Loss: 285.984 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 280/4776 | Loss: 274.759 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 290/4776 | Loss: 308.865 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 300/4776 | Loss: 295.372 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 310/4776 | Loss: 291.884 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 320/4776 | Loss: 282.665 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 330/4776 | Loss: 257.802 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 340/4776 | Loss: 300.855 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 350/4776 | Loss: 307.564 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 360/4776 | Loss: 277.025 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 370/4776 | Loss: 290.695 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 380/4776 | Loss: 300.481 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 390/4776 | Loss: 284.469 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 400/4776 | Loss: 293.976 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 410/4776 | Loss: 295.248 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 420/4776 | Loss: 306.541 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 430/4776 | Loss: 303.879 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 440/4776 | Loss: 303.217 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 450/4776 | Loss: 302.660 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 460/4776 | Loss: 298.777 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 470/4776 | Loss: 294.619 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 480/4776 | Loss: 284.065 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 490/4776 | Loss: 302.458 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 500/4776 | Loss: 301.564 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 510/4776 | Loss: 304.089 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 520/4776 | Loss: 296.339 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 530/4776 | Loss: 297.353 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 540/4776 | Loss: 297.173 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 550/4776 | Loss: 285.982 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 560/4776 | Loss: 297.963 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 570/4776 | Loss: 305.777 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 580/4776 | Loss: 299.765 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 590/4776 | Loss: 295.300 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 600/4776 | Loss: 272.077 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 610/4776 | Loss: 308.930 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 620/4776 | Loss: 285.219 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 630/4776 | Loss: 306.450 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 640/4776 | Loss: 302.805 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 650/4776 | Loss: 284.645 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 660/4776 | Loss: 300.042 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 670/4776 | Loss: 295.724 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 680/4776 | Loss: 273.997 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 690/4776 | Loss: 294.662 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 700/4776 | Loss: 311.561 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 710/4776 | Loss: 286.771 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 720/4776 | Loss: 307.450 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 730/4776 | Loss: 304.820 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 740/4776 | Loss: 285.396 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 750/4776 | Loss: 299.283 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 760/4776 | Loss: 286.523 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 770/4776 | Loss: 304.194 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 780/4776 | Loss: 299.134 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 790/4776 | Loss: 284.752 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 800/4776 | Loss: 285.484 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 810/4776 | Loss: 273.343 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 820/4776 | Loss: 270.437 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 830/4776 | Loss: 303.443 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 840/4776 | Loss: 301.104 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 850/4776 | Loss: 280.822 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 860/4776 | Loss: 282.780 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 870/4776 | Loss: 305.109 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 880/4776 | Loss: 283.687 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 890/4776 | Loss: 292.221 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 900/4776 | Loss: 319.066 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 910/4776 | Loss: 317.080 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 920/4776 | Loss: 291.911 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 930/4776 | Loss: 305.473 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 940/4776 | Loss: 292.605 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 950/4776 | Loss: 282.585 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 960/4776 | Loss: 273.940 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 970/4776 | Loss: 285.585 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 980/4776 | Loss: 292.270 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 990/4776 | Loss: 284.030 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1000/4776 | Loss: 296.364 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1010/4776 | Loss: 296.622 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1020/4776 | Loss: 281.173 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1030/4776 | Loss: 298.214 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1040/4776 | Loss: 310.813 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1050/4776 | Loss: 335.904 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1060/4776 | Loss: 314.218 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1070/4776 | Loss: 295.199 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1080/4776 | Loss: 286.068 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1090/4776 | Loss: 266.224 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 1100/4776 | Loss: 275.289 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1110/4776 | Loss: 338.872 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1120/4776 | Loss: 304.461 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1130/4776 | Loss: 300.809 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1140/4776 | Loss: 289.537 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1150/4776 | Loss: 313.795 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1160/4776 | Loss: 282.622 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1170/4776 | Loss: 312.329 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1180/4776 | Loss: 290.803 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1190/4776 | Loss: 287.942 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1200/4776 | Loss: 292.458 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1210/4776 | Loss: 307.837 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1220/4776 | Loss: 313.043 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1230/4776 | Loss: 290.144 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1240/4776 | Loss: 294.460 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1250/4776 | Loss: 297.731 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1260/4776 | Loss: 298.210 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1270/4776 | Loss: 331.341 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1280/4776 | Loss: 292.998 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1290/4776 | Loss: 297.625 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1300/4776 | Loss: 293.588 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1310/4776 | Loss: 300.689 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1320/4776 | Loss: 284.753 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1330/4776 | Loss: 306.407 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1340/4776 | Loss: 318.842 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1350/4776 | Loss: 292.746 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1360/4776 | Loss: 304.169 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1370/4776 | Loss: 298.066 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1380/4776 | Loss: 296.012 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1390/4776 | Loss: 285.425 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1400/4776 | Loss: 274.293 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 1410/4776 | Loss: 306.206 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1420/4776 | Loss: 260.477 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1430/4776 | Loss: 286.530 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1440/4776 | Loss: 282.141 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1450/4776 | Loss: 355.648 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1460/4776 | Loss: 294.392 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1470/4776 | Loss: 287.855 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1480/4776 | Loss: 311.544 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1490/4776 | Loss: 314.939 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1500/4776 | Loss: 293.081 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1510/4776 | Loss: 315.370 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1520/4776 | Loss: 293.259 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1530/4776 | Loss: 309.275 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1540/4776 | Loss: 297.467 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1550/4776 | Loss: 290.109 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1560/4776 | Loss: 287.417 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1570/4776 | Loss: 302.154 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1580/4776 | Loss: 313.874 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1590/4776 | Loss: 292.853 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1600/4776 | Loss: 301.420 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1610/4776 | Loss: 307.607 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1620/4776 | Loss: 289.807 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1630/4776 | Loss: 306.838 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1640/4776 | Loss: 284.129 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1650/4776 | Loss: 328.933 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1660/4776 | Loss: 294.388 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1670/4776 | Loss: 304.629 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1680/4776 | Loss: 302.655 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1690/4776 | Loss: 300.215 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1700/4776 | Loss: 295.208 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1710/4776 | Loss: 298.982 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1720/4776 | Loss: 275.729 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1730/4776 | Loss: 299.955 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1740/4776 | Loss: 280.654 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1750/4776 | Loss: 303.130 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1760/4776 | Loss: 294.938 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1770/4776 | Loss: 330.599 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1780/4776 | Loss: 283.670 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1790/4776 | Loss: 300.995 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1800/4776 | Loss: 285.157 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1810/4776 | Loss: 295.786 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1820/4776 | Loss: 293.134 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1830/4776 | Loss: 291.344 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1840/4776 | Loss: 300.333 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1850/4776 | Loss: 303.039 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1860/4776 | Loss: 286.454 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1870/4776 | Loss: 285.638 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1880/4776 | Loss: 279.288 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 1890/4776 | Loss: 303.820 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1900/4776 | Loss: 315.444 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1910/4776 | Loss: 315.648 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1920/4776 | Loss: 312.225 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1930/4776 | Loss: 307.398 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1940/4776 | Loss: 302.857 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1950/4776 | Loss: 289.453 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1960/4776 | Loss: 290.324 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1970/4776 | Loss: 308.502 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1980/4776 | Loss: 306.049 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1990/4776 | Loss: 296.496 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2000/4776 | Loss: 297.788 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2010/4776 | Loss: 269.773 | Accuracy: 0.500\n",
      "[Epoch: 10/200] - Step: 2020/4776 | Loss: 307.775 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2030/4776 | Loss: 297.368 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2040/4776 | Loss: 302.620 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2050/4776 | Loss: 284.725 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2060/4776 | Loss: 297.196 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2070/4776 | Loss: 296.404 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2080/4776 | Loss: 291.195 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2090/4776 | Loss: 300.183 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2100/4776 | Loss: 297.832 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2110/4776 | Loss: 294.527 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2120/4776 | Loss: 282.347 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2130/4776 | Loss: 299.530 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2140/4776 | Loss: 313.080 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2150/4776 | Loss: 306.203 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2160/4776 | Loss: 284.513 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2170/4776 | Loss: 306.829 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2180/4776 | Loss: 275.152 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2190/4776 | Loss: 289.013 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2200/4776 | Loss: 321.469 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2210/4776 | Loss: 309.748 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2220/4776 | Loss: 274.468 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2230/4776 | Loss: 294.042 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2240/4776 | Loss: 298.589 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2250/4776 | Loss: 311.340 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2260/4776 | Loss: 312.471 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2270/4776 | Loss: 282.323 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2280/4776 | Loss: 314.212 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2290/4776 | Loss: 303.709 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2300/4776 | Loss: 285.100 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2310/4776 | Loss: 290.388 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2320/4776 | Loss: 302.028 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2330/4776 | Loss: 283.298 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2340/4776 | Loss: 289.844 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2350/4776 | Loss: 285.253 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2360/4776 | Loss: 295.086 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2370/4776 | Loss: 301.234 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2380/4776 | Loss: 281.849 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2390/4776 | Loss: 280.269 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2400/4776 | Loss: 275.717 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2410/4776 | Loss: 289.250 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2420/4776 | Loss: 287.505 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2430/4776 | Loss: 308.481 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2440/4776 | Loss: 294.503 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2450/4776 | Loss: 298.666 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2460/4776 | Loss: 317.517 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2470/4776 | Loss: 289.955 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2480/4776 | Loss: 298.413 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2490/4776 | Loss: 289.475 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2500/4776 | Loss: 313.478 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2510/4776 | Loss: 284.778 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2520/4776 | Loss: 303.959 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2530/4776 | Loss: 270.523 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2540/4776 | Loss: 294.286 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2550/4776 | Loss: 296.195 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2560/4776 | Loss: 286.878 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2570/4776 | Loss: 275.133 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2580/4776 | Loss: 290.578 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2590/4776 | Loss: 315.708 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2600/4776 | Loss: 295.531 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2610/4776 | Loss: 275.208 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2620/4776 | Loss: 279.026 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2630/4776 | Loss: 275.435 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2640/4776 | Loss: 287.144 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2650/4776 | Loss: 310.819 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2660/4776 | Loss: 272.239 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2670/4776 | Loss: 277.496 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2680/4776 | Loss: 298.556 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2690/4776 | Loss: 308.894 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2700/4776 | Loss: 308.082 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2710/4776 | Loss: 299.217 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2720/4776 | Loss: 300.382 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2730/4776 | Loss: 319.645 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2740/4776 | Loss: 307.527 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2750/4776 | Loss: 310.405 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2760/4776 | Loss: 298.097 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2770/4776 | Loss: 290.807 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2780/4776 | Loss: 292.432 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2790/4776 | Loss: 304.224 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2800/4776 | Loss: 303.986 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2810/4776 | Loss: 298.548 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2820/4776 | Loss: 296.559 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2830/4776 | Loss: 294.532 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2840/4776 | Loss: 303.252 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2850/4776 | Loss: 299.861 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2860/4776 | Loss: 283.284 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2870/4776 | Loss: 280.084 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2880/4776 | Loss: 303.693 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2890/4776 | Loss: 293.844 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2900/4776 | Loss: 267.628 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 2910/4776 | Loss: 295.612 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2920/4776 | Loss: 290.772 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2930/4776 | Loss: 298.404 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2940/4776 | Loss: 299.137 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 2950/4776 | Loss: 294.250 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2960/4776 | Loss: 292.590 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2970/4776 | Loss: 293.621 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 2980/4776 | Loss: 297.810 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 2990/4776 | Loss: 307.566 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3000/4776 | Loss: 296.308 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3010/4776 | Loss: 296.233 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3020/4776 | Loss: 285.527 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3030/4776 | Loss: 294.318 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3040/4776 | Loss: 295.912 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3050/4776 | Loss: 281.565 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3060/4776 | Loss: 299.081 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3070/4776 | Loss: 303.416 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3080/4776 | Loss: 285.310 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3090/4776 | Loss: 279.300 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3100/4776 | Loss: 274.034 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3110/4776 | Loss: 286.720 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3120/4776 | Loss: 293.676 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3130/4776 | Loss: 308.219 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3140/4776 | Loss: 300.649 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3150/4776 | Loss: 303.641 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3160/4776 | Loss: 315.807 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3170/4776 | Loss: 303.331 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3180/4776 | Loss: 304.421 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3190/4776 | Loss: 302.821 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3200/4776 | Loss: 298.460 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3210/4776 | Loss: 269.042 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 3220/4776 | Loss: 291.088 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3230/4776 | Loss: 289.638 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3240/4776 | Loss: 293.079 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3250/4776 | Loss: 292.959 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3260/4776 | Loss: 293.857 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3270/4776 | Loss: 293.846 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3280/4776 | Loss: 298.906 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3290/4776 | Loss: 294.895 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3300/4776 | Loss: 295.676 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3310/4776 | Loss: 275.083 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3320/4776 | Loss: 302.330 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3330/4776 | Loss: 288.328 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3340/4776 | Loss: 289.030 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3350/4776 | Loss: 309.727 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3360/4776 | Loss: 287.265 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3370/4776 | Loss: 300.873 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3380/4776 | Loss: 278.239 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3390/4776 | Loss: 286.518 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3400/4776 | Loss: 279.866 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3410/4776 | Loss: 318.483 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3420/4776 | Loss: 307.408 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3430/4776 | Loss: 312.337 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3440/4776 | Loss: 301.532 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3450/4776 | Loss: 297.218 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3460/4776 | Loss: 289.374 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3470/4776 | Loss: 285.233 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3480/4776 | Loss: 301.224 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3490/4776 | Loss: 300.609 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3500/4776 | Loss: 304.549 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3510/4776 | Loss: 285.639 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3520/4776 | Loss: 318.004 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3530/4776 | Loss: 294.569 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3540/4776 | Loss: 291.519 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3550/4776 | Loss: 288.811 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3560/4776 | Loss: 306.824 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3570/4776 | Loss: 298.245 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3580/4776 | Loss: 283.734 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3590/4776 | Loss: 303.194 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3600/4776 | Loss: 278.113 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3610/4776 | Loss: 285.560 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3620/4776 | Loss: 301.994 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3630/4776 | Loss: 307.694 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3640/4776 | Loss: 296.383 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3650/4776 | Loss: 304.113 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3660/4776 | Loss: 287.171 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3670/4776 | Loss: 295.586 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3680/4776 | Loss: 291.984 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3690/4776 | Loss: 313.489 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3700/4776 | Loss: 317.706 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3710/4776 | Loss: 296.160 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3720/4776 | Loss: 280.045 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3730/4776 | Loss: 307.206 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3740/4776 | Loss: 299.486 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3750/4776 | Loss: 284.328 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3760/4776 | Loss: 297.829 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3770/4776 | Loss: 286.106 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3780/4776 | Loss: 338.967 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3790/4776 | Loss: 284.943 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3800/4776 | Loss: 312.413 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3810/4776 | Loss: 284.868 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3820/4776 | Loss: 300.160 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3830/4776 | Loss: 299.583 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3840/4776 | Loss: 295.196 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3850/4776 | Loss: 291.016 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3860/4776 | Loss: 303.382 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3870/4776 | Loss: 309.654 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3880/4776 | Loss: 300.691 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3890/4776 | Loss: 300.479 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3900/4776 | Loss: 302.280 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3910/4776 | Loss: 275.829 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3920/4776 | Loss: 297.067 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3930/4776 | Loss: 287.097 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3940/4776 | Loss: 302.996 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 3950/4776 | Loss: 283.392 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 3960/4776 | Loss: 307.129 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3970/4776 | Loss: 289.534 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 3980/4776 | Loss: 286.391 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 3990/4776 | Loss: 267.736 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 4000/4776 | Loss: 297.699 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4010/4776 | Loss: 306.238 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4020/4776 | Loss: 288.334 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4030/4776 | Loss: 279.939 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4040/4776 | Loss: 310.266 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4050/4776 | Loss: 273.280 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4060/4776 | Loss: 304.334 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4070/4776 | Loss: 309.993 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4080/4776 | Loss: 302.637 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4090/4776 | Loss: 292.064 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4100/4776 | Loss: 294.753 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4110/4776 | Loss: 304.560 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4120/4776 | Loss: 282.760 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4130/4776 | Loss: 286.010 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4140/4776 | Loss: 284.647 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4150/4776 | Loss: 286.474 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4160/4776 | Loss: 252.597 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 4170/4776 | Loss: 279.340 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4180/4776 | Loss: 288.522 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4190/4776 | Loss: 302.179 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4200/4776 | Loss: 306.835 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4210/4776 | Loss: 299.768 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4220/4776 | Loss: 295.194 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4230/4776 | Loss: 293.188 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4240/4776 | Loss: 316.802 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4250/4776 | Loss: 294.960 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4260/4776 | Loss: 291.661 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4270/4776 | Loss: 317.354 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4280/4776 | Loss: 300.152 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4290/4776 | Loss: 302.689 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4300/4776 | Loss: 299.225 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4310/4776 | Loss: 296.081 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4320/4776 | Loss: 304.116 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4330/4776 | Loss: 295.015 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4340/4776 | Loss: 295.315 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4350/4776 | Loss: 302.875 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4360/4776 | Loss: 301.691 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4370/4776 | Loss: 298.307 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4380/4776 | Loss: 308.959 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4390/4776 | Loss: 283.717 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4400/4776 | Loss: 294.606 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4410/4776 | Loss: 287.440 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4420/4776 | Loss: 295.861 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4430/4776 | Loss: 294.372 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4440/4776 | Loss: 292.422 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4450/4776 | Loss: 274.553 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 4460/4776 | Loss: 299.548 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4470/4776 | Loss: 302.578 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4480/4776 | Loss: 280.583 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4490/4776 | Loss: 291.695 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4500/4776 | Loss: 294.882 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4510/4776 | Loss: 306.877 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4520/4776 | Loss: 275.981 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4530/4776 | Loss: 308.440 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4540/4776 | Loss: 300.043 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4550/4776 | Loss: 294.167 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4560/4776 | Loss: 299.470 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4570/4776 | Loss: 290.175 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4580/4776 | Loss: 269.571 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4590/4776 | Loss: 296.151 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4600/4776 | Loss: 285.236 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4610/4776 | Loss: 262.151 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4620/4776 | Loss: 316.870 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4630/4776 | Loss: 292.026 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4640/4776 | Loss: 277.813 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4650/4776 | Loss: 304.779 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4660/4776 | Loss: 308.268 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4670/4776 | Loss: 258.438 | Accuracy: 0.500\n",
      "[Epoch: 10/200] - Step: 4680/4776 | Loss: 267.406 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 4690/4776 | Loss: 298.719 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4700/4776 | Loss: 330.550 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4710/4776 | Loss: 299.145 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 4720/4776 | Loss: 301.099 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4730/4776 | Loss: 287.771 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 4740/4776 | Loss: 309.103 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4750/4776 | Loss: 284.262 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4760/4776 | Loss: 298.609 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 4770/4776 | Loss: 306.125 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 11/200] - Step: 10/4776 | Loss: 300.238 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 20/4776 | Loss: 297.041 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 30/4776 | Loss: 289.270 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 40/4776 | Loss: 298.417 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 50/4776 | Loss: 294.705 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 60/4776 | Loss: 306.196 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 70/4776 | Loss: 289.279 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 80/4776 | Loss: 311.214 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 90/4776 | Loss: 285.035 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 100/4776 | Loss: 306.946 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 110/4776 | Loss: 299.864 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 120/4776 | Loss: 290.201 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 130/4776 | Loss: 286.712 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 140/4776 | Loss: 294.619 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 150/4776 | Loss: 295.480 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 160/4776 | Loss: 312.104 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 170/4776 | Loss: 308.637 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 180/4776 | Loss: 295.023 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 190/4776 | Loss: 294.776 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 200/4776 | Loss: 306.755 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 210/4776 | Loss: 308.190 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 220/4776 | Loss: 278.587 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 230/4776 | Loss: 310.862 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 240/4776 | Loss: 295.210 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 250/4776 | Loss: 309.658 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 260/4776 | Loss: 298.091 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 270/4776 | Loss: 298.797 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 280/4776 | Loss: 302.008 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 290/4776 | Loss: 313.748 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 300/4776 | Loss: 301.090 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 310/4776 | Loss: 310.515 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 320/4776 | Loss: 326.161 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 330/4776 | Loss: 295.246 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 340/4776 | Loss: 297.896 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 350/4776 | Loss: 300.407 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 360/4776 | Loss: 298.069 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 370/4776 | Loss: 296.680 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 380/4776 | Loss: 303.134 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 390/4776 | Loss: 299.491 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 400/4776 | Loss: 294.661 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 410/4776 | Loss: 292.978 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 420/4776 | Loss: 278.844 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 430/4776 | Loss: 299.907 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 440/4776 | Loss: 291.201 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 450/4776 | Loss: 321.899 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 460/4776 | Loss: 303.564 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 470/4776 | Loss: 283.917 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 480/4776 | Loss: 298.350 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 490/4776 | Loss: 287.867 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 500/4776 | Loss: 303.501 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 510/4776 | Loss: 299.946 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 520/4776 | Loss: 288.058 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 530/4776 | Loss: 304.941 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 540/4776 | Loss: 288.975 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 550/4776 | Loss: 299.710 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 560/4776 | Loss: 303.511 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 570/4776 | Loss: 303.361 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 580/4776 | Loss: 305.512 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 590/4776 | Loss: 275.890 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 600/4776 | Loss: 308.341 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 610/4776 | Loss: 300.527 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 620/4776 | Loss: 287.725 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 630/4776 | Loss: 298.564 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 640/4776 | Loss: 287.324 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 650/4776 | Loss: 283.177 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 660/4776 | Loss: 295.511 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 670/4776 | Loss: 296.764 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 680/4776 | Loss: 305.167 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 690/4776 | Loss: 284.038 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 700/4776 | Loss: 295.123 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 710/4776 | Loss: 303.560 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 720/4776 | Loss: 320.737 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 730/4776 | Loss: 294.243 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 740/4776 | Loss: 296.644 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 750/4776 | Loss: 293.921 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 760/4776 | Loss: 304.333 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 770/4776 | Loss: 291.409 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 780/4776 | Loss: 281.323 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 790/4776 | Loss: 286.218 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 800/4776 | Loss: 287.918 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 810/4776 | Loss: 292.011 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 820/4776 | Loss: 307.464 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 830/4776 | Loss: 280.660 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 840/4776 | Loss: 299.626 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 850/4776 | Loss: 298.782 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 860/4776 | Loss: 298.210 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 870/4776 | Loss: 305.775 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 880/4776 | Loss: 297.693 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 890/4776 | Loss: 298.700 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 900/4776 | Loss: 309.454 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 910/4776 | Loss: 302.172 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 920/4776 | Loss: 290.828 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 930/4776 | Loss: 314.638 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 940/4776 | Loss: 292.493 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 950/4776 | Loss: 306.639 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 960/4776 | Loss: 310.965 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 970/4776 | Loss: 297.964 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 980/4776 | Loss: 306.144 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 990/4776 | Loss: 325.725 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1000/4776 | Loss: 290.498 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1010/4776 | Loss: 288.309 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1020/4776 | Loss: 296.551 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1030/4776 | Loss: 284.071 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1040/4776 | Loss: 299.575 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1050/4776 | Loss: 293.868 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1060/4776 | Loss: 297.319 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1070/4776 | Loss: 300.570 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1080/4776 | Loss: 291.320 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1090/4776 | Loss: 289.740 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1100/4776 | Loss: 285.128 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 1110/4776 | Loss: 299.003 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1120/4776 | Loss: 290.742 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1130/4776 | Loss: 282.113 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1140/4776 | Loss: 289.893 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1150/4776 | Loss: 290.745 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1160/4776 | Loss: 321.389 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1170/4776 | Loss: 290.312 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1180/4776 | Loss: 302.760 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1190/4776 | Loss: 305.126 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1200/4776 | Loss: 312.164 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1210/4776 | Loss: 291.298 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1220/4776 | Loss: 332.845 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1230/4776 | Loss: 289.399 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1240/4776 | Loss: 294.512 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1250/4776 | Loss: 270.808 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 1260/4776 | Loss: 282.646 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1270/4776 | Loss: 288.559 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1280/4776 | Loss: 284.643 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1290/4776 | Loss: 313.019 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1300/4776 | Loss: 300.494 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1310/4776 | Loss: 271.679 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1320/4776 | Loss: 303.255 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1330/4776 | Loss: 284.757 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1340/4776 | Loss: 276.012 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1350/4776 | Loss: 287.202 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1360/4776 | Loss: 299.476 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1370/4776 | Loss: 312.546 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1380/4776 | Loss: 299.102 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1390/4776 | Loss: 296.258 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1400/4776 | Loss: 288.479 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1410/4776 | Loss: 306.736 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1420/4776 | Loss: 315.093 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1430/4776 | Loss: 286.899 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1440/4776 | Loss: 274.547 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1450/4776 | Loss: 286.346 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1460/4776 | Loss: 281.224 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1470/4776 | Loss: 296.980 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1480/4776 | Loss: 314.275 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1490/4776 | Loss: 318.578 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1500/4776 | Loss: 303.560 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1510/4776 | Loss: 288.559 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1520/4776 | Loss: 304.698 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1530/4776 | Loss: 304.207 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1540/4776 | Loss: 291.962 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1550/4776 | Loss: 300.060 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1560/4776 | Loss: 296.461 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1570/4776 | Loss: 282.477 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1580/4776 | Loss: 305.242 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1590/4776 | Loss: 280.069 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1600/4776 | Loss: 306.717 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1610/4776 | Loss: 287.904 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1620/4776 | Loss: 293.984 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1630/4776 | Loss: 304.201 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1640/4776 | Loss: 280.384 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1650/4776 | Loss: 297.033 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1660/4776 | Loss: 311.087 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1670/4776 | Loss: 291.161 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1680/4776 | Loss: 303.070 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1690/4776 | Loss: 314.577 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1700/4776 | Loss: 311.298 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1710/4776 | Loss: 290.966 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1720/4776 | Loss: 313.207 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1730/4776 | Loss: 322.882 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1740/4776 | Loss: 305.884 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1750/4776 | Loss: 308.119 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1760/4776 | Loss: 299.818 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1770/4776 | Loss: 298.149 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1780/4776 | Loss: 296.126 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1790/4776 | Loss: 285.746 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1800/4776 | Loss: 294.065 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1810/4776 | Loss: 297.947 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1820/4776 | Loss: 303.301 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1830/4776 | Loss: 292.112 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1840/4776 | Loss: 289.736 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1850/4776 | Loss: 287.488 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1860/4776 | Loss: 276.830 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1870/4776 | Loss: 299.309 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1880/4776 | Loss: 282.738 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1890/4776 | Loss: 291.481 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1900/4776 | Loss: 315.465 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1910/4776 | Loss: 289.979 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1920/4776 | Loss: 304.552 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1930/4776 | Loss: 304.201 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1940/4776 | Loss: 284.318 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 1950/4776 | Loss: 309.388 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1960/4776 | Loss: 284.114 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1970/4776 | Loss: 296.710 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1980/4776 | Loss: 294.258 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1990/4776 | Loss: 296.500 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2000/4776 | Loss: 304.824 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2010/4776 | Loss: 276.917 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2020/4776 | Loss: 285.235 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2030/4776 | Loss: 312.009 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2040/4776 | Loss: 302.206 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2050/4776 | Loss: 283.427 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2060/4776 | Loss: 298.908 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2070/4776 | Loss: 310.105 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2080/4776 | Loss: 277.879 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2090/4776 | Loss: 284.121 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2100/4776 | Loss: 309.249 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2110/4776 | Loss: 317.291 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2120/4776 | Loss: 304.923 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2130/4776 | Loss: 315.740 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2140/4776 | Loss: 306.974 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2150/4776 | Loss: 300.446 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2160/4776 | Loss: 286.982 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2170/4776 | Loss: 285.389 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2180/4776 | Loss: 295.307 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2190/4776 | Loss: 299.148 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2200/4776 | Loss: 274.452 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2210/4776 | Loss: 307.347 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2220/4776 | Loss: 288.784 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2230/4776 | Loss: 282.408 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2240/4776 | Loss: 306.519 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2250/4776 | Loss: 300.726 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2260/4776 | Loss: 274.557 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2270/4776 | Loss: 302.970 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2280/4776 | Loss: 298.127 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2290/4776 | Loss: 293.924 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2300/4776 | Loss: 272.214 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2310/4776 | Loss: 276.953 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2320/4776 | Loss: 296.122 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2330/4776 | Loss: 311.996 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2340/4776 | Loss: 303.878 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2350/4776 | Loss: 289.420 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2360/4776 | Loss: 313.614 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2370/4776 | Loss: 286.668 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2380/4776 | Loss: 279.223 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2390/4776 | Loss: 283.735 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2400/4776 | Loss: 278.424 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2410/4776 | Loss: 308.606 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2420/4776 | Loss: 301.130 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2430/4776 | Loss: 300.521 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2440/4776 | Loss: 306.536 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2450/4776 | Loss: 306.607 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2460/4776 | Loss: 301.145 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2470/4776 | Loss: 293.508 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2480/4776 | Loss: 273.824 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2490/4776 | Loss: 299.952 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2500/4776 | Loss: 294.648 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2510/4776 | Loss: 286.690 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2520/4776 | Loss: 317.928 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2530/4776 | Loss: 287.658 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2540/4776 | Loss: 299.895 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2550/4776 | Loss: 314.785 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2560/4776 | Loss: 295.956 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2570/4776 | Loss: 311.304 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2580/4776 | Loss: 308.214 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2590/4776 | Loss: 323.889 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2600/4776 | Loss: 318.835 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2610/4776 | Loss: 317.772 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2620/4776 | Loss: 282.201 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 2630/4776 | Loss: 298.033 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2640/4776 | Loss: 311.245 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2650/4776 | Loss: 294.825 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2660/4776 | Loss: 285.306 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2670/4776 | Loss: 300.122 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2680/4776 | Loss: 298.656 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2690/4776 | Loss: 291.398 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2700/4776 | Loss: 302.320 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2710/4776 | Loss: 293.090 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2720/4776 | Loss: 301.803 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2730/4776 | Loss: 290.559 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2740/4776 | Loss: 289.843 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2750/4776 | Loss: 297.975 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2760/4776 | Loss: 292.705 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2770/4776 | Loss: 296.469 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2780/4776 | Loss: 299.228 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2790/4776 | Loss: 297.555 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2800/4776 | Loss: 274.907 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2810/4776 | Loss: 281.062 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2820/4776 | Loss: 281.185 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2830/4776 | Loss: 303.312 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2840/4776 | Loss: 284.876 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2850/4776 | Loss: 295.545 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2860/4776 | Loss: 283.839 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2870/4776 | Loss: 302.683 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2880/4776 | Loss: 305.979 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2890/4776 | Loss: 300.994 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2900/4776 | Loss: 300.863 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2910/4776 | Loss: 305.658 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2920/4776 | Loss: 304.755 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2930/4776 | Loss: 307.488 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2940/4776 | Loss: 282.972 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 2950/4776 | Loss: 301.572 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 2960/4776 | Loss: 288.694 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2970/4776 | Loss: 306.330 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 2980/4776 | Loss: 298.379 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 2990/4776 | Loss: 291.056 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3000/4776 | Loss: 295.558 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3010/4776 | Loss: 278.637 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3020/4776 | Loss: 296.299 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3030/4776 | Loss: 285.158 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3040/4776 | Loss: 297.065 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3050/4776 | Loss: 295.027 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3060/4776 | Loss: 278.959 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3070/4776 | Loss: 293.479 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3080/4776 | Loss: 273.969 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3090/4776 | Loss: 305.234 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3100/4776 | Loss: 294.620 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3110/4776 | Loss: 316.849 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3120/4776 | Loss: 295.606 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3130/4776 | Loss: 300.052 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3140/4776 | Loss: 272.896 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 3150/4776 | Loss: 295.659 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3160/4776 | Loss: 304.627 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3170/4776 | Loss: 310.868 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3180/4776 | Loss: 311.016 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3190/4776 | Loss: 284.809 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3200/4776 | Loss: 285.549 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3210/4776 | Loss: 299.891 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3220/4776 | Loss: 297.794 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3230/4776 | Loss: 279.673 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3240/4776 | Loss: 301.732 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3250/4776 | Loss: 307.613 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3260/4776 | Loss: 306.330 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3270/4776 | Loss: 296.909 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3280/4776 | Loss: 280.025 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3290/4776 | Loss: 291.205 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3300/4776 | Loss: 282.210 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3310/4776 | Loss: 304.295 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3320/4776 | Loss: 271.274 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3330/4776 | Loss: 322.418 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3340/4776 | Loss: 284.645 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3350/4776 | Loss: 308.477 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3360/4776 | Loss: 279.888 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3370/4776 | Loss: 302.805 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3380/4776 | Loss: 288.229 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3390/4776 | Loss: 281.102 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3400/4776 | Loss: 326.215 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3410/4776 | Loss: 295.879 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3420/4776 | Loss: 291.518 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3430/4776 | Loss: 283.486 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3440/4776 | Loss: 287.096 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3450/4776 | Loss: 267.914 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3460/4776 | Loss: 313.458 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3470/4776 | Loss: 304.598 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3480/4776 | Loss: 309.536 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3490/4776 | Loss: 306.848 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3500/4776 | Loss: 310.353 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3510/4776 | Loss: 297.847 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3520/4776 | Loss: 291.191 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3530/4776 | Loss: 292.087 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3540/4776 | Loss: 292.072 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3550/4776 | Loss: 287.006 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3560/4776 | Loss: 292.720 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3570/4776 | Loss: 283.788 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3580/4776 | Loss: 303.501 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3590/4776 | Loss: 286.337 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3600/4776 | Loss: 302.987 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3610/4776 | Loss: 285.837 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3620/4776 | Loss: 289.129 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3630/4776 | Loss: 283.613 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3640/4776 | Loss: 293.710 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3650/4776 | Loss: 297.426 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3660/4776 | Loss: 247.850 | Accuracy: 0.500\n",
      "[Epoch: 11/200] - Step: 3670/4776 | Loss: 335.547 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3680/4776 | Loss: 281.755 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3690/4776 | Loss: 294.031 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3700/4776 | Loss: 280.626 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3710/4776 | Loss: 279.758 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3720/4776 | Loss: 284.066 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3730/4776 | Loss: 273.333 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3740/4776 | Loss: 254.343 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 3750/4776 | Loss: 296.748 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3760/4776 | Loss: 307.003 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3770/4776 | Loss: 291.665 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3780/4776 | Loss: 284.689 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3790/4776 | Loss: 331.417 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3800/4776 | Loss: 279.773 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3810/4776 | Loss: 284.952 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3820/4776 | Loss: 282.654 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3830/4776 | Loss: 282.387 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3840/4776 | Loss: 291.227 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 3850/4776 | Loss: 316.542 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3860/4776 | Loss: 306.879 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3870/4776 | Loss: 282.520 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3880/4776 | Loss: 320.075 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3890/4776 | Loss: 284.863 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3900/4776 | Loss: 306.060 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3910/4776 | Loss: 292.265 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3920/4776 | Loss: 292.914 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3930/4776 | Loss: 305.555 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3940/4776 | Loss: 300.414 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 3950/4776 | Loss: 301.248 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3960/4776 | Loss: 307.260 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 3970/4776 | Loss: 296.560 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3980/4776 | Loss: 284.161 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 3990/4776 | Loss: 283.961 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4000/4776 | Loss: 315.374 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4010/4776 | Loss: 272.016 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4020/4776 | Loss: 297.335 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4030/4776 | Loss: 279.490 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4040/4776 | Loss: 285.227 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4050/4776 | Loss: 307.005 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4060/4776 | Loss: 298.263 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4070/4776 | Loss: 306.611 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4080/4776 | Loss: 289.917 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4090/4776 | Loss: 296.139 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4100/4776 | Loss: 304.607 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4110/4776 | Loss: 296.393 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4120/4776 | Loss: 294.374 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4130/4776 | Loss: 300.141 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4140/4776 | Loss: 296.734 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4150/4776 | Loss: 304.550 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4160/4776 | Loss: 295.862 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4170/4776 | Loss: 281.608 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4180/4776 | Loss: 295.501 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4190/4776 | Loss: 306.182 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4200/4776 | Loss: 310.139 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4210/4776 | Loss: 302.134 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4220/4776 | Loss: 295.729 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4230/4776 | Loss: 274.100 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4240/4776 | Loss: 293.353 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4250/4776 | Loss: 280.513 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4260/4776 | Loss: 266.996 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4270/4776 | Loss: 300.215 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4280/4776 | Loss: 289.408 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4290/4776 | Loss: 289.846 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4300/4776 | Loss: 318.846 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4310/4776 | Loss: 300.621 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4320/4776 | Loss: 304.770 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4330/4776 | Loss: 295.807 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4340/4776 | Loss: 299.953 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4350/4776 | Loss: 290.319 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4360/4776 | Loss: 295.097 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4370/4776 | Loss: 316.226 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4380/4776 | Loss: 305.787 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4390/4776 | Loss: 284.104 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4400/4776 | Loss: 297.500 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4410/4776 | Loss: 293.165 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4420/4776 | Loss: 295.003 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4430/4776 | Loss: 290.972 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4440/4776 | Loss: 299.655 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4450/4776 | Loss: 290.914 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4460/4776 | Loss: 289.869 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4470/4776 | Loss: 298.797 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4480/4776 | Loss: 273.061 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4490/4776 | Loss: 305.322 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4500/4776 | Loss: 298.595 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4510/4776 | Loss: 291.513 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4520/4776 | Loss: 272.501 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 4530/4776 | Loss: 278.748 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4540/4776 | Loss: 311.664 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4550/4776 | Loss: 299.564 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4560/4776 | Loss: 289.901 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4570/4776 | Loss: 300.330 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4580/4776 | Loss: 292.155 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4590/4776 | Loss: 312.425 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4600/4776 | Loss: 286.561 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4610/4776 | Loss: 283.786 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4620/4776 | Loss: 286.318 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4630/4776 | Loss: 299.964 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4640/4776 | Loss: 287.576 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4650/4776 | Loss: 308.189 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4660/4776 | Loss: 302.519 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4670/4776 | Loss: 254.092 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 4680/4776 | Loss: 303.958 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4690/4776 | Loss: 311.083 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4700/4776 | Loss: 299.015 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4710/4776 | Loss: 304.245 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4720/4776 | Loss: 298.863 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4730/4776 | Loss: 290.509 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 4740/4776 | Loss: 299.784 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 4750/4776 | Loss: 295.370 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4760/4776 | Loss: 300.849 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 4770/4776 | Loss: 297.321 | Accuracy: 0.100\n",
      "Accuracy:  0.10983606557377049\n",
      "Model saved!\n",
      "[Epoch: 12/200] - Step: 10/4776 | Loss: 297.937 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 20/4776 | Loss: 282.140 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 30/4776 | Loss: 303.989 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 40/4776 | Loss: 299.819 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 50/4776 | Loss: 304.599 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 60/4776 | Loss: 290.203 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 70/4776 | Loss: 296.764 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 80/4776 | Loss: 287.046 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 90/4776 | Loss: 291.289 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 100/4776 | Loss: 307.842 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 110/4776 | Loss: 285.655 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 120/4776 | Loss: 342.599 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 130/4776 | Loss: 309.124 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 140/4776 | Loss: 296.547 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 150/4776 | Loss: 302.389 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 160/4776 | Loss: 308.582 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 170/4776 | Loss: 295.829 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 180/4776 | Loss: 283.765 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 190/4776 | Loss: 305.914 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 200/4776 | Loss: 309.552 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 210/4776 | Loss: 299.800 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 220/4776 | Loss: 308.590 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 230/4776 | Loss: 303.264 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 240/4776 | Loss: 302.589 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 250/4776 | Loss: 302.194 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 260/4776 | Loss: 292.148 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 270/4776 | Loss: 293.472 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 280/4776 | Loss: 294.515 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 290/4776 | Loss: 285.684 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 300/4776 | Loss: 300.413 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 310/4776 | Loss: 308.654 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 320/4776 | Loss: 304.157 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 330/4776 | Loss: 283.440 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 340/4776 | Loss: 301.477 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 350/4776 | Loss: 267.962 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 360/4776 | Loss: 290.645 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 370/4776 | Loss: 284.205 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 380/4776 | Loss: 315.226 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 390/4776 | Loss: 280.290 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 400/4776 | Loss: 306.702 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 410/4776 | Loss: 278.832 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 420/4776 | Loss: 297.325 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 430/4776 | Loss: 286.431 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 440/4776 | Loss: 320.000 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 450/4776 | Loss: 307.701 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 460/4776 | Loss: 283.114 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 470/4776 | Loss: 279.468 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 480/4776 | Loss: 298.576 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 490/4776 | Loss: 302.190 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 500/4776 | Loss: 291.922 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 510/4776 | Loss: 311.370 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 520/4776 | Loss: 318.027 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 530/4776 | Loss: 291.721 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 540/4776 | Loss: 291.720 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 550/4776 | Loss: 296.896 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 560/4776 | Loss: 296.419 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 570/4776 | Loss: 302.428 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 580/4776 | Loss: 325.189 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 590/4776 | Loss: 299.706 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 600/4776 | Loss: 296.617 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 610/4776 | Loss: 293.140 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 620/4776 | Loss: 292.089 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 630/4776 | Loss: 294.611 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 640/4776 | Loss: 295.657 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 650/4776 | Loss: 285.397 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 660/4776 | Loss: 291.893 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 670/4776 | Loss: 281.259 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 680/4776 | Loss: 307.912 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 690/4776 | Loss: 282.790 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 700/4776 | Loss: 294.804 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 710/4776 | Loss: 295.303 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 720/4776 | Loss: 303.861 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 730/4776 | Loss: 289.746 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 740/4776 | Loss: 270.244 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 750/4776 | Loss: 309.924 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 760/4776 | Loss: 276.602 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 770/4776 | Loss: 299.968 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 780/4776 | Loss: 295.366 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 790/4776 | Loss: 312.206 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 800/4776 | Loss: 284.789 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 810/4776 | Loss: 301.088 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 820/4776 | Loss: 299.126 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 830/4776 | Loss: 297.038 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 840/4776 | Loss: 291.914 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 850/4776 | Loss: 279.458 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 860/4776 | Loss: 288.606 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 870/4776 | Loss: 278.280 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 880/4776 | Loss: 304.833 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 890/4776 | Loss: 280.463 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 900/4776 | Loss: 313.246 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 910/4776 | Loss: 281.231 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 920/4776 | Loss: 221.877 | Accuracy: 0.500\n",
      "[Epoch: 12/200] - Step: 930/4776 | Loss: 313.398 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 940/4776 | Loss: 346.760 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 950/4776 | Loss: 290.226 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 960/4776 | Loss: 296.697 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 970/4776 | Loss: 312.188 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 980/4776 | Loss: 287.858 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 990/4776 | Loss: 302.787 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1000/4776 | Loss: 277.760 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1010/4776 | Loss: 314.622 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1020/4776 | Loss: 282.525 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1030/4776 | Loss: 290.565 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1040/4776 | Loss: 310.636 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1050/4776 | Loss: 306.055 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1060/4776 | Loss: 298.647 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1070/4776 | Loss: 289.679 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1080/4776 | Loss: 305.513 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1090/4776 | Loss: 272.118 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1100/4776 | Loss: 295.718 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1110/4776 | Loss: 280.959 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1120/4776 | Loss: 268.192 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1130/4776 | Loss: 292.353 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1140/4776 | Loss: 313.006 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1150/4776 | Loss: 299.855 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1160/4776 | Loss: 301.113 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1170/4776 | Loss: 301.736 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1180/4776 | Loss: 272.123 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1190/4776 | Loss: 301.592 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1200/4776 | Loss: 301.879 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1210/4776 | Loss: 290.434 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1220/4776 | Loss: 291.821 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1230/4776 | Loss: 278.549 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1240/4776 | Loss: 295.598 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1250/4776 | Loss: 270.754 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1260/4776 | Loss: 282.638 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1270/4776 | Loss: 294.635 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1280/4776 | Loss: 298.523 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1290/4776 | Loss: 303.515 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1300/4776 | Loss: 288.130 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1310/4776 | Loss: 318.505 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1320/4776 | Loss: 317.523 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1330/4776 | Loss: 295.854 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1340/4776 | Loss: 282.928 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1350/4776 | Loss: 261.399 | Accuracy: 0.500\n",
      "[Epoch: 12/200] - Step: 1360/4776 | Loss: 288.084 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1370/4776 | Loss: 296.511 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1380/4776 | Loss: 272.997 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1390/4776 | Loss: 296.461 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1400/4776 | Loss: 313.302 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1410/4776 | Loss: 309.738 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1420/4776 | Loss: 295.278 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1430/4776 | Loss: 281.153 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1440/4776 | Loss: 291.411 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1450/4776 | Loss: 281.741 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1460/4776 | Loss: 288.052 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1470/4776 | Loss: 306.184 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1480/4776 | Loss: 301.418 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1490/4776 | Loss: 288.136 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1500/4776 | Loss: 292.009 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1510/4776 | Loss: 282.157 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1520/4776 | Loss: 305.622 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1530/4776 | Loss: 275.490 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1540/4776 | Loss: 307.068 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1550/4776 | Loss: 304.599 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1560/4776 | Loss: 286.735 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1570/4776 | Loss: 307.066 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1580/4776 | Loss: 296.112 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1590/4776 | Loss: 305.894 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1600/4776 | Loss: 294.298 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1610/4776 | Loss: 312.219 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1620/4776 | Loss: 307.233 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1630/4776 | Loss: 314.369 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1640/4776 | Loss: 273.496 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1650/4776 | Loss: 290.054 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1660/4776 | Loss: 298.506 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1670/4776 | Loss: 288.721 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1680/4776 | Loss: 333.670 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1690/4776 | Loss: 301.207 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1700/4776 | Loss: 283.958 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1710/4776 | Loss: 306.343 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1720/4776 | Loss: 299.757 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1730/4776 | Loss: 282.829 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1740/4776 | Loss: 302.460 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1750/4776 | Loss: 305.469 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1760/4776 | Loss: 296.051 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1770/4776 | Loss: 297.113 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1780/4776 | Loss: 289.475 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1790/4776 | Loss: 305.932 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1800/4776 | Loss: 307.366 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1810/4776 | Loss: 272.940 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1820/4776 | Loss: 299.727 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1830/4776 | Loss: 278.420 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1840/4776 | Loss: 244.221 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 1850/4776 | Loss: 281.215 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1860/4776 | Loss: 316.013 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1870/4776 | Loss: 294.392 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1880/4776 | Loss: 298.134 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1890/4776 | Loss: 295.596 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1900/4776 | Loss: 291.380 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1910/4776 | Loss: 297.384 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1920/4776 | Loss: 306.947 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1930/4776 | Loss: 290.660 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1940/4776 | Loss: 289.360 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1950/4776 | Loss: 310.653 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1960/4776 | Loss: 285.309 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1970/4776 | Loss: 280.764 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1980/4776 | Loss: 275.857 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1990/4776 | Loss: 304.361 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2000/4776 | Loss: 310.725 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2010/4776 | Loss: 291.968 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2020/4776 | Loss: 294.460 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2030/4776 | Loss: 305.459 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2040/4776 | Loss: 283.291 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2050/4776 | Loss: 300.658 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2060/4776 | Loss: 287.371 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2070/4776 | Loss: 298.515 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2080/4776 | Loss: 289.597 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2090/4776 | Loss: 280.996 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 2100/4776 | Loss: 285.177 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2110/4776 | Loss: 292.087 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2120/4776 | Loss: 314.666 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2130/4776 | Loss: 267.744 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2140/4776 | Loss: 323.587 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2150/4776 | Loss: 282.680 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2160/4776 | Loss: 292.145 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2170/4776 | Loss: 289.071 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2180/4776 | Loss: 296.687 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2190/4776 | Loss: 288.551 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2200/4776 | Loss: 295.753 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2210/4776 | Loss: 301.358 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2220/4776 | Loss: 308.163 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2230/4776 | Loss: 281.598 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2240/4776 | Loss: 301.742 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2250/4776 | Loss: 296.137 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2260/4776 | Loss: 280.121 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2270/4776 | Loss: 314.411 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2280/4776 | Loss: 295.364 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2290/4776 | Loss: 295.100 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2300/4776 | Loss: 296.158 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2310/4776 | Loss: 295.129 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2320/4776 | Loss: 287.636 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2330/4776 | Loss: 311.023 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2340/4776 | Loss: 298.065 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2350/4776 | Loss: 270.991 | Accuracy: 0.500\n",
      "[Epoch: 12/200] - Step: 2360/4776 | Loss: 293.422 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2370/4776 | Loss: 300.024 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2380/4776 | Loss: 283.947 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2390/4776 | Loss: 292.255 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2400/4776 | Loss: 311.650 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2410/4776 | Loss: 282.264 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2420/4776 | Loss: 281.227 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2430/4776 | Loss: 309.021 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2440/4776 | Loss: 292.293 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2450/4776 | Loss: 303.488 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2460/4776 | Loss: 302.599 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2470/4776 | Loss: 302.551 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2480/4776 | Loss: 287.641 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2490/4776 | Loss: 264.916 | Accuracy: 0.500\n",
      "[Epoch: 12/200] - Step: 2500/4776 | Loss: 291.206 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2510/4776 | Loss: 309.854 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2520/4776 | Loss: 283.592 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2530/4776 | Loss: 296.625 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2540/4776 | Loss: 314.102 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2550/4776 | Loss: 295.106 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2560/4776 | Loss: 382.450 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2570/4776 | Loss: 306.223 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2580/4776 | Loss: 307.447 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2590/4776 | Loss: 301.933 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2600/4776 | Loss: 294.578 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2610/4776 | Loss: 298.696 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2620/4776 | Loss: 306.056 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2630/4776 | Loss: 302.135 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2640/4776 | Loss: 295.574 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2650/4776 | Loss: 306.238 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2660/4776 | Loss: 295.838 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2670/4776 | Loss: 303.041 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2680/4776 | Loss: 292.682 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2690/4776 | Loss: 314.599 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2700/4776 | Loss: 296.709 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2710/4776 | Loss: 293.043 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2720/4776 | Loss: 295.228 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2730/4776 | Loss: 317.974 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2740/4776 | Loss: 301.440 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2750/4776 | Loss: 278.554 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2760/4776 | Loss: 302.514 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2770/4776 | Loss: 298.489 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2780/4776 | Loss: 286.915 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2790/4776 | Loss: 287.807 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 2800/4776 | Loss: 293.011 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2810/4776 | Loss: 300.085 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2820/4776 | Loss: 308.995 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2830/4776 | Loss: 286.286 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2840/4776 | Loss: 306.264 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2850/4776 | Loss: 296.424 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2860/4776 | Loss: 284.902 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2870/4776 | Loss: 272.404 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 2880/4776 | Loss: 306.289 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2890/4776 | Loss: 285.937 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2900/4776 | Loss: 304.464 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2910/4776 | Loss: 307.405 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2920/4776 | Loss: 297.694 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2930/4776 | Loss: 298.181 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2940/4776 | Loss: 312.087 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2950/4776 | Loss: 301.061 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2960/4776 | Loss: 302.113 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2970/4776 | Loss: 301.978 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 2980/4776 | Loss: 305.011 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 2990/4776 | Loss: 292.968 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3000/4776 | Loss: 292.843 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3010/4776 | Loss: 309.584 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3020/4776 | Loss: 300.720 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3030/4776 | Loss: 292.809 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3040/4776 | Loss: 284.652 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3050/4776 | Loss: 284.548 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3060/4776 | Loss: 290.913 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3070/4776 | Loss: 289.555 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3080/4776 | Loss: 292.242 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3090/4776 | Loss: 289.978 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3100/4776 | Loss: 291.526 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3110/4776 | Loss: 294.809 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3120/4776 | Loss: 278.136 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3130/4776 | Loss: 301.952 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3140/4776 | Loss: 299.176 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3150/4776 | Loss: 297.681 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3160/4776 | Loss: 301.803 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3170/4776 | Loss: 298.730 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3180/4776 | Loss: 297.429 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3190/4776 | Loss: 313.400 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3200/4776 | Loss: 301.161 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3210/4776 | Loss: 304.690 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3220/4776 | Loss: 287.361 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3230/4776 | Loss: 298.477 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3240/4776 | Loss: 303.261 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3250/4776 | Loss: 287.530 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3260/4776 | Loss: 301.881 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3270/4776 | Loss: 311.693 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3280/4776 | Loss: 307.764 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3290/4776 | Loss: 289.381 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3300/4776 | Loss: 285.115 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3310/4776 | Loss: 280.411 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3320/4776 | Loss: 270.774 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3330/4776 | Loss: 283.972 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3340/4776 | Loss: 290.254 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3350/4776 | Loss: 281.531 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3360/4776 | Loss: 301.545 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3370/4776 | Loss: 337.616 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3380/4776 | Loss: 285.206 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3390/4776 | Loss: 303.380 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3400/4776 | Loss: 302.083 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3410/4776 | Loss: 281.837 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 3420/4776 | Loss: 290.070 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3430/4776 | Loss: 292.676 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3440/4776 | Loss: 290.608 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3450/4776 | Loss: 287.682 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3460/4776 | Loss: 316.296 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3470/4776 | Loss: 296.642 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3480/4776 | Loss: 309.538 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3490/4776 | Loss: 297.877 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3500/4776 | Loss: 290.854 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3510/4776 | Loss: 292.260 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3520/4776 | Loss: 296.124 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3530/4776 | Loss: 298.715 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3540/4776 | Loss: 286.128 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3550/4776 | Loss: 292.259 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3560/4776 | Loss: 286.349 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3570/4776 | Loss: 296.955 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3580/4776 | Loss: 295.055 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3590/4776 | Loss: 282.104 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3600/4776 | Loss: 267.419 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 3610/4776 | Loss: 297.932 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3620/4776 | Loss: 307.416 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3630/4776 | Loss: 288.972 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3640/4776 | Loss: 302.253 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3650/4776 | Loss: 313.926 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3660/4776 | Loss: 281.441 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3670/4776 | Loss: 278.997 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3680/4776 | Loss: 266.091 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 3690/4776 | Loss: 295.929 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3700/4776 | Loss: 303.505 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3710/4776 | Loss: 267.597 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3720/4776 | Loss: 287.199 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3730/4776 | Loss: 292.838 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3740/4776 | Loss: 301.505 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3750/4776 | Loss: 308.090 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3760/4776 | Loss: 265.009 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3770/4776 | Loss: 297.317 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3780/4776 | Loss: 300.843 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3790/4776 | Loss: 296.342 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3800/4776 | Loss: 297.451 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3810/4776 | Loss: 277.297 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3820/4776 | Loss: 275.713 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3830/4776 | Loss: 301.449 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3840/4776 | Loss: 295.368 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3850/4776 | Loss: 294.500 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3860/4776 | Loss: 277.063 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3870/4776 | Loss: 284.342 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3880/4776 | Loss: 287.546 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3890/4776 | Loss: 327.896 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3900/4776 | Loss: 282.774 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3910/4776 | Loss: 335.246 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3920/4776 | Loss: 279.800 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3930/4776 | Loss: 293.997 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3940/4776 | Loss: 307.046 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3950/4776 | Loss: 290.272 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 3960/4776 | Loss: 314.946 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 3970/4776 | Loss: 276.607 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 3980/4776 | Loss: 285.991 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 3990/4776 | Loss: 290.095 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4000/4776 | Loss: 293.583 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4010/4776 | Loss: 310.471 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4020/4776 | Loss: 284.677 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4030/4776 | Loss: 264.166 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4040/4776 | Loss: 309.606 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4050/4776 | Loss: 291.637 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4060/4776 | Loss: 300.816 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4070/4776 | Loss: 307.570 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4080/4776 | Loss: 291.700 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4090/4776 | Loss: 299.996 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4100/4776 | Loss: 303.529 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4110/4776 | Loss: 279.595 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4120/4776 | Loss: 292.244 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4130/4776 | Loss: 313.486 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4140/4776 | Loss: 317.166 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4150/4776 | Loss: 268.828 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 4160/4776 | Loss: 298.030 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4170/4776 | Loss: 308.014 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4180/4776 | Loss: 279.117 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4190/4776 | Loss: 281.208 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4200/4776 | Loss: 282.244 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4210/4776 | Loss: 315.400 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4220/4776 | Loss: 280.060 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4230/4776 | Loss: 304.547 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4240/4776 | Loss: 307.568 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4250/4776 | Loss: 302.352 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4260/4776 | Loss: 272.044 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4270/4776 | Loss: 282.796 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4280/4776 | Loss: 303.089 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4290/4776 | Loss: 294.977 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4300/4776 | Loss: 306.673 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4310/4776 | Loss: 295.680 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4320/4776 | Loss: 294.688 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4330/4776 | Loss: 291.300 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4340/4776 | Loss: 290.958 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4350/4776 | Loss: 285.422 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4360/4776 | Loss: 301.340 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4370/4776 | Loss: 313.003 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4380/4776 | Loss: 301.607 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4390/4776 | Loss: 308.699 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4400/4776 | Loss: 271.469 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 4410/4776 | Loss: 266.630 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4420/4776 | Loss: 294.667 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4430/4776 | Loss: 294.401 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4440/4776 | Loss: 305.685 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4450/4776 | Loss: 283.580 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4460/4776 | Loss: 243.223 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4470/4776 | Loss: 301.036 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4480/4776 | Loss: 280.057 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4490/4776 | Loss: 283.679 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4500/4776 | Loss: 259.515 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 4510/4776 | Loss: 310.826 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4520/4776 | Loss: 301.706 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4530/4776 | Loss: 273.317 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4540/4776 | Loss: 277.395 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4550/4776 | Loss: 254.861 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4560/4776 | Loss: 304.356 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4570/4776 | Loss: 291.585 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4580/4776 | Loss: 295.569 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4590/4776 | Loss: 268.196 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4600/4776 | Loss: 311.033 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4610/4776 | Loss: 282.228 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4620/4776 | Loss: 278.878 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4630/4776 | Loss: 292.335 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4640/4776 | Loss: 297.190 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4650/4776 | Loss: 297.699 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4660/4776 | Loss: 311.021 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4670/4776 | Loss: 288.773 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 4680/4776 | Loss: 307.864 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4690/4776 | Loss: 312.618 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4700/4776 | Loss: 293.374 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 4710/4776 | Loss: 296.779 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4720/4776 | Loss: 287.562 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4730/4776 | Loss: 314.128 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4740/4776 | Loss: 309.772 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4750/4776 | Loss: 298.167 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 4760/4776 | Loss: 288.917 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 4770/4776 | Loss: 305.942 | Accuracy: 0.100\n",
      "Accuracy:  0.03934426229508197\n",
      "[Epoch: 13/200] - Step: 10/4776 | Loss: 290.150 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 20/4776 | Loss: 304.531 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 30/4776 | Loss: 289.653 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 40/4776 | Loss: 292.296 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 50/4776 | Loss: 281.235 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 60/4776 | Loss: 281.303 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 70/4776 | Loss: 300.883 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 80/4776 | Loss: 300.603 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 90/4776 | Loss: 280.079 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 100/4776 | Loss: 300.359 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 110/4776 | Loss: 324.249 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 120/4776 | Loss: 275.118 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 130/4776 | Loss: 299.521 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 140/4776 | Loss: 289.470 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 150/4776 | Loss: 299.642 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 160/4776 | Loss: 283.980 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 170/4776 | Loss: 302.608 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 180/4776 | Loss: 301.903 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 190/4776 | Loss: 279.389 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 200/4776 | Loss: 341.062 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 210/4776 | Loss: 306.447 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 220/4776 | Loss: 286.470 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 230/4776 | Loss: 305.597 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 240/4776 | Loss: 302.572 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 250/4776 | Loss: 303.176 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 260/4776 | Loss: 313.468 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 270/4776 | Loss: 296.246 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 280/4776 | Loss: 294.016 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 290/4776 | Loss: 284.933 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 300/4776 | Loss: 327.400 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 310/4776 | Loss: 305.972 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 320/4776 | Loss: 298.368 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 330/4776 | Loss: 303.270 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 340/4776 | Loss: 287.284 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 350/4776 | Loss: 295.621 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 360/4776 | Loss: 289.076 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 370/4776 | Loss: 300.827 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 380/4776 | Loss: 285.967 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 390/4776 | Loss: 304.387 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 400/4776 | Loss: 298.277 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 410/4776 | Loss: 284.033 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 420/4776 | Loss: 302.872 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 430/4776 | Loss: 296.294 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 440/4776 | Loss: 300.269 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 450/4776 | Loss: 307.154 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 460/4776 | Loss: 284.470 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 470/4776 | Loss: 299.845 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 480/4776 | Loss: 287.328 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 490/4776 | Loss: 310.845 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 500/4776 | Loss: 289.461 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 510/4776 | Loss: 314.653 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 520/4776 | Loss: 287.226 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 530/4776 | Loss: 301.811 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 540/4776 | Loss: 285.387 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 550/4776 | Loss: 303.133 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 560/4776 | Loss: 302.267 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 570/4776 | Loss: 269.334 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 580/4776 | Loss: 298.929 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 590/4776 | Loss: 274.569 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 600/4776 | Loss: 291.861 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 610/4776 | Loss: 287.731 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 620/4776 | Loss: 302.920 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 630/4776 | Loss: 276.040 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 640/4776 | Loss: 286.356 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 650/4776 | Loss: 277.878 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 660/4776 | Loss: 299.438 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 670/4776 | Loss: 333.299 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 680/4776 | Loss: 289.726 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 690/4776 | Loss: 267.426 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 700/4776 | Loss: 306.484 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 710/4776 | Loss: 287.105 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 720/4776 | Loss: 317.571 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 730/4776 | Loss: 305.327 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 740/4776 | Loss: 308.917 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 750/4776 | Loss: 302.821 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 760/4776 | Loss: 281.700 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 770/4776 | Loss: 278.121 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 780/4776 | Loss: 299.453 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 790/4776 | Loss: 325.742 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 800/4776 | Loss: 289.858 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 810/4776 | Loss: 323.310 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 820/4776 | Loss: 301.195 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 830/4776 | Loss: 327.900 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 840/4776 | Loss: 285.798 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 850/4776 | Loss: 300.031 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 860/4776 | Loss: 297.085 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 870/4776 | Loss: 301.993 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 880/4776 | Loss: 288.313 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 890/4776 | Loss: 286.480 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 900/4776 | Loss: 288.988 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 910/4776 | Loss: 302.465 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 920/4776 | Loss: 308.416 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 930/4776 | Loss: 292.796 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 940/4776 | Loss: 306.037 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 950/4776 | Loss: 303.802 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 960/4776 | Loss: 291.868 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 970/4776 | Loss: 302.029 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 980/4776 | Loss: 283.939 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 990/4776 | Loss: 303.000 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1000/4776 | Loss: 317.212 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1010/4776 | Loss: 301.105 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1020/4776 | Loss: 293.246 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1030/4776 | Loss: 277.550 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1040/4776 | Loss: 296.594 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1050/4776 | Loss: 278.096 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1060/4776 | Loss: 271.135 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1070/4776 | Loss: 298.200 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1080/4776 | Loss: 289.837 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1090/4776 | Loss: 289.367 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1100/4776 | Loss: 276.589 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1110/4776 | Loss: 304.708 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1120/4776 | Loss: 291.124 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1130/4776 | Loss: 325.866 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1140/4776 | Loss: 289.186 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1150/4776 | Loss: 293.236 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1160/4776 | Loss: 289.181 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1170/4776 | Loss: 267.597 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1180/4776 | Loss: 290.807 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1190/4776 | Loss: 302.129 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1200/4776 | Loss: 304.227 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1210/4776 | Loss: 293.271 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1220/4776 | Loss: 303.815 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1230/4776 | Loss: 292.983 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1240/4776 | Loss: 283.240 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1250/4776 | Loss: 281.661 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1260/4776 | Loss: 304.915 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1270/4776 | Loss: 269.059 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1280/4776 | Loss: 243.959 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1290/4776 | Loss: 311.429 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1300/4776 | Loss: 307.047 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1310/4776 | Loss: 304.122 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1320/4776 | Loss: 288.698 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1330/4776 | Loss: 300.235 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1340/4776 | Loss: 309.635 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1350/4776 | Loss: 286.549 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1360/4776 | Loss: 296.765 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1370/4776 | Loss: 289.857 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1380/4776 | Loss: 293.808 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1390/4776 | Loss: 291.323 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1400/4776 | Loss: 266.505 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1410/4776 | Loss: 293.247 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1420/4776 | Loss: 285.477 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1430/4776 | Loss: 299.206 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1440/4776 | Loss: 274.442 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1450/4776 | Loss: 317.589 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1460/4776 | Loss: 306.393 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1470/4776 | Loss: 266.496 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1480/4776 | Loss: 304.111 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1490/4776 | Loss: 308.781 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1500/4776 | Loss: 283.103 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1510/4776 | Loss: 283.673 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1520/4776 | Loss: 282.472 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1530/4776 | Loss: 282.997 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1540/4776 | Loss: 305.745 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1550/4776 | Loss: 268.790 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1560/4776 | Loss: 294.299 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1570/4776 | Loss: 301.794 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1580/4776 | Loss: 316.768 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1590/4776 | Loss: 308.522 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1600/4776 | Loss: 286.598 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1610/4776 | Loss: 274.970 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1620/4776 | Loss: 301.078 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1630/4776 | Loss: 331.608 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1640/4776 | Loss: 287.412 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1650/4776 | Loss: 284.064 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1660/4776 | Loss: 243.741 | Accuracy: 0.500\n",
      "[Epoch: 13/200] - Step: 1670/4776 | Loss: 300.074 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1680/4776 | Loss: 309.785 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1690/4776 | Loss: 314.804 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1700/4776 | Loss: 304.876 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1710/4776 | Loss: 280.267 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1720/4776 | Loss: 297.244 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1730/4776 | Loss: 273.526 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1740/4776 | Loss: 307.850 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1750/4776 | Loss: 294.726 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1760/4776 | Loss: 292.900 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1770/4776 | Loss: 293.109 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1780/4776 | Loss: 326.016 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1790/4776 | Loss: 292.700 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1800/4776 | Loss: 300.357 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1810/4776 | Loss: 304.132 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1820/4776 | Loss: 290.768 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1830/4776 | Loss: 305.798 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1840/4776 | Loss: 298.073 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1850/4776 | Loss: 268.148 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1860/4776 | Loss: 300.072 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1870/4776 | Loss: 285.794 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1880/4776 | Loss: 284.391 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1890/4776 | Loss: 285.742 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1900/4776 | Loss: 305.855 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1910/4776 | Loss: 260.777 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1920/4776 | Loss: 296.543 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1930/4776 | Loss: 296.335 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1940/4776 | Loss: 281.222 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1950/4776 | Loss: 291.652 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1960/4776 | Loss: 269.755 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 1970/4776 | Loss: 317.828 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1980/4776 | Loss: 278.015 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1990/4776 | Loss: 304.910 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2000/4776 | Loss: 284.102 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2010/4776 | Loss: 301.183 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2020/4776 | Loss: 313.933 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2030/4776 | Loss: 280.951 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2040/4776 | Loss: 285.161 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2050/4776 | Loss: 310.115 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2060/4776 | Loss: 308.264 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2070/4776 | Loss: 306.450 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2080/4776 | Loss: 296.321 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2090/4776 | Loss: 309.929 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2100/4776 | Loss: 297.258 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2110/4776 | Loss: 291.290 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2120/4776 | Loss: 284.053 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2130/4776 | Loss: 273.626 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2140/4776 | Loss: 293.823 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2150/4776 | Loss: 260.386 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2160/4776 | Loss: 277.585 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2170/4776 | Loss: 267.091 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2180/4776 | Loss: 287.271 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2190/4776 | Loss: 314.054 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2200/4776 | Loss: 283.521 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2210/4776 | Loss: 302.343 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2220/4776 | Loss: 286.838 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2230/4776 | Loss: 304.971 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2240/4776 | Loss: 313.744 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2250/4776 | Loss: 296.395 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2260/4776 | Loss: 295.170 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2270/4776 | Loss: 287.248 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2280/4776 | Loss: 302.514 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2290/4776 | Loss: 311.913 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2300/4776 | Loss: 276.432 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2310/4776 | Loss: 284.910 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2320/4776 | Loss: 292.413 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2330/4776 | Loss: 259.267 | Accuracy: 0.500\n",
      "[Epoch: 13/200] - Step: 2340/4776 | Loss: 257.673 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 2350/4776 | Loss: 261.673 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 2360/4776 | Loss: 297.132 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2370/4776 | Loss: 318.229 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2380/4776 | Loss: 305.447 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2390/4776 | Loss: 299.078 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2400/4776 | Loss: 303.083 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2410/4776 | Loss: 290.742 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2420/4776 | Loss: 296.996 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2430/4776 | Loss: 302.620 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2440/4776 | Loss: 307.211 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2450/4776 | Loss: 293.701 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2460/4776 | Loss: 292.472 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2470/4776 | Loss: 287.551 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2480/4776 | Loss: 277.970 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2490/4776 | Loss: 278.376 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2500/4776 | Loss: 278.597 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2510/4776 | Loss: 292.828 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2520/4776 | Loss: 309.160 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2530/4776 | Loss: 286.865 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2540/4776 | Loss: 278.161 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2550/4776 | Loss: 306.651 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2560/4776 | Loss: 280.817 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2570/4776 | Loss: 311.783 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2580/4776 | Loss: 300.503 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2590/4776 | Loss: 293.907 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2600/4776 | Loss: 296.578 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2610/4776 | Loss: 298.867 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2620/4776 | Loss: 291.631 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2630/4776 | Loss: 280.377 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2640/4776 | Loss: 291.335 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2650/4776 | Loss: 291.536 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2660/4776 | Loss: 319.564 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2670/4776 | Loss: 293.245 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2680/4776 | Loss: 273.746 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2690/4776 | Loss: 279.814 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2700/4776 | Loss: 302.068 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2710/4776 | Loss: 307.396 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2720/4776 | Loss: 284.350 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2730/4776 | Loss: 290.311 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2740/4776 | Loss: 296.810 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2750/4776 | Loss: 273.701 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 2760/4776 | Loss: 291.176 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2770/4776 | Loss: 297.062 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2780/4776 | Loss: 307.758 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2790/4776 | Loss: 302.551 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2800/4776 | Loss: 293.982 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2810/4776 | Loss: 299.575 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2820/4776 | Loss: 286.983 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2830/4776 | Loss: 293.720 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2840/4776 | Loss: 284.630 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2850/4776 | Loss: 318.339 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2860/4776 | Loss: 286.697 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2870/4776 | Loss: 302.674 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2880/4776 | Loss: 298.798 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2890/4776 | Loss: 305.692 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2900/4776 | Loss: 298.372 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2910/4776 | Loss: 316.826 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2920/4776 | Loss: 296.417 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2930/4776 | Loss: 287.781 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2940/4776 | Loss: 292.608 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2950/4776 | Loss: 298.717 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 2960/4776 | Loss: 307.752 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 2970/4776 | Loss: 264.515 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2980/4776 | Loss: 291.225 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 2990/4776 | Loss: 304.935 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3000/4776 | Loss: 268.537 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 3010/4776 | Loss: 293.440 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3020/4776 | Loss: 275.516 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3030/4776 | Loss: 294.858 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3040/4776 | Loss: 288.983 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3050/4776 | Loss: 301.973 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3060/4776 | Loss: 275.851 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3070/4776 | Loss: 287.373 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3080/4776 | Loss: 288.786 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3090/4776 | Loss: 298.627 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3100/4776 | Loss: 296.690 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3110/4776 | Loss: 275.577 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3120/4776 | Loss: 296.282 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3130/4776 | Loss: 288.314 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3140/4776 | Loss: 291.252 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3150/4776 | Loss: 276.227 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3160/4776 | Loss: 267.317 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3170/4776 | Loss: 282.522 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3180/4776 | Loss: 308.559 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3190/4776 | Loss: 280.252 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3200/4776 | Loss: 290.613 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3210/4776 | Loss: 298.291 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3220/4776 | Loss: 288.931 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3230/4776 | Loss: 319.330 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3240/4776 | Loss: 278.123 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 3250/4776 | Loss: 287.928 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3260/4776 | Loss: 278.641 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3270/4776 | Loss: 293.447 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3280/4776 | Loss: 299.563 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3290/4776 | Loss: 296.390 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3300/4776 | Loss: 286.813 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3310/4776 | Loss: 294.780 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3320/4776 | Loss: 303.926 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3330/4776 | Loss: 299.826 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3340/4776 | Loss: 304.827 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3350/4776 | Loss: 280.790 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3360/4776 | Loss: 294.701 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3370/4776 | Loss: 313.338 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3380/4776 | Loss: 304.591 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3390/4776 | Loss: 301.501 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3400/4776 | Loss: 302.993 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3410/4776 | Loss: 289.291 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3420/4776 | Loss: 285.092 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3430/4776 | Loss: 289.084 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3440/4776 | Loss: 307.211 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3450/4776 | Loss: 315.252 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3460/4776 | Loss: 302.456 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3470/4776 | Loss: 293.064 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3480/4776 | Loss: 295.040 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3490/4776 | Loss: 278.401 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3500/4776 | Loss: 304.201 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3510/4776 | Loss: 296.787 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3520/4776 | Loss: 301.033 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3530/4776 | Loss: 293.400 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3540/4776 | Loss: 290.978 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3550/4776 | Loss: 296.587 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3560/4776 | Loss: 298.714 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3570/4776 | Loss: 255.431 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 3580/4776 | Loss: 291.474 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3590/4776 | Loss: 308.779 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3600/4776 | Loss: 312.191 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3610/4776 | Loss: 294.963 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3620/4776 | Loss: 280.734 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3630/4776 | Loss: 286.803 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3640/4776 | Loss: 287.256 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3650/4776 | Loss: 261.950 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3660/4776 | Loss: 317.230 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3670/4776 | Loss: 325.776 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3680/4776 | Loss: 301.800 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3690/4776 | Loss: 318.201 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3700/4776 | Loss: 287.937 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3710/4776 | Loss: 291.190 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3720/4776 | Loss: 296.858 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3730/4776 | Loss: 298.996 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3740/4776 | Loss: 270.872 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3750/4776 | Loss: 270.773 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 3760/4776 | Loss: 284.219 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3770/4776 | Loss: 265.144 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3780/4776 | Loss: 274.516 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3790/4776 | Loss: 277.057 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3800/4776 | Loss: 271.975 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 3810/4776 | Loss: 288.728 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3820/4776 | Loss: 312.160 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3830/4776 | Loss: 318.444 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3840/4776 | Loss: 270.695 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3850/4776 | Loss: 311.498 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3860/4776 | Loss: 303.292 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3870/4776 | Loss: 296.871 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3880/4776 | Loss: 301.139 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3890/4776 | Loss: 286.951 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3900/4776 | Loss: 296.960 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3910/4776 | Loss: 296.594 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3920/4776 | Loss: 303.313 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3930/4776 | Loss: 308.477 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3940/4776 | Loss: 290.090 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3950/4776 | Loss: 305.635 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 3960/4776 | Loss: 305.429 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 3970/4776 | Loss: 296.879 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3980/4776 | Loss: 286.204 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 3990/4776 | Loss: 298.962 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4000/4776 | Loss: 271.789 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4010/4776 | Loss: 306.987 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4020/4776 | Loss: 302.995 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4030/4776 | Loss: 283.198 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4040/4776 | Loss: 295.466 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4050/4776 | Loss: 282.981 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4060/4776 | Loss: 299.545 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4070/4776 | Loss: 309.013 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4080/4776 | Loss: 290.727 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4090/4776 | Loss: 299.889 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4100/4776 | Loss: 298.193 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4110/4776 | Loss: 299.730 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4120/4776 | Loss: 315.840 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4130/4776 | Loss: 295.193 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4140/4776 | Loss: 269.656 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4150/4776 | Loss: 300.890 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4160/4776 | Loss: 304.281 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4170/4776 | Loss: 298.520 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4180/4776 | Loss: 298.697 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4190/4776 | Loss: 307.096 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4200/4776 | Loss: 296.695 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4210/4776 | Loss: 291.027 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4220/4776 | Loss: 302.067 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4230/4776 | Loss: 300.185 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4240/4776 | Loss: 304.862 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4250/4776 | Loss: 302.416 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4260/4776 | Loss: 299.908 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4270/4776 | Loss: 303.324 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4280/4776 | Loss: 284.783 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4290/4776 | Loss: 290.575 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4300/4776 | Loss: 279.495 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4310/4776 | Loss: 293.431 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4320/4776 | Loss: 267.630 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 4330/4776 | Loss: 285.273 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4340/4776 | Loss: 261.512 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4350/4776 | Loss: 290.364 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4360/4776 | Loss: 301.619 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4370/4776 | Loss: 305.966 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4380/4776 | Loss: 290.356 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4390/4776 | Loss: 311.342 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4400/4776 | Loss: 304.026 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4410/4776 | Loss: 283.967 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4420/4776 | Loss: 292.848 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4430/4776 | Loss: 278.842 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4440/4776 | Loss: 311.706 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4450/4776 | Loss: 299.743 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4460/4776 | Loss: 320.837 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4470/4776 | Loss: 293.972 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4480/4776 | Loss: 287.559 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4490/4776 | Loss: 306.338 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4500/4776 | Loss: 301.929 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4510/4776 | Loss: 298.143 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4520/4776 | Loss: 303.150 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4530/4776 | Loss: 304.497 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4540/4776 | Loss: 302.434 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4550/4776 | Loss: 287.614 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4560/4776 | Loss: 298.656 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4570/4776 | Loss: 291.759 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4580/4776 | Loss: 293.358 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4590/4776 | Loss: 280.009 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4600/4776 | Loss: 297.031 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4610/4776 | Loss: 286.402 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4620/4776 | Loss: 280.923 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4630/4776 | Loss: 302.987 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4640/4776 | Loss: 301.517 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4650/4776 | Loss: 278.792 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 4660/4776 | Loss: 300.787 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4670/4776 | Loss: 293.952 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4680/4776 | Loss: 288.317 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4690/4776 | Loss: 309.012 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4700/4776 | Loss: 295.282 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4710/4776 | Loss: 297.440 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 4720/4776 | Loss: 282.668 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4730/4776 | Loss: 287.157 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4740/4776 | Loss: 266.364 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 4750/4776 | Loss: 292.413 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4760/4776 | Loss: 293.650 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 4770/4776 | Loss: 272.882 | Accuracy: 0.200\n",
      "Accuracy:  0.10327868852459017\n",
      "[Epoch: 14/200] - Step: 10/4776 | Loss: 304.864 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 20/4776 | Loss: 276.272 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 30/4776 | Loss: 270.550 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 40/4776 | Loss: 285.802 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 50/4776 | Loss: 271.585 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 60/4776 | Loss: 293.482 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 70/4776 | Loss: 293.466 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 80/4776 | Loss: 294.235 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 90/4776 | Loss: 307.374 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 100/4776 | Loss: 300.188 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 110/4776 | Loss: 269.605 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 120/4776 | Loss: 273.916 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 130/4776 | Loss: 266.056 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 140/4776 | Loss: 328.063 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 150/4776 | Loss: 290.676 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 160/4776 | Loss: 251.956 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 170/4776 | Loss: 279.609 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 180/4776 | Loss: 313.549 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 190/4776 | Loss: 309.458 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 200/4776 | Loss: 295.163 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 210/4776 | Loss: 304.868 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 220/4776 | Loss: 283.833 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 230/4776 | Loss: 302.590 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 240/4776 | Loss: 285.799 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 250/4776 | Loss: 309.422 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 260/4776 | Loss: 299.199 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 270/4776 | Loss: 290.933 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 280/4776 | Loss: 286.854 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 290/4776 | Loss: 298.599 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 300/4776 | Loss: 297.504 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 310/4776 | Loss: 276.030 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 320/4776 | Loss: 332.006 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 330/4776 | Loss: 306.755 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 340/4776 | Loss: 270.601 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 350/4776 | Loss: 293.875 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 360/4776 | Loss: 323.376 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 370/4776 | Loss: 297.827 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 380/4776 | Loss: 300.771 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 390/4776 | Loss: 280.208 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 400/4776 | Loss: 307.685 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 410/4776 | Loss: 276.419 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 420/4776 | Loss: 303.820 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 430/4776 | Loss: 301.612 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 440/4776 | Loss: 286.290 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 450/4776 | Loss: 298.741 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 460/4776 | Loss: 294.998 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 470/4776 | Loss: 280.786 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 480/4776 | Loss: 280.500 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 490/4776 | Loss: 290.102 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 500/4776 | Loss: 292.044 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 510/4776 | Loss: 315.274 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 520/4776 | Loss: 294.818 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 530/4776 | Loss: 274.857 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 540/4776 | Loss: 297.026 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 550/4776 | Loss: 304.267 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 560/4776 | Loss: 289.849 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 570/4776 | Loss: 295.554 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 580/4776 | Loss: 267.050 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 590/4776 | Loss: 270.059 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 600/4776 | Loss: 257.559 | Accuracy: 0.500\n",
      "[Epoch: 14/200] - Step: 610/4776 | Loss: 303.453 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 620/4776 | Loss: 309.330 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 630/4776 | Loss: 293.673 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 640/4776 | Loss: 298.198 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 650/4776 | Loss: 273.628 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 660/4776 | Loss: 306.562 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 670/4776 | Loss: 295.589 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 680/4776 | Loss: 304.648 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 690/4776 | Loss: 302.113 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 700/4776 | Loss: 289.034 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 710/4776 | Loss: 293.973 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 720/4776 | Loss: 297.442 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 730/4776 | Loss: 298.361 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 740/4776 | Loss: 287.468 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 750/4776 | Loss: 312.036 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 760/4776 | Loss: 276.334 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 770/4776 | Loss: 314.485 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 780/4776 | Loss: 297.817 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 790/4776 | Loss: 284.610 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 800/4776 | Loss: 292.646 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 810/4776 | Loss: 326.182 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 820/4776 | Loss: 313.910 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 830/4776 | Loss: 312.248 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 840/4776 | Loss: 319.040 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 850/4776 | Loss: 274.463 | Accuracy: 0.500\n",
      "[Epoch: 14/200] - Step: 860/4776 | Loss: 300.550 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 870/4776 | Loss: 284.201 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 880/4776 | Loss: 317.657 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 890/4776 | Loss: 298.168 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 900/4776 | Loss: 298.333 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 910/4776 | Loss: 285.805 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 920/4776 | Loss: 302.781 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 930/4776 | Loss: 290.773 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 940/4776 | Loss: 277.623 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 950/4776 | Loss: 276.264 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 960/4776 | Loss: 301.424 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 970/4776 | Loss: 274.938 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 980/4776 | Loss: 283.911 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 990/4776 | Loss: 273.454 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 1000/4776 | Loss: 308.146 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1010/4776 | Loss: 298.148 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1020/4776 | Loss: 285.866 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1030/4776 | Loss: 315.021 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1040/4776 | Loss: 290.169 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1050/4776 | Loss: 297.888 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1060/4776 | Loss: 292.953 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1070/4776 | Loss: 270.010 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1080/4776 | Loss: 297.686 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1090/4776 | Loss: 292.036 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1100/4776 | Loss: 313.087 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1110/4776 | Loss: 274.678 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1120/4776 | Loss: 309.661 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1130/4776 | Loss: 302.317 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1140/4776 | Loss: 281.767 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1150/4776 | Loss: 248.915 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 1160/4776 | Loss: 284.847 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1170/4776 | Loss: 298.943 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1180/4776 | Loss: 296.156 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1190/4776 | Loss: 297.556 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1200/4776 | Loss: 302.369 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1210/4776 | Loss: 287.368 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1220/4776 | Loss: 297.176 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1230/4776 | Loss: 281.233 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1240/4776 | Loss: 321.445 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1250/4776 | Loss: 296.550 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1260/4776 | Loss: 254.120 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1270/4776 | Loss: 304.845 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1280/4776 | Loss: 288.928 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1290/4776 | Loss: 281.416 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1300/4776 | Loss: 281.510 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1310/4776 | Loss: 307.778 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1320/4776 | Loss: 286.551 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1330/4776 | Loss: 308.013 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1340/4776 | Loss: 302.842 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1350/4776 | Loss: 305.466 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1360/4776 | Loss: 297.207 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1370/4776 | Loss: 305.302 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1380/4776 | Loss: 284.197 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1390/4776 | Loss: 281.083 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1400/4776 | Loss: 308.501 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1410/4776 | Loss: 289.574 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1420/4776 | Loss: 297.436 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1430/4776 | Loss: 295.005 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1440/4776 | Loss: 275.871 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1450/4776 | Loss: 311.921 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1460/4776 | Loss: 288.085 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1470/4776 | Loss: 308.180 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1480/4776 | Loss: 292.949 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1490/4776 | Loss: 306.258 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1500/4776 | Loss: 297.911 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1510/4776 | Loss: 274.582 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1520/4776 | Loss: 279.499 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1530/4776 | Loss: 297.817 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1540/4776 | Loss: 303.646 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1550/4776 | Loss: 292.198 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1560/4776 | Loss: 267.643 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1570/4776 | Loss: 287.915 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1580/4776 | Loss: 302.626 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1590/4776 | Loss: 313.004 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1600/4776 | Loss: 319.515 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1610/4776 | Loss: 293.602 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1620/4776 | Loss: 288.496 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1630/4776 | Loss: 311.318 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1640/4776 | Loss: 294.224 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1650/4776 | Loss: 268.198 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 1660/4776 | Loss: 314.947 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1670/4776 | Loss: 303.904 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1680/4776 | Loss: 279.951 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1690/4776 | Loss: 301.698 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1700/4776 | Loss: 285.509 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1710/4776 | Loss: 299.204 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1720/4776 | Loss: 307.336 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1730/4776 | Loss: 295.669 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1740/4776 | Loss: 299.662 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1750/4776 | Loss: 293.002 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1760/4776 | Loss: 301.727 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1770/4776 | Loss: 309.826 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1780/4776 | Loss: 292.388 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1790/4776 | Loss: 300.028 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1800/4776 | Loss: 292.891 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1810/4776 | Loss: 287.943 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1820/4776 | Loss: 295.220 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1830/4776 | Loss: 299.138 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1840/4776 | Loss: 288.715 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1850/4776 | Loss: 276.738 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1860/4776 | Loss: 303.939 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1870/4776 | Loss: 299.857 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1880/4776 | Loss: 295.202 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1890/4776 | Loss: 276.918 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1900/4776 | Loss: 281.651 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1910/4776 | Loss: 301.573 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1920/4776 | Loss: 303.616 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1930/4776 | Loss: 308.509 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1940/4776 | Loss: 309.243 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1950/4776 | Loss: 290.868 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1960/4776 | Loss: 291.919 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1970/4776 | Loss: 294.872 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1980/4776 | Loss: 290.752 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1990/4776 | Loss: 299.442 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2000/4776 | Loss: 306.335 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2010/4776 | Loss: 290.189 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2020/4776 | Loss: 280.287 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2030/4776 | Loss: 293.729 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2040/4776 | Loss: 301.913 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2050/4776 | Loss: 309.995 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2060/4776 | Loss: 292.135 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2070/4776 | Loss: 304.977 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2080/4776 | Loss: 294.168 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2090/4776 | Loss: 292.596 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2100/4776 | Loss: 267.563 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2110/4776 | Loss: 288.566 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2120/4776 | Loss: 306.867 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2130/4776 | Loss: 300.724 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2140/4776 | Loss: 299.809 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2150/4776 | Loss: 304.254 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2160/4776 | Loss: 324.968 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2170/4776 | Loss: 294.141 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2180/4776 | Loss: 291.790 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2190/4776 | Loss: 293.220 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2200/4776 | Loss: 301.749 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2210/4776 | Loss: 295.012 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2220/4776 | Loss: 299.594 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2230/4776 | Loss: 286.157 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2240/4776 | Loss: 279.842 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2250/4776 | Loss: 295.221 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2260/4776 | Loss: 278.505 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2270/4776 | Loss: 281.586 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2280/4776 | Loss: 304.650 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2290/4776 | Loss: 255.776 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2300/4776 | Loss: 285.298 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2310/4776 | Loss: 280.932 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2320/4776 | Loss: 303.964 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2330/4776 | Loss: 306.609 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2340/4776 | Loss: 313.055 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2350/4776 | Loss: 298.819 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2360/4776 | Loss: 290.533 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2370/4776 | Loss: 287.484 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2380/4776 | Loss: 287.703 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2390/4776 | Loss: 296.844 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2400/4776 | Loss: 274.680 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2410/4776 | Loss: 300.657 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2420/4776 | Loss: 299.652 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2430/4776 | Loss: 309.423 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2440/4776 | Loss: 283.505 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2450/4776 | Loss: 278.144 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2460/4776 | Loss: 294.737 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2470/4776 | Loss: 302.038 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2480/4776 | Loss: 297.059 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2490/4776 | Loss: 272.295 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2500/4776 | Loss: 287.639 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2510/4776 | Loss: 303.503 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2520/4776 | Loss: 278.040 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2530/4776 | Loss: 248.271 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2540/4776 | Loss: 294.706 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2550/4776 | Loss: 279.830 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2560/4776 | Loss: 277.950 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2570/4776 | Loss: 312.724 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2580/4776 | Loss: 299.204 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2590/4776 | Loss: 279.287 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2600/4776 | Loss: 259.103 | Accuracy: 0.500\n",
      "[Epoch: 14/200] - Step: 2610/4776 | Loss: 277.488 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2620/4776 | Loss: 253.407 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2630/4776 | Loss: 316.688 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2640/4776 | Loss: 307.447 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2650/4776 | Loss: 242.292 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 2660/4776 | Loss: 312.464 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2670/4776 | Loss: 295.964 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2680/4776 | Loss: 299.049 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2690/4776 | Loss: 271.295 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2700/4776 | Loss: 291.452 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2710/4776 | Loss: 274.499 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2720/4776 | Loss: 260.634 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2730/4776 | Loss: 309.617 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2740/4776 | Loss: 322.379 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2750/4776 | Loss: 296.199 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2760/4776 | Loss: 282.329 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2770/4776 | Loss: 294.029 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2780/4776 | Loss: 289.779 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2790/4776 | Loss: 298.010 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2800/4776 | Loss: 287.863 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2810/4776 | Loss: 277.924 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2820/4776 | Loss: 300.987 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2830/4776 | Loss: 299.821 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2840/4776 | Loss: 290.353 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2850/4776 | Loss: 295.064 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2860/4776 | Loss: 271.322 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2870/4776 | Loss: 294.263 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2880/4776 | Loss: 309.936 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2890/4776 | Loss: 295.939 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2900/4776 | Loss: 299.594 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2910/4776 | Loss: 262.945 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2920/4776 | Loss: 289.011 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2930/4776 | Loss: 313.089 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 2940/4776 | Loss: 300.641 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 2950/4776 | Loss: 295.125 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2960/4776 | Loss: 297.143 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2970/4776 | Loss: 293.860 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 2980/4776 | Loss: 279.359 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 2990/4776 | Loss: 288.534 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3000/4776 | Loss: 266.344 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3010/4776 | Loss: 301.015 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3020/4776 | Loss: 293.438 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3030/4776 | Loss: 287.633 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3040/4776 | Loss: 286.673 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3050/4776 | Loss: 289.502 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3060/4776 | Loss: 312.676 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3070/4776 | Loss: 296.161 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3080/4776 | Loss: 307.490 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3090/4776 | Loss: 307.094 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3100/4776 | Loss: 287.684 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3110/4776 | Loss: 271.270 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3120/4776 | Loss: 292.616 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3130/4776 | Loss: 303.962 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3140/4776 | Loss: 298.354 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3150/4776 | Loss: 291.816 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3160/4776 | Loss: 320.258 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3170/4776 | Loss: 292.147 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3180/4776 | Loss: 290.291 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3190/4776 | Loss: 294.406 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3200/4776 | Loss: 289.980 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3210/4776 | Loss: 288.009 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3220/4776 | Loss: 295.512 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3230/4776 | Loss: 290.725 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3240/4776 | Loss: 298.490 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3250/4776 | Loss: 296.678 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3260/4776 | Loss: 316.185 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3270/4776 | Loss: 305.349 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3280/4776 | Loss: 296.010 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3290/4776 | Loss: 278.929 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3300/4776 | Loss: 270.283 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3310/4776 | Loss: 336.613 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3320/4776 | Loss: 280.732 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3330/4776 | Loss: 295.008 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3340/4776 | Loss: 307.750 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3350/4776 | Loss: 319.614 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3360/4776 | Loss: 301.063 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3370/4776 | Loss: 293.027 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3380/4776 | Loss: 283.954 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3390/4776 | Loss: 282.914 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3400/4776 | Loss: 297.586 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3410/4776 | Loss: 293.353 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3420/4776 | Loss: 301.556 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3430/4776 | Loss: 287.619 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3440/4776 | Loss: 286.324 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3450/4776 | Loss: 289.399 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3460/4776 | Loss: 312.786 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3470/4776 | Loss: 299.310 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3480/4776 | Loss: 289.782 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3490/4776 | Loss: 307.472 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3500/4776 | Loss: 291.093 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3510/4776 | Loss: 289.010 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3520/4776 | Loss: 265.362 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3530/4776 | Loss: 310.497 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3540/4776 | Loss: 320.853 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3550/4776 | Loss: 278.036 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3560/4776 | Loss: 287.081 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3570/4776 | Loss: 277.470 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3580/4776 | Loss: 304.128 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3590/4776 | Loss: 308.816 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3600/4776 | Loss: 282.098 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3610/4776 | Loss: 275.724 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3620/4776 | Loss: 261.977 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 3630/4776 | Loss: 308.080 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3640/4776 | Loss: 272.428 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3650/4776 | Loss: 307.989 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3660/4776 | Loss: 326.770 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3670/4776 | Loss: 291.501 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3680/4776 | Loss: 292.710 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3690/4776 | Loss: 274.668 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3700/4776 | Loss: 276.507 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3710/4776 | Loss: 288.747 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3720/4776 | Loss: 313.711 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3730/4776 | Loss: 295.508 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3740/4776 | Loss: 298.632 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3750/4776 | Loss: 281.745 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3760/4776 | Loss: 297.012 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3770/4776 | Loss: 290.429 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3780/4776 | Loss: 293.944 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3790/4776 | Loss: 304.190 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3800/4776 | Loss: 301.142 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3810/4776 | Loss: 297.899 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3820/4776 | Loss: 290.281 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3830/4776 | Loss: 283.432 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3840/4776 | Loss: 284.630 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3850/4776 | Loss: 288.598 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3860/4776 | Loss: 293.167 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3870/4776 | Loss: 291.174 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3880/4776 | Loss: 308.148 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3890/4776 | Loss: 298.358 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3900/4776 | Loss: 294.593 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3910/4776 | Loss: 303.159 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3920/4776 | Loss: 295.468 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3930/4776 | Loss: 286.335 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3940/4776 | Loss: 304.566 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 3950/4776 | Loss: 282.865 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 3960/4776 | Loss: 298.215 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3970/4776 | Loss: 295.086 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 3980/4776 | Loss: 315.887 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 3990/4776 | Loss: 288.708 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4000/4776 | Loss: 295.549 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4010/4776 | Loss: 301.577 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4020/4776 | Loss: 299.614 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4030/4776 | Loss: 291.845 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4040/4776 | Loss: 289.462 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4050/4776 | Loss: 290.945 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4060/4776 | Loss: 292.408 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4070/4776 | Loss: 288.571 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4080/4776 | Loss: 302.276 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4090/4776 | Loss: 285.622 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4100/4776 | Loss: 282.479 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4110/4776 | Loss: 281.676 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4120/4776 | Loss: 277.864 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4130/4776 | Loss: 325.273 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4140/4776 | Loss: 299.907 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4150/4776 | Loss: 290.466 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4160/4776 | Loss: 295.140 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4170/4776 | Loss: 319.855 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4180/4776 | Loss: 288.409 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4190/4776 | Loss: 282.336 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4200/4776 | Loss: 282.565 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4210/4776 | Loss: 299.581 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4220/4776 | Loss: 264.583 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4230/4776 | Loss: 267.208 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4240/4776 | Loss: 283.748 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4250/4776 | Loss: 271.981 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4260/4776 | Loss: 322.493 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4270/4776 | Loss: 310.967 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4280/4776 | Loss: 300.270 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4290/4776 | Loss: 323.744 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4300/4776 | Loss: 292.112 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4310/4776 | Loss: 281.623 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4320/4776 | Loss: 273.890 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4330/4776 | Loss: 306.027 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4340/4776 | Loss: 309.578 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4350/4776 | Loss: 308.170 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4360/4776 | Loss: 298.992 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4370/4776 | Loss: 297.133 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4380/4776 | Loss: 303.534 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4390/4776 | Loss: 295.985 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4400/4776 | Loss: 278.667 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 4410/4776 | Loss: 294.198 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4420/4776 | Loss: 270.314 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4430/4776 | Loss: 302.618 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4440/4776 | Loss: 282.239 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4450/4776 | Loss: 305.268 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4460/4776 | Loss: 308.718 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4470/4776 | Loss: 296.182 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4480/4776 | Loss: 297.646 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4490/4776 | Loss: 303.583 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4500/4776 | Loss: 319.491 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4510/4776 | Loss: 292.938 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4520/4776 | Loss: 281.946 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 4530/4776 | Loss: 289.491 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4540/4776 | Loss: 287.609 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4550/4776 | Loss: 301.499 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4560/4776 | Loss: 294.261 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4570/4776 | Loss: 299.610 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4580/4776 | Loss: 277.351 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4590/4776 | Loss: 290.922 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4600/4776 | Loss: 307.909 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4610/4776 | Loss: 282.981 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4620/4776 | Loss: 272.652 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4630/4776 | Loss: 294.612 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4640/4776 | Loss: 293.922 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4650/4776 | Loss: 304.848 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4660/4776 | Loss: 300.113 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4670/4776 | Loss: 286.355 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4680/4776 | Loss: 297.133 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4690/4776 | Loss: 299.424 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4700/4776 | Loss: 278.694 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 4710/4776 | Loss: 316.212 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4720/4776 | Loss: 294.361 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4730/4776 | Loss: 301.702 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 4740/4776 | Loss: 297.305 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4750/4776 | Loss: 301.029 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 4760/4776 | Loss: 280.620 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 4770/4776 | Loss: 302.879 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 15/200] - Step: 10/4776 | Loss: 296.935 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 20/4776 | Loss: 301.922 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 30/4776 | Loss: 294.138 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 40/4776 | Loss: 303.052 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 50/4776 | Loss: 288.028 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 60/4776 | Loss: 288.094 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 70/4776 | Loss: 294.371 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 80/4776 | Loss: 320.047 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 90/4776 | Loss: 299.803 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 100/4776 | Loss: 290.122 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 110/4776 | Loss: 263.510 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 120/4776 | Loss: 287.690 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 130/4776 | Loss: 300.921 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 140/4776 | Loss: 276.029 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 150/4776 | Loss: 291.006 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 160/4776 | Loss: 306.931 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 170/4776 | Loss: 317.784 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 180/4776 | Loss: 300.057 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 190/4776 | Loss: 309.714 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 200/4776 | Loss: 275.361 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 210/4776 | Loss: 279.930 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 220/4776 | Loss: 315.975 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 230/4776 | Loss: 294.045 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 240/4776 | Loss: 276.752 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 250/4776 | Loss: 284.442 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 260/4776 | Loss: 288.236 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 270/4776 | Loss: 301.562 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 280/4776 | Loss: 316.017 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 290/4776 | Loss: 309.337 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 300/4776 | Loss: 293.775 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 310/4776 | Loss: 300.618 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 320/4776 | Loss: 292.227 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 330/4776 | Loss: 270.686 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 340/4776 | Loss: 291.270 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 350/4776 | Loss: 295.951 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 360/4776 | Loss: 282.228 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 370/4776 | Loss: 273.648 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 380/4776 | Loss: 274.315 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 390/4776 | Loss: 293.071 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 400/4776 | Loss: 297.127 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 410/4776 | Loss: 295.554 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 420/4776 | Loss: 292.624 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 430/4776 | Loss: 307.293 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 440/4776 | Loss: 267.277 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 450/4776 | Loss: 299.563 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 460/4776 | Loss: 264.547 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 470/4776 | Loss: 276.970 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 480/4776 | Loss: 305.930 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 490/4776 | Loss: 303.029 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 500/4776 | Loss: 290.140 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 510/4776 | Loss: 288.976 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 520/4776 | Loss: 292.815 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 530/4776 | Loss: 275.232 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 540/4776 | Loss: 309.913 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 550/4776 | Loss: 304.133 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 560/4776 | Loss: 279.660 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 570/4776 | Loss: 275.738 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 580/4776 | Loss: 309.332 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 590/4776 | Loss: 291.459 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 600/4776 | Loss: 295.725 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 610/4776 | Loss: 290.330 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 620/4776 | Loss: 293.187 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 630/4776 | Loss: 291.945 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 640/4776 | Loss: 310.956 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 650/4776 | Loss: 290.590 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 660/4776 | Loss: 287.046 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 670/4776 | Loss: 272.992 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 680/4776 | Loss: 274.085 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 690/4776 | Loss: 298.428 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 700/4776 | Loss: 301.040 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 710/4776 | Loss: 295.470 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 720/4776 | Loss: 296.530 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 730/4776 | Loss: 298.287 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 740/4776 | Loss: 281.390 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 750/4776 | Loss: 328.744 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 760/4776 | Loss: 287.420 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 770/4776 | Loss: 303.519 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 780/4776 | Loss: 269.664 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 790/4776 | Loss: 289.226 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 800/4776 | Loss: 294.872 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 810/4776 | Loss: 290.910 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 820/4776 | Loss: 306.301 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 830/4776 | Loss: 285.639 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 840/4776 | Loss: 271.279 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 850/4776 | Loss: 299.904 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 860/4776 | Loss: 289.374 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 870/4776 | Loss: 303.423 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 880/4776 | Loss: 289.766 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 890/4776 | Loss: 291.907 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 900/4776 | Loss: 267.866 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 910/4776 | Loss: 306.842 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 920/4776 | Loss: 290.498 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 930/4776 | Loss: 252.484 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 940/4776 | Loss: 286.695 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 950/4776 | Loss: 308.205 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 960/4776 | Loss: 310.597 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 970/4776 | Loss: 304.624 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 980/4776 | Loss: 303.331 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 990/4776 | Loss: 293.322 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1000/4776 | Loss: 288.910 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1010/4776 | Loss: 290.879 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1020/4776 | Loss: 306.854 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1030/4776 | Loss: 313.135 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1040/4776 | Loss: 285.119 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1050/4776 | Loss: 288.511 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1060/4776 | Loss: 322.740 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1070/4776 | Loss: 309.436 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1080/4776 | Loss: 291.362 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1090/4776 | Loss: 306.631 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1100/4776 | Loss: 282.787 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1110/4776 | Loss: 289.908 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1120/4776 | Loss: 307.219 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1130/4776 | Loss: 285.452 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1140/4776 | Loss: 292.027 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1150/4776 | Loss: 285.223 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1160/4776 | Loss: 324.823 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1170/4776 | Loss: 293.078 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1180/4776 | Loss: 301.687 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1190/4776 | Loss: 290.541 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1200/4776 | Loss: 287.890 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1210/4776 | Loss: 270.035 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1220/4776 | Loss: 286.761 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1230/4776 | Loss: 319.555 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1240/4776 | Loss: 296.680 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1250/4776 | Loss: 314.310 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1260/4776 | Loss: 308.796 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1270/4776 | Loss: 273.323 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 1280/4776 | Loss: 292.810 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1290/4776 | Loss: 304.336 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1300/4776 | Loss: 290.105 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1310/4776 | Loss: 289.268 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1320/4776 | Loss: 285.763 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1330/4776 | Loss: 287.596 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1340/4776 | Loss: 316.762 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1350/4776 | Loss: 288.835 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1360/4776 | Loss: 295.688 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1370/4776 | Loss: 303.308 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1380/4776 | Loss: 301.344 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1390/4776 | Loss: 299.041 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1400/4776 | Loss: 296.923 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1410/4776 | Loss: 281.251 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1420/4776 | Loss: 295.783 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1430/4776 | Loss: 277.128 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 1440/4776 | Loss: 315.828 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1450/4776 | Loss: 296.625 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1460/4776 | Loss: 307.633 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1470/4776 | Loss: 286.358 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1480/4776 | Loss: 300.040 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1490/4776 | Loss: 282.478 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1500/4776 | Loss: 304.968 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1510/4776 | Loss: 289.971 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1520/4776 | Loss: 293.042 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1530/4776 | Loss: 289.447 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1540/4776 | Loss: 304.018 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1550/4776 | Loss: 315.113 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1560/4776 | Loss: 279.015 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1570/4776 | Loss: 304.702 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1580/4776 | Loss: 291.350 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1590/4776 | Loss: 305.950 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1600/4776 | Loss: 287.344 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1610/4776 | Loss: 300.003 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1620/4776 | Loss: 284.440 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1630/4776 | Loss: 293.297 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1640/4776 | Loss: 268.682 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1650/4776 | Loss: 321.010 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1660/4776 | Loss: 289.383 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1670/4776 | Loss: 299.808 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1680/4776 | Loss: 295.730 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1690/4776 | Loss: 283.479 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1700/4776 | Loss: 269.156 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1710/4776 | Loss: 291.208 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1720/4776 | Loss: 286.592 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1730/4776 | Loss: 297.240 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1740/4776 | Loss: 285.581 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1750/4776 | Loss: 268.316 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1760/4776 | Loss: 280.463 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1770/4776 | Loss: 285.095 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1780/4776 | Loss: 263.478 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1790/4776 | Loss: 309.111 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1800/4776 | Loss: 282.012 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1810/4776 | Loss: 287.811 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1820/4776 | Loss: 302.508 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1830/4776 | Loss: 296.759 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1840/4776 | Loss: 312.174 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1850/4776 | Loss: 296.229 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1860/4776 | Loss: 328.499 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1870/4776 | Loss: 312.120 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1880/4776 | Loss: 286.972 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1890/4776 | Loss: 298.492 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1900/4776 | Loss: 292.389 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1910/4776 | Loss: 301.413 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1920/4776 | Loss: 307.338 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1930/4776 | Loss: 288.496 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1940/4776 | Loss: 295.254 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1950/4776 | Loss: 288.451 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1960/4776 | Loss: 287.287 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1970/4776 | Loss: 299.905 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1980/4776 | Loss: 288.636 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1990/4776 | Loss: 284.288 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2000/4776 | Loss: 283.541 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2010/4776 | Loss: 279.245 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2020/4776 | Loss: 278.530 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2030/4776 | Loss: 290.325 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2040/4776 | Loss: 270.676 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2050/4776 | Loss: 285.629 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2060/4776 | Loss: 260.469 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2070/4776 | Loss: 317.810 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2080/4776 | Loss: 284.463 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2090/4776 | Loss: 298.288 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2100/4776 | Loss: 291.466 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2110/4776 | Loss: 281.840 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2120/4776 | Loss: 324.469 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2130/4776 | Loss: 307.000 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2140/4776 | Loss: 310.744 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2150/4776 | Loss: 287.533 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2160/4776 | Loss: 299.300 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2170/4776 | Loss: 304.333 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2180/4776 | Loss: 286.836 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2190/4776 | Loss: 310.233 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2200/4776 | Loss: 279.149 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2210/4776 | Loss: 306.153 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2220/4776 | Loss: 303.149 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2230/4776 | Loss: 282.155 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2240/4776 | Loss: 246.427 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2250/4776 | Loss: 294.560 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2260/4776 | Loss: 273.519 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2270/4776 | Loss: 299.628 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2280/4776 | Loss: 296.811 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2290/4776 | Loss: 272.746 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 2300/4776 | Loss: 306.728 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2310/4776 | Loss: 302.536 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2320/4776 | Loss: 304.368 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2330/4776 | Loss: 303.448 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2340/4776 | Loss: 279.104 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2350/4776 | Loss: 279.747 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2360/4776 | Loss: 305.298 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2370/4776 | Loss: 305.367 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2380/4776 | Loss: 296.804 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2390/4776 | Loss: 282.271 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2400/4776 | Loss: 301.386 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2410/4776 | Loss: 301.442 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2420/4776 | Loss: 291.377 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2430/4776 | Loss: 287.627 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2440/4776 | Loss: 320.614 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2450/4776 | Loss: 291.717 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2460/4776 | Loss: 304.849 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2470/4776 | Loss: 268.700 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2480/4776 | Loss: 278.388 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2490/4776 | Loss: 276.657 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2500/4776 | Loss: 315.288 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2510/4776 | Loss: 309.699 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2520/4776 | Loss: 279.741 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2530/4776 | Loss: 320.680 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2540/4776 | Loss: 295.006 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2550/4776 | Loss: 298.634 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2560/4776 | Loss: 313.361 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2570/4776 | Loss: 303.037 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2580/4776 | Loss: 297.905 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2590/4776 | Loss: 306.231 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2600/4776 | Loss: 293.624 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2610/4776 | Loss: 296.979 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2620/4776 | Loss: 286.956 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2630/4776 | Loss: 286.337 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2640/4776 | Loss: 326.155 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2650/4776 | Loss: 286.907 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2660/4776 | Loss: 291.524 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2670/4776 | Loss: 288.014 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2680/4776 | Loss: 298.334 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2690/4776 | Loss: 279.798 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2700/4776 | Loss: 295.491 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2710/4776 | Loss: 286.799 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2720/4776 | Loss: 279.694 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2730/4776 | Loss: 300.995 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2740/4776 | Loss: 307.930 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2750/4776 | Loss: 281.724 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2760/4776 | Loss: 300.690 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2770/4776 | Loss: 302.815 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2780/4776 | Loss: 287.764 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2790/4776 | Loss: 302.960 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2800/4776 | Loss: 263.087 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2810/4776 | Loss: 307.345 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2820/4776 | Loss: 276.688 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2830/4776 | Loss: 295.007 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2840/4776 | Loss: 292.109 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2850/4776 | Loss: 311.088 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2860/4776 | Loss: 298.695 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2870/4776 | Loss: 293.419 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2880/4776 | Loss: 305.808 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2890/4776 | Loss: 282.105 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2900/4776 | Loss: 279.282 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2910/4776 | Loss: 315.113 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 2920/4776 | Loss: 274.742 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2930/4776 | Loss: 276.850 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2940/4776 | Loss: 282.030 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 2950/4776 | Loss: 268.192 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2960/4776 | Loss: 266.651 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2970/4776 | Loss: 278.864 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 2980/4776 | Loss: 293.851 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 2990/4776 | Loss: 325.247 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3000/4776 | Loss: 278.945 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3010/4776 | Loss: 292.408 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3020/4776 | Loss: 296.382 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3030/4776 | Loss: 310.359 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3040/4776 | Loss: 303.374 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3050/4776 | Loss: 281.767 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3060/4776 | Loss: 281.147 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3070/4776 | Loss: 336.290 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3080/4776 | Loss: 261.661 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3090/4776 | Loss: 281.704 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3100/4776 | Loss: 309.045 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3110/4776 | Loss: 294.995 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3120/4776 | Loss: 276.397 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 3130/4776 | Loss: 298.397 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3140/4776 | Loss: 290.613 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3150/4776 | Loss: 278.796 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3160/4776 | Loss: 298.609 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3170/4776 | Loss: 287.050 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3180/4776 | Loss: 272.939 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3190/4776 | Loss: 272.973 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3200/4776 | Loss: 271.811 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3210/4776 | Loss: 288.714 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3220/4776 | Loss: 288.235 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3230/4776 | Loss: 288.502 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3240/4776 | Loss: 294.793 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3250/4776 | Loss: 286.934 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3260/4776 | Loss: 269.522 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 3270/4776 | Loss: 293.039 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3280/4776 | Loss: 283.270 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3290/4776 | Loss: 308.069 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3300/4776 | Loss: 311.011 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3310/4776 | Loss: 294.321 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3320/4776 | Loss: 307.877 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3330/4776 | Loss: 298.110 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3340/4776 | Loss: 283.852 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3350/4776 | Loss: 295.449 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3360/4776 | Loss: 301.823 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3370/4776 | Loss: 305.107 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3380/4776 | Loss: 287.816 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3390/4776 | Loss: 301.441 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3400/4776 | Loss: 289.250 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3410/4776 | Loss: 296.017 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3420/4776 | Loss: 298.799 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3430/4776 | Loss: 303.188 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3440/4776 | Loss: 294.236 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3450/4776 | Loss: 288.955 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3460/4776 | Loss: 296.943 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3470/4776 | Loss: 292.351 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3480/4776 | Loss: 287.808 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3490/4776 | Loss: 263.641 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3500/4776 | Loss: 287.246 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3510/4776 | Loss: 314.856 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3520/4776 | Loss: 265.243 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3530/4776 | Loss: 288.624 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3540/4776 | Loss: 289.989 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3550/4776 | Loss: 295.242 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3560/4776 | Loss: 296.233 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3570/4776 | Loss: 300.071 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3580/4776 | Loss: 316.341 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3590/4776 | Loss: 269.399 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 3600/4776 | Loss: 275.448 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3610/4776 | Loss: 294.034 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3620/4776 | Loss: 301.014 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3630/4776 | Loss: 284.444 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3640/4776 | Loss: 293.663 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3650/4776 | Loss: 299.703 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3660/4776 | Loss: 299.032 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3670/4776 | Loss: 298.034 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3680/4776 | Loss: 289.386 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3690/4776 | Loss: 308.429 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3700/4776 | Loss: 318.159 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3710/4776 | Loss: 293.393 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3720/4776 | Loss: 298.343 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3730/4776 | Loss: 314.861 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3740/4776 | Loss: 294.270 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3750/4776 | Loss: 287.144 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3760/4776 | Loss: 277.297 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3770/4776 | Loss: 276.230 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3780/4776 | Loss: 295.251 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3790/4776 | Loss: 277.335 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3800/4776 | Loss: 276.544 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3810/4776 | Loss: 283.653 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3820/4776 | Loss: 275.178 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3830/4776 | Loss: 294.609 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3840/4776 | Loss: 286.556 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3850/4776 | Loss: 307.396 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3860/4776 | Loss: 285.250 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3870/4776 | Loss: 303.388 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3880/4776 | Loss: 317.701 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3890/4776 | Loss: 314.901 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3900/4776 | Loss: 287.334 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 3910/4776 | Loss: 307.716 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3920/4776 | Loss: 322.178 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3930/4776 | Loss: 296.648 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3940/4776 | Loss: 290.683 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3950/4776 | Loss: 307.619 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 3960/4776 | Loss: 305.219 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3970/4776 | Loss: 289.160 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 3980/4776 | Loss: 282.212 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 3990/4776 | Loss: 304.380 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4000/4776 | Loss: 298.933 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4010/4776 | Loss: 295.000 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4020/4776 | Loss: 283.414 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4030/4776 | Loss: 299.023 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4040/4776 | Loss: 296.129 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4050/4776 | Loss: 306.822 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4060/4776 | Loss: 290.469 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4070/4776 | Loss: 291.539 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4080/4776 | Loss: 295.664 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4090/4776 | Loss: 305.789 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4100/4776 | Loss: 291.362 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4110/4776 | Loss: 289.018 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4120/4776 | Loss: 294.197 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4130/4776 | Loss: 300.926 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4140/4776 | Loss: 288.792 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4150/4776 | Loss: 256.458 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4160/4776 | Loss: 305.878 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4170/4776 | Loss: 289.112 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4180/4776 | Loss: 291.452 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4190/4776 | Loss: 302.786 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4200/4776 | Loss: 303.579 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4210/4776 | Loss: 295.093 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4220/4776 | Loss: 302.739 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4230/4776 | Loss: 283.536 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4240/4776 | Loss: 303.611 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4250/4776 | Loss: 284.515 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4260/4776 | Loss: 283.021 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4270/4776 | Loss: 269.667 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4280/4776 | Loss: 293.690 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4290/4776 | Loss: 306.530 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4300/4776 | Loss: 301.666 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4310/4776 | Loss: 292.390 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4320/4776 | Loss: 287.578 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4330/4776 | Loss: 247.836 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4340/4776 | Loss: 312.873 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4350/4776 | Loss: 283.132 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4360/4776 | Loss: 293.395 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4370/4776 | Loss: 255.613 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4380/4776 | Loss: 316.076 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4390/4776 | Loss: 295.389 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4400/4776 | Loss: 268.060 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4410/4776 | Loss: 268.441 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4420/4776 | Loss: 289.091 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4430/4776 | Loss: 307.007 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4440/4776 | Loss: 302.903 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4450/4776 | Loss: 296.958 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4460/4776 | Loss: 315.982 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4470/4776 | Loss: 295.085 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4480/4776 | Loss: 297.445 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4490/4776 | Loss: 290.270 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4500/4776 | Loss: 299.008 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4510/4776 | Loss: 303.678 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4520/4776 | Loss: 275.262 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4530/4776 | Loss: 274.565 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 4540/4776 | Loss: 269.619 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4550/4776 | Loss: 264.375 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4560/4776 | Loss: 279.422 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4570/4776 | Loss: 286.387 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4580/4776 | Loss: 304.626 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4590/4776 | Loss: 278.120 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4600/4776 | Loss: 295.076 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4610/4776 | Loss: 302.316 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4620/4776 | Loss: 278.291 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4630/4776 | Loss: 290.725 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4640/4776 | Loss: 308.418 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4650/4776 | Loss: 309.764 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4660/4776 | Loss: 290.111 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4670/4776 | Loss: 292.092 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4680/4776 | Loss: 252.749 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 4690/4776 | Loss: 309.378 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4700/4776 | Loss: 309.783 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4710/4776 | Loss: 317.230 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4720/4776 | Loss: 298.367 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4730/4776 | Loss: 290.257 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4740/4776 | Loss: 269.323 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 4750/4776 | Loss: 267.824 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 4760/4776 | Loss: 301.219 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 4770/4776 | Loss: 299.339 | Accuracy: 0.100\n",
      "Accuracy:  0.10983606557377049\n",
      "[Epoch: 16/200] - Step: 10/4776 | Loss: 298.762 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 20/4776 | Loss: 281.355 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 30/4776 | Loss: 291.512 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 40/4776 | Loss: 276.195 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 50/4776 | Loss: 295.228 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 60/4776 | Loss: 276.198 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 70/4776 | Loss: 282.931 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 80/4776 | Loss: 279.722 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 90/4776 | Loss: 288.176 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 100/4776 | Loss: 284.213 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 110/4776 | Loss: 278.815 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 120/4776 | Loss: 269.568 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 130/4776 | Loss: 319.810 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 140/4776 | Loss: 260.360 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 150/4776 | Loss: 283.018 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 160/4776 | Loss: 289.800 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 170/4776 | Loss: 307.860 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 180/4776 | Loss: 295.047 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 190/4776 | Loss: 238.026 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 200/4776 | Loss: 292.696 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 210/4776 | Loss: 319.551 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 220/4776 | Loss: 299.680 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 230/4776 | Loss: 271.457 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 240/4776 | Loss: 277.272 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 250/4776 | Loss: 274.952 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 260/4776 | Loss: 296.153 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 270/4776 | Loss: 308.993 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 280/4776 | Loss: 271.879 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 290/4776 | Loss: 279.724 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 300/4776 | Loss: 295.895 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 310/4776 | Loss: 322.000 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 320/4776 | Loss: 292.611 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 330/4776 | Loss: 299.655 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 340/4776 | Loss: 284.844 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 350/4776 | Loss: 294.469 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 360/4776 | Loss: 292.862 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 370/4776 | Loss: 301.019 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 380/4776 | Loss: 291.738 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 390/4776 | Loss: 289.354 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 400/4776 | Loss: 278.236 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 410/4776 | Loss: 299.108 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 420/4776 | Loss: 288.833 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 430/4776 | Loss: 270.333 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 440/4776 | Loss: 312.976 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 450/4776 | Loss: 276.407 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 460/4776 | Loss: 273.922 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 470/4776 | Loss: 306.488 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 480/4776 | Loss: 312.245 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 490/4776 | Loss: 254.532 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 500/4776 | Loss: 304.400 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 510/4776 | Loss: 307.277 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 520/4776 | Loss: 308.292 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 530/4776 | Loss: 299.915 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 540/4776 | Loss: 297.564 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 550/4776 | Loss: 285.492 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 560/4776 | Loss: 279.977 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 570/4776 | Loss: 298.644 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 580/4776 | Loss: 291.221 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 590/4776 | Loss: 280.335 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 600/4776 | Loss: 305.154 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 610/4776 | Loss: 287.753 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 620/4776 | Loss: 314.146 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 630/4776 | Loss: 286.968 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 640/4776 | Loss: 306.037 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 650/4776 | Loss: 283.197 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 660/4776 | Loss: 293.848 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 670/4776 | Loss: 297.744 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 680/4776 | Loss: 301.058 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 690/4776 | Loss: 251.805 | Accuracy: 0.500\n",
      "[Epoch: 16/200] - Step: 700/4776 | Loss: 283.376 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 710/4776 | Loss: 331.637 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 720/4776 | Loss: 293.871 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 730/4776 | Loss: 303.856 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 740/4776 | Loss: 287.803 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 750/4776 | Loss: 278.895 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 760/4776 | Loss: 304.395 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 770/4776 | Loss: 276.447 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 780/4776 | Loss: 287.519 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 790/4776 | Loss: 291.871 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 800/4776 | Loss: 291.268 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 810/4776 | Loss: 295.106 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 820/4776 | Loss: 306.528 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 830/4776 | Loss: 285.423 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 840/4776 | Loss: 295.984 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 850/4776 | Loss: 299.041 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 860/4776 | Loss: 300.785 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 870/4776 | Loss: 290.017 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 880/4776 | Loss: 296.401 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 890/4776 | Loss: 300.451 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 900/4776 | Loss: 307.976 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 910/4776 | Loss: 300.314 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 920/4776 | Loss: 312.982 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 930/4776 | Loss: 286.139 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 940/4776 | Loss: 309.162 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 950/4776 | Loss: 291.263 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 960/4776 | Loss: 273.045 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 970/4776 | Loss: 300.838 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 980/4776 | Loss: 271.606 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 990/4776 | Loss: 295.271 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1000/4776 | Loss: 264.796 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 1010/4776 | Loss: 281.259 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1020/4776 | Loss: 279.593 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1030/4776 | Loss: 280.499 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1040/4776 | Loss: 288.056 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1050/4776 | Loss: 264.766 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1060/4776 | Loss: 330.867 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1070/4776 | Loss: 259.175 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1080/4776 | Loss: 296.062 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1090/4776 | Loss: 289.732 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1100/4776 | Loss: 293.040 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1110/4776 | Loss: 260.285 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1120/4776 | Loss: 303.352 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1130/4776 | Loss: 300.204 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1140/4776 | Loss: 290.806 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1150/4776 | Loss: 273.048 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 1160/4776 | Loss: 266.994 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1170/4776 | Loss: 286.768 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1180/4776 | Loss: 282.015 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1190/4776 | Loss: 300.255 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1200/4776 | Loss: 305.242 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1210/4776 | Loss: 269.358 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1220/4776 | Loss: 303.454 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1230/4776 | Loss: 290.531 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1240/4776 | Loss: 354.459 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1250/4776 | Loss: 315.810 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1260/4776 | Loss: 276.960 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1270/4776 | Loss: 290.258 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1280/4776 | Loss: 293.285 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 1290/4776 | Loss: 261.746 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1300/4776 | Loss: 281.056 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1310/4776 | Loss: 308.055 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1320/4776 | Loss: 292.984 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1330/4776 | Loss: 290.084 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1340/4776 | Loss: 275.683 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1350/4776 | Loss: 284.027 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1360/4776 | Loss: 273.472 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1370/4776 | Loss: 296.650 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1380/4776 | Loss: 283.667 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1390/4776 | Loss: 286.559 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1400/4776 | Loss: 278.187 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1410/4776 | Loss: 297.969 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1420/4776 | Loss: 328.417 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1430/4776 | Loss: 313.218 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1440/4776 | Loss: 259.500 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1450/4776 | Loss: 291.429 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1460/4776 | Loss: 295.162 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1470/4776 | Loss: 284.634 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1480/4776 | Loss: 296.312 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1490/4776 | Loss: 295.690 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1500/4776 | Loss: 270.967 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1510/4776 | Loss: 291.166 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1520/4776 | Loss: 299.243 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1530/4776 | Loss: 285.030 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1540/4776 | Loss: 275.760 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1550/4776 | Loss: 294.034 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1560/4776 | Loss: 306.484 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1570/4776 | Loss: 290.700 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1580/4776 | Loss: 296.677 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1590/4776 | Loss: 275.838 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1600/4776 | Loss: 264.402 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1610/4776 | Loss: 278.656 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1620/4776 | Loss: 283.438 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1630/4776 | Loss: 296.018 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1640/4776 | Loss: 291.164 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1650/4776 | Loss: 297.775 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1660/4776 | Loss: 289.865 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1670/4776 | Loss: 266.389 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1680/4776 | Loss: 296.874 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1690/4776 | Loss: 295.842 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1700/4776 | Loss: 290.933 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1710/4776 | Loss: 322.094 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1720/4776 | Loss: 289.882 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1730/4776 | Loss: 294.299 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1740/4776 | Loss: 320.621 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1750/4776 | Loss: 286.490 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1760/4776 | Loss: 279.271 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1770/4776 | Loss: 292.495 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1780/4776 | Loss: 288.966 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1790/4776 | Loss: 285.439 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1800/4776 | Loss: 297.532 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1810/4776 | Loss: 274.279 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1820/4776 | Loss: 263.467 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1830/4776 | Loss: 305.219 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1840/4776 | Loss: 284.612 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1850/4776 | Loss: 300.253 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1860/4776 | Loss: 302.144 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1870/4776 | Loss: 302.208 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1880/4776 | Loss: 299.217 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1890/4776 | Loss: 283.962 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1900/4776 | Loss: 281.444 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1910/4776 | Loss: 306.086 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1920/4776 | Loss: 306.114 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1930/4776 | Loss: 294.662 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1940/4776 | Loss: 279.153 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1950/4776 | Loss: 275.344 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1960/4776 | Loss: 289.610 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1970/4776 | Loss: 293.025 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1980/4776 | Loss: 303.494 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1990/4776 | Loss: 282.860 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2000/4776 | Loss: 288.911 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2010/4776 | Loss: 290.338 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2020/4776 | Loss: 280.905 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2030/4776 | Loss: 302.048 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2040/4776 | Loss: 293.582 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2050/4776 | Loss: 290.938 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2060/4776 | Loss: 278.757 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2070/4776 | Loss: 300.870 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2080/4776 | Loss: 294.339 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2090/4776 | Loss: 300.247 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2100/4776 | Loss: 277.177 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2110/4776 | Loss: 297.856 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2120/4776 | Loss: 295.235 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2130/4776 | Loss: 293.468 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2140/4776 | Loss: 288.399 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2150/4776 | Loss: 284.748 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2160/4776 | Loss: 253.851 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2170/4776 | Loss: 275.068 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2180/4776 | Loss: 268.543 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2190/4776 | Loss: 298.617 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2200/4776 | Loss: 293.561 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2210/4776 | Loss: 217.565 | Accuracy: 0.500\n",
      "[Epoch: 16/200] - Step: 2220/4776 | Loss: 272.877 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2230/4776 | Loss: 276.957 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2240/4776 | Loss: 294.307 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2250/4776 | Loss: 291.462 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2260/4776 | Loss: 283.775 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2270/4776 | Loss: 292.025 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2280/4776 | Loss: 224.213 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2290/4776 | Loss: 292.021 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2300/4776 | Loss: 287.139 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2310/4776 | Loss: 268.443 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2320/4776 | Loss: 303.604 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2330/4776 | Loss: 241.756 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 2340/4776 | Loss: 293.784 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2350/4776 | Loss: 253.320 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2360/4776 | Loss: 302.345 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2370/4776 | Loss: 306.271 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2380/4776 | Loss: 298.113 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2390/4776 | Loss: 290.200 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2400/4776 | Loss: 292.157 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2410/4776 | Loss: 279.078 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2420/4776 | Loss: 246.975 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2430/4776 | Loss: 301.220 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2440/4776 | Loss: 297.805 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2450/4776 | Loss: 283.872 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2460/4776 | Loss: 277.604 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2470/4776 | Loss: 311.753 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2480/4776 | Loss: 267.285 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2490/4776 | Loss: 245.396 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 2500/4776 | Loss: 279.459 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2510/4776 | Loss: 228.431 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2520/4776 | Loss: 256.863 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2530/4776 | Loss: 347.644 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2540/4776 | Loss: 282.914 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2550/4776 | Loss: 292.122 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2560/4776 | Loss: 301.088 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2570/4776 | Loss: 324.861 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2580/4776 | Loss: 288.471 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2590/4776 | Loss: 312.881 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2600/4776 | Loss: 298.759 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2610/4776 | Loss: 275.232 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2620/4776 | Loss: 287.942 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2630/4776 | Loss: 295.290 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2640/4776 | Loss: 280.269 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2650/4776 | Loss: 246.704 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2660/4776 | Loss: 296.524 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2670/4776 | Loss: 284.691 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2680/4776 | Loss: 284.690 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2690/4776 | Loss: 275.998 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2700/4776 | Loss: 276.775 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2710/4776 | Loss: 299.950 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2720/4776 | Loss: 272.986 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2730/4776 | Loss: 252.315 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 2740/4776 | Loss: 265.694 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2750/4776 | Loss: 273.472 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2760/4776 | Loss: 278.749 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2770/4776 | Loss: 276.138 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2780/4776 | Loss: 265.941 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2790/4776 | Loss: 261.506 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2800/4776 | Loss: 284.224 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2810/4776 | Loss: 282.202 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2820/4776 | Loss: 281.362 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2830/4776 | Loss: 281.078 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2840/4776 | Loss: 283.422 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2850/4776 | Loss: 276.315 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2860/4776 | Loss: 275.764 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2870/4776 | Loss: 297.363 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2880/4776 | Loss: 269.802 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 2890/4776 | Loss: 306.944 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2900/4776 | Loss: 259.430 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2910/4776 | Loss: 300.433 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2920/4776 | Loss: 268.914 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2930/4776 | Loss: 262.230 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2940/4776 | Loss: 291.067 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2950/4776 | Loss: 265.093 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 2960/4776 | Loss: 292.301 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 2970/4776 | Loss: 292.793 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2980/4776 | Loss: 283.511 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 2990/4776 | Loss: 258.780 | Accuracy: 0.500\n",
      "[Epoch: 16/200] - Step: 3000/4776 | Loss: 284.512 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3010/4776 | Loss: 275.530 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3020/4776 | Loss: 322.375 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3030/4776 | Loss: 268.786 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3040/4776 | Loss: 275.865 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3050/4776 | Loss: 261.453 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3060/4776 | Loss: 297.355 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3070/4776 | Loss: 239.321 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3080/4776 | Loss: 250.730 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3090/4776 | Loss: 257.183 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3100/4776 | Loss: 286.326 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3110/4776 | Loss: 309.267 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3120/4776 | Loss: 238.793 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3130/4776 | Loss: 318.462 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3140/4776 | Loss: 315.945 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3150/4776 | Loss: 264.899 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3160/4776 | Loss: 284.898 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3170/4776 | Loss: 265.055 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3180/4776 | Loss: 309.782 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3190/4776 | Loss: 282.064 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3200/4776 | Loss: 278.451 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3210/4776 | Loss: 287.618 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3220/4776 | Loss: 267.892 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3230/4776 | Loss: 313.707 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3240/4776 | Loss: 299.343 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3250/4776 | Loss: 289.016 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3260/4776 | Loss: 266.444 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3270/4776 | Loss: 275.464 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3280/4776 | Loss: 284.083 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3290/4776 | Loss: 221.888 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 3300/4776 | Loss: 250.094 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3310/4776 | Loss: 292.277 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3320/4776 | Loss: 268.365 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3330/4776 | Loss: 311.076 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3340/4776 | Loss: 304.289 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3350/4776 | Loss: 286.897 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3360/4776 | Loss: 249.361 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3370/4776 | Loss: 283.606 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3380/4776 | Loss: 271.662 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3390/4776 | Loss: 271.700 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3400/4776 | Loss: 284.334 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3410/4776 | Loss: 270.434 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3420/4776 | Loss: 258.528 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3430/4776 | Loss: 305.669 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3440/4776 | Loss: 253.419 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3450/4776 | Loss: 272.405 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3460/4776 | Loss: 257.080 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3470/4776 | Loss: 236.088 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3480/4776 | Loss: 261.898 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3490/4776 | Loss: 294.943 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3500/4776 | Loss: 264.940 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3510/4776 | Loss: 318.570 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3520/4776 | Loss: 293.229 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3530/4776 | Loss: 265.271 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3540/4776 | Loss: 265.426 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3550/4776 | Loss: 283.374 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3560/4776 | Loss: 270.000 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3570/4776 | Loss: 282.960 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3580/4776 | Loss: 256.073 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3590/4776 | Loss: 265.852 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3600/4776 | Loss: 250.218 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3610/4776 | Loss: 326.916 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3620/4776 | Loss: 274.952 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3630/4776 | Loss: 274.106 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3640/4776 | Loss: 278.967 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3650/4776 | Loss: 272.544 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3660/4776 | Loss: 265.767 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3670/4776 | Loss: 282.162 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3680/4776 | Loss: 270.531 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3690/4776 | Loss: 286.561 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3700/4776 | Loss: 292.191 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3710/4776 | Loss: 260.691 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3720/4776 | Loss: 261.554 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3730/4776 | Loss: 286.393 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3740/4776 | Loss: 261.095 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3750/4776 | Loss: 283.382 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3760/4776 | Loss: 294.689 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3770/4776 | Loss: 273.241 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3780/4776 | Loss: 293.097 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3790/4776 | Loss: 274.213 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3800/4776 | Loss: 285.144 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3810/4776 | Loss: 256.777 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3820/4776 | Loss: 317.306 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3830/4776 | Loss: 284.726 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3840/4776 | Loss: 242.973 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3850/4776 | Loss: 253.819 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3860/4776 | Loss: 260.425 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3870/4776 | Loss: 292.628 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3880/4776 | Loss: 268.673 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3890/4776 | Loss: 259.123 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3900/4776 | Loss: 293.263 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3910/4776 | Loss: 233.865 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3920/4776 | Loss: 274.743 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 3930/4776 | Loss: 247.913 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3940/4776 | Loss: 266.618 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3950/4776 | Loss: 313.082 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 3960/4776 | Loss: 266.292 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 3970/4776 | Loss: 301.634 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 3980/4776 | Loss: 222.437 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 3990/4776 | Loss: 283.258 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4000/4776 | Loss: 283.881 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4010/4776 | Loss: 293.985 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4020/4776 | Loss: 271.465 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4030/4776 | Loss: 269.511 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4040/4776 | Loss: 268.135 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4050/4776 | Loss: 246.159 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4060/4776 | Loss: 220.226 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4070/4776 | Loss: 263.482 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4080/4776 | Loss: 276.266 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4090/4776 | Loss: 275.723 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4100/4776 | Loss: 215.637 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 4110/4776 | Loss: 264.590 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4120/4776 | Loss: 275.083 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4130/4776 | Loss: 320.070 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4140/4776 | Loss: 245.636 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 4150/4776 | Loss: 255.634 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4160/4776 | Loss: 269.537 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4170/4776 | Loss: 305.185 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4180/4776 | Loss: 294.337 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4190/4776 | Loss: 239.645 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4200/4776 | Loss: 229.398 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4210/4776 | Loss: 275.245 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4220/4776 | Loss: 297.074 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4230/4776 | Loss: 289.083 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4240/4776 | Loss: 299.879 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4250/4776 | Loss: 250.699 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4260/4776 | Loss: 259.755 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4270/4776 | Loss: 311.250 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4280/4776 | Loss: 275.079 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4290/4776 | Loss: 295.168 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4300/4776 | Loss: 281.974 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4310/4776 | Loss: 277.853 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4320/4776 | Loss: 294.606 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4330/4776 | Loss: 272.803 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4340/4776 | Loss: 273.679 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4350/4776 | Loss: 298.969 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4360/4776 | Loss: 300.915 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4370/4776 | Loss: 262.636 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4380/4776 | Loss: 263.440 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4390/4776 | Loss: 278.521 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4400/4776 | Loss: 290.564 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4410/4776 | Loss: 296.557 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4420/4776 | Loss: 268.944 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4430/4776 | Loss: 231.728 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4440/4776 | Loss: 299.105 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4450/4776 | Loss: 288.529 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4460/4776 | Loss: 269.284 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4470/4776 | Loss: 303.388 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4480/4776 | Loss: 245.044 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4490/4776 | Loss: 251.249 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4500/4776 | Loss: 257.055 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4510/4776 | Loss: 266.859 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4520/4776 | Loss: 281.969 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4530/4776 | Loss: 297.606 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4540/4776 | Loss: 278.529 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4550/4776 | Loss: 258.723 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4560/4776 | Loss: 256.596 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4570/4776 | Loss: 243.827 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4580/4776 | Loss: 243.504 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4590/4776 | Loss: 314.218 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4600/4776 | Loss: 284.554 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4610/4776 | Loss: 297.948 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4620/4776 | Loss: 266.719 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4630/4776 | Loss: 248.305 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4640/4776 | Loss: 295.265 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4650/4776 | Loss: 248.542 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4660/4776 | Loss: 279.832 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4670/4776 | Loss: 230.577 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 4680/4776 | Loss: 231.667 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4690/4776 | Loss: 252.685 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4700/4776 | Loss: 286.023 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4710/4776 | Loss: 255.278 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4720/4776 | Loss: 312.171 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 4730/4776 | Loss: 276.260 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4740/4776 | Loss: 295.439 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4750/4776 | Loss: 266.030 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 4760/4776 | Loss: 253.047 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 4770/4776 | Loss: 265.004 | Accuracy: 0.100\n",
      "Accuracy:  0.12459016393442623\n",
      "Model saved!\n",
      "[Epoch: 17/200] - Step: 10/4776 | Loss: 260.902 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 20/4776 | Loss: 264.574 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 30/4776 | Loss: 242.495 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 40/4776 | Loss: 255.126 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 50/4776 | Loss: 239.285 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 60/4776 | Loss: 293.112 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 70/4776 | Loss: 306.738 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 80/4776 | Loss: 263.294 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 90/4776 | Loss: 304.350 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 100/4776 | Loss: 275.965 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 110/4776 | Loss: 308.379 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 120/4776 | Loss: 278.893 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 130/4776 | Loss: 251.816 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 140/4776 | Loss: 273.536 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 150/4776 | Loss: 286.541 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 160/4776 | Loss: 288.193 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 170/4776 | Loss: 259.395 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 180/4776 | Loss: 232.928 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 190/4776 | Loss: 254.835 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 200/4776 | Loss: 301.224 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 210/4776 | Loss: 253.858 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 220/4776 | Loss: 309.701 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 230/4776 | Loss: 258.590 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 240/4776 | Loss: 243.684 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 250/4776 | Loss: 295.864 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 260/4776 | Loss: 269.697 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 270/4776 | Loss: 251.773 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 280/4776 | Loss: 235.598 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 290/4776 | Loss: 281.819 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 300/4776 | Loss: 266.644 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 310/4776 | Loss: 222.462 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 320/4776 | Loss: 278.383 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 330/4776 | Loss: 253.094 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 340/4776 | Loss: 278.926 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 350/4776 | Loss: 241.866 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 360/4776 | Loss: 268.285 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 370/4776 | Loss: 266.681 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 380/4776 | Loss: 240.067 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 390/4776 | Loss: 276.062 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 400/4776 | Loss: 236.485 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 410/4776 | Loss: 241.730 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 420/4776 | Loss: 263.572 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 430/4776 | Loss: 304.653 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 440/4776 | Loss: 269.955 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 450/4776 | Loss: 257.598 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 460/4776 | Loss: 258.673 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 470/4776 | Loss: 302.427 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 480/4776 | Loss: 272.965 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 490/4776 | Loss: 299.847 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 500/4776 | Loss: 255.120 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 510/4776 | Loss: 220.763 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 520/4776 | Loss: 250.426 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 530/4776 | Loss: 279.441 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 540/4776 | Loss: 262.466 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 550/4776 | Loss: 277.803 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 560/4776 | Loss: 263.049 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 570/4776 | Loss: 262.607 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 580/4776 | Loss: 225.613 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 590/4776 | Loss: 248.797 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 600/4776 | Loss: 256.564 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 610/4776 | Loss: 246.555 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 620/4776 | Loss: 226.968 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 630/4776 | Loss: 275.475 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 640/4776 | Loss: 292.368 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 650/4776 | Loss: 285.519 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 660/4776 | Loss: 256.161 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 670/4776 | Loss: 266.958 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 680/4776 | Loss: 256.938 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 690/4776 | Loss: 291.421 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 700/4776 | Loss: 259.566 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 710/4776 | Loss: 311.925 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 720/4776 | Loss: 238.544 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 730/4776 | Loss: 253.159 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 740/4776 | Loss: 281.010 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 750/4776 | Loss: 251.224 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 760/4776 | Loss: 264.417 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 770/4776 | Loss: 234.419 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 780/4776 | Loss: 314.695 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 790/4776 | Loss: 242.726 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 800/4776 | Loss: 274.471 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 810/4776 | Loss: 282.071 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 820/4776 | Loss: 255.906 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 830/4776 | Loss: 271.680 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 840/4776 | Loss: 255.229 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 850/4776 | Loss: 298.597 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 860/4776 | Loss: 214.422 | Accuracy: 0.500\n",
      "[Epoch: 17/200] - Step: 870/4776 | Loss: 241.342 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 880/4776 | Loss: 236.914 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 890/4776 | Loss: 254.480 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 900/4776 | Loss: 333.881 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 910/4776 | Loss: 285.830 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 920/4776 | Loss: 251.444 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 930/4776 | Loss: 267.000 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 940/4776 | Loss: 270.437 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 950/4776 | Loss: 285.851 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 960/4776 | Loss: 263.900 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 970/4776 | Loss: 264.700 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 980/4776 | Loss: 266.490 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 990/4776 | Loss: 296.591 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1000/4776 | Loss: 217.490 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1010/4776 | Loss: 245.256 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1020/4776 | Loss: 265.844 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1030/4776 | Loss: 273.108 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1040/4776 | Loss: 282.016 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1050/4776 | Loss: 296.130 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1060/4776 | Loss: 261.615 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1070/4776 | Loss: 238.060 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1080/4776 | Loss: 253.850 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1090/4776 | Loss: 237.945 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1100/4776 | Loss: 288.810 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1110/4776 | Loss: 263.442 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1120/4776 | Loss: 280.521 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1130/4776 | Loss: 250.172 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1140/4776 | Loss: 237.049 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1150/4776 | Loss: 276.169 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1160/4776 | Loss: 246.458 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1170/4776 | Loss: 276.904 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1180/4776 | Loss: 263.419 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1190/4776 | Loss: 276.168 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1200/4776 | Loss: 249.820 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1210/4776 | Loss: 269.906 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1220/4776 | Loss: 273.462 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1230/4776 | Loss: 265.206 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1240/4776 | Loss: 267.819 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1250/4776 | Loss: 296.378 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1260/4776 | Loss: 286.726 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1270/4776 | Loss: 292.080 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1280/4776 | Loss: 239.669 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1290/4776 | Loss: 219.422 | Accuracy: 0.500\n",
      "[Epoch: 17/200] - Step: 1300/4776 | Loss: 286.868 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1310/4776 | Loss: 262.278 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1320/4776 | Loss: 288.216 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1330/4776 | Loss: 277.744 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1340/4776 | Loss: 252.907 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1350/4776 | Loss: 268.619 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1360/4776 | Loss: 270.359 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1370/4776 | Loss: 258.669 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1380/4776 | Loss: 271.306 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1390/4776 | Loss: 277.492 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1400/4776 | Loss: 265.267 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1410/4776 | Loss: 253.777 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1420/4776 | Loss: 236.763 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1430/4776 | Loss: 282.976 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1440/4776 | Loss: 269.632 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1450/4776 | Loss: 255.947 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1460/4776 | Loss: 257.205 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1470/4776 | Loss: 245.085 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1480/4776 | Loss: 229.381 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1490/4776 | Loss: 234.513 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1500/4776 | Loss: 267.988 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1510/4776 | Loss: 221.845 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 1520/4776 | Loss: 216.193 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1530/4776 | Loss: 322.544 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1540/4776 | Loss: 265.800 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1550/4776 | Loss: 328.179 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1560/4776 | Loss: 289.308 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1570/4776 | Loss: 276.140 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1580/4776 | Loss: 266.663 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1590/4776 | Loss: 263.169 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1600/4776 | Loss: 258.961 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1610/4776 | Loss: 259.127 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1620/4776 | Loss: 251.909 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1630/4776 | Loss: 264.261 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1640/4776 | Loss: 273.751 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1650/4776 | Loss: 265.242 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1660/4776 | Loss: 270.908 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1670/4776 | Loss: 247.608 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 1680/4776 | Loss: 288.110 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1690/4776 | Loss: 260.990 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1700/4776 | Loss: 290.104 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1710/4776 | Loss: 254.195 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1720/4776 | Loss: 203.214 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1730/4776 | Loss: 317.776 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1740/4776 | Loss: 307.128 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1750/4776 | Loss: 313.066 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1760/4776 | Loss: 254.310 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1770/4776 | Loss: 282.432 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1780/4776 | Loss: 289.776 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1790/4776 | Loss: 268.395 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1800/4776 | Loss: 294.791 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1810/4776 | Loss: 242.841 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1820/4776 | Loss: 306.147 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1830/4776 | Loss: 267.310 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1840/4776 | Loss: 266.510 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1850/4776 | Loss: 276.277 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1860/4776 | Loss: 276.060 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1870/4776 | Loss: 272.664 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1880/4776 | Loss: 248.341 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1890/4776 | Loss: 316.234 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1900/4776 | Loss: 339.988 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1910/4776 | Loss: 255.464 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1920/4776 | Loss: 264.440 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1930/4776 | Loss: 250.348 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1940/4776 | Loss: 253.748 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 1950/4776 | Loss: 252.682 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1960/4776 | Loss: 269.624 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1970/4776 | Loss: 268.994 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1980/4776 | Loss: 262.127 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1990/4776 | Loss: 301.903 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2000/4776 | Loss: 258.487 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2010/4776 | Loss: 229.844 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2020/4776 | Loss: 274.412 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2030/4776 | Loss: 295.334 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2040/4776 | Loss: 270.619 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2050/4776 | Loss: 209.893 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2060/4776 | Loss: 272.874 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2070/4776 | Loss: 233.008 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2080/4776 | Loss: 258.462 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2090/4776 | Loss: 274.555 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2100/4776 | Loss: 266.595 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2110/4776 | Loss: 310.636 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2120/4776 | Loss: 237.651 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2130/4776 | Loss: 290.785 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2140/4776 | Loss: 284.409 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2150/4776 | Loss: 250.229 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2160/4776 | Loss: 300.778 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2170/4776 | Loss: 288.850 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2180/4776 | Loss: 275.628 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2190/4776 | Loss: 271.292 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2200/4776 | Loss: 249.906 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2210/4776 | Loss: 241.980 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2220/4776 | Loss: 248.788 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2230/4776 | Loss: 228.836 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2240/4776 | Loss: 299.472 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2250/4776 | Loss: 250.227 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2260/4776 | Loss: 276.606 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2270/4776 | Loss: 312.882 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2280/4776 | Loss: 262.753 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2290/4776 | Loss: 250.323 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2300/4776 | Loss: 242.121 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2310/4776 | Loss: 243.027 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2320/4776 | Loss: 268.919 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2330/4776 | Loss: 275.531 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2340/4776 | Loss: 256.900 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2350/4776 | Loss: 293.911 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2360/4776 | Loss: 245.200 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2370/4776 | Loss: 274.034 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2380/4776 | Loss: 287.517 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2390/4776 | Loss: 277.940 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2400/4776 | Loss: 268.672 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2410/4776 | Loss: 266.039 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2420/4776 | Loss: 254.039 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2430/4776 | Loss: 237.631 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2440/4776 | Loss: 292.071 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2450/4776 | Loss: 263.220 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2460/4776 | Loss: 267.979 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2470/4776 | Loss: 283.283 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2480/4776 | Loss: 282.667 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2490/4776 | Loss: 249.637 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2500/4776 | Loss: 250.777 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2510/4776 | Loss: 278.396 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2520/4776 | Loss: 313.849 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2530/4776 | Loss: 292.063 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2540/4776 | Loss: 239.863 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2550/4776 | Loss: 266.221 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2560/4776 | Loss: 263.513 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2570/4776 | Loss: 240.244 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2580/4776 | Loss: 224.773 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2590/4776 | Loss: 276.454 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2600/4776 | Loss: 237.770 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2610/4776 | Loss: 247.731 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2620/4776 | Loss: 306.673 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2630/4776 | Loss: 305.569 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2640/4776 | Loss: 244.773 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2650/4776 | Loss: 282.954 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2660/4776 | Loss: 231.934 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2670/4776 | Loss: 262.455 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2680/4776 | Loss: 237.739 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2690/4776 | Loss: 236.054 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2700/4776 | Loss: 309.485 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2710/4776 | Loss: 245.203 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2720/4776 | Loss: 301.377 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2730/4776 | Loss: 282.294 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2740/4776 | Loss: 296.308 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2750/4776 | Loss: 285.232 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2760/4776 | Loss: 225.977 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2770/4776 | Loss: 241.237 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2780/4776 | Loss: 235.416 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2790/4776 | Loss: 387.845 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2800/4776 | Loss: 294.926 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2810/4776 | Loss: 249.533 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2820/4776 | Loss: 264.505 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2830/4776 | Loss: 285.928 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2840/4776 | Loss: 266.862 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2850/4776 | Loss: 267.964 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2860/4776 | Loss: 256.722 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 2870/4776 | Loss: 270.632 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2880/4776 | Loss: 253.071 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2890/4776 | Loss: 230.737 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2900/4776 | Loss: 251.554 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 2910/4776 | Loss: 254.066 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2920/4776 | Loss: 272.277 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2930/4776 | Loss: 237.103 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2940/4776 | Loss: 266.572 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2950/4776 | Loss: 251.888 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 2960/4776 | Loss: 292.867 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 2970/4776 | Loss: 293.155 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2980/4776 | Loss: 267.452 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 2990/4776 | Loss: 276.687 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3000/4776 | Loss: 272.948 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3010/4776 | Loss: 266.540 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3020/4776 | Loss: 263.552 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3030/4776 | Loss: 275.688 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3040/4776 | Loss: 257.368 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3050/4776 | Loss: 252.167 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3060/4776 | Loss: 236.547 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 3070/4776 | Loss: 260.327 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 3080/4776 | Loss: 265.296 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3090/4776 | Loss: 274.682 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3100/4776 | Loss: 264.305 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3110/4776 | Loss: 268.908 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3120/4776 | Loss: 255.651 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3130/4776 | Loss: 294.784 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3140/4776 | Loss: 241.482 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3150/4776 | Loss: 284.568 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3160/4776 | Loss: 265.732 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3170/4776 | Loss: 232.566 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3180/4776 | Loss: 271.200 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3190/4776 | Loss: 252.182 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3200/4776 | Loss: 310.264 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3210/4776 | Loss: 258.102 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3220/4776 | Loss: 250.953 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3230/4776 | Loss: 291.404 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3240/4776 | Loss: 296.894 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3250/4776 | Loss: 305.322 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3260/4776 | Loss: 306.537 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3270/4776 | Loss: 248.701 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3280/4776 | Loss: 245.504 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3290/4776 | Loss: 275.925 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3300/4776 | Loss: 262.575 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3310/4776 | Loss: 238.707 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3320/4776 | Loss: 264.502 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3330/4776 | Loss: 228.144 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3340/4776 | Loss: 278.729 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3350/4776 | Loss: 223.109 | Accuracy: 0.500\n",
      "[Epoch: 17/200] - Step: 3360/4776 | Loss: 275.560 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3370/4776 | Loss: 290.381 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3380/4776 | Loss: 282.019 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3390/4776 | Loss: 304.272 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3400/4776 | Loss: 257.258 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3410/4776 | Loss: 289.431 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3420/4776 | Loss: 261.931 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3430/4776 | Loss: 248.990 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3440/4776 | Loss: 261.547 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3450/4776 | Loss: 278.552 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3460/4776 | Loss: 279.427 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3470/4776 | Loss: 270.225 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3480/4776 | Loss: 283.037 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3490/4776 | Loss: 277.947 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3500/4776 | Loss: 275.490 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3510/4776 | Loss: 268.093 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3520/4776 | Loss: 274.849 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3530/4776 | Loss: 270.611 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3540/4776 | Loss: 292.612 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3550/4776 | Loss: 268.679 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3560/4776 | Loss: 255.125 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3570/4776 | Loss: 292.341 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3580/4776 | Loss: 275.520 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3590/4776 | Loss: 286.220 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3600/4776 | Loss: 248.547 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3610/4776 | Loss: 258.910 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3620/4776 | Loss: 283.902 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3630/4776 | Loss: 293.983 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3640/4776 | Loss: 250.713 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3650/4776 | Loss: 270.471 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3660/4776 | Loss: 236.937 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3670/4776 | Loss: 247.100 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3680/4776 | Loss: 263.277 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3690/4776 | Loss: 233.539 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3700/4776 | Loss: 253.116 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3710/4776 | Loss: 236.764 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3720/4776 | Loss: 251.928 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3730/4776 | Loss: 269.057 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3740/4776 | Loss: 289.033 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3750/4776 | Loss: 259.320 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3760/4776 | Loss: 267.908 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3770/4776 | Loss: 265.125 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3780/4776 | Loss: 313.456 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3790/4776 | Loss: 267.228 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3800/4776 | Loss: 297.654 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3810/4776 | Loss: 279.523 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3820/4776 | Loss: 306.803 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3830/4776 | Loss: 267.728 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3840/4776 | Loss: 235.495 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 3850/4776 | Loss: 266.076 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3860/4776 | Loss: 267.975 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3870/4776 | Loss: 255.799 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3880/4776 | Loss: 268.069 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3890/4776 | Loss: 285.170 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3900/4776 | Loss: 246.470 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3910/4776 | Loss: 260.852 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3920/4776 | Loss: 280.745 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3930/4776 | Loss: 239.422 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 3940/4776 | Loss: 270.129 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 3950/4776 | Loss: 256.767 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3960/4776 | Loss: 258.223 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 3970/4776 | Loss: 240.847 | Accuracy: 0.500\n",
      "[Epoch: 17/200] - Step: 3980/4776 | Loss: 264.476 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 3990/4776 | Loss: 269.056 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4000/4776 | Loss: 223.635 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 4010/4776 | Loss: 257.584 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4020/4776 | Loss: 296.428 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4030/4776 | Loss: 274.565 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4040/4776 | Loss: 235.220 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 4050/4776 | Loss: 260.133 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4060/4776 | Loss: 256.656 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4070/4776 | Loss: 236.446 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4080/4776 | Loss: 190.867 | Accuracy: 0.700\n",
      "[Epoch: 17/200] - Step: 4090/4776 | Loss: 278.907 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4100/4776 | Loss: 258.285 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4110/4776 | Loss: 270.846 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4120/4776 | Loss: 279.048 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4130/4776 | Loss: 293.312 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4140/4776 | Loss: 287.011 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4150/4776 | Loss: 297.831 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4160/4776 | Loss: 285.382 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4170/4776 | Loss: 258.087 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4180/4776 | Loss: 269.064 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4190/4776 | Loss: 275.332 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4200/4776 | Loss: 274.723 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4210/4776 | Loss: 290.486 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4220/4776 | Loss: 277.301 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4230/4776 | Loss: 224.732 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 4240/4776 | Loss: 298.857 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4250/4776 | Loss: 284.003 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4260/4776 | Loss: 277.824 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4270/4776 | Loss: 296.441 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4280/4776 | Loss: 270.208 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4290/4776 | Loss: 284.041 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4300/4776 | Loss: 247.389 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4310/4776 | Loss: 236.734 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4320/4776 | Loss: 269.847 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4330/4776 | Loss: 276.573 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4340/4776 | Loss: 279.614 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4350/4776 | Loss: 272.918 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4360/4776 | Loss: 277.328 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4370/4776 | Loss: 294.877 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4380/4776 | Loss: 296.948 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4390/4776 | Loss: 275.385 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4400/4776 | Loss: 284.951 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4410/4776 | Loss: 268.842 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4420/4776 | Loss: 242.902 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4430/4776 | Loss: 247.177 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4440/4776 | Loss: 222.747 | Accuracy: 0.500\n",
      "[Epoch: 17/200] - Step: 4450/4776 | Loss: 257.716 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4460/4776 | Loss: 249.904 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4470/4776 | Loss: 275.838 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4480/4776 | Loss: 275.382 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4490/4776 | Loss: 279.015 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4500/4776 | Loss: 258.161 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4510/4776 | Loss: 270.474 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4520/4776 | Loss: 230.293 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4530/4776 | Loss: 265.246 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4540/4776 | Loss: 273.147 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4550/4776 | Loss: 238.169 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4560/4776 | Loss: 335.115 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4570/4776 | Loss: 252.558 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4580/4776 | Loss: 252.006 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4590/4776 | Loss: 278.256 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4600/4776 | Loss: 293.727 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4610/4776 | Loss: 283.454 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4620/4776 | Loss: 269.112 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4630/4776 | Loss: 294.797 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4640/4776 | Loss: 254.338 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4650/4776 | Loss: 264.917 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4660/4776 | Loss: 268.054 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4670/4776 | Loss: 309.852 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4680/4776 | Loss: 238.904 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 4690/4776 | Loss: 259.322 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4700/4776 | Loss: 251.189 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4710/4776 | Loss: 278.344 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 4720/4776 | Loss: 255.571 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4730/4776 | Loss: 241.962 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4740/4776 | Loss: 247.500 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 4750/4776 | Loss: 271.035 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 4760/4776 | Loss: 236.010 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 4770/4776 | Loss: 227.618 | Accuracy: 0.300\n",
      "Accuracy:  0.12459016393442623\n",
      "[Epoch: 18/200] - Step: 10/4776 | Loss: 202.114 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 20/4776 | Loss: 336.691 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 30/4776 | Loss: 223.305 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 40/4776 | Loss: 285.994 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 50/4776 | Loss: 249.935 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 60/4776 | Loss: 274.710 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 70/4776 | Loss: 273.415 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 80/4776 | Loss: 272.749 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 90/4776 | Loss: 278.262 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 100/4776 | Loss: 255.489 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 110/4776 | Loss: 235.304 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 120/4776 | Loss: 252.563 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 130/4776 | Loss: 205.781 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 140/4776 | Loss: 223.313 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 150/4776 | Loss: 347.296 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 160/4776 | Loss: 230.185 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 170/4776 | Loss: 264.711 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 180/4776 | Loss: 271.040 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 190/4776 | Loss: 280.238 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 200/4776 | Loss: 278.719 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 210/4776 | Loss: 272.996 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 220/4776 | Loss: 260.685 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 230/4776 | Loss: 235.778 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 240/4776 | Loss: 295.277 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 250/4776 | Loss: 245.848 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 260/4776 | Loss: 264.320 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 270/4776 | Loss: 248.705 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 280/4776 | Loss: 248.388 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 290/4776 | Loss: 279.096 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 300/4776 | Loss: 265.822 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 310/4776 | Loss: 281.186 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 320/4776 | Loss: 282.090 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 330/4776 | Loss: 244.375 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 340/4776 | Loss: 262.431 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 350/4776 | Loss: 268.130 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 360/4776 | Loss: 296.225 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 370/4776 | Loss: 260.278 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 380/4776 | Loss: 227.227 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 390/4776 | Loss: 287.335 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 400/4776 | Loss: 300.279 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 410/4776 | Loss: 232.495 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 420/4776 | Loss: 278.082 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 430/4776 | Loss: 263.067 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 440/4776 | Loss: 244.505 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 450/4776 | Loss: 263.477 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 460/4776 | Loss: 266.057 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 470/4776 | Loss: 288.017 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 480/4776 | Loss: 236.724 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 490/4776 | Loss: 256.109 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 500/4776 | Loss: 278.221 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 510/4776 | Loss: 266.417 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 520/4776 | Loss: 224.441 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 530/4776 | Loss: 225.739 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 540/4776 | Loss: 267.389 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 550/4776 | Loss: 284.412 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 560/4776 | Loss: 291.778 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 570/4776 | Loss: 245.265 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 580/4776 | Loss: 253.929 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 590/4776 | Loss: 273.646 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 600/4776 | Loss: 272.319 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 610/4776 | Loss: 281.134 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 620/4776 | Loss: 265.306 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 630/4776 | Loss: 296.736 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 640/4776 | Loss: 247.279 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 650/4776 | Loss: 245.989 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 660/4776 | Loss: 267.761 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 670/4776 | Loss: 279.723 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 680/4776 | Loss: 283.510 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 690/4776 | Loss: 256.151 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 700/4776 | Loss: 267.404 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 710/4776 | Loss: 285.797 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 720/4776 | Loss: 265.760 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 730/4776 | Loss: 247.976 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 740/4776 | Loss: 251.215 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 750/4776 | Loss: 265.433 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 760/4776 | Loss: 264.958 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 770/4776 | Loss: 268.348 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 780/4776 | Loss: 270.020 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 790/4776 | Loss: 275.049 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 800/4776 | Loss: 293.173 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 810/4776 | Loss: 257.349 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 820/4776 | Loss: 283.992 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 830/4776 | Loss: 276.056 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 840/4776 | Loss: 263.893 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 850/4776 | Loss: 268.062 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 860/4776 | Loss: 301.104 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 870/4776 | Loss: 326.743 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 880/4776 | Loss: 266.278 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 890/4776 | Loss: 280.808 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 900/4776 | Loss: 250.294 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 910/4776 | Loss: 250.175 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 920/4776 | Loss: 274.411 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 930/4776 | Loss: 244.296 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 940/4776 | Loss: 258.247 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 950/4776 | Loss: 287.967 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 960/4776 | Loss: 256.753 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 970/4776 | Loss: 265.939 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 980/4776 | Loss: 236.249 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 990/4776 | Loss: 283.361 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1000/4776 | Loss: 290.423 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1010/4776 | Loss: 287.708 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1020/4776 | Loss: 291.405 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1030/4776 | Loss: 278.902 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1040/4776 | Loss: 233.228 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1050/4776 | Loss: 272.487 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1060/4776 | Loss: 284.752 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1070/4776 | Loss: 227.672 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1080/4776 | Loss: 243.821 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1090/4776 | Loss: 245.954 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1100/4776 | Loss: 258.970 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1110/4776 | Loss: 247.879 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1120/4776 | Loss: 234.370 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1130/4776 | Loss: 293.068 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1140/4776 | Loss: 324.347 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1150/4776 | Loss: 251.238 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1160/4776 | Loss: 280.922 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1170/4776 | Loss: 246.656 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1180/4776 | Loss: 276.299 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1190/4776 | Loss: 215.410 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1200/4776 | Loss: 251.076 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1210/4776 | Loss: 281.792 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1220/4776 | Loss: 268.321 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1230/4776 | Loss: 238.741 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1240/4776 | Loss: 252.367 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1250/4776 | Loss: 274.932 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1260/4776 | Loss: 234.366 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1270/4776 | Loss: 259.815 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1280/4776 | Loss: 229.284 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1290/4776 | Loss: 271.902 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1300/4776 | Loss: 213.067 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1310/4776 | Loss: 330.571 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1320/4776 | Loss: 246.895 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1330/4776 | Loss: 292.802 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1340/4776 | Loss: 279.694 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1350/4776 | Loss: 245.403 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1360/4776 | Loss: 322.137 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1370/4776 | Loss: 289.916 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1380/4776 | Loss: 229.487 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1390/4776 | Loss: 275.901 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1400/4776 | Loss: 277.039 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1410/4776 | Loss: 255.096 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1420/4776 | Loss: 273.704 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1430/4776 | Loss: 286.540 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1440/4776 | Loss: 258.058 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1450/4776 | Loss: 245.316 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1460/4776 | Loss: 256.476 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1470/4776 | Loss: 263.633 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1480/4776 | Loss: 292.234 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1490/4776 | Loss: 249.938 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1500/4776 | Loss: 281.998 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1510/4776 | Loss: 229.101 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1520/4776 | Loss: 279.144 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1530/4776 | Loss: 279.482 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1540/4776 | Loss: 230.776 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1550/4776 | Loss: 196.395 | Accuracy: 0.600\n",
      "[Epoch: 18/200] - Step: 1560/4776 | Loss: 224.930 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1570/4776 | Loss: 284.125 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1580/4776 | Loss: 212.855 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1590/4776 | Loss: 274.950 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1600/4776 | Loss: 299.776 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1610/4776 | Loss: 235.857 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1620/4776 | Loss: 206.848 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1630/4776 | Loss: 274.691 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1640/4776 | Loss: 282.508 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1650/4776 | Loss: 263.808 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1660/4776 | Loss: 244.637 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1670/4776 | Loss: 248.733 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1680/4776 | Loss: 247.993 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1690/4776 | Loss: 220.240 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1700/4776 | Loss: 246.363 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1710/4776 | Loss: 272.264 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1720/4776 | Loss: 238.195 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1730/4776 | Loss: 271.713 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1740/4776 | Loss: 246.797 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1750/4776 | Loss: 263.143 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1760/4776 | Loss: 264.461 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1770/4776 | Loss: 243.515 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1780/4776 | Loss: 262.699 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1790/4776 | Loss: 290.142 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1800/4776 | Loss: 254.701 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1810/4776 | Loss: 277.334 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1820/4776 | Loss: 260.612 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1830/4776 | Loss: 237.141 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 1840/4776 | Loss: 273.344 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1850/4776 | Loss: 274.364 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1860/4776 | Loss: 240.444 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 1870/4776 | Loss: 279.107 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1880/4776 | Loss: 236.379 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1890/4776 | Loss: 230.408 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1900/4776 | Loss: 282.150 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1910/4776 | Loss: 273.074 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1920/4776 | Loss: 252.057 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1930/4776 | Loss: 309.369 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1940/4776 | Loss: 330.217 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1950/4776 | Loss: 300.389 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1960/4776 | Loss: 275.056 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1970/4776 | Loss: 282.835 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1980/4776 | Loss: 249.899 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1990/4776 | Loss: 285.890 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2000/4776 | Loss: 261.647 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2010/4776 | Loss: 268.270 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2020/4776 | Loss: 244.108 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2030/4776 | Loss: 219.275 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 2040/4776 | Loss: 275.360 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2050/4776 | Loss: 254.857 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2060/4776 | Loss: 263.851 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2070/4776 | Loss: 213.463 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 2080/4776 | Loss: 267.319 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2090/4776 | Loss: 279.898 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2100/4776 | Loss: 269.636 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2110/4776 | Loss: 245.652 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2120/4776 | Loss: 234.542 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2130/4776 | Loss: 290.374 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2140/4776 | Loss: 295.826 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2150/4776 | Loss: 249.625 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2160/4776 | Loss: 247.879 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2170/4776 | Loss: 238.099 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2180/4776 | Loss: 261.833 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2190/4776 | Loss: 254.689 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 2200/4776 | Loss: 287.233 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2210/4776 | Loss: 250.702 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2220/4776 | Loss: 289.246 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2230/4776 | Loss: 241.354 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2240/4776 | Loss: 251.065 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2250/4776 | Loss: 305.305 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2260/4776 | Loss: 238.873 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2270/4776 | Loss: 230.443 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2280/4776 | Loss: 268.287 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2290/4776 | Loss: 262.915 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2300/4776 | Loss: 263.057 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2310/4776 | Loss: 256.479 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2320/4776 | Loss: 227.371 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2330/4776 | Loss: 261.205 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2340/4776 | Loss: 258.800 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2350/4776 | Loss: 238.854 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2360/4776 | Loss: 264.263 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2370/4776 | Loss: 296.710 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2380/4776 | Loss: 251.130 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2390/4776 | Loss: 268.621 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2400/4776 | Loss: 282.149 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2410/4776 | Loss: 256.378 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2420/4776 | Loss: 219.967 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2430/4776 | Loss: 255.974 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2440/4776 | Loss: 285.164 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2450/4776 | Loss: 282.426 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2460/4776 | Loss: 330.856 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2470/4776 | Loss: 222.064 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2480/4776 | Loss: 267.586 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2490/4776 | Loss: 270.780 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2500/4776 | Loss: 294.419 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2510/4776 | Loss: 294.302 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2520/4776 | Loss: 302.835 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2530/4776 | Loss: 276.266 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2540/4776 | Loss: 278.892 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2550/4776 | Loss: 254.176 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2560/4776 | Loss: 335.283 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2570/4776 | Loss: 261.416 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2580/4776 | Loss: 260.616 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2590/4776 | Loss: 239.107 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 2600/4776 | Loss: 293.606 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2610/4776 | Loss: 281.957 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2620/4776 | Loss: 281.957 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2630/4776 | Loss: 307.595 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2640/4776 | Loss: 264.666 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2650/4776 | Loss: 272.804 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2660/4776 | Loss: 245.632 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2670/4776 | Loss: 278.093 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2680/4776 | Loss: 247.249 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2690/4776 | Loss: 267.065 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2700/4776 | Loss: 256.665 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2710/4776 | Loss: 256.002 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2720/4776 | Loss: 272.167 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2730/4776 | Loss: 224.092 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2740/4776 | Loss: 254.835 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2750/4776 | Loss: 321.084 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2760/4776 | Loss: 256.633 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2770/4776 | Loss: 211.475 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2780/4776 | Loss: 255.775 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2790/4776 | Loss: 254.048 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2800/4776 | Loss: 267.044 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2810/4776 | Loss: 258.454 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2820/4776 | Loss: 272.948 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2830/4776 | Loss: 278.961 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2840/4776 | Loss: 253.241 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2850/4776 | Loss: 255.796 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 2860/4776 | Loss: 271.406 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2870/4776 | Loss: 213.096 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2880/4776 | Loss: 216.579 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 2890/4776 | Loss: 259.453 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2900/4776 | Loss: 296.114 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2910/4776 | Loss: 286.114 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2920/4776 | Loss: 255.530 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2930/4776 | Loss: 299.112 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 2940/4776 | Loss: 249.425 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2950/4776 | Loss: 236.190 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 2960/4776 | Loss: 240.492 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 2970/4776 | Loss: 222.807 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2980/4776 | Loss: 274.082 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 2990/4776 | Loss: 233.022 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3000/4776 | Loss: 247.018 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3010/4776 | Loss: 276.539 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3020/4776 | Loss: 256.874 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3030/4776 | Loss: 285.441 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3040/4776 | Loss: 288.568 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3050/4776 | Loss: 244.503 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3060/4776 | Loss: 264.775 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3070/4776 | Loss: 298.044 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3080/4776 | Loss: 272.688 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3090/4776 | Loss: 207.866 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 3100/4776 | Loss: 278.406 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3110/4776 | Loss: 254.562 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3120/4776 | Loss: 236.078 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3130/4776 | Loss: 266.895 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3140/4776 | Loss: 285.373 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3150/4776 | Loss: 276.878 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3160/4776 | Loss: 244.506 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3170/4776 | Loss: 254.014 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3180/4776 | Loss: 254.561 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3190/4776 | Loss: 224.273 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3200/4776 | Loss: 274.138 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3210/4776 | Loss: 264.327 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3220/4776 | Loss: 242.392 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3230/4776 | Loss: 217.200 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3240/4776 | Loss: 230.077 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 3250/4776 | Loss: 429.296 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3260/4776 | Loss: 285.956 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3270/4776 | Loss: 257.691 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3280/4776 | Loss: 271.344 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3290/4776 | Loss: 298.363 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3300/4776 | Loss: 288.762 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3310/4776 | Loss: 269.689 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3320/4776 | Loss: 292.498 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3330/4776 | Loss: 274.099 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3340/4776 | Loss: 285.209 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3350/4776 | Loss: 239.530 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3360/4776 | Loss: 244.304 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3370/4776 | Loss: 267.635 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3380/4776 | Loss: 266.143 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3390/4776 | Loss: 295.837 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3400/4776 | Loss: 213.104 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3410/4776 | Loss: 259.825 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3420/4776 | Loss: 261.571 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3430/4776 | Loss: 264.775 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3440/4776 | Loss: 260.185 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3450/4776 | Loss: 250.841 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3460/4776 | Loss: 220.107 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3470/4776 | Loss: 231.615 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3480/4776 | Loss: 237.420 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3490/4776 | Loss: 229.029 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 3500/4776 | Loss: 286.439 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3510/4776 | Loss: 257.011 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3520/4776 | Loss: 264.590 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3530/4776 | Loss: 298.633 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3540/4776 | Loss: 255.707 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3550/4776 | Loss: 212.484 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3560/4776 | Loss: 261.599 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3570/4776 | Loss: 254.196 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3580/4776 | Loss: 243.929 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3590/4776 | Loss: 241.335 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3600/4776 | Loss: 265.107 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3610/4776 | Loss: 241.866 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3620/4776 | Loss: 259.538 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3630/4776 | Loss: 241.711 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3640/4776 | Loss: 268.104 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3650/4776 | Loss: 266.145 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3660/4776 | Loss: 273.882 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3670/4776 | Loss: 292.034 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3680/4776 | Loss: 234.593 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 3690/4776 | Loss: 278.517 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3700/4776 | Loss: 276.446 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3710/4776 | Loss: 283.486 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3720/4776 | Loss: 253.862 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3730/4776 | Loss: 257.607 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3740/4776 | Loss: 238.983 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3750/4776 | Loss: 269.692 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3760/4776 | Loss: 258.448 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3770/4776 | Loss: 273.225 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3780/4776 | Loss: 278.409 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3790/4776 | Loss: 263.106 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3800/4776 | Loss: 260.274 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3810/4776 | Loss: 212.232 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3820/4776 | Loss: 311.818 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3830/4776 | Loss: 219.833 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3840/4776 | Loss: 339.735 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3850/4776 | Loss: 272.680 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3860/4776 | Loss: 279.450 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3870/4776 | Loss: 289.663 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3880/4776 | Loss: 278.234 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3890/4776 | Loss: 245.452 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 3900/4776 | Loss: 303.622 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3910/4776 | Loss: 225.495 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3920/4776 | Loss: 283.338 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3930/4776 | Loss: 262.382 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3940/4776 | Loss: 194.372 | Accuracy: 0.600\n",
      "[Epoch: 18/200] - Step: 3950/4776 | Loss: 236.364 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 3960/4776 | Loss: 305.626 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3970/4776 | Loss: 255.491 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 3980/4776 | Loss: 294.525 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 3990/4776 | Loss: 237.954 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4000/4776 | Loss: 240.238 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4010/4776 | Loss: 281.287 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4020/4776 | Loss: 233.706 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4030/4776 | Loss: 241.780 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4040/4776 | Loss: 305.025 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4050/4776 | Loss: 259.624 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4060/4776 | Loss: 266.859 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4070/4776 | Loss: 240.838 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4080/4776 | Loss: 282.485 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4090/4776 | Loss: 259.574 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4100/4776 | Loss: 265.776 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4110/4776 | Loss: 260.244 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4120/4776 | Loss: 267.401 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4130/4776 | Loss: 280.696 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4140/4776 | Loss: 247.753 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4150/4776 | Loss: 239.257 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4160/4776 | Loss: 229.656 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4170/4776 | Loss: 236.433 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4180/4776 | Loss: 326.374 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4190/4776 | Loss: 277.928 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4200/4776 | Loss: 293.624 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4210/4776 | Loss: 265.739 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4220/4776 | Loss: 261.869 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4230/4776 | Loss: 264.523 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4240/4776 | Loss: 254.265 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4250/4776 | Loss: 252.953 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4260/4776 | Loss: 271.334 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4270/4776 | Loss: 252.755 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4280/4776 | Loss: 273.764 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4290/4776 | Loss: 267.026 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4300/4776 | Loss: 262.170 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4310/4776 | Loss: 264.536 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4320/4776 | Loss: 264.938 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4330/4776 | Loss: 291.454 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4340/4776 | Loss: 307.140 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4350/4776 | Loss: 279.805 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4360/4776 | Loss: 263.214 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4370/4776 | Loss: 248.638 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4380/4776 | Loss: 252.728 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4390/4776 | Loss: 264.444 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4400/4776 | Loss: 249.780 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4410/4776 | Loss: 281.009 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4420/4776 | Loss: 271.342 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4430/4776 | Loss: 285.156 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4440/4776 | Loss: 259.347 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4450/4776 | Loss: 263.837 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4460/4776 | Loss: 205.398 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 4470/4776 | Loss: 216.718 | Accuracy: 0.500\n",
      "[Epoch: 18/200] - Step: 4480/4776 | Loss: 249.033 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4490/4776 | Loss: 268.496 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4500/4776 | Loss: 275.781 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4510/4776 | Loss: 235.840 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4520/4776 | Loss: 234.269 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4530/4776 | Loss: 258.636 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4540/4776 | Loss: 248.823 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4550/4776 | Loss: 297.555 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4560/4776 | Loss: 254.186 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4570/4776 | Loss: 243.454 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4580/4776 | Loss: 282.488 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4590/4776 | Loss: 243.400 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 4600/4776 | Loss: 245.982 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4610/4776 | Loss: 214.883 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4620/4776 | Loss: 270.288 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4630/4776 | Loss: 256.997 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4640/4776 | Loss: 259.935 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4650/4776 | Loss: 231.908 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 4660/4776 | Loss: 292.439 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4670/4776 | Loss: 291.155 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4680/4776 | Loss: 214.682 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4690/4776 | Loss: 302.569 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4700/4776 | Loss: 270.802 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4710/4776 | Loss: 268.931 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 4720/4776 | Loss: 243.856 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4730/4776 | Loss: 269.836 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4740/4776 | Loss: 234.276 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 4750/4776 | Loss: 257.889 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4760/4776 | Loss: 265.730 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 4770/4776 | Loss: 263.736 | Accuracy: 0.100\n",
      "Accuracy:  0.12950819672131147\n",
      "Model saved!\n",
      "[Epoch: 19/200] - Step: 10/4776 | Loss: 303.899 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 20/4776 | Loss: 250.365 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 30/4776 | Loss: 323.199 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 40/4776 | Loss: 297.067 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 50/4776 | Loss: 196.691 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 60/4776 | Loss: 254.407 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 70/4776 | Loss: 288.069 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 80/4776 | Loss: 250.697 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 90/4776 | Loss: 242.999 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 100/4776 | Loss: 286.777 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 110/4776 | Loss: 267.415 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 120/4776 | Loss: 252.804 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 130/4776 | Loss: 301.513 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 140/4776 | Loss: 267.439 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 150/4776 | Loss: 237.350 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 160/4776 | Loss: 250.879 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 170/4776 | Loss: 242.071 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 180/4776 | Loss: 278.549 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 190/4776 | Loss: 275.258 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 200/4776 | Loss: 295.701 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 210/4776 | Loss: 231.897 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 220/4776 | Loss: 244.440 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 230/4776 | Loss: 226.920 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 240/4776 | Loss: 265.232 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 250/4776 | Loss: 236.012 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 260/4776 | Loss: 288.024 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 270/4776 | Loss: 274.376 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 280/4776 | Loss: 250.283 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 290/4776 | Loss: 281.357 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 300/4776 | Loss: 267.381 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 310/4776 | Loss: 260.586 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 320/4776 | Loss: 212.041 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 330/4776 | Loss: 257.571 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 340/4776 | Loss: 243.620 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 350/4776 | Loss: 234.886 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 360/4776 | Loss: 339.067 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 370/4776 | Loss: 225.070 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 380/4776 | Loss: 283.566 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 390/4776 | Loss: 273.828 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 400/4776 | Loss: 264.549 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 410/4776 | Loss: 248.699 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 420/4776 | Loss: 276.148 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 430/4776 | Loss: 278.989 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 440/4776 | Loss: 261.340 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 450/4776 | Loss: 260.085 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 460/4776 | Loss: 255.972 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 470/4776 | Loss: 256.481 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 480/4776 | Loss: 223.888 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 490/4776 | Loss: 275.601 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 500/4776 | Loss: 190.441 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 510/4776 | Loss: 241.621 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 520/4776 | Loss: 311.240 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 530/4776 | Loss: 314.614 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 540/4776 | Loss: 267.331 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 550/4776 | Loss: 294.829 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 560/4776 | Loss: 266.596 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 570/4776 | Loss: 278.430 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 580/4776 | Loss: 268.347 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 590/4776 | Loss: 245.687 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 600/4776 | Loss: 238.764 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 610/4776 | Loss: 332.020 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 620/4776 | Loss: 265.429 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 630/4776 | Loss: 235.318 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 640/4776 | Loss: 256.711 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 650/4776 | Loss: 260.102 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 660/4776 | Loss: 239.287 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 670/4776 | Loss: 233.239 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 680/4776 | Loss: 259.815 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 690/4776 | Loss: 313.477 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 700/4776 | Loss: 279.895 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 710/4776 | Loss: 272.825 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 720/4776 | Loss: 268.611 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 730/4776 | Loss: 236.038 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 740/4776 | Loss: 258.382 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 750/4776 | Loss: 267.406 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 760/4776 | Loss: 277.796 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 770/4776 | Loss: 307.124 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 780/4776 | Loss: 221.498 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 790/4776 | Loss: 289.324 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 800/4776 | Loss: 243.252 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 810/4776 | Loss: 251.921 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 820/4776 | Loss: 233.926 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 830/4776 | Loss: 269.394 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 840/4776 | Loss: 259.849 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 850/4776 | Loss: 272.515 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 860/4776 | Loss: 261.337 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 870/4776 | Loss: 250.921 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 880/4776 | Loss: 274.016 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 890/4776 | Loss: 241.706 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 900/4776 | Loss: 263.848 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 910/4776 | Loss: 248.866 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 920/4776 | Loss: 224.420 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 930/4776 | Loss: 246.682 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 940/4776 | Loss: 255.461 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 950/4776 | Loss: 254.889 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 960/4776 | Loss: 224.831 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 970/4776 | Loss: 289.800 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 980/4776 | Loss: 202.462 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 990/4776 | Loss: 283.765 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1000/4776 | Loss: 267.287 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1010/4776 | Loss: 281.879 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1020/4776 | Loss: 262.655 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1030/4776 | Loss: 273.356 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1040/4776 | Loss: 257.517 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1050/4776 | Loss: 288.953 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1060/4776 | Loss: 249.791 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1070/4776 | Loss: 269.166 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1080/4776 | Loss: 279.723 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1090/4776 | Loss: 239.198 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1100/4776 | Loss: 247.056 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1110/4776 | Loss: 240.201 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1120/4776 | Loss: 275.192 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1130/4776 | Loss: 307.502 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1140/4776 | Loss: 259.053 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1150/4776 | Loss: 251.065 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1160/4776 | Loss: 271.665 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1170/4776 | Loss: 276.528 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1180/4776 | Loss: 245.755 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1190/4776 | Loss: 229.767 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1200/4776 | Loss: 242.586 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1210/4776 | Loss: 223.564 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1220/4776 | Loss: 271.863 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1230/4776 | Loss: 243.885 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1240/4776 | Loss: 261.453 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1250/4776 | Loss: 260.533 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1260/4776 | Loss: 215.581 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1270/4776 | Loss: 207.885 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1280/4776 | Loss: 256.663 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1290/4776 | Loss: 271.937 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1300/4776 | Loss: 260.818 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1310/4776 | Loss: 284.489 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1320/4776 | Loss: 232.612 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1330/4776 | Loss: 234.500 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1340/4776 | Loss: 222.008 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1350/4776 | Loss: 259.459 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1360/4776 | Loss: 270.132 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1370/4776 | Loss: 232.962 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1380/4776 | Loss: 259.330 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1390/4776 | Loss: 254.691 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1400/4776 | Loss: 250.638 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1410/4776 | Loss: 262.209 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1420/4776 | Loss: 273.241 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1430/4776 | Loss: 268.965 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1440/4776 | Loss: 250.033 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1450/4776 | Loss: 280.946 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1460/4776 | Loss: 247.768 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1470/4776 | Loss: 232.339 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 1480/4776 | Loss: 276.168 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1490/4776 | Loss: 283.162 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1500/4776 | Loss: 264.071 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1510/4776 | Loss: 302.359 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1520/4776 | Loss: 257.840 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1530/4776 | Loss: 258.393 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1540/4776 | Loss: 244.503 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1550/4776 | Loss: 276.372 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1560/4776 | Loss: 268.973 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1570/4776 | Loss: 262.775 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1580/4776 | Loss: 248.505 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1590/4776 | Loss: 290.799 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1600/4776 | Loss: 274.850 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1610/4776 | Loss: 253.501 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1620/4776 | Loss: 263.100 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1630/4776 | Loss: 296.726 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1640/4776 | Loss: 209.753 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 1650/4776 | Loss: 253.551 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1660/4776 | Loss: 243.487 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1670/4776 | Loss: 268.098 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1680/4776 | Loss: 242.087 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1690/4776 | Loss: 249.111 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1700/4776 | Loss: 267.054 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1710/4776 | Loss: 265.046 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1720/4776 | Loss: 259.746 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1730/4776 | Loss: 279.321 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1740/4776 | Loss: 276.539 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1750/4776 | Loss: 250.405 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1760/4776 | Loss: 277.205 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1770/4776 | Loss: 261.754 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1780/4776 | Loss: 287.754 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1790/4776 | Loss: 254.512 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1800/4776 | Loss: 279.926 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1810/4776 | Loss: 234.167 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 1820/4776 | Loss: 261.007 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1830/4776 | Loss: 263.804 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1840/4776 | Loss: 246.341 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1850/4776 | Loss: 269.215 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1860/4776 | Loss: 247.112 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1870/4776 | Loss: 232.981 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1880/4776 | Loss: 289.480 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1890/4776 | Loss: 283.706 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1900/4776 | Loss: 263.607 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1910/4776 | Loss: 264.357 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1920/4776 | Loss: 318.444 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1930/4776 | Loss: 256.676 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1940/4776 | Loss: 242.571 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1950/4776 | Loss: 279.730 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1960/4776 | Loss: 248.128 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1970/4776 | Loss: 271.513 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1980/4776 | Loss: 298.200 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1990/4776 | Loss: 247.247 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2000/4776 | Loss: 249.439 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2010/4776 | Loss: 215.319 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 2020/4776 | Loss: 245.255 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2030/4776 | Loss: 311.058 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2040/4776 | Loss: 239.827 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2050/4776 | Loss: 263.267 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2060/4776 | Loss: 263.566 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2070/4776 | Loss: 233.330 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2080/4776 | Loss: 259.437 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2090/4776 | Loss: 266.549 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2100/4776 | Loss: 262.582 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2110/4776 | Loss: 247.739 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2120/4776 | Loss: 286.101 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2130/4776 | Loss: 247.685 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2140/4776 | Loss: 243.578 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2150/4776 | Loss: 260.470 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2160/4776 | Loss: 270.409 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 2170/4776 | Loss: 255.995 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2180/4776 | Loss: 211.259 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 2190/4776 | Loss: 238.823 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2200/4776 | Loss: 229.455 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2210/4776 | Loss: 250.160 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2220/4776 | Loss: 283.182 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2230/4776 | Loss: 231.622 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2240/4776 | Loss: 261.054 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2250/4776 | Loss: 263.013 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2260/4776 | Loss: 197.253 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 2270/4776 | Loss: 270.584 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2280/4776 | Loss: 274.906 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2290/4776 | Loss: 212.709 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 2300/4776 | Loss: 296.314 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2310/4776 | Loss: 241.491 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2320/4776 | Loss: 253.990 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2330/4776 | Loss: 288.193 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2340/4776 | Loss: 292.253 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2350/4776 | Loss: 287.097 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 2360/4776 | Loss: 248.035 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2370/4776 | Loss: 252.929 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2380/4776 | Loss: 258.285 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2390/4776 | Loss: 283.106 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2400/4776 | Loss: 239.553 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2410/4776 | Loss: 246.206 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2420/4776 | Loss: 274.593 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2430/4776 | Loss: 267.792 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2440/4776 | Loss: 239.092 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 2450/4776 | Loss: 262.007 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2460/4776 | Loss: 255.430 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2470/4776 | Loss: 242.648 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2480/4776 | Loss: 271.096 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2490/4776 | Loss: 260.757 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2500/4776 | Loss: 245.042 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2510/4776 | Loss: 244.861 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2520/4776 | Loss: 243.619 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2530/4776 | Loss: 291.223 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2540/4776 | Loss: 245.001 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2550/4776 | Loss: 225.029 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2560/4776 | Loss: 229.010 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 2570/4776 | Loss: 202.145 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 2580/4776 | Loss: 241.650 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2590/4776 | Loss: 279.501 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2600/4776 | Loss: 251.346 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2610/4776 | Loss: 248.150 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2620/4776 | Loss: 266.128 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2630/4776 | Loss: 228.275 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2640/4776 | Loss: 222.731 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2650/4776 | Loss: 278.917 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2660/4776 | Loss: 231.682 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2670/4776 | Loss: 319.544 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2680/4776 | Loss: 268.113 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2690/4776 | Loss: 235.403 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2700/4776 | Loss: 235.925 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2710/4776 | Loss: 284.362 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2720/4776 | Loss: 274.504 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2730/4776 | Loss: 264.188 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2740/4776 | Loss: 290.671 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2750/4776 | Loss: 272.058 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2760/4776 | Loss: 274.068 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2770/4776 | Loss: 262.058 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2780/4776 | Loss: 269.099 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2790/4776 | Loss: 264.832 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2800/4776 | Loss: 236.372 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2810/4776 | Loss: 280.459 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2820/4776 | Loss: 259.282 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2830/4776 | Loss: 257.309 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2840/4776 | Loss: 289.758 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2850/4776 | Loss: 264.481 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 2860/4776 | Loss: 270.173 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2870/4776 | Loss: 246.311 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2880/4776 | Loss: 249.713 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2890/4776 | Loss: 267.370 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2900/4776 | Loss: 228.003 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 2910/4776 | Loss: 263.744 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2920/4776 | Loss: 291.144 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2930/4776 | Loss: 233.435 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2940/4776 | Loss: 240.862 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2950/4776 | Loss: 256.426 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2960/4776 | Loss: 222.242 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 2970/4776 | Loss: 268.782 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 2980/4776 | Loss: 281.072 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 2990/4776 | Loss: 265.999 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3000/4776 | Loss: 295.812 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3010/4776 | Loss: 281.336 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3020/4776 | Loss: 251.466 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3030/4776 | Loss: 233.390 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3040/4776 | Loss: 274.191 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3050/4776 | Loss: 233.484 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3060/4776 | Loss: 286.825 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3070/4776 | Loss: 232.684 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3080/4776 | Loss: 239.694 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3090/4776 | Loss: 231.609 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3100/4776 | Loss: 273.113 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3110/4776 | Loss: 232.116 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3120/4776 | Loss: 248.880 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3130/4776 | Loss: 232.129 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3140/4776 | Loss: 227.541 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3150/4776 | Loss: 262.874 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3160/4776 | Loss: 287.143 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3170/4776 | Loss: 260.829 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3180/4776 | Loss: 271.496 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3190/4776 | Loss: 255.421 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3200/4776 | Loss: 280.586 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3210/4776 | Loss: 234.543 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3220/4776 | Loss: 266.635 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3230/4776 | Loss: 248.362 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3240/4776 | Loss: 270.398 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3250/4776 | Loss: 263.912 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3260/4776 | Loss: 207.429 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 3270/4776 | Loss: 224.105 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 3280/4776 | Loss: 285.758 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3290/4776 | Loss: 253.041 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3300/4776 | Loss: 267.949 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3310/4776 | Loss: 224.708 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3320/4776 | Loss: 287.954 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3330/4776 | Loss: 307.316 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3340/4776 | Loss: 260.456 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3350/4776 | Loss: 265.116 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3360/4776 | Loss: 242.981 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3370/4776 | Loss: 275.216 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3380/4776 | Loss: 257.504 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3390/4776 | Loss: 277.344 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3400/4776 | Loss: 258.747 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3410/4776 | Loss: 290.532 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3420/4776 | Loss: 238.165 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3430/4776 | Loss: 262.948 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3440/4776 | Loss: 272.049 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3450/4776 | Loss: 305.286 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3460/4776 | Loss: 253.075 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3470/4776 | Loss: 257.316 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3480/4776 | Loss: 302.713 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3490/4776 | Loss: 256.433 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3500/4776 | Loss: 229.868 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3510/4776 | Loss: 267.236 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3520/4776 | Loss: 246.680 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3530/4776 | Loss: 260.805 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3540/4776 | Loss: 261.201 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3550/4776 | Loss: 256.424 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3560/4776 | Loss: 229.297 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3570/4776 | Loss: 291.241 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3580/4776 | Loss: 272.858 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3590/4776 | Loss: 234.126 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3600/4776 | Loss: 254.340 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3610/4776 | Loss: 271.234 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3620/4776 | Loss: 218.246 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3630/4776 | Loss: 256.733 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3640/4776 | Loss: 234.529 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3650/4776 | Loss: 270.338 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3660/4776 | Loss: 274.480 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3670/4776 | Loss: 284.407 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3680/4776 | Loss: 319.986 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3690/4776 | Loss: 291.821 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3700/4776 | Loss: 267.462 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3710/4776 | Loss: 241.268 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3720/4776 | Loss: 309.373 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3730/4776 | Loss: 288.790 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3740/4776 | Loss: 254.658 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3750/4776 | Loss: 241.093 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3760/4776 | Loss: 245.188 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3770/4776 | Loss: 260.884 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3780/4776 | Loss: 278.476 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3790/4776 | Loss: 227.735 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3800/4776 | Loss: 271.790 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3810/4776 | Loss: 254.516 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3820/4776 | Loss: 288.414 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3830/4776 | Loss: 286.375 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3840/4776 | Loss: 206.329 | Accuracy: 0.600\n",
      "[Epoch: 19/200] - Step: 3850/4776 | Loss: 246.713 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3860/4776 | Loss: 231.306 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3870/4776 | Loss: 220.899 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 3880/4776 | Loss: 218.763 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3890/4776 | Loss: 229.057 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3900/4776 | Loss: 211.782 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3910/4776 | Loss: 279.738 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3920/4776 | Loss: 281.953 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 3930/4776 | Loss: 241.521 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3940/4776 | Loss: 257.219 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3950/4776 | Loss: 243.449 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3960/4776 | Loss: 219.365 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3970/4776 | Loss: 271.864 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 3980/4776 | Loss: 251.099 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 3990/4776 | Loss: 289.916 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4000/4776 | Loss: 241.001 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4010/4776 | Loss: 283.654 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4020/4776 | Loss: 281.552 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4030/4776 | Loss: 277.897 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4040/4776 | Loss: 250.552 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4050/4776 | Loss: 286.177 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4060/4776 | Loss: 288.591 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4070/4776 | Loss: 252.426 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4080/4776 | Loss: 282.178 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4090/4776 | Loss: 283.397 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4100/4776 | Loss: 273.310 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4110/4776 | Loss: 287.606 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4120/4776 | Loss: 243.589 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4130/4776 | Loss: 246.710 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4140/4776 | Loss: 262.801 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4150/4776 | Loss: 264.369 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4160/4776 | Loss: 279.504 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4170/4776 | Loss: 215.964 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4180/4776 | Loss: 295.382 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4190/4776 | Loss: 237.846 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4200/4776 | Loss: 249.193 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4210/4776 | Loss: 231.695 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4220/4776 | Loss: 199.732 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4230/4776 | Loss: 274.972 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4240/4776 | Loss: 232.473 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4250/4776 | Loss: 286.835 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4260/4776 | Loss: 260.881 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4270/4776 | Loss: 274.059 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4280/4776 | Loss: 239.056 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4290/4776 | Loss: 253.910 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4300/4776 | Loss: 252.800 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4310/4776 | Loss: 228.108 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4320/4776 | Loss: 269.868 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4330/4776 | Loss: 290.124 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4340/4776 | Loss: 257.866 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4350/4776 | Loss: 317.026 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4360/4776 | Loss: 232.356 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4370/4776 | Loss: 263.926 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4380/4776 | Loss: 330.168 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4390/4776 | Loss: 239.237 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4400/4776 | Loss: 279.021 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4410/4776 | Loss: 207.775 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4420/4776 | Loss: 249.776 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4430/4776 | Loss: 300.801 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4440/4776 | Loss: 282.045 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4450/4776 | Loss: 259.292 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4460/4776 | Loss: 240.346 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4470/4776 | Loss: 226.146 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4480/4776 | Loss: 284.146 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4490/4776 | Loss: 228.601 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4500/4776 | Loss: 277.572 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4510/4776 | Loss: 257.235 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4520/4776 | Loss: 208.408 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4530/4776 | Loss: 244.520 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4540/4776 | Loss: 230.212 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4550/4776 | Loss: 234.220 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4560/4776 | Loss: 275.890 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4570/4776 | Loss: 245.999 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4580/4776 | Loss: 288.652 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4590/4776 | Loss: 282.351 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4600/4776 | Loss: 223.996 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4610/4776 | Loss: 231.011 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 4620/4776 | Loss: 226.137 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4630/4776 | Loss: 242.725 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4640/4776 | Loss: 255.614 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4650/4776 | Loss: 257.571 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4660/4776 | Loss: 222.821 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 4670/4776 | Loss: 284.447 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4680/4776 | Loss: 281.474 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 4690/4776 | Loss: 240.639 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 4700/4776 | Loss: 243.573 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4710/4776 | Loss: 289.269 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4720/4776 | Loss: 282.376 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4730/4776 | Loss: 241.496 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4740/4776 | Loss: 291.775 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 4750/4776 | Loss: 231.743 | Accuracy: 0.500\n",
      "[Epoch: 19/200] - Step: 4760/4776 | Loss: 301.718 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 4770/4776 | Loss: 250.338 | Accuracy: 0.300\n",
      "Accuracy:  0.11311475409836065\n",
      "[Epoch: 20/200] - Step: 10/4776 | Loss: 282.803 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 20/4776 | Loss: 268.071 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 30/4776 | Loss: 201.126 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 40/4776 | Loss: 247.833 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 50/4776 | Loss: 254.476 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 60/4776 | Loss: 282.848 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 70/4776 | Loss: 238.010 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 80/4776 | Loss: 249.814 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 90/4776 | Loss: 259.333 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 100/4776 | Loss: 272.211 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 110/4776 | Loss: 261.000 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 120/4776 | Loss: 250.942 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 130/4776 | Loss: 280.049 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 140/4776 | Loss: 227.651 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 150/4776 | Loss: 277.682 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 160/4776 | Loss: 265.484 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 170/4776 | Loss: 266.783 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 180/4776 | Loss: 238.820 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 190/4776 | Loss: 241.594 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 200/4776 | Loss: 287.077 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 210/4776 | Loss: 246.337 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 220/4776 | Loss: 279.221 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 230/4776 | Loss: 275.855 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 240/4776 | Loss: 233.036 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 250/4776 | Loss: 255.337 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 260/4776 | Loss: 295.586 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 270/4776 | Loss: 258.317 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 280/4776 | Loss: 248.299 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 290/4776 | Loss: 261.381 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 300/4776 | Loss: 225.332 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 310/4776 | Loss: 247.186 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 320/4776 | Loss: 264.384 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 330/4776 | Loss: 248.602 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 340/4776 | Loss: 250.975 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 350/4776 | Loss: 260.203 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 360/4776 | Loss: 237.853 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 370/4776 | Loss: 299.353 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 380/4776 | Loss: 240.884 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 390/4776 | Loss: 262.050 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 400/4776 | Loss: 235.880 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 410/4776 | Loss: 298.261 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 420/4776 | Loss: 212.355 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 430/4776 | Loss: 270.849 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 440/4776 | Loss: 255.820 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 450/4776 | Loss: 237.233 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 460/4776 | Loss: 260.022 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 470/4776 | Loss: 228.993 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 480/4776 | Loss: 263.974 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 490/4776 | Loss: 283.164 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 500/4776 | Loss: 256.130 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 510/4776 | Loss: 298.994 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 520/4776 | Loss: 255.454 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 530/4776 | Loss: 268.318 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 540/4776 | Loss: 254.276 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 550/4776 | Loss: 255.011 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 560/4776 | Loss: 252.073 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 570/4776 | Loss: 251.013 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 580/4776 | Loss: 233.875 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 590/4776 | Loss: 265.618 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 600/4776 | Loss: 248.891 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 610/4776 | Loss: 288.182 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 620/4776 | Loss: 284.573 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 630/4776 | Loss: 232.770 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 640/4776 | Loss: 339.967 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 650/4776 | Loss: 258.284 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 660/4776 | Loss: 289.869 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 670/4776 | Loss: 257.677 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 680/4776 | Loss: 243.394 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 690/4776 | Loss: 227.777 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 700/4776 | Loss: 244.148 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 710/4776 | Loss: 263.567 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 720/4776 | Loss: 240.635 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 730/4776 | Loss: 257.141 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 740/4776 | Loss: 258.476 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 750/4776 | Loss: 224.989 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 760/4776 | Loss: 190.149 | Accuracy: 0.700\n",
      "[Epoch: 20/200] - Step: 770/4776 | Loss: 250.750 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 780/4776 | Loss: 271.278 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 790/4776 | Loss: 278.624 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 800/4776 | Loss: 297.951 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 810/4776 | Loss: 259.856 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 820/4776 | Loss: 320.710 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 830/4776 | Loss: 268.066 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 840/4776 | Loss: 254.419 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 850/4776 | Loss: 274.101 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 860/4776 | Loss: 276.691 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 870/4776 | Loss: 283.035 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 880/4776 | Loss: 274.247 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 890/4776 | Loss: 261.947 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 900/4776 | Loss: 274.377 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 910/4776 | Loss: 256.587 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 920/4776 | Loss: 238.299 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 930/4776 | Loss: 290.465 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 940/4776 | Loss: 240.638 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 950/4776 | Loss: 268.397 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 960/4776 | Loss: 247.639 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 970/4776 | Loss: 224.564 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 980/4776 | Loss: 246.747 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 990/4776 | Loss: 247.505 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1000/4776 | Loss: 283.480 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1010/4776 | Loss: 255.920 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1020/4776 | Loss: 266.230 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1030/4776 | Loss: 280.435 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1040/4776 | Loss: 252.319 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1050/4776 | Loss: 257.411 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1060/4776 | Loss: 214.636 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1070/4776 | Loss: 235.561 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1080/4776 | Loss: 272.679 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1090/4776 | Loss: 233.932 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1100/4776 | Loss: 248.645 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1110/4776 | Loss: 262.316 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1120/4776 | Loss: 260.292 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1130/4776 | Loss: 249.551 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1140/4776 | Loss: 249.048 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1150/4776 | Loss: 247.813 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1160/4776 | Loss: 266.187 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1170/4776 | Loss: 267.790 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1180/4776 | Loss: 259.724 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1190/4776 | Loss: 340.464 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1200/4776 | Loss: 241.681 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1210/4776 | Loss: 227.876 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1220/4776 | Loss: 260.129 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1230/4776 | Loss: 259.698 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1240/4776 | Loss: 261.136 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1250/4776 | Loss: 256.145 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1260/4776 | Loss: 242.907 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1270/4776 | Loss: 228.442 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1280/4776 | Loss: 251.340 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1290/4776 | Loss: 247.013 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1300/4776 | Loss: 279.518 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1310/4776 | Loss: 273.123 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1320/4776 | Loss: 249.422 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1330/4776 | Loss: 263.389 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1340/4776 | Loss: 276.653 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1350/4776 | Loss: 240.003 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1360/4776 | Loss: 296.517 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1370/4776 | Loss: 234.182 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1380/4776 | Loss: 269.612 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1390/4776 | Loss: 262.619 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1400/4776 | Loss: 275.256 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1410/4776 | Loss: 263.525 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1420/4776 | Loss: 283.678 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1430/4776 | Loss: 253.523 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1440/4776 | Loss: 270.728 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1450/4776 | Loss: 253.812 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1460/4776 | Loss: 261.380 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1470/4776 | Loss: 218.437 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1480/4776 | Loss: 242.721 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1490/4776 | Loss: 253.183 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1500/4776 | Loss: 214.582 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1510/4776 | Loss: 236.447 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1520/4776 | Loss: 229.632 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1530/4776 | Loss: 262.107 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1540/4776 | Loss: 325.942 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1550/4776 | Loss: 227.839 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1560/4776 | Loss: 241.725 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1570/4776 | Loss: 249.688 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1580/4776 | Loss: 258.103 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1590/4776 | Loss: 236.330 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1600/4776 | Loss: 255.044 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1610/4776 | Loss: 263.444 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1620/4776 | Loss: 258.263 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1630/4776 | Loss: 269.895 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1640/4776 | Loss: 240.610 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1650/4776 | Loss: 277.263 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1660/4776 | Loss: 278.957 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1670/4776 | Loss: 217.560 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1680/4776 | Loss: 274.816 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1690/4776 | Loss: 268.930 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1700/4776 | Loss: 283.891 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1710/4776 | Loss: 246.230 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1720/4776 | Loss: 264.039 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1730/4776 | Loss: 239.417 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1740/4776 | Loss: 294.502 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1750/4776 | Loss: 251.141 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1760/4776 | Loss: 249.392 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1770/4776 | Loss: 193.892 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1780/4776 | Loss: 256.423 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1790/4776 | Loss: 253.757 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1800/4776 | Loss: 255.837 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1810/4776 | Loss: 201.845 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1820/4776 | Loss: 234.379 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 1830/4776 | Loss: 313.136 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1840/4776 | Loss: 265.129 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1850/4776 | Loss: 256.287 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1860/4776 | Loss: 209.711 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1870/4776 | Loss: 217.257 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1880/4776 | Loss: 274.542 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1890/4776 | Loss: 248.802 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1900/4776 | Loss: 273.342 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1910/4776 | Loss: 269.790 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1920/4776 | Loss: 238.488 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1930/4776 | Loss: 262.450 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1940/4776 | Loss: 318.837 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1950/4776 | Loss: 231.484 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1960/4776 | Loss: 264.631 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1970/4776 | Loss: 267.874 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1980/4776 | Loss: 216.045 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1990/4776 | Loss: 258.815 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2000/4776 | Loss: 245.600 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2010/4776 | Loss: 230.433 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2020/4776 | Loss: 261.912 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2030/4776 | Loss: 240.925 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2040/4776 | Loss: 243.933 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2050/4776 | Loss: 239.527 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2060/4776 | Loss: 248.395 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2070/4776 | Loss: 257.168 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2080/4776 | Loss: 275.528 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2090/4776 | Loss: 264.836 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2100/4776 | Loss: 233.939 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2110/4776 | Loss: 269.365 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2120/4776 | Loss: 266.404 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2130/4776 | Loss: 278.585 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2140/4776 | Loss: 262.115 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2150/4776 | Loss: 254.156 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2160/4776 | Loss: 273.968 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2170/4776 | Loss: 297.339 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2180/4776 | Loss: 256.265 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2190/4776 | Loss: 261.143 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2200/4776 | Loss: 247.514 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2210/4776 | Loss: 250.638 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2220/4776 | Loss: 261.228 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2230/4776 | Loss: 209.548 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2240/4776 | Loss: 202.624 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2250/4776 | Loss: 256.331 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2260/4776 | Loss: 254.567 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2270/4776 | Loss: 243.479 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2280/4776 | Loss: 289.946 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2290/4776 | Loss: 274.979 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2300/4776 | Loss: 269.354 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2310/4776 | Loss: 257.909 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2320/4776 | Loss: 234.035 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2330/4776 | Loss: 251.743 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2340/4776 | Loss: 257.461 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2350/4776 | Loss: 302.262 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2360/4776 | Loss: 290.431 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2370/4776 | Loss: 274.705 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2380/4776 | Loss: 253.691 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2390/4776 | Loss: 255.412 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2400/4776 | Loss: 263.546 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2410/4776 | Loss: 266.185 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2420/4776 | Loss: 249.828 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2430/4776 | Loss: 267.081 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2440/4776 | Loss: 287.042 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2450/4776 | Loss: 253.562 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2460/4776 | Loss: 246.286 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2470/4776 | Loss: 263.300 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2480/4776 | Loss: 256.673 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2490/4776 | Loss: 285.199 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2500/4776 | Loss: 232.141 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2510/4776 | Loss: 251.151 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2520/4776 | Loss: 245.375 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2530/4776 | Loss: 234.510 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2540/4776 | Loss: 205.308 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2550/4776 | Loss: 260.664 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2560/4776 | Loss: 275.030 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2570/4776 | Loss: 249.965 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2580/4776 | Loss: 269.316 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2590/4776 | Loss: 223.012 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2600/4776 | Loss: 226.180 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2610/4776 | Loss: 237.606 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2620/4776 | Loss: 247.471 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2630/4776 | Loss: 304.948 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2640/4776 | Loss: 222.182 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 2650/4776 | Loss: 271.744 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2660/4776 | Loss: 243.806 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2670/4776 | Loss: 234.228 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2680/4776 | Loss: 273.295 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2690/4776 | Loss: 224.645 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2700/4776 | Loss: 243.553 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2710/4776 | Loss: 221.743 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2720/4776 | Loss: 268.397 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2730/4776 | Loss: 252.982 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2740/4776 | Loss: 245.186 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2750/4776 | Loss: 249.519 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2760/4776 | Loss: 313.723 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2770/4776 | Loss: 248.089 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2780/4776 | Loss: 302.541 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2790/4776 | Loss: 239.258 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2800/4776 | Loss: 234.697 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2810/4776 | Loss: 242.587 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2820/4776 | Loss: 289.709 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2830/4776 | Loss: 199.616 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2840/4776 | Loss: 280.510 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 2850/4776 | Loss: 316.866 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2860/4776 | Loss: 279.732 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2870/4776 | Loss: 252.251 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2880/4776 | Loss: 247.093 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2890/4776 | Loss: 214.725 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2900/4776 | Loss: 265.417 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2910/4776 | Loss: 234.499 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 2920/4776 | Loss: 240.240 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2930/4776 | Loss: 241.760 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2940/4776 | Loss: 265.465 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2950/4776 | Loss: 248.943 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 2960/4776 | Loss: 264.507 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2970/4776 | Loss: 238.472 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 2980/4776 | Loss: 272.616 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 2990/4776 | Loss: 325.013 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3000/4776 | Loss: 268.657 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3010/4776 | Loss: 236.475 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3020/4776 | Loss: 256.777 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3030/4776 | Loss: 281.680 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3040/4776 | Loss: 219.373 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3050/4776 | Loss: 255.314 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3060/4776 | Loss: 262.011 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3070/4776 | Loss: 250.408 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3080/4776 | Loss: 223.334 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3090/4776 | Loss: 281.846 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3100/4776 | Loss: 251.382 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3110/4776 | Loss: 229.815 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3120/4776 | Loss: 285.316 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3130/4776 | Loss: 246.339 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3140/4776 | Loss: 213.830 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3150/4776 | Loss: 287.617 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3160/4776 | Loss: 246.386 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3170/4776 | Loss: 244.381 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3180/4776 | Loss: 226.404 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3190/4776 | Loss: 242.381 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3200/4776 | Loss: 253.168 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3210/4776 | Loss: 201.501 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 3220/4776 | Loss: 250.197 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3230/4776 | Loss: 262.313 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3240/4776 | Loss: 305.985 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3250/4776 | Loss: 232.519 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3260/4776 | Loss: 270.893 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3270/4776 | Loss: 263.446 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3280/4776 | Loss: 269.605 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3290/4776 | Loss: 237.826 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3300/4776 | Loss: 247.095 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3310/4776 | Loss: 259.268 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3320/4776 | Loss: 268.234 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 3330/4776 | Loss: 255.426 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3340/4776 | Loss: 262.119 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3350/4776 | Loss: 266.116 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3360/4776 | Loss: 281.284 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3370/4776 | Loss: 270.313 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3380/4776 | Loss: 225.744 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3390/4776 | Loss: 259.117 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3400/4776 | Loss: 312.937 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3410/4776 | Loss: 262.746 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3420/4776 | Loss: 261.206 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3430/4776 | Loss: 275.545 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3440/4776 | Loss: 263.376 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3450/4776 | Loss: 241.366 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3460/4776 | Loss: 272.994 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3470/4776 | Loss: 290.611 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3480/4776 | Loss: 319.310 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3490/4776 | Loss: 221.855 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3500/4776 | Loss: 249.493 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 3510/4776 | Loss: 217.795 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 3520/4776 | Loss: 236.347 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3530/4776 | Loss: 219.175 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3540/4776 | Loss: 247.186 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3550/4776 | Loss: 295.221 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3560/4776 | Loss: 247.047 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3570/4776 | Loss: 249.978 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3580/4776 | Loss: 248.306 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3590/4776 | Loss: 247.723 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3600/4776 | Loss: 319.503 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3610/4776 | Loss: 226.617 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3620/4776 | Loss: 271.865 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3630/4776 | Loss: 243.637 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3640/4776 | Loss: 219.459 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3650/4776 | Loss: 246.784 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3660/4776 | Loss: 248.647 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3670/4776 | Loss: 265.026 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3680/4776 | Loss: 221.711 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3690/4776 | Loss: 261.744 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3700/4776 | Loss: 255.040 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3710/4776 | Loss: 267.974 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3720/4776 | Loss: 280.273 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3730/4776 | Loss: 218.603 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3740/4776 | Loss: 244.053 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3750/4776 | Loss: 297.618 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3760/4776 | Loss: 215.730 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 3770/4776 | Loss: 227.824 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 3780/4776 | Loss: 269.789 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3790/4776 | Loss: 289.755 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3800/4776 | Loss: 277.388 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3810/4776 | Loss: 287.246 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3820/4776 | Loss: 291.708 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3830/4776 | Loss: 264.031 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3840/4776 | Loss: 254.529 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3850/4776 | Loss: 257.248 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3860/4776 | Loss: 293.865 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3870/4776 | Loss: 258.977 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3880/4776 | Loss: 245.522 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3890/4776 | Loss: 240.076 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3900/4776 | Loss: 295.194 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3910/4776 | Loss: 244.072 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3920/4776 | Loss: 258.753 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3930/4776 | Loss: 237.772 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3940/4776 | Loss: 241.087 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 3950/4776 | Loss: 273.668 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 3960/4776 | Loss: 262.303 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3970/4776 | Loss: 275.001 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 3980/4776 | Loss: 262.474 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 3990/4776 | Loss: 212.006 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4000/4776 | Loss: 279.510 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4010/4776 | Loss: 246.527 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4020/4776 | Loss: 257.123 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4030/4776 | Loss: 277.665 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4040/4776 | Loss: 247.452 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4050/4776 | Loss: 234.645 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4060/4776 | Loss: 258.001 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4070/4776 | Loss: 291.068 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4080/4776 | Loss: 218.469 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4090/4776 | Loss: 273.414 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4100/4776 | Loss: 269.888 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4110/4776 | Loss: 233.913 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4120/4776 | Loss: 261.459 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4130/4776 | Loss: 253.824 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4140/4776 | Loss: 230.576 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4150/4776 | Loss: 242.601 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4160/4776 | Loss: 281.242 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4170/4776 | Loss: 289.590 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4180/4776 | Loss: 228.121 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4190/4776 | Loss: 284.280 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4200/4776 | Loss: 248.663 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4210/4776 | Loss: 251.552 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4220/4776 | Loss: 265.053 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4230/4776 | Loss: 262.972 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4240/4776 | Loss: 224.661 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 4250/4776 | Loss: 246.189 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4260/4776 | Loss: 316.207 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4270/4776 | Loss: 287.529 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4280/4776 | Loss: 277.968 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4290/4776 | Loss: 222.912 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4300/4776 | Loss: 260.617 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4310/4776 | Loss: 266.575 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4320/4776 | Loss: 267.702 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4330/4776 | Loss: 295.069 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4340/4776 | Loss: 261.075 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4350/4776 | Loss: 256.501 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4360/4776 | Loss: 243.822 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4370/4776 | Loss: 238.363 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4380/4776 | Loss: 294.519 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4390/4776 | Loss: 277.406 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4400/4776 | Loss: 269.136 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4410/4776 | Loss: 244.522 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4420/4776 | Loss: 263.658 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4430/4776 | Loss: 233.589 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 4440/4776 | Loss: 261.615 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4450/4776 | Loss: 292.299 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4460/4776 | Loss: 256.867 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4470/4776 | Loss: 254.815 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4480/4776 | Loss: 225.180 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4490/4776 | Loss: 285.265 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4500/4776 | Loss: 253.959 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4510/4776 | Loss: 248.218 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4520/4776 | Loss: 255.702 | Accuracy: 0.400\n",
      "[Epoch: 20/200] - Step: 4530/4776 | Loss: 273.935 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4540/4776 | Loss: 240.790 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4550/4776 | Loss: 223.549 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4560/4776 | Loss: 260.771 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4570/4776 | Loss: 239.577 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4580/4776 | Loss: 239.667 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4590/4776 | Loss: 283.506 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4600/4776 | Loss: 297.651 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4610/4776 | Loss: 254.058 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4620/4776 | Loss: 274.679 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4630/4776 | Loss: 204.430 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4640/4776 | Loss: 268.286 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4650/4776 | Loss: 272.406 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4660/4776 | Loss: 232.650 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4670/4776 | Loss: 226.087 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4680/4776 | Loss: 248.169 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 4690/4776 | Loss: 204.551 | Accuracy: 0.600\n",
      "[Epoch: 20/200] - Step: 4700/4776 | Loss: 212.107 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4710/4776 | Loss: 251.987 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4720/4776 | Loss: 259.318 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4730/4776 | Loss: 254.265 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4740/4776 | Loss: 273.014 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 4750/4776 | Loss: 262.082 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 4760/4776 | Loss: 256.923 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 4770/4776 | Loss: 265.683 | Accuracy: 0.300\n",
      "Accuracy:  0.16229508196721312\n",
      "Model saved!\n",
      "[Epoch: 21/200] - Step: 10/4776 | Loss: 236.701 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 20/4776 | Loss: 225.133 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 30/4776 | Loss: 236.613 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 40/4776 | Loss: 224.683 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 50/4776 | Loss: 229.167 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 60/4776 | Loss: 269.836 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 70/4776 | Loss: 233.543 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 80/4776 | Loss: 232.185 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 90/4776 | Loss: 258.225 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 100/4776 | Loss: 243.203 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 110/4776 | Loss: 216.306 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 120/4776 | Loss: 276.820 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 130/4776 | Loss: 252.373 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 140/4776 | Loss: 243.905 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 150/4776 | Loss: 263.954 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 160/4776 | Loss: 237.275 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 170/4776 | Loss: 243.093 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 180/4776 | Loss: 265.272 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 190/4776 | Loss: 261.619 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 200/4776 | Loss: 227.268 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 210/4776 | Loss: 237.841 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 220/4776 | Loss: 247.576 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 230/4776 | Loss: 256.883 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 240/4776 | Loss: 251.828 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 250/4776 | Loss: 284.685 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 260/4776 | Loss: 244.506 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 270/4776 | Loss: 212.846 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 280/4776 | Loss: 264.194 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 290/4776 | Loss: 227.607 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 300/4776 | Loss: 285.683 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 310/4776 | Loss: 230.596 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 320/4776 | Loss: 255.316 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 330/4776 | Loss: 242.146 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 340/4776 | Loss: 220.730 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 350/4776 | Loss: 237.088 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 360/4776 | Loss: 256.163 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 370/4776 | Loss: 214.278 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 380/4776 | Loss: 270.897 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 390/4776 | Loss: 246.021 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 400/4776 | Loss: 253.779 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 410/4776 | Loss: 248.104 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 420/4776 | Loss: 261.929 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 430/4776 | Loss: 268.749 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 440/4776 | Loss: 267.964 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 450/4776 | Loss: 232.843 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 460/4776 | Loss: 259.334 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 470/4776 | Loss: 237.669 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 480/4776 | Loss: 237.370 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 490/4776 | Loss: 218.232 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 500/4776 | Loss: 224.218 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 510/4776 | Loss: 243.937 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 520/4776 | Loss: 225.214 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 530/4776 | Loss: 198.078 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 540/4776 | Loss: 270.960 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 550/4776 | Loss: 244.122 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 560/4776 | Loss: 258.152 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 570/4776 | Loss: 232.703 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 580/4776 | Loss: 226.186 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 590/4776 | Loss: 277.618 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 600/4776 | Loss: 235.829 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 610/4776 | Loss: 250.720 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 620/4776 | Loss: 275.704 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 630/4776 | Loss: 237.053 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 640/4776 | Loss: 288.073 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 650/4776 | Loss: 278.809 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 660/4776 | Loss: 247.625 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 670/4776 | Loss: 256.125 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 680/4776 | Loss: 247.860 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 690/4776 | Loss: 243.662 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 700/4776 | Loss: 243.883 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 710/4776 | Loss: 232.684 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 720/4776 | Loss: 275.903 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 730/4776 | Loss: 274.537 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 740/4776 | Loss: 261.112 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 750/4776 | Loss: 248.276 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 760/4776 | Loss: 239.655 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 770/4776 | Loss: 239.604 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 780/4776 | Loss: 300.698 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 790/4776 | Loss: 213.105 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 800/4776 | Loss: 253.122 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 810/4776 | Loss: 246.638 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 820/4776 | Loss: 210.553 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 830/4776 | Loss: 267.589 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 840/4776 | Loss: 229.384 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 850/4776 | Loss: 284.493 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 860/4776 | Loss: 267.448 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 870/4776 | Loss: 240.008 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 880/4776 | Loss: 261.969 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 890/4776 | Loss: 244.617 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 900/4776 | Loss: 240.814 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 910/4776 | Loss: 239.229 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 920/4776 | Loss: 239.935 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 930/4776 | Loss: 259.819 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 940/4776 | Loss: 177.114 | Accuracy: 0.700\n",
      "[Epoch: 21/200] - Step: 950/4776 | Loss: 223.650 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 960/4776 | Loss: 335.268 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 970/4776 | Loss: 250.902 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 980/4776 | Loss: 275.542 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 990/4776 | Loss: 296.137 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1000/4776 | Loss: 251.703 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1010/4776 | Loss: 274.690 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1020/4776 | Loss: 273.819 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1030/4776 | Loss: 228.621 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1040/4776 | Loss: 222.487 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1050/4776 | Loss: 199.385 | Accuracy: 0.600\n",
      "[Epoch: 21/200] - Step: 1060/4776 | Loss: 357.393 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1070/4776 | Loss: 242.444 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1080/4776 | Loss: 282.912 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1090/4776 | Loss: 209.030 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1100/4776 | Loss: 286.032 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1110/4776 | Loss: 257.580 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1120/4776 | Loss: 320.775 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1130/4776 | Loss: 263.282 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1140/4776 | Loss: 260.527 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1150/4776 | Loss: 248.864 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1160/4776 | Loss: 202.077 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1170/4776 | Loss: 240.176 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1180/4776 | Loss: 249.102 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1190/4776 | Loss: 227.996 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1200/4776 | Loss: 210.356 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 1210/4776 | Loss: 274.806 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1220/4776 | Loss: 228.442 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1230/4776 | Loss: 226.442 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1240/4776 | Loss: 237.486 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1250/4776 | Loss: 240.695 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1260/4776 | Loss: 241.780 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 1270/4776 | Loss: 245.135 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1280/4776 | Loss: 267.078 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1290/4776 | Loss: 241.156 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1300/4776 | Loss: 228.560 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1310/4776 | Loss: 276.069 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1320/4776 | Loss: 316.995 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1330/4776 | Loss: 231.172 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1340/4776 | Loss: 233.988 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1350/4776 | Loss: 238.284 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 1360/4776 | Loss: 288.227 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1370/4776 | Loss: 220.507 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1380/4776 | Loss: 264.913 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1390/4776 | Loss: 251.640 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1400/4776 | Loss: 281.367 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1410/4776 | Loss: 318.643 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1420/4776 | Loss: 280.941 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1430/4776 | Loss: 297.681 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1440/4776 | Loss: 278.173 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1450/4776 | Loss: 286.964 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1460/4776 | Loss: 259.075 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1470/4776 | Loss: 282.576 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1480/4776 | Loss: 236.229 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 1490/4776 | Loss: 252.568 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1500/4776 | Loss: 280.711 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1510/4776 | Loss: 263.786 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1520/4776 | Loss: 263.775 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1530/4776 | Loss: 235.892 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1540/4776 | Loss: 253.614 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1550/4776 | Loss: 276.006 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1560/4776 | Loss: 278.970 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1570/4776 | Loss: 247.503 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1580/4776 | Loss: 267.122 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1590/4776 | Loss: 274.663 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1600/4776 | Loss: 241.826 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1610/4776 | Loss: 249.060 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1620/4776 | Loss: 264.492 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1630/4776 | Loss: 244.274 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1640/4776 | Loss: 285.046 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1650/4776 | Loss: 227.487 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 1660/4776 | Loss: 238.318 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1670/4776 | Loss: 227.294 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1680/4776 | Loss: 319.948 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1690/4776 | Loss: 227.379 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1700/4776 | Loss: 224.465 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1710/4776 | Loss: 242.803 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1720/4776 | Loss: 221.985 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1730/4776 | Loss: 245.792 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1740/4776 | Loss: 245.691 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1750/4776 | Loss: 229.736 | Accuracy: 0.600\n",
      "[Epoch: 21/200] - Step: 1760/4776 | Loss: 254.902 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1770/4776 | Loss: 266.756 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1780/4776 | Loss: 230.064 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1790/4776 | Loss: 264.366 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1800/4776 | Loss: 225.979 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1810/4776 | Loss: 264.825 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1820/4776 | Loss: 255.264 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1830/4776 | Loss: 248.432 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1840/4776 | Loss: 253.632 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1850/4776 | Loss: 268.504 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1860/4776 | Loss: 249.339 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1870/4776 | Loss: 227.486 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1880/4776 | Loss: 227.766 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1890/4776 | Loss: 235.529 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1900/4776 | Loss: 282.453 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1910/4776 | Loss: 244.510 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1920/4776 | Loss: 257.628 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1930/4776 | Loss: 260.126 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1940/4776 | Loss: 226.649 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1950/4776 | Loss: 258.263 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1960/4776 | Loss: 252.718 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1970/4776 | Loss: 243.363 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1980/4776 | Loss: 234.168 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1990/4776 | Loss: 236.209 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2000/4776 | Loss: 249.500 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2010/4776 | Loss: 243.902 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2020/4776 | Loss: 265.538 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2030/4776 | Loss: 265.448 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2040/4776 | Loss: 269.977 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2050/4776 | Loss: 273.893 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2060/4776 | Loss: 275.032 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2070/4776 | Loss: 268.351 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2080/4776 | Loss: 286.562 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2090/4776 | Loss: 188.623 | Accuracy: 0.600\n",
      "[Epoch: 21/200] - Step: 2100/4776 | Loss: 269.679 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2110/4776 | Loss: 248.846 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2120/4776 | Loss: 240.067 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2130/4776 | Loss: 255.916 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2140/4776 | Loss: 276.169 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2150/4776 | Loss: 245.318 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2160/4776 | Loss: 256.729 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2170/4776 | Loss: 220.177 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2180/4776 | Loss: 242.184 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2190/4776 | Loss: 246.618 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2200/4776 | Loss: 248.742 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2210/4776 | Loss: 263.876 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2220/4776 | Loss: 237.767 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2230/4776 | Loss: 285.603 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2240/4776 | Loss: 252.988 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2250/4776 | Loss: 220.165 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2260/4776 | Loss: 253.942 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2270/4776 | Loss: 227.693 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2280/4776 | Loss: 261.028 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2290/4776 | Loss: 213.318 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2300/4776 | Loss: 238.962 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2310/4776 | Loss: 330.528 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2320/4776 | Loss: 269.570 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2330/4776 | Loss: 307.183 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2340/4776 | Loss: 241.483 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2350/4776 | Loss: 263.745 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2360/4776 | Loss: 248.325 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2370/4776 | Loss: 278.488 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2380/4776 | Loss: 263.291 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2390/4776 | Loss: 255.642 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2400/4776 | Loss: 237.599 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2410/4776 | Loss: 300.830 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2420/4776 | Loss: 261.688 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2430/4776 | Loss: 256.534 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2440/4776 | Loss: 273.616 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2450/4776 | Loss: 246.307 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2460/4776 | Loss: 224.410 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2470/4776 | Loss: 258.413 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2480/4776 | Loss: 222.872 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2490/4776 | Loss: 297.232 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2500/4776 | Loss: 277.739 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2510/4776 | Loss: 272.689 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2520/4776 | Loss: 247.521 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2530/4776 | Loss: 256.512 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2540/4776 | Loss: 244.600 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2550/4776 | Loss: 229.209 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2560/4776 | Loss: 279.177 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2570/4776 | Loss: 238.575 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2580/4776 | Loss: 246.317 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2590/4776 | Loss: 231.492 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2600/4776 | Loss: 235.004 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2610/4776 | Loss: 210.764 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2620/4776 | Loss: 240.247 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2630/4776 | Loss: 247.413 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2640/4776 | Loss: 203.019 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2650/4776 | Loss: 258.634 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2660/4776 | Loss: 277.705 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2670/4776 | Loss: 268.120 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2680/4776 | Loss: 225.680 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2690/4776 | Loss: 285.762 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2700/4776 | Loss: 270.537 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2710/4776 | Loss: 256.122 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2720/4776 | Loss: 276.960 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2730/4776 | Loss: 289.264 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2740/4776 | Loss: 290.757 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2750/4776 | Loss: 279.365 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2760/4776 | Loss: 239.916 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2770/4776 | Loss: 236.067 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2780/4776 | Loss: 224.684 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2790/4776 | Loss: 256.824 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2800/4776 | Loss: 304.537 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2810/4776 | Loss: 259.424 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2820/4776 | Loss: 250.272 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2830/4776 | Loss: 234.935 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2840/4776 | Loss: 264.334 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2850/4776 | Loss: 232.078 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2860/4776 | Loss: 220.546 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2870/4776 | Loss: 215.402 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2880/4776 | Loss: 254.756 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2890/4776 | Loss: 226.817 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2900/4776 | Loss: 254.883 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2910/4776 | Loss: 215.863 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 2920/4776 | Loss: 237.290 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2930/4776 | Loss: 274.063 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 2940/4776 | Loss: 252.731 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2950/4776 | Loss: 239.272 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2960/4776 | Loss: 274.766 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 2970/4776 | Loss: 205.762 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 2980/4776 | Loss: 286.852 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 2990/4776 | Loss: 211.123 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3000/4776 | Loss: 277.818 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3010/4776 | Loss: 226.269 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3020/4776 | Loss: 255.013 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3030/4776 | Loss: 262.119 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3040/4776 | Loss: 236.117 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3050/4776 | Loss: 257.508 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3060/4776 | Loss: 226.687 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3070/4776 | Loss: 293.742 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3080/4776 | Loss: 335.549 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3090/4776 | Loss: 227.340 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3100/4776 | Loss: 231.819 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3110/4776 | Loss: 205.959 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3120/4776 | Loss: 266.714 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3130/4776 | Loss: 300.528 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3140/4776 | Loss: 255.325 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3150/4776 | Loss: 264.100 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3160/4776 | Loss: 229.216 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3170/4776 | Loss: 259.354 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3180/4776 | Loss: 220.338 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3190/4776 | Loss: 232.128 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3200/4776 | Loss: 227.930 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3210/4776 | Loss: 241.041 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3220/4776 | Loss: 236.603 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3230/4776 | Loss: 256.264 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3240/4776 | Loss: 259.226 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3250/4776 | Loss: 239.597 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3260/4776 | Loss: 267.423 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3270/4776 | Loss: 244.136 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3280/4776 | Loss: 306.684 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3290/4776 | Loss: 243.047 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3300/4776 | Loss: 258.253 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3310/4776 | Loss: 276.720 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3320/4776 | Loss: 256.161 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3330/4776 | Loss: 287.778 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3340/4776 | Loss: 234.970 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3350/4776 | Loss: 232.914 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3360/4776 | Loss: 236.752 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3370/4776 | Loss: 277.738 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3380/4776 | Loss: 274.571 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3390/4776 | Loss: 289.274 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3400/4776 | Loss: 227.578 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3410/4776 | Loss: 270.787 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3420/4776 | Loss: 246.758 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3430/4776 | Loss: 203.325 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 3440/4776 | Loss: 233.620 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3450/4776 | Loss: 235.310 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3460/4776 | Loss: 243.155 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3470/4776 | Loss: 230.926 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3480/4776 | Loss: 253.693 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3490/4776 | Loss: 289.153 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3500/4776 | Loss: 263.116 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3510/4776 | Loss: 211.706 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3520/4776 | Loss: 244.934 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3530/4776 | Loss: 281.233 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3540/4776 | Loss: 232.284 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3550/4776 | Loss: 291.357 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3560/4776 | Loss: 264.663 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3570/4776 | Loss: 206.876 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3580/4776 | Loss: 238.393 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3590/4776 | Loss: 278.328 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3600/4776 | Loss: 253.621 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3610/4776 | Loss: 267.772 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3620/4776 | Loss: 271.269 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3630/4776 | Loss: 233.250 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3640/4776 | Loss: 255.126 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3650/4776 | Loss: 271.698 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3660/4776 | Loss: 280.948 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3670/4776 | Loss: 221.366 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 3680/4776 | Loss: 223.126 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3690/4776 | Loss: 274.009 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3700/4776 | Loss: 289.430 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3710/4776 | Loss: 253.712 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3720/4776 | Loss: 231.072 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3730/4776 | Loss: 296.576 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3740/4776 | Loss: 257.158 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3750/4776 | Loss: 283.629 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3760/4776 | Loss: 303.045 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3770/4776 | Loss: 242.633 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3780/4776 | Loss: 251.933 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3790/4776 | Loss: 238.708 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3800/4776 | Loss: 264.431 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3810/4776 | Loss: 222.776 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3820/4776 | Loss: 242.911 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3830/4776 | Loss: 244.537 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3840/4776 | Loss: 231.613 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3850/4776 | Loss: 246.683 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3860/4776 | Loss: 223.335 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3870/4776 | Loss: 243.278 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3880/4776 | Loss: 215.128 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3890/4776 | Loss: 293.204 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3900/4776 | Loss: 261.974 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3910/4776 | Loss: 298.879 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3920/4776 | Loss: 258.467 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 3930/4776 | Loss: 237.651 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 3940/4776 | Loss: 239.236 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3950/4776 | Loss: 215.659 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3960/4776 | Loss: 255.645 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3970/4776 | Loss: 263.661 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 3980/4776 | Loss: 238.843 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 3990/4776 | Loss: 251.710 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4000/4776 | Loss: 286.898 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4010/4776 | Loss: 228.123 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 4020/4776 | Loss: 286.244 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4030/4776 | Loss: 264.908 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4040/4776 | Loss: 284.965 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4050/4776 | Loss: 257.281 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4060/4776 | Loss: 278.748 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4070/4776 | Loss: 230.423 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 4080/4776 | Loss: 273.213 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4090/4776 | Loss: 265.422 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4100/4776 | Loss: 268.082 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4110/4776 | Loss: 267.409 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4120/4776 | Loss: 235.763 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4130/4776 | Loss: 238.936 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4140/4776 | Loss: 265.484 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4150/4776 | Loss: 263.583 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4160/4776 | Loss: 222.261 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4170/4776 | Loss: 271.570 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4180/4776 | Loss: 242.677 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4190/4776 | Loss: 235.741 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4200/4776 | Loss: 234.733 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4210/4776 | Loss: 222.743 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 4220/4776 | Loss: 260.560 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 4230/4776 | Loss: 230.801 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4240/4776 | Loss: 291.376 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4250/4776 | Loss: 262.881 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4260/4776 | Loss: 245.526 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4270/4776 | Loss: 261.897 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4280/4776 | Loss: 261.459 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4290/4776 | Loss: 245.095 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4300/4776 | Loss: 258.418 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4310/4776 | Loss: 266.956 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4320/4776 | Loss: 265.541 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4330/4776 | Loss: 260.080 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4340/4776 | Loss: 281.115 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4350/4776 | Loss: 261.502 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4360/4776 | Loss: 231.723 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4370/4776 | Loss: 218.746 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4380/4776 | Loss: 265.997 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4390/4776 | Loss: 268.910 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4400/4776 | Loss: 261.249 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4410/4776 | Loss: 269.118 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4420/4776 | Loss: 289.795 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4430/4776 | Loss: 279.556 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4440/4776 | Loss: 257.869 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4450/4776 | Loss: 258.876 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4460/4776 | Loss: 289.014 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4470/4776 | Loss: 275.364 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4480/4776 | Loss: 247.000 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4490/4776 | Loss: 241.517 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4500/4776 | Loss: 261.956 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4510/4776 | Loss: 197.078 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4520/4776 | Loss: 244.510 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4530/4776 | Loss: 281.609 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4540/4776 | Loss: 258.534 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4550/4776 | Loss: 257.936 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4560/4776 | Loss: 261.496 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4570/4776 | Loss: 265.943 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4580/4776 | Loss: 277.593 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4590/4776 | Loss: 265.579 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4600/4776 | Loss: 239.106 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4610/4776 | Loss: 237.674 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4620/4776 | Loss: 254.825 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4630/4776 | Loss: 242.130 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4640/4776 | Loss: 237.721 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4650/4776 | Loss: 266.834 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 4660/4776 | Loss: 219.964 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4670/4776 | Loss: 234.355 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4680/4776 | Loss: 231.183 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4690/4776 | Loss: 262.521 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 4700/4776 | Loss: 217.988 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4710/4776 | Loss: 251.226 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4720/4776 | Loss: 225.353 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 4730/4776 | Loss: 256.393 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4740/4776 | Loss: 262.019 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4750/4776 | Loss: 228.441 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 4760/4776 | Loss: 227.638 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 4770/4776 | Loss: 256.747 | Accuracy: 0.200\n",
      "Accuracy:  0.13114754098360656\n",
      "[Epoch: 22/200] - Step: 10/4776 | Loss: 259.790 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 20/4776 | Loss: 290.595 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 30/4776 | Loss: 171.153 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 40/4776 | Loss: 244.577 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 50/4776 | Loss: 252.080 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 60/4776 | Loss: 317.224 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 70/4776 | Loss: 266.806 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 80/4776 | Loss: 246.532 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 90/4776 | Loss: 238.228 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 100/4776 | Loss: 268.205 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 110/4776 | Loss: 264.315 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 120/4776 | Loss: 273.807 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 130/4776 | Loss: 257.960 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 140/4776 | Loss: 260.316 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 150/4776 | Loss: 231.839 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 160/4776 | Loss: 218.704 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 170/4776 | Loss: 276.291 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 180/4776 | Loss: 175.258 | Accuracy: 0.600\n",
      "[Epoch: 22/200] - Step: 190/4776 | Loss: 245.872 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 200/4776 | Loss: 277.095 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 210/4776 | Loss: 226.424 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 220/4776 | Loss: 215.340 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 230/4776 | Loss: 252.821 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 240/4776 | Loss: 259.747 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 250/4776 | Loss: 197.404 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 260/4776 | Loss: 256.911 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 270/4776 | Loss: 225.548 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 280/4776 | Loss: 238.647 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 290/4776 | Loss: 285.347 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 300/4776 | Loss: 260.362 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 310/4776 | Loss: 213.807 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 320/4776 | Loss: 253.444 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 330/4776 | Loss: 246.140 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 340/4776 | Loss: 256.967 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 350/4776 | Loss: 218.926 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 360/4776 | Loss: 247.084 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 370/4776 | Loss: 234.926 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 380/4776 | Loss: 260.446 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 390/4776 | Loss: 221.577 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 400/4776 | Loss: 224.455 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 410/4776 | Loss: 268.384 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 420/4776 | Loss: 271.194 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 430/4776 | Loss: 237.161 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 440/4776 | Loss: 260.846 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 450/4776 | Loss: 255.560 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 460/4776 | Loss: 280.665 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 470/4776 | Loss: 227.136 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 480/4776 | Loss: 301.173 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 490/4776 | Loss: 237.569 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 500/4776 | Loss: 244.777 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 510/4776 | Loss: 255.715 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 520/4776 | Loss: 223.583 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 530/4776 | Loss: 290.422 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 540/4776 | Loss: 284.547 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 550/4776 | Loss: 251.303 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 560/4776 | Loss: 270.248 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 570/4776 | Loss: 234.050 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 580/4776 | Loss: 257.402 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 590/4776 | Loss: 285.776 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 600/4776 | Loss: 231.641 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 610/4776 | Loss: 285.351 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 620/4776 | Loss: 245.751 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 630/4776 | Loss: 273.126 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 640/4776 | Loss: 234.509 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 650/4776 | Loss: 218.335 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 660/4776 | Loss: 228.613 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 670/4776 | Loss: 246.161 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 680/4776 | Loss: 243.347 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 690/4776 | Loss: 244.091 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 700/4776 | Loss: 255.168 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 710/4776 | Loss: 264.743 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 720/4776 | Loss: 253.943 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 730/4776 | Loss: 245.463 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 740/4776 | Loss: 246.377 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 750/4776 | Loss: 267.951 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 760/4776 | Loss: 288.632 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 770/4776 | Loss: 238.986 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 780/4776 | Loss: 274.701 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 790/4776 | Loss: 211.513 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 800/4776 | Loss: 211.758 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 810/4776 | Loss: 227.311 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 820/4776 | Loss: 254.391 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 830/4776 | Loss: 253.375 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 840/4776 | Loss: 248.607 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 850/4776 | Loss: 267.190 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 860/4776 | Loss: 215.043 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 870/4776 | Loss: 241.818 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 880/4776 | Loss: 234.752 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 890/4776 | Loss: 261.945 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 900/4776 | Loss: 260.392 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 910/4776 | Loss: 250.065 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 920/4776 | Loss: 276.578 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 930/4776 | Loss: 222.081 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 940/4776 | Loss: 206.827 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 950/4776 | Loss: 239.930 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 960/4776 | Loss: 249.322 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 970/4776 | Loss: 228.854 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 980/4776 | Loss: 334.001 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 990/4776 | Loss: 255.820 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1000/4776 | Loss: 231.703 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1010/4776 | Loss: 280.466 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1020/4776 | Loss: 216.391 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1030/4776 | Loss: 240.024 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1040/4776 | Loss: 263.633 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1050/4776 | Loss: 251.005 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1060/4776 | Loss: 246.030 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1070/4776 | Loss: 210.792 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1080/4776 | Loss: 284.556 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1090/4776 | Loss: 263.785 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1100/4776 | Loss: 243.735 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1110/4776 | Loss: 230.773 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1120/4776 | Loss: 223.527 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1130/4776 | Loss: 242.330 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1140/4776 | Loss: 229.800 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1150/4776 | Loss: 201.201 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1160/4776 | Loss: 236.690 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1170/4776 | Loss: 258.293 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1180/4776 | Loss: 247.624 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1190/4776 | Loss: 201.622 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1200/4776 | Loss: 236.271 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1210/4776 | Loss: 216.428 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1220/4776 | Loss: 266.634 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1230/4776 | Loss: 234.838 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1240/4776 | Loss: 229.858 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1250/4776 | Loss: 255.183 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1260/4776 | Loss: 264.860 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1270/4776 | Loss: 259.629 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1280/4776 | Loss: 295.927 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1290/4776 | Loss: 277.271 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1300/4776 | Loss: 234.146 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1310/4776 | Loss: 255.706 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1320/4776 | Loss: 250.637 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1330/4776 | Loss: 260.419 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1340/4776 | Loss: 238.094 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1350/4776 | Loss: 235.811 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1360/4776 | Loss: 233.077 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1370/4776 | Loss: 252.092 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1380/4776 | Loss: 223.111 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1390/4776 | Loss: 246.061 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1400/4776 | Loss: 250.866 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1410/4776 | Loss: 253.773 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1420/4776 | Loss: 223.264 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1430/4776 | Loss: 255.394 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1440/4776 | Loss: 246.354 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1450/4776 | Loss: 261.277 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1460/4776 | Loss: 268.598 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1470/4776 | Loss: 241.693 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1480/4776 | Loss: 237.976 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1490/4776 | Loss: 232.405 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1500/4776 | Loss: 196.537 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1510/4776 | Loss: 241.233 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1520/4776 | Loss: 229.345 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1530/4776 | Loss: 271.305 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1540/4776 | Loss: 248.244 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1550/4776 | Loss: 254.815 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1560/4776 | Loss: 261.034 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1570/4776 | Loss: 308.149 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1580/4776 | Loss: 227.334 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1590/4776 | Loss: 256.214 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1600/4776 | Loss: 217.826 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1610/4776 | Loss: 238.351 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1620/4776 | Loss: 276.354 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1630/4776 | Loss: 240.174 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1640/4776 | Loss: 221.889 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1650/4776 | Loss: 339.363 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1660/4776 | Loss: 276.864 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1670/4776 | Loss: 277.185 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1680/4776 | Loss: 226.353 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1690/4776 | Loss: 245.037 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1700/4776 | Loss: 221.130 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1710/4776 | Loss: 247.944 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1720/4776 | Loss: 258.027 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1730/4776 | Loss: 246.145 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1740/4776 | Loss: 257.658 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1750/4776 | Loss: 218.546 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1760/4776 | Loss: 249.632 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1770/4776 | Loss: 246.999 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1780/4776 | Loss: 231.929 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 1790/4776 | Loss: 254.889 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1800/4776 | Loss: 253.704 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1810/4776 | Loss: 286.479 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1820/4776 | Loss: 267.502 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1830/4776 | Loss: 264.385 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1840/4776 | Loss: 204.857 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1850/4776 | Loss: 267.762 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1860/4776 | Loss: 208.217 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 1870/4776 | Loss: 288.777 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1880/4776 | Loss: 223.325 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1890/4776 | Loss: 229.225 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1900/4776 | Loss: 262.200 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1910/4776 | Loss: 235.050 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1920/4776 | Loss: 261.983 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1930/4776 | Loss: 321.118 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1940/4776 | Loss: 233.505 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1950/4776 | Loss: 217.213 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1960/4776 | Loss: 223.584 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1970/4776 | Loss: 226.660 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1980/4776 | Loss: 246.819 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1990/4776 | Loss: 228.359 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2000/4776 | Loss: 242.711 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2010/4776 | Loss: 244.177 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2020/4776 | Loss: 225.597 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2030/4776 | Loss: 262.654 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2040/4776 | Loss: 244.854 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2050/4776 | Loss: 222.039 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 2060/4776 | Loss: 199.002 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2070/4776 | Loss: 232.668 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2080/4776 | Loss: 265.219 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2090/4776 | Loss: 208.625 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 2100/4776 | Loss: 246.107 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2110/4776 | Loss: 236.695 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2120/4776 | Loss: 205.768 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2130/4776 | Loss: 198.293 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2140/4776 | Loss: 258.757 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2150/4776 | Loss: 223.592 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2160/4776 | Loss: 289.403 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2170/4776 | Loss: 269.950 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2180/4776 | Loss: 286.077 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2190/4776 | Loss: 258.028 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2200/4776 | Loss: 231.240 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2210/4776 | Loss: 250.820 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2220/4776 | Loss: 269.577 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2230/4776 | Loss: 257.523 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2240/4776 | Loss: 248.492 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2250/4776 | Loss: 259.279 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2260/4776 | Loss: 211.983 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2270/4776 | Loss: 193.495 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2280/4776 | Loss: 283.920 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2290/4776 | Loss: 278.557 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2300/4776 | Loss: 194.482 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 2310/4776 | Loss: 258.972 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2320/4776 | Loss: 215.289 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2330/4776 | Loss: 295.826 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2340/4776 | Loss: 241.652 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2350/4776 | Loss: 237.159 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2360/4776 | Loss: 243.367 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2370/4776 | Loss: 242.492 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2380/4776 | Loss: 246.472 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2390/4776 | Loss: 235.602 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2400/4776 | Loss: 261.330 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2410/4776 | Loss: 289.721 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2420/4776 | Loss: 258.458 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2430/4776 | Loss: 214.425 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2440/4776 | Loss: 241.278 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2450/4776 | Loss: 292.528 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2460/4776 | Loss: 252.365 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2470/4776 | Loss: 206.398 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2480/4776 | Loss: 258.967 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2490/4776 | Loss: 199.669 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2500/4776 | Loss: 235.276 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2510/4776 | Loss: 235.272 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2520/4776 | Loss: 263.609 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2530/4776 | Loss: 247.974 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2540/4776 | Loss: 258.237 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2550/4776 | Loss: 236.398 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2560/4776 | Loss: 219.828 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2570/4776 | Loss: 242.908 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2580/4776 | Loss: 300.802 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2590/4776 | Loss: 232.167 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2600/4776 | Loss: 217.014 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2610/4776 | Loss: 272.659 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2620/4776 | Loss: 279.298 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2630/4776 | Loss: 235.765 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2640/4776 | Loss: 242.488 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 2650/4776 | Loss: 247.122 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2660/4776 | Loss: 186.723 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2670/4776 | Loss: 269.949 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2680/4776 | Loss: 248.320 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2690/4776 | Loss: 206.487 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2700/4776 | Loss: 249.448 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2710/4776 | Loss: 228.649 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2720/4776 | Loss: 245.295 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2730/4776 | Loss: 189.244 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2740/4776 | Loss: 243.821 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2750/4776 | Loss: 256.793 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2760/4776 | Loss: 230.675 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2770/4776 | Loss: 282.350 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2780/4776 | Loss: 245.188 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2790/4776 | Loss: 195.344 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2800/4776 | Loss: 237.090 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2810/4776 | Loss: 292.937 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2820/4776 | Loss: 197.894 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2830/4776 | Loss: 267.871 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2840/4776 | Loss: 245.326 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2850/4776 | Loss: 244.902 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2860/4776 | Loss: 288.256 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2870/4776 | Loss: 233.246 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 2880/4776 | Loss: 272.664 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2890/4776 | Loss: 262.137 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2900/4776 | Loss: 307.495 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2910/4776 | Loss: 245.166 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2920/4776 | Loss: 241.999 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2930/4776 | Loss: 342.694 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 2940/4776 | Loss: 240.869 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 2950/4776 | Loss: 227.374 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2960/4776 | Loss: 255.539 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 2970/4776 | Loss: 203.395 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 2980/4776 | Loss: 245.316 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 2990/4776 | Loss: 212.515 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3000/4776 | Loss: 219.014 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3010/4776 | Loss: 205.844 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3020/4776 | Loss: 266.471 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3030/4776 | Loss: 229.975 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3040/4776 | Loss: 243.642 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3050/4776 | Loss: 228.168 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3060/4776 | Loss: 220.426 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3070/4776 | Loss: 227.720 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3080/4776 | Loss: 245.814 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3090/4776 | Loss: 219.557 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3100/4776 | Loss: 287.031 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3110/4776 | Loss: 231.011 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3120/4776 | Loss: 261.943 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3130/4776 | Loss: 211.628 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3140/4776 | Loss: 245.002 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3150/4776 | Loss: 219.305 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3160/4776 | Loss: 278.957 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3170/4776 | Loss: 258.178 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3180/4776 | Loss: 280.444 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3190/4776 | Loss: 229.097 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3200/4776 | Loss: 214.088 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3210/4776 | Loss: 237.391 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3220/4776 | Loss: 236.757 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3230/4776 | Loss: 223.663 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3240/4776 | Loss: 258.027 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3250/4776 | Loss: 217.342 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3260/4776 | Loss: 245.782 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3270/4776 | Loss: 307.865 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3280/4776 | Loss: 245.184 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3290/4776 | Loss: 303.643 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3300/4776 | Loss: 240.631 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3310/4776 | Loss: 230.263 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3320/4776 | Loss: 238.674 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3330/4776 | Loss: 274.922 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3340/4776 | Loss: 228.674 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3350/4776 | Loss: 246.990 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3360/4776 | Loss: 248.009 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3370/4776 | Loss: 215.976 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3380/4776 | Loss: 204.847 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 3390/4776 | Loss: 290.389 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3400/4776 | Loss: 218.026 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 3410/4776 | Loss: 297.733 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3420/4776 | Loss: 226.789 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3430/4776 | Loss: 231.647 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3440/4776 | Loss: 192.188 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 3450/4776 | Loss: 228.224 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3460/4776 | Loss: 255.866 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3470/4776 | Loss: 240.690 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3480/4776 | Loss: 233.350 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3490/4776 | Loss: 298.700 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3500/4776 | Loss: 271.697 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3510/4776 | Loss: 222.458 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 3520/4776 | Loss: 262.600 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3530/4776 | Loss: 231.544 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3540/4776 | Loss: 221.991 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3550/4776 | Loss: 233.275 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3560/4776 | Loss: 275.183 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3570/4776 | Loss: 217.362 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3580/4776 | Loss: 233.750 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3590/4776 | Loss: 265.956 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3600/4776 | Loss: 296.157 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3610/4776 | Loss: 232.346 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3620/4776 | Loss: 356.174 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3630/4776 | Loss: 295.807 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3640/4776 | Loss: 273.001 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3650/4776 | Loss: 307.969 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3660/4776 | Loss: 252.517 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3670/4776 | Loss: 229.452 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3680/4776 | Loss: 277.102 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3690/4776 | Loss: 236.291 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3700/4776 | Loss: 230.837 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3710/4776 | Loss: 255.037 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3720/4776 | Loss: 259.592 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3730/4776 | Loss: 213.574 | Accuracy: 0.500\n",
      "[Epoch: 22/200] - Step: 3740/4776 | Loss: 264.612 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3750/4776 | Loss: 227.758 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3760/4776 | Loss: 246.827 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3770/4776 | Loss: 281.524 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3780/4776 | Loss: 190.574 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 3790/4776 | Loss: 270.894 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3800/4776 | Loss: 216.466 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3810/4776 | Loss: 268.374 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3820/4776 | Loss: 240.277 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3830/4776 | Loss: 272.321 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3840/4776 | Loss: 253.136 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3850/4776 | Loss: 242.321 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3860/4776 | Loss: 241.169 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3870/4776 | Loss: 244.280 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3880/4776 | Loss: 247.551 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3890/4776 | Loss: 232.245 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3900/4776 | Loss: 218.559 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3910/4776 | Loss: 240.331 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3920/4776 | Loss: 235.347 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 3930/4776 | Loss: 253.535 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3940/4776 | Loss: 235.026 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 3950/4776 | Loss: 242.136 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3960/4776 | Loss: 230.067 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 3970/4776 | Loss: 264.166 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3980/4776 | Loss: 274.922 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 3990/4776 | Loss: 312.555 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4000/4776 | Loss: 247.442 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4010/4776 | Loss: 246.148 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4020/4776 | Loss: 212.602 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4030/4776 | Loss: 202.491 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4040/4776 | Loss: 269.024 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4050/4776 | Loss: 239.032 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4060/4776 | Loss: 312.417 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4070/4776 | Loss: 258.935 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4080/4776 | Loss: 285.056 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4090/4776 | Loss: 256.084 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4100/4776 | Loss: 238.020 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4110/4776 | Loss: 198.054 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4120/4776 | Loss: 260.432 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4130/4776 | Loss: 248.476 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4140/4776 | Loss: 255.990 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4150/4776 | Loss: 248.278 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4160/4776 | Loss: 248.763 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4170/4776 | Loss: 261.290 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4180/4776 | Loss: 296.278 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4190/4776 | Loss: 253.850 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4200/4776 | Loss: 225.400 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4210/4776 | Loss: 217.351 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4220/4776 | Loss: 270.883 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4230/4776 | Loss: 215.653 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4240/4776 | Loss: 268.913 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4250/4776 | Loss: 266.989 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4260/4776 | Loss: 222.073 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4270/4776 | Loss: 225.009 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4280/4776 | Loss: 222.777 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4290/4776 | Loss: 247.237 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4300/4776 | Loss: 274.316 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4310/4776 | Loss: 273.163 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4320/4776 | Loss: 232.246 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4330/4776 | Loss: 202.499 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4340/4776 | Loss: 269.699 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4350/4776 | Loss: 240.609 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4360/4776 | Loss: 234.965 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4370/4776 | Loss: 257.769 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4380/4776 | Loss: 249.196 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4390/4776 | Loss: 235.147 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4400/4776 | Loss: 244.463 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4410/4776 | Loss: 217.620 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4420/4776 | Loss: 250.284 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4430/4776 | Loss: 261.521 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4440/4776 | Loss: 215.597 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4450/4776 | Loss: 276.138 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4460/4776 | Loss: 203.531 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4470/4776 | Loss: 268.118 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4480/4776 | Loss: 229.732 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4490/4776 | Loss: 233.317 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4500/4776 | Loss: 238.202 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4510/4776 | Loss: 299.116 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4520/4776 | Loss: 327.698 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4530/4776 | Loss: 234.143 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4540/4776 | Loss: 267.341 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4550/4776 | Loss: 212.390 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4560/4776 | Loss: 204.549 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4570/4776 | Loss: 257.876 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4580/4776 | Loss: 303.682 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4590/4776 | Loss: 247.168 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4600/4776 | Loss: 298.443 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4610/4776 | Loss: 250.388 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4620/4776 | Loss: 233.406 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4630/4776 | Loss: 232.487 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4640/4776 | Loss: 293.802 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4650/4776 | Loss: 239.569 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4660/4776 | Loss: 261.377 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 4670/4776 | Loss: 251.802 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4680/4776 | Loss: 245.203 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4690/4776 | Loss: 273.733 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4700/4776 | Loss: 263.613 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4710/4776 | Loss: 245.191 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4720/4776 | Loss: 253.784 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4730/4776 | Loss: 223.967 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 4740/4776 | Loss: 228.703 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 4750/4776 | Loss: 235.589 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 4760/4776 | Loss: 244.170 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 4770/4776 | Loss: 233.894 | Accuracy: 0.300\n",
      "Accuracy:  0.14590163934426228\n",
      "[Epoch: 23/200] - Step: 10/4776 | Loss: 237.304 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 20/4776 | Loss: 246.006 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 30/4776 | Loss: 208.884 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 40/4776 | Loss: 158.716 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 50/4776 | Loss: 222.228 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 60/4776 | Loss: 239.327 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 70/4776 | Loss: 234.463 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 80/4776 | Loss: 245.476 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 90/4776 | Loss: 269.795 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 100/4776 | Loss: 222.051 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 110/4776 | Loss: 228.218 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 120/4776 | Loss: 216.562 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 130/4776 | Loss: 254.740 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 140/4776 | Loss: 215.565 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 150/4776 | Loss: 229.795 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 160/4776 | Loss: 257.482 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 170/4776 | Loss: 236.555 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 180/4776 | Loss: 250.139 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 190/4776 | Loss: 249.415 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 200/4776 | Loss: 234.286 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 210/4776 | Loss: 245.028 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 220/4776 | Loss: 247.496 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 230/4776 | Loss: 262.902 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 240/4776 | Loss: 227.537 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 250/4776 | Loss: 238.092 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 260/4776 | Loss: 274.030 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 270/4776 | Loss: 246.655 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 280/4776 | Loss: 227.994 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 290/4776 | Loss: 253.400 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 300/4776 | Loss: 256.405 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 310/4776 | Loss: 233.477 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 320/4776 | Loss: 247.048 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 330/4776 | Loss: 234.483 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 340/4776 | Loss: 240.235 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 350/4776 | Loss: 260.279 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 360/4776 | Loss: 231.222 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 370/4776 | Loss: 200.752 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 380/4776 | Loss: 242.713 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 390/4776 | Loss: 247.695 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 400/4776 | Loss: 189.791 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 410/4776 | Loss: 247.770 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 420/4776 | Loss: 226.106 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 430/4776 | Loss: 296.966 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 440/4776 | Loss: 276.990 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 450/4776 | Loss: 245.056 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 460/4776 | Loss: 237.055 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 470/4776 | Loss: 260.228 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 480/4776 | Loss: 246.010 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 490/4776 | Loss: 230.973 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 500/4776 | Loss: 327.283 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 510/4776 | Loss: 276.390 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 520/4776 | Loss: 225.526 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 530/4776 | Loss: 259.152 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 540/4776 | Loss: 251.164 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 550/4776 | Loss: 204.571 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 560/4776 | Loss: 243.100 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 570/4776 | Loss: 256.224 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 580/4776 | Loss: 265.251 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 590/4776 | Loss: 234.419 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 600/4776 | Loss: 233.180 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 610/4776 | Loss: 243.664 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 620/4776 | Loss: 240.654 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 630/4776 | Loss: 281.700 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 640/4776 | Loss: 269.259 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 650/4776 | Loss: 241.387 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 660/4776 | Loss: 242.524 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 670/4776 | Loss: 256.426 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 680/4776 | Loss: 272.903 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 690/4776 | Loss: 247.156 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 700/4776 | Loss: 246.491 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 710/4776 | Loss: 248.534 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 720/4776 | Loss: 298.764 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 730/4776 | Loss: 256.318 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 740/4776 | Loss: 220.311 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 750/4776 | Loss: 264.300 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 760/4776 | Loss: 225.453 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 770/4776 | Loss: 239.214 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 780/4776 | Loss: 253.172 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 790/4776 | Loss: 243.038 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 800/4776 | Loss: 222.580 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 810/4776 | Loss: 241.758 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 820/4776 | Loss: 248.019 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 830/4776 | Loss: 268.731 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 840/4776 | Loss: 242.300 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 850/4776 | Loss: 276.201 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 860/4776 | Loss: 259.486 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 870/4776 | Loss: 261.385 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 880/4776 | Loss: 258.917 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 890/4776 | Loss: 235.747 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 900/4776 | Loss: 239.828 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 910/4776 | Loss: 249.523 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 920/4776 | Loss: 243.064 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 930/4776 | Loss: 233.675 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 940/4776 | Loss: 253.414 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 950/4776 | Loss: 264.165 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 960/4776 | Loss: 220.471 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 970/4776 | Loss: 253.899 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 980/4776 | Loss: 245.430 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 990/4776 | Loss: 239.973 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1000/4776 | Loss: 194.807 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 1010/4776 | Loss: 218.457 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1020/4776 | Loss: 210.203 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1030/4776 | Loss: 268.804 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1040/4776 | Loss: 243.856 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1050/4776 | Loss: 219.080 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1060/4776 | Loss: 259.403 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1070/4776 | Loss: 208.205 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 1080/4776 | Loss: 252.646 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1090/4776 | Loss: 288.958 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1100/4776 | Loss: 260.592 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1110/4776 | Loss: 225.833 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1120/4776 | Loss: 206.496 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1130/4776 | Loss: 251.536 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1140/4776 | Loss: 231.902 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1150/4776 | Loss: 258.225 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1160/4776 | Loss: 244.953 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1170/4776 | Loss: 207.384 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1180/4776 | Loss: 241.466 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1190/4776 | Loss: 244.567 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1200/4776 | Loss: 248.676 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1210/4776 | Loss: 215.721 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 1220/4776 | Loss: 234.451 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1230/4776 | Loss: 230.138 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1240/4776 | Loss: 249.096 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1250/4776 | Loss: 252.595 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1260/4776 | Loss: 227.214 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1270/4776 | Loss: 264.419 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1280/4776 | Loss: 303.531 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1290/4776 | Loss: 247.691 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1300/4776 | Loss: 262.589 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1310/4776 | Loss: 219.334 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1320/4776 | Loss: 280.933 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1330/4776 | Loss: 232.744 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1340/4776 | Loss: 252.015 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1350/4776 | Loss: 200.302 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 1360/4776 | Loss: 268.410 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1370/4776 | Loss: 246.480 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1380/4776 | Loss: 271.169 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1390/4776 | Loss: 229.628 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1400/4776 | Loss: 193.927 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1410/4776 | Loss: 271.718 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1420/4776 | Loss: 220.291 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1430/4776 | Loss: 207.145 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1440/4776 | Loss: 219.219 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1450/4776 | Loss: 225.917 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1460/4776 | Loss: 269.585 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1470/4776 | Loss: 199.435 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 1480/4776 | Loss: 234.867 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1490/4776 | Loss: 221.707 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1500/4776 | Loss: 238.576 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1510/4776 | Loss: 202.655 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1520/4776 | Loss: 253.468 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1530/4776 | Loss: 343.526 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1540/4776 | Loss: 247.190 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1550/4776 | Loss: 227.973 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1560/4776 | Loss: 245.933 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1570/4776 | Loss: 253.019 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1580/4776 | Loss: 207.110 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1590/4776 | Loss: 257.039 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1600/4776 | Loss: 225.657 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1610/4776 | Loss: 233.153 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1620/4776 | Loss: 234.564 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1630/4776 | Loss: 215.450 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 1640/4776 | Loss: 227.206 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1650/4776 | Loss: 205.978 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1660/4776 | Loss: 198.525 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1670/4776 | Loss: 250.508 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1680/4776 | Loss: 300.665 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1690/4776 | Loss: 254.699 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1700/4776 | Loss: 248.653 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1710/4776 | Loss: 222.734 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1720/4776 | Loss: 248.717 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1730/4776 | Loss: 235.224 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1740/4776 | Loss: 211.180 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1750/4776 | Loss: 230.673 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1760/4776 | Loss: 264.119 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1770/4776 | Loss: 243.673 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1780/4776 | Loss: 277.285 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1790/4776 | Loss: 216.625 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1800/4776 | Loss: 222.772 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1810/4776 | Loss: 225.561 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1820/4776 | Loss: 237.519 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1830/4776 | Loss: 232.082 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1840/4776 | Loss: 242.783 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1850/4776 | Loss: 239.313 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1860/4776 | Loss: 306.171 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1870/4776 | Loss: 224.104 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1880/4776 | Loss: 209.970 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1890/4776 | Loss: 253.915 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1900/4776 | Loss: 211.594 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1910/4776 | Loss: 286.531 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1920/4776 | Loss: 245.947 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1930/4776 | Loss: 201.535 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 1940/4776 | Loss: 215.461 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 1950/4776 | Loss: 269.845 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1960/4776 | Loss: 251.642 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1970/4776 | Loss: 243.356 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1980/4776 | Loss: 216.318 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1990/4776 | Loss: 202.404 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2000/4776 | Loss: 261.711 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2010/4776 | Loss: 262.433 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2020/4776 | Loss: 214.135 | Accuracy: 0.600\n",
      "[Epoch: 23/200] - Step: 2030/4776 | Loss: 183.028 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 2040/4776 | Loss: 272.974 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2050/4776 | Loss: 224.533 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2060/4776 | Loss: 205.242 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2070/4776 | Loss: 246.285 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2080/4776 | Loss: 221.544 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2090/4776 | Loss: 292.428 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2100/4776 | Loss: 232.405 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2110/4776 | Loss: 230.813 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2120/4776 | Loss: 225.474 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2130/4776 | Loss: 227.048 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2140/4776 | Loss: 228.931 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 2150/4776 | Loss: 253.151 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2160/4776 | Loss: 250.949 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2170/4776 | Loss: 208.802 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2180/4776 | Loss: 220.623 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 2190/4776 | Loss: 227.544 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2200/4776 | Loss: 229.679 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2210/4776 | Loss: 189.769 | Accuracy: 0.600\n",
      "[Epoch: 23/200] - Step: 2220/4776 | Loss: 260.659 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2230/4776 | Loss: 233.410 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2240/4776 | Loss: 348.568 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2250/4776 | Loss: 253.784 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2260/4776 | Loss: 212.039 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2270/4776 | Loss: 230.628 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2280/4776 | Loss: 245.978 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2290/4776 | Loss: 210.402 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2300/4776 | Loss: 242.439 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2310/4776 | Loss: 226.348 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2320/4776 | Loss: 291.181 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2330/4776 | Loss: 184.075 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 2340/4776 | Loss: 281.654 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2350/4776 | Loss: 227.946 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2360/4776 | Loss: 221.065 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2370/4776 | Loss: 267.682 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2380/4776 | Loss: 228.444 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2390/4776 | Loss: 299.491 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2400/4776 | Loss: 243.016 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2410/4776 | Loss: 302.342 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2420/4776 | Loss: 268.943 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2430/4776 | Loss: 225.475 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2440/4776 | Loss: 247.656 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2450/4776 | Loss: 237.130 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2460/4776 | Loss: 237.426 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2470/4776 | Loss: 236.680 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2480/4776 | Loss: 241.886 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2490/4776 | Loss: 258.391 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2500/4776 | Loss: 270.537 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2510/4776 | Loss: 213.355 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2520/4776 | Loss: 273.013 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2530/4776 | Loss: 217.013 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2540/4776 | Loss: 252.465 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2550/4776 | Loss: 247.806 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2560/4776 | Loss: 251.361 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2570/4776 | Loss: 277.406 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2580/4776 | Loss: 231.796 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2590/4776 | Loss: 237.052 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2600/4776 | Loss: 242.975 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2610/4776 | Loss: 331.633 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2620/4776 | Loss: 235.254 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2630/4776 | Loss: 239.253 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2640/4776 | Loss: 288.169 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2650/4776 | Loss: 244.641 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2660/4776 | Loss: 249.237 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2670/4776 | Loss: 219.842 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2680/4776 | Loss: 256.889 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2690/4776 | Loss: 282.161 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2700/4776 | Loss: 218.833 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 2710/4776 | Loss: 233.593 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2720/4776 | Loss: 225.519 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2730/4776 | Loss: 261.105 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2740/4776 | Loss: 240.392 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2750/4776 | Loss: 253.958 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2760/4776 | Loss: 267.754 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2770/4776 | Loss: 221.419 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2780/4776 | Loss: 220.477 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2790/4776 | Loss: 244.657 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2800/4776 | Loss: 185.961 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2810/4776 | Loss: 232.887 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2820/4776 | Loss: 305.111 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2830/4776 | Loss: 270.385 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2840/4776 | Loss: 241.054 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2850/4776 | Loss: 227.350 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2860/4776 | Loss: 245.071 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2870/4776 | Loss: 182.169 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 2880/4776 | Loss: 257.176 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2890/4776 | Loss: 235.977 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2900/4776 | Loss: 252.623 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2910/4776 | Loss: 271.713 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 2920/4776 | Loss: 270.882 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2930/4776 | Loss: 215.407 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 2940/4776 | Loss: 274.962 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2950/4776 | Loss: 201.071 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 2960/4776 | Loss: 254.195 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2970/4776 | Loss: 218.276 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 2980/4776 | Loss: 252.208 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 2990/4776 | Loss: 264.606 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3000/4776 | Loss: 245.903 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3010/4776 | Loss: 258.725 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3020/4776 | Loss: 243.930 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3030/4776 | Loss: 218.625 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3040/4776 | Loss: 222.562 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3050/4776 | Loss: 228.654 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3060/4776 | Loss: 260.744 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3070/4776 | Loss: 253.917 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3080/4776 | Loss: 217.634 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 3090/4776 | Loss: 236.336 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3100/4776 | Loss: 258.822 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3110/4776 | Loss: 203.009 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 3120/4776 | Loss: 242.866 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3130/4776 | Loss: 272.285 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3140/4776 | Loss: 213.299 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3150/4776 | Loss: 161.720 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 3160/4776 | Loss: 227.371 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3170/4776 | Loss: 200.992 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3180/4776 | Loss: 244.632 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3190/4776 | Loss: 211.946 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3200/4776 | Loss: 222.016 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3210/4776 | Loss: 248.424 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3220/4776 | Loss: 213.137 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 3230/4776 | Loss: 272.613 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3240/4776 | Loss: 259.868 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3250/4776 | Loss: 220.671 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3260/4776 | Loss: 241.103 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3270/4776 | Loss: 240.705 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3280/4776 | Loss: 262.325 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3290/4776 | Loss: 241.176 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3300/4776 | Loss: 229.068 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3310/4776 | Loss: 234.382 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3320/4776 | Loss: 213.619 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 3330/4776 | Loss: 236.961 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3340/4776 | Loss: 218.063 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3350/4776 | Loss: 281.257 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3360/4776 | Loss: 252.638 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3370/4776 | Loss: 205.917 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3380/4776 | Loss: 283.805 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3390/4776 | Loss: 254.378 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3400/4776 | Loss: 257.617 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3410/4776 | Loss: 249.600 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3420/4776 | Loss: 242.431 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3430/4776 | Loss: 221.898 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3440/4776 | Loss: 234.522 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3450/4776 | Loss: 237.185 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3460/4776 | Loss: 253.844 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3470/4776 | Loss: 249.544 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3480/4776 | Loss: 257.289 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3490/4776 | Loss: 243.794 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3500/4776 | Loss: 265.925 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3510/4776 | Loss: 259.725 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3520/4776 | Loss: 263.307 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3530/4776 | Loss: 220.313 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3540/4776 | Loss: 292.284 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3550/4776 | Loss: 259.208 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3560/4776 | Loss: 227.732 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3570/4776 | Loss: 280.604 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3580/4776 | Loss: 245.728 | Accuracy: 0.600\n",
      "[Epoch: 23/200] - Step: 3590/4776 | Loss: 223.325 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3600/4776 | Loss: 199.408 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3610/4776 | Loss: 275.133 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3620/4776 | Loss: 240.606 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3630/4776 | Loss: 278.257 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3640/4776 | Loss: 272.704 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3650/4776 | Loss: 255.279 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3660/4776 | Loss: 273.485 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3670/4776 | Loss: 259.363 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3680/4776 | Loss: 215.510 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3690/4776 | Loss: 233.762 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3700/4776 | Loss: 220.612 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3710/4776 | Loss: 261.001 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3720/4776 | Loss: 217.273 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3730/4776 | Loss: 239.167 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3740/4776 | Loss: 244.969 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 3750/4776 | Loss: 293.755 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3760/4776 | Loss: 240.686 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3770/4776 | Loss: 267.677 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3780/4776 | Loss: 230.596 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3790/4776 | Loss: 235.054 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3800/4776 | Loss: 244.860 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3810/4776 | Loss: 234.325 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3820/4776 | Loss: 262.062 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3830/4776 | Loss: 238.723 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3840/4776 | Loss: 258.252 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3850/4776 | Loss: 244.656 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3860/4776 | Loss: 243.241 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3870/4776 | Loss: 217.746 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3880/4776 | Loss: 219.592 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3890/4776 | Loss: 215.907 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3900/4776 | Loss: 248.358 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3910/4776 | Loss: 244.571 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3920/4776 | Loss: 194.204 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 3930/4776 | Loss: 257.533 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3940/4776 | Loss: 244.687 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3950/4776 | Loss: 226.236 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 3960/4776 | Loss: 265.416 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 3970/4776 | Loss: 241.135 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3980/4776 | Loss: 271.757 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 3990/4776 | Loss: 211.879 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 4000/4776 | Loss: 229.578 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4010/4776 | Loss: 258.204 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4020/4776 | Loss: 225.687 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4030/4776 | Loss: 184.890 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 4040/4776 | Loss: 268.072 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4050/4776 | Loss: 232.946 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4060/4776 | Loss: 239.931 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4070/4776 | Loss: 226.227 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4080/4776 | Loss: 241.302 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4090/4776 | Loss: 222.663 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4100/4776 | Loss: 261.376 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4110/4776 | Loss: 198.933 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4120/4776 | Loss: 242.312 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4130/4776 | Loss: 241.858 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4140/4776 | Loss: 213.566 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 4150/4776 | Loss: 262.982 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4160/4776 | Loss: 259.268 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4170/4776 | Loss: 195.927 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4180/4776 | Loss: 265.173 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4190/4776 | Loss: 221.218 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4200/4776 | Loss: 287.820 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4210/4776 | Loss: 205.447 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4220/4776 | Loss: 196.400 | Accuracy: 0.600\n",
      "[Epoch: 23/200] - Step: 4230/4776 | Loss: 239.150 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4240/4776 | Loss: 242.700 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4250/4776 | Loss: 216.389 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4260/4776 | Loss: 249.402 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4270/4776 | Loss: 224.082 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4280/4776 | Loss: 251.599 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4290/4776 | Loss: 251.685 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4300/4776 | Loss: 264.845 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4310/4776 | Loss: 209.724 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4320/4776 | Loss: 231.318 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4330/4776 | Loss: 221.168 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4340/4776 | Loss: 243.798 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4350/4776 | Loss: 220.490 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4360/4776 | Loss: 241.103 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4370/4776 | Loss: 188.716 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4380/4776 | Loss: 247.470 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4390/4776 | Loss: 255.060 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4400/4776 | Loss: 270.879 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4410/4776 | Loss: 278.667 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4420/4776 | Loss: 161.342 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4430/4776 | Loss: 194.066 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4440/4776 | Loss: 281.166 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4450/4776 | Loss: 263.972 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4460/4776 | Loss: 232.032 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4470/4776 | Loss: 274.749 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4480/4776 | Loss: 239.372 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 4490/4776 | Loss: 287.726 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4500/4776 | Loss: 250.537 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4510/4776 | Loss: 240.144 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4520/4776 | Loss: 241.626 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4530/4776 | Loss: 229.202 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4540/4776 | Loss: 236.000 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4550/4776 | Loss: 238.782 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4560/4776 | Loss: 251.007 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4570/4776 | Loss: 228.935 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4580/4776 | Loss: 263.105 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4590/4776 | Loss: 218.742 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4600/4776 | Loss: 251.095 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4610/4776 | Loss: 237.746 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4620/4776 | Loss: 259.323 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4630/4776 | Loss: 241.205 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4640/4776 | Loss: 228.611 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4650/4776 | Loss: 225.111 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4660/4776 | Loss: 246.041 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4670/4776 | Loss: 225.437 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4680/4776 | Loss: 281.367 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4690/4776 | Loss: 259.437 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4700/4776 | Loss: 211.279 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4710/4776 | Loss: 220.227 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 4720/4776 | Loss: 225.364 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4730/4776 | Loss: 247.535 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 4740/4776 | Loss: 213.075 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4750/4776 | Loss: 250.455 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 4760/4776 | Loss: 198.732 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 4770/4776 | Loss: 214.058 | Accuracy: 0.100\n",
      "Accuracy:  0.14754098360655737\n",
      "[Epoch: 24/200] - Step: 10/4776 | Loss: 219.363 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 20/4776 | Loss: 212.508 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 30/4776 | Loss: 254.885 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 40/4776 | Loss: 248.253 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 50/4776 | Loss: 232.908 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 60/4776 | Loss: 235.629 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 70/4776 | Loss: 254.257 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 80/4776 | Loss: 201.527 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 90/4776 | Loss: 247.570 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 100/4776 | Loss: 217.725 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 110/4776 | Loss: 225.421 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 120/4776 | Loss: 234.313 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 130/4776 | Loss: 217.814 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 140/4776 | Loss: 271.272 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 150/4776 | Loss: 256.209 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 160/4776 | Loss: 264.589 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 170/4776 | Loss: 187.854 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 180/4776 | Loss: 210.720 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 190/4776 | Loss: 231.454 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 200/4776 | Loss: 227.752 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 210/4776 | Loss: 272.793 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 220/4776 | Loss: 232.935 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 230/4776 | Loss: 287.122 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 240/4776 | Loss: 272.499 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 250/4776 | Loss: 260.389 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 260/4776 | Loss: 239.968 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 270/4776 | Loss: 230.120 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 280/4776 | Loss: 262.593 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 290/4776 | Loss: 211.342 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 300/4776 | Loss: 217.908 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 310/4776 | Loss: 269.592 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 320/4776 | Loss: 232.205 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 330/4776 | Loss: 249.960 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 340/4776 | Loss: 240.990 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 350/4776 | Loss: 264.393 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 360/4776 | Loss: 208.501 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 370/4776 | Loss: 269.094 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 380/4776 | Loss: 250.638 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 390/4776 | Loss: 232.354 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 400/4776 | Loss: 218.180 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 410/4776 | Loss: 215.286 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 420/4776 | Loss: 214.576 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 430/4776 | Loss: 220.109 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 440/4776 | Loss: 236.139 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 450/4776 | Loss: 200.138 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 460/4776 | Loss: 218.002 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 470/4776 | Loss: 227.976 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 480/4776 | Loss: 228.445 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 490/4776 | Loss: 206.548 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 500/4776 | Loss: 242.292 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 510/4776 | Loss: 230.232 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 520/4776 | Loss: 238.057 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 530/4776 | Loss: 207.898 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 540/4776 | Loss: 216.573 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 550/4776 | Loss: 219.366 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 560/4776 | Loss: 259.135 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 570/4776 | Loss: 228.442 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 580/4776 | Loss: 229.834 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 590/4776 | Loss: 232.475 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 600/4776 | Loss: 250.937 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 610/4776 | Loss: 252.987 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 620/4776 | Loss: 274.632 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 630/4776 | Loss: 255.852 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 640/4776 | Loss: 240.856 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 650/4776 | Loss: 259.257 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 660/4776 | Loss: 237.732 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 670/4776 | Loss: 248.856 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 680/4776 | Loss: 215.786 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 690/4776 | Loss: 224.590 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 700/4776 | Loss: 172.469 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 710/4776 | Loss: 206.087 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 720/4776 | Loss: 281.983 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 730/4776 | Loss: 201.764 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 740/4776 | Loss: 229.427 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 750/4776 | Loss: 270.118 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 760/4776 | Loss: 216.015 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 770/4776 | Loss: 257.798 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 780/4776 | Loss: 216.589 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 790/4776 | Loss: 165.988 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 800/4776 | Loss: 211.732 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 810/4776 | Loss: 204.452 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 820/4776 | Loss: 267.148 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 830/4776 | Loss: 265.659 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 840/4776 | Loss: 203.534 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 850/4776 | Loss: 253.519 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 860/4776 | Loss: 212.312 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 870/4776 | Loss: 259.854 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 880/4776 | Loss: 260.919 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 890/4776 | Loss: 247.784 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 900/4776 | Loss: 232.354 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 910/4776 | Loss: 209.312 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 920/4776 | Loss: 259.665 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 930/4776 | Loss: 302.721 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 940/4776 | Loss: 226.469 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 950/4776 | Loss: 243.154 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 960/4776 | Loss: 238.528 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 970/4776 | Loss: 222.065 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 980/4776 | Loss: 253.877 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 990/4776 | Loss: 220.392 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1000/4776 | Loss: 229.333 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1010/4776 | Loss: 253.026 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1020/4776 | Loss: 238.535 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1030/4776 | Loss: 285.227 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1040/4776 | Loss: 272.125 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1050/4776 | Loss: 253.258 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1060/4776 | Loss: 265.688 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1070/4776 | Loss: 230.453 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1080/4776 | Loss: 243.130 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1090/4776 | Loss: 261.303 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1100/4776 | Loss: 245.030 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1110/4776 | Loss: 260.536 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1120/4776 | Loss: 230.935 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1130/4776 | Loss: 222.909 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1140/4776 | Loss: 241.833 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1150/4776 | Loss: 201.916 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1160/4776 | Loss: 246.045 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1170/4776 | Loss: 210.700 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1180/4776 | Loss: 243.815 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1190/4776 | Loss: 219.601 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1200/4776 | Loss: 256.982 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1210/4776 | Loss: 211.653 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1220/4776 | Loss: 214.848 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1230/4776 | Loss: 249.757 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1240/4776 | Loss: 239.151 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1250/4776 | Loss: 301.746 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1260/4776 | Loss: 291.398 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1270/4776 | Loss: 219.442 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1280/4776 | Loss: 215.081 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1290/4776 | Loss: 240.762 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1300/4776 | Loss: 228.272 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1310/4776 | Loss: 284.584 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1320/4776 | Loss: 248.086 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1330/4776 | Loss: 221.373 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1340/4776 | Loss: 228.640 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 1350/4776 | Loss: 267.159 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1360/4776 | Loss: 189.814 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1370/4776 | Loss: 248.074 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1380/4776 | Loss: 249.001 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1390/4776 | Loss: 227.624 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1400/4776 | Loss: 218.641 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1410/4776 | Loss: 249.587 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1420/4776 | Loss: 254.216 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1430/4776 | Loss: 213.688 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1440/4776 | Loss: 205.357 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1450/4776 | Loss: 235.758 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1460/4776 | Loss: 269.914 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1470/4776 | Loss: 231.459 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1480/4776 | Loss: 229.330 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1490/4776 | Loss: 223.264 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1500/4776 | Loss: 225.166 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1510/4776 | Loss: 239.738 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1520/4776 | Loss: 239.344 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1530/4776 | Loss: 206.502 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1540/4776 | Loss: 225.611 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1550/4776 | Loss: 287.822 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1560/4776 | Loss: 267.273 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1570/4776 | Loss: 237.970 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1580/4776 | Loss: 201.903 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1590/4776 | Loss: 268.830 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1600/4776 | Loss: 208.154 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1610/4776 | Loss: 219.300 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1620/4776 | Loss: 202.338 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1630/4776 | Loss: 183.614 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1640/4776 | Loss: 259.750 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1650/4776 | Loss: 222.272 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1660/4776 | Loss: 236.779 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1670/4776 | Loss: 262.616 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1680/4776 | Loss: 207.457 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1690/4776 | Loss: 223.024 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1700/4776 | Loss: 245.573 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1710/4776 | Loss: 291.508 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1720/4776 | Loss: 212.991 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1730/4776 | Loss: 270.435 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1740/4776 | Loss: 262.538 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1750/4776 | Loss: 271.482 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1760/4776 | Loss: 245.484 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1770/4776 | Loss: 262.796 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1780/4776 | Loss: 245.679 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1790/4776 | Loss: 244.560 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1800/4776 | Loss: 235.742 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1810/4776 | Loss: 241.110 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1820/4776 | Loss: 220.229 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1830/4776 | Loss: 249.036 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1840/4776 | Loss: 258.207 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1850/4776 | Loss: 272.693 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1860/4776 | Loss: 235.848 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1870/4776 | Loss: 217.024 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1880/4776 | Loss: 234.199 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1890/4776 | Loss: 254.155 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1900/4776 | Loss: 239.512 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1910/4776 | Loss: 264.971 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1920/4776 | Loss: 240.311 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1930/4776 | Loss: 257.228 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1940/4776 | Loss: 212.748 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1950/4776 | Loss: 238.287 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1960/4776 | Loss: 206.914 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 1970/4776 | Loss: 225.526 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1980/4776 | Loss: 244.653 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1990/4776 | Loss: 204.832 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2000/4776 | Loss: 199.064 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2010/4776 | Loss: 214.354 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2020/4776 | Loss: 223.355 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2030/4776 | Loss: 246.939 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2040/4776 | Loss: 325.888 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2050/4776 | Loss: 252.936 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2060/4776 | Loss: 246.548 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2070/4776 | Loss: 224.952 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2080/4776 | Loss: 228.473 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2090/4776 | Loss: 185.527 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2100/4776 | Loss: 218.745 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2110/4776 | Loss: 229.555 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2120/4776 | Loss: 257.114 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2130/4776 | Loss: 221.972 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2140/4776 | Loss: 238.466 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2150/4776 | Loss: 223.190 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2160/4776 | Loss: 219.989 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2170/4776 | Loss: 261.591 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2180/4776 | Loss: 173.978 | Accuracy: 0.600\n",
      "[Epoch: 24/200] - Step: 2190/4776 | Loss: 267.539 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2200/4776 | Loss: 287.792 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2210/4776 | Loss: 204.650 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2220/4776 | Loss: 294.736 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2230/4776 | Loss: 259.003 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2240/4776 | Loss: 228.999 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2250/4776 | Loss: 212.772 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 2260/4776 | Loss: 248.159 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2270/4776 | Loss: 233.616 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2280/4776 | Loss: 220.612 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2290/4776 | Loss: 225.435 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2300/4776 | Loss: 247.303 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2310/4776 | Loss: 247.905 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2320/4776 | Loss: 237.918 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2330/4776 | Loss: 190.891 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2340/4776 | Loss: 214.325 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2350/4776 | Loss: 228.524 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2360/4776 | Loss: 225.591 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2370/4776 | Loss: 216.658 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2380/4776 | Loss: 195.883 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2390/4776 | Loss: 222.089 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2400/4776 | Loss: 185.804 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 2410/4776 | Loss: 217.313 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2420/4776 | Loss: 265.279 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2430/4776 | Loss: 228.099 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2440/4776 | Loss: 256.600 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2450/4776 | Loss: 245.921 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2460/4776 | Loss: 248.089 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2470/4776 | Loss: 239.508 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2480/4776 | Loss: 256.005 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2490/4776 | Loss: 238.174 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2500/4776 | Loss: 217.413 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2510/4776 | Loss: 218.861 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2520/4776 | Loss: 231.991 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2530/4776 | Loss: 209.996 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2540/4776 | Loss: 207.477 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2550/4776 | Loss: 196.333 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2560/4776 | Loss: 209.863 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2570/4776 | Loss: 231.513 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2580/4776 | Loss: 218.026 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2590/4776 | Loss: 270.338 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2600/4776 | Loss: 239.275 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2610/4776 | Loss: 197.408 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2620/4776 | Loss: 249.174 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2630/4776 | Loss: 152.147 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2640/4776 | Loss: 200.298 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2650/4776 | Loss: 241.586 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2660/4776 | Loss: 223.851 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2670/4776 | Loss: 221.597 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2680/4776 | Loss: 226.353 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2690/4776 | Loss: 193.805 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2700/4776 | Loss: 185.749 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2710/4776 | Loss: 228.829 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2720/4776 | Loss: 293.475 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2730/4776 | Loss: 238.126 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2740/4776 | Loss: 232.123 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2750/4776 | Loss: 235.431 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2760/4776 | Loss: 272.189 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2770/4776 | Loss: 198.330 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2780/4776 | Loss: 267.771 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 2790/4776 | Loss: 212.352 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2800/4776 | Loss: 245.427 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2810/4776 | Loss: 228.166 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2820/4776 | Loss: 243.112 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2830/4776 | Loss: 221.981 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2840/4776 | Loss: 197.717 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2850/4776 | Loss: 274.698 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2860/4776 | Loss: 209.127 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2870/4776 | Loss: 261.037 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2880/4776 | Loss: 327.316 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2890/4776 | Loss: 191.280 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2900/4776 | Loss: 241.150 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2910/4776 | Loss: 212.194 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2920/4776 | Loss: 250.679 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2930/4776 | Loss: 208.861 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2940/4776 | Loss: 249.620 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 2950/4776 | Loss: 252.645 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2960/4776 | Loss: 233.797 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 2970/4776 | Loss: 227.268 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 2980/4776 | Loss: 212.097 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 2990/4776 | Loss: 244.027 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3000/4776 | Loss: 244.258 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3010/4776 | Loss: 256.829 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3020/4776 | Loss: 269.595 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3030/4776 | Loss: 233.089 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3040/4776 | Loss: 229.529 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3050/4776 | Loss: 230.703 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3060/4776 | Loss: 241.984 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3070/4776 | Loss: 251.252 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3080/4776 | Loss: 290.969 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3090/4776 | Loss: 204.153 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3100/4776 | Loss: 243.846 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3110/4776 | Loss: 222.882 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3120/4776 | Loss: 284.811 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3130/4776 | Loss: 223.734 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3140/4776 | Loss: 201.355 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3150/4776 | Loss: 229.426 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3160/4776 | Loss: 234.645 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3170/4776 | Loss: 230.939 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3180/4776 | Loss: 213.077 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3190/4776 | Loss: 278.084 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3200/4776 | Loss: 225.215 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3210/4776 | Loss: 232.266 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3220/4776 | Loss: 296.752 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3230/4776 | Loss: 268.680 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3240/4776 | Loss: 201.812 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3250/4776 | Loss: 260.102 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3260/4776 | Loss: 222.638 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3270/4776 | Loss: 268.705 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3280/4776 | Loss: 196.038 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3290/4776 | Loss: 201.322 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3300/4776 | Loss: 211.621 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3310/4776 | Loss: 193.072 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3320/4776 | Loss: 224.517 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3330/4776 | Loss: 243.453 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3340/4776 | Loss: 227.614 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3350/4776 | Loss: 280.885 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3360/4776 | Loss: 245.028 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3370/4776 | Loss: 255.944 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3380/4776 | Loss: 247.560 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3390/4776 | Loss: 223.684 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3400/4776 | Loss: 178.814 | Accuracy: 0.600\n",
      "[Epoch: 24/200] - Step: 3410/4776 | Loss: 190.020 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 3420/4776 | Loss: 223.060 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3430/4776 | Loss: 231.977 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3440/4776 | Loss: 271.966 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3450/4776 | Loss: 212.333 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 3460/4776 | Loss: 304.767 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3470/4776 | Loss: 231.361 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3480/4776 | Loss: 216.659 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3490/4776 | Loss: 270.331 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3500/4776 | Loss: 264.081 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3510/4776 | Loss: 248.841 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3520/4776 | Loss: 209.380 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3530/4776 | Loss: 210.032 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3540/4776 | Loss: 279.681 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3550/4776 | Loss: 251.703 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3560/4776 | Loss: 274.336 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3570/4776 | Loss: 221.683 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3580/4776 | Loss: 233.472 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3590/4776 | Loss: 226.896 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3600/4776 | Loss: 267.963 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3610/4776 | Loss: 242.492 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3620/4776 | Loss: 273.293 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3630/4776 | Loss: 237.438 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3640/4776 | Loss: 221.674 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3650/4776 | Loss: 277.154 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3660/4776 | Loss: 272.554 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3670/4776 | Loss: 252.764 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3680/4776 | Loss: 225.021 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3690/4776 | Loss: 205.227 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3700/4776 | Loss: 256.937 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3710/4776 | Loss: 215.898 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 3720/4776 | Loss: 259.768 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3730/4776 | Loss: 229.415 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3740/4776 | Loss: 244.370 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3750/4776 | Loss: 215.117 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3760/4776 | Loss: 201.528 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3770/4776 | Loss: 254.193 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3780/4776 | Loss: 231.205 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3790/4776 | Loss: 227.438 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3800/4776 | Loss: 242.141 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3810/4776 | Loss: 245.134 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3820/4776 | Loss: 255.917 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3830/4776 | Loss: 241.871 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3840/4776 | Loss: 265.098 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3850/4776 | Loss: 231.937 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3860/4776 | Loss: 209.464 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3870/4776 | Loss: 241.818 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3880/4776 | Loss: 217.401 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 3890/4776 | Loss: 201.776 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3900/4776 | Loss: 239.354 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3910/4776 | Loss: 199.791 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3920/4776 | Loss: 234.947 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3930/4776 | Loss: 276.442 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3940/4776 | Loss: 208.676 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3950/4776 | Loss: 230.538 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3960/4776 | Loss: 213.023 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 3970/4776 | Loss: 283.877 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 3980/4776 | Loss: 250.735 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 3990/4776 | Loss: 232.017 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4000/4776 | Loss: 286.113 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4010/4776 | Loss: 284.010 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4020/4776 | Loss: 203.004 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4030/4776 | Loss: 197.135 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4040/4776 | Loss: 211.092 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4050/4776 | Loss: 261.563 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4060/4776 | Loss: 223.828 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4070/4776 | Loss: 238.834 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4080/4776 | Loss: 240.581 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4090/4776 | Loss: 227.161 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4100/4776 | Loss: 229.611 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4110/4776 | Loss: 281.379 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4120/4776 | Loss: 228.658 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4130/4776 | Loss: 258.125 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4140/4776 | Loss: 216.879 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4150/4776 | Loss: 273.659 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4160/4776 | Loss: 251.789 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4170/4776 | Loss: 234.176 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4180/4776 | Loss: 247.778 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4190/4776 | Loss: 198.989 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4200/4776 | Loss: 238.999 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4210/4776 | Loss: 244.157 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4220/4776 | Loss: 277.216 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4230/4776 | Loss: 213.890 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4240/4776 | Loss: 241.884 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4250/4776 | Loss: 249.426 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4260/4776 | Loss: 287.288 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4270/4776 | Loss: 216.079 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4280/4776 | Loss: 194.163 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4290/4776 | Loss: 220.643 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4300/4776 | Loss: 238.985 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4310/4776 | Loss: 236.405 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4320/4776 | Loss: 204.027 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4330/4776 | Loss: 210.926 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4340/4776 | Loss: 234.015 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4350/4776 | Loss: 217.078 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4360/4776 | Loss: 210.428 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4370/4776 | Loss: 192.729 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4380/4776 | Loss: 219.080 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4390/4776 | Loss: 205.556 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4400/4776 | Loss: 158.514 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 4410/4776 | Loss: 221.495 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4420/4776 | Loss: 190.573 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4430/4776 | Loss: 245.012 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4440/4776 | Loss: 284.904 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4450/4776 | Loss: 267.169 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4460/4776 | Loss: 237.289 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4470/4776 | Loss: 247.158 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4480/4776 | Loss: 204.388 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4490/4776 | Loss: 235.156 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4500/4776 | Loss: 231.511 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4510/4776 | Loss: 213.976 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4520/4776 | Loss: 261.940 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4530/4776 | Loss: 244.085 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4540/4776 | Loss: 272.285 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 4550/4776 | Loss: 231.554 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4560/4776 | Loss: 191.691 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 4570/4776 | Loss: 260.855 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4580/4776 | Loss: 200.528 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4590/4776 | Loss: 244.447 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4600/4776 | Loss: 210.366 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4610/4776 | Loss: 227.877 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4620/4776 | Loss: 264.063 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4630/4776 | Loss: 252.954 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4640/4776 | Loss: 241.407 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4650/4776 | Loss: 184.778 | Accuracy: 0.500\n",
      "[Epoch: 24/200] - Step: 4660/4776 | Loss: 221.370 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4670/4776 | Loss: 236.976 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4680/4776 | Loss: 251.108 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4690/4776 | Loss: 211.786 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4700/4776 | Loss: 186.256 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 4710/4776 | Loss: 220.475 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4720/4776 | Loss: 261.587 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4730/4776 | Loss: 239.094 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4740/4776 | Loss: 209.027 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 4750/4776 | Loss: 263.888 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 4760/4776 | Loss: 237.538 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 4770/4776 | Loss: 216.760 | Accuracy: 0.200\n",
      "Accuracy:  0.16229508196721312\n",
      "[Epoch: 25/200] - Step: 10/4776 | Loss: 224.891 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 20/4776 | Loss: 250.159 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 30/4776 | Loss: 226.840 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 40/4776 | Loss: 212.778 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 50/4776 | Loss: 221.405 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 60/4776 | Loss: 299.157 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 70/4776 | Loss: 216.935 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 80/4776 | Loss: 200.910 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 90/4776 | Loss: 279.927 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 100/4776 | Loss: 221.043 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 110/4776 | Loss: 255.026 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 120/4776 | Loss: 229.200 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 130/4776 | Loss: 220.250 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 140/4776 | Loss: 238.723 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 150/4776 | Loss: 248.765 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 160/4776 | Loss: 213.706 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 170/4776 | Loss: 209.485 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 180/4776 | Loss: 251.249 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 190/4776 | Loss: 226.998 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 200/4776 | Loss: 236.595 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 210/4776 | Loss: 264.906 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 220/4776 | Loss: 246.245 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 230/4776 | Loss: 233.068 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 240/4776 | Loss: 199.233 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 250/4776 | Loss: 212.657 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 260/4776 | Loss: 236.200 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 270/4776 | Loss: 256.170 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 280/4776 | Loss: 256.707 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 290/4776 | Loss: 257.354 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 300/4776 | Loss: 213.838 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 310/4776 | Loss: 216.341 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 320/4776 | Loss: 206.896 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 330/4776 | Loss: 183.147 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 340/4776 | Loss: 246.061 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 350/4776 | Loss: 216.667 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 360/4776 | Loss: 258.470 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 370/4776 | Loss: 204.354 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 380/4776 | Loss: 219.605 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 390/4776 | Loss: 257.058 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 400/4776 | Loss: 187.854 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 410/4776 | Loss: 236.016 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 420/4776 | Loss: 281.610 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 430/4776 | Loss: 221.947 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 440/4776 | Loss: 239.388 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 450/4776 | Loss: 211.199 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 460/4776 | Loss: 232.536 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 470/4776 | Loss: 271.743 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 480/4776 | Loss: 245.318 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 490/4776 | Loss: 223.619 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 500/4776 | Loss: 289.906 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 510/4776 | Loss: 234.693 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 520/4776 | Loss: 229.272 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 530/4776 | Loss: 224.086 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 540/4776 | Loss: 242.306 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 550/4776 | Loss: 225.143 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 560/4776 | Loss: 233.294 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 570/4776 | Loss: 243.624 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 580/4776 | Loss: 241.195 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 590/4776 | Loss: 206.932 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 600/4776 | Loss: 206.977 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 610/4776 | Loss: 261.378 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 620/4776 | Loss: 214.753 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 630/4776 | Loss: 236.460 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 640/4776 | Loss: 206.570 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 650/4776 | Loss: 211.973 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 660/4776 | Loss: 231.263 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 670/4776 | Loss: 167.511 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 680/4776 | Loss: 208.453 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 690/4776 | Loss: 226.096 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 700/4776 | Loss: 198.073 | Accuracy: 0.600\n",
      "[Epoch: 25/200] - Step: 710/4776 | Loss: 204.141 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 720/4776 | Loss: 196.989 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 730/4776 | Loss: 241.191 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 740/4776 | Loss: 253.593 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 750/4776 | Loss: 260.727 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 760/4776 | Loss: 258.584 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 770/4776 | Loss: 247.209 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 780/4776 | Loss: 233.412 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 790/4776 | Loss: 195.862 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 800/4776 | Loss: 260.795 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 810/4776 | Loss: 189.666 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 820/4776 | Loss: 224.547 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 830/4776 | Loss: 223.959 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 840/4776 | Loss: 208.334 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 850/4776 | Loss: 250.361 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 860/4776 | Loss: 226.383 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 870/4776 | Loss: 221.017 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 880/4776 | Loss: 243.986 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 890/4776 | Loss: 236.549 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 900/4776 | Loss: 169.500 | Accuracy: 0.600\n",
      "[Epoch: 25/200] - Step: 910/4776 | Loss: 227.606 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 920/4776 | Loss: 195.830 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 930/4776 | Loss: 275.688 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 940/4776 | Loss: 247.169 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 950/4776 | Loss: 194.625 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 960/4776 | Loss: 264.012 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 970/4776 | Loss: 221.949 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 980/4776 | Loss: 236.665 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 990/4776 | Loss: 249.327 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1000/4776 | Loss: 245.300 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1010/4776 | Loss: 225.859 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1020/4776 | Loss: 194.077 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1030/4776 | Loss: 207.173 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1040/4776 | Loss: 204.614 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1050/4776 | Loss: 300.296 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1060/4776 | Loss: 234.781 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1070/4776 | Loss: 181.568 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1080/4776 | Loss: 202.545 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1090/4776 | Loss: 198.854 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1100/4776 | Loss: 227.960 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1110/4776 | Loss: 198.570 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1120/4776 | Loss: 242.998 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1130/4776 | Loss: 247.018 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1140/4776 | Loss: 240.635 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1150/4776 | Loss: 220.180 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1160/4776 | Loss: 205.554 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1170/4776 | Loss: 208.074 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1180/4776 | Loss: 197.719 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1190/4776 | Loss: 276.137 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1200/4776 | Loss: 227.937 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1210/4776 | Loss: 217.324 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1220/4776 | Loss: 251.933 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1230/4776 | Loss: 220.127 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1240/4776 | Loss: 228.610 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1250/4776 | Loss: 230.417 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1260/4776 | Loss: 245.120 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1270/4776 | Loss: 206.541 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1280/4776 | Loss: 262.483 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1290/4776 | Loss: 215.090 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1300/4776 | Loss: 208.027 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1310/4776 | Loss: 278.049 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1320/4776 | Loss: 247.393 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1330/4776 | Loss: 198.218 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1340/4776 | Loss: 206.121 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1350/4776 | Loss: 259.933 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1360/4776 | Loss: 198.092 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1370/4776 | Loss: 213.078 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1380/4776 | Loss: 265.097 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1390/4776 | Loss: 195.219 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1400/4776 | Loss: 326.994 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1410/4776 | Loss: 225.741 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1420/4776 | Loss: 148.417 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1430/4776 | Loss: 213.279 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1440/4776 | Loss: 244.325 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1450/4776 | Loss: 242.421 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1460/4776 | Loss: 228.952 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1470/4776 | Loss: 233.092 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1480/4776 | Loss: 255.583 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1490/4776 | Loss: 232.229 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1500/4776 | Loss: 251.978 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1510/4776 | Loss: 227.006 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1520/4776 | Loss: 246.898 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1530/4776 | Loss: 232.065 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1540/4776 | Loss: 230.066 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1550/4776 | Loss: 247.441 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1560/4776 | Loss: 240.525 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1570/4776 | Loss: 250.292 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1580/4776 | Loss: 221.834 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1590/4776 | Loss: 192.914 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1600/4776 | Loss: 260.655 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1610/4776 | Loss: 199.134 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 1620/4776 | Loss: 226.591 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1630/4776 | Loss: 241.225 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1640/4776 | Loss: 260.761 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1650/4776 | Loss: 219.824 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1660/4776 | Loss: 221.444 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1670/4776 | Loss: 280.226 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1680/4776 | Loss: 268.548 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1690/4776 | Loss: 240.977 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1700/4776 | Loss: 234.983 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1710/4776 | Loss: 193.090 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1720/4776 | Loss: 216.270 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1730/4776 | Loss: 187.595 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 1740/4776 | Loss: 269.114 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1750/4776 | Loss: 200.693 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1760/4776 | Loss: 198.295 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1770/4776 | Loss: 275.403 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1780/4776 | Loss: 202.679 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1790/4776 | Loss: 247.705 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1800/4776 | Loss: 234.170 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1810/4776 | Loss: 270.470 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1820/4776 | Loss: 203.512 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1830/4776 | Loss: 256.949 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1840/4776 | Loss: 237.741 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1850/4776 | Loss: 215.845 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1860/4776 | Loss: 241.668 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1870/4776 | Loss: 247.870 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1880/4776 | Loss: 307.480 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1890/4776 | Loss: 220.959 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1900/4776 | Loss: 247.458 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1910/4776 | Loss: 206.999 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1920/4776 | Loss: 250.275 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1930/4776 | Loss: 249.835 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1940/4776 | Loss: 223.279 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1950/4776 | Loss: 207.716 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1960/4776 | Loss: 203.264 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 1970/4776 | Loss: 205.877 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1980/4776 | Loss: 243.084 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1990/4776 | Loss: 174.870 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2000/4776 | Loss: 305.488 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2010/4776 | Loss: 226.042 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2020/4776 | Loss: 221.888 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2030/4776 | Loss: 261.843 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2040/4776 | Loss: 227.990 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2050/4776 | Loss: 210.465 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2060/4776 | Loss: 223.234 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2070/4776 | Loss: 253.454 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2080/4776 | Loss: 223.192 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2090/4776 | Loss: 217.356 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2100/4776 | Loss: 230.303 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2110/4776 | Loss: 203.672 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2120/4776 | Loss: 297.361 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2130/4776 | Loss: 245.387 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2140/4776 | Loss: 218.085 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2150/4776 | Loss: 178.822 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2160/4776 | Loss: 246.993 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2170/4776 | Loss: 190.766 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2180/4776 | Loss: 231.838 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2190/4776 | Loss: 248.263 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2200/4776 | Loss: 212.688 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2210/4776 | Loss: 265.066 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2220/4776 | Loss: 232.225 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2230/4776 | Loss: 253.753 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2240/4776 | Loss: 206.239 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2250/4776 | Loss: 230.584 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2260/4776 | Loss: 218.713 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2270/4776 | Loss: 237.528 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2280/4776 | Loss: 256.604 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2290/4776 | Loss: 242.559 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2300/4776 | Loss: 202.331 | Accuracy: 0.600\n",
      "[Epoch: 25/200] - Step: 2310/4776 | Loss: 198.271 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2320/4776 | Loss: 215.104 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2330/4776 | Loss: 233.555 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2340/4776 | Loss: 220.338 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2350/4776 | Loss: 207.960 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2360/4776 | Loss: 232.960 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2370/4776 | Loss: 270.839 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2380/4776 | Loss: 195.999 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2390/4776 | Loss: 267.818 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2400/4776 | Loss: 248.159 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2410/4776 | Loss: 188.675 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2420/4776 | Loss: 252.681 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2430/4776 | Loss: 248.626 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2440/4776 | Loss: 229.694 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2450/4776 | Loss: 243.413 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2460/4776 | Loss: 217.216 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2470/4776 | Loss: 210.234 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2480/4776 | Loss: 218.576 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2490/4776 | Loss: 230.035 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2500/4776 | Loss: 233.073 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2510/4776 | Loss: 271.248 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2520/4776 | Loss: 225.568 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2530/4776 | Loss: 203.841 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2540/4776 | Loss: 253.186 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2550/4776 | Loss: 173.231 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2560/4776 | Loss: 214.852 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2570/4776 | Loss: 241.948 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2580/4776 | Loss: 215.318 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2590/4776 | Loss: 257.601 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2600/4776 | Loss: 200.795 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2610/4776 | Loss: 251.756 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2620/4776 | Loss: 237.994 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2630/4776 | Loss: 227.104 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2640/4776 | Loss: 211.006 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2650/4776 | Loss: 202.172 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2660/4776 | Loss: 230.127 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2670/4776 | Loss: 225.227 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2680/4776 | Loss: 230.513 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2690/4776 | Loss: 234.539 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2700/4776 | Loss: 233.167 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2710/4776 | Loss: 192.674 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2720/4776 | Loss: 247.652 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2730/4776 | Loss: 234.428 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2740/4776 | Loss: 168.262 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2750/4776 | Loss: 200.796 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2760/4776 | Loss: 261.167 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2770/4776 | Loss: 204.053 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2780/4776 | Loss: 213.220 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2790/4776 | Loss: 233.695 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2800/4776 | Loss: 188.391 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2810/4776 | Loss: 187.427 | Accuracy: 0.700\n",
      "[Epoch: 25/200] - Step: 2820/4776 | Loss: 236.668 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2830/4776 | Loss: 254.680 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2840/4776 | Loss: 201.864 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2850/4776 | Loss: 214.012 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2860/4776 | Loss: 210.279 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2870/4776 | Loss: 210.645 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2880/4776 | Loss: 205.522 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 2890/4776 | Loss: 211.801 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2900/4776 | Loss: 272.791 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2910/4776 | Loss: 265.211 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2920/4776 | Loss: 230.387 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2930/4776 | Loss: 243.071 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 2940/4776 | Loss: 210.808 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 2950/4776 | Loss: 255.854 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2960/4776 | Loss: 254.280 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 2970/4776 | Loss: 209.622 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 2980/4776 | Loss: 229.465 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 2990/4776 | Loss: 222.217 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3000/4776 | Loss: 210.041 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3010/4776 | Loss: 272.085 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3020/4776 | Loss: 253.999 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3030/4776 | Loss: 187.221 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3040/4776 | Loss: 262.012 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3050/4776 | Loss: 258.076 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3060/4776 | Loss: 200.274 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3070/4776 | Loss: 233.005 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3080/4776 | Loss: 241.380 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3090/4776 | Loss: 211.358 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3100/4776 | Loss: 204.299 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 3110/4776 | Loss: 198.426 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3120/4776 | Loss: 223.420 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3130/4776 | Loss: 221.148 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3140/4776 | Loss: 211.277 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3150/4776 | Loss: 227.167 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3160/4776 | Loss: 241.195 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3170/4776 | Loss: 250.510 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3180/4776 | Loss: 233.700 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3190/4776 | Loss: 239.958 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3200/4776 | Loss: 257.115 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3210/4776 | Loss: 241.118 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3220/4776 | Loss: 195.624 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3230/4776 | Loss: 178.956 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3240/4776 | Loss: 213.543 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3250/4776 | Loss: 218.584 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3260/4776 | Loss: 267.266 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3270/4776 | Loss: 246.341 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3280/4776 | Loss: 249.780 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3290/4776 | Loss: 242.563 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3300/4776 | Loss: 260.975 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3310/4776 | Loss: 286.817 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3320/4776 | Loss: 264.012 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3330/4776 | Loss: 212.990 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3340/4776 | Loss: 265.069 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3350/4776 | Loss: 258.360 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3360/4776 | Loss: 265.468 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3370/4776 | Loss: 223.699 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3380/4776 | Loss: 168.903 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 3390/4776 | Loss: 217.359 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3400/4776 | Loss: 248.339 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3410/4776 | Loss: 238.685 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3420/4776 | Loss: 227.764 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3430/4776 | Loss: 224.441 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3440/4776 | Loss: 202.662 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3450/4776 | Loss: 224.718 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3460/4776 | Loss: 199.161 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3470/4776 | Loss: 212.326 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3480/4776 | Loss: 288.095 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3490/4776 | Loss: 247.192 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 3500/4776 | Loss: 163.811 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3510/4776 | Loss: 223.984 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3520/4776 | Loss: 215.702 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3530/4776 | Loss: 217.278 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3540/4776 | Loss: 257.612 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3550/4776 | Loss: 207.042 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3560/4776 | Loss: 238.364 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3570/4776 | Loss: 215.276 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3580/4776 | Loss: 235.661 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3590/4776 | Loss: 202.723 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3600/4776 | Loss: 207.369 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3610/4776 | Loss: 219.733 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3620/4776 | Loss: 175.212 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3630/4776 | Loss: 181.981 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3640/4776 | Loss: 248.800 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3650/4776 | Loss: 230.698 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3660/4776 | Loss: 272.941 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3670/4776 | Loss: 243.060 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3680/4776 | Loss: 225.503 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3690/4776 | Loss: 245.061 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3700/4776 | Loss: 210.137 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3710/4776 | Loss: 243.282 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3720/4776 | Loss: 238.472 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3730/4776 | Loss: 206.725 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3740/4776 | Loss: 210.372 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3750/4776 | Loss: 220.883 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3760/4776 | Loss: 189.740 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3770/4776 | Loss: 198.605 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3780/4776 | Loss: 245.160 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3790/4776 | Loss: 247.263 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3800/4776 | Loss: 247.954 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3810/4776 | Loss: 202.765 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3820/4776 | Loss: 257.148 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3830/4776 | Loss: 257.368 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3840/4776 | Loss: 211.164 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3850/4776 | Loss: 288.691 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3860/4776 | Loss: 246.850 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3870/4776 | Loss: 210.984 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3880/4776 | Loss: 227.938 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3890/4776 | Loss: 205.018 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3900/4776 | Loss: 216.916 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3910/4776 | Loss: 213.719 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 3920/4776 | Loss: 227.432 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3930/4776 | Loss: 250.679 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3940/4776 | Loss: 259.886 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 3950/4776 | Loss: 247.797 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 3960/4776 | Loss: 212.970 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3970/4776 | Loss: 214.751 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 3980/4776 | Loss: 245.949 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 3990/4776 | Loss: 255.751 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4000/4776 | Loss: 195.359 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4010/4776 | Loss: 199.927 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4020/4776 | Loss: 215.091 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4030/4776 | Loss: 234.862 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4040/4776 | Loss: 185.612 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4050/4776 | Loss: 200.650 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4060/4776 | Loss: 176.449 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4070/4776 | Loss: 235.487 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4080/4776 | Loss: 227.085 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4090/4776 | Loss: 214.975 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4100/4776 | Loss: 188.698 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4110/4776 | Loss: 230.510 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4120/4776 | Loss: 214.769 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4130/4776 | Loss: 271.481 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4140/4776 | Loss: 244.659 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4150/4776 | Loss: 281.530 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4160/4776 | Loss: 252.924 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4170/4776 | Loss: 237.939 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4180/4776 | Loss: 250.349 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4190/4776 | Loss: 213.824 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4200/4776 | Loss: 231.667 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4210/4776 | Loss: 170.524 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4220/4776 | Loss: 224.206 | Accuracy: 0.600\n",
      "[Epoch: 25/200] - Step: 4230/4776 | Loss: 222.047 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4240/4776 | Loss: 247.424 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4250/4776 | Loss: 230.442 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4260/4776 | Loss: 236.113 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4270/4776 | Loss: 221.018 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4280/4776 | Loss: 255.059 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4290/4776 | Loss: 261.514 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4300/4776 | Loss: 224.885 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4310/4776 | Loss: 283.049 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4320/4776 | Loss: 219.361 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4330/4776 | Loss: 268.426 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4340/4776 | Loss: 200.478 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4350/4776 | Loss: 248.678 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4360/4776 | Loss: 271.936 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4370/4776 | Loss: 251.604 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4380/4776 | Loss: 240.922 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4390/4776 | Loss: 195.029 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4400/4776 | Loss: 258.610 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4410/4776 | Loss: 202.186 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4420/4776 | Loss: 193.992 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4430/4776 | Loss: 205.102 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4440/4776 | Loss: 239.627 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4450/4776 | Loss: 250.634 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4460/4776 | Loss: 273.421 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4470/4776 | Loss: 236.847 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4480/4776 | Loss: 264.773 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 4490/4776 | Loss: 223.685 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4500/4776 | Loss: 214.592 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4510/4776 | Loss: 240.095 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4520/4776 | Loss: 258.170 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4530/4776 | Loss: 247.200 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4540/4776 | Loss: 251.978 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4550/4776 | Loss: 203.493 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4560/4776 | Loss: 251.968 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4570/4776 | Loss: 206.334 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4580/4776 | Loss: 204.441 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4590/4776 | Loss: 230.106 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4600/4776 | Loss: 246.266 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4610/4776 | Loss: 226.491 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4620/4776 | Loss: 236.250 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4630/4776 | Loss: 223.025 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4640/4776 | Loss: 195.047 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4650/4776 | Loss: 243.995 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4660/4776 | Loss: 208.913 | Accuracy: 0.500\n",
      "[Epoch: 25/200] - Step: 4670/4776 | Loss: 259.540 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4680/4776 | Loss: 264.939 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4690/4776 | Loss: 180.645 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 4700/4776 | Loss: 222.950 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4710/4776 | Loss: 229.706 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4720/4776 | Loss: 276.981 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4730/4776 | Loss: 235.715 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 4740/4776 | Loss: 165.708 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 4750/4776 | Loss: 235.153 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4760/4776 | Loss: 203.645 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 4770/4776 | Loss: 217.642 | Accuracy: 0.300\n",
      "Accuracy:  0.14754098360655737\n",
      "[Epoch: 26/200] - Step: 10/4776 | Loss: 187.821 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 20/4776 | Loss: 215.868 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 30/4776 | Loss: 210.235 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 40/4776 | Loss: 266.765 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 50/4776 | Loss: 259.447 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 60/4776 | Loss: 196.679 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 70/4776 | Loss: 193.896 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 80/4776 | Loss: 235.906 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 90/4776 | Loss: 234.728 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 100/4776 | Loss: 213.456 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 110/4776 | Loss: 227.369 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 120/4776 | Loss: 228.497 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 130/4776 | Loss: 207.701 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 140/4776 | Loss: 196.647 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 150/4776 | Loss: 202.387 | Accuracy: 0.600\n",
      "[Epoch: 26/200] - Step: 160/4776 | Loss: 238.128 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 170/4776 | Loss: 201.168 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 180/4776 | Loss: 228.036 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 190/4776 | Loss: 245.539 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 200/4776 | Loss: 222.072 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 210/4776 | Loss: 241.686 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 220/4776 | Loss: 244.853 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 230/4776 | Loss: 219.192 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 240/4776 | Loss: 203.031 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 250/4776 | Loss: 163.545 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 260/4776 | Loss: 204.199 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 270/4776 | Loss: 209.538 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 280/4776 | Loss: 236.170 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 290/4776 | Loss: 196.936 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 300/4776 | Loss: 196.216 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 310/4776 | Loss: 223.078 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 320/4776 | Loss: 165.996 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 330/4776 | Loss: 239.831 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 340/4776 | Loss: 186.742 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 350/4776 | Loss: 252.980 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 360/4776 | Loss: 211.464 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 370/4776 | Loss: 236.863 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 380/4776 | Loss: 197.577 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 390/4776 | Loss: 230.906 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 400/4776 | Loss: 224.654 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 410/4776 | Loss: 191.719 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 420/4776 | Loss: 196.802 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 430/4776 | Loss: 235.686 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 440/4776 | Loss: 195.157 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 450/4776 | Loss: 229.290 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 460/4776 | Loss: 250.080 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 470/4776 | Loss: 220.019 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 480/4776 | Loss: 245.824 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 490/4776 | Loss: 200.672 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 500/4776 | Loss: 209.742 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 510/4776 | Loss: 256.293 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 520/4776 | Loss: 229.931 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 530/4776 | Loss: 214.457 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 540/4776 | Loss: 262.532 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 550/4776 | Loss: 246.982 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 560/4776 | Loss: 244.451 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 570/4776 | Loss: 213.586 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 580/4776 | Loss: 220.865 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 590/4776 | Loss: 213.897 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 600/4776 | Loss: 264.880 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 610/4776 | Loss: 203.864 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 620/4776 | Loss: 212.368 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 630/4776 | Loss: 235.272 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 640/4776 | Loss: 246.184 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 650/4776 | Loss: 204.779 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 660/4776 | Loss: 252.790 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 670/4776 | Loss: 207.299 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 680/4776 | Loss: 248.036 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 690/4776 | Loss: 201.499 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 700/4776 | Loss: 251.501 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 710/4776 | Loss: 241.295 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 720/4776 | Loss: 267.030 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 730/4776 | Loss: 185.501 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 740/4776 | Loss: 204.244 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 750/4776 | Loss: 286.181 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 760/4776 | Loss: 240.450 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 770/4776 | Loss: 239.712 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 780/4776 | Loss: 204.110 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 790/4776 | Loss: 220.272 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 800/4776 | Loss: 177.938 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 810/4776 | Loss: 214.075 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 820/4776 | Loss: 210.269 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 830/4776 | Loss: 224.162 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 840/4776 | Loss: 231.243 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 850/4776 | Loss: 229.939 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 860/4776 | Loss: 216.917 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 870/4776 | Loss: 238.885 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 880/4776 | Loss: 219.334 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 890/4776 | Loss: 235.904 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 900/4776 | Loss: 192.705 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 910/4776 | Loss: 263.204 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 920/4776 | Loss: 215.905 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 930/4776 | Loss: 204.811 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 940/4776 | Loss: 191.488 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 950/4776 | Loss: 204.784 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 960/4776 | Loss: 237.547 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 970/4776 | Loss: 204.015 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 980/4776 | Loss: 235.110 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 990/4776 | Loss: 205.446 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1000/4776 | Loss: 202.024 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1010/4776 | Loss: 208.232 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1020/4776 | Loss: 235.030 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1030/4776 | Loss: 241.269 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1040/4776 | Loss: 237.194 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1050/4776 | Loss: 196.776 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 1060/4776 | Loss: 204.450 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1070/4776 | Loss: 229.976 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1080/4776 | Loss: 252.597 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1090/4776 | Loss: 215.901 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1100/4776 | Loss: 215.867 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1110/4776 | Loss: 237.444 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1120/4776 | Loss: 224.327 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1130/4776 | Loss: 235.557 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1140/4776 | Loss: 217.592 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 1150/4776 | Loss: 256.071 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1160/4776 | Loss: 184.107 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1170/4776 | Loss: 271.858 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1180/4776 | Loss: 236.725 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1190/4776 | Loss: 221.978 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1200/4776 | Loss: 249.015 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1210/4776 | Loss: 218.405 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1220/4776 | Loss: 211.472 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1230/4776 | Loss: 219.588 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1240/4776 | Loss: 214.053 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1250/4776 | Loss: 237.101 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1260/4776 | Loss: 205.989 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1270/4776 | Loss: 213.619 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1280/4776 | Loss: 236.730 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1290/4776 | Loss: 231.470 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1300/4776 | Loss: 277.930 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1310/4776 | Loss: 273.625 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1320/4776 | Loss: 236.442 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1330/4776 | Loss: 228.818 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1340/4776 | Loss: 210.261 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1350/4776 | Loss: 258.977 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1360/4776 | Loss: 240.883 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1370/4776 | Loss: 241.377 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1380/4776 | Loss: 267.946 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1390/4776 | Loss: 246.520 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1400/4776 | Loss: 266.795 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1410/4776 | Loss: 261.617 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1420/4776 | Loss: 238.587 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1430/4776 | Loss: 244.395 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1440/4776 | Loss: 234.473 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1450/4776 | Loss: 232.532 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1460/4776 | Loss: 255.771 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1470/4776 | Loss: 209.373 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1480/4776 | Loss: 227.161 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1490/4776 | Loss: 263.231 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1500/4776 | Loss: 230.812 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1510/4776 | Loss: 249.203 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1520/4776 | Loss: 192.819 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1530/4776 | Loss: 244.772 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1540/4776 | Loss: 219.801 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1550/4776 | Loss: 207.340 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1560/4776 | Loss: 187.842 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1570/4776 | Loss: 237.381 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1580/4776 | Loss: 221.980 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1590/4776 | Loss: 244.905 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1600/4776 | Loss: 225.136 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1610/4776 | Loss: 241.667 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1620/4776 | Loss: 287.199 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1630/4776 | Loss: 231.474 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1640/4776 | Loss: 225.684 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1650/4776 | Loss: 249.302 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1660/4776 | Loss: 217.270 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1670/4776 | Loss: 232.438 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1680/4776 | Loss: 236.083 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1690/4776 | Loss: 212.891 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1700/4776 | Loss: 232.701 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1710/4776 | Loss: 223.238 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1720/4776 | Loss: 195.756 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1730/4776 | Loss: 207.635 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1740/4776 | Loss: 177.177 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 1750/4776 | Loss: 212.389 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1760/4776 | Loss: 278.849 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1770/4776 | Loss: 201.444 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1780/4776 | Loss: 254.475 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1790/4776 | Loss: 223.954 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1800/4776 | Loss: 173.786 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 1810/4776 | Loss: 191.638 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1820/4776 | Loss: 205.751 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1830/4776 | Loss: 213.067 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1840/4776 | Loss: 253.609 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1850/4776 | Loss: 220.416 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1860/4776 | Loss: 208.957 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1870/4776 | Loss: 185.245 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1880/4776 | Loss: 214.831 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1890/4776 | Loss: 206.211 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1900/4776 | Loss: 218.488 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1910/4776 | Loss: 175.038 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1920/4776 | Loss: 266.346 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1930/4776 | Loss: 250.304 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1940/4776 | Loss: 227.162 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1950/4776 | Loss: 216.406 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1960/4776 | Loss: 247.428 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1970/4776 | Loss: 193.994 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1980/4776 | Loss: 262.413 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1990/4776 | Loss: 275.520 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2000/4776 | Loss: 249.694 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2010/4776 | Loss: 206.878 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2020/4776 | Loss: 215.069 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2030/4776 | Loss: 200.871 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 2040/4776 | Loss: 220.269 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2050/4776 | Loss: 239.576 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2060/4776 | Loss: 233.965 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2070/4776 | Loss: 219.032 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2080/4776 | Loss: 215.341 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2090/4776 | Loss: 221.692 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2100/4776 | Loss: 227.629 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2110/4776 | Loss: 183.339 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2120/4776 | Loss: 204.548 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2130/4776 | Loss: 193.128 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2140/4776 | Loss: 267.734 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2150/4776 | Loss: 206.819 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2160/4776 | Loss: 245.055 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2170/4776 | Loss: 330.786 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2180/4776 | Loss: 249.341 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2190/4776 | Loss: 207.600 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2200/4776 | Loss: 230.172 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2210/4776 | Loss: 244.390 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2220/4776 | Loss: 252.728 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2230/4776 | Loss: 233.144 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2240/4776 | Loss: 227.646 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2250/4776 | Loss: 220.090 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2260/4776 | Loss: 179.317 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2270/4776 | Loss: 299.308 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2280/4776 | Loss: 242.388 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2290/4776 | Loss: 215.544 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2300/4776 | Loss: 243.836 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2310/4776 | Loss: 214.707 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2320/4776 | Loss: 267.233 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2330/4776 | Loss: 220.930 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2340/4776 | Loss: 176.962 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 2350/4776 | Loss: 247.495 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2360/4776 | Loss: 253.527 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2370/4776 | Loss: 256.152 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2380/4776 | Loss: 253.936 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2390/4776 | Loss: 210.011 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2400/4776 | Loss: 234.041 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2410/4776 | Loss: 234.856 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2420/4776 | Loss: 210.926 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2430/4776 | Loss: 244.470 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2440/4776 | Loss: 233.823 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2450/4776 | Loss: 222.436 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2460/4776 | Loss: 193.848 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2470/4776 | Loss: 222.235 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2480/4776 | Loss: 183.369 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2490/4776 | Loss: 248.521 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2500/4776 | Loss: 212.508 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2510/4776 | Loss: 232.051 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2520/4776 | Loss: 223.570 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2530/4776 | Loss: 258.990 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2540/4776 | Loss: 221.561 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2550/4776 | Loss: 200.510 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2560/4776 | Loss: 219.639 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2570/4776 | Loss: 208.694 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2580/4776 | Loss: 200.084 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2590/4776 | Loss: 245.792 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2600/4776 | Loss: 225.639 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2610/4776 | Loss: 210.569 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2620/4776 | Loss: 201.728 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2630/4776 | Loss: 266.910 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2640/4776 | Loss: 211.263 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2650/4776 | Loss: 239.588 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2660/4776 | Loss: 229.456 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2670/4776 | Loss: 178.064 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2680/4776 | Loss: 204.576 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2690/4776 | Loss: 230.468 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2700/4776 | Loss: 221.600 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2710/4776 | Loss: 248.871 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2720/4776 | Loss: 168.582 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2730/4776 | Loss: 248.293 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2740/4776 | Loss: 248.531 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2750/4776 | Loss: 209.545 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2760/4776 | Loss: 279.615 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2770/4776 | Loss: 261.116 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2780/4776 | Loss: 248.561 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2790/4776 | Loss: 237.374 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2800/4776 | Loss: 228.505 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2810/4776 | Loss: 251.135 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2820/4776 | Loss: 205.588 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2830/4776 | Loss: 191.971 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2840/4776 | Loss: 195.675 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 2850/4776 | Loss: 256.605 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2860/4776 | Loss: 200.644 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2870/4776 | Loss: 206.054 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2880/4776 | Loss: 246.676 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 2890/4776 | Loss: 220.400 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2900/4776 | Loss: 255.180 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2910/4776 | Loss: 203.177 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2920/4776 | Loss: 245.855 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2930/4776 | Loss: 220.294 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 2940/4776 | Loss: 248.829 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2950/4776 | Loss: 199.883 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 2960/4776 | Loss: 226.613 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2970/4776 | Loss: 254.073 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 2980/4776 | Loss: 214.533 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 2990/4776 | Loss: 221.268 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3000/4776 | Loss: 249.992 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3010/4776 | Loss: 217.261 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3020/4776 | Loss: 237.450 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3030/4776 | Loss: 222.432 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3040/4776 | Loss: 216.316 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3050/4776 | Loss: 224.726 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3060/4776 | Loss: 226.736 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3070/4776 | Loss: 254.553 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3080/4776 | Loss: 198.897 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3090/4776 | Loss: 246.314 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3100/4776 | Loss: 246.712 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3110/4776 | Loss: 235.564 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3120/4776 | Loss: 245.273 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3130/4776 | Loss: 227.192 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3140/4776 | Loss: 217.644 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3150/4776 | Loss: 210.124 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3160/4776 | Loss: 226.447 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3170/4776 | Loss: 194.156 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3180/4776 | Loss: 236.136 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3190/4776 | Loss: 170.049 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 3200/4776 | Loss: 233.475 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3210/4776 | Loss: 233.554 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3220/4776 | Loss: 243.348 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3230/4776 | Loss: 183.200 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3240/4776 | Loss: 295.045 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3250/4776 | Loss: 236.137 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3260/4776 | Loss: 212.717 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3270/4776 | Loss: 211.840 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3280/4776 | Loss: 240.575 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3290/4776 | Loss: 244.483 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3300/4776 | Loss: 151.708 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 3310/4776 | Loss: 201.756 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3320/4776 | Loss: 209.095 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3330/4776 | Loss: 273.660 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3340/4776 | Loss: 257.796 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3350/4776 | Loss: 185.696 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3360/4776 | Loss: 242.869 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3370/4776 | Loss: 235.566 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3380/4776 | Loss: 214.223 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3390/4776 | Loss: 217.418 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 3400/4776 | Loss: 166.969 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 3410/4776 | Loss: 233.462 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3420/4776 | Loss: 208.357 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3430/4776 | Loss: 247.613 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3440/4776 | Loss: 209.163 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3450/4776 | Loss: 253.353 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3460/4776 | Loss: 228.719 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3470/4776 | Loss: 239.246 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3480/4776 | Loss: 226.251 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3490/4776 | Loss: 218.533 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3500/4776 | Loss: 223.672 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3510/4776 | Loss: 227.282 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3520/4776 | Loss: 254.758 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3530/4776 | Loss: 216.173 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3540/4776 | Loss: 202.926 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3550/4776 | Loss: 197.271 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3560/4776 | Loss: 239.250 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3570/4776 | Loss: 220.967 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3580/4776 | Loss: 187.175 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3590/4776 | Loss: 173.465 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3600/4776 | Loss: 195.583 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3610/4776 | Loss: 273.240 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3620/4776 | Loss: 224.501 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3630/4776 | Loss: 254.450 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3640/4776 | Loss: 191.820 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3650/4776 | Loss: 195.278 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3660/4776 | Loss: 214.656 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3670/4776 | Loss: 231.470 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3680/4776 | Loss: 244.710 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3690/4776 | Loss: 207.560 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3700/4776 | Loss: 212.358 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3710/4776 | Loss: 234.573 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3720/4776 | Loss: 224.338 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3730/4776 | Loss: 256.415 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3740/4776 | Loss: 279.366 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3750/4776 | Loss: 283.395 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3760/4776 | Loss: 243.556 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3770/4776 | Loss: 243.968 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3780/4776 | Loss: 224.479 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3790/4776 | Loss: 232.527 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3800/4776 | Loss: 190.710 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3810/4776 | Loss: 222.431 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3820/4776 | Loss: 166.704 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3830/4776 | Loss: 238.217 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3840/4776 | Loss: 220.514 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3850/4776 | Loss: 218.300 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 3860/4776 | Loss: 237.571 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3870/4776 | Loss: 224.741 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3880/4776 | Loss: 172.910 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3890/4776 | Loss: 182.626 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3900/4776 | Loss: 186.546 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3910/4776 | Loss: 202.513 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3920/4776 | Loss: 187.490 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 3930/4776 | Loss: 232.902 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 3940/4776 | Loss: 242.336 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3950/4776 | Loss: 206.112 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 3960/4776 | Loss: 195.547 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3970/4776 | Loss: 221.077 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3980/4776 | Loss: 202.783 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 3990/4776 | Loss: 228.047 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4000/4776 | Loss: 195.117 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4010/4776 | Loss: 207.807 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4020/4776 | Loss: 206.725 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4030/4776 | Loss: 224.424 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4040/4776 | Loss: 240.521 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4050/4776 | Loss: 195.844 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4060/4776 | Loss: 230.872 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4070/4776 | Loss: 230.682 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4080/4776 | Loss: 232.225 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4090/4776 | Loss: 213.325 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 4100/4776 | Loss: 182.360 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4110/4776 | Loss: 232.611 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4120/4776 | Loss: 193.815 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4130/4776 | Loss: 204.209 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4140/4776 | Loss: 229.425 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4150/4776 | Loss: 216.410 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4160/4776 | Loss: 241.780 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4170/4776 | Loss: 274.350 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4180/4776 | Loss: 231.405 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4190/4776 | Loss: 246.164 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4200/4776 | Loss: 186.694 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4210/4776 | Loss: 178.024 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4220/4776 | Loss: 233.805 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4230/4776 | Loss: 182.317 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4240/4776 | Loss: 232.033 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4250/4776 | Loss: 209.084 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4260/4776 | Loss: 210.066 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4270/4776 | Loss: 198.236 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4280/4776 | Loss: 207.462 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4290/4776 | Loss: 238.674 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4300/4776 | Loss: 198.013 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4310/4776 | Loss: 244.007 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4320/4776 | Loss: 217.589 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4330/4776 | Loss: 201.198 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4340/4776 | Loss: 213.667 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4350/4776 | Loss: 213.018 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4360/4776 | Loss: 229.576 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4370/4776 | Loss: 211.126 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4380/4776 | Loss: 238.882 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4390/4776 | Loss: 238.850 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4400/4776 | Loss: 210.248 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4410/4776 | Loss: 219.352 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 4420/4776 | Loss: 233.911 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4430/4776 | Loss: 247.264 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4440/4776 | Loss: 177.550 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4450/4776 | Loss: 193.853 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4460/4776 | Loss: 235.314 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4470/4776 | Loss: 185.069 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4480/4776 | Loss: 267.102 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4490/4776 | Loss: 203.297 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4500/4776 | Loss: 210.982 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4510/4776 | Loss: 321.168 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 4520/4776 | Loss: 240.165 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4530/4776 | Loss: 227.924 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4540/4776 | Loss: 216.744 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4550/4776 | Loss: 269.495 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 4560/4776 | Loss: 237.399 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4570/4776 | Loss: 177.185 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 4580/4776 | Loss: 217.981 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4590/4776 | Loss: 219.284 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4600/4776 | Loss: 246.764 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4610/4776 | Loss: 175.546 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 4620/4776 | Loss: 185.054 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 4630/4776 | Loss: 235.378 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4640/4776 | Loss: 233.343 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4650/4776 | Loss: 246.391 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4660/4776 | Loss: 238.433 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4670/4776 | Loss: 236.536 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4680/4776 | Loss: 220.545 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4690/4776 | Loss: 234.102 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 4700/4776 | Loss: 230.155 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4710/4776 | Loss: 202.916 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4720/4776 | Loss: 233.605 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4730/4776 | Loss: 250.138 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4740/4776 | Loss: 175.247 | Accuracy: 0.500\n",
      "[Epoch: 26/200] - Step: 4750/4776 | Loss: 178.892 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 4760/4776 | Loss: 172.136 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 4770/4776 | Loss: 214.496 | Accuracy: 0.100\n",
      "Accuracy:  0.14918032786885246\n",
      "[Epoch: 27/200] - Step: 10/4776 | Loss: 238.885 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 20/4776 | Loss: 229.067 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 30/4776 | Loss: 202.801 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 40/4776 | Loss: 191.422 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 50/4776 | Loss: 268.600 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 60/4776 | Loss: 212.501 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 70/4776 | Loss: 205.273 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 80/4776 | Loss: 186.116 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 90/4776 | Loss: 168.006 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 100/4776 | Loss: 185.551 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 110/4776 | Loss: 227.310 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 120/4776 | Loss: 231.737 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 130/4776 | Loss: 206.238 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 140/4776 | Loss: 202.864 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 150/4776 | Loss: 213.409 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 160/4776 | Loss: 218.123 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 170/4776 | Loss: 187.597 | Accuracy: 0.700\n",
      "[Epoch: 27/200] - Step: 180/4776 | Loss: 229.280 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 190/4776 | Loss: 280.815 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 200/4776 | Loss: 223.533 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 210/4776 | Loss: 209.477 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 220/4776 | Loss: 245.530 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 230/4776 | Loss: 206.524 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 240/4776 | Loss: 249.266 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 250/4776 | Loss: 216.707 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 260/4776 | Loss: 222.612 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 270/4776 | Loss: 221.780 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 280/4776 | Loss: 238.353 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 290/4776 | Loss: 237.156 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 300/4776 | Loss: 245.429 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 310/4776 | Loss: 233.895 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 320/4776 | Loss: 202.973 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 330/4776 | Loss: 205.554 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 340/4776 | Loss: 195.319 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 350/4776 | Loss: 197.016 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 360/4776 | Loss: 205.296 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 370/4776 | Loss: 206.941 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 380/4776 | Loss: 196.115 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 390/4776 | Loss: 246.540 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 400/4776 | Loss: 203.398 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 410/4776 | Loss: 185.128 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 420/4776 | Loss: 252.089 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 430/4776 | Loss: 220.098 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 440/4776 | Loss: 186.929 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 450/4776 | Loss: 211.809 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 460/4776 | Loss: 170.613 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 470/4776 | Loss: 234.697 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 480/4776 | Loss: 207.015 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 490/4776 | Loss: 213.147 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 500/4776 | Loss: 240.595 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 510/4776 | Loss: 232.684 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 520/4776 | Loss: 176.198 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 530/4776 | Loss: 209.440 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 540/4776 | Loss: 200.198 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 550/4776 | Loss: 231.627 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 560/4776 | Loss: 197.991 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 570/4776 | Loss: 265.379 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 580/4776 | Loss: 260.707 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 590/4776 | Loss: 193.240 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 600/4776 | Loss: 215.951 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 610/4776 | Loss: 201.402 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 620/4776 | Loss: 257.455 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 630/4776 | Loss: 266.617 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 640/4776 | Loss: 203.976 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 650/4776 | Loss: 185.786 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 660/4776 | Loss: 220.689 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 670/4776 | Loss: 264.074 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 680/4776 | Loss: 183.937 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 690/4776 | Loss: 208.631 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 700/4776 | Loss: 190.502 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 710/4776 | Loss: 203.296 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 720/4776 | Loss: 219.768 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 730/4776 | Loss: 221.625 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 740/4776 | Loss: 320.023 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 750/4776 | Loss: 225.390 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 760/4776 | Loss: 193.414 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 770/4776 | Loss: 231.785 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 780/4776 | Loss: 191.551 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 790/4776 | Loss: 226.394 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 800/4776 | Loss: 187.061 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 810/4776 | Loss: 185.498 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 820/4776 | Loss: 190.260 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 830/4776 | Loss: 190.164 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 840/4776 | Loss: 178.597 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 850/4776 | Loss: 268.012 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 860/4776 | Loss: 212.959 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 870/4776 | Loss: 230.532 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 880/4776 | Loss: 204.626 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 890/4776 | Loss: 217.219 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 900/4776 | Loss: 233.083 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 910/4776 | Loss: 226.345 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 920/4776 | Loss: 166.334 | Accuracy: 0.600\n",
      "[Epoch: 27/200] - Step: 930/4776 | Loss: 252.288 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 940/4776 | Loss: 217.556 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 950/4776 | Loss: 229.681 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 960/4776 | Loss: 225.471 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 970/4776 | Loss: 261.722 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 980/4776 | Loss: 227.244 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 990/4776 | Loss: 238.988 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1000/4776 | Loss: 206.963 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1010/4776 | Loss: 278.057 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1020/4776 | Loss: 233.554 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1030/4776 | Loss: 228.001 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1040/4776 | Loss: 254.308 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1050/4776 | Loss: 257.812 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1060/4776 | Loss: 221.372 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1070/4776 | Loss: 253.574 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1080/4776 | Loss: 189.764 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1090/4776 | Loss: 263.014 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1100/4776 | Loss: 203.682 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1110/4776 | Loss: 216.934 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1120/4776 | Loss: 174.254 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1130/4776 | Loss: 252.856 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1140/4776 | Loss: 267.390 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1150/4776 | Loss: 190.062 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1160/4776 | Loss: 241.271 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1170/4776 | Loss: 173.120 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1180/4776 | Loss: 254.371 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1190/4776 | Loss: 197.149 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1200/4776 | Loss: 203.317 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1210/4776 | Loss: 241.136 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1220/4776 | Loss: 223.224 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1230/4776 | Loss: 193.664 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1240/4776 | Loss: 213.525 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1250/4776 | Loss: 257.664 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1260/4776 | Loss: 230.181 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1270/4776 | Loss: 247.228 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1280/4776 | Loss: 209.866 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1290/4776 | Loss: 211.211 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1300/4776 | Loss: 182.948 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1310/4776 | Loss: 195.110 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1320/4776 | Loss: 259.288 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1330/4776 | Loss: 204.176 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1340/4776 | Loss: 228.987 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1350/4776 | Loss: 182.949 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1360/4776 | Loss: 189.160 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1370/4776 | Loss: 234.101 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1380/4776 | Loss: 185.263 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1390/4776 | Loss: 200.933 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1400/4776 | Loss: 266.198 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1410/4776 | Loss: 215.178 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1420/4776 | Loss: 182.466 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1430/4776 | Loss: 236.236 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1440/4776 | Loss: 228.828 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1450/4776 | Loss: 197.035 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1460/4776 | Loss: 270.070 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1470/4776 | Loss: 210.553 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1480/4776 | Loss: 176.472 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1490/4776 | Loss: 211.134 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1500/4776 | Loss: 224.613 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1510/4776 | Loss: 194.648 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1520/4776 | Loss: 208.245 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1530/4776 | Loss: 176.733 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1540/4776 | Loss: 223.541 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1550/4776 | Loss: 205.274 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1560/4776 | Loss: 193.264 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1570/4776 | Loss: 227.629 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1580/4776 | Loss: 166.475 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1590/4776 | Loss: 174.813 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1600/4776 | Loss: 211.503 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1610/4776 | Loss: 262.766 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1620/4776 | Loss: 181.875 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1630/4776 | Loss: 232.423 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1640/4776 | Loss: 194.963 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1650/4776 | Loss: 241.688 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1660/4776 | Loss: 230.989 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1670/4776 | Loss: 249.925 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1680/4776 | Loss: 247.936 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1690/4776 | Loss: 195.622 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1700/4776 | Loss: 212.449 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1710/4776 | Loss: 225.033 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1720/4776 | Loss: 253.720 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1730/4776 | Loss: 194.085 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1740/4776 | Loss: 227.126 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1750/4776 | Loss: 228.673 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1760/4776 | Loss: 171.475 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1770/4776 | Loss: 257.436 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1780/4776 | Loss: 210.037 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1790/4776 | Loss: 160.434 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 1800/4776 | Loss: 241.578 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1810/4776 | Loss: 237.818 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1820/4776 | Loss: 201.193 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1830/4776 | Loss: 186.096 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1840/4776 | Loss: 169.025 | Accuracy: 0.600\n",
      "[Epoch: 27/200] - Step: 1850/4776 | Loss: 229.137 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1860/4776 | Loss: 185.469 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1870/4776 | Loss: 214.717 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1880/4776 | Loss: 223.989 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1890/4776 | Loss: 234.642 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1900/4776 | Loss: 209.903 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 1910/4776 | Loss: 271.726 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1920/4776 | Loss: 223.963 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1930/4776 | Loss: 204.175 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1940/4776 | Loss: 217.375 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1950/4776 | Loss: 217.906 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1960/4776 | Loss: 256.458 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1970/4776 | Loss: 201.874 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1980/4776 | Loss: 214.276 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1990/4776 | Loss: 256.997 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2000/4776 | Loss: 183.744 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2010/4776 | Loss: 171.534 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2020/4776 | Loss: 250.438 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2030/4776 | Loss: 239.762 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2040/4776 | Loss: 226.658 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2050/4776 | Loss: 193.242 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2060/4776 | Loss: 234.334 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2070/4776 | Loss: 194.719 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2080/4776 | Loss: 212.979 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2090/4776 | Loss: 218.862 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2100/4776 | Loss: 209.000 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2110/4776 | Loss: 254.922 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2120/4776 | Loss: 218.043 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2130/4776 | Loss: 189.436 | Accuracy: 0.600\n",
      "[Epoch: 27/200] - Step: 2140/4776 | Loss: 189.178 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2150/4776 | Loss: 224.279 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2160/4776 | Loss: 201.339 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2170/4776 | Loss: 227.012 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2180/4776 | Loss: 207.098 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2190/4776 | Loss: 143.205 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2200/4776 | Loss: 250.499 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2210/4776 | Loss: 188.522 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2220/4776 | Loss: 215.022 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2230/4776 | Loss: 185.967 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2240/4776 | Loss: 228.963 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2250/4776 | Loss: 206.358 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2260/4776 | Loss: 208.458 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2270/4776 | Loss: 214.232 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2280/4776 | Loss: 264.294 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2290/4776 | Loss: 213.790 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2300/4776 | Loss: 235.105 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2310/4776 | Loss: 209.666 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2320/4776 | Loss: 183.056 | Accuracy: 0.600\n",
      "[Epoch: 27/200] - Step: 2330/4776 | Loss: 202.200 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2340/4776 | Loss: 181.652 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2350/4776 | Loss: 219.678 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2360/4776 | Loss: 197.266 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2370/4776 | Loss: 218.150 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2380/4776 | Loss: 244.137 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2390/4776 | Loss: 251.318 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2400/4776 | Loss: 213.115 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2410/4776 | Loss: 249.659 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2420/4776 | Loss: 254.160 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2430/4776 | Loss: 244.293 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2440/4776 | Loss: 219.608 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2450/4776 | Loss: 219.284 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2460/4776 | Loss: 229.705 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2470/4776 | Loss: 221.371 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2480/4776 | Loss: 228.452 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2490/4776 | Loss: 230.734 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2500/4776 | Loss: 270.350 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2510/4776 | Loss: 191.598 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2520/4776 | Loss: 228.428 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2530/4776 | Loss: 202.839 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2540/4776 | Loss: 278.042 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2550/4776 | Loss: 185.501 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2560/4776 | Loss: 212.205 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2570/4776 | Loss: 173.094 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2580/4776 | Loss: 234.270 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2590/4776 | Loss: 234.414 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2600/4776 | Loss: 257.027 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2610/4776 | Loss: 254.082 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2620/4776 | Loss: 315.687 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2630/4776 | Loss: 269.144 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2640/4776 | Loss: 192.831 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2650/4776 | Loss: 243.069 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2660/4776 | Loss: 139.339 | Accuracy: 0.700\n",
      "[Epoch: 27/200] - Step: 2670/4776 | Loss: 235.577 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2680/4776 | Loss: 239.506 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2690/4776 | Loss: 221.865 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2700/4776 | Loss: 264.147 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2710/4776 | Loss: 231.623 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2720/4776 | Loss: 179.785 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2730/4776 | Loss: 242.614 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2740/4776 | Loss: 224.762 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2750/4776 | Loss: 260.694 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2760/4776 | Loss: 249.696 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2770/4776 | Loss: 223.900 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2780/4776 | Loss: 234.305 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2790/4776 | Loss: 173.212 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2800/4776 | Loss: 185.445 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2810/4776 | Loss: 220.751 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2820/4776 | Loss: 247.984 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2830/4776 | Loss: 235.553 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2840/4776 | Loss: 230.438 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2850/4776 | Loss: 196.396 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2860/4776 | Loss: 190.134 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2870/4776 | Loss: 231.170 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2880/4776 | Loss: 219.327 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2890/4776 | Loss: 210.340 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 2900/4776 | Loss: 239.652 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2910/4776 | Loss: 256.553 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2920/4776 | Loss: 225.728 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2930/4776 | Loss: 231.100 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 2940/4776 | Loss: 224.143 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 2950/4776 | Loss: 181.438 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2960/4776 | Loss: 249.091 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 2970/4776 | Loss: 225.675 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 2980/4776 | Loss: 161.518 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 2990/4776 | Loss: 231.349 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3000/4776 | Loss: 248.917 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3010/4776 | Loss: 216.153 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3020/4776 | Loss: 224.210 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3030/4776 | Loss: 212.958 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3040/4776 | Loss: 234.060 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3050/4776 | Loss: 196.639 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3060/4776 | Loss: 271.504 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3070/4776 | Loss: 277.390 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3080/4776 | Loss: 229.550 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3090/4776 | Loss: 217.342 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3100/4776 | Loss: 206.787 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3110/4776 | Loss: 187.961 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3120/4776 | Loss: 210.364 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3130/4776 | Loss: 187.379 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3140/4776 | Loss: 198.543 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3150/4776 | Loss: 226.512 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3160/4776 | Loss: 225.129 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3170/4776 | Loss: 197.689 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 3180/4776 | Loss: 209.480 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3190/4776 | Loss: 239.520 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3200/4776 | Loss: 224.455 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3210/4776 | Loss: 266.409 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3220/4776 | Loss: 194.702 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3230/4776 | Loss: 233.020 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3240/4776 | Loss: 223.933 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3250/4776 | Loss: 228.984 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3260/4776 | Loss: 211.056 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3270/4776 | Loss: 214.784 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3280/4776 | Loss: 254.522 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3290/4776 | Loss: 249.620 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 3300/4776 | Loss: 224.702 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 3310/4776 | Loss: 228.617 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3320/4776 | Loss: 180.313 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3330/4776 | Loss: 226.741 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3340/4776 | Loss: 192.790 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 3350/4776 | Loss: 188.033 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3360/4776 | Loss: 245.291 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3370/4776 | Loss: 205.305 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3380/4776 | Loss: 265.452 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 3390/4776 | Loss: 234.548 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3400/4776 | Loss: 224.434 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3410/4776 | Loss: 208.691 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3420/4776 | Loss: 203.451 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3430/4776 | Loss: 227.304 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3440/4776 | Loss: 224.337 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3450/4776 | Loss: 197.465 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3460/4776 | Loss: 160.628 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3470/4776 | Loss: 177.672 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3480/4776 | Loss: 236.379 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3490/4776 | Loss: 224.145 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3500/4776 | Loss: 210.062 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3510/4776 | Loss: 200.510 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3520/4776 | Loss: 214.251 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3530/4776 | Loss: 234.079 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3540/4776 | Loss: 207.338 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3550/4776 | Loss: 199.987 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3560/4776 | Loss: 214.693 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3570/4776 | Loss: 212.436 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3580/4776 | Loss: 244.759 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3590/4776 | Loss: 304.538 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3600/4776 | Loss: 222.814 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3610/4776 | Loss: 208.179 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3620/4776 | Loss: 257.828 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3630/4776 | Loss: 182.261 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3640/4776 | Loss: 180.586 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3650/4776 | Loss: 223.080 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3660/4776 | Loss: 247.996 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3670/4776 | Loss: 214.615 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3680/4776 | Loss: 228.697 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3690/4776 | Loss: 229.075 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3700/4776 | Loss: 227.752 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3710/4776 | Loss: 237.915 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3720/4776 | Loss: 198.790 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3730/4776 | Loss: 227.455 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3740/4776 | Loss: 247.548 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3750/4776 | Loss: 226.267 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3760/4776 | Loss: 229.525 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3770/4776 | Loss: 244.414 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 3780/4776 | Loss: 295.106 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3790/4776 | Loss: 223.766 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3800/4776 | Loss: 236.373 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 3810/4776 | Loss: 233.844 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3820/4776 | Loss: 184.234 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3830/4776 | Loss: 243.638 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3840/4776 | Loss: 212.295 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3850/4776 | Loss: 205.774 | Accuracy: 0.600\n",
      "[Epoch: 27/200] - Step: 3860/4776 | Loss: 204.142 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3870/4776 | Loss: 257.343 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3880/4776 | Loss: 209.633 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3890/4776 | Loss: 139.394 | Accuracy: 0.700\n",
      "[Epoch: 27/200] - Step: 3900/4776 | Loss: 217.573 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3910/4776 | Loss: 205.902 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 3920/4776 | Loss: 213.534 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 3930/4776 | Loss: 194.822 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3940/4776 | Loss: 215.780 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 3950/4776 | Loss: 238.834 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3960/4776 | Loss: 262.251 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3970/4776 | Loss: 228.371 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 3980/4776 | Loss: 217.935 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 3990/4776 | Loss: 288.173 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 4000/4776 | Loss: 239.065 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4010/4776 | Loss: 211.237 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4020/4776 | Loss: 243.964 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4030/4776 | Loss: 198.674 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4040/4776 | Loss: 204.014 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4050/4776 | Loss: 200.897 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4060/4776 | Loss: 223.378 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4070/4776 | Loss: 191.651 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4080/4776 | Loss: 213.272 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4090/4776 | Loss: 225.651 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4100/4776 | Loss: 191.060 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4110/4776 | Loss: 213.761 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4120/4776 | Loss: 201.499 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4130/4776 | Loss: 267.074 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4140/4776 | Loss: 208.770 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4150/4776 | Loss: 259.385 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 4160/4776 | Loss: 228.564 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 4170/4776 | Loss: 183.764 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4180/4776 | Loss: 240.109 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4190/4776 | Loss: 235.598 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4200/4776 | Loss: 175.802 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4210/4776 | Loss: 220.933 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4220/4776 | Loss: 260.871 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4230/4776 | Loss: 212.739 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4240/4776 | Loss: 277.141 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4250/4776 | Loss: 203.367 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4260/4776 | Loss: 193.791 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4270/4776 | Loss: 223.892 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4280/4776 | Loss: 182.373 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 4290/4776 | Loss: 265.976 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 4300/4776 | Loss: 205.567 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4310/4776 | Loss: 198.284 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4320/4776 | Loss: 198.419 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4330/4776 | Loss: 212.896 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4340/4776 | Loss: 251.238 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4350/4776 | Loss: 190.100 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4360/4776 | Loss: 238.870 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4370/4776 | Loss: 211.626 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4380/4776 | Loss: 179.075 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4390/4776 | Loss: 269.800 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4400/4776 | Loss: 205.782 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4410/4776 | Loss: 211.449 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4420/4776 | Loss: 239.215 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4430/4776 | Loss: 202.685 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4440/4776 | Loss: 236.038 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4450/4776 | Loss: 218.133 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4460/4776 | Loss: 213.303 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4470/4776 | Loss: 221.213 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4480/4776 | Loss: 279.574 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4490/4776 | Loss: 176.705 | Accuracy: 0.500\n",
      "[Epoch: 27/200] - Step: 4500/4776 | Loss: 271.001 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4510/4776 | Loss: 197.134 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4520/4776 | Loss: 236.759 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4530/4776 | Loss: 200.138 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4540/4776 | Loss: 222.005 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 4550/4776 | Loss: 243.741 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4560/4776 | Loss: 238.241 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4570/4776 | Loss: 246.989 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4580/4776 | Loss: 197.596 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4590/4776 | Loss: 248.502 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4600/4776 | Loss: 226.118 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4610/4776 | Loss: 211.758 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4620/4776 | Loss: 182.346 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4630/4776 | Loss: 190.219 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4640/4776 | Loss: 239.423 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4650/4776 | Loss: 219.794 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4660/4776 | Loss: 192.652 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 4670/4776 | Loss: 211.751 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4680/4776 | Loss: 190.126 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4690/4776 | Loss: 230.782 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4700/4776 | Loss: 213.706 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4710/4776 | Loss: 189.451 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 4720/4776 | Loss: 217.297 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 4730/4776 | Loss: 237.875 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 4740/4776 | Loss: 236.989 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4750/4776 | Loss: 223.477 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4760/4776 | Loss: 247.638 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 4770/4776 | Loss: 203.572 | Accuracy: 0.300\n",
      "Accuracy:  0.1885245901639344\n",
      "Model saved!\n",
      "[Epoch: 28/200] - Step: 10/4776 | Loss: 195.999 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 20/4776 | Loss: 238.694 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 30/4776 | Loss: 225.879 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 40/4776 | Loss: 223.824 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 50/4776 | Loss: 209.366 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 60/4776 | Loss: 207.202 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 70/4776 | Loss: 185.535 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 80/4776 | Loss: 212.094 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 90/4776 | Loss: 191.095 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 100/4776 | Loss: 224.467 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 110/4776 | Loss: 181.365 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 120/4776 | Loss: 245.924 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 130/4776 | Loss: 246.540 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 140/4776 | Loss: 210.137 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 150/4776 | Loss: 211.469 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 160/4776 | Loss: 249.693 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 170/4776 | Loss: 197.984 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 180/4776 | Loss: 242.082 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 190/4776 | Loss: 171.824 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 200/4776 | Loss: 159.193 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 210/4776 | Loss: 229.706 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 220/4776 | Loss: 243.696 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 230/4776 | Loss: 228.318 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 240/4776 | Loss: 226.577 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 250/4776 | Loss: 181.591 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 260/4776 | Loss: 246.413 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 270/4776 | Loss: 176.821 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 280/4776 | Loss: 202.699 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 290/4776 | Loss: 187.297 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 300/4776 | Loss: 189.081 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 310/4776 | Loss: 175.834 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 320/4776 | Loss: 243.830 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 330/4776 | Loss: 211.560 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 340/4776 | Loss: 237.999 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 350/4776 | Loss: 201.750 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 360/4776 | Loss: 210.372 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 370/4776 | Loss: 197.267 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 380/4776 | Loss: 218.792 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 390/4776 | Loss: 218.816 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 400/4776 | Loss: 210.037 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 410/4776 | Loss: 212.675 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 420/4776 | Loss: 184.912 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 430/4776 | Loss: 208.622 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 440/4776 | Loss: 198.033 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 450/4776 | Loss: 214.198 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 460/4776 | Loss: 231.123 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 470/4776 | Loss: 222.492 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 480/4776 | Loss: 209.182 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 490/4776 | Loss: 174.972 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 500/4776 | Loss: 215.024 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 510/4776 | Loss: 219.786 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 520/4776 | Loss: 231.411 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 530/4776 | Loss: 210.687 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 540/4776 | Loss: 221.385 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 550/4776 | Loss: 190.730 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 560/4776 | Loss: 222.745 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 570/4776 | Loss: 228.027 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 580/4776 | Loss: 209.710 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 590/4776 | Loss: 196.644 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 600/4776 | Loss: 164.688 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 610/4776 | Loss: 195.645 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 620/4776 | Loss: 180.633 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 630/4776 | Loss: 268.155 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 640/4776 | Loss: 238.734 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 650/4776 | Loss: 245.610 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 660/4776 | Loss: 213.832 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 670/4776 | Loss: 257.583 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 680/4776 | Loss: 218.956 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 690/4776 | Loss: 255.354 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 700/4776 | Loss: 166.943 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 710/4776 | Loss: 206.300 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 720/4776 | Loss: 203.649 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 730/4776 | Loss: 164.360 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 740/4776 | Loss: 253.199 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 750/4776 | Loss: 158.918 | Accuracy: 0.600\n",
      "[Epoch: 28/200] - Step: 760/4776 | Loss: 229.038 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 770/4776 | Loss: 221.439 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 780/4776 | Loss: 271.766 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 790/4776 | Loss: 199.790 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 800/4776 | Loss: 207.902 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 810/4776 | Loss: 193.608 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 820/4776 | Loss: 155.677 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 830/4776 | Loss: 204.675 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 840/4776 | Loss: 227.164 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 850/4776 | Loss: 202.085 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 860/4776 | Loss: 255.555 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 870/4776 | Loss: 164.497 | Accuracy: 0.600\n",
      "[Epoch: 28/200] - Step: 880/4776 | Loss: 248.266 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 890/4776 | Loss: 208.476 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 900/4776 | Loss: 181.910 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 910/4776 | Loss: 186.948 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 920/4776 | Loss: 199.782 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 930/4776 | Loss: 185.140 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 940/4776 | Loss: 173.993 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 950/4776 | Loss: 232.971 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 960/4776 | Loss: 208.195 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 970/4776 | Loss: 236.420 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 980/4776 | Loss: 168.263 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 990/4776 | Loss: 279.148 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1000/4776 | Loss: 219.288 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1010/4776 | Loss: 223.965 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1020/4776 | Loss: 218.120 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1030/4776 | Loss: 196.526 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1040/4776 | Loss: 178.498 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1050/4776 | Loss: 183.263 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1060/4776 | Loss: 190.531 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1070/4776 | Loss: 183.632 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1080/4776 | Loss: 173.977 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1090/4776 | Loss: 268.235 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1100/4776 | Loss: 185.707 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1110/4776 | Loss: 145.604 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1120/4776 | Loss: 217.678 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1130/4776 | Loss: 200.278 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1140/4776 | Loss: 213.892 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1150/4776 | Loss: 209.729 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1160/4776 | Loss: 241.535 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1170/4776 | Loss: 246.218 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1180/4776 | Loss: 190.502 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1190/4776 | Loss: 224.049 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1200/4776 | Loss: 252.192 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1210/4776 | Loss: 236.855 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1220/4776 | Loss: 287.019 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1230/4776 | Loss: 232.702 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1240/4776 | Loss: 218.309 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1250/4776 | Loss: 237.572 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1260/4776 | Loss: 171.481 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1270/4776 | Loss: 256.664 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1280/4776 | Loss: 214.425 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1290/4776 | Loss: 196.446 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1300/4776 | Loss: 228.128 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1310/4776 | Loss: 199.017 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1320/4776 | Loss: 174.305 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1330/4776 | Loss: 263.059 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1340/4776 | Loss: 188.667 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1350/4776 | Loss: 228.095 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1360/4776 | Loss: 219.387 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1370/4776 | Loss: 220.162 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1380/4776 | Loss: 188.514 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1390/4776 | Loss: 196.880 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1400/4776 | Loss: 182.857 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1410/4776 | Loss: 208.256 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1420/4776 | Loss: 239.057 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1430/4776 | Loss: 228.609 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1440/4776 | Loss: 228.211 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1450/4776 | Loss: 194.774 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1460/4776 | Loss: 211.720 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1470/4776 | Loss: 182.495 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1480/4776 | Loss: 285.272 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1490/4776 | Loss: 216.041 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1500/4776 | Loss: 217.145 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1510/4776 | Loss: 165.263 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1520/4776 | Loss: 293.713 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1530/4776 | Loss: 235.299 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1540/4776 | Loss: 223.504 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1550/4776 | Loss: 275.927 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1560/4776 | Loss: 189.034 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1570/4776 | Loss: 255.711 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1580/4776 | Loss: 215.806 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1590/4776 | Loss: 188.870 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1600/4776 | Loss: 244.412 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1610/4776 | Loss: 250.416 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1620/4776 | Loss: 223.748 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1630/4776 | Loss: 270.516 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1640/4776 | Loss: 234.094 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1650/4776 | Loss: 161.393 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1660/4776 | Loss: 207.728 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1670/4776 | Loss: 260.442 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1680/4776 | Loss: 191.645 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1690/4776 | Loss: 194.048 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1700/4776 | Loss: 229.542 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1710/4776 | Loss: 221.330 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1720/4776 | Loss: 217.979 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1730/4776 | Loss: 233.790 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1740/4776 | Loss: 220.439 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1750/4776 | Loss: 212.101 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1760/4776 | Loss: 174.717 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1770/4776 | Loss: 185.275 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1780/4776 | Loss: 213.225 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1790/4776 | Loss: 240.023 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1800/4776 | Loss: 218.781 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1810/4776 | Loss: 200.321 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1820/4776 | Loss: 196.114 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1830/4776 | Loss: 210.346 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1840/4776 | Loss: 192.012 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1850/4776 | Loss: 229.476 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1860/4776 | Loss: 257.218 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1870/4776 | Loss: 184.818 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1880/4776 | Loss: 188.141 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1890/4776 | Loss: 204.989 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1900/4776 | Loss: 220.749 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1910/4776 | Loss: 219.985 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1920/4776 | Loss: 213.296 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1930/4776 | Loss: 179.602 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1940/4776 | Loss: 222.110 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1950/4776 | Loss: 185.713 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 1960/4776 | Loss: 247.519 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1970/4776 | Loss: 187.194 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1980/4776 | Loss: 226.200 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1990/4776 | Loss: 230.594 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2000/4776 | Loss: 185.155 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2010/4776 | Loss: 251.972 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2020/4776 | Loss: 241.658 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2030/4776 | Loss: 260.013 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2040/4776 | Loss: 247.911 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2050/4776 | Loss: 251.404 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2060/4776 | Loss: 192.032 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2070/4776 | Loss: 212.011 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2080/4776 | Loss: 243.452 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2090/4776 | Loss: 200.165 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2100/4776 | Loss: 189.115 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 2110/4776 | Loss: 224.980 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2120/4776 | Loss: 220.670 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2130/4776 | Loss: 161.292 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 2140/4776 | Loss: 236.697 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2150/4776 | Loss: 191.525 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2160/4776 | Loss: 232.367 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2170/4776 | Loss: 208.188 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 2180/4776 | Loss: 167.162 | Accuracy: 0.600\n",
      "[Epoch: 28/200] - Step: 2190/4776 | Loss: 231.535 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2200/4776 | Loss: 201.860 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2210/4776 | Loss: 240.254 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2220/4776 | Loss: 179.435 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2230/4776 | Loss: 198.989 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2240/4776 | Loss: 196.895 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2250/4776 | Loss: 263.871 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2260/4776 | Loss: 207.850 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2270/4776 | Loss: 190.766 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2280/4776 | Loss: 211.060 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2290/4776 | Loss: 287.441 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 2300/4776 | Loss: 233.951 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2310/4776 | Loss: 194.880 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2320/4776 | Loss: 203.710 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2330/4776 | Loss: 215.499 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2340/4776 | Loss: 205.772 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2350/4776 | Loss: 204.248 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2360/4776 | Loss: 212.768 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2370/4776 | Loss: 231.578 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2380/4776 | Loss: 182.905 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 2390/4776 | Loss: 191.515 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2400/4776 | Loss: 199.328 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2410/4776 | Loss: 161.111 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 2420/4776 | Loss: 207.458 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2430/4776 | Loss: 176.763 | Accuracy: 0.600\n",
      "[Epoch: 28/200] - Step: 2440/4776 | Loss: 198.073 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2450/4776 | Loss: 234.491 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2460/4776 | Loss: 209.411 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2470/4776 | Loss: 201.087 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2480/4776 | Loss: 261.302 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 2490/4776 | Loss: 227.780 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2500/4776 | Loss: 201.376 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2510/4776 | Loss: 267.418 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2520/4776 | Loss: 198.491 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2530/4776 | Loss: 179.609 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2540/4776 | Loss: 210.036 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 2550/4776 | Loss: 174.028 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2560/4776 | Loss: 267.157 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2570/4776 | Loss: 227.062 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2580/4776 | Loss: 229.403 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2590/4776 | Loss: 222.508 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2600/4776 | Loss: 212.542 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 2610/4776 | Loss: 232.622 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2620/4776 | Loss: 194.608 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2630/4776 | Loss: 256.842 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2640/4776 | Loss: 224.823 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2650/4776 | Loss: 242.272 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2660/4776 | Loss: 189.813 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2670/4776 | Loss: 265.832 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2680/4776 | Loss: 245.502 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2690/4776 | Loss: 198.114 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2700/4776 | Loss: 206.399 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2710/4776 | Loss: 200.200 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2720/4776 | Loss: 195.762 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2730/4776 | Loss: 202.212 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2740/4776 | Loss: 203.442 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2750/4776 | Loss: 192.401 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2760/4776 | Loss: 207.692 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2770/4776 | Loss: 207.038 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2780/4776 | Loss: 188.761 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2790/4776 | Loss: 234.804 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2800/4776 | Loss: 225.395 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2810/4776 | Loss: 195.525 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2820/4776 | Loss: 177.067 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2830/4776 | Loss: 205.660 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2840/4776 | Loss: 186.418 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2850/4776 | Loss: 264.489 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2860/4776 | Loss: 226.031 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2870/4776 | Loss: 164.143 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2880/4776 | Loss: 204.631 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2890/4776 | Loss: 195.230 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2900/4776 | Loss: 202.311 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2910/4776 | Loss: 213.346 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2920/4776 | Loss: 231.447 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2930/4776 | Loss: 197.596 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 2940/4776 | Loss: 181.703 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2950/4776 | Loss: 192.712 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2960/4776 | Loss: 152.585 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 2970/4776 | Loss: 205.775 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 2980/4776 | Loss: 193.338 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 2990/4776 | Loss: 192.575 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3000/4776 | Loss: 257.119 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3010/4776 | Loss: 178.330 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3020/4776 | Loss: 213.706 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3030/4776 | Loss: 221.914 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3040/4776 | Loss: 235.054 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3050/4776 | Loss: 220.607 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3060/4776 | Loss: 220.901 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3070/4776 | Loss: 188.141 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 3080/4776 | Loss: 182.805 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3090/4776 | Loss: 240.143 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3100/4776 | Loss: 217.233 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3110/4776 | Loss: 178.099 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3120/4776 | Loss: 169.723 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3130/4776 | Loss: 221.627 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3140/4776 | Loss: 201.612 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3150/4776 | Loss: 193.962 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3160/4776 | Loss: 202.432 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3170/4776 | Loss: 250.016 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3180/4776 | Loss: 202.552 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3190/4776 | Loss: 271.519 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3200/4776 | Loss: 199.208 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3210/4776 | Loss: 203.296 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3220/4776 | Loss: 221.316 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3230/4776 | Loss: 197.577 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3240/4776 | Loss: 190.722 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3250/4776 | Loss: 208.884 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3260/4776 | Loss: 202.949 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3270/4776 | Loss: 230.891 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3280/4776 | Loss: 249.402 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3290/4776 | Loss: 213.258 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3300/4776 | Loss: 220.519 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3310/4776 | Loss: 212.981 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3320/4776 | Loss: 216.474 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3330/4776 | Loss: 209.400 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3340/4776 | Loss: 242.517 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3350/4776 | Loss: 252.231 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3360/4776 | Loss: 197.244 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3370/4776 | Loss: 270.155 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3380/4776 | Loss: 227.663 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3390/4776 | Loss: 239.274 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3400/4776 | Loss: 177.459 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3410/4776 | Loss: 209.765 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3420/4776 | Loss: 175.854 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 3430/4776 | Loss: 223.169 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3440/4776 | Loss: 188.131 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3450/4776 | Loss: 201.932 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3460/4776 | Loss: 169.390 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3470/4776 | Loss: 197.727 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3480/4776 | Loss: 222.249 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3490/4776 | Loss: 203.768 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3500/4776 | Loss: 190.053 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3510/4776 | Loss: 211.165 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3520/4776 | Loss: 207.258 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3530/4776 | Loss: 214.649 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3540/4776 | Loss: 226.689 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3550/4776 | Loss: 199.743 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3560/4776 | Loss: 167.475 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3570/4776 | Loss: 240.574 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3580/4776 | Loss: 210.459 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3590/4776 | Loss: 221.259 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3600/4776 | Loss: 254.481 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3610/4776 | Loss: 167.488 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 3620/4776 | Loss: 198.435 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3630/4776 | Loss: 214.122 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3640/4776 | Loss: 213.789 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3650/4776 | Loss: 193.928 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 3660/4776 | Loss: 209.953 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3670/4776 | Loss: 222.124 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3680/4776 | Loss: 213.257 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3690/4776 | Loss: 222.017 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3700/4776 | Loss: 192.678 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3710/4776 | Loss: 250.206 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3720/4776 | Loss: 165.103 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3730/4776 | Loss: 207.610 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3740/4776 | Loss: 220.868 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3750/4776 | Loss: 196.377 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3760/4776 | Loss: 222.549 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3770/4776 | Loss: 204.522 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3780/4776 | Loss: 179.120 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3790/4776 | Loss: 197.072 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3800/4776 | Loss: 205.457 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3810/4776 | Loss: 222.841 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3820/4776 | Loss: 209.266 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3830/4776 | Loss: 196.783 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3840/4776 | Loss: 147.414 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3850/4776 | Loss: 223.745 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3860/4776 | Loss: 222.685 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3870/4776 | Loss: 218.911 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3880/4776 | Loss: 165.462 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 3890/4776 | Loss: 158.359 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 3900/4776 | Loss: 242.714 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3910/4776 | Loss: 219.956 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3920/4776 | Loss: 194.612 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3930/4776 | Loss: 283.400 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3940/4776 | Loss: 279.217 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3950/4776 | Loss: 218.957 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 3960/4776 | Loss: 194.110 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 3970/4776 | Loss: 223.624 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 3980/4776 | Loss: 271.672 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 3990/4776 | Loss: 256.232 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4000/4776 | Loss: 213.560 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4010/4776 | Loss: 218.920 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4020/4776 | Loss: 257.215 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4030/4776 | Loss: 193.398 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4040/4776 | Loss: 240.438 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4050/4776 | Loss: 202.210 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4060/4776 | Loss: 203.044 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4070/4776 | Loss: 223.150 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4080/4776 | Loss: 189.997 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4090/4776 | Loss: 206.128 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4100/4776 | Loss: 213.346 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4110/4776 | Loss: 215.924 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4120/4776 | Loss: 208.433 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4130/4776 | Loss: 201.099 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4140/4776 | Loss: 233.946 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4150/4776 | Loss: 192.312 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4160/4776 | Loss: 183.027 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 4170/4776 | Loss: 208.391 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4180/4776 | Loss: 188.988 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4190/4776 | Loss: 230.487 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4200/4776 | Loss: 176.388 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4210/4776 | Loss: 192.655 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4220/4776 | Loss: 220.265 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4230/4776 | Loss: 299.881 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4240/4776 | Loss: 251.100 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4250/4776 | Loss: 208.783 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4260/4776 | Loss: 225.481 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 4270/4776 | Loss: 194.665 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4280/4776 | Loss: 214.754 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4290/4776 | Loss: 218.117 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4300/4776 | Loss: 196.708 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4310/4776 | Loss: 243.470 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4320/4776 | Loss: 217.970 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4330/4776 | Loss: 230.145 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4340/4776 | Loss: 211.516 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4350/4776 | Loss: 255.714 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4360/4776 | Loss: 156.677 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4370/4776 | Loss: 214.086 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4380/4776 | Loss: 170.417 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 4390/4776 | Loss: 188.575 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4400/4776 | Loss: 193.398 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4410/4776 | Loss: 206.586 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4420/4776 | Loss: 180.177 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4430/4776 | Loss: 258.270 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4440/4776 | Loss: 217.776 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4450/4776 | Loss: 208.581 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4460/4776 | Loss: 242.450 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4470/4776 | Loss: 185.681 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4480/4776 | Loss: 226.188 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 4490/4776 | Loss: 201.280 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4500/4776 | Loss: 188.505 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4510/4776 | Loss: 199.854 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4520/4776 | Loss: 217.178 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4530/4776 | Loss: 156.388 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4540/4776 | Loss: 231.135 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4550/4776 | Loss: 202.743 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4560/4776 | Loss: 240.783 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 4570/4776 | Loss: 220.720 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4580/4776 | Loss: 210.171 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4590/4776 | Loss: 202.239 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 4600/4776 | Loss: 255.537 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4610/4776 | Loss: 220.993 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4620/4776 | Loss: 245.942 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 4630/4776 | Loss: 207.634 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4640/4776 | Loss: 201.351 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4650/4776 | Loss: 213.649 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4660/4776 | Loss: 152.698 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4670/4776 | Loss: 204.793 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4680/4776 | Loss: 192.170 | Accuracy: 0.400\n",
      "[Epoch: 28/200] - Step: 4690/4776 | Loss: 207.288 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 4700/4776 | Loss: 214.260 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4710/4776 | Loss: 232.453 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4720/4776 | Loss: 256.476 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4730/4776 | Loss: 275.055 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4740/4776 | Loss: 245.242 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 4750/4776 | Loss: 164.605 | Accuracy: 0.600\n",
      "[Epoch: 28/200] - Step: 4760/4776 | Loss: 237.248 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 4770/4776 | Loss: 183.285 | Accuracy: 0.400\n",
      "Accuracy:  0.14754098360655737\n",
      "[Epoch: 29/200] - Step: 10/4776 | Loss: 194.323 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 20/4776 | Loss: 243.555 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 30/4776 | Loss: 219.597 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 40/4776 | Loss: 185.520 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 50/4776 | Loss: 190.600 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 60/4776 | Loss: 208.633 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 70/4776 | Loss: 187.357 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 80/4776 | Loss: 235.334 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 90/4776 | Loss: 203.677 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 100/4776 | Loss: 189.858 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 110/4776 | Loss: 197.814 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 120/4776 | Loss: 148.448 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 130/4776 | Loss: 212.539 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 140/4776 | Loss: 197.392 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 150/4776 | Loss: 248.024 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 160/4776 | Loss: 216.143 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 170/4776 | Loss: 219.930 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 180/4776 | Loss: 182.050 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 190/4776 | Loss: 232.390 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 200/4776 | Loss: 179.059 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 210/4776 | Loss: 201.798 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 220/4776 | Loss: 202.071 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 230/4776 | Loss: 216.159 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 240/4776 | Loss: 181.281 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 250/4776 | Loss: 164.376 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 260/4776 | Loss: 206.278 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 270/4776 | Loss: 210.147 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 280/4776 | Loss: 288.474 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 290/4776 | Loss: 215.878 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 300/4776 | Loss: 222.974 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 310/4776 | Loss: 204.219 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 320/4776 | Loss: 259.125 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 330/4776 | Loss: 209.287 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 340/4776 | Loss: 213.187 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 350/4776 | Loss: 215.612 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 360/4776 | Loss: 190.714 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 370/4776 | Loss: 161.729 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 380/4776 | Loss: 189.048 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 390/4776 | Loss: 218.604 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 400/4776 | Loss: 182.134 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 410/4776 | Loss: 162.787 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 420/4776 | Loss: 193.852 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 430/4776 | Loss: 229.496 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 440/4776 | Loss: 185.020 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 450/4776 | Loss: 235.916 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 460/4776 | Loss: 224.905 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 470/4776 | Loss: 195.980 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 480/4776 | Loss: 190.088 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 490/4776 | Loss: 155.540 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 500/4776 | Loss: 203.238 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 510/4776 | Loss: 224.815 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 520/4776 | Loss: 243.512 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 530/4776 | Loss: 188.953 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 540/4776 | Loss: 200.339 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 550/4776 | Loss: 245.609 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 560/4776 | Loss: 192.601 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 570/4776 | Loss: 217.433 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 580/4776 | Loss: 208.260 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 590/4776 | Loss: 226.040 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 600/4776 | Loss: 188.661 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 610/4776 | Loss: 231.803 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 620/4776 | Loss: 159.652 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 630/4776 | Loss: 178.140 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 640/4776 | Loss: 155.305 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 650/4776 | Loss: 172.813 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 660/4776 | Loss: 231.805 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 670/4776 | Loss: 176.351 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 680/4776 | Loss: 202.252 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 690/4776 | Loss: 205.828 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 700/4776 | Loss: 214.567 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 710/4776 | Loss: 200.145 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 720/4776 | Loss: 169.043 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 730/4776 | Loss: 215.428 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 740/4776 | Loss: 236.800 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 750/4776 | Loss: 234.324 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 760/4776 | Loss: 163.300 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 770/4776 | Loss: 243.496 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 780/4776 | Loss: 228.227 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 790/4776 | Loss: 247.210 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 800/4776 | Loss: 161.262 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 810/4776 | Loss: 200.474 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 820/4776 | Loss: 247.290 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 830/4776 | Loss: 209.972 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 840/4776 | Loss: 227.158 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 850/4776 | Loss: 189.403 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 860/4776 | Loss: 231.852 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 870/4776 | Loss: 179.957 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 880/4776 | Loss: 223.798 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 890/4776 | Loss: 214.718 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 900/4776 | Loss: 237.431 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 910/4776 | Loss: 180.803 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 920/4776 | Loss: 162.825 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 930/4776 | Loss: 249.089 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 940/4776 | Loss: 137.240 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 950/4776 | Loss: 197.333 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 960/4776 | Loss: 173.603 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 970/4776 | Loss: 184.745 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 980/4776 | Loss: 199.163 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 990/4776 | Loss: 198.734 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1000/4776 | Loss: 246.704 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1010/4776 | Loss: 157.674 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 1020/4776 | Loss: 165.930 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1030/4776 | Loss: 200.498 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1040/4776 | Loss: 214.068 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1050/4776 | Loss: 134.350 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1060/4776 | Loss: 237.569 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1070/4776 | Loss: 196.407 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1080/4776 | Loss: 261.199 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1090/4776 | Loss: 208.655 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1100/4776 | Loss: 214.956 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1110/4776 | Loss: 182.723 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1120/4776 | Loss: 252.750 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1130/4776 | Loss: 224.882 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1140/4776 | Loss: 202.309 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1150/4776 | Loss: 215.068 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1160/4776 | Loss: 252.467 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1170/4776 | Loss: 214.089 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1180/4776 | Loss: 179.321 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1190/4776 | Loss: 189.052 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1200/4776 | Loss: 220.451 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1210/4776 | Loss: 223.979 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1220/4776 | Loss: 202.047 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1230/4776 | Loss: 187.523 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1240/4776 | Loss: 183.180 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1250/4776 | Loss: 171.634 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1260/4776 | Loss: 177.388 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 1270/4776 | Loss: 226.246 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1280/4776 | Loss: 279.818 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1290/4776 | Loss: 233.396 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1300/4776 | Loss: 201.275 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1310/4776 | Loss: 211.331 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1320/4776 | Loss: 183.626 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1330/4776 | Loss: 187.815 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1340/4776 | Loss: 175.894 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1350/4776 | Loss: 210.261 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1360/4776 | Loss: 208.108 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1370/4776 | Loss: 216.437 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1380/4776 | Loss: 254.627 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1390/4776 | Loss: 203.969 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1400/4776 | Loss: 197.168 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1410/4776 | Loss: 235.964 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1420/4776 | Loss: 164.853 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1430/4776 | Loss: 224.193 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1440/4776 | Loss: 246.667 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1450/4776 | Loss: 244.191 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1460/4776 | Loss: 215.991 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1470/4776 | Loss: 215.006 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1480/4776 | Loss: 234.457 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1490/4776 | Loss: 229.536 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1500/4776 | Loss: 167.857 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1510/4776 | Loss: 215.209 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1520/4776 | Loss: 189.096 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1530/4776 | Loss: 216.596 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1540/4776 | Loss: 243.620 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1550/4776 | Loss: 152.178 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 1560/4776 | Loss: 159.753 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1570/4776 | Loss: 199.931 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1580/4776 | Loss: 204.712 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1590/4776 | Loss: 177.794 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1600/4776 | Loss: 239.774 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1610/4776 | Loss: 232.190 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1620/4776 | Loss: 206.868 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1630/4776 | Loss: 191.674 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1640/4776 | Loss: 192.315 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1650/4776 | Loss: 241.770 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1660/4776 | Loss: 186.684 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1670/4776 | Loss: 227.531 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1680/4776 | Loss: 197.539 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1690/4776 | Loss: 199.709 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1700/4776 | Loss: 214.966 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1710/4776 | Loss: 225.626 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1720/4776 | Loss: 248.251 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1730/4776 | Loss: 212.440 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1740/4776 | Loss: 185.679 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1750/4776 | Loss: 218.135 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1760/4776 | Loss: 204.288 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1770/4776 | Loss: 241.365 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1780/4776 | Loss: 151.044 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1790/4776 | Loss: 144.057 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 1800/4776 | Loss: 160.211 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1810/4776 | Loss: 199.034 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1820/4776 | Loss: 163.887 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 1830/4776 | Loss: 235.148 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1840/4776 | Loss: 198.546 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1850/4776 | Loss: 187.984 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1860/4776 | Loss: 225.175 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1870/4776 | Loss: 223.941 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1880/4776 | Loss: 184.170 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 1890/4776 | Loss: 245.211 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1900/4776 | Loss: 183.067 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1910/4776 | Loss: 223.025 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1920/4776 | Loss: 199.438 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1930/4776 | Loss: 178.086 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1940/4776 | Loss: 285.471 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1950/4776 | Loss: 210.551 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1960/4776 | Loss: 227.484 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1970/4776 | Loss: 182.956 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1980/4776 | Loss: 238.922 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1990/4776 | Loss: 201.000 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2000/4776 | Loss: 223.929 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2010/4776 | Loss: 199.090 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2020/4776 | Loss: 234.491 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2030/4776 | Loss: 201.427 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2040/4776 | Loss: 148.000 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2050/4776 | Loss: 180.539 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2060/4776 | Loss: 220.883 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2070/4776 | Loss: 169.752 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2080/4776 | Loss: 229.856 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2090/4776 | Loss: 242.149 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2100/4776 | Loss: 229.131 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2110/4776 | Loss: 224.239 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2120/4776 | Loss: 219.463 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2130/4776 | Loss: 164.331 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2140/4776 | Loss: 195.747 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2150/4776 | Loss: 214.365 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2160/4776 | Loss: 213.827 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2170/4776 | Loss: 174.141 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2180/4776 | Loss: 221.318 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2190/4776 | Loss: 187.897 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2200/4776 | Loss: 201.440 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2210/4776 | Loss: 209.729 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2220/4776 | Loss: 247.077 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2230/4776 | Loss: 165.806 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2240/4776 | Loss: 228.953 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2250/4776 | Loss: 200.466 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2260/4776 | Loss: 183.392 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2270/4776 | Loss: 154.355 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2280/4776 | Loss: 207.199 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2290/4776 | Loss: 167.581 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2300/4776 | Loss: 198.654 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2310/4776 | Loss: 258.935 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2320/4776 | Loss: 228.044 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2330/4776 | Loss: 200.258 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2340/4776 | Loss: 229.501 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2350/4776 | Loss: 243.959 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2360/4776 | Loss: 206.301 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2370/4776 | Loss: 224.553 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2380/4776 | Loss: 181.784 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2390/4776 | Loss: 197.530 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2400/4776 | Loss: 199.979 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2410/4776 | Loss: 182.016 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2420/4776 | Loss: 218.285 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2430/4776 | Loss: 199.413 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2440/4776 | Loss: 207.420 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2450/4776 | Loss: 189.865 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2460/4776 | Loss: 220.221 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2470/4776 | Loss: 205.328 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2480/4776 | Loss: 240.752 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2490/4776 | Loss: 148.751 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2500/4776 | Loss: 209.103 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2510/4776 | Loss: 197.369 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2520/4776 | Loss: 233.760 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2530/4776 | Loss: 187.320 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2540/4776 | Loss: 245.973 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2550/4776 | Loss: 245.352 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2560/4776 | Loss: 177.675 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2570/4776 | Loss: 213.259 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2580/4776 | Loss: 196.915 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2590/4776 | Loss: 258.911 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2600/4776 | Loss: 234.608 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2610/4776 | Loss: 193.214 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2620/4776 | Loss: 208.432 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2630/4776 | Loss: 199.601 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2640/4776 | Loss: 252.888 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2650/4776 | Loss: 158.565 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 2660/4776 | Loss: 202.750 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2670/4776 | Loss: 193.677 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2680/4776 | Loss: 202.298 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2690/4776 | Loss: 209.764 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2700/4776 | Loss: 230.695 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2710/4776 | Loss: 225.845 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2720/4776 | Loss: 130.135 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2730/4776 | Loss: 216.496 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2740/4776 | Loss: 213.933 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2750/4776 | Loss: 211.338 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2760/4776 | Loss: 224.811 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2770/4776 | Loss: 189.249 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2780/4776 | Loss: 191.067 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2790/4776 | Loss: 293.362 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2800/4776 | Loss: 189.565 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2810/4776 | Loss: 216.192 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2820/4776 | Loss: 254.070 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2830/4776 | Loss: 195.595 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2840/4776 | Loss: 173.824 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 2850/4776 | Loss: 217.254 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2860/4776 | Loss: 213.660 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2870/4776 | Loss: 297.530 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2880/4776 | Loss: 233.057 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2890/4776 | Loss: 172.886 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 2900/4776 | Loss: 246.481 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2910/4776 | Loss: 169.922 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2920/4776 | Loss: 232.778 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2930/4776 | Loss: 257.777 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2940/4776 | Loss: 196.587 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 2950/4776 | Loss: 225.835 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2960/4776 | Loss: 249.747 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 2970/4776 | Loss: 212.692 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 2980/4776 | Loss: 191.854 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 2990/4776 | Loss: 199.995 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3000/4776 | Loss: 164.985 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 3010/4776 | Loss: 202.826 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3020/4776 | Loss: 172.925 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3030/4776 | Loss: 194.969 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3040/4776 | Loss: 174.572 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3050/4776 | Loss: 109.306 | Accuracy: 0.700\n",
      "[Epoch: 29/200] - Step: 3060/4776 | Loss: 208.204 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3070/4776 | Loss: 184.373 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3080/4776 | Loss: 193.147 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3090/4776 | Loss: 174.316 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 3100/4776 | Loss: 201.768 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3110/4776 | Loss: 197.202 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3120/4776 | Loss: 146.231 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 3130/4776 | Loss: 189.112 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3140/4776 | Loss: 230.319 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3150/4776 | Loss: 197.748 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3160/4776 | Loss: 270.350 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3170/4776 | Loss: 175.188 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3180/4776 | Loss: 202.075 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3190/4776 | Loss: 226.241 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3200/4776 | Loss: 210.210 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3210/4776 | Loss: 194.832 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3220/4776 | Loss: 207.830 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3230/4776 | Loss: 244.066 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3240/4776 | Loss: 161.025 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3250/4776 | Loss: 202.381 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3260/4776 | Loss: 231.638 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3270/4776 | Loss: 215.037 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3280/4776 | Loss: 200.457 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3290/4776 | Loss: 170.093 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3300/4776 | Loss: 177.396 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3310/4776 | Loss: 220.706 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3320/4776 | Loss: 204.245 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3330/4776 | Loss: 199.606 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3340/4776 | Loss: 197.122 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3350/4776 | Loss: 201.740 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3360/4776 | Loss: 181.867 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3370/4776 | Loss: 192.038 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3380/4776 | Loss: 243.733 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3390/4776 | Loss: 211.778 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3400/4776 | Loss: 184.433 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3410/4776 | Loss: 185.080 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3420/4776 | Loss: 226.280 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3430/4776 | Loss: 197.555 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3440/4776 | Loss: 207.398 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3450/4776 | Loss: 189.264 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3460/4776 | Loss: 199.895 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3470/4776 | Loss: 198.151 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3480/4776 | Loss: 221.012 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3490/4776 | Loss: 198.121 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3500/4776 | Loss: 256.649 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3510/4776 | Loss: 243.926 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3520/4776 | Loss: 202.501 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3530/4776 | Loss: 180.853 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 3540/4776 | Loss: 191.768 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3550/4776 | Loss: 195.462 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3560/4776 | Loss: 164.775 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3570/4776 | Loss: 233.002 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3580/4776 | Loss: 302.900 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3590/4776 | Loss: 192.981 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3600/4776 | Loss: 283.148 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3610/4776 | Loss: 313.494 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3620/4776 | Loss: 217.863 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3630/4776 | Loss: 255.765 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3640/4776 | Loss: 178.111 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 3650/4776 | Loss: 185.488 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3660/4776 | Loss: 185.547 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 3670/4776 | Loss: 223.887 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3680/4776 | Loss: 226.505 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3690/4776 | Loss: 195.156 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3700/4776 | Loss: 285.834 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3710/4776 | Loss: 185.133 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3720/4776 | Loss: 196.598 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3730/4776 | Loss: 201.363 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3740/4776 | Loss: 198.742 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3750/4776 | Loss: 190.125 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3760/4776 | Loss: 189.103 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3770/4776 | Loss: 297.205 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3780/4776 | Loss: 231.720 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3790/4776 | Loss: 227.122 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3800/4776 | Loss: 192.621 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3810/4776 | Loss: 171.011 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3820/4776 | Loss: 234.496 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3830/4776 | Loss: 216.647 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3840/4776 | Loss: 201.441 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3850/4776 | Loss: 270.511 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3860/4776 | Loss: 130.533 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 3870/4776 | Loss: 165.324 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 3880/4776 | Loss: 235.282 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3890/4776 | Loss: 206.039 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3900/4776 | Loss: 235.575 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 3910/4776 | Loss: 208.866 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 3920/4776 | Loss: 234.750 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3930/4776 | Loss: 196.864 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3940/4776 | Loss: 273.068 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 3950/4776 | Loss: 179.054 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3960/4776 | Loss: 209.405 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3970/4776 | Loss: 226.396 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 3980/4776 | Loss: 215.642 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 3990/4776 | Loss: 215.358 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4000/4776 | Loss: 217.869 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4010/4776 | Loss: 202.889 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4020/4776 | Loss: 188.395 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4030/4776 | Loss: 171.131 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 4040/4776 | Loss: 194.461 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4050/4776 | Loss: 218.710 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4060/4776 | Loss: 201.939 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4070/4776 | Loss: 169.281 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4080/4776 | Loss: 198.287 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4090/4776 | Loss: 172.696 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4100/4776 | Loss: 215.011 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4110/4776 | Loss: 194.772 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4120/4776 | Loss: 193.735 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4130/4776 | Loss: 143.485 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 4140/4776 | Loss: 283.738 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4150/4776 | Loss: 183.666 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4160/4776 | Loss: 186.239 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4170/4776 | Loss: 178.065 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4180/4776 | Loss: 216.722 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4190/4776 | Loss: 205.235 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4200/4776 | Loss: 212.414 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4210/4776 | Loss: 134.591 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 4220/4776 | Loss: 200.511 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4230/4776 | Loss: 193.185 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4240/4776 | Loss: 216.903 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4250/4776 | Loss: 150.478 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4260/4776 | Loss: 179.844 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4270/4776 | Loss: 235.370 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4280/4776 | Loss: 228.505 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4290/4776 | Loss: 234.516 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4300/4776 | Loss: 252.561 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4310/4776 | Loss: 188.095 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4320/4776 | Loss: 217.101 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4330/4776 | Loss: 261.196 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 4340/4776 | Loss: 234.588 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4350/4776 | Loss: 228.227 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4360/4776 | Loss: 195.308 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4370/4776 | Loss: 193.036 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4380/4776 | Loss: 193.504 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4390/4776 | Loss: 191.192 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4400/4776 | Loss: 194.038 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4410/4776 | Loss: 210.704 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4420/4776 | Loss: 197.781 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4430/4776 | Loss: 240.737 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4440/4776 | Loss: 175.871 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4450/4776 | Loss: 245.032 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4460/4776 | Loss: 203.663 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4470/4776 | Loss: 204.047 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4480/4776 | Loss: 200.099 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4490/4776 | Loss: 197.435 | Accuracy: 0.500\n",
      "[Epoch: 29/200] - Step: 4500/4776 | Loss: 304.516 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 4510/4776 | Loss: 199.038 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4520/4776 | Loss: 213.100 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4530/4776 | Loss: 166.535 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4540/4776 | Loss: 212.970 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4550/4776 | Loss: 202.520 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4560/4776 | Loss: 221.043 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4570/4776 | Loss: 189.389 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4580/4776 | Loss: 217.149 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4590/4776 | Loss: 168.298 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4600/4776 | Loss: 200.211 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4610/4776 | Loss: 147.050 | Accuracy: 0.600\n",
      "[Epoch: 29/200] - Step: 4620/4776 | Loss: 223.884 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4630/4776 | Loss: 242.358 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4640/4776 | Loss: 248.989 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4650/4776 | Loss: 187.950 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4660/4776 | Loss: 210.698 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4670/4776 | Loss: 231.738 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4680/4776 | Loss: 248.906 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4690/4776 | Loss: 180.922 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4700/4776 | Loss: 181.396 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4710/4776 | Loss: 197.245 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4720/4776 | Loss: 205.234 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 4730/4776 | Loss: 204.965 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 4740/4776 | Loss: 234.143 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4750/4776 | Loss: 192.456 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 4760/4776 | Loss: 230.068 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 4770/4776 | Loss: 179.333 | Accuracy: 0.200\n",
      "Accuracy:  0.16885245901639345\n",
      "[Epoch: 30/200] - Step: 10/4776 | Loss: 159.945 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 20/4776 | Loss: 207.940 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 30/4776 | Loss: 204.629 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 40/4776 | Loss: 244.022 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 50/4776 | Loss: 175.350 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 60/4776 | Loss: 220.171 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 70/4776 | Loss: 199.870 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 80/4776 | Loss: 179.498 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 90/4776 | Loss: 187.069 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 100/4776 | Loss: 199.618 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 110/4776 | Loss: 215.457 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 120/4776 | Loss: 174.145 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 130/4776 | Loss: 223.406 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 140/4776 | Loss: 217.342 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 150/4776 | Loss: 190.895 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 160/4776 | Loss: 196.053 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 170/4776 | Loss: 200.757 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 180/4776 | Loss: 218.140 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 190/4776 | Loss: 200.828 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 200/4776 | Loss: 215.901 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 210/4776 | Loss: 182.220 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 220/4776 | Loss: 159.791 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 230/4776 | Loss: 197.068 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 240/4776 | Loss: 237.528 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 250/4776 | Loss: 218.214 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 260/4776 | Loss: 234.520 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 270/4776 | Loss: 260.093 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 280/4776 | Loss: 193.692 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 290/4776 | Loss: 162.174 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 300/4776 | Loss: 229.938 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 310/4776 | Loss: 196.247 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 320/4776 | Loss: 196.765 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 330/4776 | Loss: 198.668 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 340/4776 | Loss: 204.203 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 350/4776 | Loss: 235.465 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 360/4776 | Loss: 172.594 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 370/4776 | Loss: 263.442 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 380/4776 | Loss: 157.182 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 390/4776 | Loss: 202.198 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 400/4776 | Loss: 170.468 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 410/4776 | Loss: 200.077 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 420/4776 | Loss: 197.037 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 430/4776 | Loss: 224.362 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 440/4776 | Loss: 210.207 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 450/4776 | Loss: 152.848 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 460/4776 | Loss: 184.696 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 470/4776 | Loss: 214.155 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 480/4776 | Loss: 235.342 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 490/4776 | Loss: 216.558 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 500/4776 | Loss: 229.194 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 510/4776 | Loss: 180.153 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 520/4776 | Loss: 230.338 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 530/4776 | Loss: 200.345 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 540/4776 | Loss: 180.945 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 550/4776 | Loss: 173.783 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 560/4776 | Loss: 225.443 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 570/4776 | Loss: 183.263 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 580/4776 | Loss: 219.651 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 590/4776 | Loss: 162.125 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 600/4776 | Loss: 164.500 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 610/4776 | Loss: 229.378 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 620/4776 | Loss: 246.498 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 630/4776 | Loss: 163.404 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 640/4776 | Loss: 176.420 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 650/4776 | Loss: 185.577 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 660/4776 | Loss: 178.624 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 670/4776 | Loss: 171.638 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 680/4776 | Loss: 187.726 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 690/4776 | Loss: 146.091 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 700/4776 | Loss: 223.599 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 710/4776 | Loss: 209.755 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 720/4776 | Loss: 206.612 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 730/4776 | Loss: 216.026 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 740/4776 | Loss: 219.005 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 750/4776 | Loss: 205.164 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 760/4776 | Loss: 195.649 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 770/4776 | Loss: 165.060 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 780/4776 | Loss: 150.152 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 790/4776 | Loss: 234.373 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 800/4776 | Loss: 161.295 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 810/4776 | Loss: 169.957 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 820/4776 | Loss: 164.643 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 830/4776 | Loss: 156.832 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 840/4776 | Loss: 199.252 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 850/4776 | Loss: 179.946 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 860/4776 | Loss: 222.722 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 870/4776 | Loss: 198.718 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 880/4776 | Loss: 195.276 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 890/4776 | Loss: 182.593 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 900/4776 | Loss: 160.719 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 910/4776 | Loss: 210.747 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 920/4776 | Loss: 239.730 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 930/4776 | Loss: 215.042 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 940/4776 | Loss: 229.336 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 950/4776 | Loss: 223.301 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 960/4776 | Loss: 199.190 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 970/4776 | Loss: 256.721 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 980/4776 | Loss: 229.830 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 990/4776 | Loss: 220.752 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1000/4776 | Loss: 239.374 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1010/4776 | Loss: 189.475 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1020/4776 | Loss: 167.609 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1030/4776 | Loss: 206.952 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1040/4776 | Loss: 212.996 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1050/4776 | Loss: 209.819 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1060/4776 | Loss: 186.490 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1070/4776 | Loss: 164.824 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1080/4776 | Loss: 154.473 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1090/4776 | Loss: 208.930 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1100/4776 | Loss: 203.157 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1110/4776 | Loss: 212.259 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1120/4776 | Loss: 142.415 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1130/4776 | Loss: 217.196 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1140/4776 | Loss: 198.948 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1150/4776 | Loss: 219.475 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1160/4776 | Loss: 204.186 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1170/4776 | Loss: 190.725 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1180/4776 | Loss: 224.751 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1190/4776 | Loss: 154.497 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1200/4776 | Loss: 247.565 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1210/4776 | Loss: 193.089 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1220/4776 | Loss: 189.908 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1230/4776 | Loss: 200.555 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1240/4776 | Loss: 234.065 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1250/4776 | Loss: 188.706 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1260/4776 | Loss: 224.776 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1270/4776 | Loss: 224.838 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1280/4776 | Loss: 224.229 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1290/4776 | Loss: 250.891 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1300/4776 | Loss: 214.923 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1310/4776 | Loss: 169.213 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1320/4776 | Loss: 230.158 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1330/4776 | Loss: 154.660 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1340/4776 | Loss: 315.811 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1350/4776 | Loss: 222.495 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1360/4776 | Loss: 212.274 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1370/4776 | Loss: 259.294 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1380/4776 | Loss: 204.042 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1390/4776 | Loss: 307.118 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1400/4776 | Loss: 199.822 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1410/4776 | Loss: 219.152 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1420/4776 | Loss: 218.848 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1430/4776 | Loss: 194.241 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1440/4776 | Loss: 235.928 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1450/4776 | Loss: 183.966 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1460/4776 | Loss: 200.215 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1470/4776 | Loss: 195.083 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1480/4776 | Loss: 193.822 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1490/4776 | Loss: 231.796 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1500/4776 | Loss: 187.920 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1510/4776 | Loss: 192.433 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1520/4776 | Loss: 213.562 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1530/4776 | Loss: 176.915 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1540/4776 | Loss: 137.730 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1550/4776 | Loss: 178.711 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1560/4776 | Loss: 170.144 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1570/4776 | Loss: 217.622 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1580/4776 | Loss: 224.012 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1590/4776 | Loss: 200.559 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1600/4776 | Loss: 213.242 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1610/4776 | Loss: 147.908 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1620/4776 | Loss: 194.940 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1630/4776 | Loss: 210.900 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1640/4776 | Loss: 171.765 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1650/4776 | Loss: 209.727 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1660/4776 | Loss: 199.392 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1670/4776 | Loss: 198.617 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1680/4776 | Loss: 187.520 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1690/4776 | Loss: 193.376 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1700/4776 | Loss: 199.127 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1710/4776 | Loss: 187.828 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1720/4776 | Loss: 195.021 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1730/4776 | Loss: 213.157 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1740/4776 | Loss: 256.235 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1750/4776 | Loss: 160.526 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 1760/4776 | Loss: 191.665 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1770/4776 | Loss: 199.630 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1780/4776 | Loss: 196.520 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1790/4776 | Loss: 196.972 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1800/4776 | Loss: 260.805 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1810/4776 | Loss: 236.076 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1820/4776 | Loss: 182.259 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1830/4776 | Loss: 197.133 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1840/4776 | Loss: 221.167 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1850/4776 | Loss: 205.938 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1860/4776 | Loss: 199.278 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1870/4776 | Loss: 231.225 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1880/4776 | Loss: 197.604 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1890/4776 | Loss: 200.047 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1900/4776 | Loss: 182.804 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1910/4776 | Loss: 221.040 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1920/4776 | Loss: 220.260 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1930/4776 | Loss: 225.915 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1940/4776 | Loss: 154.360 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1950/4776 | Loss: 217.105 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 1960/4776 | Loss: 221.045 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1970/4776 | Loss: 214.266 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1980/4776 | Loss: 179.982 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1990/4776 | Loss: 170.324 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2000/4776 | Loss: 209.530 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2010/4776 | Loss: 229.680 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2020/4776 | Loss: 219.978 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2030/4776 | Loss: 213.429 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2040/4776 | Loss: 189.733 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2050/4776 | Loss: 200.198 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2060/4776 | Loss: 221.581 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2070/4776 | Loss: 220.492 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2080/4776 | Loss: 232.093 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2090/4776 | Loss: 168.261 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2100/4776 | Loss: 207.586 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2110/4776 | Loss: 150.720 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2120/4776 | Loss: 184.461 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2130/4776 | Loss: 184.810 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2140/4776 | Loss: 239.950 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2150/4776 | Loss: 192.272 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2160/4776 | Loss: 214.689 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2170/4776 | Loss: 195.155 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2180/4776 | Loss: 114.004 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2190/4776 | Loss: 207.362 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2200/4776 | Loss: 195.638 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2210/4776 | Loss: 247.895 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2220/4776 | Loss: 184.921 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2230/4776 | Loss: 130.573 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2240/4776 | Loss: 237.290 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2250/4776 | Loss: 190.527 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2260/4776 | Loss: 169.967 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2270/4776 | Loss: 205.234 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2280/4776 | Loss: 177.792 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2290/4776 | Loss: 187.889 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2300/4776 | Loss: 201.129 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2310/4776 | Loss: 252.506 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2320/4776 | Loss: 175.903 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2330/4776 | Loss: 196.829 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 2340/4776 | Loss: 233.721 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2350/4776 | Loss: 156.596 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2360/4776 | Loss: 176.590 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2370/4776 | Loss: 200.258 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2380/4776 | Loss: 192.936 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2390/4776 | Loss: 221.266 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2400/4776 | Loss: 154.001 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2410/4776 | Loss: 246.992 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2420/4776 | Loss: 145.622 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2430/4776 | Loss: 209.378 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2440/4776 | Loss: 208.466 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2450/4776 | Loss: 196.452 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2460/4776 | Loss: 225.304 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2470/4776 | Loss: 173.288 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2480/4776 | Loss: 196.243 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2490/4776 | Loss: 214.963 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2500/4776 | Loss: 196.107 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2510/4776 | Loss: 211.321 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2520/4776 | Loss: 193.726 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2530/4776 | Loss: 180.260 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2540/4776 | Loss: 159.891 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2550/4776 | Loss: 170.985 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2560/4776 | Loss: 188.509 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2570/4776 | Loss: 202.933 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2580/4776 | Loss: 170.574 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2590/4776 | Loss: 271.119 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2600/4776 | Loss: 243.708 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2610/4776 | Loss: 222.733 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2620/4776 | Loss: 192.044 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2630/4776 | Loss: 216.425 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2640/4776 | Loss: 178.227 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2650/4776 | Loss: 200.432 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2660/4776 | Loss: 185.146 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 2670/4776 | Loss: 204.619 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2680/4776 | Loss: 209.552 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2690/4776 | Loss: 168.800 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2700/4776 | Loss: 167.700 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2710/4776 | Loss: 197.814 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2720/4776 | Loss: 230.872 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2730/4776 | Loss: 186.294 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2740/4776 | Loss: 176.717 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2750/4776 | Loss: 274.652 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 2760/4776 | Loss: 174.565 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2770/4776 | Loss: 216.920 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2780/4776 | Loss: 183.908 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2790/4776 | Loss: 139.868 | Accuracy: 0.700\n",
      "[Epoch: 30/200] - Step: 2800/4776 | Loss: 219.077 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2810/4776 | Loss: 159.976 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2820/4776 | Loss: 218.608 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2830/4776 | Loss: 164.817 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2840/4776 | Loss: 145.473 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 2850/4776 | Loss: 212.045 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 2860/4776 | Loss: 215.749 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2870/4776 | Loss: 230.883 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2880/4776 | Loss: 203.284 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2890/4776 | Loss: 179.158 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2900/4776 | Loss: 191.901 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2910/4776 | Loss: 255.319 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2920/4776 | Loss: 154.552 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 2930/4776 | Loss: 198.086 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2940/4776 | Loss: 184.106 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2950/4776 | Loss: 221.572 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 2960/4776 | Loss: 240.304 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 2970/4776 | Loss: 172.318 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 2980/4776 | Loss: 195.932 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 2990/4776 | Loss: 173.825 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3000/4776 | Loss: 243.981 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3010/4776 | Loss: 208.320 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3020/4776 | Loss: 185.199 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3030/4776 | Loss: 152.193 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3040/4776 | Loss: 164.704 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3050/4776 | Loss: 229.664 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3060/4776 | Loss: 213.822 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3070/4776 | Loss: 195.481 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3080/4776 | Loss: 183.131 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3090/4776 | Loss: 190.433 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3100/4776 | Loss: 211.333 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3110/4776 | Loss: 238.143 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 3120/4776 | Loss: 196.699 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3130/4776 | Loss: 144.646 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3140/4776 | Loss: 182.163 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3150/4776 | Loss: 193.943 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3160/4776 | Loss: 185.582 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3170/4776 | Loss: 210.085 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3180/4776 | Loss: 189.876 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3190/4776 | Loss: 208.099 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3200/4776 | Loss: 271.341 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3210/4776 | Loss: 177.495 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3220/4776 | Loss: 223.053 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3230/4776 | Loss: 204.348 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3240/4776 | Loss: 175.368 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3250/4776 | Loss: 183.017 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3260/4776 | Loss: 198.124 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3270/4776 | Loss: 185.777 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3280/4776 | Loss: 210.455 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 3290/4776 | Loss: 213.619 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3300/4776 | Loss: 179.646 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3310/4776 | Loss: 212.960 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3320/4776 | Loss: 192.238 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3330/4776 | Loss: 197.643 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3340/4776 | Loss: 187.143 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3350/4776 | Loss: 182.378 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3360/4776 | Loss: 169.791 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3370/4776 | Loss: 221.027 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3380/4776 | Loss: 196.763 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3390/4776 | Loss: 250.023 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 3400/4776 | Loss: 241.185 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 3410/4776 | Loss: 258.401 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3420/4776 | Loss: 213.902 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3430/4776 | Loss: 209.359 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3440/4776 | Loss: 167.799 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3450/4776 | Loss: 188.720 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3460/4776 | Loss: 182.203 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3470/4776 | Loss: 214.859 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3480/4776 | Loss: 209.551 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3490/4776 | Loss: 166.780 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3500/4776 | Loss: 211.025 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3510/4776 | Loss: 255.347 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3520/4776 | Loss: 222.920 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3530/4776 | Loss: 195.360 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3540/4776 | Loss: 182.063 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3550/4776 | Loss: 247.973 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3560/4776 | Loss: 208.716 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3570/4776 | Loss: 151.147 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3580/4776 | Loss: 202.913 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3590/4776 | Loss: 146.556 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3600/4776 | Loss: 225.760 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3610/4776 | Loss: 179.170 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3620/4776 | Loss: 215.613 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3630/4776 | Loss: 206.838 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3640/4776 | Loss: 155.791 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3650/4776 | Loss: 197.857 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3660/4776 | Loss: 214.255 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3670/4776 | Loss: 155.120 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3680/4776 | Loss: 188.855 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3690/4776 | Loss: 276.751 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3700/4776 | Loss: 172.613 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3710/4776 | Loss: 187.891 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3720/4776 | Loss: 197.475 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3730/4776 | Loss: 156.684 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3740/4776 | Loss: 207.935 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3750/4776 | Loss: 209.766 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3760/4776 | Loss: 151.164 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3770/4776 | Loss: 184.875 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3780/4776 | Loss: 216.090 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3790/4776 | Loss: 197.301 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3800/4776 | Loss: 175.377 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3810/4776 | Loss: 195.580 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3820/4776 | Loss: 175.019 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3830/4776 | Loss: 172.256 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3840/4776 | Loss: 207.540 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 3850/4776 | Loss: 208.218 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3860/4776 | Loss: 174.901 | Accuracy: 0.700\n",
      "[Epoch: 30/200] - Step: 3870/4776 | Loss: 162.550 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3880/4776 | Loss: 175.555 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3890/4776 | Loss: 178.329 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3900/4776 | Loss: 222.915 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3910/4776 | Loss: 168.125 | Accuracy: 0.700\n",
      "[Epoch: 30/200] - Step: 3920/4776 | Loss: 176.455 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 3930/4776 | Loss: 244.139 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 3940/4776 | Loss: 175.837 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3950/4776 | Loss: 233.606 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 3960/4776 | Loss: 186.946 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3970/4776 | Loss: 179.260 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 3980/4776 | Loss: 241.506 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 3990/4776 | Loss: 175.600 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4000/4776 | Loss: 232.364 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4010/4776 | Loss: 218.360 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4020/4776 | Loss: 193.341 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 4030/4776 | Loss: 206.088 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 4040/4776 | Loss: 164.276 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4050/4776 | Loss: 163.617 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4060/4776 | Loss: 222.664 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4070/4776 | Loss: 285.327 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4080/4776 | Loss: 225.978 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4090/4776 | Loss: 181.110 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4100/4776 | Loss: 202.655 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4110/4776 | Loss: 201.607 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4120/4776 | Loss: 213.613 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4130/4776 | Loss: 224.500 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4140/4776 | Loss: 158.298 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4150/4776 | Loss: 194.657 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4160/4776 | Loss: 171.828 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4170/4776 | Loss: 200.826 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4180/4776 | Loss: 174.679 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 4190/4776 | Loss: 254.718 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4200/4776 | Loss: 205.106 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4210/4776 | Loss: 168.736 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4220/4776 | Loss: 213.224 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4230/4776 | Loss: 238.827 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4240/4776 | Loss: 190.039 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 4250/4776 | Loss: 186.742 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4260/4776 | Loss: 170.829 | Accuracy: 0.600\n",
      "[Epoch: 30/200] - Step: 4270/4776 | Loss: 246.167 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4280/4776 | Loss: 191.534 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4290/4776 | Loss: 227.314 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4300/4776 | Loss: 200.175 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4310/4776 | Loss: 187.109 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4320/4776 | Loss: 187.029 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4330/4776 | Loss: 159.206 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4340/4776 | Loss: 190.306 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4350/4776 | Loss: 174.863 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 4360/4776 | Loss: 177.503 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4370/4776 | Loss: 170.639 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4380/4776 | Loss: 138.856 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4390/4776 | Loss: 178.029 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 4400/4776 | Loss: 198.241 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4410/4776 | Loss: 188.253 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4420/4776 | Loss: 202.801 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4430/4776 | Loss: 177.590 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4440/4776 | Loss: 227.159 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4450/4776 | Loss: 218.339 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 4460/4776 | Loss: 192.758 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4470/4776 | Loss: 196.520 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4480/4776 | Loss: 230.921 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4490/4776 | Loss: 196.060 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4500/4776 | Loss: 180.510 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4510/4776 | Loss: 193.701 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4520/4776 | Loss: 182.666 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4530/4776 | Loss: 188.722 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4540/4776 | Loss: 199.634 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4550/4776 | Loss: 236.076 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4560/4776 | Loss: 197.636 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4570/4776 | Loss: 202.454 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4580/4776 | Loss: 218.776 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4590/4776 | Loss: 197.006 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4600/4776 | Loss: 200.884 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4610/4776 | Loss: 227.036 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4620/4776 | Loss: 259.752 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 4630/4776 | Loss: 217.404 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4640/4776 | Loss: 164.319 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4650/4776 | Loss: 208.827 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4660/4776 | Loss: 225.434 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4670/4776 | Loss: 190.933 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 4680/4776 | Loss: 197.998 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4690/4776 | Loss: 190.843 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4700/4776 | Loss: 184.398 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4710/4776 | Loss: 194.229 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4720/4776 | Loss: 177.990 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4730/4776 | Loss: 181.452 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 4740/4776 | Loss: 179.299 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 4750/4776 | Loss: 189.659 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4760/4776 | Loss: 202.170 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 4770/4776 | Loss: 181.356 | Accuracy: 0.300\n",
      "Accuracy:  0.1557377049180328\n",
      "[Epoch: 31/200] - Step: 10/4776 | Loss: 168.584 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 20/4776 | Loss: 184.638 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 30/4776 | Loss: 178.636 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 40/4776 | Loss: 177.138 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 50/4776 | Loss: 174.481 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 60/4776 | Loss: 203.689 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 70/4776 | Loss: 142.329 | Accuracy: 0.700\n",
      "[Epoch: 31/200] - Step: 80/4776 | Loss: 206.554 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 90/4776 | Loss: 199.750 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 100/4776 | Loss: 140.894 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 110/4776 | Loss: 256.877 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 120/4776 | Loss: 227.220 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 130/4776 | Loss: 193.352 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 140/4776 | Loss: 233.110 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 150/4776 | Loss: 150.430 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 160/4776 | Loss: 212.884 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 170/4776 | Loss: 134.904 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 180/4776 | Loss: 138.888 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 190/4776 | Loss: 168.121 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 200/4776 | Loss: 190.820 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 210/4776 | Loss: 192.114 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 220/4776 | Loss: 127.797 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 230/4776 | Loss: 171.823 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 240/4776 | Loss: 265.826 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 250/4776 | Loss: 205.471 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 260/4776 | Loss: 250.453 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 270/4776 | Loss: 205.027 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 280/4776 | Loss: 183.042 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 290/4776 | Loss: 176.029 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 300/4776 | Loss: 178.419 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 310/4776 | Loss: 215.418 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 320/4776 | Loss: 243.170 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 330/4776 | Loss: 206.721 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 340/4776 | Loss: 187.902 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 350/4776 | Loss: 188.469 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 360/4776 | Loss: 168.299 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 370/4776 | Loss: 212.027 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 380/4776 | Loss: 240.458 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 390/4776 | Loss: 190.368 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 400/4776 | Loss: 145.112 | Accuracy: 0.700\n",
      "[Epoch: 31/200] - Step: 410/4776 | Loss: 187.995 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 420/4776 | Loss: 233.496 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 430/4776 | Loss: 167.217 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 440/4776 | Loss: 170.588 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 450/4776 | Loss: 184.624 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 460/4776 | Loss: 173.218 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 470/4776 | Loss: 168.274 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 480/4776 | Loss: 259.757 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 490/4776 | Loss: 226.868 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 500/4776 | Loss: 171.737 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 510/4776 | Loss: 243.845 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 520/4776 | Loss: 204.209 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 530/4776 | Loss: 204.346 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 540/4776 | Loss: 162.784 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 550/4776 | Loss: 192.772 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 560/4776 | Loss: 216.053 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 570/4776 | Loss: 180.918 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 580/4776 | Loss: 185.904 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 590/4776 | Loss: 207.618 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 600/4776 | Loss: 178.460 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 610/4776 | Loss: 193.625 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 620/4776 | Loss: 169.901 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 630/4776 | Loss: 185.018 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 640/4776 | Loss: 212.043 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 650/4776 | Loss: 179.630 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 660/4776 | Loss: 194.762 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 670/4776 | Loss: 176.356 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 680/4776 | Loss: 207.804 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 690/4776 | Loss: 212.586 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 700/4776 | Loss: 180.401 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 710/4776 | Loss: 187.269 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 720/4776 | Loss: 163.268 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 730/4776 | Loss: 145.042 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 740/4776 | Loss: 222.348 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 750/4776 | Loss: 155.930 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 760/4776 | Loss: 196.367 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 770/4776 | Loss: 204.152 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 780/4776 | Loss: 174.711 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 790/4776 | Loss: 267.021 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 800/4776 | Loss: 210.509 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 810/4776 | Loss: 201.052 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 820/4776 | Loss: 208.309 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 830/4776 | Loss: 241.348 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 840/4776 | Loss: 214.014 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 850/4776 | Loss: 202.770 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 860/4776 | Loss: 194.434 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 870/4776 | Loss: 228.581 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 880/4776 | Loss: 176.712 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 890/4776 | Loss: 180.955 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 900/4776 | Loss: 160.824 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 910/4776 | Loss: 214.736 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 920/4776 | Loss: 122.798 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 930/4776 | Loss: 209.554 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 940/4776 | Loss: 177.371 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 950/4776 | Loss: 188.284 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 960/4776 | Loss: 217.061 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 970/4776 | Loss: 217.372 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 980/4776 | Loss: 219.663 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 990/4776 | Loss: 212.497 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1000/4776 | Loss: 187.818 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1010/4776 | Loss: 178.609 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1020/4776 | Loss: 140.712 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1030/4776 | Loss: 202.113 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1040/4776 | Loss: 229.734 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1050/4776 | Loss: 212.049 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1060/4776 | Loss: 135.213 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1070/4776 | Loss: 165.132 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1080/4776 | Loss: 207.018 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1090/4776 | Loss: 202.539 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1100/4776 | Loss: 207.172 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1110/4776 | Loss: 185.862 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1120/4776 | Loss: 183.853 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1130/4776 | Loss: 199.945 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1140/4776 | Loss: 180.833 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1150/4776 | Loss: 152.623 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1160/4776 | Loss: 203.702 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1170/4776 | Loss: 257.999 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1180/4776 | Loss: 180.130 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1190/4776 | Loss: 162.287 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1200/4776 | Loss: 212.804 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1210/4776 | Loss: 254.944 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1220/4776 | Loss: 197.219 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1230/4776 | Loss: 135.587 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 1240/4776 | Loss: 189.268 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1250/4776 | Loss: 143.128 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1260/4776 | Loss: 186.533 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1270/4776 | Loss: 137.509 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1280/4776 | Loss: 201.463 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1290/4776 | Loss: 162.755 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1300/4776 | Loss: 246.360 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1310/4776 | Loss: 145.536 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1320/4776 | Loss: 259.492 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1330/4776 | Loss: 212.381 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1340/4776 | Loss: 178.732 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1350/4776 | Loss: 207.399 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1360/4776 | Loss: 175.869 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1370/4776 | Loss: 227.436 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1380/4776 | Loss: 164.083 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1390/4776 | Loss: 201.539 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1400/4776 | Loss: 236.044 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1410/4776 | Loss: 176.259 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1420/4776 | Loss: 234.860 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1430/4776 | Loss: 191.275 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1440/4776 | Loss: 228.297 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1450/4776 | Loss: 214.939 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1460/4776 | Loss: 159.723 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1470/4776 | Loss: 194.271 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1480/4776 | Loss: 196.544 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1490/4776 | Loss: 161.481 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1500/4776 | Loss: 165.671 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1510/4776 | Loss: 230.386 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1520/4776 | Loss: 215.973 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1530/4776 | Loss: 168.317 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1540/4776 | Loss: 157.472 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1550/4776 | Loss: 193.633 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1560/4776 | Loss: 190.005 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1570/4776 | Loss: 219.628 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1580/4776 | Loss: 199.741 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1590/4776 | Loss: 174.997 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1600/4776 | Loss: 235.421 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1610/4776 | Loss: 182.070 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1620/4776 | Loss: 161.118 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1630/4776 | Loss: 178.890 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1640/4776 | Loss: 185.122 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1650/4776 | Loss: 215.061 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1660/4776 | Loss: 185.014 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1670/4776 | Loss: 245.842 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1680/4776 | Loss: 240.652 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1690/4776 | Loss: 192.583 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1700/4776 | Loss: 181.692 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1710/4776 | Loss: 191.863 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1720/4776 | Loss: 199.588 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1730/4776 | Loss: 167.004 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1740/4776 | Loss: 198.938 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1750/4776 | Loss: 202.366 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1760/4776 | Loss: 173.307 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1770/4776 | Loss: 199.199 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1780/4776 | Loss: 187.502 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1790/4776 | Loss: 175.536 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1800/4776 | Loss: 191.063 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1810/4776 | Loss: 177.959 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1820/4776 | Loss: 206.783 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1830/4776 | Loss: 136.222 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1840/4776 | Loss: 206.618 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1850/4776 | Loss: 164.553 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1860/4776 | Loss: 194.852 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1870/4776 | Loss: 161.154 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1880/4776 | Loss: 207.599 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1890/4776 | Loss: 207.534 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1900/4776 | Loss: 216.394 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1910/4776 | Loss: 174.108 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1920/4776 | Loss: 193.204 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1930/4776 | Loss: 164.354 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 1940/4776 | Loss: 206.679 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1950/4776 | Loss: 231.296 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1960/4776 | Loss: 168.599 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1970/4776 | Loss: 173.267 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1980/4776 | Loss: 138.559 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 1990/4776 | Loss: 166.284 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2000/4776 | Loss: 189.878 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2010/4776 | Loss: 229.899 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2020/4776 | Loss: 202.959 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2030/4776 | Loss: 208.819 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2040/4776 | Loss: 170.920 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2050/4776 | Loss: 208.571 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2060/4776 | Loss: 202.953 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2070/4776 | Loss: 206.355 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2080/4776 | Loss: 187.438 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2090/4776 | Loss: 182.497 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2100/4776 | Loss: 169.814 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2110/4776 | Loss: 204.010 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2120/4776 | Loss: 171.259 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2130/4776 | Loss: 231.361 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2140/4776 | Loss: 197.354 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2150/4776 | Loss: 160.755 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2160/4776 | Loss: 181.444 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2170/4776 | Loss: 155.992 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2180/4776 | Loss: 161.242 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2190/4776 | Loss: 259.700 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2200/4776 | Loss: 271.759 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2210/4776 | Loss: 186.115 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2220/4776 | Loss: 268.688 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2230/4776 | Loss: 180.662 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2240/4776 | Loss: 146.225 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2250/4776 | Loss: 190.274 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2260/4776 | Loss: 164.482 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2270/4776 | Loss: 156.487 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2280/4776 | Loss: 178.513 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2290/4776 | Loss: 166.790 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2300/4776 | Loss: 165.202 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2310/4776 | Loss: 223.083 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2320/4776 | Loss: 168.742 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2330/4776 | Loss: 184.362 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2340/4776 | Loss: 150.494 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2350/4776 | Loss: 157.845 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2360/4776 | Loss: 184.693 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2370/4776 | Loss: 200.906 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2380/4776 | Loss: 211.111 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2390/4776 | Loss: 220.814 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2400/4776 | Loss: 213.115 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2410/4776 | Loss: 175.193 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2420/4776 | Loss: 240.398 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2430/4776 | Loss: 194.552 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2440/4776 | Loss: 217.186 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2450/4776 | Loss: 214.840 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2460/4776 | Loss: 195.459 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2470/4776 | Loss: 182.220 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2480/4776 | Loss: 191.863 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2490/4776 | Loss: 203.720 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2500/4776 | Loss: 181.000 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2510/4776 | Loss: 173.410 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2520/4776 | Loss: 228.488 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2530/4776 | Loss: 176.003 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2540/4776 | Loss: 210.860 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2550/4776 | Loss: 182.092 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2560/4776 | Loss: 170.393 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2570/4776 | Loss: 262.998 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2580/4776 | Loss: 224.390 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2590/4776 | Loss: 185.477 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2600/4776 | Loss: 276.111 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2610/4776 | Loss: 233.084 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2620/4776 | Loss: 173.202 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2630/4776 | Loss: 207.188 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2640/4776 | Loss: 177.904 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2650/4776 | Loss: 216.906 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2660/4776 | Loss: 175.647 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2670/4776 | Loss: 216.369 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2680/4776 | Loss: 179.668 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2690/4776 | Loss: 180.502 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2700/4776 | Loss: 214.942 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2710/4776 | Loss: 150.437 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2720/4776 | Loss: 117.931 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 2730/4776 | Loss: 185.076 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2740/4776 | Loss: 204.485 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2750/4776 | Loss: 182.607 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2760/4776 | Loss: 173.467 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2770/4776 | Loss: 175.708 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2780/4776 | Loss: 184.945 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2790/4776 | Loss: 118.147 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 2800/4776 | Loss: 213.406 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2810/4776 | Loss: 185.206 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2820/4776 | Loss: 216.564 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2830/4776 | Loss: 181.974 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2840/4776 | Loss: 177.735 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2850/4776 | Loss: 180.404 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2860/4776 | Loss: 206.103 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2870/4776 | Loss: 206.259 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 2880/4776 | Loss: 156.398 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 2890/4776 | Loss: 198.560 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2900/4776 | Loss: 249.938 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 2910/4776 | Loss: 184.876 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2920/4776 | Loss: 208.626 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2930/4776 | Loss: 170.520 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2940/4776 | Loss: 178.384 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 2950/4776 | Loss: 158.885 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 2960/4776 | Loss: 139.377 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 2970/4776 | Loss: 202.571 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 2980/4776 | Loss: 166.920 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 2990/4776 | Loss: 179.359 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3000/4776 | Loss: 149.939 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3010/4776 | Loss: 186.271 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3020/4776 | Loss: 186.816 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3030/4776 | Loss: 184.978 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3040/4776 | Loss: 196.709 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3050/4776 | Loss: 179.440 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3060/4776 | Loss: 214.343 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3070/4776 | Loss: 187.568 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3080/4776 | Loss: 128.556 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3090/4776 | Loss: 256.488 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3100/4776 | Loss: 140.408 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3110/4776 | Loss: 182.911 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3120/4776 | Loss: 164.409 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3130/4776 | Loss: 203.618 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3140/4776 | Loss: 226.872 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3150/4776 | Loss: 254.996 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3160/4776 | Loss: 172.523 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3170/4776 | Loss: 208.810 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3180/4776 | Loss: 243.032 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3190/4776 | Loss: 205.492 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3200/4776 | Loss: 213.453 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3210/4776 | Loss: 184.827 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3220/4776 | Loss: 173.634 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3230/4776 | Loss: 179.102 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3240/4776 | Loss: 210.765 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3250/4776 | Loss: 197.964 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3260/4776 | Loss: 168.280 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3270/4776 | Loss: 210.596 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3280/4776 | Loss: 191.434 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3290/4776 | Loss: 182.066 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3300/4776 | Loss: 171.530 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3310/4776 | Loss: 204.182 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3320/4776 | Loss: 171.933 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3330/4776 | Loss: 202.678 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3340/4776 | Loss: 174.626 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3350/4776 | Loss: 201.062 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3360/4776 | Loss: 187.477 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3370/4776 | Loss: 175.798 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3380/4776 | Loss: 167.613 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3390/4776 | Loss: 199.758 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3400/4776 | Loss: 178.948 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3410/4776 | Loss: 220.012 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3420/4776 | Loss: 209.807 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3430/4776 | Loss: 157.179 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3440/4776 | Loss: 204.196 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3450/4776 | Loss: 162.655 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3460/4776 | Loss: 204.492 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3470/4776 | Loss: 209.372 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3480/4776 | Loss: 166.180 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3490/4776 | Loss: 171.345 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3500/4776 | Loss: 214.846 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3510/4776 | Loss: 179.125 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3520/4776 | Loss: 208.666 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3530/4776 | Loss: 193.440 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3540/4776 | Loss: 211.442 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3550/4776 | Loss: 208.414 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3560/4776 | Loss: 178.684 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3570/4776 | Loss: 207.130 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3580/4776 | Loss: 210.409 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3590/4776 | Loss: 174.203 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3600/4776 | Loss: 237.531 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3610/4776 | Loss: 210.148 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3620/4776 | Loss: 152.516 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3630/4776 | Loss: 187.054 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3640/4776 | Loss: 237.774 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3650/4776 | Loss: 217.804 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3660/4776 | Loss: 207.727 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3670/4776 | Loss: 246.231 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 3680/4776 | Loss: 166.804 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3690/4776 | Loss: 172.442 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3700/4776 | Loss: 179.554 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3710/4776 | Loss: 222.066 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3720/4776 | Loss: 183.442 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 3730/4776 | Loss: 203.928 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3740/4776 | Loss: 141.524 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 3750/4776 | Loss: 212.875 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3760/4776 | Loss: 182.867 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3770/4776 | Loss: 168.319 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3780/4776 | Loss: 175.973 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3790/4776 | Loss: 227.822 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3800/4776 | Loss: 195.770 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3810/4776 | Loss: 157.519 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3820/4776 | Loss: 217.312 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3830/4776 | Loss: 155.764 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3840/4776 | Loss: 219.197 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3850/4776 | Loss: 196.868 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3860/4776 | Loss: 185.579 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3870/4776 | Loss: 206.759 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3880/4776 | Loss: 214.242 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3890/4776 | Loss: 192.870 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3900/4776 | Loss: 180.779 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3910/4776 | Loss: 175.430 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 3920/4776 | Loss: 151.499 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3930/4776 | Loss: 222.993 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 3940/4776 | Loss: 165.558 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3950/4776 | Loss: 167.089 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3960/4776 | Loss: 193.722 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 3970/4776 | Loss: 202.149 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3980/4776 | Loss: 201.780 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 3990/4776 | Loss: 172.313 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4000/4776 | Loss: 185.218 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4010/4776 | Loss: 229.351 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4020/4776 | Loss: 166.263 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4030/4776 | Loss: 196.112 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4040/4776 | Loss: 176.177 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4050/4776 | Loss: 220.548 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4060/4776 | Loss: 206.156 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4070/4776 | Loss: 151.385 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4080/4776 | Loss: 140.738 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4090/4776 | Loss: 163.197 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4100/4776 | Loss: 117.999 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4110/4776 | Loss: 177.661 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4120/4776 | Loss: 158.677 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4130/4776 | Loss: 192.993 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4140/4776 | Loss: 168.149 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4150/4776 | Loss: 198.885 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4160/4776 | Loss: 280.918 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4170/4776 | Loss: 192.053 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4180/4776 | Loss: 198.538 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4190/4776 | Loss: 217.868 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 4200/4776 | Loss: 226.243 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4210/4776 | Loss: 210.906 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4220/4776 | Loss: 204.132 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4230/4776 | Loss: 239.397 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4240/4776 | Loss: 192.075 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4250/4776 | Loss: 170.729 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4260/4776 | Loss: 222.520 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4270/4776 | Loss: 225.998 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4280/4776 | Loss: 210.409 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4290/4776 | Loss: 184.488 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4300/4776 | Loss: 167.024 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 4310/4776 | Loss: 175.484 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4320/4776 | Loss: 255.270 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 4330/4776 | Loss: 178.049 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4340/4776 | Loss: 189.264 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4350/4776 | Loss: 151.460 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4360/4776 | Loss: 211.938 | Accuracy: 0.700\n",
      "[Epoch: 31/200] - Step: 4370/4776 | Loss: 169.075 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4380/4776 | Loss: 243.100 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4390/4776 | Loss: 202.549 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4400/4776 | Loss: 179.371 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4410/4776 | Loss: 204.056 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4420/4776 | Loss: 216.719 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4430/4776 | Loss: 166.447 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4440/4776 | Loss: 175.947 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4450/4776 | Loss: 182.771 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4460/4776 | Loss: 200.587 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 4470/4776 | Loss: 223.889 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4480/4776 | Loss: 184.826 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4490/4776 | Loss: 246.984 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4500/4776 | Loss: 153.951 | Accuracy: 0.600\n",
      "[Epoch: 31/200] - Step: 4510/4776 | Loss: 229.677 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4520/4776 | Loss: 200.273 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4530/4776 | Loss: 201.141 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4540/4776 | Loss: 169.110 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4550/4776 | Loss: 202.490 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4560/4776 | Loss: 196.077 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4570/4776 | Loss: 230.627 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4580/4776 | Loss: 212.314 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4590/4776 | Loss: 222.396 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4600/4776 | Loss: 193.460 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4610/4776 | Loss: 174.172 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4620/4776 | Loss: 212.711 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4630/4776 | Loss: 267.200 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 4640/4776 | Loss: 156.023 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4650/4776 | Loss: 198.593 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 4660/4776 | Loss: 216.264 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4670/4776 | Loss: 225.166 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4680/4776 | Loss: 203.717 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4690/4776 | Loss: 181.450 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4700/4776 | Loss: 226.064 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4710/4776 | Loss: 199.835 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 4720/4776 | Loss: 206.000 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4730/4776 | Loss: 223.551 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 4740/4776 | Loss: 161.536 | Accuracy: 0.500\n",
      "[Epoch: 31/200] - Step: 4750/4776 | Loss: 208.696 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 4760/4776 | Loss: 185.375 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 4770/4776 | Loss: 191.115 | Accuracy: 0.400\n",
      "Accuracy:  0.18032786885245902\n",
      "[Epoch: 32/200] - Step: 10/4776 | Loss: 174.158 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 20/4776 | Loss: 190.185 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 30/4776 | Loss: 163.766 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 40/4776 | Loss: 260.570 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 50/4776 | Loss: 149.424 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 60/4776 | Loss: 186.845 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 70/4776 | Loss: 174.348 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 80/4776 | Loss: 183.086 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 90/4776 | Loss: 192.542 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 100/4776 | Loss: 237.415 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 110/4776 | Loss: 176.641 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 120/4776 | Loss: 186.051 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 130/4776 | Loss: 166.201 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 140/4776 | Loss: 197.252 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 150/4776 | Loss: 167.439 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 160/4776 | Loss: 165.735 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 170/4776 | Loss: 138.374 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 180/4776 | Loss: 203.389 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 190/4776 | Loss: 222.577 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 200/4776 | Loss: 179.776 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 210/4776 | Loss: 182.569 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 220/4776 | Loss: 193.577 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 230/4776 | Loss: 196.731 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 240/4776 | Loss: 166.195 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 250/4776 | Loss: 196.489 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 260/4776 | Loss: 176.414 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 270/4776 | Loss: 172.615 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 280/4776 | Loss: 197.849 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 290/4776 | Loss: 157.677 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 300/4776 | Loss: 155.795 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 310/4776 | Loss: 143.646 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 320/4776 | Loss: 177.605 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 330/4776 | Loss: 166.810 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 340/4776 | Loss: 206.698 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 350/4776 | Loss: 187.895 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 360/4776 | Loss: 165.158 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 370/4776 | Loss: 216.388 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 380/4776 | Loss: 184.395 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 390/4776 | Loss: 184.707 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 400/4776 | Loss: 178.003 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 410/4776 | Loss: 151.149 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 420/4776 | Loss: 189.487 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 430/4776 | Loss: 147.742 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 440/4776 | Loss: 240.710 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 450/4776 | Loss: 191.765 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 460/4776 | Loss: 214.728 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 470/4776 | Loss: 137.802 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 480/4776 | Loss: 205.859 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 490/4776 | Loss: 187.596 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 500/4776 | Loss: 257.409 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 510/4776 | Loss: 187.381 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 520/4776 | Loss: 212.477 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 530/4776 | Loss: 122.649 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 540/4776 | Loss: 272.304 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 550/4776 | Loss: 134.612 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 560/4776 | Loss: 209.300 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 570/4776 | Loss: 228.336 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 580/4776 | Loss: 162.662 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 590/4776 | Loss: 199.432 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 600/4776 | Loss: 198.152 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 610/4776 | Loss: 199.863 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 620/4776 | Loss: 221.025 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 630/4776 | Loss: 200.819 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 640/4776 | Loss: 178.826 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 650/4776 | Loss: 178.470 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 660/4776 | Loss: 176.747 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 670/4776 | Loss: 199.790 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 680/4776 | Loss: 219.428 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 690/4776 | Loss: 179.080 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 700/4776 | Loss: 153.791 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 710/4776 | Loss: 195.318 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 720/4776 | Loss: 176.373 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 730/4776 | Loss: 178.341 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 740/4776 | Loss: 206.496 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 750/4776 | Loss: 171.297 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 760/4776 | Loss: 190.817 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 770/4776 | Loss: 178.571 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 780/4776 | Loss: 166.487 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 790/4776 | Loss: 186.967 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 800/4776 | Loss: 186.233 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 810/4776 | Loss: 222.171 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 820/4776 | Loss: 191.407 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 830/4776 | Loss: 193.326 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 840/4776 | Loss: 205.068 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 850/4776 | Loss: 146.106 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 860/4776 | Loss: 249.545 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 870/4776 | Loss: 226.188 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 880/4776 | Loss: 167.443 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 890/4776 | Loss: 168.687 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 900/4776 | Loss: 186.599 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 910/4776 | Loss: 184.078 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 920/4776 | Loss: 199.530 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 930/4776 | Loss: 174.903 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 940/4776 | Loss: 158.508 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 950/4776 | Loss: 147.096 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 960/4776 | Loss: 156.670 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 970/4776 | Loss: 215.104 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 980/4776 | Loss: 200.200 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 990/4776 | Loss: 218.322 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1000/4776 | Loss: 183.414 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1010/4776 | Loss: 216.616 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1020/4776 | Loss: 186.942 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1030/4776 | Loss: 174.662 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1040/4776 | Loss: 182.661 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1050/4776 | Loss: 203.437 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1060/4776 | Loss: 180.810 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1070/4776 | Loss: 185.342 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 1080/4776 | Loss: 178.921 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1090/4776 | Loss: 188.328 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1100/4776 | Loss: 162.527 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1110/4776 | Loss: 150.525 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 1120/4776 | Loss: 195.560 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1130/4776 | Loss: 177.781 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1140/4776 | Loss: 172.090 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1150/4776 | Loss: 190.960 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1160/4776 | Loss: 157.577 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1170/4776 | Loss: 138.988 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1180/4776 | Loss: 156.065 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1190/4776 | Loss: 201.684 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1200/4776 | Loss: 200.304 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1210/4776 | Loss: 190.512 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1220/4776 | Loss: 176.479 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1230/4776 | Loss: 157.624 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1240/4776 | Loss: 139.532 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 1250/4776 | Loss: 180.319 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1260/4776 | Loss: 171.786 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1270/4776 | Loss: 188.814 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1280/4776 | Loss: 239.588 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1290/4776 | Loss: 167.241 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1300/4776 | Loss: 192.225 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1310/4776 | Loss: 220.761 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1320/4776 | Loss: 172.795 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1330/4776 | Loss: 220.486 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1340/4776 | Loss: 205.394 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1350/4776 | Loss: 164.605 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1360/4776 | Loss: 212.741 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1370/4776 | Loss: 168.217 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1380/4776 | Loss: 182.534 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1390/4776 | Loss: 180.723 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1400/4776 | Loss: 209.294 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1410/4776 | Loss: 127.279 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 1420/4776 | Loss: 209.160 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1430/4776 | Loss: 204.301 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1440/4776 | Loss: 157.017 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 1450/4776 | Loss: 179.745 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1460/4776 | Loss: 171.308 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1470/4776 | Loss: 178.186 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1480/4776 | Loss: 166.235 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 1490/4776 | Loss: 197.294 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1500/4776 | Loss: 196.352 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1510/4776 | Loss: 217.175 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1520/4776 | Loss: 185.674 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1530/4776 | Loss: 169.629 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1540/4776 | Loss: 149.888 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1550/4776 | Loss: 167.596 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1560/4776 | Loss: 185.571 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1570/4776 | Loss: 203.769 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1580/4776 | Loss: 268.085 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1590/4776 | Loss: 147.728 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 1600/4776 | Loss: 194.063 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1610/4776 | Loss: 139.581 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1620/4776 | Loss: 246.781 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1630/4776 | Loss: 196.768 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1640/4776 | Loss: 178.782 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1650/4776 | Loss: 191.260 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1660/4776 | Loss: 140.610 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1670/4776 | Loss: 192.982 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1680/4776 | Loss: 130.069 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 1690/4776 | Loss: 191.695 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1700/4776 | Loss: 191.816 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1710/4776 | Loss: 188.867 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1720/4776 | Loss: 184.623 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1730/4776 | Loss: 170.756 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1740/4776 | Loss: 192.533 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1750/4776 | Loss: 195.265 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1760/4776 | Loss: 216.970 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1770/4776 | Loss: 141.285 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 1780/4776 | Loss: 198.519 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1790/4776 | Loss: 185.923 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1800/4776 | Loss: 179.677 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1810/4776 | Loss: 175.114 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1820/4776 | Loss: 191.976 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1830/4776 | Loss: 221.804 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 1840/4776 | Loss: 195.242 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1850/4776 | Loss: 174.558 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1860/4776 | Loss: 222.945 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1870/4776 | Loss: 195.191 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1880/4776 | Loss: 207.190 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1890/4776 | Loss: 204.206 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1900/4776 | Loss: 191.587 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1910/4776 | Loss: 213.099 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1920/4776 | Loss: 170.792 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1930/4776 | Loss: 185.486 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1940/4776 | Loss: 180.983 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1950/4776 | Loss: 197.440 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1960/4776 | Loss: 210.761 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1970/4776 | Loss: 181.912 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 1980/4776 | Loss: 227.009 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1990/4776 | Loss: 220.833 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2000/4776 | Loss: 226.565 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2010/4776 | Loss: 193.016 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2020/4776 | Loss: 176.947 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2030/4776 | Loss: 178.469 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2040/4776 | Loss: 156.442 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2050/4776 | Loss: 210.033 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2060/4776 | Loss: 147.773 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2070/4776 | Loss: 200.829 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2080/4776 | Loss: 216.694 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2090/4776 | Loss: 204.398 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 2100/4776 | Loss: 231.320 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2110/4776 | Loss: 143.650 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 2120/4776 | Loss: 161.557 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2130/4776 | Loss: 159.475 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2140/4776 | Loss: 198.612 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2150/4776 | Loss: 166.459 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2160/4776 | Loss: 220.256 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2170/4776 | Loss: 172.215 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2180/4776 | Loss: 227.879 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2190/4776 | Loss: 173.994 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2200/4776 | Loss: 183.719 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2210/4776 | Loss: 161.953 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2220/4776 | Loss: 169.666 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2230/4776 | Loss: 180.723 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2240/4776 | Loss: 201.115 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2250/4776 | Loss: 195.872 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 2260/4776 | Loss: 199.477 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2270/4776 | Loss: 196.576 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2280/4776 | Loss: 214.118 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2290/4776 | Loss: 165.788 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2300/4776 | Loss: 194.499 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2310/4776 | Loss: 188.678 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2320/4776 | Loss: 266.922 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2330/4776 | Loss: 232.284 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2340/4776 | Loss: 191.461 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2350/4776 | Loss: 152.097 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2360/4776 | Loss: 211.886 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2370/4776 | Loss: 209.365 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2380/4776 | Loss: 172.239 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2390/4776 | Loss: 168.235 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2400/4776 | Loss: 158.348 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2410/4776 | Loss: 161.805 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2420/4776 | Loss: 186.089 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2430/4776 | Loss: 198.023 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2440/4776 | Loss: 195.942 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2450/4776 | Loss: 166.229 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2460/4776 | Loss: 196.122 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2470/4776 | Loss: 154.023 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2480/4776 | Loss: 202.123 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 2490/4776 | Loss: 164.129 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2500/4776 | Loss: 192.482 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2510/4776 | Loss: 172.135 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2520/4776 | Loss: 210.683 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2530/4776 | Loss: 194.141 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2540/4776 | Loss: 211.594 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2550/4776 | Loss: 291.275 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2560/4776 | Loss: 168.914 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2570/4776 | Loss: 172.417 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2580/4776 | Loss: 165.285 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2590/4776 | Loss: 159.411 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2600/4776 | Loss: 205.304 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2610/4776 | Loss: 247.936 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2620/4776 | Loss: 156.564 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2630/4776 | Loss: 220.057 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2640/4776 | Loss: 161.523 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2650/4776 | Loss: 190.230 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2660/4776 | Loss: 155.509 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2670/4776 | Loss: 183.224 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2680/4776 | Loss: 136.529 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2690/4776 | Loss: 194.760 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2700/4776 | Loss: 205.921 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2710/4776 | Loss: 179.996 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2720/4776 | Loss: 238.002 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2730/4776 | Loss: 195.740 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2740/4776 | Loss: 201.807 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2750/4776 | Loss: 175.291 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2760/4776 | Loss: 165.159 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2770/4776 | Loss: 179.014 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2780/4776 | Loss: 197.404 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2790/4776 | Loss: 364.088 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2800/4776 | Loss: 200.911 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2810/4776 | Loss: 184.470 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2820/4776 | Loss: 216.144 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2830/4776 | Loss: 202.378 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2840/4776 | Loss: 181.755 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 2850/4776 | Loss: 161.443 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2860/4776 | Loss: 144.260 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 2870/4776 | Loss: 175.964 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2880/4776 | Loss: 207.920 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2890/4776 | Loss: 142.273 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2900/4776 | Loss: 211.508 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2910/4776 | Loss: 202.510 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 2920/4776 | Loss: 215.761 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2930/4776 | Loss: 173.606 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2940/4776 | Loss: 186.698 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2950/4776 | Loss: 206.800 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 2960/4776 | Loss: 181.198 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 2970/4776 | Loss: 218.967 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2980/4776 | Loss: 187.532 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 2990/4776 | Loss: 167.241 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3000/4776 | Loss: 219.102 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3010/4776 | Loss: 202.072 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3020/4776 | Loss: 238.404 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 3030/4776 | Loss: 158.290 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3040/4776 | Loss: 179.888 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3050/4776 | Loss: 159.807 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3060/4776 | Loss: 130.275 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3070/4776 | Loss: 186.174 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3080/4776 | Loss: 211.462 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3090/4776 | Loss: 199.443 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3100/4776 | Loss: 239.198 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3110/4776 | Loss: 199.092 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3120/4776 | Loss: 124.900 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3130/4776 | Loss: 149.830 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3140/4776 | Loss: 171.991 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3150/4776 | Loss: 178.232 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3160/4776 | Loss: 213.840 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3170/4776 | Loss: 224.220 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3180/4776 | Loss: 190.007 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3190/4776 | Loss: 207.026 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3200/4776 | Loss: 202.955 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3210/4776 | Loss: 194.751 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3220/4776 | Loss: 211.498 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3230/4776 | Loss: 197.090 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3240/4776 | Loss: 186.542 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3250/4776 | Loss: 166.447 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3260/4776 | Loss: 200.660 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3270/4776 | Loss: 167.492 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3280/4776 | Loss: 186.824 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3290/4776 | Loss: 165.478 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3300/4776 | Loss: 163.192 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3310/4776 | Loss: 176.683 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3320/4776 | Loss: 129.249 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3330/4776 | Loss: 149.522 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3340/4776 | Loss: 177.711 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3350/4776 | Loss: 169.850 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3360/4776 | Loss: 147.556 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3370/4776 | Loss: 226.572 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3380/4776 | Loss: 190.829 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3390/4776 | Loss: 170.109 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3400/4776 | Loss: 190.124 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3410/4776 | Loss: 177.658 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3420/4776 | Loss: 169.022 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3430/4776 | Loss: 178.191 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3440/4776 | Loss: 169.349 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3450/4776 | Loss: 180.577 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3460/4776 | Loss: 158.638 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3470/4776 | Loss: 186.252 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3480/4776 | Loss: 176.887 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3490/4776 | Loss: 201.222 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3500/4776 | Loss: 184.426 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3510/4776 | Loss: 232.967 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3520/4776 | Loss: 235.100 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3530/4776 | Loss: 185.854 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3540/4776 | Loss: 180.699 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3550/4776 | Loss: 192.962 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3560/4776 | Loss: 182.678 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3570/4776 | Loss: 190.782 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3580/4776 | Loss: 259.227 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3590/4776 | Loss: 239.959 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3600/4776 | Loss: 170.990 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3610/4776 | Loss: 184.090 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3620/4776 | Loss: 200.772 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3630/4776 | Loss: 211.652 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3640/4776 | Loss: 225.599 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3650/4776 | Loss: 247.995 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3660/4776 | Loss: 186.239 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3670/4776 | Loss: 147.369 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3680/4776 | Loss: 190.429 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3690/4776 | Loss: 190.684 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3700/4776 | Loss: 184.560 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3710/4776 | Loss: 209.883 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3720/4776 | Loss: 191.997 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3730/4776 | Loss: 176.596 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3740/4776 | Loss: 168.345 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3750/4776 | Loss: 159.915 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3760/4776 | Loss: 125.974 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3770/4776 | Loss: 229.972 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3780/4776 | Loss: 136.944 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3790/4776 | Loss: 157.210 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3800/4776 | Loss: 185.456 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3810/4776 | Loss: 171.038 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3820/4776 | Loss: 128.716 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 3830/4776 | Loss: 163.343 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3840/4776 | Loss: 162.166 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3850/4776 | Loss: 220.511 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3860/4776 | Loss: 210.260 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3870/4776 | Loss: 166.253 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 3880/4776 | Loss: 238.685 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3890/4776 | Loss: 201.242 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3900/4776 | Loss: 181.965 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3910/4776 | Loss: 218.371 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3920/4776 | Loss: 180.392 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3930/4776 | Loss: 172.969 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 3940/4776 | Loss: 221.286 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3950/4776 | Loss: 191.968 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3960/4776 | Loss: 219.683 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 3970/4776 | Loss: 202.074 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 3980/4776 | Loss: 224.760 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 3990/4776 | Loss: 193.406 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4000/4776 | Loss: 159.794 | Accuracy: 0.700\n",
      "[Epoch: 32/200] - Step: 4010/4776 | Loss: 249.217 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 4020/4776 | Loss: 198.424 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4030/4776 | Loss: 218.183 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4040/4776 | Loss: 206.761 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4050/4776 | Loss: 191.212 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4060/4776 | Loss: 191.068 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4070/4776 | Loss: 243.370 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4080/4776 | Loss: 176.471 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4090/4776 | Loss: 193.694 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4100/4776 | Loss: 107.734 | Accuracy: 0.700\n",
      "[Epoch: 32/200] - Step: 4110/4776 | Loss: 198.313 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4120/4776 | Loss: 184.715 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4130/4776 | Loss: 156.475 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4140/4776 | Loss: 151.800 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 4150/4776 | Loss: 194.058 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4160/4776 | Loss: 173.853 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4170/4776 | Loss: 141.560 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 4180/4776 | Loss: 213.094 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4190/4776 | Loss: 149.074 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4200/4776 | Loss: 153.152 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4210/4776 | Loss: 198.507 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4220/4776 | Loss: 158.823 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4230/4776 | Loss: 211.837 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4240/4776 | Loss: 213.402 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4250/4776 | Loss: 150.912 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4260/4776 | Loss: 218.895 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 4270/4776 | Loss: 198.366 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4280/4776 | Loss: 186.366 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4290/4776 | Loss: 174.057 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4300/4776 | Loss: 166.272 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4310/4776 | Loss: 173.323 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4320/4776 | Loss: 193.837 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4330/4776 | Loss: 186.547 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4340/4776 | Loss: 173.952 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 4350/4776 | Loss: 196.283 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4360/4776 | Loss: 156.451 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 4370/4776 | Loss: 188.540 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4380/4776 | Loss: 208.960 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4390/4776 | Loss: 165.903 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4400/4776 | Loss: 198.847 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 4410/4776 | Loss: 202.283 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4420/4776 | Loss: 218.623 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4430/4776 | Loss: 195.709 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4440/4776 | Loss: 166.695 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4450/4776 | Loss: 206.333 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4460/4776 | Loss: 186.443 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4470/4776 | Loss: 189.800 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4480/4776 | Loss: 210.552 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4490/4776 | Loss: 166.182 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4500/4776 | Loss: 143.110 | Accuracy: 0.600\n",
      "[Epoch: 32/200] - Step: 4510/4776 | Loss: 167.031 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4520/4776 | Loss: 191.767 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4530/4776 | Loss: 142.468 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 4540/4776 | Loss: 216.004 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4550/4776 | Loss: 156.555 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4560/4776 | Loss: 180.633 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4570/4776 | Loss: 179.627 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4580/4776 | Loss: 202.549 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 4590/4776 | Loss: 212.772 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 4600/4776 | Loss: 204.637 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4610/4776 | Loss: 151.974 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4620/4776 | Loss: 208.592 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4630/4776 | Loss: 203.901 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4640/4776 | Loss: 213.723 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4650/4776 | Loss: 160.975 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4660/4776 | Loss: 178.550 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4670/4776 | Loss: 166.005 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4680/4776 | Loss: 124.289 | Accuracy: 0.500\n",
      "[Epoch: 32/200] - Step: 4690/4776 | Loss: 178.135 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4700/4776 | Loss: 205.302 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4710/4776 | Loss: 137.459 | Accuracy: 0.700\n",
      "[Epoch: 32/200] - Step: 4720/4776 | Loss: 186.567 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4730/4776 | Loss: 188.522 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 4740/4776 | Loss: 163.040 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 4750/4776 | Loss: 170.354 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4760/4776 | Loss: 191.800 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 4770/4776 | Loss: 190.020 | Accuracy: 0.600\n",
      "Accuracy:  0.17868852459016393\n",
      "[Epoch: 33/200] - Step: 10/4776 | Loss: 186.689 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 20/4776 | Loss: 217.242 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 30/4776 | Loss: 168.124 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 40/4776 | Loss: 169.471 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 50/4776 | Loss: 133.153 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 60/4776 | Loss: 173.514 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 70/4776 | Loss: 209.890 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 80/4776 | Loss: 189.904 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 90/4776 | Loss: 276.424 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 100/4776 | Loss: 153.839 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 110/4776 | Loss: 204.549 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 120/4776 | Loss: 161.095 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 130/4776 | Loss: 177.852 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 140/4776 | Loss: 177.588 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 150/4776 | Loss: 194.141 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 160/4776 | Loss: 171.793 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 170/4776 | Loss: 193.134 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 180/4776 | Loss: 172.873 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 190/4776 | Loss: 154.911 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 200/4776 | Loss: 155.691 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 210/4776 | Loss: 168.695 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 220/4776 | Loss: 184.443 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 230/4776 | Loss: 138.962 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 240/4776 | Loss: 184.368 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 250/4776 | Loss: 157.530 | Accuracy: 0.700\n",
      "[Epoch: 33/200] - Step: 260/4776 | Loss: 192.157 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 270/4776 | Loss: 164.142 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 280/4776 | Loss: 199.418 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 290/4776 | Loss: 172.287 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 300/4776 | Loss: 175.279 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 310/4776 | Loss: 179.444 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 320/4776 | Loss: 241.866 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 330/4776 | Loss: 241.861 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 340/4776 | Loss: 194.054 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 350/4776 | Loss: 193.660 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 360/4776 | Loss: 210.038 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 370/4776 | Loss: 157.142 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 380/4776 | Loss: 170.839 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 390/4776 | Loss: 173.961 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 400/4776 | Loss: 154.606 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 410/4776 | Loss: 201.279 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 420/4776 | Loss: 175.110 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 430/4776 | Loss: 194.019 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 440/4776 | Loss: 166.067 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 450/4776 | Loss: 166.739 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 460/4776 | Loss: 198.514 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 470/4776 | Loss: 208.587 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 480/4776 | Loss: 164.836 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 490/4776 | Loss: 188.640 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 500/4776 | Loss: 177.582 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 510/4776 | Loss: 166.186 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 520/4776 | Loss: 190.042 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 530/4776 | Loss: 149.556 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 540/4776 | Loss: 181.851 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 550/4776 | Loss: 166.497 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 560/4776 | Loss: 173.589 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 570/4776 | Loss: 178.241 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 580/4776 | Loss: 152.680 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 590/4776 | Loss: 152.729 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 600/4776 | Loss: 201.262 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 610/4776 | Loss: 206.336 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 620/4776 | Loss: 153.944 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 630/4776 | Loss: 161.454 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 640/4776 | Loss: 174.339 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 650/4776 | Loss: 212.312 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 660/4776 | Loss: 162.121 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 670/4776 | Loss: 190.413 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 680/4776 | Loss: 165.741 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 690/4776 | Loss: 200.234 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 700/4776 | Loss: 226.460 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 710/4776 | Loss: 155.902 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 720/4776 | Loss: 133.105 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 730/4776 | Loss: 196.821 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 740/4776 | Loss: 198.780 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 750/4776 | Loss: 168.747 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 760/4776 | Loss: 187.253 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 770/4776 | Loss: 216.477 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 780/4776 | Loss: 157.999 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 790/4776 | Loss: 173.325 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 800/4776 | Loss: 141.110 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 810/4776 | Loss: 201.506 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 820/4776 | Loss: 168.916 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 830/4776 | Loss: 181.792 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 840/4776 | Loss: 195.629 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 850/4776 | Loss: 181.427 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 860/4776 | Loss: 252.932 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 870/4776 | Loss: 164.400 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 880/4776 | Loss: 130.869 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 890/4776 | Loss: 186.277 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 900/4776 | Loss: 175.882 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 910/4776 | Loss: 178.415 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 920/4776 | Loss: 204.774 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 930/4776 | Loss: 129.836 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 940/4776 | Loss: 155.250 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 950/4776 | Loss: 144.016 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 960/4776 | Loss: 150.290 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 970/4776 | Loss: 203.891 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 980/4776 | Loss: 155.714 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 990/4776 | Loss: 188.008 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1000/4776 | Loss: 158.957 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1010/4776 | Loss: 199.957 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1020/4776 | Loss: 251.884 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1030/4776 | Loss: 171.348 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1040/4776 | Loss: 199.168 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1050/4776 | Loss: 153.080 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1060/4776 | Loss: 179.904 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1070/4776 | Loss: 180.960 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1080/4776 | Loss: 138.169 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1090/4776 | Loss: 167.931 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1100/4776 | Loss: 178.176 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1110/4776 | Loss: 165.009 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1120/4776 | Loss: 163.160 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1130/4776 | Loss: 197.822 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1140/4776 | Loss: 162.264 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1150/4776 | Loss: 165.141 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1160/4776 | Loss: 155.820 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1170/4776 | Loss: 159.486 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1180/4776 | Loss: 144.212 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1190/4776 | Loss: 198.488 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1200/4776 | Loss: 198.188 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1210/4776 | Loss: 138.015 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1220/4776 | Loss: 164.511 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1230/4776 | Loss: 241.421 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1240/4776 | Loss: 174.517 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1250/4776 | Loss: 186.934 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1260/4776 | Loss: 178.524 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1270/4776 | Loss: 226.178 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1280/4776 | Loss: 177.306 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1290/4776 | Loss: 164.342 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1300/4776 | Loss: 200.261 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1310/4776 | Loss: 207.688 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1320/4776 | Loss: 198.080 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1330/4776 | Loss: 202.869 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1340/4776 | Loss: 157.214 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1350/4776 | Loss: 183.474 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1360/4776 | Loss: 203.893 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1370/4776 | Loss: 196.371 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1380/4776 | Loss: 160.363 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1390/4776 | Loss: 212.063 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1400/4776 | Loss: 138.966 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1410/4776 | Loss: 260.891 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1420/4776 | Loss: 155.874 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1430/4776 | Loss: 159.749 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1440/4776 | Loss: 183.965 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1450/4776 | Loss: 190.083 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1460/4776 | Loss: 231.030 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1470/4776 | Loss: 176.763 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1480/4776 | Loss: 176.243 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1490/4776 | Loss: 177.541 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1500/4776 | Loss: 194.097 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1510/4776 | Loss: 146.151 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1520/4776 | Loss: 234.421 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 1530/4776 | Loss: 224.130 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1540/4776 | Loss: 178.296 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1550/4776 | Loss: 195.533 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1560/4776 | Loss: 126.593 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1570/4776 | Loss: 153.636 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1580/4776 | Loss: 181.630 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1590/4776 | Loss: 206.152 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1600/4776 | Loss: 186.601 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1610/4776 | Loss: 180.110 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1620/4776 | Loss: 146.467 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1630/4776 | Loss: 105.054 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1640/4776 | Loss: 176.496 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1650/4776 | Loss: 149.740 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1660/4776 | Loss: 189.460 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1670/4776 | Loss: 181.764 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1680/4776 | Loss: 164.423 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1690/4776 | Loss: 143.655 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1700/4776 | Loss: 151.639 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1710/4776 | Loss: 238.896 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1720/4776 | Loss: 126.979 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1730/4776 | Loss: 152.834 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1740/4776 | Loss: 178.095 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1750/4776 | Loss: 157.302 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1760/4776 | Loss: 192.327 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1770/4776 | Loss: 196.565 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1780/4776 | Loss: 237.201 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1790/4776 | Loss: 145.703 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1800/4776 | Loss: 136.859 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1810/4776 | Loss: 145.344 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1820/4776 | Loss: 123.342 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1830/4776 | Loss: 136.321 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1840/4776 | Loss: 175.682 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1850/4776 | Loss: 112.947 | Accuracy: 0.800\n",
      "[Epoch: 33/200] - Step: 1860/4776 | Loss: 155.155 | Accuracy: 0.700\n",
      "[Epoch: 33/200] - Step: 1870/4776 | Loss: 163.351 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1880/4776 | Loss: 146.606 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1890/4776 | Loss: 170.198 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 1900/4776 | Loss: 152.634 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1910/4776 | Loss: 209.753 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1920/4776 | Loss: 180.020 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1930/4776 | Loss: 205.087 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1940/4776 | Loss: 220.517 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1950/4776 | Loss: 201.027 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1960/4776 | Loss: 152.759 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 1970/4776 | Loss: 204.283 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 1980/4776 | Loss: 153.423 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1990/4776 | Loss: 234.013 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2000/4776 | Loss: 192.252 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2010/4776 | Loss: 198.642 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2020/4776 | Loss: 182.321 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2030/4776 | Loss: 216.689 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2040/4776 | Loss: 183.382 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2050/4776 | Loss: 213.856 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2060/4776 | Loss: 177.839 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2070/4776 | Loss: 169.005 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2080/4776 | Loss: 260.301 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2090/4776 | Loss: 166.326 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 2100/4776 | Loss: 206.564 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2110/4776 | Loss: 134.044 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2120/4776 | Loss: 196.059 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2130/4776 | Loss: 210.509 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2140/4776 | Loss: 174.313 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2150/4776 | Loss: 195.371 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2160/4776 | Loss: 164.149 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2170/4776 | Loss: 254.374 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2180/4776 | Loss: 226.812 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2190/4776 | Loss: 295.138 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2200/4776 | Loss: 231.787 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2210/4776 | Loss: 189.705 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2220/4776 | Loss: 193.722 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2230/4776 | Loss: 189.917 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2240/4776 | Loss: 182.768 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2250/4776 | Loss: 204.627 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 2260/4776 | Loss: 207.667 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2270/4776 | Loss: 190.311 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2280/4776 | Loss: 177.442 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2290/4776 | Loss: 171.819 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2300/4776 | Loss: 176.402 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2310/4776 | Loss: 225.682 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2320/4776 | Loss: 185.409 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2330/4776 | Loss: 214.469 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 2340/4776 | Loss: 181.114 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2350/4776 | Loss: 173.857 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2360/4776 | Loss: 168.052 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2370/4776 | Loss: 217.550 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2380/4776 | Loss: 172.551 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2390/4776 | Loss: 190.559 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2400/4776 | Loss: 219.078 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 2410/4776 | Loss: 147.817 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2420/4776 | Loss: 247.120 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 2430/4776 | Loss: 141.934 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2440/4776 | Loss: 184.726 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2450/4776 | Loss: 215.048 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2460/4776 | Loss: 148.963 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 2470/4776 | Loss: 167.246 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2480/4776 | Loss: 168.760 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2490/4776 | Loss: 204.719 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2500/4776 | Loss: 170.017 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2510/4776 | Loss: 155.231 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2520/4776 | Loss: 181.370 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2530/4776 | Loss: 130.206 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2540/4776 | Loss: 176.811 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2550/4776 | Loss: 221.796 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2560/4776 | Loss: 211.385 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2570/4776 | Loss: 142.657 | Accuracy: 0.700\n",
      "[Epoch: 33/200] - Step: 2580/4776 | Loss: 221.439 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2590/4776 | Loss: 176.133 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2600/4776 | Loss: 148.053 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 2610/4776 | Loss: 197.753 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2620/4776 | Loss: 165.090 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 2630/4776 | Loss: 146.852 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2640/4776 | Loss: 170.151 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2650/4776 | Loss: 200.191 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2660/4776 | Loss: 199.532 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2670/4776 | Loss: 146.603 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2680/4776 | Loss: 161.717 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2690/4776 | Loss: 220.341 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 2700/4776 | Loss: 161.473 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2710/4776 | Loss: 176.053 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2720/4776 | Loss: 191.493 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2730/4776 | Loss: 222.058 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2740/4776 | Loss: 143.714 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 2750/4776 | Loss: 203.751 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2760/4776 | Loss: 187.082 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2770/4776 | Loss: 190.759 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2780/4776 | Loss: 173.617 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2790/4776 | Loss: 211.651 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2800/4776 | Loss: 203.571 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2810/4776 | Loss: 228.034 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2820/4776 | Loss: 150.548 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2830/4776 | Loss: 153.916 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2840/4776 | Loss: 156.185 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2850/4776 | Loss: 191.026 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2860/4776 | Loss: 210.178 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2870/4776 | Loss: 226.443 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2880/4776 | Loss: 201.838 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2890/4776 | Loss: 151.037 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2900/4776 | Loss: 223.212 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2910/4776 | Loss: 137.415 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2920/4776 | Loss: 153.484 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2930/4776 | Loss: 246.146 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2940/4776 | Loss: 192.007 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 2950/4776 | Loss: 174.171 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 2960/4776 | Loss: 191.552 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 2970/4776 | Loss: 161.620 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 2980/4776 | Loss: 178.742 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 2990/4776 | Loss: 204.138 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3000/4776 | Loss: 172.204 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3010/4776 | Loss: 213.387 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3020/4776 | Loss: 185.222 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3030/4776 | Loss: 168.007 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3040/4776 | Loss: 179.103 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3050/4776 | Loss: 221.573 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3060/4776 | Loss: 127.591 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3070/4776 | Loss: 170.755 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3080/4776 | Loss: 198.480 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3090/4776 | Loss: 172.843 | Accuracy: 0.700\n",
      "[Epoch: 33/200] - Step: 3100/4776 | Loss: 174.668 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3110/4776 | Loss: 187.852 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3120/4776 | Loss: 183.621 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3130/4776 | Loss: 172.266 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3140/4776 | Loss: 212.685 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3150/4776 | Loss: 175.232 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3160/4776 | Loss: 230.123 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3170/4776 | Loss: 167.897 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3180/4776 | Loss: 182.683 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3190/4776 | Loss: 166.370 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3200/4776 | Loss: 146.842 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 3210/4776 | Loss: 153.359 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3220/4776 | Loss: 169.168 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3230/4776 | Loss: 180.958 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3240/4776 | Loss: 157.826 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3250/4776 | Loss: 163.669 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3260/4776 | Loss: 160.046 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3270/4776 | Loss: 200.034 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3280/4776 | Loss: 190.708 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3290/4776 | Loss: 164.096 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3300/4776 | Loss: 207.293 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3310/4776 | Loss: 209.892 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3320/4776 | Loss: 173.973 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3330/4776 | Loss: 155.191 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3340/4776 | Loss: 97.246 | Accuracy: 0.800\n",
      "[Epoch: 33/200] - Step: 3350/4776 | Loss: 189.656 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3360/4776 | Loss: 126.847 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3370/4776 | Loss: 141.168 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3380/4776 | Loss: 168.770 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3390/4776 | Loss: 186.715 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3400/4776 | Loss: 210.074 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3410/4776 | Loss: 192.170 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3420/4776 | Loss: 157.062 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3430/4776 | Loss: 185.859 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3440/4776 | Loss: 200.127 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3450/4776 | Loss: 192.420 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3460/4776 | Loss: 164.417 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3470/4776 | Loss: 143.036 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3480/4776 | Loss: 159.255 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3490/4776 | Loss: 238.207 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3500/4776 | Loss: 201.698 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3510/4776 | Loss: 152.129 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3520/4776 | Loss: 199.525 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3530/4776 | Loss: 184.235 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3540/4776 | Loss: 177.752 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3550/4776 | Loss: 205.687 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3560/4776 | Loss: 172.433 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3570/4776 | Loss: 170.121 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3580/4776 | Loss: 222.884 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3590/4776 | Loss: 194.115 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3600/4776 | Loss: 152.655 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3610/4776 | Loss: 166.076 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3620/4776 | Loss: 146.140 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3630/4776 | Loss: 225.357 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3640/4776 | Loss: 198.422 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3650/4776 | Loss: 220.993 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3660/4776 | Loss: 111.971 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3670/4776 | Loss: 192.381 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3680/4776 | Loss: 193.405 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3690/4776 | Loss: 214.186 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3700/4776 | Loss: 212.287 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3710/4776 | Loss: 164.684 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3720/4776 | Loss: 228.614 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3730/4776 | Loss: 146.231 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3740/4776 | Loss: 172.528 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3750/4776 | Loss: 117.308 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3760/4776 | Loss: 186.346 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 3770/4776 | Loss: 133.300 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 3780/4776 | Loss: 176.550 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3790/4776 | Loss: 156.413 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3800/4776 | Loss: 152.903 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3810/4776 | Loss: 138.156 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 3820/4776 | Loss: 172.206 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3830/4776 | Loss: 173.521 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3840/4776 | Loss: 195.738 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3850/4776 | Loss: 195.172 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3860/4776 | Loss: 199.045 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3870/4776 | Loss: 164.629 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3880/4776 | Loss: 155.993 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3890/4776 | Loss: 137.945 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 3900/4776 | Loss: 231.517 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 3910/4776 | Loss: 108.812 | Accuracy: 0.700\n",
      "[Epoch: 33/200] - Step: 3920/4776 | Loss: 225.566 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3930/4776 | Loss: 171.190 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3940/4776 | Loss: 183.057 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3950/4776 | Loss: 182.551 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3960/4776 | Loss: 180.800 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 3970/4776 | Loss: 229.698 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 3980/4776 | Loss: 189.362 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 3990/4776 | Loss: 158.013 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4000/4776 | Loss: 202.837 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4010/4776 | Loss: 220.360 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4020/4776 | Loss: 176.756 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4030/4776 | Loss: 207.432 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4040/4776 | Loss: 182.783 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4050/4776 | Loss: 159.690 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4060/4776 | Loss: 207.949 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4070/4776 | Loss: 231.643 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4080/4776 | Loss: 200.422 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4090/4776 | Loss: 151.154 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4100/4776 | Loss: 219.624 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4110/4776 | Loss: 155.889 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4120/4776 | Loss: 171.487 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4130/4776 | Loss: 170.072 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 4140/4776 | Loss: 162.325 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4150/4776 | Loss: 203.910 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4160/4776 | Loss: 185.566 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4170/4776 | Loss: 163.576 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4180/4776 | Loss: 173.851 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4190/4776 | Loss: 254.095 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 4200/4776 | Loss: 182.676 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4210/4776 | Loss: 192.021 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4220/4776 | Loss: 190.519 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4230/4776 | Loss: 190.784 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4240/4776 | Loss: 192.573 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4250/4776 | Loss: 202.436 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4260/4776 | Loss: 193.418 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4270/4776 | Loss: 210.012 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4280/4776 | Loss: 161.801 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 4290/4776 | Loss: 178.679 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4300/4776 | Loss: 208.601 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4310/4776 | Loss: 200.777 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4320/4776 | Loss: 174.365 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4330/4776 | Loss: 121.955 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 4340/4776 | Loss: 175.903 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4350/4776 | Loss: 200.019 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4360/4776 | Loss: 199.472 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4370/4776 | Loss: 203.051 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4380/4776 | Loss: 181.579 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4390/4776 | Loss: 206.804 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4400/4776 | Loss: 161.845 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4410/4776 | Loss: 182.467 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4420/4776 | Loss: 207.907 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4430/4776 | Loss: 182.626 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4440/4776 | Loss: 135.233 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4450/4776 | Loss: 207.393 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4460/4776 | Loss: 171.168 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4470/4776 | Loss: 218.159 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 4480/4776 | Loss: 176.292 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4490/4776 | Loss: 210.186 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4500/4776 | Loss: 204.155 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 4510/4776 | Loss: 151.505 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4520/4776 | Loss: 151.224 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4530/4776 | Loss: 172.077 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4540/4776 | Loss: 170.655 | Accuracy: 0.600\n",
      "[Epoch: 33/200] - Step: 4550/4776 | Loss: 217.533 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 4560/4776 | Loss: 190.283 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4570/4776 | Loss: 193.766 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4580/4776 | Loss: 180.401 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4590/4776 | Loss: 197.185 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4600/4776 | Loss: 153.204 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4610/4776 | Loss: 277.003 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4620/4776 | Loss: 181.859 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4630/4776 | Loss: 173.962 | Accuracy: 0.500\n",
      "[Epoch: 33/200] - Step: 4640/4776 | Loss: 184.030 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4650/4776 | Loss: 146.780 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4660/4776 | Loss: 186.345 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4670/4776 | Loss: 193.663 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4680/4776 | Loss: 178.900 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4690/4776 | Loss: 154.986 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4700/4776 | Loss: 133.487 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 4710/4776 | Loss: 178.956 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4720/4776 | Loss: 210.054 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4730/4776 | Loss: 187.629 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4740/4776 | Loss: 180.580 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 4750/4776 | Loss: 161.038 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 4760/4776 | Loss: 189.342 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 4770/4776 | Loss: 179.533 | Accuracy: 0.300\n",
      "Accuracy:  0.1737704918032787\n",
      "[Epoch: 34/200] - Step: 10/4776 | Loss: 140.112 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 20/4776 | Loss: 214.056 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 30/4776 | Loss: 219.041 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 40/4776 | Loss: 187.274 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 50/4776 | Loss: 148.877 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 60/4776 | Loss: 161.884 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 70/4776 | Loss: 125.370 | Accuracy: 0.700\n",
      "[Epoch: 34/200] - Step: 80/4776 | Loss: 207.078 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 90/4776 | Loss: 211.818 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 100/4776 | Loss: 171.910 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 110/4776 | Loss: 169.683 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 120/4776 | Loss: 131.079 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 130/4776 | Loss: 144.394 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 140/4776 | Loss: 156.562 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 150/4776 | Loss: 159.506 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 160/4776 | Loss: 177.262 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 170/4776 | Loss: 208.781 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 180/4776 | Loss: 147.259 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 190/4776 | Loss: 258.893 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 200/4776 | Loss: 206.419 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 210/4776 | Loss: 209.831 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 220/4776 | Loss: 192.348 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 230/4776 | Loss: 152.829 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 240/4776 | Loss: 197.536 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 250/4776 | Loss: 175.387 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 260/4776 | Loss: 154.072 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 270/4776 | Loss: 125.142 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 280/4776 | Loss: 153.280 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 290/4776 | Loss: 187.246 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 300/4776 | Loss: 156.982 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 310/4776 | Loss: 162.080 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 320/4776 | Loss: 148.786 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 330/4776 | Loss: 177.452 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 340/4776 | Loss: 210.325 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 350/4776 | Loss: 175.952 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 360/4776 | Loss: 201.394 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 370/4776 | Loss: 146.549 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 380/4776 | Loss: 141.486 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 390/4776 | Loss: 141.437 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 400/4776 | Loss: 150.642 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 410/4776 | Loss: 149.161 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 420/4776 | Loss: 149.823 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 430/4776 | Loss: 148.230 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 440/4776 | Loss: 127.812 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 450/4776 | Loss: 194.119 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 460/4776 | Loss: 139.603 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 470/4776 | Loss: 170.545 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 480/4776 | Loss: 193.509 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 490/4776 | Loss: 163.767 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 500/4776 | Loss: 166.848 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 510/4776 | Loss: 118.650 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 520/4776 | Loss: 167.191 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 530/4776 | Loss: 162.855 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 540/4776 | Loss: 141.039 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 550/4776 | Loss: 199.116 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 560/4776 | Loss: 195.408 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 570/4776 | Loss: 214.181 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 580/4776 | Loss: 182.309 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 590/4776 | Loss: 135.219 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 600/4776 | Loss: 148.549 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 610/4776 | Loss: 212.139 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 620/4776 | Loss: 162.185 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 630/4776 | Loss: 161.106 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 640/4776 | Loss: 164.716 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 650/4776 | Loss: 156.776 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 660/4776 | Loss: 141.895 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 670/4776 | Loss: 176.794 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 680/4776 | Loss: 146.651 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 690/4776 | Loss: 194.765 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 700/4776 | Loss: 203.653 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 710/4776 | Loss: 206.071 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 720/4776 | Loss: 109.280 | Accuracy: 0.800\n",
      "[Epoch: 34/200] - Step: 730/4776 | Loss: 223.662 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 740/4776 | Loss: 164.382 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 750/4776 | Loss: 219.745 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 760/4776 | Loss: 115.987 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 770/4776 | Loss: 193.534 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 780/4776 | Loss: 238.210 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 790/4776 | Loss: 267.625 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 800/4776 | Loss: 149.226 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 810/4776 | Loss: 266.942 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 820/4776 | Loss: 159.195 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 830/4776 | Loss: 190.640 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 840/4776 | Loss: 180.501 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 850/4776 | Loss: 185.771 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 860/4776 | Loss: 178.517 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 870/4776 | Loss: 160.205 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 880/4776 | Loss: 185.763 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 890/4776 | Loss: 171.753 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 900/4776 | Loss: 181.880 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 910/4776 | Loss: 178.064 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 920/4776 | Loss: 178.463 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 930/4776 | Loss: 172.072 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 940/4776 | Loss: 158.908 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 950/4776 | Loss: 135.646 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 960/4776 | Loss: 183.904 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 970/4776 | Loss: 192.422 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 980/4776 | Loss: 149.005 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 990/4776 | Loss: 152.077 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1000/4776 | Loss: 175.005 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1010/4776 | Loss: 166.909 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1020/4776 | Loss: 183.351 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1030/4776 | Loss: 179.388 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1040/4776 | Loss: 177.552 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1050/4776 | Loss: 185.005 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1060/4776 | Loss: 175.486 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1070/4776 | Loss: 136.658 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 1080/4776 | Loss: 135.185 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1090/4776 | Loss: 208.777 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1100/4776 | Loss: 136.872 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 1110/4776 | Loss: 173.050 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1120/4776 | Loss: 197.723 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1130/4776 | Loss: 173.869 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1140/4776 | Loss: 142.625 | Accuracy: 0.700\n",
      "[Epoch: 34/200] - Step: 1150/4776 | Loss: 265.031 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1160/4776 | Loss: 141.345 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1170/4776 | Loss: 219.308 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1180/4776 | Loss: 235.716 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1190/4776 | Loss: 190.881 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1200/4776 | Loss: 229.661 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1210/4776 | Loss: 176.208 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1220/4776 | Loss: 179.993 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1230/4776 | Loss: 190.656 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1240/4776 | Loss: 166.537 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1250/4776 | Loss: 164.986 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1260/4776 | Loss: 176.503 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1270/4776 | Loss: 172.149 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1280/4776 | Loss: 161.272 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1290/4776 | Loss: 183.780 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1300/4776 | Loss: 197.529 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1310/4776 | Loss: 166.253 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1320/4776 | Loss: 133.407 | Accuracy: 0.700\n",
      "[Epoch: 34/200] - Step: 1330/4776 | Loss: 163.545 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1340/4776 | Loss: 205.948 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1350/4776 | Loss: 182.886 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1360/4776 | Loss: 215.117 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1370/4776 | Loss: 206.001 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1380/4776 | Loss: 160.466 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1390/4776 | Loss: 180.079 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1400/4776 | Loss: 213.941 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1410/4776 | Loss: 247.187 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1420/4776 | Loss: 205.171 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1430/4776 | Loss: 161.955 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1440/4776 | Loss: 210.168 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1450/4776 | Loss: 127.857 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 1460/4776 | Loss: 205.751 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1470/4776 | Loss: 193.093 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1480/4776 | Loss: 190.900 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1490/4776 | Loss: 206.956 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1500/4776 | Loss: 204.541 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1510/4776 | Loss: 184.040 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1520/4776 | Loss: 174.339 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1530/4776 | Loss: 150.700 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1540/4776 | Loss: 181.337 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1550/4776 | Loss: 162.453 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 1560/4776 | Loss: 162.399 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1570/4776 | Loss: 182.529 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1580/4776 | Loss: 201.577 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1590/4776 | Loss: 179.369 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1600/4776 | Loss: 230.336 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1610/4776 | Loss: 170.661 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1620/4776 | Loss: 158.338 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1630/4776 | Loss: 184.779 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1640/4776 | Loss: 174.324 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1650/4776 | Loss: 230.783 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1660/4776 | Loss: 191.236 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1670/4776 | Loss: 178.132 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1680/4776 | Loss: 179.027 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1690/4776 | Loss: 196.441 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1700/4776 | Loss: 176.474 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1710/4776 | Loss: 198.274 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1720/4776 | Loss: 207.908 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1730/4776 | Loss: 180.345 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1740/4776 | Loss: 151.724 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1750/4776 | Loss: 157.101 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1760/4776 | Loss: 187.626 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1770/4776 | Loss: 194.210 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1780/4776 | Loss: 141.482 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1790/4776 | Loss: 171.105 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1800/4776 | Loss: 148.732 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1810/4776 | Loss: 170.309 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1820/4776 | Loss: 161.778 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1830/4776 | Loss: 212.945 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1840/4776 | Loss: 184.744 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1850/4776 | Loss: 178.624 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1860/4776 | Loss: 154.591 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1870/4776 | Loss: 143.525 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1880/4776 | Loss: 180.456 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1890/4776 | Loss: 193.796 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1900/4776 | Loss: 151.311 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 1910/4776 | Loss: 266.917 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1920/4776 | Loss: 144.891 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1930/4776 | Loss: 185.038 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1940/4776 | Loss: 172.836 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1950/4776 | Loss: 161.861 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1960/4776 | Loss: 200.180 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1970/4776 | Loss: 254.301 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1980/4776 | Loss: 168.521 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 1990/4776 | Loss: 173.120 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2000/4776 | Loss: 150.199 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2010/4776 | Loss: 135.117 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2020/4776 | Loss: 178.574 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2030/4776 | Loss: 194.870 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2040/4776 | Loss: 151.393 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2050/4776 | Loss: 109.915 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 2060/4776 | Loss: 173.035 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 2070/4776 | Loss: 231.843 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2080/4776 | Loss: 160.201 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2090/4776 | Loss: 199.606 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2100/4776 | Loss: 171.480 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2110/4776 | Loss: 161.712 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2120/4776 | Loss: 161.549 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 2130/4776 | Loss: 206.920 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2140/4776 | Loss: 164.142 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2150/4776 | Loss: 178.529 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2160/4776 | Loss: 193.745 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2170/4776 | Loss: 155.885 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2180/4776 | Loss: 158.042 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2190/4776 | Loss: 185.853 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2200/4776 | Loss: 168.613 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2210/4776 | Loss: 196.546 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 2220/4776 | Loss: 152.590 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2230/4776 | Loss: 148.207 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2240/4776 | Loss: 171.018 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2250/4776 | Loss: 154.109 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2260/4776 | Loss: 137.980 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2270/4776 | Loss: 136.582 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2280/4776 | Loss: 204.078 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2290/4776 | Loss: 155.516 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2300/4776 | Loss: 166.060 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2310/4776 | Loss: 205.084 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2320/4776 | Loss: 194.174 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2330/4776 | Loss: 167.447 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2340/4776 | Loss: 160.540 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2350/4776 | Loss: 225.530 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2360/4776 | Loss: 223.305 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2370/4776 | Loss: 186.491 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2380/4776 | Loss: 174.450 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2390/4776 | Loss: 215.892 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2400/4776 | Loss: 181.547 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2410/4776 | Loss: 191.787 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2420/4776 | Loss: 167.019 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2430/4776 | Loss: 187.425 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2440/4776 | Loss: 187.536 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2450/4776 | Loss: 202.212 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2460/4776 | Loss: 280.312 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2470/4776 | Loss: 116.711 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 2480/4776 | Loss: 231.588 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2490/4776 | Loss: 195.554 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2500/4776 | Loss: 152.665 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2510/4776 | Loss: 189.279 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2520/4776 | Loss: 188.142 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2530/4776 | Loss: 167.000 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2540/4776 | Loss: 163.507 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2550/4776 | Loss: 176.332 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2560/4776 | Loss: 165.668 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2570/4776 | Loss: 203.429 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 2580/4776 | Loss: 205.447 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2590/4776 | Loss: 113.520 | Accuracy: 0.700\n",
      "[Epoch: 34/200] - Step: 2600/4776 | Loss: 142.420 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2610/4776 | Loss: 165.116 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2620/4776 | Loss: 221.332 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2630/4776 | Loss: 172.495 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2640/4776 | Loss: 202.724 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2650/4776 | Loss: 192.341 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2660/4776 | Loss: 177.335 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2670/4776 | Loss: 174.256 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2680/4776 | Loss: 192.516 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2690/4776 | Loss: 180.241 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2700/4776 | Loss: 151.065 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2710/4776 | Loss: 153.472 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2720/4776 | Loss: 175.204 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2730/4776 | Loss: 175.855 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2740/4776 | Loss: 183.674 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2750/4776 | Loss: 139.034 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2760/4776 | Loss: 157.934 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2770/4776 | Loss: 153.383 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 2780/4776 | Loss: 170.730 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2790/4776 | Loss: 193.669 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2800/4776 | Loss: 225.654 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2810/4776 | Loss: 206.058 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2820/4776 | Loss: 252.853 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2830/4776 | Loss: 178.996 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2840/4776 | Loss: 188.149 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2850/4776 | Loss: 188.414 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2860/4776 | Loss: 178.458 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2870/4776 | Loss: 160.752 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 2880/4776 | Loss: 197.659 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2890/4776 | Loss: 169.752 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2900/4776 | Loss: 202.810 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 2910/4776 | Loss: 182.127 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2920/4776 | Loss: 140.835 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 2930/4776 | Loss: 199.859 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2940/4776 | Loss: 132.975 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2950/4776 | Loss: 175.420 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2960/4776 | Loss: 215.606 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2970/4776 | Loss: 204.467 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 2980/4776 | Loss: 183.550 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 2990/4776 | Loss: 176.476 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3000/4776 | Loss: 181.650 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3010/4776 | Loss: 170.734 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3020/4776 | Loss: 202.139 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3030/4776 | Loss: 181.369 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3040/4776 | Loss: 147.845 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3050/4776 | Loss: 132.552 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3060/4776 | Loss: 152.925 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3070/4776 | Loss: 171.920 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3080/4776 | Loss: 215.354 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3090/4776 | Loss: 198.801 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3100/4776 | Loss: 163.884 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3110/4776 | Loss: 195.756 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3120/4776 | Loss: 191.621 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3130/4776 | Loss: 140.427 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3140/4776 | Loss: 150.880 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3150/4776 | Loss: 198.076 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3160/4776 | Loss: 148.519 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3170/4776 | Loss: 139.461 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3180/4776 | Loss: 165.559 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3190/4776 | Loss: 201.330 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3200/4776 | Loss: 178.970 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3210/4776 | Loss: 136.117 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3220/4776 | Loss: 149.824 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3230/4776 | Loss: 156.242 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3240/4776 | Loss: 169.023 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3250/4776 | Loss: 213.391 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3260/4776 | Loss: 179.395 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3270/4776 | Loss: 153.277 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3280/4776 | Loss: 148.132 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3290/4776 | Loss: 159.584 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3300/4776 | Loss: 164.737 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3310/4776 | Loss: 148.470 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3320/4776 | Loss: 131.996 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3330/4776 | Loss: 173.837 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3340/4776 | Loss: 209.350 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3350/4776 | Loss: 158.810 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3360/4776 | Loss: 144.276 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3370/4776 | Loss: 172.665 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3380/4776 | Loss: 254.662 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3390/4776 | Loss: 157.110 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3400/4776 | Loss: 178.122 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3410/4776 | Loss: 165.579 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3420/4776 | Loss: 143.059 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3430/4776 | Loss: 153.166 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3440/4776 | Loss: 187.515 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3450/4776 | Loss: 215.261 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3460/4776 | Loss: 129.997 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3470/4776 | Loss: 214.981 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3480/4776 | Loss: 147.508 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3490/4776 | Loss: 188.496 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3500/4776 | Loss: 174.435 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3510/4776 | Loss: 169.171 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3520/4776 | Loss: 154.068 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3530/4776 | Loss: 159.115 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3540/4776 | Loss: 190.362 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3550/4776 | Loss: 121.275 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3560/4776 | Loss: 198.178 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3570/4776 | Loss: 182.316 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3580/4776 | Loss: 169.473 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3590/4776 | Loss: 167.006 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3600/4776 | Loss: 107.632 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3610/4776 | Loss: 157.022 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3620/4776 | Loss: 152.796 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3630/4776 | Loss: 218.106 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3640/4776 | Loss: 147.860 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3650/4776 | Loss: 202.831 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3660/4776 | Loss: 188.936 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3670/4776 | Loss: 151.457 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3680/4776 | Loss: 211.402 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3690/4776 | Loss: 186.782 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3700/4776 | Loss: 237.371 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3710/4776 | Loss: 164.814 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3720/4776 | Loss: 170.184 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3730/4776 | Loss: 160.298 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3740/4776 | Loss: 166.256 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3750/4776 | Loss: 175.865 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3760/4776 | Loss: 189.068 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3770/4776 | Loss: 202.733 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3780/4776 | Loss: 183.954 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3790/4776 | Loss: 166.274 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3800/4776 | Loss: 168.849 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3810/4776 | Loss: 157.980 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3820/4776 | Loss: 178.386 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3830/4776 | Loss: 177.371 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3840/4776 | Loss: 184.725 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3850/4776 | Loss: 204.908 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3860/4776 | Loss: 164.196 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3870/4776 | Loss: 149.002 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 3880/4776 | Loss: 156.598 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3890/4776 | Loss: 145.436 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3900/4776 | Loss: 183.342 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 3910/4776 | Loss: 183.023 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3920/4776 | Loss: 161.180 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3930/4776 | Loss: 181.623 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3940/4776 | Loss: 205.252 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3950/4776 | Loss: 186.366 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 3960/4776 | Loss: 164.532 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 3970/4776 | Loss: 165.472 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 3980/4776 | Loss: 172.833 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 3990/4776 | Loss: 198.513 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4000/4776 | Loss: 190.141 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4010/4776 | Loss: 160.989 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4020/4776 | Loss: 183.588 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4030/4776 | Loss: 264.173 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4040/4776 | Loss: 160.164 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4050/4776 | Loss: 155.546 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4060/4776 | Loss: 186.402 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4070/4776 | Loss: 218.795 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4080/4776 | Loss: 191.650 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4090/4776 | Loss: 217.562 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4100/4776 | Loss: 168.683 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4110/4776 | Loss: 174.465 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4120/4776 | Loss: 210.804 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4130/4776 | Loss: 200.578 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4140/4776 | Loss: 142.365 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4150/4776 | Loss: 148.818 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4160/4776 | Loss: 179.908 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4170/4776 | Loss: 147.992 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4180/4776 | Loss: 153.012 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4190/4776 | Loss: 150.667 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4200/4776 | Loss: 201.147 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4210/4776 | Loss: 224.367 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4220/4776 | Loss: 148.856 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4230/4776 | Loss: 148.131 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4240/4776 | Loss: 165.837 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4250/4776 | Loss: 196.401 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4260/4776 | Loss: 155.691 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4270/4776 | Loss: 221.325 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4280/4776 | Loss: 176.293 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4290/4776 | Loss: 140.400 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4300/4776 | Loss: 233.113 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4310/4776 | Loss: 150.794 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4320/4776 | Loss: 195.750 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4330/4776 | Loss: 164.680 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4340/4776 | Loss: 212.315 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4350/4776 | Loss: 239.346 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4360/4776 | Loss: 155.979 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4370/4776 | Loss: 178.648 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4380/4776 | Loss: 224.705 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4390/4776 | Loss: 158.604 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 4400/4776 | Loss: 185.102 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4410/4776 | Loss: 200.423 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4420/4776 | Loss: 165.081 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4430/4776 | Loss: 186.175 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4440/4776 | Loss: 181.335 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4450/4776 | Loss: 153.868 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4460/4776 | Loss: 190.289 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4470/4776 | Loss: 178.147 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4480/4776 | Loss: 132.215 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4490/4776 | Loss: 181.943 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4500/4776 | Loss: 195.852 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4510/4776 | Loss: 199.759 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4520/4776 | Loss: 204.307 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4530/4776 | Loss: 192.584 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4540/4776 | Loss: 146.090 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 4550/4776 | Loss: 181.042 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4560/4776 | Loss: 184.953 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4570/4776 | Loss: 131.274 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4580/4776 | Loss: 205.174 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4590/4776 | Loss: 197.620 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4600/4776 | Loss: 152.260 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4610/4776 | Loss: 207.054 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4620/4776 | Loss: 239.208 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4630/4776 | Loss: 166.410 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4640/4776 | Loss: 118.012 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4650/4776 | Loss: 204.552 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4660/4776 | Loss: 186.738 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 4670/4776 | Loss: 177.634 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4680/4776 | Loss: 222.073 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4690/4776 | Loss: 191.148 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4700/4776 | Loss: 164.337 | Accuracy: 0.600\n",
      "[Epoch: 34/200] - Step: 4710/4776 | Loss: 248.298 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4720/4776 | Loss: 189.457 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 4730/4776 | Loss: 176.831 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4740/4776 | Loss: 236.751 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 4750/4776 | Loss: 160.442 | Accuracy: 0.500\n",
      "[Epoch: 34/200] - Step: 4760/4776 | Loss: 212.441 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 4770/4776 | Loss: 211.126 | Accuracy: 0.300\n",
      "Accuracy:  0.1737704918032787\n",
      "[Epoch: 35/200] - Step: 10/4776 | Loss: 210.023 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 20/4776 | Loss: 208.925 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 30/4776 | Loss: 170.507 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 40/4776 | Loss: 158.595 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 50/4776 | Loss: 164.465 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 60/4776 | Loss: 171.496 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 70/4776 | Loss: 109.473 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 80/4776 | Loss: 161.194 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 90/4776 | Loss: 214.842 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 100/4776 | Loss: 144.127 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 110/4776 | Loss: 124.504 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 120/4776 | Loss: 197.262 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 130/4776 | Loss: 185.068 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 140/4776 | Loss: 157.830 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 150/4776 | Loss: 125.959 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 160/4776 | Loss: 139.065 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 170/4776 | Loss: 174.404 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 180/4776 | Loss: 173.518 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 190/4776 | Loss: 201.149 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 200/4776 | Loss: 134.519 | Accuracy: 0.800\n",
      "[Epoch: 35/200] - Step: 210/4776 | Loss: 225.054 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 220/4776 | Loss: 141.369 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 230/4776 | Loss: 195.726 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 240/4776 | Loss: 180.863 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 250/4776 | Loss: 183.698 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 260/4776 | Loss: 191.756 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 270/4776 | Loss: 192.907 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 280/4776 | Loss: 157.002 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 290/4776 | Loss: 205.489 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 300/4776 | Loss: 168.440 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 310/4776 | Loss: 136.617 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 320/4776 | Loss: 166.900 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 330/4776 | Loss: 147.967 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 340/4776 | Loss: 194.824 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 350/4776 | Loss: 142.695 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 360/4776 | Loss: 194.919 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 370/4776 | Loss: 155.882 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 380/4776 | Loss: 184.753 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 390/4776 | Loss: 129.640 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 400/4776 | Loss: 192.671 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 410/4776 | Loss: 224.277 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 420/4776 | Loss: 189.718 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 430/4776 | Loss: 189.008 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 440/4776 | Loss: 180.332 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 450/4776 | Loss: 135.041 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 460/4776 | Loss: 134.581 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 470/4776 | Loss: 232.828 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 480/4776 | Loss: 169.535 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 490/4776 | Loss: 133.988 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 500/4776 | Loss: 167.935 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 510/4776 | Loss: 125.089 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 520/4776 | Loss: 174.207 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 530/4776 | Loss: 217.893 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 540/4776 | Loss: 183.203 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 550/4776 | Loss: 193.139 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 560/4776 | Loss: 142.865 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 570/4776 | Loss: 195.966 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 580/4776 | Loss: 157.833 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 590/4776 | Loss: 161.446 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 600/4776 | Loss: 202.541 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 610/4776 | Loss: 133.409 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 620/4776 | Loss: 213.435 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 630/4776 | Loss: 152.408 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 640/4776 | Loss: 153.393 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 650/4776 | Loss: 163.731 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 660/4776 | Loss: 161.210 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 670/4776 | Loss: 183.334 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 680/4776 | Loss: 178.606 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 690/4776 | Loss: 157.746 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 700/4776 | Loss: 238.924 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 710/4776 | Loss: 181.943 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 720/4776 | Loss: 219.716 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 730/4776 | Loss: 170.369 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 740/4776 | Loss: 183.681 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 750/4776 | Loss: 162.342 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 760/4776 | Loss: 192.987 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 770/4776 | Loss: 178.919 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 780/4776 | Loss: 213.130 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 790/4776 | Loss: 202.655 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 800/4776 | Loss: 157.423 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 810/4776 | Loss: 165.471 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 820/4776 | Loss: 203.854 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 830/4776 | Loss: 189.579 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 840/4776 | Loss: 165.318 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 850/4776 | Loss: 159.506 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 860/4776 | Loss: 186.476 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 870/4776 | Loss: 152.525 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 880/4776 | Loss: 229.209 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 890/4776 | Loss: 177.390 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 900/4776 | Loss: 167.788 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 910/4776 | Loss: 123.293 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 920/4776 | Loss: 207.661 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 930/4776 | Loss: 167.436 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 940/4776 | Loss: 166.958 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 950/4776 | Loss: 148.314 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 960/4776 | Loss: 155.908 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 970/4776 | Loss: 167.451 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 980/4776 | Loss: 174.599 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 990/4776 | Loss: 180.227 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1000/4776 | Loss: 169.494 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1010/4776 | Loss: 128.440 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1020/4776 | Loss: 160.844 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1030/4776 | Loss: 125.286 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1040/4776 | Loss: 158.723 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1050/4776 | Loss: 207.675 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1060/4776 | Loss: 157.711 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1070/4776 | Loss: 185.257 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1080/4776 | Loss: 168.242 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1090/4776 | Loss: 165.375 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1100/4776 | Loss: 133.238 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1110/4776 | Loss: 174.823 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1120/4776 | Loss: 160.834 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1130/4776 | Loss: 157.939 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1140/4776 | Loss: 197.293 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1150/4776 | Loss: 170.785 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1160/4776 | Loss: 146.445 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1170/4776 | Loss: 186.182 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1180/4776 | Loss: 158.391 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1190/4776 | Loss: 203.070 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1200/4776 | Loss: 169.152 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1210/4776 | Loss: 196.883 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1220/4776 | Loss: 164.690 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1230/4776 | Loss: 151.195 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1240/4776 | Loss: 220.970 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1250/4776 | Loss: 164.683 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1260/4776 | Loss: 176.049 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1270/4776 | Loss: 153.402 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1280/4776 | Loss: 185.654 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1290/4776 | Loss: 117.425 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1300/4776 | Loss: 201.273 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1310/4776 | Loss: 212.327 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1320/4776 | Loss: 155.642 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1330/4776 | Loss: 205.182 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1340/4776 | Loss: 216.185 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1350/4776 | Loss: 153.313 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1360/4776 | Loss: 140.275 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1370/4776 | Loss: 132.786 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1380/4776 | Loss: 120.254 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1390/4776 | Loss: 161.578 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1400/4776 | Loss: 151.181 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1410/4776 | Loss: 208.959 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1420/4776 | Loss: 166.674 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1430/4776 | Loss: 173.323 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1440/4776 | Loss: 156.128 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1450/4776 | Loss: 201.632 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1460/4776 | Loss: 115.329 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1470/4776 | Loss: 200.953 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1480/4776 | Loss: 200.204 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1490/4776 | Loss: 165.519 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1500/4776 | Loss: 170.501 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1510/4776 | Loss: 170.690 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1520/4776 | Loss: 174.914 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1530/4776 | Loss: 186.675 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1540/4776 | Loss: 217.223 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1550/4776 | Loss: 228.556 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1560/4776 | Loss: 150.120 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1570/4776 | Loss: 215.210 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1580/4776 | Loss: 177.224 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1590/4776 | Loss: 140.140 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1600/4776 | Loss: 144.946 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1610/4776 | Loss: 173.326 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1620/4776 | Loss: 198.102 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1630/4776 | Loss: 174.885 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1640/4776 | Loss: 150.404 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1650/4776 | Loss: 189.074 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1660/4776 | Loss: 130.197 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1670/4776 | Loss: 156.174 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1680/4776 | Loss: 200.756 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1690/4776 | Loss: 137.386 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1700/4776 | Loss: 150.507 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1710/4776 | Loss: 180.582 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1720/4776 | Loss: 151.629 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1730/4776 | Loss: 142.027 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1740/4776 | Loss: 202.769 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1750/4776 | Loss: 195.830 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1760/4776 | Loss: 163.991 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1770/4776 | Loss: 232.781 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1780/4776 | Loss: 191.770 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1790/4776 | Loss: 171.632 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1800/4776 | Loss: 127.305 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1810/4776 | Loss: 262.601 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1820/4776 | Loss: 192.054 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1830/4776 | Loss: 181.345 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 1840/4776 | Loss: 152.545 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1850/4776 | Loss: 181.812 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1860/4776 | Loss: 215.967 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1870/4776 | Loss: 127.057 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1880/4776 | Loss: 148.261 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1890/4776 | Loss: 201.169 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1900/4776 | Loss: 153.227 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1910/4776 | Loss: 189.997 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1920/4776 | Loss: 164.460 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1930/4776 | Loss: 156.918 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 1940/4776 | Loss: 162.297 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 1950/4776 | Loss: 148.894 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1960/4776 | Loss: 197.572 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1970/4776 | Loss: 191.155 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1980/4776 | Loss: 177.403 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 1990/4776 | Loss: 132.453 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2000/4776 | Loss: 178.075 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2010/4776 | Loss: 82.014 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 2020/4776 | Loss: 218.756 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2030/4776 | Loss: 188.761 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2040/4776 | Loss: 182.816 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2050/4776 | Loss: 182.712 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2060/4776 | Loss: 185.465 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2070/4776 | Loss: 180.932 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2080/4776 | Loss: 152.849 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2090/4776 | Loss: 190.094 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2100/4776 | Loss: 124.772 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 2110/4776 | Loss: 178.753 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2120/4776 | Loss: 170.941 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2130/4776 | Loss: 224.603 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2140/4776 | Loss: 181.335 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2150/4776 | Loss: 193.591 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2160/4776 | Loss: 248.223 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2170/4776 | Loss: 243.587 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2180/4776 | Loss: 192.175 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2190/4776 | Loss: 145.576 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2200/4776 | Loss: 191.170 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2210/4776 | Loss: 184.432 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2220/4776 | Loss: 195.119 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2230/4776 | Loss: 216.224 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2240/4776 | Loss: 239.216 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2250/4776 | Loss: 151.949 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2260/4776 | Loss: 192.780 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2270/4776 | Loss: 174.945 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2280/4776 | Loss: 179.497 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2290/4776 | Loss: 164.284 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2300/4776 | Loss: 151.928 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2310/4776 | Loss: 156.037 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2320/4776 | Loss: 199.679 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2330/4776 | Loss: 296.047 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2340/4776 | Loss: 168.293 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2350/4776 | Loss: 207.530 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2360/4776 | Loss: 169.725 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2370/4776 | Loss: 198.592 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2380/4776 | Loss: 172.132 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2390/4776 | Loss: 174.085 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2400/4776 | Loss: 169.782 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2410/4776 | Loss: 199.352 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2420/4776 | Loss: 203.592 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2430/4776 | Loss: 165.470 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2440/4776 | Loss: 152.158 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2450/4776 | Loss: 158.160 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2460/4776 | Loss: 173.200 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2470/4776 | Loss: 160.531 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2480/4776 | Loss: 187.109 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2490/4776 | Loss: 201.122 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2500/4776 | Loss: 190.807 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2510/4776 | Loss: 163.863 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2520/4776 | Loss: 165.474 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2530/4776 | Loss: 115.932 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 2540/4776 | Loss: 170.554 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2550/4776 | Loss: 193.918 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2560/4776 | Loss: 138.693 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2570/4776 | Loss: 174.883 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2580/4776 | Loss: 156.796 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2590/4776 | Loss: 151.986 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2600/4776 | Loss: 135.143 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 2610/4776 | Loss: 141.161 | Accuracy: 0.800\n",
      "[Epoch: 35/200] - Step: 2620/4776 | Loss: 194.817 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2630/4776 | Loss: 195.241 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2640/4776 | Loss: 153.671 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2650/4776 | Loss: 163.330 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2660/4776 | Loss: 162.911 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2670/4776 | Loss: 182.262 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2680/4776 | Loss: 150.394 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2690/4776 | Loss: 152.170 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2700/4776 | Loss: 262.480 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2710/4776 | Loss: 167.385 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2720/4776 | Loss: 232.593 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2730/4776 | Loss: 214.244 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2740/4776 | Loss: 168.938 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2750/4776 | Loss: 200.107 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2760/4776 | Loss: 176.715 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2770/4776 | Loss: 136.812 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2780/4776 | Loss: 175.060 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2790/4776 | Loss: 195.903 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2800/4776 | Loss: 198.915 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2810/4776 | Loss: 151.948 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2820/4776 | Loss: 188.334 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2830/4776 | Loss: 211.951 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2840/4776 | Loss: 134.390 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2850/4776 | Loss: 208.378 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 2860/4776 | Loss: 176.791 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2870/4776 | Loss: 177.858 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2880/4776 | Loss: 157.989 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 2890/4776 | Loss: 149.258 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 2900/4776 | Loss: 164.125 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2910/4776 | Loss: 188.800 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 2920/4776 | Loss: 165.480 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2930/4776 | Loss: 138.962 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 2940/4776 | Loss: 168.381 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2950/4776 | Loss: 139.421 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2960/4776 | Loss: 112.585 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 2970/4776 | Loss: 173.885 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 2980/4776 | Loss: 241.972 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 2990/4776 | Loss: 164.513 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3000/4776 | Loss: 148.629 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3010/4776 | Loss: 170.308 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3020/4776 | Loss: 246.834 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 3030/4776 | Loss: 203.395 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3040/4776 | Loss: 209.329 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3050/4776 | Loss: 188.668 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3060/4776 | Loss: 161.818 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3070/4776 | Loss: 190.243 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3080/4776 | Loss: 168.606 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3090/4776 | Loss: 213.037 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3100/4776 | Loss: 172.167 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3110/4776 | Loss: 112.523 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 3120/4776 | Loss: 159.884 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3130/4776 | Loss: 167.819 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3140/4776 | Loss: 153.582 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3150/4776 | Loss: 151.097 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3160/4776 | Loss: 152.084 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3170/4776 | Loss: 142.293 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3180/4776 | Loss: 165.635 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3190/4776 | Loss: 131.171 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3200/4776 | Loss: 208.004 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3210/4776 | Loss: 167.268 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3220/4776 | Loss: 133.494 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 3230/4776 | Loss: 160.710 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3240/4776 | Loss: 167.221 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3250/4776 | Loss: 169.358 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3260/4776 | Loss: 160.863 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3270/4776 | Loss: 171.667 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3280/4776 | Loss: 174.037 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3290/4776 | Loss: 208.719 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3300/4776 | Loss: 170.164 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3310/4776 | Loss: 175.543 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3320/4776 | Loss: 127.682 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3330/4776 | Loss: 133.053 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3340/4776 | Loss: 161.649 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3350/4776 | Loss: 152.491 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3360/4776 | Loss: 151.820 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3370/4776 | Loss: 222.806 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3380/4776 | Loss: 153.651 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3390/4776 | Loss: 155.522 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3400/4776 | Loss: 116.700 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3410/4776 | Loss: 132.161 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3420/4776 | Loss: 216.497 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3430/4776 | Loss: 156.188 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3440/4776 | Loss: 112.776 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3450/4776 | Loss: 146.350 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3460/4776 | Loss: 223.329 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3470/4776 | Loss: 172.107 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3480/4776 | Loss: 163.630 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3490/4776 | Loss: 130.159 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3500/4776 | Loss: 157.225 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3510/4776 | Loss: 133.469 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3520/4776 | Loss: 127.602 | Accuracy: 0.800\n",
      "[Epoch: 35/200] - Step: 3530/4776 | Loss: 175.865 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3540/4776 | Loss: 162.658 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3550/4776 | Loss: 182.244 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 3560/4776 | Loss: 220.943 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3570/4776 | Loss: 188.603 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3580/4776 | Loss: 217.908 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3590/4776 | Loss: 195.104 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3600/4776 | Loss: 184.393 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3610/4776 | Loss: 186.460 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3620/4776 | Loss: 151.370 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3630/4776 | Loss: 171.341 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3640/4776 | Loss: 154.661 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3650/4776 | Loss: 176.253 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3660/4776 | Loss: 169.255 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3670/4776 | Loss: 135.499 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3680/4776 | Loss: 145.030 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3690/4776 | Loss: 191.614 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3700/4776 | Loss: 188.782 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3710/4776 | Loss: 195.774 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3720/4776 | Loss: 156.639 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3730/4776 | Loss: 172.375 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3740/4776 | Loss: 168.108 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3750/4776 | Loss: 108.213 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 3760/4776 | Loss: 164.172 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3770/4776 | Loss: 215.989 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3780/4776 | Loss: 174.283 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3790/4776 | Loss: 201.978 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3800/4776 | Loss: 175.342 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3810/4776 | Loss: 214.703 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3820/4776 | Loss: 195.061 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3830/4776 | Loss: 231.995 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3840/4776 | Loss: 138.509 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3850/4776 | Loss: 153.633 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 3860/4776 | Loss: 174.766 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3870/4776 | Loss: 179.806 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3880/4776 | Loss: 150.386 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3890/4776 | Loss: 202.627 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3900/4776 | Loss: 220.214 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 3910/4776 | Loss: 193.907 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3920/4776 | Loss: 187.721 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3930/4776 | Loss: 215.512 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3940/4776 | Loss: 159.756 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 3950/4776 | Loss: 169.237 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 3960/4776 | Loss: 161.430 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 3970/4776 | Loss: 205.025 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3980/4776 | Loss: 190.673 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 3990/4776 | Loss: 198.450 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4000/4776 | Loss: 148.290 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4010/4776 | Loss: 163.531 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 4020/4776 | Loss: 188.648 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4030/4776 | Loss: 183.099 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4040/4776 | Loss: 104.809 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 4050/4776 | Loss: 164.835 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4060/4776 | Loss: 210.551 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4070/4776 | Loss: 155.009 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4080/4776 | Loss: 97.028 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4090/4776 | Loss: 185.100 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4100/4776 | Loss: 194.971 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4110/4776 | Loss: 145.846 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4120/4776 | Loss: 153.037 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4130/4776 | Loss: 156.852 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 4140/4776 | Loss: 172.914 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4150/4776 | Loss: 122.599 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4160/4776 | Loss: 154.961 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4170/4776 | Loss: 180.866 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4180/4776 | Loss: 212.521 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 4190/4776 | Loss: 188.411 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4200/4776 | Loss: 197.711 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 4210/4776 | Loss: 152.369 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4220/4776 | Loss: 134.750 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4230/4776 | Loss: 180.559 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4240/4776 | Loss: 147.949 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4250/4776 | Loss: 180.266 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4260/4776 | Loss: 170.550 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4270/4776 | Loss: 192.551 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4280/4776 | Loss: 162.064 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4290/4776 | Loss: 171.234 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4300/4776 | Loss: 156.359 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4310/4776 | Loss: 150.432 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 4320/4776 | Loss: 149.766 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4330/4776 | Loss: 165.365 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4340/4776 | Loss: 164.245 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4350/4776 | Loss: 156.285 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4360/4776 | Loss: 166.284 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4370/4776 | Loss: 161.100 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4380/4776 | Loss: 219.125 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4390/4776 | Loss: 204.002 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4400/4776 | Loss: 152.739 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4410/4776 | Loss: 174.870 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4420/4776 | Loss: 234.066 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4430/4776 | Loss: 186.189 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4440/4776 | Loss: 162.425 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4450/4776 | Loss: 165.356 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4460/4776 | Loss: 188.375 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4470/4776 | Loss: 195.478 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4480/4776 | Loss: 223.600 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4490/4776 | Loss: 154.590 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4500/4776 | Loss: 222.514 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4510/4776 | Loss: 176.373 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4520/4776 | Loss: 132.170 | Accuracy: 0.700\n",
      "[Epoch: 35/200] - Step: 4530/4776 | Loss: 154.873 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4540/4776 | Loss: 145.270 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4550/4776 | Loss: 176.818 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4560/4776 | Loss: 124.677 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4570/4776 | Loss: 126.996 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4580/4776 | Loss: 181.115 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4590/4776 | Loss: 187.726 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4600/4776 | Loss: 152.917 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4610/4776 | Loss: 210.051 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 4620/4776 | Loss: 140.908 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4630/4776 | Loss: 186.014 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4640/4776 | Loss: 145.349 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4650/4776 | Loss: 152.426 | Accuracy: 0.500\n",
      "[Epoch: 35/200] - Step: 4660/4776 | Loss: 148.793 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4670/4776 | Loss: 149.533 | Accuracy: 0.600\n",
      "[Epoch: 35/200] - Step: 4680/4776 | Loss: 137.590 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4690/4776 | Loss: 169.864 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4700/4776 | Loss: 183.313 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4710/4776 | Loss: 150.402 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4720/4776 | Loss: 194.270 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 4730/4776 | Loss: 177.299 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 4740/4776 | Loss: 218.579 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4750/4776 | Loss: 160.640 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4760/4776 | Loss: 161.585 | Accuracy: 0.400\n",
      "[Epoch: 35/200] - Step: 4770/4776 | Loss: 181.390 | Accuracy: 0.200\n",
      "Accuracy:  0.18688524590163935\n",
      "[Epoch: 36/200] - Step: 10/4776 | Loss: 130.886 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 20/4776 | Loss: 149.480 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 30/4776 | Loss: 208.436 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 40/4776 | Loss: 170.198 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 50/4776 | Loss: 190.115 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 60/4776 | Loss: 208.097 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 70/4776 | Loss: 172.368 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 80/4776 | Loss: 155.194 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 90/4776 | Loss: 187.129 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 100/4776 | Loss: 165.706 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 110/4776 | Loss: 150.268 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 120/4776 | Loss: 134.665 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 130/4776 | Loss: 127.224 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 140/4776 | Loss: 153.147 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 150/4776 | Loss: 143.372 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 160/4776 | Loss: 164.710 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 170/4776 | Loss: 200.821 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 180/4776 | Loss: 151.111 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 190/4776 | Loss: 150.086 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 200/4776 | Loss: 184.506 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 210/4776 | Loss: 128.870 | Accuracy: 0.800\n",
      "[Epoch: 36/200] - Step: 220/4776 | Loss: 122.712 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 230/4776 | Loss: 199.937 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 240/4776 | Loss: 151.341 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 250/4776 | Loss: 109.657 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 260/4776 | Loss: 176.904 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 270/4776 | Loss: 160.633 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 280/4776 | Loss: 145.140 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 290/4776 | Loss: 158.055 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 300/4776 | Loss: 140.980 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 310/4776 | Loss: 170.530 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 320/4776 | Loss: 150.589 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 330/4776 | Loss: 187.137 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 340/4776 | Loss: 173.461 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 350/4776 | Loss: 187.242 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 360/4776 | Loss: 160.610 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 370/4776 | Loss: 205.777 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 380/4776 | Loss: 132.014 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 390/4776 | Loss: 162.608 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 400/4776 | Loss: 204.542 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 410/4776 | Loss: 179.159 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 420/4776 | Loss: 146.002 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 430/4776 | Loss: 189.190 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 440/4776 | Loss: 176.656 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 450/4776 | Loss: 229.870 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 460/4776 | Loss: 220.074 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 470/4776 | Loss: 226.489 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 480/4776 | Loss: 183.113 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 490/4776 | Loss: 165.976 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 500/4776 | Loss: 183.365 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 510/4776 | Loss: 171.058 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 520/4776 | Loss: 153.656 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 530/4776 | Loss: 177.496 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 540/4776 | Loss: 171.741 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 550/4776 | Loss: 166.952 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 560/4776 | Loss: 179.665 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 570/4776 | Loss: 207.947 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 580/4776 | Loss: 120.080 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 590/4776 | Loss: 155.632 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 600/4776 | Loss: 131.521 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 610/4776 | Loss: 207.923 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 620/4776 | Loss: 167.133 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 630/4776 | Loss: 237.010 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 640/4776 | Loss: 148.996 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 650/4776 | Loss: 151.651 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 660/4776 | Loss: 157.573 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 670/4776 | Loss: 139.024 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 680/4776 | Loss: 156.950 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 690/4776 | Loss: 187.429 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 700/4776 | Loss: 164.908 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 710/4776 | Loss: 192.820 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 720/4776 | Loss: 146.041 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 730/4776 | Loss: 152.273 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 740/4776 | Loss: 162.898 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 750/4776 | Loss: 193.049 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 760/4776 | Loss: 195.316 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 770/4776 | Loss: 132.553 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 780/4776 | Loss: 166.007 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 790/4776 | Loss: 170.474 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 800/4776 | Loss: 157.390 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 810/4776 | Loss: 229.692 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 820/4776 | Loss: 171.825 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 830/4776 | Loss: 172.266 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 840/4776 | Loss: 236.165 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 850/4776 | Loss: 174.143 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 860/4776 | Loss: 133.648 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 870/4776 | Loss: 183.152 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 880/4776 | Loss: 142.863 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 890/4776 | Loss: 175.599 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 900/4776 | Loss: 203.715 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 910/4776 | Loss: 132.114 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 920/4776 | Loss: 184.558 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 930/4776 | Loss: 178.530 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 940/4776 | Loss: 232.263 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 950/4776 | Loss: 157.946 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 960/4776 | Loss: 202.168 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 970/4776 | Loss: 203.861 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 980/4776 | Loss: 169.275 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 990/4776 | Loss: 170.208 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1000/4776 | Loss: 184.705 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1010/4776 | Loss: 114.431 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1020/4776 | Loss: 234.227 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1030/4776 | Loss: 158.248 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1040/4776 | Loss: 174.564 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1050/4776 | Loss: 169.995 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1060/4776 | Loss: 155.148 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1070/4776 | Loss: 173.056 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1080/4776 | Loss: 155.825 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1090/4776 | Loss: 176.091 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1100/4776 | Loss: 139.417 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1110/4776 | Loss: 175.286 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1120/4776 | Loss: 167.804 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1130/4776 | Loss: 119.157 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 1140/4776 | Loss: 180.800 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1150/4776 | Loss: 215.674 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1160/4776 | Loss: 254.449 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1170/4776 | Loss: 140.604 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1180/4776 | Loss: 154.301 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1190/4776 | Loss: 159.228 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1200/4776 | Loss: 125.530 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1210/4776 | Loss: 168.459 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1220/4776 | Loss: 144.441 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1230/4776 | Loss: 194.631 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1240/4776 | Loss: 182.519 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1250/4776 | Loss: 125.055 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1260/4776 | Loss: 174.515 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1270/4776 | Loss: 230.917 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1280/4776 | Loss: 167.971 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1290/4776 | Loss: 164.743 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1300/4776 | Loss: 160.896 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1310/4776 | Loss: 176.778 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1320/4776 | Loss: 127.314 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1330/4776 | Loss: 157.284 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1340/4776 | Loss: 153.616 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1350/4776 | Loss: 175.579 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1360/4776 | Loss: 177.931 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1370/4776 | Loss: 136.066 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1380/4776 | Loss: 117.523 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 1390/4776 | Loss: 141.938 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1400/4776 | Loss: 193.180 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1410/4776 | Loss: 160.157 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1420/4776 | Loss: 170.158 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1430/4776 | Loss: 218.058 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1440/4776 | Loss: 215.156 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1450/4776 | Loss: 217.872 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 1460/4776 | Loss: 159.571 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1470/4776 | Loss: 144.316 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1480/4776 | Loss: 139.442 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1490/4776 | Loss: 184.530 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1500/4776 | Loss: 155.830 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1510/4776 | Loss: 136.056 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1520/4776 | Loss: 194.787 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1530/4776 | Loss: 207.605 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1540/4776 | Loss: 147.333 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1550/4776 | Loss: 125.559 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1560/4776 | Loss: 126.901 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 1570/4776 | Loss: 129.817 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1580/4776 | Loss: 136.952 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1590/4776 | Loss: 107.123 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 1600/4776 | Loss: 183.633 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1610/4776 | Loss: 149.266 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1620/4776 | Loss: 194.196 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1630/4776 | Loss: 179.957 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1640/4776 | Loss: 131.634 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1650/4776 | Loss: 172.590 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1660/4776 | Loss: 157.531 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1670/4776 | Loss: 160.710 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1680/4776 | Loss: 152.214 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1690/4776 | Loss: 195.126 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1700/4776 | Loss: 161.656 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1710/4776 | Loss: 179.105 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1720/4776 | Loss: 162.087 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1730/4776 | Loss: 156.230 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1740/4776 | Loss: 206.427 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1750/4776 | Loss: 220.400 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1760/4776 | Loss: 143.575 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1770/4776 | Loss: 140.354 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1780/4776 | Loss: 166.934 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 1790/4776 | Loss: 209.496 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1800/4776 | Loss: 143.577 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1810/4776 | Loss: 155.515 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1820/4776 | Loss: 156.272 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1830/4776 | Loss: 171.979 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1840/4776 | Loss: 151.873 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1850/4776 | Loss: 171.212 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1860/4776 | Loss: 210.066 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1870/4776 | Loss: 144.679 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 1880/4776 | Loss: 98.687 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 1890/4776 | Loss: 197.226 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1900/4776 | Loss: 145.847 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1910/4776 | Loss: 135.969 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1920/4776 | Loss: 147.930 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1930/4776 | Loss: 124.572 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 1940/4776 | Loss: 243.380 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1950/4776 | Loss: 194.438 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1960/4776 | Loss: 179.753 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1970/4776 | Loss: 199.748 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1980/4776 | Loss: 182.919 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1990/4776 | Loss: 148.288 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2000/4776 | Loss: 193.962 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2010/4776 | Loss: 155.759 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2020/4776 | Loss: 147.460 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2030/4776 | Loss: 135.869 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2040/4776 | Loss: 147.218 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2050/4776 | Loss: 136.993 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2060/4776 | Loss: 150.641 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2070/4776 | Loss: 166.104 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2080/4776 | Loss: 182.763 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2090/4776 | Loss: 198.382 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2100/4776 | Loss: 194.503 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2110/4776 | Loss: 145.701 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2120/4776 | Loss: 207.441 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2130/4776 | Loss: 176.751 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2140/4776 | Loss: 189.689 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2150/4776 | Loss: 157.872 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2160/4776 | Loss: 224.553 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2170/4776 | Loss: 182.135 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2180/4776 | Loss: 168.179 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2190/4776 | Loss: 184.627 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2200/4776 | Loss: 175.923 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2210/4776 | Loss: 159.176 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2220/4776 | Loss: 162.646 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2230/4776 | Loss: 166.080 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2240/4776 | Loss: 195.966 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 2250/4776 | Loss: 178.825 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2260/4776 | Loss: 117.768 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 2270/4776 | Loss: 187.455 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2280/4776 | Loss: 179.073 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2290/4776 | Loss: 163.262 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2300/4776 | Loss: 196.434 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2310/4776 | Loss: 177.441 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2320/4776 | Loss: 144.962 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2330/4776 | Loss: 224.543 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2340/4776 | Loss: 168.135 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2350/4776 | Loss: 164.722 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 2360/4776 | Loss: 129.804 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2370/4776 | Loss: 142.120 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2380/4776 | Loss: 168.627 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2390/4776 | Loss: 160.714 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2400/4776 | Loss: 178.188 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2410/4776 | Loss: 156.875 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2420/4776 | Loss: 194.000 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2430/4776 | Loss: 172.056 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2440/4776 | Loss: 210.486 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2450/4776 | Loss: 160.047 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2460/4776 | Loss: 227.325 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2470/4776 | Loss: 252.890 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2480/4776 | Loss: 152.053 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2490/4776 | Loss: 180.618 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2500/4776 | Loss: 139.041 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2510/4776 | Loss: 192.560 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2520/4776 | Loss: 182.704 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2530/4776 | Loss: 162.448 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2540/4776 | Loss: 171.020 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2550/4776 | Loss: 212.425 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2560/4776 | Loss: 172.518 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2570/4776 | Loss: 163.616 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2580/4776 | Loss: 187.167 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2590/4776 | Loss: 165.837 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2600/4776 | Loss: 213.728 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2610/4776 | Loss: 153.115 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2620/4776 | Loss: 193.818 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2630/4776 | Loss: 189.962 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2640/4776 | Loss: 171.391 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2650/4776 | Loss: 147.341 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2660/4776 | Loss: 171.445 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2670/4776 | Loss: 186.244 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2680/4776 | Loss: 183.405 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2690/4776 | Loss: 152.924 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2700/4776 | Loss: 129.241 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 2710/4776 | Loss: 147.797 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2720/4776 | Loss: 153.946 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2730/4776 | Loss: 190.298 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2740/4776 | Loss: 170.646 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2750/4776 | Loss: 196.774 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2760/4776 | Loss: 161.939 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2770/4776 | Loss: 203.683 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2780/4776 | Loss: 174.133 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2790/4776 | Loss: 156.890 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2800/4776 | Loss: 201.917 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2810/4776 | Loss: 185.302 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2820/4776 | Loss: 174.501 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2830/4776 | Loss: 209.393 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2840/4776 | Loss: 207.397 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2850/4776 | Loss: 145.426 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2860/4776 | Loss: 146.519 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2870/4776 | Loss: 207.869 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2880/4776 | Loss: 178.408 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2890/4776 | Loss: 162.708 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2900/4776 | Loss: 176.403 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 2910/4776 | Loss: 183.973 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2920/4776 | Loss: 168.986 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2930/4776 | Loss: 136.765 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 2940/4776 | Loss: 162.117 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 2950/4776 | Loss: 187.785 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2960/4776 | Loss: 151.728 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2970/4776 | Loss: 148.232 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 2980/4776 | Loss: 178.929 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 2990/4776 | Loss: 170.949 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3000/4776 | Loss: 151.952 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3010/4776 | Loss: 158.484 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3020/4776 | Loss: 212.434 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 3030/4776 | Loss: 128.651 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3040/4776 | Loss: 158.511 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3050/4776 | Loss: 139.139 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3060/4776 | Loss: 165.946 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3070/4776 | Loss: 187.399 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3080/4776 | Loss: 209.593 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3090/4776 | Loss: 205.097 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3100/4776 | Loss: 212.057 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3110/4776 | Loss: 259.013 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3120/4776 | Loss: 177.254 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3130/4776 | Loss: 167.893 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3140/4776 | Loss: 152.658 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3150/4776 | Loss: 137.512 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3160/4776 | Loss: 204.184 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3170/4776 | Loss: 114.712 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 3180/4776 | Loss: 151.873 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3190/4776 | Loss: 168.439 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3200/4776 | Loss: 148.020 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3210/4776 | Loss: 185.286 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3220/4776 | Loss: 170.799 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3230/4776 | Loss: 139.011 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 3240/4776 | Loss: 185.204 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3250/4776 | Loss: 168.389 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3260/4776 | Loss: 192.369 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3270/4776 | Loss: 163.574 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3280/4776 | Loss: 224.546 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3290/4776 | Loss: 110.879 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3300/4776 | Loss: 149.274 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3310/4776 | Loss: 204.564 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3320/4776 | Loss: 173.017 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3330/4776 | Loss: 166.850 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3340/4776 | Loss: 187.159 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3350/4776 | Loss: 158.155 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3360/4776 | Loss: 155.866 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3370/4776 | Loss: 172.292 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3380/4776 | Loss: 127.313 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3390/4776 | Loss: 147.895 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3400/4776 | Loss: 170.815 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3410/4776 | Loss: 152.937 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3420/4776 | Loss: 191.883 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3430/4776 | Loss: 181.313 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3440/4776 | Loss: 165.722 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3450/4776 | Loss: 161.772 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3460/4776 | Loss: 186.768 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3470/4776 | Loss: 192.787 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3480/4776 | Loss: 173.147 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3490/4776 | Loss: 147.621 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3500/4776 | Loss: 128.224 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3510/4776 | Loss: 145.496 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3520/4776 | Loss: 187.112 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3530/4776 | Loss: 111.131 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 3540/4776 | Loss: 183.323 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3550/4776 | Loss: 222.664 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3560/4776 | Loss: 257.758 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3570/4776 | Loss: 188.380 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3580/4776 | Loss: 143.005 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3590/4776 | Loss: 203.751 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3600/4776 | Loss: 186.908 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3610/4776 | Loss: 177.271 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3620/4776 | Loss: 216.115 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3630/4776 | Loss: 177.272 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3640/4776 | Loss: 142.190 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3650/4776 | Loss: 158.918 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3660/4776 | Loss: 134.738 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3670/4776 | Loss: 204.592 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3680/4776 | Loss: 171.226 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3690/4776 | Loss: 203.267 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3700/4776 | Loss: 212.634 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3710/4776 | Loss: 176.636 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3720/4776 | Loss: 152.025 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3730/4776 | Loss: 214.126 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3740/4776 | Loss: 161.916 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3750/4776 | Loss: 131.606 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3760/4776 | Loss: 96.652 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 3770/4776 | Loss: 197.448 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3780/4776 | Loss: 151.158 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3790/4776 | Loss: 139.254 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3800/4776 | Loss: 212.565 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3810/4776 | Loss: 175.833 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3820/4776 | Loss: 193.475 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3830/4776 | Loss: 139.867 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3840/4776 | Loss: 179.760 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3850/4776 | Loss: 227.670 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3860/4776 | Loss: 165.820 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3870/4776 | Loss: 162.169 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3880/4776 | Loss: 156.955 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3890/4776 | Loss: 141.524 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3900/4776 | Loss: 174.828 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3910/4776 | Loss: 156.096 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 3920/4776 | Loss: 159.065 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3930/4776 | Loss: 211.043 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3940/4776 | Loss: 165.962 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 3950/4776 | Loss: 187.710 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3960/4776 | Loss: 215.667 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 3970/4776 | Loss: 182.086 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 3980/4776 | Loss: 368.408 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 3990/4776 | Loss: 158.504 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4000/4776 | Loss: 228.409 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4010/4776 | Loss: 170.820 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4020/4776 | Loss: 192.747 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4030/4776 | Loss: 206.601 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4040/4776 | Loss: 140.243 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4050/4776 | Loss: 175.101 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4060/4776 | Loss: 182.705 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4070/4776 | Loss: 153.387 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4080/4776 | Loss: 158.008 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4090/4776 | Loss: 204.977 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4100/4776 | Loss: 155.274 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4110/4776 | Loss: 144.859 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4120/4776 | Loss: 157.906 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4130/4776 | Loss: 139.171 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4140/4776 | Loss: 181.857 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4150/4776 | Loss: 171.480 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4160/4776 | Loss: 210.819 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4170/4776 | Loss: 146.735 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4180/4776 | Loss: 197.242 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4190/4776 | Loss: 112.828 | Accuracy: 0.700\n",
      "[Epoch: 36/200] - Step: 4200/4776 | Loss: 151.470 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 4210/4776 | Loss: 194.761 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4220/4776 | Loss: 168.372 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4230/4776 | Loss: 175.055 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4240/4776 | Loss: 187.571 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4250/4776 | Loss: 192.493 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4260/4776 | Loss: 169.605 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4270/4776 | Loss: 191.548 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4280/4776 | Loss: 191.737 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4290/4776 | Loss: 182.919 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4300/4776 | Loss: 169.809 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4310/4776 | Loss: 177.646 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4320/4776 | Loss: 157.616 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4330/4776 | Loss: 192.976 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4340/4776 | Loss: 154.999 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4350/4776 | Loss: 154.163 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 4360/4776 | Loss: 155.934 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4370/4776 | Loss: 122.625 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 4380/4776 | Loss: 191.645 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4390/4776 | Loss: 190.048 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4400/4776 | Loss: 166.672 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4410/4776 | Loss: 167.202 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4420/4776 | Loss: 171.181 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4430/4776 | Loss: 141.653 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4440/4776 | Loss: 141.957 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4450/4776 | Loss: 77.358 | Accuracy: 0.800\n",
      "[Epoch: 36/200] - Step: 4460/4776 | Loss: 184.716 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4470/4776 | Loss: 228.437 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4480/4776 | Loss: 168.986 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4490/4776 | Loss: 152.808 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4500/4776 | Loss: 193.245 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4510/4776 | Loss: 161.729 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4520/4776 | Loss: 160.067 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4530/4776 | Loss: 154.376 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4540/4776 | Loss: 197.645 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4550/4776 | Loss: 165.799 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4560/4776 | Loss: 240.012 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4570/4776 | Loss: 179.304 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4580/4776 | Loss: 149.543 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4590/4776 | Loss: 194.361 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4600/4776 | Loss: 178.730 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4610/4776 | Loss: 202.062 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4620/4776 | Loss: 188.837 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4630/4776 | Loss: 224.681 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 4640/4776 | Loss: 161.803 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4650/4776 | Loss: 154.626 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4660/4776 | Loss: 149.211 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4670/4776 | Loss: 157.719 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4680/4776 | Loss: 129.261 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4690/4776 | Loss: 144.549 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4700/4776 | Loss: 120.052 | Accuracy: 0.500\n",
      "[Epoch: 36/200] - Step: 4710/4776 | Loss: 150.924 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4720/4776 | Loss: 142.607 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4730/4776 | Loss: 127.347 | Accuracy: 0.600\n",
      "[Epoch: 36/200] - Step: 4740/4776 | Loss: 154.997 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 4750/4776 | Loss: 175.579 | Accuracy: 0.400\n",
      "[Epoch: 36/200] - Step: 4760/4776 | Loss: 185.804 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 4770/4776 | Loss: 153.613 | Accuracy: 0.200\n",
      "Accuracy:  0.1918032786885246\n",
      "Model saved!\n",
      "[Epoch: 37/200] - Step: 10/4776 | Loss: 129.330 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 20/4776 | Loss: 190.147 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 30/4776 | Loss: 134.579 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 40/4776 | Loss: 199.715 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 50/4776 | Loss: 145.578 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 60/4776 | Loss: 140.344 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 70/4776 | Loss: 177.547 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 80/4776 | Loss: 165.899 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 90/4776 | Loss: 144.974 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 100/4776 | Loss: 131.238 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 110/4776 | Loss: 141.286 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 120/4776 | Loss: 124.791 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 130/4776 | Loss: 147.091 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 140/4776 | Loss: 164.783 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 150/4776 | Loss: 135.293 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 160/4776 | Loss: 185.982 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 170/4776 | Loss: 152.361 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 180/4776 | Loss: 176.453 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 190/4776 | Loss: 237.200 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 200/4776 | Loss: 163.776 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 210/4776 | Loss: 121.655 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 220/4776 | Loss: 132.475 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 230/4776 | Loss: 117.866 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 240/4776 | Loss: 189.934 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 250/4776 | Loss: 225.981 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 260/4776 | Loss: 166.603 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 270/4776 | Loss: 167.654 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 280/4776 | Loss: 199.524 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 290/4776 | Loss: 155.511 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 300/4776 | Loss: 123.968 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 310/4776 | Loss: 161.455 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 320/4776 | Loss: 130.428 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 330/4776 | Loss: 166.610 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 340/4776 | Loss: 123.896 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 350/4776 | Loss: 165.609 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 360/4776 | Loss: 136.242 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 370/4776 | Loss: 155.563 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 380/4776 | Loss: 187.897 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 390/4776 | Loss: 158.758 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 400/4776 | Loss: 158.177 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 410/4776 | Loss: 186.251 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 420/4776 | Loss: 158.020 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 430/4776 | Loss: 132.382 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 440/4776 | Loss: 140.857 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 450/4776 | Loss: 170.301 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 460/4776 | Loss: 193.108 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 470/4776 | Loss: 157.647 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 480/4776 | Loss: 158.693 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 490/4776 | Loss: 191.748 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 500/4776 | Loss: 122.292 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 510/4776 | Loss: 134.602 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 520/4776 | Loss: 140.830 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 530/4776 | Loss: 150.055 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 540/4776 | Loss: 134.167 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 550/4776 | Loss: 145.547 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 560/4776 | Loss: 159.538 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 570/4776 | Loss: 214.112 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 580/4776 | Loss: 190.013 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 590/4776 | Loss: 120.434 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 600/4776 | Loss: 175.942 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 610/4776 | Loss: 187.000 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 620/4776 | Loss: 180.952 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 630/4776 | Loss: 212.474 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 640/4776 | Loss: 188.427 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 650/4776 | Loss: 135.593 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 660/4776 | Loss: 181.813 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 670/4776 | Loss: 156.528 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 680/4776 | Loss: 185.081 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 690/4776 | Loss: 176.556 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 700/4776 | Loss: 106.923 | Accuracy: 0.800\n",
      "[Epoch: 37/200] - Step: 710/4776 | Loss: 120.954 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 720/4776 | Loss: 130.883 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 730/4776 | Loss: 194.659 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 740/4776 | Loss: 197.874 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 750/4776 | Loss: 161.179 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 760/4776 | Loss: 180.637 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 770/4776 | Loss: 132.958 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 780/4776 | Loss: 158.071 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 790/4776 | Loss: 180.362 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 800/4776 | Loss: 165.303 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 810/4776 | Loss: 139.451 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 820/4776 | Loss: 193.165 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 830/4776 | Loss: 169.514 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 840/4776 | Loss: 139.674 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 850/4776 | Loss: 132.026 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 860/4776 | Loss: 186.129 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 870/4776 | Loss: 127.869 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 880/4776 | Loss: 125.717 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 890/4776 | Loss: 217.514 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 900/4776 | Loss: 209.669 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 910/4776 | Loss: 205.435 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 920/4776 | Loss: 153.613 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 930/4776 | Loss: 193.887 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 940/4776 | Loss: 169.976 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 950/4776 | Loss: 205.815 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 960/4776 | Loss: 173.602 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 970/4776 | Loss: 156.616 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 980/4776 | Loss: 178.043 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 990/4776 | Loss: 180.957 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1000/4776 | Loss: 151.671 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1010/4776 | Loss: 159.136 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1020/4776 | Loss: 169.799 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1030/4776 | Loss: 157.760 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1040/4776 | Loss: 128.765 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1050/4776 | Loss: 158.618 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1060/4776 | Loss: 127.246 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1070/4776 | Loss: 173.118 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1080/4776 | Loss: 190.580 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1090/4776 | Loss: 185.924 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1100/4776 | Loss: 175.997 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1110/4776 | Loss: 188.021 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1120/4776 | Loss: 138.015 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1130/4776 | Loss: 197.339 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1140/4776 | Loss: 172.384 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1150/4776 | Loss: 124.327 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1160/4776 | Loss: 196.327 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1170/4776 | Loss: 179.551 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1180/4776 | Loss: 140.206 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1190/4776 | Loss: 133.857 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1200/4776 | Loss: 179.622 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1210/4776 | Loss: 160.125 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1220/4776 | Loss: 185.652 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1230/4776 | Loss: 173.947 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1240/4776 | Loss: 166.761 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1250/4776 | Loss: 165.094 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1260/4776 | Loss: 139.287 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1270/4776 | Loss: 177.012 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1280/4776 | Loss: 158.122 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1290/4776 | Loss: 182.827 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1300/4776 | Loss: 145.002 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1310/4776 | Loss: 133.294 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1320/4776 | Loss: 137.257 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1330/4776 | Loss: 166.713 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1340/4776 | Loss: 159.850 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1350/4776 | Loss: 131.868 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1360/4776 | Loss: 156.763 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1370/4776 | Loss: 151.852 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1380/4776 | Loss: 160.287 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1390/4776 | Loss: 154.866 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1400/4776 | Loss: 146.407 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1410/4776 | Loss: 139.047 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1420/4776 | Loss: 173.073 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1430/4776 | Loss: 177.448 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1440/4776 | Loss: 109.107 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1450/4776 | Loss: 150.152 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1460/4776 | Loss: 143.316 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1470/4776 | Loss: 211.184 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1480/4776 | Loss: 178.772 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1490/4776 | Loss: 201.216 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1500/4776 | Loss: 199.033 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1510/4776 | Loss: 174.391 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1520/4776 | Loss: 179.359 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1530/4776 | Loss: 183.948 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1540/4776 | Loss: 126.423 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1550/4776 | Loss: 152.200 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1560/4776 | Loss: 159.618 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1570/4776 | Loss: 132.078 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1580/4776 | Loss: 142.725 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 1590/4776 | Loss: 173.097 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1600/4776 | Loss: 145.094 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1610/4776 | Loss: 224.751 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1620/4776 | Loss: 154.139 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1630/4776 | Loss: 225.945 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1640/4776 | Loss: 133.150 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1650/4776 | Loss: 147.791 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1660/4776 | Loss: 142.912 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1670/4776 | Loss: 169.177 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1680/4776 | Loss: 117.989 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1690/4776 | Loss: 216.076 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1700/4776 | Loss: 129.518 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1710/4776 | Loss: 155.119 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1720/4776 | Loss: 170.965 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1730/4776 | Loss: 125.830 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1740/4776 | Loss: 175.105 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1750/4776 | Loss: 211.119 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1760/4776 | Loss: 171.975 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1770/4776 | Loss: 161.382 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1780/4776 | Loss: 149.093 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1790/4776 | Loss: 150.849 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1800/4776 | Loss: 136.828 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1810/4776 | Loss: 167.908 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1820/4776 | Loss: 178.153 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1830/4776 | Loss: 177.876 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1840/4776 | Loss: 133.090 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1850/4776 | Loss: 188.530 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1860/4776 | Loss: 173.818 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1870/4776 | Loss: 121.721 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 1880/4776 | Loss: 141.550 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1890/4776 | Loss: 248.562 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1900/4776 | Loss: 162.458 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1910/4776 | Loss: 189.974 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1920/4776 | Loss: 210.732 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1930/4776 | Loss: 174.532 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1940/4776 | Loss: 173.697 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1950/4776 | Loss: 170.085 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 1960/4776 | Loss: 134.502 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 1970/4776 | Loss: 157.789 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 1980/4776 | Loss: 189.433 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1990/4776 | Loss: 176.177 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2000/4776 | Loss: 219.832 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2010/4776 | Loss: 143.083 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2020/4776 | Loss: 215.400 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2030/4776 | Loss: 153.443 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2040/4776 | Loss: 186.839 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2050/4776 | Loss: 210.790 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2060/4776 | Loss: 154.464 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2070/4776 | Loss: 154.401 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2080/4776 | Loss: 181.410 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2090/4776 | Loss: 127.592 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2100/4776 | Loss: 163.730 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2110/4776 | Loss: 162.268 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2120/4776 | Loss: 196.582 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2130/4776 | Loss: 164.986 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2140/4776 | Loss: 134.564 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2150/4776 | Loss: 123.423 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2160/4776 | Loss: 158.221 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2170/4776 | Loss: 157.642 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2180/4776 | Loss: 157.430 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2190/4776 | Loss: 172.883 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2200/4776 | Loss: 140.478 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2210/4776 | Loss: 138.155 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2220/4776 | Loss: 129.216 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2230/4776 | Loss: 220.658 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2240/4776 | Loss: 183.042 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2250/4776 | Loss: 178.104 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2260/4776 | Loss: 188.016 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2270/4776 | Loss: 189.150 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2280/4776 | Loss: 147.649 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2290/4776 | Loss: 179.628 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2300/4776 | Loss: 137.396 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2310/4776 | Loss: 157.634 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2320/4776 | Loss: 138.011 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2330/4776 | Loss: 170.292 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2340/4776 | Loss: 139.938 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2350/4776 | Loss: 192.065 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2360/4776 | Loss: 150.192 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2370/4776 | Loss: 197.951 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2380/4776 | Loss: 160.179 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2390/4776 | Loss: 171.431 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2400/4776 | Loss: 132.311 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2410/4776 | Loss: 141.605 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2420/4776 | Loss: 193.060 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2430/4776 | Loss: 269.147 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2440/4776 | Loss: 179.474 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2450/4776 | Loss: 155.106 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2460/4776 | Loss: 216.318 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2470/4776 | Loss: 146.329 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2480/4776 | Loss: 201.511 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2490/4776 | Loss: 191.150 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2500/4776 | Loss: 143.930 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2510/4776 | Loss: 197.636 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2520/4776 | Loss: 158.041 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2530/4776 | Loss: 163.176 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2540/4776 | Loss: 159.223 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2550/4776 | Loss: 185.922 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2560/4776 | Loss: 150.327 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2570/4776 | Loss: 203.395 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2580/4776 | Loss: 159.886 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2590/4776 | Loss: 178.925 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2600/4776 | Loss: 141.672 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2610/4776 | Loss: 151.766 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2620/4776 | Loss: 148.993 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2630/4776 | Loss: 165.471 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2640/4776 | Loss: 192.034 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2650/4776 | Loss: 172.140 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2660/4776 | Loss: 251.341 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2670/4776 | Loss: 159.008 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2680/4776 | Loss: 146.267 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2690/4776 | Loss: 149.212 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2700/4776 | Loss: 142.310 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2710/4776 | Loss: 177.105 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2720/4776 | Loss: 197.432 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2730/4776 | Loss: 221.596 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2740/4776 | Loss: 184.843 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2750/4776 | Loss: 160.053 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2760/4776 | Loss: 183.511 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2770/4776 | Loss: 167.629 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2780/4776 | Loss: 160.030 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2790/4776 | Loss: 133.164 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2800/4776 | Loss: 164.359 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2810/4776 | Loss: 147.675 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2820/4776 | Loss: 122.491 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2830/4776 | Loss: 189.304 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 2840/4776 | Loss: 192.890 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 2850/4776 | Loss: 154.291 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2860/4776 | Loss: 179.344 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 2870/4776 | Loss: 151.953 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2880/4776 | Loss: 165.614 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2890/4776 | Loss: 169.815 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2900/4776 | Loss: 174.829 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2910/4776 | Loss: 133.726 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2920/4776 | Loss: 178.355 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2930/4776 | Loss: 166.600 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2940/4776 | Loss: 96.566 | Accuracy: 0.800\n",
      "[Epoch: 37/200] - Step: 2950/4776 | Loss: 142.320 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2960/4776 | Loss: 153.096 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 2970/4776 | Loss: 145.163 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 2980/4776 | Loss: 175.169 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 2990/4776 | Loss: 137.737 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3000/4776 | Loss: 129.801 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3010/4776 | Loss: 157.898 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3020/4776 | Loss: 180.889 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3030/4776 | Loss: 144.765 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3040/4776 | Loss: 189.143 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3050/4776 | Loss: 139.785 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3060/4776 | Loss: 154.836 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3070/4776 | Loss: 150.650 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3080/4776 | Loss: 165.341 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3090/4776 | Loss: 207.732 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 3100/4776 | Loss: 128.265 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3110/4776 | Loss: 168.527 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3120/4776 | Loss: 178.112 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3130/4776 | Loss: 157.047 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3140/4776 | Loss: 120.195 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3150/4776 | Loss: 189.712 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3160/4776 | Loss: 196.897 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 3170/4776 | Loss: 146.962 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3180/4776 | Loss: 181.170 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3190/4776 | Loss: 168.502 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3200/4776 | Loss: 164.871 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3210/4776 | Loss: 154.651 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3220/4776 | Loss: 148.131 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3230/4776 | Loss: 148.610 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3240/4776 | Loss: 163.689 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3250/4776 | Loss: 177.413 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3260/4776 | Loss: 130.770 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3270/4776 | Loss: 154.472 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3280/4776 | Loss: 221.278 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3290/4776 | Loss: 154.283 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3300/4776 | Loss: 162.498 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3310/4776 | Loss: 173.648 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3320/4776 | Loss: 157.868 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3330/4776 | Loss: 182.936 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3340/4776 | Loss: 156.473 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3350/4776 | Loss: 210.997 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3360/4776 | Loss: 131.784 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3370/4776 | Loss: 117.629 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3380/4776 | Loss: 108.408 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3390/4776 | Loss: 153.164 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3400/4776 | Loss: 196.206 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3410/4776 | Loss: 148.368 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3420/4776 | Loss: 170.851 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3430/4776 | Loss: 210.226 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3440/4776 | Loss: 124.614 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 3450/4776 | Loss: 139.492 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3460/4776 | Loss: 151.564 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3470/4776 | Loss: 170.055 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3480/4776 | Loss: 148.572 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3490/4776 | Loss: 159.310 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3500/4776 | Loss: 151.299 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3510/4776 | Loss: 244.578 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 3520/4776 | Loss: 120.501 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3530/4776 | Loss: 175.995 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3540/4776 | Loss: 140.367 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3550/4776 | Loss: 195.406 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3560/4776 | Loss: 149.498 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3570/4776 | Loss: 158.665 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3580/4776 | Loss: 136.814 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3590/4776 | Loss: 179.601 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3600/4776 | Loss: 186.282 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3610/4776 | Loss: 193.182 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 3620/4776 | Loss: 206.489 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 3630/4776 | Loss: 203.681 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 3640/4776 | Loss: 150.794 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3650/4776 | Loss: 186.548 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3660/4776 | Loss: 183.792 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3670/4776 | Loss: 107.464 | Accuracy: 0.800\n",
      "[Epoch: 37/200] - Step: 3680/4776 | Loss: 147.456 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3690/4776 | Loss: 170.684 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3700/4776 | Loss: 134.300 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3710/4776 | Loss: 169.442 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3720/4776 | Loss: 140.037 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3730/4776 | Loss: 119.983 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3740/4776 | Loss: 120.730 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3750/4776 | Loss: 141.663 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3760/4776 | Loss: 174.478 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3770/4776 | Loss: 158.956 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3780/4776 | Loss: 130.274 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3790/4776 | Loss: 190.421 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3800/4776 | Loss: 171.577 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3810/4776 | Loss: 183.567 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3820/4776 | Loss: 127.293 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 3830/4776 | Loss: 189.448 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3840/4776 | Loss: 208.752 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3850/4776 | Loss: 237.464 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3860/4776 | Loss: 192.650 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3870/4776 | Loss: 140.279 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3880/4776 | Loss: 126.346 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3890/4776 | Loss: 179.761 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3900/4776 | Loss: 127.158 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3910/4776 | Loss: 197.508 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 3920/4776 | Loss: 147.062 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 3930/4776 | Loss: 124.474 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 3940/4776 | Loss: 204.873 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3950/4776 | Loss: 204.775 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3960/4776 | Loss: 165.755 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 3970/4776 | Loss: 159.989 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 3980/4776 | Loss: 136.392 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 3990/4776 | Loss: 195.663 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4000/4776 | Loss: 158.056 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4010/4776 | Loss: 144.508 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4020/4776 | Loss: 175.779 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4030/4776 | Loss: 140.396 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4040/4776 | Loss: 164.206 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4050/4776 | Loss: 201.367 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4060/4776 | Loss: 148.865 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4070/4776 | Loss: 167.873 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4080/4776 | Loss: 157.412 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4090/4776 | Loss: 196.586 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4100/4776 | Loss: 138.224 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4110/4776 | Loss: 157.681 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4120/4776 | Loss: 208.315 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4130/4776 | Loss: 147.562 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4140/4776 | Loss: 141.590 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4150/4776 | Loss: 190.930 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4160/4776 | Loss: 151.349 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4170/4776 | Loss: 156.524 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4180/4776 | Loss: 269.031 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4190/4776 | Loss: 145.319 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4200/4776 | Loss: 183.316 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4210/4776 | Loss: 211.554 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 4220/4776 | Loss: 217.402 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4230/4776 | Loss: 182.617 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4240/4776 | Loss: 170.912 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4250/4776 | Loss: 173.338 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4260/4776 | Loss: 138.530 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4270/4776 | Loss: 167.420 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4280/4776 | Loss: 171.543 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4290/4776 | Loss: 178.627 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 4300/4776 | Loss: 177.204 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4310/4776 | Loss: 189.525 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4320/4776 | Loss: 131.343 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 4330/4776 | Loss: 154.275 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4340/4776 | Loss: 171.641 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4350/4776 | Loss: 153.507 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4360/4776 | Loss: 201.923 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4370/4776 | Loss: 146.823 | Accuracy: 0.700\n",
      "[Epoch: 37/200] - Step: 4380/4776 | Loss: 159.763 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4390/4776 | Loss: 159.310 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4400/4776 | Loss: 139.102 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4410/4776 | Loss: 146.197 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4420/4776 | Loss: 179.544 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4430/4776 | Loss: 143.397 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4440/4776 | Loss: 207.858 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 4450/4776 | Loss: 203.098 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4460/4776 | Loss: 136.351 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4470/4776 | Loss: 206.632 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4480/4776 | Loss: 172.973 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4490/4776 | Loss: 196.255 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4500/4776 | Loss: 196.444 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 4510/4776 | Loss: 138.158 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 4520/4776 | Loss: 196.082 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4530/4776 | Loss: 141.734 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4540/4776 | Loss: 191.306 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4550/4776 | Loss: 142.151 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4560/4776 | Loss: 173.637 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4570/4776 | Loss: 134.105 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4580/4776 | Loss: 187.107 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4590/4776 | Loss: 247.084 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 4600/4776 | Loss: 166.728 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4610/4776 | Loss: 150.087 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4620/4776 | Loss: 160.876 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4630/4776 | Loss: 212.635 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 4640/4776 | Loss: 255.605 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4650/4776 | Loss: 174.045 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4660/4776 | Loss: 212.086 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 4670/4776 | Loss: 145.496 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4680/4776 | Loss: 140.092 | Accuracy: 0.600\n",
      "[Epoch: 37/200] - Step: 4690/4776 | Loss: 128.133 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 4700/4776 | Loss: 139.958 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4710/4776 | Loss: 168.124 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 4720/4776 | Loss: 150.277 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4730/4776 | Loss: 180.402 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4740/4776 | Loss: 183.913 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 4750/4776 | Loss: 190.186 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 4760/4776 | Loss: 171.251 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 4770/4776 | Loss: 177.186 | Accuracy: 0.100\n",
      "Accuracy:  0.2\n",
      "Model saved!\n",
      "[Epoch: 38/200] - Step: 10/4776 | Loss: 164.221 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 20/4776 | Loss: 194.717 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 30/4776 | Loss: 163.174 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 40/4776 | Loss: 135.234 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 50/4776 | Loss: 123.729 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 60/4776 | Loss: 126.161 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 70/4776 | Loss: 212.628 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 80/4776 | Loss: 352.114 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 90/4776 | Loss: 134.028 | Accuracy: 0.800\n",
      "[Epoch: 38/200] - Step: 100/4776 | Loss: 131.198 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 110/4776 | Loss: 134.389 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 120/4776 | Loss: 170.290 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 130/4776 | Loss: 136.842 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 140/4776 | Loss: 148.253 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 150/4776 | Loss: 114.118 | Accuracy: 0.800\n",
      "[Epoch: 38/200] - Step: 160/4776 | Loss: 167.438 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 170/4776 | Loss: 181.186 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 180/4776 | Loss: 151.545 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 190/4776 | Loss: 112.866 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 200/4776 | Loss: 174.108 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 210/4776 | Loss: 154.614 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 220/4776 | Loss: 199.845 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 230/4776 | Loss: 157.563 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 240/4776 | Loss: 169.687 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 250/4776 | Loss: 185.979 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 260/4776 | Loss: 186.415 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 270/4776 | Loss: 157.472 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 280/4776 | Loss: 120.703 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 290/4776 | Loss: 182.197 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 300/4776 | Loss: 158.078 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 310/4776 | Loss: 163.282 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 320/4776 | Loss: 130.831 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 330/4776 | Loss: 203.160 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 340/4776 | Loss: 116.892 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 350/4776 | Loss: 185.008 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 360/4776 | Loss: 147.165 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 370/4776 | Loss: 160.004 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 380/4776 | Loss: 116.496 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 390/4776 | Loss: 190.887 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 400/4776 | Loss: 120.594 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 410/4776 | Loss: 174.565 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 420/4776 | Loss: 107.741 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 430/4776 | Loss: 142.410 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 440/4776 | Loss: 165.281 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 450/4776 | Loss: 204.882 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 460/4776 | Loss: 193.541 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 470/4776 | Loss: 155.908 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 480/4776 | Loss: 165.790 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 490/4776 | Loss: 181.578 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 500/4776 | Loss: 146.252 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 510/4776 | Loss: 162.944 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 520/4776 | Loss: 146.530 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 530/4776 | Loss: 176.962 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 540/4776 | Loss: 152.621 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 550/4776 | Loss: 209.023 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 560/4776 | Loss: 156.282 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 570/4776 | Loss: 121.771 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 580/4776 | Loss: 154.748 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 590/4776 | Loss: 175.393 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 600/4776 | Loss: 183.647 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 610/4776 | Loss: 167.681 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 620/4776 | Loss: 219.450 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 630/4776 | Loss: 234.545 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 640/4776 | Loss: 192.174 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 650/4776 | Loss: 211.997 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 660/4776 | Loss: 134.695 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 670/4776 | Loss: 163.248 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 680/4776 | Loss: 127.693 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 690/4776 | Loss: 176.362 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 700/4776 | Loss: 123.131 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 710/4776 | Loss: 179.474 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 720/4776 | Loss: 166.344 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 730/4776 | Loss: 124.446 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 740/4776 | Loss: 123.490 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 750/4776 | Loss: 186.564 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 760/4776 | Loss: 161.709 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 770/4776 | Loss: 150.032 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 780/4776 | Loss: 139.620 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 790/4776 | Loss: 164.202 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 800/4776 | Loss: 155.511 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 810/4776 | Loss: 101.902 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 820/4776 | Loss: 118.319 | Accuracy: 0.800\n",
      "[Epoch: 38/200] - Step: 830/4776 | Loss: 157.520 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 840/4776 | Loss: 182.923 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 850/4776 | Loss: 115.222 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 860/4776 | Loss: 222.070 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 870/4776 | Loss: 168.881 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 880/4776 | Loss: 157.753 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 890/4776 | Loss: 157.958 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 900/4776 | Loss: 152.922 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 910/4776 | Loss: 154.378 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 920/4776 | Loss: 96.642 | Accuracy: 0.900\n",
      "[Epoch: 38/200] - Step: 930/4776 | Loss: 163.043 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 940/4776 | Loss: 156.125 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 950/4776 | Loss: 153.109 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 960/4776 | Loss: 122.301 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 970/4776 | Loss: 191.342 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 980/4776 | Loss: 183.610 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 990/4776 | Loss: 128.066 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1000/4776 | Loss: 148.864 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1010/4776 | Loss: 210.275 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1020/4776 | Loss: 119.929 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 1030/4776 | Loss: 162.507 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1040/4776 | Loss: 126.537 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 1050/4776 | Loss: 169.976 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1060/4776 | Loss: 164.023 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1070/4776 | Loss: 152.098 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1080/4776 | Loss: 140.919 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1090/4776 | Loss: 200.631 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1100/4776 | Loss: 149.568 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1110/4776 | Loss: 162.748 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1120/4776 | Loss: 176.260 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1130/4776 | Loss: 163.247 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1140/4776 | Loss: 177.013 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1150/4776 | Loss: 172.521 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1160/4776 | Loss: 233.986 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1170/4776 | Loss: 206.922 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1180/4776 | Loss: 159.887 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1190/4776 | Loss: 227.983 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1200/4776 | Loss: 196.775 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1210/4776 | Loss: 165.339 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1220/4776 | Loss: 154.664 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1230/4776 | Loss: 149.526 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1240/4776 | Loss: 167.772 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1250/4776 | Loss: 173.580 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1260/4776 | Loss: 173.923 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1270/4776 | Loss: 198.976 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1280/4776 | Loss: 178.573 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1290/4776 | Loss: 167.895 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 1300/4776 | Loss: 148.210 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1310/4776 | Loss: 153.197 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1320/4776 | Loss: 173.789 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1330/4776 | Loss: 139.144 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1340/4776 | Loss: 170.316 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1350/4776 | Loss: 108.772 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1360/4776 | Loss: 119.002 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 1370/4776 | Loss: 145.880 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1380/4776 | Loss: 179.343 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1390/4776 | Loss: 134.842 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1400/4776 | Loss: 162.415 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1410/4776 | Loss: 154.612 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1420/4776 | Loss: 133.426 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1430/4776 | Loss: 111.599 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 1440/4776 | Loss: 140.971 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1450/4776 | Loss: 170.048 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1460/4776 | Loss: 156.403 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1470/4776 | Loss: 158.019 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 1480/4776 | Loss: 141.905 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1490/4776 | Loss: 143.656 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1500/4776 | Loss: 143.046 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1510/4776 | Loss: 162.567 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1520/4776 | Loss: 170.380 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1530/4776 | Loss: 140.341 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1540/4776 | Loss: 138.830 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1550/4776 | Loss: 160.478 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1560/4776 | Loss: 142.066 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1570/4776 | Loss: 125.285 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1580/4776 | Loss: 164.951 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1590/4776 | Loss: 201.233 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1600/4776 | Loss: 98.919 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 1610/4776 | Loss: 202.269 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1620/4776 | Loss: 166.722 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1630/4776 | Loss: 124.709 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1640/4776 | Loss: 179.256 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1650/4776 | Loss: 130.089 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1660/4776 | Loss: 147.696 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1670/4776 | Loss: 219.806 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1680/4776 | Loss: 152.089 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1690/4776 | Loss: 134.723 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1700/4776 | Loss: 147.996 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1710/4776 | Loss: 213.010 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1720/4776 | Loss: 215.911 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1730/4776 | Loss: 173.917 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1740/4776 | Loss: 177.379 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1750/4776 | Loss: 167.193 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1760/4776 | Loss: 189.990 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1770/4776 | Loss: 166.674 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1780/4776 | Loss: 214.434 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1790/4776 | Loss: 171.122 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1800/4776 | Loss: 176.555 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1810/4776 | Loss: 150.089 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1820/4776 | Loss: 154.946 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1830/4776 | Loss: 136.795 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 1840/4776 | Loss: 211.439 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1850/4776 | Loss: 91.393 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 1860/4776 | Loss: 212.470 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1870/4776 | Loss: 126.988 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1880/4776 | Loss: 148.517 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1890/4776 | Loss: 241.985 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1900/4776 | Loss: 181.863 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1910/4776 | Loss: 184.953 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1920/4776 | Loss: 175.190 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1930/4776 | Loss: 151.097 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 1940/4776 | Loss: 177.809 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1950/4776 | Loss: 186.893 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1960/4776 | Loss: 127.856 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 1970/4776 | Loss: 207.554 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1980/4776 | Loss: 164.571 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1990/4776 | Loss: 152.567 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2000/4776 | Loss: 165.100 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2010/4776 | Loss: 192.831 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2020/4776 | Loss: 154.082 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2030/4776 | Loss: 130.700 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2040/4776 | Loss: 202.474 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2050/4776 | Loss: 170.332 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 2060/4776 | Loss: 153.060 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2070/4776 | Loss: 143.126 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2080/4776 | Loss: 219.001 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2090/4776 | Loss: 227.830 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 2100/4776 | Loss: 153.024 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2110/4776 | Loss: 171.129 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2120/4776 | Loss: 178.065 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2130/4776 | Loss: 121.132 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2140/4776 | Loss: 206.013 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 2150/4776 | Loss: 137.981 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2160/4776 | Loss: 138.023 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2170/4776 | Loss: 163.300 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2180/4776 | Loss: 141.884 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2190/4776 | Loss: 189.364 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2200/4776 | Loss: 95.079 | Accuracy: 0.800\n",
      "[Epoch: 38/200] - Step: 2210/4776 | Loss: 144.453 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2220/4776 | Loss: 123.684 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 2230/4776 | Loss: 137.503 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2240/4776 | Loss: 124.709 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2250/4776 | Loss: 119.776 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2260/4776 | Loss: 154.940 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2270/4776 | Loss: 154.733 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2280/4776 | Loss: 182.863 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2290/4776 | Loss: 227.244 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2300/4776 | Loss: 165.173 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2310/4776 | Loss: 199.834 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 2320/4776 | Loss: 188.345 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2330/4776 | Loss: 200.791 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2340/4776 | Loss: 132.344 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2350/4776 | Loss: 127.611 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2360/4776 | Loss: 159.989 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2370/4776 | Loss: 181.387 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 2380/4776 | Loss: 196.073 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 2390/4776 | Loss: 225.748 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2400/4776 | Loss: 162.560 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2410/4776 | Loss: 105.292 | Accuracy: 0.800\n",
      "[Epoch: 38/200] - Step: 2420/4776 | Loss: 170.858 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2430/4776 | Loss: 190.673 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2440/4776 | Loss: 168.649 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2450/4776 | Loss: 174.596 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2460/4776 | Loss: 118.578 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2470/4776 | Loss: 165.225 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2480/4776 | Loss: 147.607 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2490/4776 | Loss: 157.357 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2500/4776 | Loss: 147.247 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2510/4776 | Loss: 151.808 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2520/4776 | Loss: 180.604 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2530/4776 | Loss: 157.442 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2540/4776 | Loss: 193.202 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 2550/4776 | Loss: 146.507 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2560/4776 | Loss: 114.097 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2570/4776 | Loss: 161.744 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2580/4776 | Loss: 176.933 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2590/4776 | Loss: 161.560 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2600/4776 | Loss: 182.835 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2610/4776 | Loss: 142.850 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2620/4776 | Loss: 172.631 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2630/4776 | Loss: 205.487 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2640/4776 | Loss: 200.230 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2650/4776 | Loss: 160.984 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2660/4776 | Loss: 170.964 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2670/4776 | Loss: 137.416 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2680/4776 | Loss: 170.909 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2690/4776 | Loss: 169.510 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2700/4776 | Loss: 140.535 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2710/4776 | Loss: 179.117 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2720/4776 | Loss: 151.765 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2730/4776 | Loss: 143.734 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2740/4776 | Loss: 243.799 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2750/4776 | Loss: 125.888 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2760/4776 | Loss: 153.236 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2770/4776 | Loss: 184.671 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2780/4776 | Loss: 132.615 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 2790/4776 | Loss: 99.736 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 2800/4776 | Loss: 156.589 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2810/4776 | Loss: 168.316 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2820/4776 | Loss: 167.820 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2830/4776 | Loss: 179.139 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2840/4776 | Loss: 183.997 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2850/4776 | Loss: 131.436 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2860/4776 | Loss: 180.196 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2870/4776 | Loss: 190.895 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 2880/4776 | Loss: 211.754 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2890/4776 | Loss: 180.176 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 2900/4776 | Loss: 133.599 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2910/4776 | Loss: 188.363 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2920/4776 | Loss: 206.208 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2930/4776 | Loss: 217.407 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 2940/4776 | Loss: 181.917 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2950/4776 | Loss: 186.002 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 2960/4776 | Loss: 194.856 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2970/4776 | Loss: 180.487 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 2980/4776 | Loss: 163.241 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 2990/4776 | Loss: 161.834 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3000/4776 | Loss: 160.330 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3010/4776 | Loss: 137.109 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3020/4776 | Loss: 189.764 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3030/4776 | Loss: 177.154 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3040/4776 | Loss: 191.357 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3050/4776 | Loss: 195.220 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3060/4776 | Loss: 168.325 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3070/4776 | Loss: 162.865 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3080/4776 | Loss: 223.271 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3090/4776 | Loss: 214.119 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3100/4776 | Loss: 142.243 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3110/4776 | Loss: 118.397 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 3120/4776 | Loss: 134.797 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3130/4776 | Loss: 151.939 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3140/4776 | Loss: 172.206 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3150/4776 | Loss: 166.417 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3160/4776 | Loss: 118.017 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3170/4776 | Loss: 113.818 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 3180/4776 | Loss: 132.554 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3190/4776 | Loss: 151.605 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3200/4776 | Loss: 223.417 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3210/4776 | Loss: 150.389 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3220/4776 | Loss: 156.366 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3230/4776 | Loss: 134.728 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3240/4776 | Loss: 167.861 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3250/4776 | Loss: 169.744 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3260/4776 | Loss: 149.805 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3270/4776 | Loss: 150.918 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3280/4776 | Loss: 183.953 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3290/4776 | Loss: 188.055 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3300/4776 | Loss: 221.804 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3310/4776 | Loss: 152.111 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3320/4776 | Loss: 210.259 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3330/4776 | Loss: 133.588 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3340/4776 | Loss: 148.063 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3350/4776 | Loss: 215.535 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3360/4776 | Loss: 166.135 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3370/4776 | Loss: 98.469 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 3380/4776 | Loss: 213.179 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3390/4776 | Loss: 256.208 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3400/4776 | Loss: 152.101 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3410/4776 | Loss: 169.879 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3420/4776 | Loss: 132.181 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 3430/4776 | Loss: 201.132 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3440/4776 | Loss: 137.486 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3450/4776 | Loss: 178.504 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3460/4776 | Loss: 145.706 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3470/4776 | Loss: 125.139 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3480/4776 | Loss: 174.843 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3490/4776 | Loss: 144.517 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3500/4776 | Loss: 110.203 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3510/4776 | Loss: 168.085 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3520/4776 | Loss: 142.215 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 3530/4776 | Loss: 156.434 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3540/4776 | Loss: 155.925 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3550/4776 | Loss: 154.823 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3560/4776 | Loss: 191.403 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3570/4776 | Loss: 106.898 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3580/4776 | Loss: 188.308 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3590/4776 | Loss: 178.510 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3600/4776 | Loss: 161.868 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3610/4776 | Loss: 138.524 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3620/4776 | Loss: 194.422 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3630/4776 | Loss: 125.462 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3640/4776 | Loss: 134.559 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 3650/4776 | Loss: 181.941 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3660/4776 | Loss: 170.457 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3670/4776 | Loss: 176.834 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3680/4776 | Loss: 179.908 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3690/4776 | Loss: 212.320 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3700/4776 | Loss: 166.655 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3710/4776 | Loss: 181.321 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3720/4776 | Loss: 159.977 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3730/4776 | Loss: 212.169 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3740/4776 | Loss: 155.394 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3750/4776 | Loss: 182.184 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3760/4776 | Loss: 210.906 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3770/4776 | Loss: 146.894 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3780/4776 | Loss: 138.869 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3790/4776 | Loss: 212.940 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3800/4776 | Loss: 171.481 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3810/4776 | Loss: 141.308 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3820/4776 | Loss: 150.384 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3830/4776 | Loss: 136.614 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3840/4776 | Loss: 167.002 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 3850/4776 | Loss: 143.636 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3860/4776 | Loss: 135.322 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3870/4776 | Loss: 155.267 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3880/4776 | Loss: 156.811 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3890/4776 | Loss: 147.839 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3900/4776 | Loss: 133.602 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3910/4776 | Loss: 259.244 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 3920/4776 | Loss: 133.782 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 3930/4776 | Loss: 156.515 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3940/4776 | Loss: 160.678 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3950/4776 | Loss: 154.446 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3960/4776 | Loss: 161.293 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 3970/4776 | Loss: 176.625 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 3980/4776 | Loss: 142.187 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 3990/4776 | Loss: 154.047 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4000/4776 | Loss: 105.579 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4010/4776 | Loss: 135.069 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4020/4776 | Loss: 167.624 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4030/4776 | Loss: 226.274 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 4040/4776 | Loss: 174.508 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4050/4776 | Loss: 213.324 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4060/4776 | Loss: 101.313 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4070/4776 | Loss: 149.279 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4080/4776 | Loss: 152.888 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4090/4776 | Loss: 202.791 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4100/4776 | Loss: 159.264 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4110/4776 | Loss: 182.897 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4120/4776 | Loss: 144.365 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4130/4776 | Loss: 202.429 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4140/4776 | Loss: 178.639 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4150/4776 | Loss: 200.017 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4160/4776 | Loss: 138.368 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4170/4776 | Loss: 139.115 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4180/4776 | Loss: 184.840 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4190/4776 | Loss: 207.238 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 4200/4776 | Loss: 148.265 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4210/4776 | Loss: 169.354 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 4220/4776 | Loss: 147.674 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4230/4776 | Loss: 154.016 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4240/4776 | Loss: 159.211 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4250/4776 | Loss: 184.383 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 4260/4776 | Loss: 188.113 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4270/4776 | Loss: 196.261 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4280/4776 | Loss: 182.682 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4290/4776 | Loss: 172.136 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4300/4776 | Loss: 141.695 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4310/4776 | Loss: 143.492 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4320/4776 | Loss: 174.860 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4330/4776 | Loss: 138.177 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4340/4776 | Loss: 177.365 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 4350/4776 | Loss: 140.278 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4360/4776 | Loss: 183.029 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4370/4776 | Loss: 189.545 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4380/4776 | Loss: 151.167 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4390/4776 | Loss: 173.840 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4400/4776 | Loss: 164.656 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4410/4776 | Loss: 150.649 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4420/4776 | Loss: 166.359 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4430/4776 | Loss: 150.392 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4440/4776 | Loss: 123.543 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4450/4776 | Loss: 174.635 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4460/4776 | Loss: 140.472 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4470/4776 | Loss: 182.277 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4480/4776 | Loss: 160.161 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4490/4776 | Loss: 188.281 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4500/4776 | Loss: 185.059 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4510/4776 | Loss: 132.853 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4520/4776 | Loss: 182.500 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4530/4776 | Loss: 158.671 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4540/4776 | Loss: 138.778 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4550/4776 | Loss: 165.826 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4560/4776 | Loss: 159.089 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4570/4776 | Loss: 135.887 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4580/4776 | Loss: 139.341 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 4590/4776 | Loss: 149.738 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4600/4776 | Loss: 115.866 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 4610/4776 | Loss: 162.653 | Accuracy: 0.700\n",
      "[Epoch: 38/200] - Step: 4620/4776 | Loss: 163.465 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4630/4776 | Loss: 147.724 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4640/4776 | Loss: 186.669 | Accuracy: 0.600\n",
      "[Epoch: 38/200] - Step: 4650/4776 | Loss: 182.261 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4660/4776 | Loss: 145.632 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4670/4776 | Loss: 147.510 | Accuracy: 0.500\n",
      "[Epoch: 38/200] - Step: 4680/4776 | Loss: 174.044 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4690/4776 | Loss: 152.543 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4700/4776 | Loss: 156.411 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4710/4776 | Loss: 218.421 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 4720/4776 | Loss: 134.130 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4730/4776 | Loss: 150.970 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4740/4776 | Loss: 157.300 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4750/4776 | Loss: 162.927 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 4760/4776 | Loss: 113.552 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 4770/4776 | Loss: 190.813 | Accuracy: 0.300\n",
      "Accuracy:  0.19672131147540983\n",
      "[Epoch: 39/200] - Step: 10/4776 | Loss: 136.189 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 20/4776 | Loss: 159.155 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 30/4776 | Loss: 150.759 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 40/4776 | Loss: 134.359 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 50/4776 | Loss: 133.557 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 60/4776 | Loss: 158.159 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 70/4776 | Loss: 175.774 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 80/4776 | Loss: 132.147 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 90/4776 | Loss: 196.170 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 100/4776 | Loss: 112.926 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 110/4776 | Loss: 184.598 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 120/4776 | Loss: 128.507 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 130/4776 | Loss: 132.272 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 140/4776 | Loss: 160.530 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 150/4776 | Loss: 178.404 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 160/4776 | Loss: 192.402 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 170/4776 | Loss: 164.605 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 180/4776 | Loss: 128.132 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 190/4776 | Loss: 161.827 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 200/4776 | Loss: 150.620 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 210/4776 | Loss: 121.912 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 220/4776 | Loss: 151.764 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 230/4776 | Loss: 116.514 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 240/4776 | Loss: 147.019 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 250/4776 | Loss: 156.296 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 260/4776 | Loss: 232.337 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 270/4776 | Loss: 183.906 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 280/4776 | Loss: 147.996 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 290/4776 | Loss: 201.444 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 300/4776 | Loss: 145.071 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 310/4776 | Loss: 172.829 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 320/4776 | Loss: 147.605 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 330/4776 | Loss: 132.598 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 340/4776 | Loss: 251.743 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 350/4776 | Loss: 193.867 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 360/4776 | Loss: 217.339 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 370/4776 | Loss: 157.290 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 380/4776 | Loss: 97.073 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 390/4776 | Loss: 161.738 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 400/4776 | Loss: 156.063 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 410/4776 | Loss: 176.280 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 420/4776 | Loss: 179.969 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 430/4776 | Loss: 165.430 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 440/4776 | Loss: 98.233 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 450/4776 | Loss: 137.716 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 460/4776 | Loss: 187.214 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 470/4776 | Loss: 175.540 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 480/4776 | Loss: 136.938 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 490/4776 | Loss: 223.910 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 500/4776 | Loss: 199.598 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 510/4776 | Loss: 167.419 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 520/4776 | Loss: 122.888 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 530/4776 | Loss: 159.808 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 540/4776 | Loss: 174.491 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 550/4776 | Loss: 179.979 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 560/4776 | Loss: 164.623 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 570/4776 | Loss: 236.584 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 580/4776 | Loss: 200.796 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 590/4776 | Loss: 174.832 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 600/4776 | Loss: 161.797 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 610/4776 | Loss: 133.149 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 620/4776 | Loss: 150.075 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 630/4776 | Loss: 132.673 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 640/4776 | Loss: 121.197 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 650/4776 | Loss: 170.651 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 660/4776 | Loss: 84.543 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 670/4776 | Loss: 202.355 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 680/4776 | Loss: 150.234 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 690/4776 | Loss: 161.885 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 700/4776 | Loss: 183.522 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 710/4776 | Loss: 150.486 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 720/4776 | Loss: 121.840 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 730/4776 | Loss: 155.204 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 740/4776 | Loss: 125.597 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 750/4776 | Loss: 215.111 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 760/4776 | Loss: 156.227 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 770/4776 | Loss: 153.131 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 780/4776 | Loss: 178.405 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 790/4776 | Loss: 153.598 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 800/4776 | Loss: 118.316 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 810/4776 | Loss: 131.613 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 820/4776 | Loss: 154.934 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 830/4776 | Loss: 194.579 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 840/4776 | Loss: 128.426 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 850/4776 | Loss: 163.126 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 860/4776 | Loss: 159.739 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 870/4776 | Loss: 145.553 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 880/4776 | Loss: 113.181 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 890/4776 | Loss: 107.534 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 900/4776 | Loss: 115.074 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 910/4776 | Loss: 172.844 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 920/4776 | Loss: 123.897 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 930/4776 | Loss: 176.996 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 940/4776 | Loss: 200.816 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 950/4776 | Loss: 140.457 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 960/4776 | Loss: 186.916 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 970/4776 | Loss: 170.758 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 980/4776 | Loss: 221.244 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 990/4776 | Loss: 138.827 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1000/4776 | Loss: 151.988 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1010/4776 | Loss: 180.833 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1020/4776 | Loss: 150.776 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1030/4776 | Loss: 175.121 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1040/4776 | Loss: 108.618 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1050/4776 | Loss: 103.226 | Accuracy: 0.800\n",
      "[Epoch: 39/200] - Step: 1060/4776 | Loss: 119.780 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1070/4776 | Loss: 102.248 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1080/4776 | Loss: 201.772 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1090/4776 | Loss: 146.469 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1100/4776 | Loss: 161.090 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1110/4776 | Loss: 121.015 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 1120/4776 | Loss: 147.538 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1130/4776 | Loss: 189.830 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1140/4776 | Loss: 123.513 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1150/4776 | Loss: 178.166 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1160/4776 | Loss: 101.147 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 1170/4776 | Loss: 125.271 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1180/4776 | Loss: 158.711 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1190/4776 | Loss: 167.601 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1200/4776 | Loss: 174.483 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1210/4776 | Loss: 167.219 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1220/4776 | Loss: 201.462 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1230/4776 | Loss: 149.895 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1240/4776 | Loss: 184.867 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1250/4776 | Loss: 196.319 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1260/4776 | Loss: 202.064 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1270/4776 | Loss: 150.640 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1280/4776 | Loss: 197.358 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1290/4776 | Loss: 144.650 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1300/4776 | Loss: 166.241 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1310/4776 | Loss: 135.599 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1320/4776 | Loss: 171.987 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1330/4776 | Loss: 137.094 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1340/4776 | Loss: 178.214 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1350/4776 | Loss: 164.582 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1360/4776 | Loss: 117.734 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1370/4776 | Loss: 159.657 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1380/4776 | Loss: 223.110 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1390/4776 | Loss: 155.135 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1400/4776 | Loss: 189.464 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1410/4776 | Loss: 155.411 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1420/4776 | Loss: 132.650 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1430/4776 | Loss: 168.466 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1440/4776 | Loss: 166.617 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1450/4776 | Loss: 143.357 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1460/4776 | Loss: 196.198 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1470/4776 | Loss: 107.577 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1480/4776 | Loss: 141.873 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1490/4776 | Loss: 162.726 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1500/4776 | Loss: 187.091 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1510/4776 | Loss: 165.536 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1520/4776 | Loss: 187.025 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1530/4776 | Loss: 193.916 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1540/4776 | Loss: 206.246 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1550/4776 | Loss: 145.793 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1560/4776 | Loss: 159.860 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1570/4776 | Loss: 116.116 | Accuracy: 0.800\n",
      "[Epoch: 39/200] - Step: 1580/4776 | Loss: 169.304 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1590/4776 | Loss: 174.716 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1600/4776 | Loss: 152.574 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1610/4776 | Loss: 135.983 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1620/4776 | Loss: 158.947 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1630/4776 | Loss: 167.009 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1640/4776 | Loss: 131.989 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1650/4776 | Loss: 158.076 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1660/4776 | Loss: 117.429 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1670/4776 | Loss: 168.652 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1680/4776 | Loss: 121.603 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1690/4776 | Loss: 214.303 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1700/4776 | Loss: 176.933 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1710/4776 | Loss: 135.234 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1720/4776 | Loss: 148.064 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1730/4776 | Loss: 144.873 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1740/4776 | Loss: 173.513 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1750/4776 | Loss: 160.029 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1760/4776 | Loss: 162.822 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1770/4776 | Loss: 166.635 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1780/4776 | Loss: 97.708 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 1790/4776 | Loss: 122.251 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1800/4776 | Loss: 125.660 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1810/4776 | Loss: 177.071 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1820/4776 | Loss: 170.063 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1830/4776 | Loss: 151.193 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1840/4776 | Loss: 171.791 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1850/4776 | Loss: 118.209 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1860/4776 | Loss: 176.171 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1870/4776 | Loss: 156.610 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1880/4776 | Loss: 173.722 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1890/4776 | Loss: 134.311 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 1900/4776 | Loss: 149.857 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1910/4776 | Loss: 104.303 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 1920/4776 | Loss: 210.717 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1930/4776 | Loss: 178.799 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1940/4776 | Loss: 151.978 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1950/4776 | Loss: 179.439 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1960/4776 | Loss: 179.141 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1970/4776 | Loss: 133.415 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1980/4776 | Loss: 117.649 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 1990/4776 | Loss: 174.248 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2000/4776 | Loss: 163.288 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2010/4776 | Loss: 147.351 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2020/4776 | Loss: 164.484 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2030/4776 | Loss: 166.604 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2040/4776 | Loss: 158.221 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2050/4776 | Loss: 124.611 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2060/4776 | Loss: 175.382 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2070/4776 | Loss: 170.742 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2080/4776 | Loss: 152.943 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2090/4776 | Loss: 138.646 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2100/4776 | Loss: 159.835 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2110/4776 | Loss: 143.992 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2120/4776 | Loss: 166.556 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2130/4776 | Loss: 140.563 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2140/4776 | Loss: 188.985 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2150/4776 | Loss: 195.879 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2160/4776 | Loss: 187.952 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2170/4776 | Loss: 191.695 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2180/4776 | Loss: 137.998 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2190/4776 | Loss: 134.955 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2200/4776 | Loss: 155.041 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2210/4776 | Loss: 195.296 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2220/4776 | Loss: 107.285 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2230/4776 | Loss: 118.679 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2240/4776 | Loss: 178.286 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2250/4776 | Loss: 194.286 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2260/4776 | Loss: 204.139 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2270/4776 | Loss: 232.538 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2280/4776 | Loss: 171.348 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2290/4776 | Loss: 141.217 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2300/4776 | Loss: 155.257 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2310/4776 | Loss: 236.512 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2320/4776 | Loss: 170.907 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2330/4776 | Loss: 120.536 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2340/4776 | Loss: 200.446 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2350/4776 | Loss: 130.605 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2360/4776 | Loss: 106.519 | Accuracy: 0.800\n",
      "[Epoch: 39/200] - Step: 2370/4776 | Loss: 151.355 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2380/4776 | Loss: 121.258 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2390/4776 | Loss: 152.000 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2400/4776 | Loss: 159.785 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2410/4776 | Loss: 152.687 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2420/4776 | Loss: 124.552 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2430/4776 | Loss: 134.582 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2440/4776 | Loss: 155.198 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2450/4776 | Loss: 134.377 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2460/4776 | Loss: 131.522 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2470/4776 | Loss: 147.618 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2480/4776 | Loss: 189.552 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 2490/4776 | Loss: 178.984 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2500/4776 | Loss: 143.521 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2510/4776 | Loss: 158.389 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2520/4776 | Loss: 144.825 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2530/4776 | Loss: 109.121 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2540/4776 | Loss: 171.203 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2550/4776 | Loss: 165.282 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2560/4776 | Loss: 166.447 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2570/4776 | Loss: 140.269 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2580/4776 | Loss: 175.623 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2590/4776 | Loss: 174.408 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2600/4776 | Loss: 148.340 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2610/4776 | Loss: 220.222 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 2620/4776 | Loss: 181.453 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2630/4776 | Loss: 171.246 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2640/4776 | Loss: 126.648 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2650/4776 | Loss: 117.444 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2660/4776 | Loss: 131.534 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2670/4776 | Loss: 164.787 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2680/4776 | Loss: 155.701 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2690/4776 | Loss: 173.447 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2700/4776 | Loss: 170.449 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2710/4776 | Loss: 146.821 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2720/4776 | Loss: 215.141 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2730/4776 | Loss: 138.867 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2740/4776 | Loss: 164.526 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2750/4776 | Loss: 168.908 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2760/4776 | Loss: 145.248 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2770/4776 | Loss: 155.521 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2780/4776 | Loss: 192.461 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2790/4776 | Loss: 136.430 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2800/4776 | Loss: 187.136 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2810/4776 | Loss: 126.619 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2820/4776 | Loss: 209.336 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2830/4776 | Loss: 131.089 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2840/4776 | Loss: 138.601 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2850/4776 | Loss: 209.102 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2860/4776 | Loss: 163.567 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 2870/4776 | Loss: 135.747 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2880/4776 | Loss: 151.961 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2890/4776 | Loss: 216.120 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2900/4776 | Loss: 160.314 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2910/4776 | Loss: 175.500 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2920/4776 | Loss: 157.556 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2930/4776 | Loss: 150.185 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2940/4776 | Loss: 187.555 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 2950/4776 | Loss: 176.092 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2960/4776 | Loss: 174.263 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 2970/4776 | Loss: 139.853 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 2980/4776 | Loss: 137.695 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 2990/4776 | Loss: 165.187 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3000/4776 | Loss: 168.413 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3010/4776 | Loss: 140.456 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3020/4776 | Loss: 171.866 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3030/4776 | Loss: 177.347 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3040/4776 | Loss: 108.951 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3050/4776 | Loss: 157.424 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3060/4776 | Loss: 164.109 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3070/4776 | Loss: 179.055 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3080/4776 | Loss: 118.230 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3090/4776 | Loss: 116.822 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3100/4776 | Loss: 157.994 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3110/4776 | Loss: 195.286 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3120/4776 | Loss: 161.279 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3130/4776 | Loss: 142.659 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3140/4776 | Loss: 177.760 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3150/4776 | Loss: 155.047 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3160/4776 | Loss: 135.644 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3170/4776 | Loss: 196.559 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3180/4776 | Loss: 119.726 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3190/4776 | Loss: 160.635 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3200/4776 | Loss: 154.314 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3210/4776 | Loss: 155.031 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3220/4776 | Loss: 215.041 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3230/4776 | Loss: 180.618 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3240/4776 | Loss: 153.489 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3250/4776 | Loss: 170.225 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3260/4776 | Loss: 156.530 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3270/4776 | Loss: 206.375 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3280/4776 | Loss: 217.032 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3290/4776 | Loss: 177.914 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3300/4776 | Loss: 196.922 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3310/4776 | Loss: 160.540 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3320/4776 | Loss: 187.295 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3330/4776 | Loss: 175.675 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3340/4776 | Loss: 162.112 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3350/4776 | Loss: 164.237 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3360/4776 | Loss: 143.389 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3370/4776 | Loss: 159.781 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3380/4776 | Loss: 183.122 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3390/4776 | Loss: 119.081 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 3400/4776 | Loss: 150.658 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3410/4776 | Loss: 113.478 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3420/4776 | Loss: 137.348 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3430/4776 | Loss: 141.967 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3440/4776 | Loss: 191.878 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3450/4776 | Loss: 174.472 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3460/4776 | Loss: 264.856 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3470/4776 | Loss: 145.206 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 3480/4776 | Loss: 193.158 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3490/4776 | Loss: 175.262 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3500/4776 | Loss: 150.297 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3510/4776 | Loss: 146.112 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3520/4776 | Loss: 165.814 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3530/4776 | Loss: 189.304 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3540/4776 | Loss: 195.620 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3550/4776 | Loss: 203.365 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3560/4776 | Loss: 121.894 | Accuracy: 0.800\n",
      "[Epoch: 39/200] - Step: 3570/4776 | Loss: 172.798 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3580/4776 | Loss: 175.925 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3590/4776 | Loss: 137.305 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3600/4776 | Loss: 165.785 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3610/4776 | Loss: 180.419 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3620/4776 | Loss: 152.376 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3630/4776 | Loss: 143.541 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3640/4776 | Loss: 125.054 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3650/4776 | Loss: 121.585 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3660/4776 | Loss: 113.658 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 3670/4776 | Loss: 144.535 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3680/4776 | Loss: 138.796 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3690/4776 | Loss: 217.921 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3700/4776 | Loss: 147.350 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3710/4776 | Loss: 159.073 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3720/4776 | Loss: 107.960 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3730/4776 | Loss: 117.490 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3740/4776 | Loss: 149.963 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3750/4776 | Loss: 164.240 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3760/4776 | Loss: 122.695 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3770/4776 | Loss: 101.583 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 3780/4776 | Loss: 180.352 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3790/4776 | Loss: 137.173 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3800/4776 | Loss: 172.529 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3810/4776 | Loss: 101.089 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3820/4776 | Loss: 107.578 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 3830/4776 | Loss: 162.855 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3840/4776 | Loss: 211.658 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3850/4776 | Loss: 201.807 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 3860/4776 | Loss: 155.517 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3870/4776 | Loss: 150.384 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3880/4776 | Loss: 131.475 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3890/4776 | Loss: 157.731 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3900/4776 | Loss: 156.630 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3910/4776 | Loss: 169.264 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3920/4776 | Loss: 192.476 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3930/4776 | Loss: 181.963 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 3940/4776 | Loss: 119.340 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3950/4776 | Loss: 200.893 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3960/4776 | Loss: 143.039 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 3970/4776 | Loss: 187.816 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 3980/4776 | Loss: 174.110 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 3990/4776 | Loss: 175.956 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4000/4776 | Loss: 158.096 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 4010/4776 | Loss: 172.898 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4020/4776 | Loss: 175.113 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4030/4776 | Loss: 197.644 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4040/4776 | Loss: 182.184 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4050/4776 | Loss: 138.420 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4060/4776 | Loss: 141.536 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4070/4776 | Loss: 192.527 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4080/4776 | Loss: 134.113 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4090/4776 | Loss: 146.268 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4100/4776 | Loss: 141.447 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4110/4776 | Loss: 212.715 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4120/4776 | Loss: 134.981 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4130/4776 | Loss: 110.591 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4140/4776 | Loss: 148.851 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4150/4776 | Loss: 154.015 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4160/4776 | Loss: 117.439 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4170/4776 | Loss: 137.026 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4180/4776 | Loss: 141.405 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4190/4776 | Loss: 204.214 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 4200/4776 | Loss: 166.181 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4210/4776 | Loss: 150.965 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4220/4776 | Loss: 169.820 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4230/4776 | Loss: 162.290 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4240/4776 | Loss: 119.872 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4250/4776 | Loss: 132.795 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4260/4776 | Loss: 131.665 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4270/4776 | Loss: 170.661 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4280/4776 | Loss: 132.026 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4290/4776 | Loss: 165.665 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4300/4776 | Loss: 113.011 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4310/4776 | Loss: 151.155 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4320/4776 | Loss: 90.031 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 4330/4776 | Loss: 148.332 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4340/4776 | Loss: 139.107 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4350/4776 | Loss: 137.706 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 4360/4776 | Loss: 205.849 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4370/4776 | Loss: 163.502 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4380/4776 | Loss: 126.479 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4390/4776 | Loss: 154.322 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4400/4776 | Loss: 151.213 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4410/4776 | Loss: 161.804 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4420/4776 | Loss: 128.034 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4430/4776 | Loss: 227.417 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 4440/4776 | Loss: 197.212 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 4450/4776 | Loss: 201.149 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4460/4776 | Loss: 223.422 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4470/4776 | Loss: 198.363 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4480/4776 | Loss: 190.260 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4490/4776 | Loss: 160.947 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4500/4776 | Loss: 163.331 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4510/4776 | Loss: 130.774 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4520/4776 | Loss: 143.353 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4530/4776 | Loss: 132.470 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4540/4776 | Loss: 154.622 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4550/4776 | Loss: 158.988 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4560/4776 | Loss: 183.660 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4570/4776 | Loss: 155.068 | Accuracy: 0.500\n",
      "[Epoch: 39/200] - Step: 4580/4776 | Loss: 171.664 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4590/4776 | Loss: 96.138 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 4600/4776 | Loss: 162.831 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4610/4776 | Loss: 166.364 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4620/4776 | Loss: 201.731 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4630/4776 | Loss: 201.220 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4640/4776 | Loss: 123.234 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 4650/4776 | Loss: 166.365 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4660/4776 | Loss: 190.849 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4670/4776 | Loss: 124.247 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4680/4776 | Loss: 143.535 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 4690/4776 | Loss: 153.778 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4700/4776 | Loss: 187.458 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 4710/4776 | Loss: 125.732 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4720/4776 | Loss: 101.142 | Accuracy: 0.700\n",
      "[Epoch: 39/200] - Step: 4730/4776 | Loss: 126.025 | Accuracy: 0.600\n",
      "[Epoch: 39/200] - Step: 4740/4776 | Loss: 153.453 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4750/4776 | Loss: 148.397 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4760/4776 | Loss: 175.103 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 4770/4776 | Loss: 190.962 | Accuracy: 0.300\n",
      "Accuracy:  0.1721311475409836\n",
      "[Epoch: 40/200] - Step: 10/4776 | Loss: 131.432 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 20/4776 | Loss: 193.048 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 30/4776 | Loss: 197.823 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 40/4776 | Loss: 159.969 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 50/4776 | Loss: 110.452 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 60/4776 | Loss: 211.040 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 70/4776 | Loss: 165.443 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 80/4776 | Loss: 177.383 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 90/4776 | Loss: 147.349 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 100/4776 | Loss: 159.574 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 110/4776 | Loss: 145.407 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 120/4776 | Loss: 157.168 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 130/4776 | Loss: 134.420 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 140/4776 | Loss: 176.417 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 150/4776 | Loss: 152.752 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 160/4776 | Loss: 150.546 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 170/4776 | Loss: 120.596 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 180/4776 | Loss: 145.906 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 190/4776 | Loss: 186.330 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 200/4776 | Loss: 180.074 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 210/4776 | Loss: 154.130 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 220/4776 | Loss: 190.742 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 230/4776 | Loss: 149.354 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 240/4776 | Loss: 160.149 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 250/4776 | Loss: 156.428 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 260/4776 | Loss: 160.509 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 270/4776 | Loss: 198.968 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 280/4776 | Loss: 157.019 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 290/4776 | Loss: 159.461 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 300/4776 | Loss: 177.173 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 310/4776 | Loss: 179.922 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 320/4776 | Loss: 176.883 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 330/4776 | Loss: 170.087 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 340/4776 | Loss: 167.226 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 350/4776 | Loss: 152.138 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 360/4776 | Loss: 143.363 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 370/4776 | Loss: 148.893 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 380/4776 | Loss: 159.471 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 390/4776 | Loss: 124.135 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 400/4776 | Loss: 161.928 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 410/4776 | Loss: 126.747 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 420/4776 | Loss: 81.778 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 430/4776 | Loss: 202.163 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 440/4776 | Loss: 169.777 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 450/4776 | Loss: 154.031 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 460/4776 | Loss: 170.367 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 470/4776 | Loss: 102.253 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 480/4776 | Loss: 149.160 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 490/4776 | Loss: 162.044 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 500/4776 | Loss: 115.930 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 510/4776 | Loss: 107.982 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 520/4776 | Loss: 160.219 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 530/4776 | Loss: 212.261 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 540/4776 | Loss: 100.378 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 550/4776 | Loss: 142.712 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 560/4776 | Loss: 165.905 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 570/4776 | Loss: 156.142 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 580/4776 | Loss: 137.793 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 590/4776 | Loss: 140.600 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 600/4776 | Loss: 163.538 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 610/4776 | Loss: 180.450 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 620/4776 | Loss: 100.291 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 630/4776 | Loss: 131.384 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 640/4776 | Loss: 142.654 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 650/4776 | Loss: 119.821 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 660/4776 | Loss: 159.961 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 670/4776 | Loss: 160.748 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 680/4776 | Loss: 163.281 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 690/4776 | Loss: 139.356 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 700/4776 | Loss: 145.619 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 710/4776 | Loss: 128.327 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 720/4776 | Loss: 196.870 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 730/4776 | Loss: 137.793 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 740/4776 | Loss: 115.729 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 750/4776 | Loss: 104.775 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 760/4776 | Loss: 213.831 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 770/4776 | Loss: 168.976 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 780/4776 | Loss: 132.160 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 790/4776 | Loss: 151.489 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 800/4776 | Loss: 163.277 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 810/4776 | Loss: 161.780 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 820/4776 | Loss: 154.483 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 830/4776 | Loss: 164.577 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 840/4776 | Loss: 191.758 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 850/4776 | Loss: 145.592 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 860/4776 | Loss: 110.523 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 870/4776 | Loss: 151.901 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 880/4776 | Loss: 112.523 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 890/4776 | Loss: 161.587 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 900/4776 | Loss: 206.840 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 910/4776 | Loss: 171.213 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 920/4776 | Loss: 133.175 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 930/4776 | Loss: 199.848 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 940/4776 | Loss: 150.454 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 950/4776 | Loss: 123.570 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 960/4776 | Loss: 152.816 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 970/4776 | Loss: 197.141 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 980/4776 | Loss: 130.986 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 990/4776 | Loss: 169.587 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1000/4776 | Loss: 116.521 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1010/4776 | Loss: 164.788 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1020/4776 | Loss: 148.989 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1030/4776 | Loss: 139.450 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1040/4776 | Loss: 153.904 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1050/4776 | Loss: 149.974 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1060/4776 | Loss: 193.639 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1070/4776 | Loss: 196.681 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1080/4776 | Loss: 173.608 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1090/4776 | Loss: 132.334 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1100/4776 | Loss: 142.317 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1110/4776 | Loss: 158.279 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1120/4776 | Loss: 120.732 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1130/4776 | Loss: 148.678 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1140/4776 | Loss: 99.235 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1150/4776 | Loss: 154.427 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1160/4776 | Loss: 235.293 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1170/4776 | Loss: 150.927 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1180/4776 | Loss: 158.787 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1190/4776 | Loss: 176.829 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1200/4776 | Loss: 136.931 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1210/4776 | Loss: 174.923 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1220/4776 | Loss: 113.372 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1230/4776 | Loss: 166.498 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1240/4776 | Loss: 163.483 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1250/4776 | Loss: 153.565 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1260/4776 | Loss: 160.463 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1270/4776 | Loss: 112.945 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1280/4776 | Loss: 124.564 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1290/4776 | Loss: 106.506 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1300/4776 | Loss: 166.317 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1310/4776 | Loss: 96.159 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1320/4776 | Loss: 123.591 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1330/4776 | Loss: 147.857 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1340/4776 | Loss: 115.604 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1350/4776 | Loss: 156.478 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1360/4776 | Loss: 185.276 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1370/4776 | Loss: 172.146 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1380/4776 | Loss: 146.466 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1390/4776 | Loss: 168.007 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1400/4776 | Loss: 149.198 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1410/4776 | Loss: 163.660 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1420/4776 | Loss: 147.875 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1430/4776 | Loss: 142.428 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1440/4776 | Loss: 135.398 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1450/4776 | Loss: 137.194 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1460/4776 | Loss: 154.847 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1470/4776 | Loss: 132.194 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1480/4776 | Loss: 129.135 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1490/4776 | Loss: 210.176 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1500/4776 | Loss: 154.273 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1510/4776 | Loss: 138.894 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1520/4776 | Loss: 173.171 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1530/4776 | Loss: 134.755 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1540/4776 | Loss: 174.926 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1550/4776 | Loss: 193.227 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1560/4776 | Loss: 196.594 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1570/4776 | Loss: 164.021 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1580/4776 | Loss: 147.633 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1590/4776 | Loss: 160.915 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1600/4776 | Loss: 136.811 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1610/4776 | Loss: 107.338 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 1620/4776 | Loss: 187.408 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1630/4776 | Loss: 114.261 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1640/4776 | Loss: 183.729 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1650/4776 | Loss: 103.146 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1660/4776 | Loss: 150.877 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1670/4776 | Loss: 163.055 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1680/4776 | Loss: 128.236 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1690/4776 | Loss: 165.218 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1700/4776 | Loss: 170.709 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1710/4776 | Loss: 146.034 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1720/4776 | Loss: 221.485 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1730/4776 | Loss: 215.086 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1740/4776 | Loss: 148.902 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1750/4776 | Loss: 133.043 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1760/4776 | Loss: 132.369 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 1770/4776 | Loss: 184.889 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1780/4776 | Loss: 124.272 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1790/4776 | Loss: 142.157 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1800/4776 | Loss: 125.585 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1810/4776 | Loss: 222.838 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1820/4776 | Loss: 169.121 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1830/4776 | Loss: 114.121 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1840/4776 | Loss: 228.430 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1850/4776 | Loss: 142.670 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1860/4776 | Loss: 127.479 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1870/4776 | Loss: 136.626 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1880/4776 | Loss: 145.698 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1890/4776 | Loss: 122.047 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1900/4776 | Loss: 171.902 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1910/4776 | Loss: 124.960 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1920/4776 | Loss: 214.947 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1930/4776 | Loss: 156.326 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1940/4776 | Loss: 164.376 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1950/4776 | Loss: 164.236 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 1960/4776 | Loss: 179.762 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1970/4776 | Loss: 132.596 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1980/4776 | Loss: 127.971 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 1990/4776 | Loss: 132.430 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2000/4776 | Loss: 180.786 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2010/4776 | Loss: 149.394 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2020/4776 | Loss: 162.959 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2030/4776 | Loss: 173.472 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2040/4776 | Loss: 134.160 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2050/4776 | Loss: 145.008 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2060/4776 | Loss: 197.530 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2070/4776 | Loss: 154.881 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2080/4776 | Loss: 156.038 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2090/4776 | Loss: 153.508 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2100/4776 | Loss: 144.763 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2110/4776 | Loss: 169.662 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2120/4776 | Loss: 152.328 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2130/4776 | Loss: 160.301 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2140/4776 | Loss: 193.968 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2150/4776 | Loss: 179.973 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2160/4776 | Loss: 110.259 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2170/4776 | Loss: 131.621 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2180/4776 | Loss: 183.430 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2190/4776 | Loss: 125.469 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2200/4776 | Loss: 145.088 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2210/4776 | Loss: 115.649 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2220/4776 | Loss: 223.879 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2230/4776 | Loss: 122.725 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2240/4776 | Loss: 147.785 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2250/4776 | Loss: 106.523 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2260/4776 | Loss: 151.066 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2270/4776 | Loss: 227.965 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2280/4776 | Loss: 199.917 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2290/4776 | Loss: 196.570 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2300/4776 | Loss: 175.157 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2310/4776 | Loss: 144.504 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2320/4776 | Loss: 131.228 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2330/4776 | Loss: 154.552 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2340/4776 | Loss: 184.750 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2350/4776 | Loss: 151.806 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2360/4776 | Loss: 141.623 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2370/4776 | Loss: 146.221 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2380/4776 | Loss: 135.657 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2390/4776 | Loss: 131.829 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2400/4776 | Loss: 180.924 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2410/4776 | Loss: 119.716 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2420/4776 | Loss: 163.404 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2430/4776 | Loss: 153.958 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2440/4776 | Loss: 155.229 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2450/4776 | Loss: 142.802 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2460/4776 | Loss: 141.086 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2470/4776 | Loss: 127.263 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2480/4776 | Loss: 120.632 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2490/4776 | Loss: 174.229 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2500/4776 | Loss: 199.433 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2510/4776 | Loss: 106.145 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2520/4776 | Loss: 118.632 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2530/4776 | Loss: 167.989 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2540/4776 | Loss: 146.539 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2550/4776 | Loss: 107.267 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2560/4776 | Loss: 185.701 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2570/4776 | Loss: 110.099 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2580/4776 | Loss: 203.391 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2590/4776 | Loss: 156.113 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2600/4776 | Loss: 166.333 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2610/4776 | Loss: 183.542 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2620/4776 | Loss: 157.371 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2630/4776 | Loss: 124.413 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2640/4776 | Loss: 145.311 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2650/4776 | Loss: 152.988 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2660/4776 | Loss: 124.314 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2670/4776 | Loss: 116.840 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2680/4776 | Loss: 184.246 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2690/4776 | Loss: 203.313 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2700/4776 | Loss: 130.657 | Accuracy: 0.800\n",
      "[Epoch: 40/200] - Step: 2710/4776 | Loss: 182.633 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2720/4776 | Loss: 197.435 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2730/4776 | Loss: 180.092 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2740/4776 | Loss: 125.698 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2750/4776 | Loss: 156.298 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2760/4776 | Loss: 158.163 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2770/4776 | Loss: 116.630 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 2780/4776 | Loss: 162.835 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2790/4776 | Loss: 148.247 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2800/4776 | Loss: 240.863 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2810/4776 | Loss: 194.092 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2820/4776 | Loss: 150.714 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2830/4776 | Loss: 129.349 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 2840/4776 | Loss: 211.760 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2850/4776 | Loss: 148.436 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2860/4776 | Loss: 177.358 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2870/4776 | Loss: 180.225 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2880/4776 | Loss: 144.129 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2890/4776 | Loss: 143.450 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2900/4776 | Loss: 152.660 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 2910/4776 | Loss: 178.982 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2920/4776 | Loss: 131.044 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2930/4776 | Loss: 222.111 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 2940/4776 | Loss: 131.839 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2950/4776 | Loss: 205.066 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2960/4776 | Loss: 189.348 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 2970/4776 | Loss: 180.219 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 2980/4776 | Loss: 183.442 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 2990/4776 | Loss: 199.569 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3000/4776 | Loss: 159.642 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3010/4776 | Loss: 138.610 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3020/4776 | Loss: 142.626 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3030/4776 | Loss: 128.099 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3040/4776 | Loss: 122.908 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3050/4776 | Loss: 155.891 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3060/4776 | Loss: 204.305 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3070/4776 | Loss: 143.947 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3080/4776 | Loss: 131.133 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3090/4776 | Loss: 144.926 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3100/4776 | Loss: 135.849 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3110/4776 | Loss: 124.228 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3120/4776 | Loss: 142.379 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3130/4776 | Loss: 126.714 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 3140/4776 | Loss: 146.450 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3150/4776 | Loss: 135.057 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3160/4776 | Loss: 155.974 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3170/4776 | Loss: 149.891 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3180/4776 | Loss: 144.357 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3190/4776 | Loss: 149.092 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3200/4776 | Loss: 132.874 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3210/4776 | Loss: 131.154 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3220/4776 | Loss: 173.645 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3230/4776 | Loss: 116.207 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3240/4776 | Loss: 244.263 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 3250/4776 | Loss: 153.262 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3260/4776 | Loss: 146.136 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3270/4776 | Loss: 144.897 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3280/4776 | Loss: 150.742 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3290/4776 | Loss: 166.038 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3300/4776 | Loss: 176.270 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3310/4776 | Loss: 82.754 | Accuracy: 0.800\n",
      "[Epoch: 40/200] - Step: 3320/4776 | Loss: 168.510 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3330/4776 | Loss: 167.650 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3340/4776 | Loss: 131.292 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3350/4776 | Loss: 182.472 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3360/4776 | Loss: 272.847 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3370/4776 | Loss: 128.439 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3380/4776 | Loss: 180.273 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3390/4776 | Loss: 137.511 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3400/4776 | Loss: 217.724 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3410/4776 | Loss: 187.917 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3420/4776 | Loss: 187.610 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3430/4776 | Loss: 219.880 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3440/4776 | Loss: 175.753 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 3450/4776 | Loss: 183.792 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3460/4776 | Loss: 149.809 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3470/4776 | Loss: 188.209 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3480/4776 | Loss: 184.437 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3490/4776 | Loss: 174.353 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3500/4776 | Loss: 202.618 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3510/4776 | Loss: 166.048 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3520/4776 | Loss: 144.837 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3530/4776 | Loss: 174.672 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3540/4776 | Loss: 157.588 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3550/4776 | Loss: 166.231 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3560/4776 | Loss: 157.240 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3570/4776 | Loss: 191.299 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3580/4776 | Loss: 138.360 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3590/4776 | Loss: 141.779 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3600/4776 | Loss: 146.852 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3610/4776 | Loss: 151.253 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3620/4776 | Loss: 165.203 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3630/4776 | Loss: 148.137 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3640/4776 | Loss: 133.918 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3650/4776 | Loss: 110.625 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 3660/4776 | Loss: 130.818 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3670/4776 | Loss: 144.577 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3680/4776 | Loss: 141.281 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3690/4776 | Loss: 158.860 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3700/4776 | Loss: 106.207 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3710/4776 | Loss: 201.767 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3720/4776 | Loss: 123.776 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3730/4776 | Loss: 134.295 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3740/4776 | Loss: 127.775 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3750/4776 | Loss: 165.399 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3760/4776 | Loss: 135.663 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3770/4776 | Loss: 180.662 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3780/4776 | Loss: 178.510 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3790/4776 | Loss: 166.869 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3800/4776 | Loss: 137.816 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3810/4776 | Loss: 166.233 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3820/4776 | Loss: 107.057 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 3830/4776 | Loss: 180.571 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3840/4776 | Loss: 152.877 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3850/4776 | Loss: 100.013 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3860/4776 | Loss: 210.543 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3870/4776 | Loss: 144.030 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3880/4776 | Loss: 136.369 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3890/4776 | Loss: 117.736 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3900/4776 | Loss: 198.073 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3910/4776 | Loss: 162.018 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3920/4776 | Loss: 172.730 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 3930/4776 | Loss: 200.907 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3940/4776 | Loss: 159.316 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3950/4776 | Loss: 177.239 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 3960/4776 | Loss: 83.812 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 3970/4776 | Loss: 169.038 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 3980/4776 | Loss: 150.196 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 3990/4776 | Loss: 156.923 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4000/4776 | Loss: 198.386 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4010/4776 | Loss: 108.054 | Accuracy: 0.700\n",
      "[Epoch: 40/200] - Step: 4020/4776 | Loss: 168.127 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4030/4776 | Loss: 152.390 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4040/4776 | Loss: 111.979 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4050/4776 | Loss: 90.629 | Accuracy: 0.800\n",
      "[Epoch: 40/200] - Step: 4060/4776 | Loss: 207.323 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4070/4776 | Loss: 151.342 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4080/4776 | Loss: 166.287 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4090/4776 | Loss: 155.188 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4100/4776 | Loss: 118.364 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4110/4776 | Loss: 177.167 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4120/4776 | Loss: 177.752 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4130/4776 | Loss: 154.570 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4140/4776 | Loss: 201.045 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4150/4776 | Loss: 204.755 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4160/4776 | Loss: 166.414 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4170/4776 | Loss: 117.062 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4180/4776 | Loss: 169.829 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4190/4776 | Loss: 147.734 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4200/4776 | Loss: 173.301 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4210/4776 | Loss: 141.872 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4220/4776 | Loss: 179.117 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4230/4776 | Loss: 182.372 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4240/4776 | Loss: 174.652 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4250/4776 | Loss: 180.248 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4260/4776 | Loss: 160.543 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4270/4776 | Loss: 135.755 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4280/4776 | Loss: 150.252 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4290/4776 | Loss: 201.726 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4300/4776 | Loss: 150.052 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4310/4776 | Loss: 127.851 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4320/4776 | Loss: 143.558 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4330/4776 | Loss: 143.795 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4340/4776 | Loss: 137.671 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4350/4776 | Loss: 140.203 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4360/4776 | Loss: 136.564 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4370/4776 | Loss: 134.873 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4380/4776 | Loss: 117.411 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4390/4776 | Loss: 113.286 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4400/4776 | Loss: 166.525 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4410/4776 | Loss: 144.523 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4420/4776 | Loss: 318.283 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4430/4776 | Loss: 153.615 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4440/4776 | Loss: 128.771 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4450/4776 | Loss: 184.040 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4460/4776 | Loss: 166.356 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4470/4776 | Loss: 180.763 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4480/4776 | Loss: 207.187 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4490/4776 | Loss: 150.846 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4500/4776 | Loss: 208.948 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4510/4776 | Loss: 149.249 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4520/4776 | Loss: 159.390 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4530/4776 | Loss: 115.004 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4540/4776 | Loss: 180.298 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4550/4776 | Loss: 155.632 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4560/4776 | Loss: 172.281 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4570/4776 | Loss: 146.163 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4580/4776 | Loss: 155.682 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4590/4776 | Loss: 144.152 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4600/4776 | Loss: 268.091 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4610/4776 | Loss: 123.460 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4620/4776 | Loss: 149.262 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4630/4776 | Loss: 194.762 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4640/4776 | Loss: 160.113 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4650/4776 | Loss: 190.433 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4660/4776 | Loss: 94.989 | Accuracy: 0.800\n",
      "[Epoch: 40/200] - Step: 4670/4776 | Loss: 172.896 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4680/4776 | Loss: 151.028 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4690/4776 | Loss: 127.968 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4700/4776 | Loss: 166.147 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4710/4776 | Loss: 143.608 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4720/4776 | Loss: 147.736 | Accuracy: 0.600\n",
      "[Epoch: 40/200] - Step: 4730/4776 | Loss: 174.989 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 4740/4776 | Loss: 142.148 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 4750/4776 | Loss: 223.640 | Accuracy: 0.500\n",
      "[Epoch: 40/200] - Step: 4760/4776 | Loss: 179.943 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 4770/4776 | Loss: 171.168 | Accuracy: 0.100\n",
      "Accuracy:  0.18032786885245902\n",
      "[Epoch: 41/200] - Step: 10/4776 | Loss: 196.864 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 20/4776 | Loss: 180.701 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 30/4776 | Loss: 113.009 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 40/4776 | Loss: 114.891 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 50/4776 | Loss: 164.066 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 60/4776 | Loss: 190.339 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 70/4776 | Loss: 195.271 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 80/4776 | Loss: 167.380 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 90/4776 | Loss: 136.909 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 100/4776 | Loss: 125.826 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 110/4776 | Loss: 135.455 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 120/4776 | Loss: 182.780 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 130/4776 | Loss: 142.369 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 140/4776 | Loss: 101.576 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 150/4776 | Loss: 218.508 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 160/4776 | Loss: 130.916 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 170/4776 | Loss: 163.480 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 180/4776 | Loss: 102.168 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 190/4776 | Loss: 122.892 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 200/4776 | Loss: 142.800 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 210/4776 | Loss: 152.266 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 220/4776 | Loss: 170.621 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 230/4776 | Loss: 150.892 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 240/4776 | Loss: 171.385 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 250/4776 | Loss: 178.102 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 260/4776 | Loss: 108.280 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 270/4776 | Loss: 141.162 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 280/4776 | Loss: 151.647 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 290/4776 | Loss: 142.810 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 300/4776 | Loss: 127.914 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 310/4776 | Loss: 166.239 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 320/4776 | Loss: 139.267 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 330/4776 | Loss: 132.746 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 340/4776 | Loss: 169.804 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 350/4776 | Loss: 113.499 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 360/4776 | Loss: 125.502 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 370/4776 | Loss: 206.877 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 380/4776 | Loss: 112.000 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 390/4776 | Loss: 151.372 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 400/4776 | Loss: 176.969 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 410/4776 | Loss: 141.218 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 420/4776 | Loss: 153.082 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 430/4776 | Loss: 181.481 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 440/4776 | Loss: 132.729 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 450/4776 | Loss: 166.886 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 460/4776 | Loss: 98.752 | Accuracy: 0.800\n",
      "[Epoch: 41/200] - Step: 470/4776 | Loss: 119.354 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 480/4776 | Loss: 104.235 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 490/4776 | Loss: 161.744 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 500/4776 | Loss: 182.069 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 510/4776 | Loss: 139.368 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 520/4776 | Loss: 170.652 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 530/4776 | Loss: 125.256 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 540/4776 | Loss: 160.088 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 550/4776 | Loss: 172.752 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 560/4776 | Loss: 108.406 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 570/4776 | Loss: 200.149 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 580/4776 | Loss: 193.012 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 590/4776 | Loss: 169.170 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 600/4776 | Loss: 149.656 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 610/4776 | Loss: 179.537 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 620/4776 | Loss: 146.402 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 630/4776 | Loss: 153.964 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 640/4776 | Loss: 173.994 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 650/4776 | Loss: 138.403 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 660/4776 | Loss: 131.776 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 670/4776 | Loss: 163.365 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 680/4776 | Loss: 124.094 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 690/4776 | Loss: 184.553 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 700/4776 | Loss: 109.304 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 710/4776 | Loss: 132.930 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 720/4776 | Loss: 155.570 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 730/4776 | Loss: 119.275 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 740/4776 | Loss: 140.376 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 750/4776 | Loss: 207.082 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 760/4776 | Loss: 93.863 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 770/4776 | Loss: 117.717 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 780/4776 | Loss: 141.948 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 790/4776 | Loss: 169.245 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 800/4776 | Loss: 165.867 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 810/4776 | Loss: 132.097 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 820/4776 | Loss: 145.102 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 830/4776 | Loss: 161.575 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 840/4776 | Loss: 111.037 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 850/4776 | Loss: 224.120 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 860/4776 | Loss: 133.134 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 870/4776 | Loss: 180.801 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 880/4776 | Loss: 170.786 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 890/4776 | Loss: 183.177 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 900/4776 | Loss: 160.013 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 910/4776 | Loss: 148.468 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 920/4776 | Loss: 131.293 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 930/4776 | Loss: 213.833 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 940/4776 | Loss: 254.127 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 950/4776 | Loss: 112.433 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 960/4776 | Loss: 159.179 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 970/4776 | Loss: 122.231 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 980/4776 | Loss: 109.760 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 990/4776 | Loss: 165.811 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1000/4776 | Loss: 149.675 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1010/4776 | Loss: 130.818 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1020/4776 | Loss: 152.557 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1030/4776 | Loss: 164.301 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1040/4776 | Loss: 119.332 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1050/4776 | Loss: 168.418 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1060/4776 | Loss: 204.667 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1070/4776 | Loss: 170.059 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1080/4776 | Loss: 186.919 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1090/4776 | Loss: 138.519 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1100/4776 | Loss: 142.085 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1110/4776 | Loss: 170.731 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1120/4776 | Loss: 174.768 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1130/4776 | Loss: 175.442 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1140/4776 | Loss: 135.374 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1150/4776 | Loss: 115.909 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1160/4776 | Loss: 136.624 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1170/4776 | Loss: 177.406 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1180/4776 | Loss: 162.226 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1190/4776 | Loss: 144.764 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1200/4776 | Loss: 125.134 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1210/4776 | Loss: 123.473 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1220/4776 | Loss: 173.828 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1230/4776 | Loss: 113.833 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1240/4776 | Loss: 184.853 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1250/4776 | Loss: 159.635 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1260/4776 | Loss: 135.380 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1270/4776 | Loss: 174.027 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1280/4776 | Loss: 165.762 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1290/4776 | Loss: 145.462 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1300/4776 | Loss: 195.331 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1310/4776 | Loss: 141.759 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1320/4776 | Loss: 142.009 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1330/4776 | Loss: 140.317 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1340/4776 | Loss: 182.038 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1350/4776 | Loss: 133.623 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1360/4776 | Loss: 109.841 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1370/4776 | Loss: 137.765 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1380/4776 | Loss: 156.795 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1390/4776 | Loss: 199.104 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1400/4776 | Loss: 139.254 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1410/4776 | Loss: 118.371 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1420/4776 | Loss: 103.402 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1430/4776 | Loss: 134.881 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1440/4776 | Loss: 145.946 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1450/4776 | Loss: 107.438 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1460/4776 | Loss: 140.986 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1470/4776 | Loss: 116.885 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1480/4776 | Loss: 97.766 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1490/4776 | Loss: 162.548 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1500/4776 | Loss: 123.376 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1510/4776 | Loss: 145.193 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1520/4776 | Loss: 211.315 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1530/4776 | Loss: 159.696 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1540/4776 | Loss: 151.659 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1550/4776 | Loss: 170.339 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1560/4776 | Loss: 150.509 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1570/4776 | Loss: 122.952 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1580/4776 | Loss: 171.863 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1590/4776 | Loss: 161.428 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1600/4776 | Loss: 136.071 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1610/4776 | Loss: 170.187 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1620/4776 | Loss: 189.883 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1630/4776 | Loss: 130.872 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1640/4776 | Loss: 158.166 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1650/4776 | Loss: 144.500 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1660/4776 | Loss: 202.227 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1670/4776 | Loss: 163.821 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1680/4776 | Loss: 152.376 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1690/4776 | Loss: 180.093 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1700/4776 | Loss: 177.852 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1710/4776 | Loss: 158.046 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1720/4776 | Loss: 113.632 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1730/4776 | Loss: 194.854 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1740/4776 | Loss: 164.519 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1750/4776 | Loss: 156.414 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1760/4776 | Loss: 165.304 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1770/4776 | Loss: 145.429 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1780/4776 | Loss: 170.220 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1790/4776 | Loss: 179.508 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1800/4776 | Loss: 212.865 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1810/4776 | Loss: 191.942 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1820/4776 | Loss: 156.968 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1830/4776 | Loss: 142.131 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 1840/4776 | Loss: 134.212 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1850/4776 | Loss: 141.063 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1860/4776 | Loss: 149.312 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1870/4776 | Loss: 128.964 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 1880/4776 | Loss: 128.390 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 1890/4776 | Loss: 169.578 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1900/4776 | Loss: 137.452 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1910/4776 | Loss: 176.251 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1920/4776 | Loss: 179.843 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1930/4776 | Loss: 184.475 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1940/4776 | Loss: 200.704 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1950/4776 | Loss: 158.060 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1960/4776 | Loss: 179.845 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1970/4776 | Loss: 198.965 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1980/4776 | Loss: 138.838 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 1990/4776 | Loss: 143.237 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2000/4776 | Loss: 148.169 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2010/4776 | Loss: 164.219 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2020/4776 | Loss: 166.252 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2030/4776 | Loss: 191.235 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2040/4776 | Loss: 140.302 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2050/4776 | Loss: 120.933 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2060/4776 | Loss: 154.317 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2070/4776 | Loss: 98.666 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2080/4776 | Loss: 152.082 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2090/4776 | Loss: 148.474 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2100/4776 | Loss: 139.401 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2110/4776 | Loss: 131.432 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2120/4776 | Loss: 181.043 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2130/4776 | Loss: 173.328 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2140/4776 | Loss: 147.562 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2150/4776 | Loss: 104.643 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2160/4776 | Loss: 137.257 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2170/4776 | Loss: 136.041 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2180/4776 | Loss: 148.740 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2190/4776 | Loss: 140.366 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2200/4776 | Loss: 144.593 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2210/4776 | Loss: 129.964 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2220/4776 | Loss: 206.372 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2230/4776 | Loss: 130.212 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2240/4776 | Loss: 159.771 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2250/4776 | Loss: 111.520 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2260/4776 | Loss: 162.698 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2270/4776 | Loss: 144.475 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2280/4776 | Loss: 103.020 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2290/4776 | Loss: 135.668 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2300/4776 | Loss: 159.523 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2310/4776 | Loss: 125.833 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2320/4776 | Loss: 143.074 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2330/4776 | Loss: 183.323 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2340/4776 | Loss: 113.532 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2350/4776 | Loss: 113.055 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2360/4776 | Loss: 132.487 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2370/4776 | Loss: 94.794 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2380/4776 | Loss: 150.070 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2390/4776 | Loss: 190.513 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2400/4776 | Loss: 177.308 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2410/4776 | Loss: 104.308 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2420/4776 | Loss: 114.589 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2430/4776 | Loss: 141.056 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2440/4776 | Loss: 131.985 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 2450/4776 | Loss: 158.589 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2460/4776 | Loss: 166.339 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2470/4776 | Loss: 89.794 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2480/4776 | Loss: 177.210 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2490/4776 | Loss: 230.095 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2500/4776 | Loss: 179.290 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2510/4776 | Loss: 124.196 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2520/4776 | Loss: 127.235 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2530/4776 | Loss: 139.150 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2540/4776 | Loss: 113.878 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2550/4776 | Loss: 196.211 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2560/4776 | Loss: 196.911 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2570/4776 | Loss: 179.724 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2580/4776 | Loss: 112.906 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2590/4776 | Loss: 147.431 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2600/4776 | Loss: 131.162 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2610/4776 | Loss: 170.042 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2620/4776 | Loss: 210.573 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2630/4776 | Loss: 157.005 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2640/4776 | Loss: 151.335 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2650/4776 | Loss: 152.351 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 2660/4776 | Loss: 103.073 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2670/4776 | Loss: 132.650 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2680/4776 | Loss: 149.643 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2690/4776 | Loss: 121.165 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2700/4776 | Loss: 163.457 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2710/4776 | Loss: 108.390 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2720/4776 | Loss: 169.725 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2730/4776 | Loss: 157.617 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2740/4776 | Loss: 157.491 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2750/4776 | Loss: 185.013 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2760/4776 | Loss: 124.191 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2770/4776 | Loss: 146.273 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2780/4776 | Loss: 185.784 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2790/4776 | Loss: 156.957 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2800/4776 | Loss: 139.573 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2810/4776 | Loss: 155.168 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2820/4776 | Loss: 153.984 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2830/4776 | Loss: 131.304 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2840/4776 | Loss: 141.592 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2850/4776 | Loss: 136.781 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2860/4776 | Loss: 242.206 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2870/4776 | Loss: 209.959 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2880/4776 | Loss: 206.231 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 2890/4776 | Loss: 169.676 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2900/4776 | Loss: 147.009 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2910/4776 | Loss: 125.976 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2920/4776 | Loss: 171.376 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2930/4776 | Loss: 180.497 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2940/4776 | Loss: 137.527 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 2950/4776 | Loss: 93.683 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 2960/4776 | Loss: 135.521 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2970/4776 | Loss: 108.425 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 2980/4776 | Loss: 152.883 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 2990/4776 | Loss: 205.932 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3000/4776 | Loss: 123.591 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3010/4776 | Loss: 93.946 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3020/4776 | Loss: 141.776 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3030/4776 | Loss: 176.573 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3040/4776 | Loss: 194.731 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3050/4776 | Loss: 173.788 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3060/4776 | Loss: 140.838 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3070/4776 | Loss: 183.055 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3080/4776 | Loss: 145.282 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3090/4776 | Loss: 125.666 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3100/4776 | Loss: 119.584 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3110/4776 | Loss: 126.969 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3120/4776 | Loss: 139.074 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3130/4776 | Loss: 189.132 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 3140/4776 | Loss: 121.319 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3150/4776 | Loss: 119.928 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3160/4776 | Loss: 126.515 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3170/4776 | Loss: 162.686 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3180/4776 | Loss: 147.278 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3190/4776 | Loss: 169.428 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3200/4776 | Loss: 140.822 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3210/4776 | Loss: 178.844 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3220/4776 | Loss: 201.348 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3230/4776 | Loss: 155.385 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3240/4776 | Loss: 191.506 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 3250/4776 | Loss: 162.625 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3260/4776 | Loss: 145.235 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3270/4776 | Loss: 147.179 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3280/4776 | Loss: 178.431 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3290/4776 | Loss: 221.289 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 3300/4776 | Loss: 136.395 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3310/4776 | Loss: 109.346 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3320/4776 | Loss: 175.656 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3330/4776 | Loss: 208.129 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3340/4776 | Loss: 213.629 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3350/4776 | Loss: 121.550 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3360/4776 | Loss: 130.878 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3370/4776 | Loss: 157.859 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3380/4776 | Loss: 146.894 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3390/4776 | Loss: 181.560 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3400/4776 | Loss: 152.549 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3410/4776 | Loss: 189.176 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 3420/4776 | Loss: 204.713 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3430/4776 | Loss: 73.176 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3440/4776 | Loss: 151.402 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3450/4776 | Loss: 142.117 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3460/4776 | Loss: 129.949 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3470/4776 | Loss: 165.097 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3480/4776 | Loss: 142.747 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3490/4776 | Loss: 143.000 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3500/4776 | Loss: 140.310 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3510/4776 | Loss: 126.219 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3520/4776 | Loss: 170.584 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3530/4776 | Loss: 119.130 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3540/4776 | Loss: 120.516 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3550/4776 | Loss: 141.452 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3560/4776 | Loss: 145.128 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3570/4776 | Loss: 64.989 | Accuracy: 0.800\n",
      "[Epoch: 41/200] - Step: 3580/4776 | Loss: 124.578 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3590/4776 | Loss: 186.469 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3600/4776 | Loss: 143.244 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3610/4776 | Loss: 97.754 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3620/4776 | Loss: 140.215 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3630/4776 | Loss: 169.715 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3640/4776 | Loss: 130.479 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3650/4776 | Loss: 113.320 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3660/4776 | Loss: 144.727 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3670/4776 | Loss: 158.457 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3680/4776 | Loss: 195.568 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3690/4776 | Loss: 182.446 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3700/4776 | Loss: 121.412 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3710/4776 | Loss: 143.665 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3720/4776 | Loss: 169.452 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3730/4776 | Loss: 138.422 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3740/4776 | Loss: 154.591 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3750/4776 | Loss: 137.657 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3760/4776 | Loss: 204.091 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3770/4776 | Loss: 148.364 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3780/4776 | Loss: 182.848 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3790/4776 | Loss: 153.969 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3800/4776 | Loss: 175.857 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3810/4776 | Loss: 154.049 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3820/4776 | Loss: 173.797 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3830/4776 | Loss: 135.696 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3840/4776 | Loss: 155.992 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3850/4776 | Loss: 154.597 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3860/4776 | Loss: 171.234 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3870/4776 | Loss: 163.052 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3880/4776 | Loss: 195.513 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 3890/4776 | Loss: 189.027 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3900/4776 | Loss: 139.804 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3910/4776 | Loss: 171.274 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3920/4776 | Loss: 137.908 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3930/4776 | Loss: 183.320 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 3940/4776 | Loss: 119.985 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 3950/4776 | Loss: 194.004 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3960/4776 | Loss: 160.461 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 3970/4776 | Loss: 120.380 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 3980/4776 | Loss: 205.895 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 3990/4776 | Loss: 166.693 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4000/4776 | Loss: 133.645 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4010/4776 | Loss: 152.863 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4020/4776 | Loss: 158.124 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4030/4776 | Loss: 162.337 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4040/4776 | Loss: 112.884 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4050/4776 | Loss: 157.636 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4060/4776 | Loss: 151.171 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4070/4776 | Loss: 148.398 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4080/4776 | Loss: 168.938 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4090/4776 | Loss: 252.894 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4100/4776 | Loss: 118.071 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4110/4776 | Loss: 139.751 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4120/4776 | Loss: 171.893 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4130/4776 | Loss: 169.446 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4140/4776 | Loss: 107.237 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4150/4776 | Loss: 111.494 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4160/4776 | Loss: 136.806 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4170/4776 | Loss: 141.455 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4180/4776 | Loss: 169.429 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4190/4776 | Loss: 122.872 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4200/4776 | Loss: 148.094 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4210/4776 | Loss: 248.438 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4220/4776 | Loss: 172.085 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 4230/4776 | Loss: 158.230 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4240/4776 | Loss: 155.893 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4250/4776 | Loss: 183.802 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4260/4776 | Loss: 147.425 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4270/4776 | Loss: 159.398 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4280/4776 | Loss: 149.192 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4290/4776 | Loss: 230.533 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 4300/4776 | Loss: 156.594 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4310/4776 | Loss: 158.608 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4320/4776 | Loss: 195.980 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4330/4776 | Loss: 136.222 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4340/4776 | Loss: 201.872 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4350/4776 | Loss: 170.753 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4360/4776 | Loss: 617.352 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4370/4776 | Loss: 170.723 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4380/4776 | Loss: 139.609 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4390/4776 | Loss: 167.048 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4400/4776 | Loss: 165.014 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4410/4776 | Loss: 180.825 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 4420/4776 | Loss: 181.816 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4430/4776 | Loss: 160.602 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4440/4776 | Loss: 168.444 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4450/4776 | Loss: 176.953 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4460/4776 | Loss: 161.643 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4470/4776 | Loss: 118.433 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4480/4776 | Loss: 178.807 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4490/4776 | Loss: 159.895 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4500/4776 | Loss: 177.229 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4510/4776 | Loss: 173.053 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4520/4776 | Loss: 177.085 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4530/4776 | Loss: 167.805 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4540/4776 | Loss: 132.922 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4550/4776 | Loss: 172.003 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 4560/4776 | Loss: 162.906 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4570/4776 | Loss: 206.256 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 4580/4776 | Loss: 175.606 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4590/4776 | Loss: 240.885 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4600/4776 | Loss: 111.938 | Accuracy: 0.700\n",
      "[Epoch: 41/200] - Step: 4610/4776 | Loss: 146.245 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4620/4776 | Loss: 170.735 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4630/4776 | Loss: 171.561 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4640/4776 | Loss: 117.421 | Accuracy: 0.800\n",
      "[Epoch: 41/200] - Step: 4650/4776 | Loss: 126.459 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4660/4776 | Loss: 137.990 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4670/4776 | Loss: 167.498 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4680/4776 | Loss: 123.985 | Accuracy: 0.600\n",
      "[Epoch: 41/200] - Step: 4690/4776 | Loss: 143.883 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4700/4776 | Loss: 140.429 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4710/4776 | Loss: 158.526 | Accuracy: 0.500\n",
      "[Epoch: 41/200] - Step: 4720/4776 | Loss: 185.807 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4730/4776 | Loss: 159.839 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 4740/4776 | Loss: 150.525 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 4750/4776 | Loss: 145.569 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 4760/4776 | Loss: 151.977 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 4770/4776 | Loss: 117.473 | Accuracy: 0.500\n",
      "Accuracy:  0.19508196721311474\n",
      "[Epoch: 42/200] - Step: 10/4776 | Loss: 147.261 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 20/4776 | Loss: 144.380 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 30/4776 | Loss: 129.636 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 40/4776 | Loss: 85.160 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 50/4776 | Loss: 160.784 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 60/4776 | Loss: 137.734 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 70/4776 | Loss: 148.338 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 80/4776 | Loss: 101.393 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 90/4776 | Loss: 141.167 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 100/4776 | Loss: 153.652 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 110/4776 | Loss: 127.440 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 120/4776 | Loss: 168.149 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 130/4776 | Loss: 129.713 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 140/4776 | Loss: 145.146 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 150/4776 | Loss: 162.971 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 160/4776 | Loss: 139.500 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 170/4776 | Loss: 143.970 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 180/4776 | Loss: 117.958 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 190/4776 | Loss: 166.652 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 200/4776 | Loss: 184.682 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 210/4776 | Loss: 118.767 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 220/4776 | Loss: 238.433 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 230/4776 | Loss: 87.154 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 240/4776 | Loss: 87.592 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 250/4776 | Loss: 166.277 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 260/4776 | Loss: 122.347 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 270/4776 | Loss: 264.625 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 280/4776 | Loss: 115.451 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 290/4776 | Loss: 135.270 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 300/4776 | Loss: 199.832 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 310/4776 | Loss: 138.513 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 320/4776 | Loss: 101.485 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 330/4776 | Loss: 167.795 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 340/4776 | Loss: 121.676 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 350/4776 | Loss: 111.456 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 360/4776 | Loss: 105.523 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 370/4776 | Loss: 135.378 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 380/4776 | Loss: 129.497 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 390/4776 | Loss: 108.685 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 400/4776 | Loss: 90.052 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 410/4776 | Loss: 144.519 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 420/4776 | Loss: 94.186 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 430/4776 | Loss: 98.111 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 440/4776 | Loss: 187.451 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 450/4776 | Loss: 169.824 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 460/4776 | Loss: 158.088 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 470/4776 | Loss: 105.095 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 480/4776 | Loss: 191.215 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 490/4776 | Loss: 114.050 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 500/4776 | Loss: 164.814 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 510/4776 | Loss: 96.735 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 520/4776 | Loss: 152.413 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 530/4776 | Loss: 144.142 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 540/4776 | Loss: 106.177 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 550/4776 | Loss: 110.427 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 560/4776 | Loss: 172.145 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 570/4776 | Loss: 144.696 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 580/4776 | Loss: 164.265 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 590/4776 | Loss: 131.680 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 600/4776 | Loss: 139.845 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 610/4776 | Loss: 175.928 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 620/4776 | Loss: 149.004 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 630/4776 | Loss: 131.967 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 640/4776 | Loss: 169.722 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 650/4776 | Loss: 149.216 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 660/4776 | Loss: 149.048 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 670/4776 | Loss: 191.197 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 680/4776 | Loss: 146.138 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 690/4776 | Loss: 153.379 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 700/4776 | Loss: 160.533 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 710/4776 | Loss: 94.721 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 720/4776 | Loss: 168.447 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 730/4776 | Loss: 158.632 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 740/4776 | Loss: 192.548 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 750/4776 | Loss: 115.866 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 760/4776 | Loss: 173.611 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 770/4776 | Loss: 152.637 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 780/4776 | Loss: 157.310 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 790/4776 | Loss: 146.767 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 800/4776 | Loss: 166.894 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 810/4776 | Loss: 127.790 | Accuracy: 0.900\n",
      "[Epoch: 42/200] - Step: 820/4776 | Loss: 130.689 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 830/4776 | Loss: 107.462 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 840/4776 | Loss: 152.798 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 850/4776 | Loss: 157.072 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 860/4776 | Loss: 166.680 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 870/4776 | Loss: 131.543 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 880/4776 | Loss: 185.480 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 890/4776 | Loss: 169.143 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 900/4776 | Loss: 105.741 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 910/4776 | Loss: 147.375 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 920/4776 | Loss: 155.098 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 930/4776 | Loss: 161.425 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 940/4776 | Loss: 117.295 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 950/4776 | Loss: 107.069 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 960/4776 | Loss: 169.142 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 970/4776 | Loss: 141.660 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 980/4776 | Loss: 155.626 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 990/4776 | Loss: 164.569 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1000/4776 | Loss: 141.658 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1010/4776 | Loss: 173.142 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1020/4776 | Loss: 142.979 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1030/4776 | Loss: 180.940 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1040/4776 | Loss: 155.447 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1050/4776 | Loss: 148.278 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1060/4776 | Loss: 125.850 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1070/4776 | Loss: 155.507 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1080/4776 | Loss: 237.175 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1090/4776 | Loss: 154.467 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1100/4776 | Loss: 104.961 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1110/4776 | Loss: 147.407 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1120/4776 | Loss: 162.526 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1130/4776 | Loss: 137.835 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1140/4776 | Loss: 112.253 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1150/4776 | Loss: 124.270 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1160/4776 | Loss: 176.763 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1170/4776 | Loss: 107.678 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1180/4776 | Loss: 157.410 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1190/4776 | Loss: 154.153 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1200/4776 | Loss: 164.280 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1210/4776 | Loss: 173.300 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1220/4776 | Loss: 119.914 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1230/4776 | Loss: 155.676 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1240/4776 | Loss: 168.812 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1250/4776 | Loss: 182.401 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1260/4776 | Loss: 132.026 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1270/4776 | Loss: 212.862 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 1280/4776 | Loss: 169.745 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1290/4776 | Loss: 163.543 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1300/4776 | Loss: 173.737 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1310/4776 | Loss: 158.497 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1320/4776 | Loss: 187.382 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1330/4776 | Loss: 133.693 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1340/4776 | Loss: 108.289 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1350/4776 | Loss: 119.150 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1360/4776 | Loss: 165.806 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1370/4776 | Loss: 146.288 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1380/4776 | Loss: 143.264 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1390/4776 | Loss: 131.048 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1400/4776 | Loss: 130.441 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1410/4776 | Loss: 184.036 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1420/4776 | Loss: 139.794 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1430/4776 | Loss: 126.497 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1440/4776 | Loss: 165.179 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1450/4776 | Loss: 125.712 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1460/4776 | Loss: 204.502 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1470/4776 | Loss: 137.053 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1480/4776 | Loss: 144.205 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1490/4776 | Loss: 171.297 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1500/4776 | Loss: 148.854 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1510/4776 | Loss: 142.625 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1520/4776 | Loss: 180.492 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1530/4776 | Loss: 141.511 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1540/4776 | Loss: 177.313 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1550/4776 | Loss: 138.092 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1560/4776 | Loss: 145.826 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1570/4776 | Loss: 165.724 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1580/4776 | Loss: 108.167 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1590/4776 | Loss: 133.259 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1600/4776 | Loss: 209.218 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1610/4776 | Loss: 207.448 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1620/4776 | Loss: 201.879 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1630/4776 | Loss: 123.707 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1640/4776 | Loss: 188.320 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1650/4776 | Loss: 119.421 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1660/4776 | Loss: 119.692 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1670/4776 | Loss: 165.438 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1680/4776 | Loss: 152.390 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1690/4776 | Loss: 145.128 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1700/4776 | Loss: 174.580 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1710/4776 | Loss: 160.043 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1720/4776 | Loss: 149.656 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1730/4776 | Loss: 170.759 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1740/4776 | Loss: 155.551 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1750/4776 | Loss: 148.867 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1760/4776 | Loss: 132.890 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1770/4776 | Loss: 146.438 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1780/4776 | Loss: 167.431 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1790/4776 | Loss: 156.932 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1800/4776 | Loss: 154.400 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1810/4776 | Loss: 227.212 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1820/4776 | Loss: 108.446 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1830/4776 | Loss: 126.264 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1840/4776 | Loss: 90.624 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1850/4776 | Loss: 170.979 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1860/4776 | Loss: 120.208 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1870/4776 | Loss: 127.797 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1880/4776 | Loss: 172.465 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1890/4776 | Loss: 73.873 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1900/4776 | Loss: 129.843 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 1910/4776 | Loss: 136.942 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 1920/4776 | Loss: 129.207 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1930/4776 | Loss: 141.417 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1940/4776 | Loss: 141.004 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 1950/4776 | Loss: 151.743 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1960/4776 | Loss: 142.445 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1970/4776 | Loss: 117.049 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 1980/4776 | Loss: 160.999 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1990/4776 | Loss: 196.170 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2000/4776 | Loss: 106.592 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2010/4776 | Loss: 181.715 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 2020/4776 | Loss: 155.034 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2030/4776 | Loss: 147.869 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2040/4776 | Loss: 112.756 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2050/4776 | Loss: 144.799 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2060/4776 | Loss: 200.313 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2070/4776 | Loss: 152.968 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2080/4776 | Loss: 167.176 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2090/4776 | Loss: 178.729 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2100/4776 | Loss: 136.636 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2110/4776 | Loss: 138.504 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2120/4776 | Loss: 144.925 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2130/4776 | Loss: 182.745 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2140/4776 | Loss: 120.540 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2150/4776 | Loss: 131.726 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2160/4776 | Loss: 86.160 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 2170/4776 | Loss: 161.014 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2180/4776 | Loss: 180.758 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2190/4776 | Loss: 156.583 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2200/4776 | Loss: 104.337 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2210/4776 | Loss: 171.550 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2220/4776 | Loss: 146.929 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2230/4776 | Loss: 122.201 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2240/4776 | Loss: 121.007 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2250/4776 | Loss: 129.274 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2260/4776 | Loss: 182.570 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2270/4776 | Loss: 147.715 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2280/4776 | Loss: 211.046 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2290/4776 | Loss: 131.409 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2300/4776 | Loss: 128.725 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2310/4776 | Loss: 130.663 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2320/4776 | Loss: 126.114 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2330/4776 | Loss: 200.235 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2340/4776 | Loss: 184.306 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2350/4776 | Loss: 106.137 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2360/4776 | Loss: 198.222 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2370/4776 | Loss: 202.871 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2380/4776 | Loss: 153.899 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2390/4776 | Loss: 141.284 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2400/4776 | Loss: 116.635 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2410/4776 | Loss: 184.358 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2420/4776 | Loss: 204.826 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2430/4776 | Loss: 185.578 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2440/4776 | Loss: 111.583 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2450/4776 | Loss: 116.720 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2460/4776 | Loss: 149.873 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2470/4776 | Loss: 157.468 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2480/4776 | Loss: 109.287 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2490/4776 | Loss: 207.628 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2500/4776 | Loss: 174.452 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2510/4776 | Loss: 170.334 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2520/4776 | Loss: 147.362 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2530/4776 | Loss: 152.826 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2540/4776 | Loss: 148.530 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2550/4776 | Loss: 141.525 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2560/4776 | Loss: 204.955 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2570/4776 | Loss: 197.030 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2580/4776 | Loss: 139.989 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2590/4776 | Loss: 137.814 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2600/4776 | Loss: 156.525 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2610/4776 | Loss: 107.164 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2620/4776 | Loss: 138.889 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2630/4776 | Loss: 189.161 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2640/4776 | Loss: 166.521 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2650/4776 | Loss: 118.623 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2660/4776 | Loss: 170.701 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2670/4776 | Loss: 115.501 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 2680/4776 | Loss: 205.923 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 2690/4776 | Loss: 161.378 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2700/4776 | Loss: 146.576 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2710/4776 | Loss: 191.390 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2720/4776 | Loss: 157.310 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2730/4776 | Loss: 166.659 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2740/4776 | Loss: 107.032 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2750/4776 | Loss: 139.253 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2760/4776 | Loss: 168.759 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2770/4776 | Loss: 137.997 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2780/4776 | Loss: 95.997 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2790/4776 | Loss: 140.461 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2800/4776 | Loss: 202.142 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2810/4776 | Loss: 149.450 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2820/4776 | Loss: 209.565 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2830/4776 | Loss: 129.740 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2840/4776 | Loss: 171.155 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2850/4776 | Loss: 140.756 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2860/4776 | Loss: 136.947 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2870/4776 | Loss: 134.577 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2880/4776 | Loss: 121.645 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2890/4776 | Loss: 101.218 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2900/4776 | Loss: 163.471 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 2910/4776 | Loss: 131.304 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2920/4776 | Loss: 151.122 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2930/4776 | Loss: 107.612 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2940/4776 | Loss: 125.056 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 2950/4776 | Loss: 118.571 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 2960/4776 | Loss: 107.930 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 2970/4776 | Loss: 157.365 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 2980/4776 | Loss: 129.482 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 2990/4776 | Loss: 166.551 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3000/4776 | Loss: 187.521 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3010/4776 | Loss: 163.556 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3020/4776 | Loss: 125.540 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3030/4776 | Loss: 126.235 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 3040/4776 | Loss: 185.273 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 3050/4776 | Loss: 154.782 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3060/4776 | Loss: 168.450 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 3070/4776 | Loss: 124.364 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3080/4776 | Loss: 100.681 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 3090/4776 | Loss: 148.611 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3100/4776 | Loss: 110.373 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 3110/4776 | Loss: 203.693 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3120/4776 | Loss: 143.116 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3130/4776 | Loss: 157.126 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3140/4776 | Loss: 145.841 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3150/4776 | Loss: 184.988 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3160/4776 | Loss: 172.211 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3170/4776 | Loss: 140.124 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3180/4776 | Loss: 128.933 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3190/4776 | Loss: 178.098 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3200/4776 | Loss: 130.757 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3210/4776 | Loss: 179.484 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3220/4776 | Loss: 170.450 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3230/4776 | Loss: 181.706 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3240/4776 | Loss: 149.100 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3250/4776 | Loss: 128.091 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3260/4776 | Loss: 231.607 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3270/4776 | Loss: 164.420 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3280/4776 | Loss: 166.470 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3290/4776 | Loss: 157.983 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3300/4776 | Loss: 161.814 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3310/4776 | Loss: 136.657 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3320/4776 | Loss: 152.480 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3330/4776 | Loss: 192.243 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3340/4776 | Loss: 132.398 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3350/4776 | Loss: 125.590 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3360/4776 | Loss: 134.274 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3370/4776 | Loss: 131.112 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3380/4776 | Loss: 111.449 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 3390/4776 | Loss: 131.714 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3400/4776 | Loss: 219.369 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3410/4776 | Loss: 158.249 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3420/4776 | Loss: 162.090 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3430/4776 | Loss: 137.427 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3440/4776 | Loss: 132.869 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3450/4776 | Loss: 254.684 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3460/4776 | Loss: 164.435 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3470/4776 | Loss: 137.960 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3480/4776 | Loss: 192.902 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3490/4776 | Loss: 144.472 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3500/4776 | Loss: 110.153 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3510/4776 | Loss: 192.753 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3520/4776 | Loss: 112.508 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 3530/4776 | Loss: 75.662 | Accuracy: 0.900\n",
      "[Epoch: 42/200] - Step: 3540/4776 | Loss: 104.577 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 3550/4776 | Loss: 147.963 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3560/4776 | Loss: 110.846 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3570/4776 | Loss: 142.032 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3580/4776 | Loss: 149.361 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3590/4776 | Loss: 181.538 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3600/4776 | Loss: 140.971 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3610/4776 | Loss: 79.159 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3620/4776 | Loss: 188.196 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 3630/4776 | Loss: 103.668 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3640/4776 | Loss: 164.442 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3650/4776 | Loss: 131.451 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3660/4776 | Loss: 126.548 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3670/4776 | Loss: 104.599 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3680/4776 | Loss: 153.422 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3690/4776 | Loss: 126.736 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 3700/4776 | Loss: 189.587 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 3710/4776 | Loss: 214.952 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3720/4776 | Loss: 137.675 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3730/4776 | Loss: 102.909 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3740/4776 | Loss: 69.372 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3750/4776 | Loss: 185.634 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3760/4776 | Loss: 135.709 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3770/4776 | Loss: 158.816 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3780/4776 | Loss: 128.530 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3790/4776 | Loss: 169.909 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3800/4776 | Loss: 143.758 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3810/4776 | Loss: 128.465 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 3820/4776 | Loss: 130.533 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3830/4776 | Loss: 121.903 | Accuracy: 0.800\n",
      "[Epoch: 42/200] - Step: 3840/4776 | Loss: 142.112 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3850/4776 | Loss: 142.251 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3860/4776 | Loss: 123.645 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3870/4776 | Loss: 147.890 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3880/4776 | Loss: 196.451 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3890/4776 | Loss: 138.594 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 3900/4776 | Loss: 112.042 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3910/4776 | Loss: 158.055 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3920/4776 | Loss: 129.226 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3930/4776 | Loss: 137.042 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3940/4776 | Loss: 204.016 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 3950/4776 | Loss: 147.324 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 3960/4776 | Loss: 208.217 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 3970/4776 | Loss: 188.521 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3980/4776 | Loss: 189.314 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 3990/4776 | Loss: 167.422 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4000/4776 | Loss: 182.660 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 4010/4776 | Loss: 114.732 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4020/4776 | Loss: 126.642 | Accuracy: 0.700\n",
      "[Epoch: 42/200] - Step: 4030/4776 | Loss: 122.776 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4040/4776 | Loss: 111.778 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4050/4776 | Loss: 125.819 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4060/4776 | Loss: 112.769 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4070/4776 | Loss: 197.017 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4080/4776 | Loss: 147.570 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4090/4776 | Loss: 212.628 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4100/4776 | Loss: 143.918 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4110/4776 | Loss: 153.903 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4120/4776 | Loss: 158.689 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4130/4776 | Loss: 158.849 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4140/4776 | Loss: 152.138 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4150/4776 | Loss: 196.070 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 4160/4776 | Loss: 141.473 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4170/4776 | Loss: 155.727 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4180/4776 | Loss: 129.377 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4190/4776 | Loss: 133.007 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4200/4776 | Loss: 183.035 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4210/4776 | Loss: 149.414 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4220/4776 | Loss: 161.743 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4230/4776 | Loss: 196.131 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4240/4776 | Loss: 112.972 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4250/4776 | Loss: 117.838 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4260/4776 | Loss: 191.433 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4270/4776 | Loss: 140.658 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4280/4776 | Loss: 135.930 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4290/4776 | Loss: 142.865 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4300/4776 | Loss: 139.680 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4310/4776 | Loss: 160.063 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4320/4776 | Loss: 104.515 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4330/4776 | Loss: 168.790 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4340/4776 | Loss: 132.494 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4350/4776 | Loss: 155.822 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4360/4776 | Loss: 152.876 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4370/4776 | Loss: 166.558 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4380/4776 | Loss: 177.696 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4390/4776 | Loss: 200.530 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 4400/4776 | Loss: 114.301 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4410/4776 | Loss: 192.898 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4420/4776 | Loss: 143.048 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4430/4776 | Loss: 141.735 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4440/4776 | Loss: 171.979 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 4450/4776 | Loss: 158.730 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4460/4776 | Loss: 146.142 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4470/4776 | Loss: 140.130 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4480/4776 | Loss: 150.298 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4490/4776 | Loss: 179.802 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4500/4776 | Loss: 133.065 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4510/4776 | Loss: 122.734 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4520/4776 | Loss: 156.670 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4530/4776 | Loss: 202.352 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4540/4776 | Loss: 149.150 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4550/4776 | Loss: 279.234 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4560/4776 | Loss: 170.556 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4570/4776 | Loss: 162.316 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4580/4776 | Loss: 143.551 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4590/4776 | Loss: 174.072 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4600/4776 | Loss: 188.170 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4610/4776 | Loss: 131.337 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4620/4776 | Loss: 171.578 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4630/4776 | Loss: 174.668 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4640/4776 | Loss: 129.817 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4650/4776 | Loss: 169.151 | Accuracy: 0.600\n",
      "[Epoch: 42/200] - Step: 4660/4776 | Loss: 169.167 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 4670/4776 | Loss: 188.596 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4680/4776 | Loss: 128.472 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4690/4776 | Loss: 146.567 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4700/4776 | Loss: 182.564 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4710/4776 | Loss: 172.432 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4720/4776 | Loss: 161.665 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4730/4776 | Loss: 181.685 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 4740/4776 | Loss: 124.792 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 4750/4776 | Loss: 228.657 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4760/4776 | Loss: 126.853 | Accuracy: 0.500\n",
      "[Epoch: 42/200] - Step: 4770/4776 | Loss: 116.335 | Accuracy: 0.600\n",
      "Accuracy:  0.2262295081967213\n",
      "Model saved!\n",
      "[Epoch: 43/200] - Step: 10/4776 | Loss: 155.154 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 20/4776 | Loss: 115.472 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 30/4776 | Loss: 192.687 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 40/4776 | Loss: 141.408 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 50/4776 | Loss: 173.520 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 60/4776 | Loss: 116.088 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 70/4776 | Loss: 133.936 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 80/4776 | Loss: 131.614 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 90/4776 | Loss: 71.390 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 100/4776 | Loss: 154.517 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 110/4776 | Loss: 121.526 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 120/4776 | Loss: 164.908 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 130/4776 | Loss: 117.009 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 140/4776 | Loss: 145.606 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 150/4776 | Loss: 73.322 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 160/4776 | Loss: 183.190 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 170/4776 | Loss: 106.643 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 180/4776 | Loss: 171.339 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 190/4776 | Loss: 154.879 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 200/4776 | Loss: 131.527 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 210/4776 | Loss: 158.543 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 220/4776 | Loss: 153.812 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 230/4776 | Loss: 128.762 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 240/4776 | Loss: 147.737 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 250/4776 | Loss: 79.065 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 260/4776 | Loss: 151.265 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 270/4776 | Loss: 158.280 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 280/4776 | Loss: 177.236 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 290/4776 | Loss: 85.786 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 300/4776 | Loss: 119.167 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 310/4776 | Loss: 132.130 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 320/4776 | Loss: 102.626 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 330/4776 | Loss: 130.508 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 340/4776 | Loss: 141.959 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 350/4776 | Loss: 133.681 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 360/4776 | Loss: 114.767 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 370/4776 | Loss: 100.036 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 380/4776 | Loss: 116.876 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 390/4776 | Loss: 170.480 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 400/4776 | Loss: 113.330 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 410/4776 | Loss: 138.826 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 420/4776 | Loss: 136.766 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 430/4776 | Loss: 116.033 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 440/4776 | Loss: 99.321 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 450/4776 | Loss: 109.533 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 460/4776 | Loss: 148.891 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 470/4776 | Loss: 101.195 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 480/4776 | Loss: 145.015 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 490/4776 | Loss: 116.046 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 500/4776 | Loss: 119.697 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 510/4776 | Loss: 123.428 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 520/4776 | Loss: 111.622 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 530/4776 | Loss: 149.757 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 540/4776 | Loss: 159.895 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 550/4776 | Loss: 98.500 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 560/4776 | Loss: 164.203 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 570/4776 | Loss: 91.806 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 580/4776 | Loss: 155.772 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 590/4776 | Loss: 134.194 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 600/4776 | Loss: 85.373 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 610/4776 | Loss: 167.003 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 620/4776 | Loss: 120.212 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 630/4776 | Loss: 114.117 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 640/4776 | Loss: 211.634 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 650/4776 | Loss: 145.314 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 660/4776 | Loss: 148.342 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 670/4776 | Loss: 138.859 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 680/4776 | Loss: 160.575 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 690/4776 | Loss: 197.464 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 700/4776 | Loss: 133.017 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 710/4776 | Loss: 207.169 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 720/4776 | Loss: 119.775 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 730/4776 | Loss: 130.097 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 740/4776 | Loss: 124.922 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 750/4776 | Loss: 133.729 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 760/4776 | Loss: 146.880 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 770/4776 | Loss: 132.538 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 780/4776 | Loss: 151.379 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 790/4776 | Loss: 186.992 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 800/4776 | Loss: 153.452 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 810/4776 | Loss: 101.557 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 820/4776 | Loss: 95.101 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 830/4776 | Loss: 175.144 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 840/4776 | Loss: 141.177 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 850/4776 | Loss: 355.051 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 860/4776 | Loss: 222.315 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 870/4776 | Loss: 180.579 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 880/4776 | Loss: 113.215 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 890/4776 | Loss: 116.131 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 900/4776 | Loss: 152.033 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 910/4776 | Loss: 180.532 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 920/4776 | Loss: 136.743 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 930/4776 | Loss: 134.543 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 940/4776 | Loss: 132.286 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 950/4776 | Loss: 177.910 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 960/4776 | Loss: 125.012 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 970/4776 | Loss: 104.518 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 980/4776 | Loss: 111.059 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 990/4776 | Loss: 127.088 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1000/4776 | Loss: 118.783 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1010/4776 | Loss: 170.675 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1020/4776 | Loss: 89.400 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 1030/4776 | Loss: 151.665 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1040/4776 | Loss: 144.165 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1050/4776 | Loss: 115.276 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1060/4776 | Loss: 109.366 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1070/4776 | Loss: 173.399 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1080/4776 | Loss: 142.647 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1090/4776 | Loss: 107.707 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1100/4776 | Loss: 123.449 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1110/4776 | Loss: 129.289 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1120/4776 | Loss: 126.037 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1130/4776 | Loss: 165.871 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1140/4776 | Loss: 119.291 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1150/4776 | Loss: 181.077 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1160/4776 | Loss: 164.633 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1170/4776 | Loss: 127.697 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1180/4776 | Loss: 231.871 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1190/4776 | Loss: 119.110 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1200/4776 | Loss: 131.452 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1210/4776 | Loss: 154.554 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1220/4776 | Loss: 152.515 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1230/4776 | Loss: 147.490 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1240/4776 | Loss: 114.199 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1250/4776 | Loss: 136.993 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1260/4776 | Loss: 113.046 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1270/4776 | Loss: 124.946 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1280/4776 | Loss: 102.506 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1290/4776 | Loss: 142.302 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1300/4776 | Loss: 165.808 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1310/4776 | Loss: 171.406 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1320/4776 | Loss: 127.642 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1330/4776 | Loss: 170.474 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1340/4776 | Loss: 87.583 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 1350/4776 | Loss: 140.371 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1360/4776 | Loss: 161.984 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1370/4776 | Loss: 154.871 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1380/4776 | Loss: 139.029 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1390/4776 | Loss: 143.634 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1400/4776 | Loss: 170.713 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1410/4776 | Loss: 161.660 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1420/4776 | Loss: 132.003 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1430/4776 | Loss: 126.568 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1440/4776 | Loss: 163.199 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1450/4776 | Loss: 130.608 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1460/4776 | Loss: 120.703 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1470/4776 | Loss: 175.394 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1480/4776 | Loss: 117.159 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1490/4776 | Loss: 140.234 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1500/4776 | Loss: 143.456 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1510/4776 | Loss: 86.161 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 1520/4776 | Loss: 115.641 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1530/4776 | Loss: 179.126 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1540/4776 | Loss: 183.560 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1550/4776 | Loss: 148.610 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1560/4776 | Loss: 142.184 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1570/4776 | Loss: 160.478 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1580/4776 | Loss: 144.200 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1590/4776 | Loss: 250.498 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1600/4776 | Loss: 164.292 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1610/4776 | Loss: 208.705 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1620/4776 | Loss: 105.207 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1630/4776 | Loss: 125.452 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1640/4776 | Loss: 160.626 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1650/4776 | Loss: 181.054 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1660/4776 | Loss: 165.114 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1670/4776 | Loss: 164.300 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1680/4776 | Loss: 115.158 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1690/4776 | Loss: 166.762 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1700/4776 | Loss: 73.361 | Accuracy: 0.900\n",
      "[Epoch: 43/200] - Step: 1710/4776 | Loss: 154.049 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1720/4776 | Loss: 161.772 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1730/4776 | Loss: 133.810 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1740/4776 | Loss: 143.325 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1750/4776 | Loss: 99.186 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1760/4776 | Loss: 123.452 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1770/4776 | Loss: 122.747 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1780/4776 | Loss: 98.055 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1790/4776 | Loss: 147.045 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1800/4776 | Loss: 101.819 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 1810/4776 | Loss: 168.114 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1820/4776 | Loss: 126.725 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1830/4776 | Loss: 129.548 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1840/4776 | Loss: 189.849 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1850/4776 | Loss: 92.772 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 1860/4776 | Loss: 199.896 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1870/4776 | Loss: 138.382 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1880/4776 | Loss: 140.227 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1890/4776 | Loss: 142.563 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1900/4776 | Loss: 173.633 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1910/4776 | Loss: 185.510 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1920/4776 | Loss: 156.590 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1930/4776 | Loss: 120.215 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1940/4776 | Loss: 196.286 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1950/4776 | Loss: 158.955 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1960/4776 | Loss: 172.853 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1970/4776 | Loss: 120.042 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 1980/4776 | Loss: 158.460 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 1990/4776 | Loss: 173.223 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2000/4776 | Loss: 158.340 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2010/4776 | Loss: 126.942 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2020/4776 | Loss: 134.917 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2030/4776 | Loss: 130.487 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2040/4776 | Loss: 126.262 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2050/4776 | Loss: 135.172 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2060/4776 | Loss: 139.361 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2070/4776 | Loss: 131.025 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2080/4776 | Loss: 100.854 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2090/4776 | Loss: 105.102 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2100/4776 | Loss: 119.956 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 2110/4776 | Loss: 135.057 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2120/4776 | Loss: 145.797 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2130/4776 | Loss: 121.041 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2140/4776 | Loss: 148.439 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2150/4776 | Loss: 152.203 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2160/4776 | Loss: 141.370 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2170/4776 | Loss: 82.838 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2180/4776 | Loss: 138.954 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2190/4776 | Loss: 156.383 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2200/4776 | Loss: 138.424 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2210/4776 | Loss: 166.489 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2220/4776 | Loss: 160.699 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2230/4776 | Loss: 163.076 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2240/4776 | Loss: 112.877 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2250/4776 | Loss: 124.643 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2260/4776 | Loss: 104.111 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2270/4776 | Loss: 172.412 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 2280/4776 | Loss: 139.956 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2290/4776 | Loss: 165.400 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2300/4776 | Loss: 121.284 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2310/4776 | Loss: 110.187 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2320/4776 | Loss: 150.365 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2330/4776 | Loss: 144.168 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2340/4776 | Loss: 180.831 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2350/4776 | Loss: 83.194 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 2360/4776 | Loss: 129.512 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2370/4776 | Loss: 189.770 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2380/4776 | Loss: 123.051 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2390/4776 | Loss: 180.460 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2400/4776 | Loss: 208.169 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2410/4776 | Loss: 172.578 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2420/4776 | Loss: 119.702 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2430/4776 | Loss: 155.620 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2440/4776 | Loss: 162.595 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2450/4776 | Loss: 211.325 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 2460/4776 | Loss: 185.182 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2470/4776 | Loss: 151.541 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2480/4776 | Loss: 175.514 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2490/4776 | Loss: 156.210 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2500/4776 | Loss: 113.820 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2510/4776 | Loss: 101.280 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 2520/4776 | Loss: 133.078 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2530/4776 | Loss: 135.872 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2540/4776 | Loss: 158.987 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2550/4776 | Loss: 157.277 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2560/4776 | Loss: 208.374 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2570/4776 | Loss: 175.298 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2580/4776 | Loss: 160.534 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2590/4776 | Loss: 184.016 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2600/4776 | Loss: 157.179 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2610/4776 | Loss: 178.219 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2620/4776 | Loss: 137.357 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2630/4776 | Loss: 187.778 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 2640/4776 | Loss: 171.192 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2650/4776 | Loss: 156.883 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2660/4776 | Loss: 163.421 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2670/4776 | Loss: 178.840 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2680/4776 | Loss: 125.797 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2690/4776 | Loss: 154.630 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2700/4776 | Loss: 178.769 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2710/4776 | Loss: 152.553 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2720/4776 | Loss: 159.496 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2730/4776 | Loss: 158.913 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2740/4776 | Loss: 110.473 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 2750/4776 | Loss: 202.026 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2760/4776 | Loss: 199.302 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2770/4776 | Loss: 167.115 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2780/4776 | Loss: 202.396 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 2790/4776 | Loss: 114.770 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2800/4776 | Loss: 167.744 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2810/4776 | Loss: 131.133 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2820/4776 | Loss: 142.489 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2830/4776 | Loss: 166.125 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2840/4776 | Loss: 110.082 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2850/4776 | Loss: 110.014 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2860/4776 | Loss: 126.447 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2870/4776 | Loss: 145.154 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2880/4776 | Loss: 183.300 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2890/4776 | Loss: 160.147 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2900/4776 | Loss: 150.642 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 2910/4776 | Loss: 139.036 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2920/4776 | Loss: 84.213 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2930/4776 | Loss: 96.840 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 2940/4776 | Loss: 149.508 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 2950/4776 | Loss: 165.677 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 2960/4776 | Loss: 97.753 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 2970/4776 | Loss: 102.283 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2980/4776 | Loss: 157.695 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 2990/4776 | Loss: 88.323 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3000/4776 | Loss: 179.321 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3010/4776 | Loss: 133.524 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3020/4776 | Loss: 165.797 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3030/4776 | Loss: 148.347 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3040/4776 | Loss: 163.222 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3050/4776 | Loss: 147.143 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3060/4776 | Loss: 102.935 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3070/4776 | Loss: 208.354 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3080/4776 | Loss: 157.417 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3090/4776 | Loss: 197.366 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3100/4776 | Loss: 148.055 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3110/4776 | Loss: 194.000 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3120/4776 | Loss: 139.927 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3130/4776 | Loss: 134.726 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3140/4776 | Loss: 162.450 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3150/4776 | Loss: 122.298 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3160/4776 | Loss: 150.510 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3170/4776 | Loss: 142.703 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3180/4776 | Loss: 157.094 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3190/4776 | Loss: 135.464 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3200/4776 | Loss: 159.908 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3210/4776 | Loss: 167.656 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3220/4776 | Loss: 247.507 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3230/4776 | Loss: 174.349 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3240/4776 | Loss: 117.814 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3250/4776 | Loss: 194.266 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3260/4776 | Loss: 135.168 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3270/4776 | Loss: 141.224 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3280/4776 | Loss: 123.264 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3290/4776 | Loss: 224.368 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3300/4776 | Loss: 157.233 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3310/4776 | Loss: 129.433 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3320/4776 | Loss: 113.006 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3330/4776 | Loss: 165.037 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3340/4776 | Loss: 131.452 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3350/4776 | Loss: 226.866 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3360/4776 | Loss: 176.984 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3370/4776 | Loss: 152.157 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3380/4776 | Loss: 150.331 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3390/4776 | Loss: 119.457 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3400/4776 | Loss: 138.935 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3410/4776 | Loss: 176.793 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3420/4776 | Loss: 192.038 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3430/4776 | Loss: 144.710 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3440/4776 | Loss: 132.183 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3450/4776 | Loss: 151.140 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3460/4776 | Loss: 117.439 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3470/4776 | Loss: 139.560 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3480/4776 | Loss: 195.830 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3490/4776 | Loss: 153.574 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3500/4776 | Loss: 164.265 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3510/4776 | Loss: 123.026 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3520/4776 | Loss: 96.787 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3530/4776 | Loss: 137.855 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3540/4776 | Loss: 171.613 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3550/4776 | Loss: 135.478 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3560/4776 | Loss: 189.576 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3570/4776 | Loss: 107.755 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3580/4776 | Loss: 149.450 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3590/4776 | Loss: 114.777 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3600/4776 | Loss: 202.073 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3610/4776 | Loss: 198.915 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3620/4776 | Loss: 105.247 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3630/4776 | Loss: 121.541 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3640/4776 | Loss: 181.987 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3650/4776 | Loss: 118.306 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3660/4776 | Loss: 141.572 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3670/4776 | Loss: 155.846 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3680/4776 | Loss: 208.825 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3690/4776 | Loss: 122.885 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3700/4776 | Loss: 206.022 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3710/4776 | Loss: 135.368 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3720/4776 | Loss: 182.014 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3730/4776 | Loss: 104.130 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3740/4776 | Loss: 180.272 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3750/4776 | Loss: 97.551 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3760/4776 | Loss: 141.605 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3770/4776 | Loss: 136.192 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3780/4776 | Loss: 151.659 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3790/4776 | Loss: 182.376 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3800/4776 | Loss: 156.376 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3810/4776 | Loss: 115.137 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3820/4776 | Loss: 138.889 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3830/4776 | Loss: 110.676 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3840/4776 | Loss: 116.055 | Accuracy: 0.800\n",
      "[Epoch: 43/200] - Step: 3850/4776 | Loss: 165.013 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3860/4776 | Loss: 143.322 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3870/4776 | Loss: 165.741 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3880/4776 | Loss: 117.948 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3890/4776 | Loss: 190.194 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3900/4776 | Loss: 193.824 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 3910/4776 | Loss: 109.435 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3920/4776 | Loss: 151.194 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 3930/4776 | Loss: 145.428 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 3940/4776 | Loss: 119.061 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3950/4776 | Loss: 127.918 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3960/4776 | Loss: 124.666 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 3970/4776 | Loss: 130.784 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 3980/4776 | Loss: 107.974 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 3990/4776 | Loss: 207.789 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4000/4776 | Loss: 141.163 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4010/4776 | Loss: 114.905 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4020/4776 | Loss: 125.581 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4030/4776 | Loss: 161.459 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4040/4776 | Loss: 164.025 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4050/4776 | Loss: 130.842 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4060/4776 | Loss: 159.967 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4070/4776 | Loss: 152.811 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4080/4776 | Loss: 190.284 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4090/4776 | Loss: 137.619 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4100/4776 | Loss: 181.704 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4110/4776 | Loss: 139.567 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4120/4776 | Loss: 171.435 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4130/4776 | Loss: 158.515 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4140/4776 | Loss: 192.373 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4150/4776 | Loss: 135.649 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4160/4776 | Loss: 189.810 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4170/4776 | Loss: 103.286 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4180/4776 | Loss: 137.675 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4190/4776 | Loss: 171.844 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4200/4776 | Loss: 181.383 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4210/4776 | Loss: 99.827 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4220/4776 | Loss: 165.802 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4230/4776 | Loss: 75.764 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4240/4776 | Loss: 109.854 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4250/4776 | Loss: 166.564 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4260/4776 | Loss: 132.197 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4270/4776 | Loss: 185.077 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 4280/4776 | Loss: 148.831 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4290/4776 | Loss: 210.606 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4300/4776 | Loss: 175.153 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4310/4776 | Loss: 144.465 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4320/4776 | Loss: 223.662 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4330/4776 | Loss: 127.292 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4340/4776 | Loss: 122.478 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4350/4776 | Loss: 141.503 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4360/4776 | Loss: 183.972 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4370/4776 | Loss: 156.410 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4380/4776 | Loss: 120.241 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4390/4776 | Loss: 130.277 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4400/4776 | Loss: 159.634 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4410/4776 | Loss: 143.764 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4420/4776 | Loss: 87.626 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4430/4776 | Loss: 106.770 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4440/4776 | Loss: 111.189 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4450/4776 | Loss: 267.861 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 4460/4776 | Loss: 158.886 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4470/4776 | Loss: 176.689 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4480/4776 | Loss: 187.014 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4490/4776 | Loss: 127.648 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4500/4776 | Loss: 180.568 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4510/4776 | Loss: 158.094 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4520/4776 | Loss: 152.648 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4530/4776 | Loss: 157.232 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4540/4776 | Loss: 144.448 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4550/4776 | Loss: 117.272 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4560/4776 | Loss: 136.476 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4570/4776 | Loss: 157.570 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4580/4776 | Loss: 161.521 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4590/4776 | Loss: 141.891 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4600/4776 | Loss: 103.180 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4610/4776 | Loss: 149.643 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4620/4776 | Loss: 142.870 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4630/4776 | Loss: 150.460 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4640/4776 | Loss: 160.380 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4650/4776 | Loss: 115.049 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4660/4776 | Loss: 130.717 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4670/4776 | Loss: 165.398 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4680/4776 | Loss: 127.017 | Accuracy: 0.500\n",
      "[Epoch: 43/200] - Step: 4690/4776 | Loss: 104.312 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4700/4776 | Loss: 109.835 | Accuracy: 0.600\n",
      "[Epoch: 43/200] - Step: 4710/4776 | Loss: 170.292 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 4720/4776 | Loss: 190.811 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4730/4776 | Loss: 140.682 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 4740/4776 | Loss: 99.285 | Accuracy: 0.700\n",
      "[Epoch: 43/200] - Step: 4750/4776 | Loss: 129.550 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 4760/4776 | Loss: 188.479 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 4770/4776 | Loss: 112.050 | Accuracy: 0.600\n",
      "Accuracy:  0.17868852459016393\n",
      "[Epoch: 44/200] - Step: 10/4776 | Loss: 133.276 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 20/4776 | Loss: 147.988 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 30/4776 | Loss: 137.227 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 40/4776 | Loss: 121.234 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 50/4776 | Loss: 127.658 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 60/4776 | Loss: 109.272 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 70/4776 | Loss: 143.415 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 80/4776 | Loss: 180.129 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 90/4776 | Loss: 149.210 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 100/4776 | Loss: 138.001 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 110/4776 | Loss: 114.220 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 120/4776 | Loss: 214.153 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 130/4776 | Loss: 158.404 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 140/4776 | Loss: 141.931 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 150/4776 | Loss: 166.249 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 160/4776 | Loss: 106.851 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 170/4776 | Loss: 123.597 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 180/4776 | Loss: 176.644 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 190/4776 | Loss: 121.918 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 200/4776 | Loss: 101.079 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 210/4776 | Loss: 136.517 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 220/4776 | Loss: 120.808 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 230/4776 | Loss: 84.718 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 240/4776 | Loss: 163.729 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 250/4776 | Loss: 175.082 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 260/4776 | Loss: 150.602 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 270/4776 | Loss: 109.603 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 280/4776 | Loss: 142.308 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 290/4776 | Loss: 88.033 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 300/4776 | Loss: 124.980 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 310/4776 | Loss: 133.897 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 320/4776 | Loss: 135.512 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 330/4776 | Loss: 194.784 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 340/4776 | Loss: 196.988 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 350/4776 | Loss: 138.219 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 360/4776 | Loss: 121.472 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 370/4776 | Loss: 113.388 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 380/4776 | Loss: 120.410 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 390/4776 | Loss: 152.074 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 400/4776 | Loss: 165.521 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 410/4776 | Loss: 170.473 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 420/4776 | Loss: 161.121 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 430/4776 | Loss: 124.263 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 440/4776 | Loss: 134.910 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 450/4776 | Loss: 188.779 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 460/4776 | Loss: 95.569 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 470/4776 | Loss: 162.102 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 480/4776 | Loss: 120.847 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 490/4776 | Loss: 93.735 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 500/4776 | Loss: 127.949 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 510/4776 | Loss: 133.873 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 520/4776 | Loss: 109.235 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 530/4776 | Loss: 188.591 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 540/4776 | Loss: 162.719 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 550/4776 | Loss: 133.378 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 560/4776 | Loss: 149.345 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 570/4776 | Loss: 145.348 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 580/4776 | Loss: 120.246 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 590/4776 | Loss: 139.994 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 600/4776 | Loss: 138.681 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 610/4776 | Loss: 104.824 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 620/4776 | Loss: 155.491 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 630/4776 | Loss: 160.383 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 640/4776 | Loss: 96.665 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 650/4776 | Loss: 165.545 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 660/4776 | Loss: 176.587 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 670/4776 | Loss: 183.329 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 680/4776 | Loss: 155.394 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 690/4776 | Loss: 158.926 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 700/4776 | Loss: 119.794 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 710/4776 | Loss: 138.119 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 720/4776 | Loss: 125.997 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 730/4776 | Loss: 118.131 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 740/4776 | Loss: 188.415 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 750/4776 | Loss: 188.553 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 760/4776 | Loss: 125.510 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 770/4776 | Loss: 139.819 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 780/4776 | Loss: 104.759 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 790/4776 | Loss: 189.369 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 800/4776 | Loss: 124.675 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 810/4776 | Loss: 167.313 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 820/4776 | Loss: 146.761 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 830/4776 | Loss: 154.616 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 840/4776 | Loss: 132.862 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 850/4776 | Loss: 105.682 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 860/4776 | Loss: 137.012 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 870/4776 | Loss: 130.603 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 880/4776 | Loss: 147.629 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 890/4776 | Loss: 91.205 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 900/4776 | Loss: 121.515 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 910/4776 | Loss: 165.847 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 920/4776 | Loss: 90.429 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 930/4776 | Loss: 140.844 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 940/4776 | Loss: 180.173 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 950/4776 | Loss: 125.295 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 960/4776 | Loss: 98.450 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 970/4776 | Loss: 152.574 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 980/4776 | Loss: 119.450 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 990/4776 | Loss: 110.497 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1000/4776 | Loss: 133.924 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1010/4776 | Loss: 122.605 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1020/4776 | Loss: 110.887 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1030/4776 | Loss: 108.805 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1040/4776 | Loss: 105.308 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1050/4776 | Loss: 156.193 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1060/4776 | Loss: 126.564 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1070/4776 | Loss: 163.101 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1080/4776 | Loss: 199.882 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 1090/4776 | Loss: 83.856 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1100/4776 | Loss: 157.732 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1110/4776 | Loss: 151.690 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1120/4776 | Loss: 146.057 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1130/4776 | Loss: 83.861 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1140/4776 | Loss: 169.161 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1150/4776 | Loss: 124.919 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1160/4776 | Loss: 90.342 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 1170/4776 | Loss: 76.646 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1180/4776 | Loss: 148.603 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1190/4776 | Loss: 106.432 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1200/4776 | Loss: 128.237 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1210/4776 | Loss: 100.033 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1220/4776 | Loss: 116.046 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1230/4776 | Loss: 122.820 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1240/4776 | Loss: 79.506 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1250/4776 | Loss: 193.325 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1260/4776 | Loss: 131.111 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1270/4776 | Loss: 139.840 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1280/4776 | Loss: 167.871 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1290/4776 | Loss: 114.597 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1300/4776 | Loss: 122.104 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1310/4776 | Loss: 157.230 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1320/4776 | Loss: 188.292 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1330/4776 | Loss: 134.697 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1340/4776 | Loss: 125.218 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1350/4776 | Loss: 142.181 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1360/4776 | Loss: 216.689 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1370/4776 | Loss: 113.437 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1380/4776 | Loss: 110.959 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1390/4776 | Loss: 159.993 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1400/4776 | Loss: 189.203 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1410/4776 | Loss: 160.257 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1420/4776 | Loss: 198.572 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1430/4776 | Loss: 139.791 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1440/4776 | Loss: 123.500 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1450/4776 | Loss: 158.092 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1460/4776 | Loss: 150.567 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1470/4776 | Loss: 183.191 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1480/4776 | Loss: 150.839 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1490/4776 | Loss: 165.576 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1500/4776 | Loss: 186.772 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1510/4776 | Loss: 87.503 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1520/4776 | Loss: 169.128 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1530/4776 | Loss: 116.394 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1540/4776 | Loss: 150.398 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1550/4776 | Loss: 165.817 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1560/4776 | Loss: 209.644 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1570/4776 | Loss: 141.284 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1580/4776 | Loss: 159.500 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1590/4776 | Loss: 121.975 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1600/4776 | Loss: 135.964 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1610/4776 | Loss: 114.893 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1620/4776 | Loss: 112.095 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1630/4776 | Loss: 132.103 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1640/4776 | Loss: 115.221 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1650/4776 | Loss: 148.702 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1660/4776 | Loss: 152.178 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1670/4776 | Loss: 142.933 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1680/4776 | Loss: 187.660 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1690/4776 | Loss: 145.723 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1700/4776 | Loss: 184.535 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 1710/4776 | Loss: 82.935 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1720/4776 | Loss: 148.966 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1730/4776 | Loss: 168.406 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1740/4776 | Loss: 108.142 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1750/4776 | Loss: 160.223 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1760/4776 | Loss: 155.303 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1770/4776 | Loss: 124.150 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1780/4776 | Loss: 149.667 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1790/4776 | Loss: 127.331 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1800/4776 | Loss: 135.679 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 1810/4776 | Loss: 152.180 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1820/4776 | Loss: 131.751 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1830/4776 | Loss: 170.700 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1840/4776 | Loss: 228.757 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1850/4776 | Loss: 140.431 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1860/4776 | Loss: 124.417 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1870/4776 | Loss: 175.270 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1880/4776 | Loss: 130.328 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1890/4776 | Loss: 144.610 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1900/4776 | Loss: 153.143 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1910/4776 | Loss: 226.480 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1920/4776 | Loss: 144.795 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1930/4776 | Loss: 159.861 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1940/4776 | Loss: 170.611 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 1950/4776 | Loss: 147.516 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1960/4776 | Loss: 153.033 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1970/4776 | Loss: 82.588 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 1980/4776 | Loss: 129.542 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1990/4776 | Loss: 110.926 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2000/4776 | Loss: 133.302 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2010/4776 | Loss: 132.568 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2020/4776 | Loss: 169.925 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2030/4776 | Loss: 139.828 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2040/4776 | Loss: 156.247 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2050/4776 | Loss: 147.887 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2060/4776 | Loss: 169.857 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2070/4776 | Loss: 158.540 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2080/4776 | Loss: 153.564 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2090/4776 | Loss: 124.977 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2100/4776 | Loss: 167.235 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2110/4776 | Loss: 180.698 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2120/4776 | Loss: 199.969 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 2130/4776 | Loss: 184.736 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 2140/4776 | Loss: 158.586 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2150/4776 | Loss: 168.088 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 2160/4776 | Loss: 113.464 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2170/4776 | Loss: 117.765 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2180/4776 | Loss: 140.971 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2190/4776 | Loss: 136.690 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2200/4776 | Loss: 87.289 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 2210/4776 | Loss: 143.210 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2220/4776 | Loss: 151.934 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2230/4776 | Loss: 175.573 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 2240/4776 | Loss: 151.074 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2250/4776 | Loss: 135.658 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2260/4776 | Loss: 139.077 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2270/4776 | Loss: 131.329 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2280/4776 | Loss: 145.639 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2290/4776 | Loss: 184.058 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2300/4776 | Loss: 208.690 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 2310/4776 | Loss: 126.394 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2320/4776 | Loss: 120.855 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2330/4776 | Loss: 162.286 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2340/4776 | Loss: 151.590 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2350/4776 | Loss: 152.675 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2360/4776 | Loss: 151.366 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2370/4776 | Loss: 111.641 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2380/4776 | Loss: 115.117 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2390/4776 | Loss: 135.585 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2400/4776 | Loss: 136.567 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2410/4776 | Loss: 140.934 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2420/4776 | Loss: 137.673 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2430/4776 | Loss: 106.328 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2440/4776 | Loss: 151.035 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2450/4776 | Loss: 135.970 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2460/4776 | Loss: 91.702 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2470/4776 | Loss: 189.726 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 2480/4776 | Loss: 151.890 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2490/4776 | Loss: 103.239 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2500/4776 | Loss: 131.447 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2510/4776 | Loss: 109.547 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2520/4776 | Loss: 87.868 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2530/4776 | Loss: 136.589 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2540/4776 | Loss: 118.047 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2550/4776 | Loss: 166.467 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2560/4776 | Loss: 133.478 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2570/4776 | Loss: 196.439 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2580/4776 | Loss: 146.986 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2590/4776 | Loss: 186.028 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2600/4776 | Loss: 158.479 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2610/4776 | Loss: 165.741 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2620/4776 | Loss: 141.207 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2630/4776 | Loss: 74.673 | Accuracy: 0.900\n",
      "[Epoch: 44/200] - Step: 2640/4776 | Loss: 152.219 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2650/4776 | Loss: 109.647 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2660/4776 | Loss: 156.588 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2670/4776 | Loss: 122.604 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2680/4776 | Loss: 139.202 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2690/4776 | Loss: 110.905 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2700/4776 | Loss: 111.116 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2710/4776 | Loss: 140.206 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2720/4776 | Loss: 137.137 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2730/4776 | Loss: 130.275 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2740/4776 | Loss: 78.835 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2750/4776 | Loss: 141.330 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2760/4776 | Loss: 122.795 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2770/4776 | Loss: 139.062 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2780/4776 | Loss: 136.013 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2790/4776 | Loss: 131.912 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2800/4776 | Loss: 127.047 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2810/4776 | Loss: 212.762 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 2820/4776 | Loss: 129.859 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2830/4776 | Loss: 107.104 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2840/4776 | Loss: 147.556 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2850/4776 | Loss: 162.201 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2860/4776 | Loss: 119.872 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2870/4776 | Loss: 119.565 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2880/4776 | Loss: 140.283 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2890/4776 | Loss: 103.970 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 2900/4776 | Loss: 169.017 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2910/4776 | Loss: 181.087 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2920/4776 | Loss: 136.532 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2930/4776 | Loss: 171.697 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 2940/4776 | Loss: 181.136 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2950/4776 | Loss: 114.856 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 2960/4776 | Loss: 140.128 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2970/4776 | Loss: 130.914 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 2980/4776 | Loss: 137.606 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 2990/4776 | Loss: 147.087 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3000/4776 | Loss: 109.876 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3010/4776 | Loss: 211.740 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3020/4776 | Loss: 192.548 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3030/4776 | Loss: 167.813 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3040/4776 | Loss: 132.450 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3050/4776 | Loss: 172.098 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3060/4776 | Loss: 133.343 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3070/4776 | Loss: 73.262 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 3080/4776 | Loss: 131.443 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3090/4776 | Loss: 139.980 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3100/4776 | Loss: 170.691 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3110/4776 | Loss: 172.770 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3120/4776 | Loss: 171.591 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3130/4776 | Loss: 181.606 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3140/4776 | Loss: 123.943 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3150/4776 | Loss: 126.970 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3160/4776 | Loss: 168.615 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3170/4776 | Loss: 193.220 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3180/4776 | Loss: 134.597 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3190/4776 | Loss: 175.280 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3200/4776 | Loss: 96.728 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3210/4776 | Loss: 117.088 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3220/4776 | Loss: 130.843 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3230/4776 | Loss: 109.448 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 3240/4776 | Loss: 149.588 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3250/4776 | Loss: 203.474 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 3260/4776 | Loss: 155.269 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3270/4776 | Loss: 140.865 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3280/4776 | Loss: 182.656 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3290/4776 | Loss: 160.719 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3300/4776 | Loss: 196.465 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3310/4776 | Loss: 136.741 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3320/4776 | Loss: 173.265 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3330/4776 | Loss: 122.938 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3340/4776 | Loss: 140.044 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3350/4776 | Loss: 138.670 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3360/4776 | Loss: 170.180 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3370/4776 | Loss: 157.870 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3380/4776 | Loss: 140.027 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3390/4776 | Loss: 107.173 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3400/4776 | Loss: 142.646 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3410/4776 | Loss: 115.247 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3420/4776 | Loss: 192.902 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3430/4776 | Loss: 112.188 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3440/4776 | Loss: 164.711 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3450/4776 | Loss: 221.063 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 3460/4776 | Loss: 156.462 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3470/4776 | Loss: 161.715 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3480/4776 | Loss: 124.216 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3490/4776 | Loss: 130.297 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3500/4776 | Loss: 157.816 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3510/4776 | Loss: 184.162 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3520/4776 | Loss: 149.632 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3530/4776 | Loss: 106.168 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3540/4776 | Loss: 134.261 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3550/4776 | Loss: 166.537 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3560/4776 | Loss: 123.044 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3570/4776 | Loss: 122.368 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3580/4776 | Loss: 113.221 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3590/4776 | Loss: 196.792 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3600/4776 | Loss: 116.696 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3610/4776 | Loss: 159.199 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3620/4776 | Loss: 160.897 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3630/4776 | Loss: 201.724 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3640/4776 | Loss: 175.715 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3650/4776 | Loss: 151.686 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3660/4776 | Loss: 90.361 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 3670/4776 | Loss: 169.372 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3680/4776 | Loss: 104.252 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 3690/4776 | Loss: 134.341 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3700/4776 | Loss: 144.546 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3710/4776 | Loss: 135.257 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3720/4776 | Loss: 114.178 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3730/4776 | Loss: 181.040 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3740/4776 | Loss: 133.506 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3750/4776 | Loss: 124.780 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3760/4776 | Loss: 154.200 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3770/4776 | Loss: 132.326 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3780/4776 | Loss: 138.736 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3790/4776 | Loss: 162.160 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3800/4776 | Loss: 107.502 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 3810/4776 | Loss: 163.704 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3820/4776 | Loss: 165.282 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3830/4776 | Loss: 137.662 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3840/4776 | Loss: 146.742 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3850/4776 | Loss: 167.995 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3860/4776 | Loss: 165.829 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 3870/4776 | Loss: 154.874 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3880/4776 | Loss: 152.473 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 3890/4776 | Loss: 136.401 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3900/4776 | Loss: 188.164 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3910/4776 | Loss: 161.717 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3920/4776 | Loss: 157.120 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3930/4776 | Loss: 142.569 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3940/4776 | Loss: 149.372 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 3950/4776 | Loss: 153.214 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3960/4776 | Loss: 145.869 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3970/4776 | Loss: 146.622 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 3980/4776 | Loss: 119.197 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 3990/4776 | Loss: 131.057 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4000/4776 | Loss: 123.400 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4010/4776 | Loss: 66.388 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 4020/4776 | Loss: 118.112 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4030/4776 | Loss: 139.738 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4040/4776 | Loss: 130.164 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4050/4776 | Loss: 128.523 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4060/4776 | Loss: 161.700 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4070/4776 | Loss: 128.348 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4080/4776 | Loss: 114.848 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4090/4776 | Loss: 165.021 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4100/4776 | Loss: 165.914 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4110/4776 | Loss: 207.927 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4120/4776 | Loss: 106.058 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4130/4776 | Loss: 90.767 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 4140/4776 | Loss: 175.098 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4150/4776 | Loss: 103.854 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4160/4776 | Loss: 141.231 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4170/4776 | Loss: 163.374 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4180/4776 | Loss: 197.320 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4190/4776 | Loss: 147.952 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4200/4776 | Loss: 179.684 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4210/4776 | Loss: 174.650 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4220/4776 | Loss: 128.908 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4230/4776 | Loss: 162.573 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4240/4776 | Loss: 176.950 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4250/4776 | Loss: 173.484 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4260/4776 | Loss: 152.381 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4270/4776 | Loss: 139.422 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4280/4776 | Loss: 156.669 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4290/4776 | Loss: 152.708 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4300/4776 | Loss: 107.173 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4310/4776 | Loss: 113.528 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4320/4776 | Loss: 135.857 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4330/4776 | Loss: 143.734 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4340/4776 | Loss: 140.693 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4350/4776 | Loss: 146.501 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4360/4776 | Loss: 172.705 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4370/4776 | Loss: 142.788 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4380/4776 | Loss: 145.371 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4390/4776 | Loss: 118.413 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4400/4776 | Loss: 139.908 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4410/4776 | Loss: 118.743 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4420/4776 | Loss: 99.901 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4430/4776 | Loss: 162.594 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4440/4776 | Loss: 172.709 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4450/4776 | Loss: 177.914 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4460/4776 | Loss: 158.344 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4470/4776 | Loss: 155.148 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4480/4776 | Loss: 127.434 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4490/4776 | Loss: 103.699 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4500/4776 | Loss: 137.022 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4510/4776 | Loss: 179.490 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4520/4776 | Loss: 128.682 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4530/4776 | Loss: 97.906 | Accuracy: 0.700\n",
      "[Epoch: 44/200] - Step: 4540/4776 | Loss: 139.798 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4550/4776 | Loss: 113.570 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4560/4776 | Loss: 139.929 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4570/4776 | Loss: 151.867 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4580/4776 | Loss: 145.076 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4590/4776 | Loss: 173.952 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4600/4776 | Loss: 204.538 | Accuracy: 0.600\n",
      "[Epoch: 44/200] - Step: 4610/4776 | Loss: 200.714 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4620/4776 | Loss: 170.882 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4630/4776 | Loss: 144.224 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4640/4776 | Loss: 136.020 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4650/4776 | Loss: 159.212 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4660/4776 | Loss: 122.893 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 4670/4776 | Loss: 110.633 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 4680/4776 | Loss: 158.923 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4690/4776 | Loss: 151.721 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4700/4776 | Loss: 166.900 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4710/4776 | Loss: 174.955 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4720/4776 | Loss: 138.923 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4730/4776 | Loss: 122.615 | Accuracy: 0.800\n",
      "[Epoch: 44/200] - Step: 4740/4776 | Loss: 163.311 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 4750/4776 | Loss: 128.535 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 4760/4776 | Loss: 131.927 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 4770/4776 | Loss: 201.216 | Accuracy: 0.400\n",
      "Accuracy:  0.20655737704918034\n",
      "[Epoch: 45/200] - Step: 10/4776 | Loss: 134.563 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 20/4776 | Loss: 173.547 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 30/4776 | Loss: 131.128 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 40/4776 | Loss: 169.577 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 50/4776 | Loss: 145.569 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 60/4776 | Loss: 163.387 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 70/4776 | Loss: 156.569 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 80/4776 | Loss: 156.201 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 90/4776 | Loss: 125.008 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 100/4776 | Loss: 155.677 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 110/4776 | Loss: 135.116 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 120/4776 | Loss: 138.140 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 130/4776 | Loss: 100.597 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 140/4776 | Loss: 159.361 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 150/4776 | Loss: 159.627 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 160/4776 | Loss: 172.080 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 170/4776 | Loss: 130.896 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 180/4776 | Loss: 202.939 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 190/4776 | Loss: 152.079 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 200/4776 | Loss: 132.261 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 210/4776 | Loss: 95.222 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 220/4776 | Loss: 168.353 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 230/4776 | Loss: 99.873 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 240/4776 | Loss: 134.449 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 250/4776 | Loss: 130.090 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 260/4776 | Loss: 139.213 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 270/4776 | Loss: 129.468 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 280/4776 | Loss: 134.350 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 290/4776 | Loss: 131.082 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 300/4776 | Loss: 137.341 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 310/4776 | Loss: 155.082 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 320/4776 | Loss: 129.363 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 330/4776 | Loss: 64.755 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 340/4776 | Loss: 189.431 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 350/4776 | Loss: 145.734 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 360/4776 | Loss: 95.855 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 370/4776 | Loss: 159.440 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 380/4776 | Loss: 176.357 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 390/4776 | Loss: 163.415 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 400/4776 | Loss: 139.379 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 410/4776 | Loss: 108.417 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 420/4776 | Loss: 187.078 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 430/4776 | Loss: 97.243 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 440/4776 | Loss: 117.292 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 450/4776 | Loss: 151.042 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 460/4776 | Loss: 66.860 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 470/4776 | Loss: 127.608 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 480/4776 | Loss: 170.945 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 490/4776 | Loss: 125.861 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 500/4776 | Loss: 151.688 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 510/4776 | Loss: 115.852 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 520/4776 | Loss: 129.295 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 530/4776 | Loss: 177.557 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 540/4776 | Loss: 113.717 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 550/4776 | Loss: 154.201 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 560/4776 | Loss: 122.915 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 570/4776 | Loss: 112.280 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 580/4776 | Loss: 92.863 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 590/4776 | Loss: 196.115 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 600/4776 | Loss: 120.029 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 610/4776 | Loss: 105.086 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 620/4776 | Loss: 112.863 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 630/4776 | Loss: 106.819 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 640/4776 | Loss: 196.319 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 650/4776 | Loss: 155.477 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 660/4776 | Loss: 190.132 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 670/4776 | Loss: 170.329 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 680/4776 | Loss: 166.735 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 690/4776 | Loss: 109.785 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 700/4776 | Loss: 144.405 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 710/4776 | Loss: 166.135 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 720/4776 | Loss: 95.435 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 730/4776 | Loss: 155.330 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 740/4776 | Loss: 153.757 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 750/4776 | Loss: 139.442 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 760/4776 | Loss: 159.469 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 770/4776 | Loss: 120.439 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 780/4776 | Loss: 138.105 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 790/4776 | Loss: 193.171 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 800/4776 | Loss: 150.344 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 810/4776 | Loss: 154.862 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 820/4776 | Loss: 146.149 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 830/4776 | Loss: 130.978 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 840/4776 | Loss: 128.670 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 850/4776 | Loss: 147.325 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 860/4776 | Loss: 101.217 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 870/4776 | Loss: 204.470 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 880/4776 | Loss: 166.186 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 890/4776 | Loss: 140.865 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 900/4776 | Loss: 174.431 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 910/4776 | Loss: 153.986 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 920/4776 | Loss: 118.337 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 930/4776 | Loss: 160.191 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 940/4776 | Loss: 146.653 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 950/4776 | Loss: 143.985 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 960/4776 | Loss: 153.240 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 970/4776 | Loss: 148.256 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 980/4776 | Loss: 178.284 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 990/4776 | Loss: 152.153 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1000/4776 | Loss: 176.972 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1010/4776 | Loss: 99.789 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1020/4776 | Loss: 141.875 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1030/4776 | Loss: 122.883 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1040/4776 | Loss: 137.684 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1050/4776 | Loss: 94.057 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1060/4776 | Loss: 135.530 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1070/4776 | Loss: 130.874 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1080/4776 | Loss: 178.114 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1090/4776 | Loss: 166.382 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1100/4776 | Loss: 128.398 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1110/4776 | Loss: 101.594 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1120/4776 | Loss: 137.435 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1130/4776 | Loss: 135.025 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1140/4776 | Loss: 149.198 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1150/4776 | Loss: 158.845 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1160/4776 | Loss: 157.491 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1170/4776 | Loss: 143.693 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1180/4776 | Loss: 130.392 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1190/4776 | Loss: 87.200 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1200/4776 | Loss: 198.196 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1210/4776 | Loss: 104.842 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1220/4776 | Loss: 173.744 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1230/4776 | Loss: 148.472 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1240/4776 | Loss: 145.940 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1250/4776 | Loss: 131.159 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1260/4776 | Loss: 138.551 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1270/4776 | Loss: 74.557 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1280/4776 | Loss: 177.008 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1290/4776 | Loss: 196.081 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1300/4776 | Loss: 193.465 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1310/4776 | Loss: 135.270 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1320/4776 | Loss: 102.951 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1330/4776 | Loss: 131.585 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1340/4776 | Loss: 108.900 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1350/4776 | Loss: 142.067 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1360/4776 | Loss: 134.199 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1370/4776 | Loss: 100.060 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1380/4776 | Loss: 199.240 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1390/4776 | Loss: 136.690 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1400/4776 | Loss: 104.050 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 1410/4776 | Loss: 129.850 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1420/4776 | Loss: 103.836 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1430/4776 | Loss: 155.166 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1440/4776 | Loss: 154.887 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1450/4776 | Loss: 138.451 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1460/4776 | Loss: 197.441 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1470/4776 | Loss: 156.389 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1480/4776 | Loss: 118.048 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1490/4776 | Loss: 176.720 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1500/4776 | Loss: 157.196 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1510/4776 | Loss: 102.655 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1520/4776 | Loss: 126.178 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1530/4776 | Loss: 165.952 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1540/4776 | Loss: 189.999 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1550/4776 | Loss: 128.680 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1560/4776 | Loss: 194.380 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1570/4776 | Loss: 178.857 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1580/4776 | Loss: 146.819 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1590/4776 | Loss: 142.258 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1600/4776 | Loss: 155.410 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1610/4776 | Loss: 147.466 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1620/4776 | Loss: 95.341 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1630/4776 | Loss: 95.211 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1640/4776 | Loss: 96.655 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1650/4776 | Loss: 194.784 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1660/4776 | Loss: 177.569 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1670/4776 | Loss: 153.159 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1680/4776 | Loss: 129.567 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1690/4776 | Loss: 110.565 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1700/4776 | Loss: 142.000 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1710/4776 | Loss: 110.059 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1720/4776 | Loss: 118.226 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1730/4776 | Loss: 126.358 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1740/4776 | Loss: 92.839 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1750/4776 | Loss: 252.397 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1760/4776 | Loss: 201.430 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1770/4776 | Loss: 188.436 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1780/4776 | Loss: 147.832 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1790/4776 | Loss: 132.176 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1800/4776 | Loss: 129.908 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1810/4776 | Loss: 140.983 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1820/4776 | Loss: 136.376 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1830/4776 | Loss: 106.420 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1840/4776 | Loss: 153.228 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1850/4776 | Loss: 123.736 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1860/4776 | Loss: 99.766 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1870/4776 | Loss: 137.801 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1880/4776 | Loss: 146.642 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1890/4776 | Loss: 166.533 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1900/4776 | Loss: 97.613 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1910/4776 | Loss: 172.494 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1920/4776 | Loss: 132.573 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 1930/4776 | Loss: 144.233 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 1940/4776 | Loss: 155.365 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 1950/4776 | Loss: 112.689 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1960/4776 | Loss: 147.448 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1970/4776 | Loss: 121.086 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 1980/4776 | Loss: 132.791 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1990/4776 | Loss: 155.209 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2000/4776 | Loss: 82.283 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2010/4776 | Loss: 129.459 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2020/4776 | Loss: 129.427 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2030/4776 | Loss: 120.389 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2040/4776 | Loss: 141.055 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2050/4776 | Loss: 124.697 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2060/4776 | Loss: 172.478 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 2070/4776 | Loss: 124.423 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2080/4776 | Loss: 119.527 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2090/4776 | Loss: 154.448 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2100/4776 | Loss: 171.500 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 2110/4776 | Loss: 95.208 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2120/4776 | Loss: 133.686 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2130/4776 | Loss: 151.675 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2140/4776 | Loss: 133.304 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2150/4776 | Loss: 107.080 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2160/4776 | Loss: 107.949 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2170/4776 | Loss: 121.564 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2180/4776 | Loss: 155.968 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2190/4776 | Loss: 156.614 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2200/4776 | Loss: 146.580 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2210/4776 | Loss: 52.327 | Accuracy: 1.000\n",
      "[Epoch: 45/200] - Step: 2220/4776 | Loss: 142.140 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2230/4776 | Loss: 157.021 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2240/4776 | Loss: 144.464 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2250/4776 | Loss: 93.341 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2260/4776 | Loss: 109.779 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2270/4776 | Loss: 199.821 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2280/4776 | Loss: 147.801 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2290/4776 | Loss: 105.856 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2300/4776 | Loss: 161.430 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2310/4776 | Loss: 123.197 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2320/4776 | Loss: 121.782 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2330/4776 | Loss: 137.467 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2340/4776 | Loss: 208.127 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2350/4776 | Loss: 131.395 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2360/4776 | Loss: 124.447 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2370/4776 | Loss: 125.344 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2380/4776 | Loss: 141.781 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2390/4776 | Loss: 169.703 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2400/4776 | Loss: 220.792 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2410/4776 | Loss: 124.321 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2420/4776 | Loss: 169.780 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2430/4776 | Loss: 89.543 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 2440/4776 | Loss: 114.376 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2450/4776 | Loss: 111.561 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2460/4776 | Loss: 181.512 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2470/4776 | Loss: 53.228 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 2480/4776 | Loss: 146.729 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2490/4776 | Loss: 110.837 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2500/4776 | Loss: 134.259 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2510/4776 | Loss: 130.656 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2520/4776 | Loss: 130.371 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2530/4776 | Loss: 106.833 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2540/4776 | Loss: 123.442 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2550/4776 | Loss: 139.746 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2560/4776 | Loss: 74.562 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 2570/4776 | Loss: 130.583 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2580/4776 | Loss: 176.998 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2590/4776 | Loss: 127.504 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2600/4776 | Loss: 155.432 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2610/4776 | Loss: 185.689 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 2620/4776 | Loss: 97.163 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2630/4776 | Loss: 182.815 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2640/4776 | Loss: 181.881 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2650/4776 | Loss: 185.334 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2660/4776 | Loss: 158.896 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2670/4776 | Loss: 208.315 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 2680/4776 | Loss: 148.175 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2690/4776 | Loss: 179.413 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2700/4776 | Loss: 123.150 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2710/4776 | Loss: 147.573 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 2720/4776 | Loss: 133.940 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2730/4776 | Loss: 103.856 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2740/4776 | Loss: 180.463 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2750/4776 | Loss: 194.036 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 2760/4776 | Loss: 111.461 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2770/4776 | Loss: 127.851 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2780/4776 | Loss: 103.341 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2790/4776 | Loss: 135.130 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2800/4776 | Loss: 142.259 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2810/4776 | Loss: 148.199 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2820/4776 | Loss: 98.136 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2830/4776 | Loss: 132.436 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2840/4776 | Loss: 155.480 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2850/4776 | Loss: 125.716 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2860/4776 | Loss: 146.434 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2870/4776 | Loss: 116.565 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2880/4776 | Loss: 106.510 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2890/4776 | Loss: 156.913 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 2900/4776 | Loss: 127.097 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2910/4776 | Loss: 127.810 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2920/4776 | Loss: 123.917 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2930/4776 | Loss: 149.322 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 2940/4776 | Loss: 99.833 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2950/4776 | Loss: 115.748 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 2960/4776 | Loss: 130.803 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 2970/4776 | Loss: 112.543 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 2980/4776 | Loss: 155.866 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 2990/4776 | Loss: 165.937 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3000/4776 | Loss: 121.165 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3010/4776 | Loss: 100.907 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3020/4776 | Loss: 119.578 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3030/4776 | Loss: 136.434 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3040/4776 | Loss: 123.265 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3050/4776 | Loss: 123.388 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3060/4776 | Loss: 120.174 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3070/4776 | Loss: 120.967 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3080/4776 | Loss: 121.515 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3090/4776 | Loss: 122.839 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3100/4776 | Loss: 132.489 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3110/4776 | Loss: 124.516 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3120/4776 | Loss: 104.232 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3130/4776 | Loss: 193.986 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3140/4776 | Loss: 166.884 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3150/4776 | Loss: 106.491 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3160/4776 | Loss: 115.371 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3170/4776 | Loss: 97.078 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3180/4776 | Loss: 175.916 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3190/4776 | Loss: 190.195 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3200/4776 | Loss: 166.368 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3210/4776 | Loss: 100.849 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3220/4776 | Loss: 135.323 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3230/4776 | Loss: 126.610 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3240/4776 | Loss: 143.001 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3250/4776 | Loss: 149.878 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3260/4776 | Loss: 168.586 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3270/4776 | Loss: 155.261 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3280/4776 | Loss: 164.609 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3290/4776 | Loss: 144.056 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3300/4776 | Loss: 104.697 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3310/4776 | Loss: 135.433 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3320/4776 | Loss: 121.489 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3330/4776 | Loss: 115.835 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3340/4776 | Loss: 174.220 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3350/4776 | Loss: 184.901 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3360/4776 | Loss: 127.778 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3370/4776 | Loss: 216.379 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3380/4776 | Loss: 183.434 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3390/4776 | Loss: 83.287 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3400/4776 | Loss: 118.285 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3410/4776 | Loss: 95.899 | Accuracy: 0.900\n",
      "[Epoch: 45/200] - Step: 3420/4776 | Loss: 152.687 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3430/4776 | Loss: 105.341 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3440/4776 | Loss: 169.164 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3450/4776 | Loss: 125.315 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3460/4776 | Loss: 112.195 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3470/4776 | Loss: 188.409 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3480/4776 | Loss: 119.490 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3490/4776 | Loss: 190.338 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3500/4776 | Loss: 148.378 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3510/4776 | Loss: 161.462 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3520/4776 | Loss: 182.850 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3530/4776 | Loss: 108.147 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3540/4776 | Loss: 104.305 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3550/4776 | Loss: 125.996 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3560/4776 | Loss: 114.838 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3570/4776 | Loss: 133.732 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3580/4776 | Loss: 129.290 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3590/4776 | Loss: 148.525 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3600/4776 | Loss: 111.684 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3610/4776 | Loss: 143.023 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3620/4776 | Loss: 192.698 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3630/4776 | Loss: 161.929 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3640/4776 | Loss: 86.187 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3650/4776 | Loss: 160.009 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3660/4776 | Loss: 96.977 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3670/4776 | Loss: 179.334 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3680/4776 | Loss: 121.045 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3690/4776 | Loss: 105.453 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3700/4776 | Loss: 111.686 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3710/4776 | Loss: 104.319 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3720/4776 | Loss: 121.011 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3730/4776 | Loss: 150.751 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3740/4776 | Loss: 185.733 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3750/4776 | Loss: 233.007 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3760/4776 | Loss: 144.460 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3770/4776 | Loss: 149.396 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3780/4776 | Loss: 115.619 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3790/4776 | Loss: 117.636 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3800/4776 | Loss: 108.328 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3810/4776 | Loss: 183.809 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3820/4776 | Loss: 151.780 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3830/4776 | Loss: 105.441 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3840/4776 | Loss: 145.998 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3850/4776 | Loss: 100.764 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3860/4776 | Loss: 130.282 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3870/4776 | Loss: 123.554 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3880/4776 | Loss: 182.013 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3890/4776 | Loss: 139.897 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3900/4776 | Loss: 125.347 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3910/4776 | Loss: 102.337 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 3920/4776 | Loss: 170.218 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 3930/4776 | Loss: 128.071 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3940/4776 | Loss: 164.845 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 3950/4776 | Loss: 152.623 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3960/4776 | Loss: 156.486 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 3970/4776 | Loss: 108.076 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 3980/4776 | Loss: 152.386 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 3990/4776 | Loss: 102.479 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 4000/4776 | Loss: 98.195 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4010/4776 | Loss: 157.453 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4020/4776 | Loss: 139.289 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4030/4776 | Loss: 117.735 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4040/4776 | Loss: 130.317 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4050/4776 | Loss: 96.749 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4060/4776 | Loss: 130.630 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4070/4776 | Loss: 92.627 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4080/4776 | Loss: 154.424 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4090/4776 | Loss: 169.623 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4100/4776 | Loss: 138.669 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4110/4776 | Loss: 119.737 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4120/4776 | Loss: 101.368 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4130/4776 | Loss: 126.566 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4140/4776 | Loss: 99.613 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4150/4776 | Loss: 164.010 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4160/4776 | Loss: 127.253 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4170/4776 | Loss: 149.963 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4180/4776 | Loss: 107.947 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4190/4776 | Loss: 129.276 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4200/4776 | Loss: 175.689 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4210/4776 | Loss: 149.633 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4220/4776 | Loss: 106.908 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4230/4776 | Loss: 173.424 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4240/4776 | Loss: 193.411 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4250/4776 | Loss: 203.147 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4260/4776 | Loss: 103.211 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4270/4776 | Loss: 145.142 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4280/4776 | Loss: 112.512 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4290/4776 | Loss: 122.927 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4300/4776 | Loss: 170.878 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 4310/4776 | Loss: 144.225 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4320/4776 | Loss: 97.267 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4330/4776 | Loss: 138.923 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4340/4776 | Loss: 133.810 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4350/4776 | Loss: 125.586 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4360/4776 | Loss: 150.813 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4370/4776 | Loss: 160.379 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4380/4776 | Loss: 129.571 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4390/4776 | Loss: 145.587 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4400/4776 | Loss: 102.615 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4410/4776 | Loss: 146.307 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4420/4776 | Loss: 108.546 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4430/4776 | Loss: 93.950 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4440/4776 | Loss: 132.497 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4450/4776 | Loss: 120.261 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4460/4776 | Loss: 184.061 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4470/4776 | Loss: 88.772 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4480/4776 | Loss: 162.101 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4490/4776 | Loss: 146.296 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4500/4776 | Loss: 114.404 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4510/4776 | Loss: 180.263 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4520/4776 | Loss: 115.852 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4530/4776 | Loss: 132.660 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4540/4776 | Loss: 150.493 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4550/4776 | Loss: 192.305 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4560/4776 | Loss: 78.342 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4570/4776 | Loss: 218.739 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 4580/4776 | Loss: 122.631 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4590/4776 | Loss: 133.685 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4600/4776 | Loss: 221.238 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4610/4776 | Loss: 97.912 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4620/4776 | Loss: 187.476 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4630/4776 | Loss: 143.674 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4640/4776 | Loss: 176.867 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 4650/4776 | Loss: 161.609 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4660/4776 | Loss: 120.936 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4670/4776 | Loss: 95.123 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 4680/4776 | Loss: 112.592 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4690/4776 | Loss: 184.973 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 4700/4776 | Loss: 102.125 | Accuracy: 0.700\n",
      "[Epoch: 45/200] - Step: 4710/4776 | Loss: 84.940 | Accuracy: 0.800\n",
      "[Epoch: 45/200] - Step: 4720/4776 | Loss: 94.512 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4730/4776 | Loss: 127.427 | Accuracy: 0.600\n",
      "[Epoch: 45/200] - Step: 4740/4776 | Loss: 129.764 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 4750/4776 | Loss: 201.692 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 4760/4776 | Loss: 131.920 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 4770/4776 | Loss: 167.607 | Accuracy: 0.300\n",
      "Accuracy:  0.1901639344262295\n",
      "[Epoch: 46/200] - Step: 10/4776 | Loss: 168.496 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 20/4776 | Loss: 140.396 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 30/4776 | Loss: 166.925 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 40/4776 | Loss: 90.087 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 50/4776 | Loss: 127.961 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 60/4776 | Loss: 125.945 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 70/4776 | Loss: 150.803 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 80/4776 | Loss: 145.684 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 90/4776 | Loss: 102.508 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 100/4776 | Loss: 88.793 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 110/4776 | Loss: 185.146 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 120/4776 | Loss: 88.501 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 130/4776 | Loss: 120.497 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 140/4776 | Loss: 141.348 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 150/4776 | Loss: 74.074 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 160/4776 | Loss: 158.076 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 170/4776 | Loss: 123.683 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 180/4776 | Loss: 173.759 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 190/4776 | Loss: 126.550 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 200/4776 | Loss: 163.558 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 210/4776 | Loss: 104.237 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 220/4776 | Loss: 167.591 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 230/4776 | Loss: 170.539 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 240/4776 | Loss: 104.629 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 250/4776 | Loss: 103.046 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 260/4776 | Loss: 151.774 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 270/4776 | Loss: 117.474 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 280/4776 | Loss: 135.962 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 290/4776 | Loss: 193.458 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 300/4776 | Loss: 93.435 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 310/4776 | Loss: 146.210 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 320/4776 | Loss: 82.142 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 330/4776 | Loss: 94.902 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 340/4776 | Loss: 98.435 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 350/4776 | Loss: 94.999 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 360/4776 | Loss: 96.838 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 370/4776 | Loss: 101.758 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 380/4776 | Loss: 134.088 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 390/4776 | Loss: 135.211 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 400/4776 | Loss: 103.611 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 410/4776 | Loss: 98.808 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 420/4776 | Loss: 127.027 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 430/4776 | Loss: 156.836 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 440/4776 | Loss: 76.187 | Accuracy: 0.900\n",
      "[Epoch: 46/200] - Step: 450/4776 | Loss: 90.657 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 460/4776 | Loss: 151.055 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 470/4776 | Loss: 131.753 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 480/4776 | Loss: 106.577 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 490/4776 | Loss: 136.261 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 500/4776 | Loss: 115.626 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 510/4776 | Loss: 162.502 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 520/4776 | Loss: 103.112 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 530/4776 | Loss: 138.544 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 540/4776 | Loss: 177.074 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 550/4776 | Loss: 108.710 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 560/4776 | Loss: 103.203 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 570/4776 | Loss: 126.983 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 580/4776 | Loss: 144.222 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 590/4776 | Loss: 144.924 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 600/4776 | Loss: 125.147 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 610/4776 | Loss: 142.174 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 620/4776 | Loss: 109.707 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 630/4776 | Loss: 141.336 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 640/4776 | Loss: 139.289 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 650/4776 | Loss: 113.304 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 660/4776 | Loss: 116.920 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 670/4776 | Loss: 183.837 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 680/4776 | Loss: 165.207 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 690/4776 | Loss: 119.314 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 700/4776 | Loss: 127.591 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 710/4776 | Loss: 107.779 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 720/4776 | Loss: 114.134 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 730/4776 | Loss: 218.659 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 740/4776 | Loss: 134.076 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 750/4776 | Loss: 190.850 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 760/4776 | Loss: 108.863 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 770/4776 | Loss: 132.096 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 780/4776 | Loss: 116.657 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 790/4776 | Loss: 109.958 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 800/4776 | Loss: 157.417 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 810/4776 | Loss: 97.634 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 820/4776 | Loss: 133.723 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 830/4776 | Loss: 57.207 | Accuracy: 0.900\n",
      "[Epoch: 46/200] - Step: 840/4776 | Loss: 159.317 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 850/4776 | Loss: 62.641 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 860/4776 | Loss: 138.255 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 870/4776 | Loss: 124.106 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 880/4776 | Loss: 102.785 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 890/4776 | Loss: 169.766 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 900/4776 | Loss: 201.335 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 910/4776 | Loss: 160.522 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 920/4776 | Loss: 138.308 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 930/4776 | Loss: 174.999 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 940/4776 | Loss: 112.045 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 950/4776 | Loss: 115.994 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 960/4776 | Loss: 154.690 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 970/4776 | Loss: 149.036 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 980/4776 | Loss: 104.285 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 990/4776 | Loss: 121.787 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1000/4776 | Loss: 166.987 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1010/4776 | Loss: 104.069 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1020/4776 | Loss: 134.391 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1030/4776 | Loss: 162.135 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1040/4776 | Loss: 218.802 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1050/4776 | Loss: 139.618 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1060/4776 | Loss: 126.950 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1070/4776 | Loss: 56.949 | Accuracy: 1.000\n",
      "[Epoch: 46/200] - Step: 1080/4776 | Loss: 118.375 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1090/4776 | Loss: 183.709 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1100/4776 | Loss: 182.807 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1110/4776 | Loss: 213.640 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1120/4776 | Loss: 77.922 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 1130/4776 | Loss: 114.891 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1140/4776 | Loss: 106.810 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1150/4776 | Loss: 170.174 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1160/4776 | Loss: 128.516 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1170/4776 | Loss: 115.011 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1180/4776 | Loss: 142.944 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1190/4776 | Loss: 123.513 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1200/4776 | Loss: 112.727 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1210/4776 | Loss: 139.839 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1220/4776 | Loss: 184.012 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1230/4776 | Loss: 115.044 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1240/4776 | Loss: 116.182 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1250/4776 | Loss: 122.257 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1260/4776 | Loss: 130.430 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1270/4776 | Loss: 171.549 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1280/4776 | Loss: 115.989 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1290/4776 | Loss: 95.396 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1300/4776 | Loss: 179.402 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1310/4776 | Loss: 135.052 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1320/4776 | Loss: 102.517 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1330/4776 | Loss: 136.285 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1340/4776 | Loss: 99.868 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1350/4776 | Loss: 98.603 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1360/4776 | Loss: 115.614 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1370/4776 | Loss: 98.887 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1380/4776 | Loss: 136.691 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1390/4776 | Loss: 143.171 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1400/4776 | Loss: 135.833 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1410/4776 | Loss: 139.941 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1420/4776 | Loss: 146.381 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1430/4776 | Loss: 70.045 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1440/4776 | Loss: 110.066 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1450/4776 | Loss: 133.885 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1460/4776 | Loss: 99.621 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1470/4776 | Loss: 106.075 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1480/4776 | Loss: 91.589 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1490/4776 | Loss: 153.084 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1500/4776 | Loss: 146.972 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1510/4776 | Loss: 148.831 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1520/4776 | Loss: 99.765 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 1530/4776 | Loss: 138.435 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1540/4776 | Loss: 108.806 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1550/4776 | Loss: 156.090 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1560/4776 | Loss: 176.725 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1570/4776 | Loss: 105.617 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1580/4776 | Loss: 102.137 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1590/4776 | Loss: 140.902 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1600/4776 | Loss: 148.654 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1610/4776 | Loss: 138.084 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1620/4776 | Loss: 99.804 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1630/4776 | Loss: 168.712 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1640/4776 | Loss: 147.178 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1650/4776 | Loss: 126.431 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1660/4776 | Loss: 118.831 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1670/4776 | Loss: 100.559 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1680/4776 | Loss: 136.560 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1690/4776 | Loss: 81.809 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1700/4776 | Loss: 109.755 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1710/4776 | Loss: 125.207 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1720/4776 | Loss: 114.617 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1730/4776 | Loss: 97.191 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1740/4776 | Loss: 121.000 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1750/4776 | Loss: 117.615 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1760/4776 | Loss: 238.455 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1770/4776 | Loss: 98.527 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1780/4776 | Loss: 123.122 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1790/4776 | Loss: 102.819 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1800/4776 | Loss: 134.764 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1810/4776 | Loss: 246.067 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1820/4776 | Loss: 144.607 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1830/4776 | Loss: 193.116 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1840/4776 | Loss: 159.588 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1850/4776 | Loss: 161.652 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1860/4776 | Loss: 101.293 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1870/4776 | Loss: 90.145 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 1880/4776 | Loss: 226.407 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1890/4776 | Loss: 144.590 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1900/4776 | Loss: 153.641 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1910/4776 | Loss: 109.846 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 1920/4776 | Loss: 134.445 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1930/4776 | Loss: 110.163 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1940/4776 | Loss: 156.055 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1950/4776 | Loss: 149.711 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1960/4776 | Loss: 123.136 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1970/4776 | Loss: 105.875 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 1980/4776 | Loss: 179.179 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 1990/4776 | Loss: 163.931 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2000/4776 | Loss: 110.426 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2010/4776 | Loss: 54.622 | Accuracy: 1.000\n",
      "[Epoch: 46/200] - Step: 2020/4776 | Loss: 120.858 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2030/4776 | Loss: 171.684 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2040/4776 | Loss: 114.626 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2050/4776 | Loss: 180.836 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2060/4776 | Loss: 105.572 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2070/4776 | Loss: 101.682 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2080/4776 | Loss: 128.999 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2090/4776 | Loss: 161.649 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2100/4776 | Loss: 157.691 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2110/4776 | Loss: 103.144 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2120/4776 | Loss: 128.088 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2130/4776 | Loss: 175.385 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2140/4776 | Loss: 128.852 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2150/4776 | Loss: 172.224 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2160/4776 | Loss: 134.453 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2170/4776 | Loss: 181.862 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 2180/4776 | Loss: 77.037 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2190/4776 | Loss: 114.102 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2200/4776 | Loss: 125.421 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2210/4776 | Loss: 121.666 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2220/4776 | Loss: 144.530 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2230/4776 | Loss: 164.164 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2240/4776 | Loss: 149.617 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2250/4776 | Loss: 134.668 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2260/4776 | Loss: 101.412 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2270/4776 | Loss: 154.509 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2280/4776 | Loss: 109.773 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2290/4776 | Loss: 179.925 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 2300/4776 | Loss: 133.337 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 2310/4776 | Loss: 121.720 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2320/4776 | Loss: 137.760 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2330/4776 | Loss: 205.734 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 2340/4776 | Loss: 144.155 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2350/4776 | Loss: 104.591 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2360/4776 | Loss: 137.136 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2370/4776 | Loss: 162.772 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2380/4776 | Loss: 143.293 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2390/4776 | Loss: 107.598 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2400/4776 | Loss: 114.545 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2410/4776 | Loss: 122.324 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2420/4776 | Loss: 136.533 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2430/4776 | Loss: 172.530 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 2440/4776 | Loss: 102.129 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2450/4776 | Loss: 143.036 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2460/4776 | Loss: 179.193 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2470/4776 | Loss: 156.816 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2480/4776 | Loss: 126.138 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2490/4776 | Loss: 202.370 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2500/4776 | Loss: 85.103 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2510/4776 | Loss: 89.684 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2520/4776 | Loss: 164.464 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2530/4776 | Loss: 76.887 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2540/4776 | Loss: 132.856 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2550/4776 | Loss: 182.956 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2560/4776 | Loss: 121.909 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2570/4776 | Loss: 193.219 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2580/4776 | Loss: 127.850 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2590/4776 | Loss: 153.989 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2600/4776 | Loss: 185.595 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2610/4776 | Loss: 175.772 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 2620/4776 | Loss: 90.751 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 2630/4776 | Loss: 130.891 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2640/4776 | Loss: 107.451 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2650/4776 | Loss: 147.611 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2660/4776 | Loss: 107.615 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2670/4776 | Loss: 142.218 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2680/4776 | Loss: 125.779 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2690/4776 | Loss: 118.778 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 2700/4776 | Loss: 123.520 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2710/4776 | Loss: 108.814 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2720/4776 | Loss: 175.303 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2730/4776 | Loss: 79.780 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 2740/4776 | Loss: 164.583 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2750/4776 | Loss: 87.577 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2760/4776 | Loss: 146.854 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2770/4776 | Loss: 168.480 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2780/4776 | Loss: 117.594 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2790/4776 | Loss: 89.063 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2800/4776 | Loss: 105.227 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2810/4776 | Loss: 148.745 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2820/4776 | Loss: 151.264 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2830/4776 | Loss: 161.636 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2840/4776 | Loss: 162.159 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2850/4776 | Loss: 164.471 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2860/4776 | Loss: 129.029 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 2870/4776 | Loss: 137.499 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2880/4776 | Loss: 132.968 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 2890/4776 | Loss: 213.479 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 2900/4776 | Loss: 149.382 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2910/4776 | Loss: 144.954 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2920/4776 | Loss: 122.370 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2930/4776 | Loss: 128.420 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2940/4776 | Loss: 110.424 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2950/4776 | Loss: 94.142 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 2960/4776 | Loss: 210.248 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 2970/4776 | Loss: 121.578 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2980/4776 | Loss: 141.288 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 2990/4776 | Loss: 134.228 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3000/4776 | Loss: 121.687 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3010/4776 | Loss: 156.519 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3020/4776 | Loss: 123.380 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3030/4776 | Loss: 176.506 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3040/4776 | Loss: 121.612 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3050/4776 | Loss: 102.730 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 3060/4776 | Loss: 106.163 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 3070/4776 | Loss: 176.090 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3080/4776 | Loss: 147.376 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3090/4776 | Loss: 132.192 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3100/4776 | Loss: 87.219 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3110/4776 | Loss: 180.149 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3120/4776 | Loss: 187.262 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 3130/4776 | Loss: 117.143 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3140/4776 | Loss: 188.276 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3150/4776 | Loss: 121.190 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3160/4776 | Loss: 201.523 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 3170/4776 | Loss: 159.675 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3180/4776 | Loss: 176.821 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3190/4776 | Loss: 129.294 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3200/4776 | Loss: 136.389 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3210/4776 | Loss: 160.989 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3220/4776 | Loss: 185.678 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3230/4776 | Loss: 165.475 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3240/4776 | Loss: 175.501 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3250/4776 | Loss: 168.189 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3260/4776 | Loss: 214.835 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3270/4776 | Loss: 175.818 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3280/4776 | Loss: 140.855 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3290/4776 | Loss: 131.236 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3300/4776 | Loss: 126.072 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3310/4776 | Loss: 98.615 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3320/4776 | Loss: 112.840 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3330/4776 | Loss: 109.262 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3340/4776 | Loss: 168.901 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3350/4776 | Loss: 79.988 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3360/4776 | Loss: 172.027 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3370/4776 | Loss: 161.071 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3380/4776 | Loss: 112.742 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3390/4776 | Loss: 100.601 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3400/4776 | Loss: 81.348 | Accuracy: 0.900\n",
      "[Epoch: 46/200] - Step: 3410/4776 | Loss: 90.326 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3420/4776 | Loss: 113.461 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3430/4776 | Loss: 149.206 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3440/4776 | Loss: 134.981 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3450/4776 | Loss: 114.516 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3460/4776 | Loss: 129.616 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3470/4776 | Loss: 158.193 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3480/4776 | Loss: 153.827 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3490/4776 | Loss: 132.884 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3500/4776 | Loss: 161.065 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3510/4776 | Loss: 195.406 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3520/4776 | Loss: 266.687 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3530/4776 | Loss: 110.619 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3540/4776 | Loss: 164.312 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3550/4776 | Loss: 75.603 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 3560/4776 | Loss: 106.947 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3570/4776 | Loss: 126.108 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3580/4776 | Loss: 137.012 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3590/4776 | Loss: 172.192 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3600/4776 | Loss: 94.477 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3610/4776 | Loss: 98.411 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 3620/4776 | Loss: 95.439 | Accuracy: 0.900\n",
      "[Epoch: 46/200] - Step: 3630/4776 | Loss: 106.628 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3640/4776 | Loss: 138.257 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3650/4776 | Loss: 129.090 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3660/4776 | Loss: 108.187 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3670/4776 | Loss: 142.493 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3680/4776 | Loss: 153.414 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3690/4776 | Loss: 105.093 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3700/4776 | Loss: 114.682 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3710/4776 | Loss: 148.218 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3720/4776 | Loss: 174.104 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3730/4776 | Loss: 150.897 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3740/4776 | Loss: 161.544 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3750/4776 | Loss: 131.204 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3760/4776 | Loss: 146.424 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3770/4776 | Loss: 87.844 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 3780/4776 | Loss: 132.293 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3790/4776 | Loss: 145.996 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3800/4776 | Loss: 125.010 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3810/4776 | Loss: 169.287 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3820/4776 | Loss: 179.628 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 3830/4776 | Loss: 161.246 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3840/4776 | Loss: 157.408 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3850/4776 | Loss: 111.221 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 3860/4776 | Loss: 129.840 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3870/4776 | Loss: 101.120 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3880/4776 | Loss: 127.009 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3890/4776 | Loss: 151.010 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 3900/4776 | Loss: 94.909 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3910/4776 | Loss: 152.545 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 3920/4776 | Loss: 177.561 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3930/4776 | Loss: 110.290 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 3940/4776 | Loss: 125.927 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3950/4776 | Loss: 107.945 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3960/4776 | Loss: 127.248 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3970/4776 | Loss: 193.122 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3980/4776 | Loss: 182.634 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 3990/4776 | Loss: 145.498 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4000/4776 | Loss: 125.669 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4010/4776 | Loss: 164.528 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4020/4776 | Loss: 142.899 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4030/4776 | Loss: 177.020 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 4040/4776 | Loss: 192.785 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4050/4776 | Loss: 133.824 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4060/4776 | Loss: 187.053 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4070/4776 | Loss: 141.359 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4080/4776 | Loss: 115.574 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4090/4776 | Loss: 121.530 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4100/4776 | Loss: 138.246 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4110/4776 | Loss: 151.109 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4120/4776 | Loss: 161.539 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4130/4776 | Loss: 154.142 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4140/4776 | Loss: 150.320 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4150/4776 | Loss: 137.903 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4160/4776 | Loss: 140.121 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4170/4776 | Loss: 113.324 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4180/4776 | Loss: 145.370 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4190/4776 | Loss: 127.708 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4200/4776 | Loss: 91.021 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4210/4776 | Loss: 179.868 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4220/4776 | Loss: 162.760 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4230/4776 | Loss: 129.511 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 4240/4776 | Loss: 150.308 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4250/4776 | Loss: 96.974 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4260/4776 | Loss: 109.228 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4270/4776 | Loss: 147.806 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4280/4776 | Loss: 108.583 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4290/4776 | Loss: 145.070 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4300/4776 | Loss: 134.453 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4310/4776 | Loss: 103.971 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4320/4776 | Loss: 144.412 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4330/4776 | Loss: 149.615 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4340/4776 | Loss: 151.071 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4350/4776 | Loss: 197.259 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4360/4776 | Loss: 165.397 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4370/4776 | Loss: 119.046 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4380/4776 | Loss: 122.366 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4390/4776 | Loss: 111.609 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4400/4776 | Loss: 181.047 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4410/4776 | Loss: 97.849 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4420/4776 | Loss: 107.185 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4430/4776 | Loss: 88.557 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 4440/4776 | Loss: 190.251 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4450/4776 | Loss: 147.630 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4460/4776 | Loss: 147.181 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4470/4776 | Loss: 128.485 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4480/4776 | Loss: 131.797 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4490/4776 | Loss: 149.099 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4500/4776 | Loss: 114.881 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4510/4776 | Loss: 133.612 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4520/4776 | Loss: 91.285 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 4530/4776 | Loss: 170.952 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4540/4776 | Loss: 138.875 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4550/4776 | Loss: 186.067 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4560/4776 | Loss: 139.719 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4570/4776 | Loss: 128.081 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4580/4776 | Loss: 80.383 | Accuracy: 1.000\n",
      "[Epoch: 46/200] - Step: 4590/4776 | Loss: 159.288 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 4600/4776 | Loss: 93.917 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4610/4776 | Loss: 181.645 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 4620/4776 | Loss: 146.115 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 4630/4776 | Loss: 183.314 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4640/4776 | Loss: 102.402 | Accuracy: 0.700\n",
      "[Epoch: 46/200] - Step: 4650/4776 | Loss: 134.856 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4660/4776 | Loss: 117.433 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4670/4776 | Loss: 195.915 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 4680/4776 | Loss: 100.519 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 4690/4776 | Loss: 91.620 | Accuracy: 0.800\n",
      "[Epoch: 46/200] - Step: 4700/4776 | Loss: 144.577 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4710/4776 | Loss: 123.282 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4720/4776 | Loss: 121.278 | Accuracy: 0.600\n",
      "[Epoch: 46/200] - Step: 4730/4776 | Loss: 155.399 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4740/4776 | Loss: 107.158 | Accuracy: 0.500\n",
      "[Epoch: 46/200] - Step: 4750/4776 | Loss: 166.314 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 4760/4776 | Loss: 127.177 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 4770/4776 | Loss: 121.895 | Accuracy: 0.500\n",
      "Accuracy:  0.19672131147540983\n",
      "[Epoch: 47/200] - Step: 10/4776 | Loss: 101.915 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 20/4776 | Loss: 137.791 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 30/4776 | Loss: 123.866 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 40/4776 | Loss: 81.938 | Accuracy: 0.900\n",
      "[Epoch: 47/200] - Step: 50/4776 | Loss: 103.777 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 60/4776 | Loss: 69.529 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 70/4776 | Loss: 101.393 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 80/4776 | Loss: 119.477 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 90/4776 | Loss: 145.245 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 100/4776 | Loss: 117.812 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 110/4776 | Loss: 90.988 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 120/4776 | Loss: 131.835 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 130/4776 | Loss: 153.135 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 140/4776 | Loss: 167.754 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 150/4776 | Loss: 150.334 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 160/4776 | Loss: 111.191 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 170/4776 | Loss: 96.962 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 180/4776 | Loss: 151.554 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 190/4776 | Loss: 133.158 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 200/4776 | Loss: 117.378 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 210/4776 | Loss: 174.758 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 220/4776 | Loss: 151.040 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 230/4776 | Loss: 157.498 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 240/4776 | Loss: 105.198 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 250/4776 | Loss: 158.039 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 260/4776 | Loss: 129.846 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 270/4776 | Loss: 131.133 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 280/4776 | Loss: 181.137 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 290/4776 | Loss: 172.898 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 300/4776 | Loss: 107.934 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 310/4776 | Loss: 124.618 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 320/4776 | Loss: 112.347 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 330/4776 | Loss: 136.286 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 340/4776 | Loss: 172.099 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 350/4776 | Loss: 150.631 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 360/4776 | Loss: 90.376 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 370/4776 | Loss: 186.682 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 380/4776 | Loss: 99.008 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 390/4776 | Loss: 114.546 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 400/4776 | Loss: 140.388 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 410/4776 | Loss: 106.636 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 420/4776 | Loss: 113.176 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 430/4776 | Loss: 155.083 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 440/4776 | Loss: 123.903 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 450/4776 | Loss: 184.808 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 460/4776 | Loss: 141.170 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 470/4776 | Loss: 152.641 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 480/4776 | Loss: 103.253 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 490/4776 | Loss: 169.873 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 500/4776 | Loss: 117.283 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 510/4776 | Loss: 152.550 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 520/4776 | Loss: 110.279 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 530/4776 | Loss: 135.231 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 540/4776 | Loss: 120.277 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 550/4776 | Loss: 170.803 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 560/4776 | Loss: 194.512 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 570/4776 | Loss: 172.803 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 580/4776 | Loss: 151.443 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 590/4776 | Loss: 118.152 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 600/4776 | Loss: 110.530 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 610/4776 | Loss: 135.629 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 620/4776 | Loss: 215.347 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 630/4776 | Loss: 143.180 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 640/4776 | Loss: 138.914 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 650/4776 | Loss: 134.840 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 660/4776 | Loss: 153.323 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 670/4776 | Loss: 170.507 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 680/4776 | Loss: 129.647 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 690/4776 | Loss: 128.146 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 700/4776 | Loss: 92.920 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 710/4776 | Loss: 171.052 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 720/4776 | Loss: 97.887 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 730/4776 | Loss: 83.810 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 740/4776 | Loss: 97.787 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 750/4776 | Loss: 123.862 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 760/4776 | Loss: 91.027 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 770/4776 | Loss: 134.757 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 780/4776 | Loss: 133.993 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 790/4776 | Loss: 191.189 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 800/4776 | Loss: 158.418 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 810/4776 | Loss: 149.715 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 820/4776 | Loss: 138.154 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 830/4776 | Loss: 130.012 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 840/4776 | Loss: 133.712 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 850/4776 | Loss: 166.509 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 860/4776 | Loss: 170.561 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 870/4776 | Loss: 120.826 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 880/4776 | Loss: 87.577 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 890/4776 | Loss: 118.123 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 900/4776 | Loss: 100.560 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 910/4776 | Loss: 136.782 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 920/4776 | Loss: 142.156 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 930/4776 | Loss: 93.517 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 940/4776 | Loss: 114.913 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 950/4776 | Loss: 73.464 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 960/4776 | Loss: 145.258 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 970/4776 | Loss: 114.706 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 980/4776 | Loss: 128.052 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 990/4776 | Loss: 109.172 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1000/4776 | Loss: 112.974 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1010/4776 | Loss: 95.128 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1020/4776 | Loss: 74.996 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 1030/4776 | Loss: 148.325 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1040/4776 | Loss: 88.837 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1050/4776 | Loss: 109.946 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1060/4776 | Loss: 130.255 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1070/4776 | Loss: 134.627 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1080/4776 | Loss: 124.541 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1090/4776 | Loss: 136.322 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1100/4776 | Loss: 178.229 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 1110/4776 | Loss: 145.603 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1120/4776 | Loss: 130.490 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1130/4776 | Loss: 140.873 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1140/4776 | Loss: 129.972 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1150/4776 | Loss: 119.187 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1160/4776 | Loss: 112.924 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1170/4776 | Loss: 114.036 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 1180/4776 | Loss: 128.679 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1190/4776 | Loss: 131.823 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1200/4776 | Loss: 127.212 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1210/4776 | Loss: 85.124 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1220/4776 | Loss: 194.226 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1230/4776 | Loss: 80.262 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1240/4776 | Loss: 127.399 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1250/4776 | Loss: 152.433 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1260/4776 | Loss: 148.911 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1270/4776 | Loss: 91.542 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1280/4776 | Loss: 132.078 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1290/4776 | Loss: 133.699 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1300/4776 | Loss: 133.747 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1310/4776 | Loss: 116.209 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1320/4776 | Loss: 89.439 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1330/4776 | Loss: 88.259 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1340/4776 | Loss: 172.786 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1350/4776 | Loss: 138.007 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1360/4776 | Loss: 177.142 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1370/4776 | Loss: 144.714 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1380/4776 | Loss: 136.813 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1390/4776 | Loss: 82.083 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 1400/4776 | Loss: 112.810 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1410/4776 | Loss: 129.016 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1420/4776 | Loss: 99.343 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1430/4776 | Loss: 155.568 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1440/4776 | Loss: 139.728 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1450/4776 | Loss: 129.350 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1460/4776 | Loss: 113.784 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1470/4776 | Loss: 128.843 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1480/4776 | Loss: 103.003 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1490/4776 | Loss: 113.644 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1500/4776 | Loss: 87.327 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1510/4776 | Loss: 143.117 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1520/4776 | Loss: 134.689 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1530/4776 | Loss: 134.262 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1540/4776 | Loss: 103.834 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1550/4776 | Loss: 170.954 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1560/4776 | Loss: 85.777 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1570/4776 | Loss: 165.750 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1580/4776 | Loss: 69.944 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 1590/4776 | Loss: 153.139 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1600/4776 | Loss: 156.012 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1610/4776 | Loss: 98.399 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1620/4776 | Loss: 213.340 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1630/4776 | Loss: 122.052 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1640/4776 | Loss: 101.022 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1650/4776 | Loss: 134.248 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1660/4776 | Loss: 126.888 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1670/4776 | Loss: 170.270 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1680/4776 | Loss: 117.566 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1690/4776 | Loss: 106.984 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1700/4776 | Loss: 146.037 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1710/4776 | Loss: 161.248 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1720/4776 | Loss: 124.382 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1730/4776 | Loss: 80.451 | Accuracy: 0.900\n",
      "[Epoch: 47/200] - Step: 1740/4776 | Loss: 150.233 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1750/4776 | Loss: 111.051 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1760/4776 | Loss: 91.376 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1770/4776 | Loss: 156.523 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1780/4776 | Loss: 151.993 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1790/4776 | Loss: 139.277 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1800/4776 | Loss: 102.519 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1810/4776 | Loss: 206.010 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1820/4776 | Loss: 186.479 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1830/4776 | Loss: 160.515 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1840/4776 | Loss: 95.555 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1850/4776 | Loss: 155.798 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1860/4776 | Loss: 144.132 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1870/4776 | Loss: 168.199 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 1880/4776 | Loss: 117.457 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1890/4776 | Loss: 115.102 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1900/4776 | Loss: 158.145 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1910/4776 | Loss: 86.770 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1920/4776 | Loss: 88.279 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1930/4776 | Loss: 112.939 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1940/4776 | Loss: 95.803 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 1950/4776 | Loss: 121.905 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1960/4776 | Loss: 185.801 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1970/4776 | Loss: 118.658 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 1980/4776 | Loss: 99.305 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 1990/4776 | Loss: 88.136 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2000/4776 | Loss: 197.834 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2010/4776 | Loss: 117.476 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 2020/4776 | Loss: 139.890 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2030/4776 | Loss: 179.263 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2040/4776 | Loss: 120.115 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2050/4776 | Loss: 152.393 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2060/4776 | Loss: 111.653 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2070/4776 | Loss: 102.983 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2080/4776 | Loss: 130.983 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2090/4776 | Loss: 185.688 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2100/4776 | Loss: 128.094 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2110/4776 | Loss: 151.734 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2120/4776 | Loss: 111.997 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2130/4776 | Loss: 201.420 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2140/4776 | Loss: 196.178 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2150/4776 | Loss: 133.801 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2160/4776 | Loss: 102.276 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 2170/4776 | Loss: 174.117 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2180/4776 | Loss: 83.674 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 2190/4776 | Loss: 149.118 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2200/4776 | Loss: 99.912 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2210/4776 | Loss: 193.007 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2220/4776 | Loss: 149.624 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2230/4776 | Loss: 171.905 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2240/4776 | Loss: 127.010 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2250/4776 | Loss: 148.036 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2260/4776 | Loss: 123.806 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2270/4776 | Loss: 91.211 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2280/4776 | Loss: 108.510 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2290/4776 | Loss: 106.986 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2300/4776 | Loss: 118.878 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2310/4776 | Loss: 162.700 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2320/4776 | Loss: 91.608 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2330/4776 | Loss: 116.443 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2340/4776 | Loss: 121.732 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2350/4776 | Loss: 119.304 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2360/4776 | Loss: 232.553 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2370/4776 | Loss: 97.506 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2380/4776 | Loss: 125.339 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2390/4776 | Loss: 160.587 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2400/4776 | Loss: 140.017 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2410/4776 | Loss: 133.048 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2420/4776 | Loss: 135.258 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2430/4776 | Loss: 191.755 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2440/4776 | Loss: 167.767 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2450/4776 | Loss: 176.684 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2460/4776 | Loss: 114.050 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2470/4776 | Loss: 145.492 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2480/4776 | Loss: 144.724 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2490/4776 | Loss: 87.993 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2500/4776 | Loss: 159.310 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2510/4776 | Loss: 133.369 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2520/4776 | Loss: 137.281 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2530/4776 | Loss: 153.275 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2540/4776 | Loss: 132.892 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2550/4776 | Loss: 213.981 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2560/4776 | Loss: 125.499 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2570/4776 | Loss: 97.510 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2580/4776 | Loss: 158.170 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2590/4776 | Loss: 101.165 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2600/4776 | Loss: 138.276 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2610/4776 | Loss: 116.573 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2620/4776 | Loss: 150.001 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2630/4776 | Loss: 119.335 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2640/4776 | Loss: 147.391 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2650/4776 | Loss: 178.790 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2660/4776 | Loss: 96.893 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2670/4776 | Loss: 156.604 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2680/4776 | Loss: 172.643 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2690/4776 | Loss: 146.684 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2700/4776 | Loss: 137.130 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2710/4776 | Loss: 108.167 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2720/4776 | Loss: 79.734 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2730/4776 | Loss: 98.623 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2740/4776 | Loss: 117.706 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2750/4776 | Loss: 160.814 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2760/4776 | Loss: 173.115 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2770/4776 | Loss: 120.765 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2780/4776 | Loss: 107.677 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2790/4776 | Loss: 110.050 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2800/4776 | Loss: 87.332 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2810/4776 | Loss: 134.396 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2820/4776 | Loss: 189.614 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2830/4776 | Loss: 138.088 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2840/4776 | Loss: 115.803 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2850/4776 | Loss: 143.659 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2860/4776 | Loss: 139.017 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 2870/4776 | Loss: 192.147 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2880/4776 | Loss: 126.007 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2890/4776 | Loss: 140.172 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2900/4776 | Loss: 108.016 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 2910/4776 | Loss: 138.457 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2920/4776 | Loss: 134.882 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2930/4776 | Loss: 199.984 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 2940/4776 | Loss: 170.823 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2950/4776 | Loss: 165.240 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 2960/4776 | Loss: 150.538 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2970/4776 | Loss: 121.661 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 2980/4776 | Loss: 99.694 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 2990/4776 | Loss: 136.658 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3000/4776 | Loss: 212.982 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 3010/4776 | Loss: 110.911 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3020/4776 | Loss: 88.919 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3030/4776 | Loss: 145.876 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3040/4776 | Loss: 107.346 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3050/4776 | Loss: 125.762 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3060/4776 | Loss: 79.560 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3070/4776 | Loss: 97.597 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 3080/4776 | Loss: 214.224 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3090/4776 | Loss: 182.317 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3100/4776 | Loss: 154.715 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3110/4776 | Loss: 123.474 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3120/4776 | Loss: 147.300 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3130/4776 | Loss: 109.960 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3140/4776 | Loss: 178.633 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3150/4776 | Loss: 121.443 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3160/4776 | Loss: 133.332 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3170/4776 | Loss: 111.850 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3180/4776 | Loss: 135.396 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3190/4776 | Loss: 140.010 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3200/4776 | Loss: 133.190 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3210/4776 | Loss: 107.008 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3220/4776 | Loss: 119.356 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3230/4776 | Loss: 74.151 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3240/4776 | Loss: 101.637 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3250/4776 | Loss: 91.933 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3260/4776 | Loss: 164.112 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 3270/4776 | Loss: 122.262 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3280/4776 | Loss: 87.442 | Accuracy: 0.900\n",
      "[Epoch: 47/200] - Step: 3290/4776 | Loss: 134.523 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3300/4776 | Loss: 167.829 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3310/4776 | Loss: 126.450 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3320/4776 | Loss: 149.308 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3330/4776 | Loss: 142.581 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3340/4776 | Loss: 104.588 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3350/4776 | Loss: 106.475 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3360/4776 | Loss: 136.519 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3370/4776 | Loss: 147.485 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3380/4776 | Loss: 162.074 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3390/4776 | Loss: 77.288 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3400/4776 | Loss: 92.300 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3410/4776 | Loss: 97.563 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3420/4776 | Loss: 110.715 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3430/4776 | Loss: 94.297 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3440/4776 | Loss: 167.670 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3450/4776 | Loss: 93.115 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3460/4776 | Loss: 189.591 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3470/4776 | Loss: 103.534 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3480/4776 | Loss: 141.550 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3490/4776 | Loss: 224.560 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3500/4776 | Loss: 111.845 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3510/4776 | Loss: 145.028 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3520/4776 | Loss: 135.201 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3530/4776 | Loss: 149.618 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3540/4776 | Loss: 149.623 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3550/4776 | Loss: 90.012 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3560/4776 | Loss: 165.040 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3570/4776 | Loss: 126.742 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3580/4776 | Loss: 111.822 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3590/4776 | Loss: 143.408 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3600/4776 | Loss: 127.048 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3610/4776 | Loss: 85.162 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 3620/4776 | Loss: 108.410 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3630/4776 | Loss: 166.932 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 3640/4776 | Loss: 172.995 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3650/4776 | Loss: 63.887 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 3660/4776 | Loss: 102.701 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3670/4776 | Loss: 115.348 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3680/4776 | Loss: 166.782 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3690/4776 | Loss: 78.797 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3700/4776 | Loss: 80.629 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3710/4776 | Loss: 119.936 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3720/4776 | Loss: 130.111 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3730/4776 | Loss: 89.156 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3740/4776 | Loss: 160.092 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3750/4776 | Loss: 159.953 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3760/4776 | Loss: 146.648 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3770/4776 | Loss: 114.135 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3780/4776 | Loss: 196.227 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3790/4776 | Loss: 125.742 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3800/4776 | Loss: 113.837 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3810/4776 | Loss: 103.728 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3820/4776 | Loss: 204.711 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3830/4776 | Loss: 149.460 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3840/4776 | Loss: 103.752 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3850/4776 | Loss: 138.150 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3860/4776 | Loss: 116.674 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3870/4776 | Loss: 120.427 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3880/4776 | Loss: 128.965 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3890/4776 | Loss: 123.858 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3900/4776 | Loss: 61.074 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 3910/4776 | Loss: 157.740 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3920/4776 | Loss: 123.593 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 3930/4776 | Loss: 169.882 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 3940/4776 | Loss: 97.825 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 3950/4776 | Loss: 148.332 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3960/4776 | Loss: 155.754 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 3970/4776 | Loss: 130.306 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 3980/4776 | Loss: 165.264 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 3990/4776 | Loss: 112.814 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4000/4776 | Loss: 123.674 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4010/4776 | Loss: 161.443 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4020/4776 | Loss: 135.902 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4030/4776 | Loss: 83.880 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 4040/4776 | Loss: 156.049 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4050/4776 | Loss: 120.135 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4060/4776 | Loss: 111.748 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4070/4776 | Loss: 107.357 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4080/4776 | Loss: 144.564 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4090/4776 | Loss: 130.689 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4100/4776 | Loss: 154.088 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4110/4776 | Loss: 139.763 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4120/4776 | Loss: 161.719 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4130/4776 | Loss: 144.393 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4140/4776 | Loss: 137.160 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4150/4776 | Loss: 154.001 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4160/4776 | Loss: 73.589 | Accuracy: 0.800\n",
      "[Epoch: 47/200] - Step: 4170/4776 | Loss: 150.765 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4180/4776 | Loss: 108.450 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4190/4776 | Loss: 166.539 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4200/4776 | Loss: 98.433 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4210/4776 | Loss: 119.571 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4220/4776 | Loss: 117.098 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4230/4776 | Loss: 149.285 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4240/4776 | Loss: 100.044 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4250/4776 | Loss: 86.742 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 4260/4776 | Loss: 194.896 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4270/4776 | Loss: 112.928 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4280/4776 | Loss: 130.733 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4290/4776 | Loss: 145.841 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4300/4776 | Loss: 158.386 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4310/4776 | Loss: 156.170 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4320/4776 | Loss: 125.417 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 4330/4776 | Loss: 91.660 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4340/4776 | Loss: 145.746 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4350/4776 | Loss: 162.829 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4360/4776 | Loss: 193.522 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 4370/4776 | Loss: 122.657 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4380/4776 | Loss: 162.702 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4390/4776 | Loss: 179.039 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 4400/4776 | Loss: 134.623 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4410/4776 | Loss: 163.205 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4420/4776 | Loss: 143.916 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4430/4776 | Loss: 180.389 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4440/4776 | Loss: 175.811 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4450/4776 | Loss: 142.572 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4460/4776 | Loss: 138.212 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4470/4776 | Loss: 132.945 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4480/4776 | Loss: 146.267 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 4490/4776 | Loss: 124.621 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4500/4776 | Loss: 147.208 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4510/4776 | Loss: 152.396 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4520/4776 | Loss: 130.015 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4530/4776 | Loss: 115.386 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 4540/4776 | Loss: 182.854 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4550/4776 | Loss: 117.452 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4560/4776 | Loss: 76.548 | Accuracy: 0.900\n",
      "[Epoch: 47/200] - Step: 4570/4776 | Loss: 138.021 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4580/4776 | Loss: 180.164 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4590/4776 | Loss: 125.052 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4600/4776 | Loss: 130.833 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4610/4776 | Loss: 108.979 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4620/4776 | Loss: 143.298 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4630/4776 | Loss: 175.220 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4640/4776 | Loss: 132.014 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4650/4776 | Loss: 177.531 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 4660/4776 | Loss: 144.757 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 4670/4776 | Loss: 113.071 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4680/4776 | Loss: 89.021 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 4690/4776 | Loss: 107.295 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4700/4776 | Loss: 127.291 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4710/4776 | Loss: 153.050 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 4720/4776 | Loss: 132.906 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 4730/4776 | Loss: 149.239 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4740/4776 | Loss: 121.042 | Accuracy: 0.700\n",
      "[Epoch: 47/200] - Step: 4750/4776 | Loss: 164.608 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 4760/4776 | Loss: 108.182 | Accuracy: 0.600\n",
      "[Epoch: 47/200] - Step: 4770/4776 | Loss: 130.808 | Accuracy: 0.300\n",
      "Accuracy:  0.18360655737704917\n",
      "[Epoch: 48/200] - Step: 10/4776 | Loss: 168.557 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 20/4776 | Loss: 154.960 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 30/4776 | Loss: 165.570 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 40/4776 | Loss: 104.323 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 50/4776 | Loss: 112.629 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 60/4776 | Loss: 82.195 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 70/4776 | Loss: 137.400 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 80/4776 | Loss: 119.308 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 90/4776 | Loss: 118.584 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 100/4776 | Loss: 159.723 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 110/4776 | Loss: 107.325 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 120/4776 | Loss: 149.476 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 130/4776 | Loss: 101.550 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 140/4776 | Loss: 96.948 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 150/4776 | Loss: 148.028 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 160/4776 | Loss: 123.104 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 170/4776 | Loss: 175.622 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 180/4776 | Loss: 154.366 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 190/4776 | Loss: 210.930 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 200/4776 | Loss: 137.543 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 210/4776 | Loss: 182.082 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 220/4776 | Loss: 160.650 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 230/4776 | Loss: 116.287 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 240/4776 | Loss: 117.012 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 250/4776 | Loss: 167.076 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 260/4776 | Loss: 86.725 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 270/4776 | Loss: 136.936 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 280/4776 | Loss: 124.038 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 290/4776 | Loss: 148.847 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 300/4776 | Loss: 105.479 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 310/4776 | Loss: 176.685 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 320/4776 | Loss: 132.195 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 330/4776 | Loss: 96.456 | Accuracy: 0.900\n",
      "[Epoch: 48/200] - Step: 340/4776 | Loss: 175.317 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 350/4776 | Loss: 116.487 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 360/4776 | Loss: 120.785 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 370/4776 | Loss: 145.777 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 380/4776 | Loss: 112.904 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 390/4776 | Loss: 119.181 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 400/4776 | Loss: 93.248 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 410/4776 | Loss: 123.174 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 420/4776 | Loss: 122.872 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 430/4776 | Loss: 118.683 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 440/4776 | Loss: 135.916 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 450/4776 | Loss: 166.192 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 460/4776 | Loss: 85.407 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 470/4776 | Loss: 148.085 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 480/4776 | Loss: 105.385 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 490/4776 | Loss: 121.541 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 500/4776 | Loss: 137.327 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 510/4776 | Loss: 107.257 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 520/4776 | Loss: 178.745 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 530/4776 | Loss: 124.421 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 540/4776 | Loss: 98.683 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 550/4776 | Loss: 117.346 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 560/4776 | Loss: 132.289 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 570/4776 | Loss: 102.453 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 580/4776 | Loss: 114.973 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 590/4776 | Loss: 135.285 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 600/4776 | Loss: 138.990 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 610/4776 | Loss: 144.751 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 620/4776 | Loss: 142.506 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 630/4776 | Loss: 213.901 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 640/4776 | Loss: 165.617 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 650/4776 | Loss: 192.295 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 660/4776 | Loss: 145.358 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 670/4776 | Loss: 152.642 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 680/4776 | Loss: 174.237 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 690/4776 | Loss: 133.432 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 700/4776 | Loss: 109.201 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 710/4776 | Loss: 122.575 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 720/4776 | Loss: 83.651 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 730/4776 | Loss: 136.626 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 740/4776 | Loss: 148.506 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 750/4776 | Loss: 160.315 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 760/4776 | Loss: 108.580 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 770/4776 | Loss: 140.659 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 780/4776 | Loss: 109.231 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 790/4776 | Loss: 202.569 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 800/4776 | Loss: 104.784 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 810/4776 | Loss: 123.998 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 820/4776 | Loss: 136.044 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 830/4776 | Loss: 175.601 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 840/4776 | Loss: 72.691 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 850/4776 | Loss: 129.874 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 860/4776 | Loss: 128.086 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 870/4776 | Loss: 83.463 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 880/4776 | Loss: 107.211 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 890/4776 | Loss: 119.498 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 900/4776 | Loss: 96.852 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 910/4776 | Loss: 128.391 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 920/4776 | Loss: 129.399 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 930/4776 | Loss: 137.152 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 940/4776 | Loss: 104.872 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 950/4776 | Loss: 109.504 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 960/4776 | Loss: 112.320 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 970/4776 | Loss: 123.554 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 980/4776 | Loss: 129.940 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 990/4776 | Loss: 93.336 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1000/4776 | Loss: 161.652 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1010/4776 | Loss: 115.401 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1020/4776 | Loss: 140.326 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1030/4776 | Loss: 105.140 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1040/4776 | Loss: 106.652 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1050/4776 | Loss: 151.673 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1060/4776 | Loss: 96.466 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1070/4776 | Loss: 104.532 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1080/4776 | Loss: 132.626 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1090/4776 | Loss: 155.411 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1100/4776 | Loss: 95.075 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1110/4776 | Loss: 128.184 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1120/4776 | Loss: 79.592 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1130/4776 | Loss: 166.052 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1140/4776 | Loss: 113.754 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1150/4776 | Loss: 149.773 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1160/4776 | Loss: 181.195 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1170/4776 | Loss: 163.650 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1180/4776 | Loss: 192.557 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1190/4776 | Loss: 156.455 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1200/4776 | Loss: 149.767 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1210/4776 | Loss: 124.151 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1220/4776 | Loss: 173.068 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1230/4776 | Loss: 101.952 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1240/4776 | Loss: 137.142 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1250/4776 | Loss: 143.446 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1260/4776 | Loss: 109.836 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1270/4776 | Loss: 103.268 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1280/4776 | Loss: 111.814 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1290/4776 | Loss: 146.495 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1300/4776 | Loss: 167.867 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1310/4776 | Loss: 143.624 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1320/4776 | Loss: 144.196 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1330/4776 | Loss: 133.666 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1340/4776 | Loss: 112.775 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1350/4776 | Loss: 117.590 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1360/4776 | Loss: 126.686 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1370/4776 | Loss: 148.839 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1380/4776 | Loss: 86.426 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1390/4776 | Loss: 105.404 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1400/4776 | Loss: 110.231 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1410/4776 | Loss: 113.272 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1420/4776 | Loss: 139.313 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1430/4776 | Loss: 110.375 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1440/4776 | Loss: 77.631 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1450/4776 | Loss: 123.449 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1460/4776 | Loss: 156.810 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1470/4776 | Loss: 100.464 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1480/4776 | Loss: 100.472 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1490/4776 | Loss: 72.656 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1500/4776 | Loss: 107.756 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1510/4776 | Loss: 142.776 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1520/4776 | Loss: 109.035 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1530/4776 | Loss: 264.084 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1540/4776 | Loss: 62.443 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1550/4776 | Loss: 128.582 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1560/4776 | Loss: 115.646 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1570/4776 | Loss: 92.790 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1580/4776 | Loss: 161.959 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1590/4776 | Loss: 109.853 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1600/4776 | Loss: 124.313 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1610/4776 | Loss: 130.508 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1620/4776 | Loss: 95.726 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1630/4776 | Loss: 184.510 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1640/4776 | Loss: 162.085 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1650/4776 | Loss: 143.952 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1660/4776 | Loss: 104.124 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1670/4776 | Loss: 179.866 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1680/4776 | Loss: 84.970 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1690/4776 | Loss: 141.214 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1700/4776 | Loss: 124.179 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1710/4776 | Loss: 147.043 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1720/4776 | Loss: 111.067 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1730/4776 | Loss: 108.698 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1740/4776 | Loss: 184.855 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1750/4776 | Loss: 165.873 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1760/4776 | Loss: 126.023 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1770/4776 | Loss: 118.448 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1780/4776 | Loss: 87.638 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1790/4776 | Loss: 57.969 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1800/4776 | Loss: 155.293 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1810/4776 | Loss: 113.580 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1820/4776 | Loss: 145.672 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1830/4776 | Loss: 129.852 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1840/4776 | Loss: 132.812 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1850/4776 | Loss: 146.169 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1860/4776 | Loss: 159.197 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1870/4776 | Loss: 174.985 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1880/4776 | Loss: 117.826 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1890/4776 | Loss: 130.210 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1900/4776 | Loss: 158.291 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1910/4776 | Loss: 115.026 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 1920/4776 | Loss: 152.309 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1930/4776 | Loss: 168.651 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1940/4776 | Loss: 169.925 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1950/4776 | Loss: 142.459 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 1960/4776 | Loss: 108.095 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 1970/4776 | Loss: 137.314 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 1980/4776 | Loss: 146.678 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 1990/4776 | Loss: 145.078 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2000/4776 | Loss: 116.602 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2010/4776 | Loss: 108.069 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2020/4776 | Loss: 123.157 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2030/4776 | Loss: 157.143 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2040/4776 | Loss: 98.583 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2050/4776 | Loss: 196.738 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2060/4776 | Loss: 163.545 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2070/4776 | Loss: 154.917 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2080/4776 | Loss: 139.723 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2090/4776 | Loss: 180.203 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 2100/4776 | Loss: 179.334 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2110/4776 | Loss: 105.407 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2120/4776 | Loss: 130.497 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2130/4776 | Loss: 82.661 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2140/4776 | Loss: 129.481 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2150/4776 | Loss: 126.847 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2160/4776 | Loss: 98.751 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2170/4776 | Loss: 152.046 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2180/4776 | Loss: 113.957 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2190/4776 | Loss: 138.927 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2200/4776 | Loss: 73.067 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 2210/4776 | Loss: 171.781 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 2220/4776 | Loss: 89.071 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2230/4776 | Loss: 68.416 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 2240/4776 | Loss: 123.970 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2250/4776 | Loss: 126.617 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2260/4776 | Loss: 175.664 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 2270/4776 | Loss: 153.829 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 2280/4776 | Loss: 101.682 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2290/4776 | Loss: 124.378 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2300/4776 | Loss: 145.433 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2310/4776 | Loss: 153.437 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2320/4776 | Loss: 174.159 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2330/4776 | Loss: 133.504 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2340/4776 | Loss: 105.105 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2350/4776 | Loss: 98.463 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2360/4776 | Loss: 93.928 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2370/4776 | Loss: 139.331 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2380/4776 | Loss: 137.354 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2390/4776 | Loss: 84.050 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2400/4776 | Loss: 192.586 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2410/4776 | Loss: 111.608 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2420/4776 | Loss: 140.452 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2430/4776 | Loss: 168.704 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2440/4776 | Loss: 91.871 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 2450/4776 | Loss: 140.700 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2460/4776 | Loss: 93.006 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2470/4776 | Loss: 113.383 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2480/4776 | Loss: 174.458 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2490/4776 | Loss: 115.506 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2500/4776 | Loss: 92.597 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2510/4776 | Loss: 146.882 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2520/4776 | Loss: 186.796 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2530/4776 | Loss: 180.923 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 2540/4776 | Loss: 101.613 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2550/4776 | Loss: 171.569 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2560/4776 | Loss: 155.730 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2570/4776 | Loss: 122.564 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2580/4776 | Loss: 72.764 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2590/4776 | Loss: 118.411 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2600/4776 | Loss: 129.911 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2610/4776 | Loss: 164.485 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2620/4776 | Loss: 120.273 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2630/4776 | Loss: 89.463 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2640/4776 | Loss: 108.737 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2650/4776 | Loss: 83.960 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 2660/4776 | Loss: 111.246 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2670/4776 | Loss: 122.295 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2680/4776 | Loss: 102.046 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2690/4776 | Loss: 122.927 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2700/4776 | Loss: 140.642 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2710/4776 | Loss: 107.390 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2720/4776 | Loss: 124.660 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2730/4776 | Loss: 160.588 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2740/4776 | Loss: 113.043 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2750/4776 | Loss: 143.357 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2760/4776 | Loss: 108.817 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2770/4776 | Loss: 106.708 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2780/4776 | Loss: 131.650 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2790/4776 | Loss: 157.645 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2800/4776 | Loss: 123.297 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2810/4776 | Loss: 140.453 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2820/4776 | Loss: 137.207 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2830/4776 | Loss: 151.808 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2840/4776 | Loss: 83.286 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2850/4776 | Loss: 96.497 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2860/4776 | Loss: 141.234 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2870/4776 | Loss: 143.113 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2880/4776 | Loss: 115.595 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2890/4776 | Loss: 155.653 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2900/4776 | Loss: 141.002 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 2910/4776 | Loss: 100.624 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 2920/4776 | Loss: 128.191 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2930/4776 | Loss: 99.122 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2940/4776 | Loss: 138.851 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2950/4776 | Loss: 153.375 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 2960/4776 | Loss: 147.913 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 2970/4776 | Loss: 97.121 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2980/4776 | Loss: 125.487 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 2990/4776 | Loss: 107.233 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3000/4776 | Loss: 145.531 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3010/4776 | Loss: 126.693 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3020/4776 | Loss: 145.861 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3030/4776 | Loss: 87.570 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3040/4776 | Loss: 85.639 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 3050/4776 | Loss: 67.945 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3060/4776 | Loss: 136.580 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3070/4776 | Loss: 131.460 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3080/4776 | Loss: 62.348 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3090/4776 | Loss: 172.996 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3100/4776 | Loss: 134.703 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3110/4776 | Loss: 203.924 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3120/4776 | Loss: 200.253 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3130/4776 | Loss: 150.185 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3140/4776 | Loss: 92.558 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3150/4776 | Loss: 182.211 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3160/4776 | Loss: 140.137 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3170/4776 | Loss: 112.540 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3180/4776 | Loss: 105.936 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3190/4776 | Loss: 162.084 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3200/4776 | Loss: 93.541 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3210/4776 | Loss: 142.651 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3220/4776 | Loss: 130.518 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3230/4776 | Loss: 105.625 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3240/4776 | Loss: 100.465 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3250/4776 | Loss: 120.514 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3260/4776 | Loss: 88.643 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3270/4776 | Loss: 78.049 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3280/4776 | Loss: 125.066 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3290/4776 | Loss: 105.212 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3300/4776 | Loss: 162.495 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3310/4776 | Loss: 101.044 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3320/4776 | Loss: 123.595 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3330/4776 | Loss: 158.873 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3340/4776 | Loss: 70.193 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 3350/4776 | Loss: 171.139 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3360/4776 | Loss: 98.545 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3370/4776 | Loss: 153.584 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3380/4776 | Loss: 129.198 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3390/4776 | Loss: 100.237 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3400/4776 | Loss: 104.830 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3410/4776 | Loss: 99.382 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3420/4776 | Loss: 178.677 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3430/4776 | Loss: 147.435 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3440/4776 | Loss: 178.587 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3450/4776 | Loss: 121.457 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3460/4776 | Loss: 108.673 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3470/4776 | Loss: 185.072 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3480/4776 | Loss: 92.944 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3490/4776 | Loss: 183.990 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3500/4776 | Loss: 250.203 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3510/4776 | Loss: 78.205 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3520/4776 | Loss: 236.421 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3530/4776 | Loss: 134.674 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3540/4776 | Loss: 165.006 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3550/4776 | Loss: 202.044 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 3560/4776 | Loss: 191.178 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 3570/4776 | Loss: 143.431 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3580/4776 | Loss: 136.233 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3590/4776 | Loss: 116.724 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3600/4776 | Loss: 123.485 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3610/4776 | Loss: 144.574 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3620/4776 | Loss: 120.226 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3630/4776 | Loss: 153.565 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3640/4776 | Loss: 117.279 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3650/4776 | Loss: 85.166 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3660/4776 | Loss: 102.014 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 3670/4776 | Loss: 180.134 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3680/4776 | Loss: 147.907 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3690/4776 | Loss: 125.579 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3700/4776 | Loss: 108.280 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3710/4776 | Loss: 141.048 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3720/4776 | Loss: 88.238 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 3730/4776 | Loss: 101.147 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3740/4776 | Loss: 150.431 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3750/4776 | Loss: 123.434 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3760/4776 | Loss: 128.439 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3770/4776 | Loss: 81.352 | Accuracy: 0.900\n",
      "[Epoch: 48/200] - Step: 3780/4776 | Loss: 75.107 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3790/4776 | Loss: 128.348 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3800/4776 | Loss: 112.595 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3810/4776 | Loss: 131.740 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3820/4776 | Loss: 133.771 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3830/4776 | Loss: 114.223 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3840/4776 | Loss: 161.856 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3850/4776 | Loss: 120.339 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3860/4776 | Loss: 150.330 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3870/4776 | Loss: 135.671 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3880/4776 | Loss: 132.569 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 3890/4776 | Loss: 100.672 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3900/4776 | Loss: 148.501 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3910/4776 | Loss: 190.427 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 3920/4776 | Loss: 56.871 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 3930/4776 | Loss: 212.821 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 3940/4776 | Loss: 105.658 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 3950/4776 | Loss: 124.173 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3960/4776 | Loss: 142.412 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 3970/4776 | Loss: 125.937 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 3980/4776 | Loss: 116.058 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 3990/4776 | Loss: 99.943 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4000/4776 | Loss: 138.213 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4010/4776 | Loss: 145.132 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4020/4776 | Loss: 97.529 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4030/4776 | Loss: 123.794 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4040/4776 | Loss: 177.072 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4050/4776 | Loss: 139.132 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4060/4776 | Loss: 107.901 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4070/4776 | Loss: 98.742 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4080/4776 | Loss: 136.572 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4090/4776 | Loss: 145.354 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4100/4776 | Loss: 148.179 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4110/4776 | Loss: 112.375 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4120/4776 | Loss: 163.261 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4130/4776 | Loss: 115.219 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4140/4776 | Loss: 166.768 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 4150/4776 | Loss: 169.037 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4160/4776 | Loss: 174.829 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4170/4776 | Loss: 138.921 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4180/4776 | Loss: 84.207 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4190/4776 | Loss: 101.882 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4200/4776 | Loss: 51.872 | Accuracy: 0.900\n",
      "[Epoch: 48/200] - Step: 4210/4776 | Loss: 121.689 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4220/4776 | Loss: 183.958 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4230/4776 | Loss: 74.133 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4240/4776 | Loss: 147.582 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4250/4776 | Loss: 114.358 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4260/4776 | Loss: 103.284 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4270/4776 | Loss: 176.563 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4280/4776 | Loss: 171.434 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4290/4776 | Loss: 140.158 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4300/4776 | Loss: 147.699 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4310/4776 | Loss: 95.845 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4320/4776 | Loss: 122.657 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4330/4776 | Loss: 193.470 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4340/4776 | Loss: 195.761 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4350/4776 | Loss: 119.861 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4360/4776 | Loss: 128.123 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4370/4776 | Loss: 129.934 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4380/4776 | Loss: 121.025 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4390/4776 | Loss: 139.413 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4400/4776 | Loss: 141.525 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4410/4776 | Loss: 164.207 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4420/4776 | Loss: 153.693 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4430/4776 | Loss: 109.583 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4440/4776 | Loss: 183.459 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 4450/4776 | Loss: 164.790 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4460/4776 | Loss: 94.645 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4470/4776 | Loss: 116.123 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4480/4776 | Loss: 109.490 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4490/4776 | Loss: 149.347 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4500/4776 | Loss: 128.072 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4510/4776 | Loss: 155.033 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4520/4776 | Loss: 145.946 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4530/4776 | Loss: 218.542 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4540/4776 | Loss: 142.643 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4550/4776 | Loss: 134.655 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4560/4776 | Loss: 169.932 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4570/4776 | Loss: 175.128 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4580/4776 | Loss: 89.948 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4590/4776 | Loss: 150.431 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4600/4776 | Loss: 148.559 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4610/4776 | Loss: 139.456 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4620/4776 | Loss: 89.513 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4630/4776 | Loss: 124.900 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4640/4776 | Loss: 219.468 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4650/4776 | Loss: 122.136 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4660/4776 | Loss: 118.178 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4670/4776 | Loss: 156.585 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4680/4776 | Loss: 162.444 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4690/4776 | Loss: 143.725 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4700/4776 | Loss: 156.823 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 4710/4776 | Loss: 96.805 | Accuracy: 0.600\n",
      "[Epoch: 48/200] - Step: 4720/4776 | Loss: 136.857 | Accuracy: 0.500\n",
      "[Epoch: 48/200] - Step: 4730/4776 | Loss: 123.733 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 4740/4776 | Loss: 100.650 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 4750/4776 | Loss: 79.925 | Accuracy: 0.800\n",
      "[Epoch: 48/200] - Step: 4760/4776 | Loss: 84.855 | Accuracy: 0.700\n",
      "[Epoch: 48/200] - Step: 4770/4776 | Loss: 132.406 | Accuracy: 0.600\n",
      "Accuracy:  0.21967213114754097\n",
      "[Epoch: 49/200] - Step: 10/4776 | Loss: 143.617 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 20/4776 | Loss: 110.069 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 30/4776 | Loss: 145.696 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 40/4776 | Loss: 145.199 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 50/4776 | Loss: 143.260 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 60/4776 | Loss: 105.412 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 70/4776 | Loss: 123.285 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 80/4776 | Loss: 82.677 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 90/4776 | Loss: 159.085 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 100/4776 | Loss: 160.229 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 110/4776 | Loss: 148.416 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 120/4776 | Loss: 88.076 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 130/4776 | Loss: 80.789 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 140/4776 | Loss: 207.928 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 150/4776 | Loss: 140.120 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 160/4776 | Loss: 83.996 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 170/4776 | Loss: 110.759 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 180/4776 | Loss: 150.904 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 190/4776 | Loss: 152.121 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 200/4776 | Loss: 171.991 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 210/4776 | Loss: 137.322 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 220/4776 | Loss: 73.579 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 230/4776 | Loss: 146.678 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 240/4776 | Loss: 166.905 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 250/4776 | Loss: 119.439 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 260/4776 | Loss: 141.380 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 270/4776 | Loss: 128.888 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 280/4776 | Loss: 137.741 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 290/4776 | Loss: 91.930 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 300/4776 | Loss: 153.520 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 310/4776 | Loss: 110.040 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 320/4776 | Loss: 129.807 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 330/4776 | Loss: 135.509 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 340/4776 | Loss: 139.202 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 350/4776 | Loss: 157.699 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 360/4776 | Loss: 163.645 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 370/4776 | Loss: 107.481 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 380/4776 | Loss: 173.663 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 390/4776 | Loss: 142.141 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 400/4776 | Loss: 141.196 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 410/4776 | Loss: 221.800 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 420/4776 | Loss: 133.327 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 430/4776 | Loss: 154.106 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 440/4776 | Loss: 144.111 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 450/4776 | Loss: 129.381 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 460/4776 | Loss: 159.933 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 470/4776 | Loss: 147.995 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 480/4776 | Loss: 73.807 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 490/4776 | Loss: 101.522 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 500/4776 | Loss: 113.819 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 510/4776 | Loss: 114.644 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 520/4776 | Loss: 131.500 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 530/4776 | Loss: 117.096 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 540/4776 | Loss: 84.816 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 550/4776 | Loss: 165.563 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 560/4776 | Loss: 104.326 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 570/4776 | Loss: 126.041 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 580/4776 | Loss: 92.163 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 590/4776 | Loss: 121.322 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 600/4776 | Loss: 147.255 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 610/4776 | Loss: 126.050 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 620/4776 | Loss: 120.037 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 630/4776 | Loss: 98.319 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 640/4776 | Loss: 118.187 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 650/4776 | Loss: 102.793 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 660/4776 | Loss: 96.307 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 670/4776 | Loss: 148.643 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 680/4776 | Loss: 218.623 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 690/4776 | Loss: 150.955 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 700/4776 | Loss: 120.484 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 710/4776 | Loss: 151.185 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 720/4776 | Loss: 111.103 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 730/4776 | Loss: 117.790 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 740/4776 | Loss: 114.868 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 750/4776 | Loss: 148.622 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 760/4776 | Loss: 127.324 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 770/4776 | Loss: 136.502 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 780/4776 | Loss: 157.073 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 790/4776 | Loss: 134.757 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 800/4776 | Loss: 95.658 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 810/4776 | Loss: 104.110 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 820/4776 | Loss: 92.921 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 830/4776 | Loss: 83.730 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 840/4776 | Loss: 124.488 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 850/4776 | Loss: 132.015 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 860/4776 | Loss: 108.746 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 870/4776 | Loss: 112.087 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 880/4776 | Loss: 127.303 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 890/4776 | Loss: 118.073 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 900/4776 | Loss: 99.682 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 910/4776 | Loss: 132.360 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 920/4776 | Loss: 155.026 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 930/4776 | Loss: 125.833 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 940/4776 | Loss: 100.083 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 950/4776 | Loss: 110.327 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 960/4776 | Loss: 123.829 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 970/4776 | Loss: 103.318 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 980/4776 | Loss: 104.043 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 990/4776 | Loss: 132.194 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1000/4776 | Loss: 151.199 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1010/4776 | Loss: 113.216 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1020/4776 | Loss: 114.699 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1030/4776 | Loss: 105.887 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1040/4776 | Loss: 152.993 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1050/4776 | Loss: 105.824 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1060/4776 | Loss: 101.520 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1070/4776 | Loss: 93.776 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 1080/4776 | Loss: 175.257 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1090/4776 | Loss: 95.766 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 1100/4776 | Loss: 74.809 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 1110/4776 | Loss: 131.999 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1120/4776 | Loss: 135.762 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1130/4776 | Loss: 136.380 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1140/4776 | Loss: 83.049 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1150/4776 | Loss: 123.029 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1160/4776 | Loss: 161.524 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1170/4776 | Loss: 101.852 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1180/4776 | Loss: 75.278 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 1190/4776 | Loss: 121.697 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1200/4776 | Loss: 63.323 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 1210/4776 | Loss: 75.976 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1220/4776 | Loss: 92.647 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1230/4776 | Loss: 180.331 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1240/4776 | Loss: 150.459 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1250/4776 | Loss: 95.003 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1260/4776 | Loss: 143.846 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1270/4776 | Loss: 109.143 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1280/4776 | Loss: 147.512 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1290/4776 | Loss: 166.395 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1300/4776 | Loss: 104.465 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1310/4776 | Loss: 168.214 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1320/4776 | Loss: 201.281 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1330/4776 | Loss: 129.644 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1340/4776 | Loss: 163.679 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1350/4776 | Loss: 161.307 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1360/4776 | Loss: 88.932 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1370/4776 | Loss: 86.534 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1380/4776 | Loss: 155.574 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1390/4776 | Loss: 125.794 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1400/4776 | Loss: 152.853 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1410/4776 | Loss: 121.799 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1420/4776 | Loss: 93.504 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 1430/4776 | Loss: 154.511 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1440/4776 | Loss: 119.067 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1450/4776 | Loss: 117.792 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1460/4776 | Loss: 92.922 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1470/4776 | Loss: 129.310 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1480/4776 | Loss: 132.884 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1490/4776 | Loss: 94.844 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1500/4776 | Loss: 153.375 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1510/4776 | Loss: 151.899 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1520/4776 | Loss: 116.114 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1530/4776 | Loss: 107.504 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1540/4776 | Loss: 115.997 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1550/4776 | Loss: 132.925 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1560/4776 | Loss: 140.911 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1570/4776 | Loss: 128.936 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1580/4776 | Loss: 105.334 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1590/4776 | Loss: 150.378 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1600/4776 | Loss: 162.591 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1610/4776 | Loss: 102.775 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1620/4776 | Loss: 125.428 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1630/4776 | Loss: 94.091 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1640/4776 | Loss: 253.864 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1650/4776 | Loss: 140.540 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1660/4776 | Loss: 97.842 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1670/4776 | Loss: 97.597 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 1680/4776 | Loss: 66.566 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1690/4776 | Loss: 146.920 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1700/4776 | Loss: 99.136 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1710/4776 | Loss: 201.101 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1720/4776 | Loss: 116.028 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1730/4776 | Loss: 154.946 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1740/4776 | Loss: 216.675 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1750/4776 | Loss: 49.417 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 1760/4776 | Loss: 148.758 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1770/4776 | Loss: 155.705 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1780/4776 | Loss: 92.043 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1790/4776 | Loss: 199.405 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1800/4776 | Loss: 97.111 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1810/4776 | Loss: 181.849 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1820/4776 | Loss: 134.928 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1830/4776 | Loss: 184.068 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1840/4776 | Loss: 74.590 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 1850/4776 | Loss: 136.661 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1860/4776 | Loss: 116.601 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1870/4776 | Loss: 173.170 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1880/4776 | Loss: 105.049 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1890/4776 | Loss: 158.135 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1900/4776 | Loss: 101.691 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1910/4776 | Loss: 182.393 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1920/4776 | Loss: 102.327 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1930/4776 | Loss: 85.285 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1940/4776 | Loss: 135.196 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1950/4776 | Loss: 102.649 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 1960/4776 | Loss: 134.046 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 1970/4776 | Loss: 73.428 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 1980/4776 | Loss: 94.455 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 1990/4776 | Loss: 146.596 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2000/4776 | Loss: 104.034 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2010/4776 | Loss: 117.708 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2020/4776 | Loss: 107.078 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2030/4776 | Loss: 154.257 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2040/4776 | Loss: 124.272 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 2050/4776 | Loss: 149.853 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2060/4776 | Loss: 153.743 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2070/4776 | Loss: 152.791 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2080/4776 | Loss: 114.597 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2090/4776 | Loss: 143.583 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2100/4776 | Loss: 79.589 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 2110/4776 | Loss: 154.536 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2120/4776 | Loss: 98.123 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2130/4776 | Loss: 114.667 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2140/4776 | Loss: 104.070 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2150/4776 | Loss: 117.335 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2160/4776 | Loss: 168.834 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2170/4776 | Loss: 108.816 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2180/4776 | Loss: 134.314 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2190/4776 | Loss: 112.609 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2200/4776 | Loss: 102.078 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2210/4776 | Loss: 90.554 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2220/4776 | Loss: 118.697 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2230/4776 | Loss: 133.784 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2240/4776 | Loss: 101.570 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2250/4776 | Loss: 128.441 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2260/4776 | Loss: 134.466 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2270/4776 | Loss: 168.478 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 2280/4776 | Loss: 118.216 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2290/4776 | Loss: 151.505 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2300/4776 | Loss: 99.902 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2310/4776 | Loss: 98.311 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2320/4776 | Loss: 118.040 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2330/4776 | Loss: 103.656 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2340/4776 | Loss: 145.370 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2350/4776 | Loss: 100.697 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2360/4776 | Loss: 164.590 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2370/4776 | Loss: 179.503 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 2380/4776 | Loss: 97.576 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2390/4776 | Loss: 137.583 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2400/4776 | Loss: 184.891 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2410/4776 | Loss: 140.339 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2420/4776 | Loss: 129.972 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2430/4776 | Loss: 148.669 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2440/4776 | Loss: 211.242 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2450/4776 | Loss: 155.875 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2460/4776 | Loss: 132.649 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2470/4776 | Loss: 138.530 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2480/4776 | Loss: 101.544 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2490/4776 | Loss: 111.978 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2500/4776 | Loss: 170.988 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2510/4776 | Loss: 121.947 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2520/4776 | Loss: 158.774 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2530/4776 | Loss: 117.462 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2540/4776 | Loss: 161.370 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2550/4776 | Loss: 118.469 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2560/4776 | Loss: 98.691 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2570/4776 | Loss: 105.659 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2580/4776 | Loss: 158.362 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2590/4776 | Loss: 115.651 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2600/4776 | Loss: 120.179 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2610/4776 | Loss: 83.876 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 2620/4776 | Loss: 95.816 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2630/4776 | Loss: 116.800 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2640/4776 | Loss: 98.146 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2650/4776 | Loss: 107.726 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2660/4776 | Loss: 124.318 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2670/4776 | Loss: 176.349 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2680/4776 | Loss: 155.161 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2690/4776 | Loss: 109.942 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2700/4776 | Loss: 233.126 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 2710/4776 | Loss: 135.051 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2720/4776 | Loss: 79.420 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2730/4776 | Loss: 69.450 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 2740/4776 | Loss: 142.051 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2750/4776 | Loss: 97.208 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2760/4776 | Loss: 232.966 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 2770/4776 | Loss: 83.879 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 2780/4776 | Loss: 135.037 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2790/4776 | Loss: 130.193 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2800/4776 | Loss: 63.791 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 2810/4776 | Loss: 115.386 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2820/4776 | Loss: 157.745 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 2830/4776 | Loss: 100.304 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2840/4776 | Loss: 125.425 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2850/4776 | Loss: 118.662 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2860/4776 | Loss: 77.031 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 2870/4776 | Loss: 96.751 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2880/4776 | Loss: 107.316 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2890/4776 | Loss: 85.222 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2900/4776 | Loss: 107.885 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2910/4776 | Loss: 154.117 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2920/4776 | Loss: 138.164 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2930/4776 | Loss: 111.433 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 2940/4776 | Loss: 131.698 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 2950/4776 | Loss: 148.285 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2960/4776 | Loss: 148.931 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2970/4776 | Loss: 107.323 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 2980/4776 | Loss: 178.174 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 2990/4776 | Loss: 118.127 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3000/4776 | Loss: 110.684 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3010/4776 | Loss: 143.491 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3020/4776 | Loss: 105.330 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3030/4776 | Loss: 147.352 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3040/4776 | Loss: 159.958 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3050/4776 | Loss: 107.700 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3060/4776 | Loss: 115.220 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3070/4776 | Loss: 153.897 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3080/4776 | Loss: 125.630 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3090/4776 | Loss: 122.059 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3100/4776 | Loss: 95.629 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3110/4776 | Loss: 134.280 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3120/4776 | Loss: 98.527 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3130/4776 | Loss: 155.971 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3140/4776 | Loss: 93.860 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3150/4776 | Loss: 110.135 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3160/4776 | Loss: 87.899 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3170/4776 | Loss: 116.433 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3180/4776 | Loss: 112.414 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3190/4776 | Loss: 83.142 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3200/4776 | Loss: 64.154 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3210/4776 | Loss: 171.297 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3220/4776 | Loss: 124.097 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3230/4776 | Loss: 76.325 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3240/4776 | Loss: 102.946 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3250/4776 | Loss: 81.199 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3260/4776 | Loss: 162.229 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3270/4776 | Loss: 159.073 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3280/4776 | Loss: 161.454 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3290/4776 | Loss: 114.917 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3300/4776 | Loss: 132.137 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3310/4776 | Loss: 205.587 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3320/4776 | Loss: 83.724 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3330/4776 | Loss: 113.960 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3340/4776 | Loss: 58.745 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3350/4776 | Loss: 121.081 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3360/4776 | Loss: 177.548 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3370/4776 | Loss: 148.774 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3380/4776 | Loss: 105.321 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3390/4776 | Loss: 86.277 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3400/4776 | Loss: 132.308 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3410/4776 | Loss: 153.299 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3420/4776 | Loss: 128.198 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3430/4776 | Loss: 95.836 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3440/4776 | Loss: 92.034 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3450/4776 | Loss: 126.564 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3460/4776 | Loss: 211.052 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3470/4776 | Loss: 142.083 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3480/4776 | Loss: 114.240 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3490/4776 | Loss: 85.594 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3500/4776 | Loss: 136.700 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3510/4776 | Loss: 176.675 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3520/4776 | Loss: 66.721 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3530/4776 | Loss: 238.623 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 3540/4776 | Loss: 74.203 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 3550/4776 | Loss: 150.471 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3560/4776 | Loss: 112.992 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3570/4776 | Loss: 171.403 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3580/4776 | Loss: 152.120 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3590/4776 | Loss: 92.158 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3600/4776 | Loss: 174.766 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3610/4776 | Loss: 131.644 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3620/4776 | Loss: 125.567 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3630/4776 | Loss: 116.979 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3640/4776 | Loss: 142.946 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3650/4776 | Loss: 91.394 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3660/4776 | Loss: 141.178 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3670/4776 | Loss: 137.351 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3680/4776 | Loss: 145.666 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3690/4776 | Loss: 124.194 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3700/4776 | Loss: 165.637 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3710/4776 | Loss: 124.450 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3720/4776 | Loss: 183.607 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3730/4776 | Loss: 209.330 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3740/4776 | Loss: 95.980 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3750/4776 | Loss: 144.113 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3760/4776 | Loss: 102.251 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3770/4776 | Loss: 178.877 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3780/4776 | Loss: 101.698 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3790/4776 | Loss: 96.693 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3800/4776 | Loss: 105.328 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3810/4776 | Loss: 90.505 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3820/4776 | Loss: 112.169 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3830/4776 | Loss: 60.617 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 3840/4776 | Loss: 167.928 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 3850/4776 | Loss: 120.474 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3860/4776 | Loss: 154.009 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3870/4776 | Loss: 158.778 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 3880/4776 | Loss: 123.355 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3890/4776 | Loss: 137.293 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3900/4776 | Loss: 90.014 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3910/4776 | Loss: 95.105 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 3920/4776 | Loss: 151.748 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3930/4776 | Loss: 146.695 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3940/4776 | Loss: 126.516 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3950/4776 | Loss: 113.599 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 3960/4776 | Loss: 186.585 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 3970/4776 | Loss: 91.525 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 3980/4776 | Loss: 213.130 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 3990/4776 | Loss: 117.923 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4000/4776 | Loss: 128.008 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4010/4776 | Loss: 163.787 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4020/4776 | Loss: 83.277 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 4030/4776 | Loss: 87.720 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 4040/4776 | Loss: 135.174 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4050/4776 | Loss: 108.712 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4060/4776 | Loss: 100.380 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 4070/4776 | Loss: 175.655 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4080/4776 | Loss: 67.254 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4090/4776 | Loss: 119.169 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4100/4776 | Loss: 95.396 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4110/4776 | Loss: 126.971 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4120/4776 | Loss: 135.106 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4130/4776 | Loss: 172.112 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4140/4776 | Loss: 82.104 | Accuracy: 0.800\n",
      "[Epoch: 49/200] - Step: 4150/4776 | Loss: 63.032 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4160/4776 | Loss: 102.284 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4170/4776 | Loss: 100.049 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4180/4776 | Loss: 88.590 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4190/4776 | Loss: 99.555 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4200/4776 | Loss: 156.263 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4210/4776 | Loss: 35.908 | Accuracy: 1.000\n",
      "[Epoch: 49/200] - Step: 4220/4776 | Loss: 116.987 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4230/4776 | Loss: 125.174 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4240/4776 | Loss: 174.208 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4250/4776 | Loss: 176.974 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4260/4776 | Loss: 137.879 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4270/4776 | Loss: 70.472 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4280/4776 | Loss: 137.144 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4290/4776 | Loss: 120.500 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4300/4776 | Loss: 166.782 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4310/4776 | Loss: 107.755 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4320/4776 | Loss: 127.459 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4330/4776 | Loss: 120.957 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4340/4776 | Loss: 155.068 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4350/4776 | Loss: 248.119 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4360/4776 | Loss: 112.048 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4370/4776 | Loss: 164.330 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4380/4776 | Loss: 162.565 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4390/4776 | Loss: 101.905 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4400/4776 | Loss: 171.373 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4410/4776 | Loss: 133.918 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4420/4776 | Loss: 118.724 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4430/4776 | Loss: 77.211 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 4440/4776 | Loss: 175.653 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4450/4776 | Loss: 106.066 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4460/4776 | Loss: 132.313 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4470/4776 | Loss: 142.979 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4480/4776 | Loss: 180.868 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4490/4776 | Loss: 162.988 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4500/4776 | Loss: 175.494 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4510/4776 | Loss: 153.156 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4520/4776 | Loss: 187.151 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4530/4776 | Loss: 163.107 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4540/4776 | Loss: 122.980 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4550/4776 | Loss: 192.166 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4560/4776 | Loss: 119.050 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4570/4776 | Loss: 141.480 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4580/4776 | Loss: 151.928 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4590/4776 | Loss: 166.134 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4600/4776 | Loss: 175.254 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4610/4776 | Loss: 87.886 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4620/4776 | Loss: 105.124 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4630/4776 | Loss: 130.229 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4640/4776 | Loss: 108.588 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4650/4776 | Loss: 139.247 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4660/4776 | Loss: 137.476 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 4670/4776 | Loss: 74.686 | Accuracy: 0.900\n",
      "[Epoch: 49/200] - Step: 4680/4776 | Loss: 98.280 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4690/4776 | Loss: 99.748 | Accuracy: 0.600\n",
      "[Epoch: 49/200] - Step: 4700/4776 | Loss: 202.616 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4710/4776 | Loss: 96.532 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4720/4776 | Loss: 89.555 | Accuracy: 0.700\n",
      "[Epoch: 49/200] - Step: 4730/4776 | Loss: 140.282 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4740/4776 | Loss: 173.351 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 4750/4776 | Loss: 158.075 | Accuracy: 0.500\n",
      "[Epoch: 49/200] - Step: 4760/4776 | Loss: 139.622 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 4770/4776 | Loss: 139.241 | Accuracy: 0.400\n",
      "Accuracy:  0.1885245901639344\n",
      "[Epoch: 50/200] - Step: 10/4776 | Loss: 130.741 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 20/4776 | Loss: 105.322 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 30/4776 | Loss: 114.438 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 40/4776 | Loss: 103.785 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 50/4776 | Loss: 118.551 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 60/4776 | Loss: 163.232 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 70/4776 | Loss: 112.890 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 80/4776 | Loss: 108.170 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 90/4776 | Loss: 126.970 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 100/4776 | Loss: 87.730 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 110/4776 | Loss: 134.593 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 120/4776 | Loss: 97.051 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 130/4776 | Loss: 104.100 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 140/4776 | Loss: 144.565 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 150/4776 | Loss: 92.107 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 160/4776 | Loss: 123.094 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 170/4776 | Loss: 114.889 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 180/4776 | Loss: 116.770 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 190/4776 | Loss: 132.441 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 200/4776 | Loss: 116.969 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 210/4776 | Loss: 100.322 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 220/4776 | Loss: 141.398 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 230/4776 | Loss: 134.188 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 240/4776 | Loss: 125.535 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 250/4776 | Loss: 101.031 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 260/4776 | Loss: 212.795 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 270/4776 | Loss: 184.984 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 280/4776 | Loss: 105.486 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 290/4776 | Loss: 129.666 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 300/4776 | Loss: 105.363 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 310/4776 | Loss: 83.230 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 320/4776 | Loss: 71.545 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 330/4776 | Loss: 100.948 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 340/4776 | Loss: 114.779 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 350/4776 | Loss: 137.043 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 360/4776 | Loss: 108.768 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 370/4776 | Loss: 69.051 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 380/4776 | Loss: 131.737 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 390/4776 | Loss: 105.928 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 400/4776 | Loss: 124.405 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 410/4776 | Loss: 104.569 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 420/4776 | Loss: 96.016 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 430/4776 | Loss: 154.818 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 440/4776 | Loss: 113.826 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 450/4776 | Loss: 73.330 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 460/4776 | Loss: 138.601 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 470/4776 | Loss: 154.529 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 480/4776 | Loss: 151.445 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 490/4776 | Loss: 122.818 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 500/4776 | Loss: 254.259 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 510/4776 | Loss: 84.937 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 520/4776 | Loss: 103.712 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 530/4776 | Loss: 103.895 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 540/4776 | Loss: 83.041 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 550/4776 | Loss: 104.809 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 560/4776 | Loss: 133.621 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 570/4776 | Loss: 97.564 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 580/4776 | Loss: 129.206 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 590/4776 | Loss: 131.221 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 600/4776 | Loss: 108.952 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 610/4776 | Loss: 105.537 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 620/4776 | Loss: 70.925 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 630/4776 | Loss: 157.207 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 640/4776 | Loss: 91.181 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 650/4776 | Loss: 116.589 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 660/4776 | Loss: 140.231 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 670/4776 | Loss: 86.203 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 680/4776 | Loss: 135.150 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 690/4776 | Loss: 97.639 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 700/4776 | Loss: 178.439 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 710/4776 | Loss: 144.613 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 720/4776 | Loss: 136.270 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 730/4776 | Loss: 164.080 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 740/4776 | Loss: 128.930 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 750/4776 | Loss: 139.806 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 760/4776 | Loss: 147.582 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 770/4776 | Loss: 68.586 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 780/4776 | Loss: 170.528 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 790/4776 | Loss: 98.044 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 800/4776 | Loss: 148.309 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 810/4776 | Loss: 144.665 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 820/4776 | Loss: 182.219 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 830/4776 | Loss: 112.697 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 840/4776 | Loss: 117.321 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 850/4776 | Loss: 110.747 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 860/4776 | Loss: 117.244 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 870/4776 | Loss: 72.723 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 880/4776 | Loss: 83.520 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 890/4776 | Loss: 149.968 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 900/4776 | Loss: 132.484 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 910/4776 | Loss: 94.505 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 920/4776 | Loss: 99.227 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 930/4776 | Loss: 102.063 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 940/4776 | Loss: 156.828 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 950/4776 | Loss: 119.483 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 960/4776 | Loss: 77.028 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 970/4776 | Loss: 114.362 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 980/4776 | Loss: 117.662 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 990/4776 | Loss: 122.620 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1000/4776 | Loss: 123.985 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1010/4776 | Loss: 100.220 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1020/4776 | Loss: 113.672 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1030/4776 | Loss: 80.851 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1040/4776 | Loss: 125.441 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1050/4776 | Loss: 141.127 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1060/4776 | Loss: 119.058 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1070/4776 | Loss: 89.374 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 1080/4776 | Loss: 66.127 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1090/4776 | Loss: 110.903 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1100/4776 | Loss: 104.576 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1110/4776 | Loss: 139.147 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1120/4776 | Loss: 138.092 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1130/4776 | Loss: 140.299 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1140/4776 | Loss: 84.369 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1150/4776 | Loss: 119.095 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1160/4776 | Loss: 181.689 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1170/4776 | Loss: 76.713 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 1180/4776 | Loss: 137.186 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1190/4776 | Loss: 119.930 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1200/4776 | Loss: 212.280 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1210/4776 | Loss: 146.834 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1220/4776 | Loss: 110.968 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1230/4776 | Loss: 157.023 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1240/4776 | Loss: 137.288 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1250/4776 | Loss: 81.983 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1260/4776 | Loss: 89.228 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 1270/4776 | Loss: 139.188 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1280/4776 | Loss: 137.214 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1290/4776 | Loss: 134.841 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1300/4776 | Loss: 108.890 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1310/4776 | Loss: 112.611 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1320/4776 | Loss: 94.644 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1330/4776 | Loss: 102.529 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1340/4776 | Loss: 85.543 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1350/4776 | Loss: 76.821 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1360/4776 | Loss: 101.833 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1370/4776 | Loss: 58.109 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1380/4776 | Loss: 169.796 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1390/4776 | Loss: 98.758 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1400/4776 | Loss: 102.783 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 1410/4776 | Loss: 139.933 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1420/4776 | Loss: 96.685 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1430/4776 | Loss: 106.292 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1440/4776 | Loss: 134.407 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1450/4776 | Loss: 98.224 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1460/4776 | Loss: 110.012 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1470/4776 | Loss: 108.486 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1480/4776 | Loss: 97.681 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1490/4776 | Loss: 112.098 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1500/4776 | Loss: 148.942 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1510/4776 | Loss: 122.615 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1520/4776 | Loss: 131.187 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1530/4776 | Loss: 152.673 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1540/4776 | Loss: 120.299 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1550/4776 | Loss: 171.771 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1560/4776 | Loss: 118.992 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1570/4776 | Loss: 201.524 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1580/4776 | Loss: 159.474 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1590/4776 | Loss: 121.480 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1600/4776 | Loss: 110.266 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1610/4776 | Loss: 104.408 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1620/4776 | Loss: 91.102 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1630/4776 | Loss: 113.569 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1640/4776 | Loss: 76.103 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1650/4776 | Loss: 86.259 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1660/4776 | Loss: 116.003 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1670/4776 | Loss: 110.766 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1680/4776 | Loss: 146.006 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1690/4776 | Loss: 117.722 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1700/4776 | Loss: 133.459 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1710/4776 | Loss: 113.981 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1720/4776 | Loss: 91.655 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1730/4776 | Loss: 129.881 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1740/4776 | Loss: 137.722 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1750/4776 | Loss: 62.752 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1760/4776 | Loss: 87.399 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1770/4776 | Loss: 70.172 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1780/4776 | Loss: 128.993 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1790/4776 | Loss: 162.341 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1800/4776 | Loss: 109.410 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1810/4776 | Loss: 122.188 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1820/4776 | Loss: 167.761 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1830/4776 | Loss: 127.626 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1840/4776 | Loss: 118.940 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 1850/4776 | Loss: 118.806 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1860/4776 | Loss: 91.906 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 1870/4776 | Loss: 125.348 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1880/4776 | Loss: 80.358 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1890/4776 | Loss: 198.618 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1900/4776 | Loss: 116.870 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1910/4776 | Loss: 138.713 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1920/4776 | Loss: 149.640 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1930/4776 | Loss: 183.816 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1940/4776 | Loss: 165.940 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 1950/4776 | Loss: 146.123 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1960/4776 | Loss: 180.735 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1970/4776 | Loss: 139.930 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 1980/4776 | Loss: 89.062 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 1990/4776 | Loss: 139.359 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2000/4776 | Loss: 187.836 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2010/4776 | Loss: 102.278 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2020/4776 | Loss: 71.464 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 2030/4776 | Loss: 119.986 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2040/4776 | Loss: 68.640 | Accuracy: 0.900\n",
      "[Epoch: 50/200] - Step: 2050/4776 | Loss: 123.691 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2060/4776 | Loss: 95.346 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2070/4776 | Loss: 94.761 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2080/4776 | Loss: 115.983 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2090/4776 | Loss: 129.954 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2100/4776 | Loss: 106.279 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2110/4776 | Loss: 178.375 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2120/4776 | Loss: 144.717 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2130/4776 | Loss: 191.832 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 2140/4776 | Loss: 132.611 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2150/4776 | Loss: 122.546 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2160/4776 | Loss: 160.870 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2170/4776 | Loss: 120.170 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2180/4776 | Loss: 62.735 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2190/4776 | Loss: 136.209 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2200/4776 | Loss: 116.622 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2210/4776 | Loss: 105.817 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2220/4776 | Loss: 156.883 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2230/4776 | Loss: 103.459 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2240/4776 | Loss: 92.502 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2250/4776 | Loss: 160.811 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2260/4776 | Loss: 74.676 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2270/4776 | Loss: 101.291 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2280/4776 | Loss: 137.507 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2290/4776 | Loss: 147.535 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2300/4776 | Loss: 135.608 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2310/4776 | Loss: 189.097 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2320/4776 | Loss: 110.771 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2330/4776 | Loss: 189.463 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 2340/4776 | Loss: 130.541 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2350/4776 | Loss: 135.152 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2360/4776 | Loss: 97.533 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2370/4776 | Loss: 197.627 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2380/4776 | Loss: 198.055 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2390/4776 | Loss: 148.869 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2400/4776 | Loss: 70.399 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2410/4776 | Loss: 128.186 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2420/4776 | Loss: 120.522 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2430/4776 | Loss: 131.791 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2440/4776 | Loss: 131.603 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2450/4776 | Loss: 176.574 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2460/4776 | Loss: 104.702 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2470/4776 | Loss: 136.498 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2480/4776 | Loss: 83.430 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2490/4776 | Loss: 131.421 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2500/4776 | Loss: 137.815 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2510/4776 | Loss: 115.426 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2520/4776 | Loss: 124.130 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2530/4776 | Loss: 144.339 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2540/4776 | Loss: 137.898 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2550/4776 | Loss: 145.431 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2560/4776 | Loss: 75.929 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2570/4776 | Loss: 83.706 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2580/4776 | Loss: 127.917 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2590/4776 | Loss: 128.938 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2600/4776 | Loss: 99.858 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2610/4776 | Loss: 134.604 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2620/4776 | Loss: 106.054 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2630/4776 | Loss: 119.859 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2640/4776 | Loss: 123.612 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2650/4776 | Loss: 147.345 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2660/4776 | Loss: 173.930 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 2670/4776 | Loss: 131.617 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2680/4776 | Loss: 169.460 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2690/4776 | Loss: 90.923 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2700/4776 | Loss: 79.889 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2710/4776 | Loss: 109.792 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2720/4776 | Loss: 104.273 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2730/4776 | Loss: 124.857 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2740/4776 | Loss: 81.309 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2750/4776 | Loss: 108.182 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2760/4776 | Loss: 133.328 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2770/4776 | Loss: 127.075 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2780/4776 | Loss: 105.107 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2790/4776 | Loss: 175.357 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2800/4776 | Loss: 121.595 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2810/4776 | Loss: 110.210 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2820/4776 | Loss: 130.970 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2830/4776 | Loss: 87.081 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2840/4776 | Loss: 122.240 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2850/4776 | Loss: 101.627 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 2860/4776 | Loss: 73.543 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2870/4776 | Loss: 163.086 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 2880/4776 | Loss: 110.113 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2890/4776 | Loss: 127.954 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2900/4776 | Loss: 79.994 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2910/4776 | Loss: 105.515 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2920/4776 | Loss: 102.329 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2930/4776 | Loss: 105.930 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 2940/4776 | Loss: 105.048 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2950/4776 | Loss: 170.850 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2960/4776 | Loss: 89.184 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 2970/4776 | Loss: 102.470 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 2980/4776 | Loss: 174.990 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 2990/4776 | Loss: 143.644 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3000/4776 | Loss: 101.468 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3010/4776 | Loss: 121.659 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3020/4776 | Loss: 115.173 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3030/4776 | Loss: 110.637 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3040/4776 | Loss: 146.838 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3050/4776 | Loss: 106.498 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3060/4776 | Loss: 147.039 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3070/4776 | Loss: 147.150 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3080/4776 | Loss: 109.789 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3090/4776 | Loss: 111.774 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3100/4776 | Loss: 80.179 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3110/4776 | Loss: 60.150 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3120/4776 | Loss: 158.527 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3130/4776 | Loss: 103.178 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3140/4776 | Loss: 163.605 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 3150/4776 | Loss: 133.699 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3160/4776 | Loss: 116.602 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3170/4776 | Loss: 186.517 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3180/4776 | Loss: 96.862 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3190/4776 | Loss: 125.164 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3200/4776 | Loss: 113.094 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3210/4776 | Loss: 119.343 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3220/4776 | Loss: 142.284 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 3230/4776 | Loss: 182.734 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3240/4776 | Loss: 92.401 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3250/4776 | Loss: 145.141 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3260/4776 | Loss: 130.638 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3270/4776 | Loss: 92.494 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3280/4776 | Loss: 104.223 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3290/4776 | Loss: 98.433 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3300/4776 | Loss: 134.407 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3310/4776 | Loss: 95.963 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3320/4776 | Loss: 104.619 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3330/4776 | Loss: 97.377 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3340/4776 | Loss: 69.327 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3350/4776 | Loss: 126.851 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3360/4776 | Loss: 164.157 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3370/4776 | Loss: 99.870 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3380/4776 | Loss: 120.032 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3390/4776 | Loss: 146.491 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3400/4776 | Loss: 108.690 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3410/4776 | Loss: 163.234 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3420/4776 | Loss: 74.254 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3430/4776 | Loss: 153.474 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3440/4776 | Loss: 173.774 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3450/4776 | Loss: 101.737 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3460/4776 | Loss: 136.519 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3470/4776 | Loss: 149.496 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3480/4776 | Loss: 151.891 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3490/4776 | Loss: 176.815 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3500/4776 | Loss: 131.191 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3510/4776 | Loss: 74.279 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3520/4776 | Loss: 142.775 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3530/4776 | Loss: 113.600 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3540/4776 | Loss: 124.121 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3550/4776 | Loss: 98.032 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3560/4776 | Loss: 135.687 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3570/4776 | Loss: 93.581 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3580/4776 | Loss: 83.392 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3590/4776 | Loss: 178.006 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 3600/4776 | Loss: 142.860 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3610/4776 | Loss: 94.042 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3620/4776 | Loss: 102.878 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3630/4776 | Loss: 128.428 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3640/4776 | Loss: 165.601 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3650/4776 | Loss: 128.686 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3660/4776 | Loss: 126.689 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3670/4776 | Loss: 131.856 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 3680/4776 | Loss: 86.194 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 3690/4776 | Loss: 106.604 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3700/4776 | Loss: 78.907 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3710/4776 | Loss: 264.387 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 3720/4776 | Loss: 125.752 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3730/4776 | Loss: 54.808 | Accuracy: 0.900\n",
      "[Epoch: 50/200] - Step: 3740/4776 | Loss: 168.458 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3750/4776 | Loss: 104.216 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3760/4776 | Loss: 114.110 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3770/4776 | Loss: 94.489 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3780/4776 | Loss: 120.563 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3790/4776 | Loss: 108.727 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3800/4776 | Loss: 146.156 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3810/4776 | Loss: 127.358 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3820/4776 | Loss: 75.160 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3830/4776 | Loss: 101.684 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3840/4776 | Loss: 116.877 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3850/4776 | Loss: 113.485 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3860/4776 | Loss: 125.773 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3870/4776 | Loss: 155.785 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 3880/4776 | Loss: 117.548 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3890/4776 | Loss: 154.131 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3900/4776 | Loss: 104.102 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3910/4776 | Loss: 80.740 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3920/4776 | Loss: 169.399 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3930/4776 | Loss: 108.521 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3940/4776 | Loss: 127.814 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 3950/4776 | Loss: 86.103 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3960/4776 | Loss: 81.882 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 3970/4776 | Loss: 124.796 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 3980/4776 | Loss: 104.268 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 3990/4776 | Loss: 138.497 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4000/4776 | Loss: 148.465 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4010/4776 | Loss: 102.935 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4020/4776 | Loss: 125.451 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4030/4776 | Loss: 112.549 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4040/4776 | Loss: 112.191 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4050/4776 | Loss: 124.935 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4060/4776 | Loss: 148.633 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4070/4776 | Loss: 133.156 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4080/4776 | Loss: 114.196 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4090/4776 | Loss: 162.139 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4100/4776 | Loss: 66.446 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4110/4776 | Loss: 132.103 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4120/4776 | Loss: 203.446 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 4130/4776 | Loss: 154.408 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4140/4776 | Loss: 88.735 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 4150/4776 | Loss: 102.701 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4160/4776 | Loss: 84.563 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4170/4776 | Loss: 144.219 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4180/4776 | Loss: 196.176 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4190/4776 | Loss: 107.838 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4200/4776 | Loss: 211.052 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4210/4776 | Loss: 72.811 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 4220/4776 | Loss: 133.548 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4230/4776 | Loss: 148.589 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4240/4776 | Loss: 69.166 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 4250/4776 | Loss: 99.455 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4260/4776 | Loss: 100.072 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4270/4776 | Loss: 44.064 | Accuracy: 0.900\n",
      "[Epoch: 50/200] - Step: 4280/4776 | Loss: 148.333 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4290/4776 | Loss: 98.454 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4300/4776 | Loss: 129.108 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4310/4776 | Loss: 112.343 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4320/4776 | Loss: 117.335 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4330/4776 | Loss: 118.463 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4340/4776 | Loss: 127.162 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4350/4776 | Loss: 200.365 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4360/4776 | Loss: 137.111 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4370/4776 | Loss: 149.783 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4380/4776 | Loss: 113.529 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4390/4776 | Loss: 124.651 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4400/4776 | Loss: 117.652 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4410/4776 | Loss: 63.355 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 4420/4776 | Loss: 107.775 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4430/4776 | Loss: 113.928 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4440/4776 | Loss: 108.224 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4450/4776 | Loss: 130.220 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4460/4776 | Loss: 118.331 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4470/4776 | Loss: 148.615 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4480/4776 | Loss: 122.720 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4490/4776 | Loss: 150.411 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4500/4776 | Loss: 122.308 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4510/4776 | Loss: 120.229 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4520/4776 | Loss: 125.027 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4530/4776 | Loss: 150.906 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4540/4776 | Loss: 137.683 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4550/4776 | Loss: 128.174 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4560/4776 | Loss: 87.337 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4570/4776 | Loss: 138.014 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 4580/4776 | Loss: 126.289 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4590/4776 | Loss: 107.431 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4600/4776 | Loss: 128.365 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4610/4776 | Loss: 118.795 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4620/4776 | Loss: 115.260 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4630/4776 | Loss: 105.435 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4640/4776 | Loss: 92.316 | Accuracy: 0.800\n",
      "[Epoch: 50/200] - Step: 4650/4776 | Loss: 129.339 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4660/4776 | Loss: 150.188 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4670/4776 | Loss: 118.347 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4680/4776 | Loss: 138.747 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4690/4776 | Loss: 169.489 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4700/4776 | Loss: 112.811 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 4710/4776 | Loss: 144.690 | Accuracy: 0.400\n",
      "[Epoch: 50/200] - Step: 4720/4776 | Loss: 212.349 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 4730/4776 | Loss: 74.232 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4740/4776 | Loss: 156.925 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4750/4776 | Loss: 93.098 | Accuracy: 0.700\n",
      "[Epoch: 50/200] - Step: 4760/4776 | Loss: 113.127 | Accuracy: 0.600\n",
      "[Epoch: 50/200] - Step: 4770/4776 | Loss: 56.886 | Accuracy: 0.800\n",
      "Accuracy:  0.17540983606557378\n",
      "[Epoch: 51/200] - Step: 10/4776 | Loss: 144.602 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 20/4776 | Loss: 89.598 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 30/4776 | Loss: 132.702 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 40/4776 | Loss: 165.236 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 50/4776 | Loss: 116.651 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 60/4776 | Loss: 151.599 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 70/4776 | Loss: 105.304 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 80/4776 | Loss: 154.297 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 90/4776 | Loss: 187.026 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 100/4776 | Loss: 115.985 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 110/4776 | Loss: 95.266 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 120/4776 | Loss: 141.342 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 130/4776 | Loss: 118.582 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 140/4776 | Loss: 167.323 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 150/4776 | Loss: 119.617 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 160/4776 | Loss: 73.863 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 170/4776 | Loss: 228.882 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 180/4776 | Loss: 153.695 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 190/4776 | Loss: 108.386 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 200/4776 | Loss: 146.652 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 210/4776 | Loss: 70.246 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 220/4776 | Loss: 121.236 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 230/4776 | Loss: 119.860 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 240/4776 | Loss: 107.677 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 250/4776 | Loss: 173.652 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 260/4776 | Loss: 131.150 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 270/4776 | Loss: 109.532 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 280/4776 | Loss: 67.842 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 290/4776 | Loss: 93.893 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 300/4776 | Loss: 132.298 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 310/4776 | Loss: 121.276 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 320/4776 | Loss: 169.342 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 330/4776 | Loss: 109.592 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 340/4776 | Loss: 153.337 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 350/4776 | Loss: 114.619 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 360/4776 | Loss: 112.533 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 370/4776 | Loss: 149.971 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 380/4776 | Loss: 151.097 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 390/4776 | Loss: 170.523 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 400/4776 | Loss: 67.741 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 410/4776 | Loss: 75.712 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 420/4776 | Loss: 184.662 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 430/4776 | Loss: 67.279 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 440/4776 | Loss: 85.548 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 450/4776 | Loss: 105.620 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 460/4776 | Loss: 127.072 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 470/4776 | Loss: 66.727 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 480/4776 | Loss: 129.243 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 490/4776 | Loss: 79.659 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 500/4776 | Loss: 81.738 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 510/4776 | Loss: 81.796 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 520/4776 | Loss: 197.627 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 530/4776 | Loss: 130.952 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 540/4776 | Loss: 66.352 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 550/4776 | Loss: 110.387 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 560/4776 | Loss: 147.047 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 570/4776 | Loss: 61.730 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 580/4776 | Loss: 82.794 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 590/4776 | Loss: 116.666 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 600/4776 | Loss: 120.938 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 610/4776 | Loss: 56.888 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 620/4776 | Loss: 114.689 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 630/4776 | Loss: 135.472 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 640/4776 | Loss: 107.962 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 650/4776 | Loss: 166.608 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 660/4776 | Loss: 55.461 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 670/4776 | Loss: 84.689 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 680/4776 | Loss: 59.956 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 690/4776 | Loss: 100.623 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 700/4776 | Loss: 199.880 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 710/4776 | Loss: 168.726 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 720/4776 | Loss: 168.302 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 730/4776 | Loss: 178.229 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 740/4776 | Loss: 171.696 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 750/4776 | Loss: 158.310 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 760/4776 | Loss: 108.489 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 770/4776 | Loss: 101.915 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 780/4776 | Loss: 113.980 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 790/4776 | Loss: 216.394 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 800/4776 | Loss: 174.437 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 810/4776 | Loss: 149.149 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 820/4776 | Loss: 146.365 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 830/4776 | Loss: 68.165 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 840/4776 | Loss: 164.446 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 850/4776 | Loss: 104.406 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 860/4776 | Loss: 122.481 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 870/4776 | Loss: 167.646 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 880/4776 | Loss: 133.638 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 890/4776 | Loss: 105.059 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 900/4776 | Loss: 135.124 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 910/4776 | Loss: 76.507 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 920/4776 | Loss: 128.897 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 930/4776 | Loss: 141.145 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 940/4776 | Loss: 106.843 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 950/4776 | Loss: 150.633 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 960/4776 | Loss: 101.215 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 970/4776 | Loss: 118.722 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 980/4776 | Loss: 139.968 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 990/4776 | Loss: 146.525 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1000/4776 | Loss: 132.890 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1010/4776 | Loss: 87.388 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1020/4776 | Loss: 136.571 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1030/4776 | Loss: 126.745 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1040/4776 | Loss: 87.892 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1050/4776 | Loss: 146.223 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1060/4776 | Loss: 99.825 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1070/4776 | Loss: 136.857 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1080/4776 | Loss: 104.579 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1090/4776 | Loss: 149.540 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1100/4776 | Loss: 96.636 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1110/4776 | Loss: 124.246 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1120/4776 | Loss: 100.890 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1130/4776 | Loss: 150.330 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1140/4776 | Loss: 85.195 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1150/4776 | Loss: 130.373 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1160/4776 | Loss: 127.208 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1170/4776 | Loss: 136.336 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1180/4776 | Loss: 122.530 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1190/4776 | Loss: 161.308 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1200/4776 | Loss: 111.161 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1210/4776 | Loss: 102.865 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1220/4776 | Loss: 128.416 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1230/4776 | Loss: 157.111 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1240/4776 | Loss: 128.374 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1250/4776 | Loss: 166.900 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1260/4776 | Loss: 133.555 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1270/4776 | Loss: 127.356 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1280/4776 | Loss: 153.791 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1290/4776 | Loss: 111.427 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1300/4776 | Loss: 115.031 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1310/4776 | Loss: 110.696 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1320/4776 | Loss: 116.827 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1330/4776 | Loss: 92.860 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1340/4776 | Loss: 112.301 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1350/4776 | Loss: 84.804 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1360/4776 | Loss: 137.486 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1370/4776 | Loss: 125.451 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1380/4776 | Loss: 109.983 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1390/4776 | Loss: 56.657 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 1400/4776 | Loss: 90.961 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1410/4776 | Loss: 55.517 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1420/4776 | Loss: 123.551 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1430/4776 | Loss: 127.964 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1440/4776 | Loss: 120.375 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1450/4776 | Loss: 125.758 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1460/4776 | Loss: 100.182 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1470/4776 | Loss: 111.065 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1480/4776 | Loss: 102.476 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1490/4776 | Loss: 109.186 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1500/4776 | Loss: 79.484 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1510/4776 | Loss: 146.348 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1520/4776 | Loss: 130.377 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1530/4776 | Loss: 111.073 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1540/4776 | Loss: 130.339 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1550/4776 | Loss: 105.276 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1560/4776 | Loss: 64.919 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1570/4776 | Loss: 121.902 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1580/4776 | Loss: 162.986 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1590/4776 | Loss: 91.478 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1600/4776 | Loss: 130.444 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1610/4776 | Loss: 128.327 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1620/4776 | Loss: 135.612 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1630/4776 | Loss: 159.728 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1640/4776 | Loss: 102.956 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1650/4776 | Loss: 173.769 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1660/4776 | Loss: 109.689 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1670/4776 | Loss: 119.838 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1680/4776 | Loss: 93.928 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1690/4776 | Loss: 80.969 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1700/4776 | Loss: 99.792 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1710/4776 | Loss: 77.788 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1720/4776 | Loss: 134.271 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1730/4776 | Loss: 153.241 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1740/4776 | Loss: 129.580 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1750/4776 | Loss: 127.437 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1760/4776 | Loss: 110.570 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1770/4776 | Loss: 90.961 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1780/4776 | Loss: 104.989 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1790/4776 | Loss: 179.472 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1800/4776 | Loss: 135.431 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1810/4776 | Loss: 156.929 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1820/4776 | Loss: 94.892 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1830/4776 | Loss: 143.196 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1840/4776 | Loss: 121.543 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1850/4776 | Loss: 121.193 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1860/4776 | Loss: 98.818 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1870/4776 | Loss: 123.428 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1880/4776 | Loss: 137.317 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 1890/4776 | Loss: 113.237 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1900/4776 | Loss: 87.260 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1910/4776 | Loss: 73.524 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1920/4776 | Loss: 76.863 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 1930/4776 | Loss: 105.513 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1940/4776 | Loss: 92.472 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 1950/4776 | Loss: 119.789 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 1960/4776 | Loss: 137.293 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1970/4776 | Loss: 145.369 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 1980/4776 | Loss: 61.443 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 1990/4776 | Loss: 106.793 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2000/4776 | Loss: 99.869 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2010/4776 | Loss: 126.223 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2020/4776 | Loss: 97.637 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2030/4776 | Loss: 116.776 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2040/4776 | Loss: 142.734 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2050/4776 | Loss: 141.481 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2060/4776 | Loss: 180.739 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2070/4776 | Loss: 103.757 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2080/4776 | Loss: 127.974 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2090/4776 | Loss: 204.055 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 2100/4776 | Loss: 78.217 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2110/4776 | Loss: 98.041 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2120/4776 | Loss: 74.499 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2130/4776 | Loss: 115.541 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2140/4776 | Loss: 63.639 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2150/4776 | Loss: 135.862 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2160/4776 | Loss: 124.286 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2170/4776 | Loss: 173.534 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2180/4776 | Loss: 90.651 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2190/4776 | Loss: 113.925 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2200/4776 | Loss: 100.196 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2210/4776 | Loss: 120.009 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2220/4776 | Loss: 120.298 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2230/4776 | Loss: 99.432 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2240/4776 | Loss: 127.769 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2250/4776 | Loss: 125.774 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2260/4776 | Loss: 76.556 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2270/4776 | Loss: 81.955 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2280/4776 | Loss: 103.111 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2290/4776 | Loss: 121.553 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2300/4776 | Loss: 133.232 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2310/4776 | Loss: 116.950 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2320/4776 | Loss: 95.514 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2330/4776 | Loss: 99.999 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2340/4776 | Loss: 93.381 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2350/4776 | Loss: 83.830 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2360/4776 | Loss: 84.734 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2370/4776 | Loss: 116.579 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2380/4776 | Loss: 172.237 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 2390/4776 | Loss: 125.441 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2400/4776 | Loss: 79.911 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2410/4776 | Loss: 102.069 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2420/4776 | Loss: 86.928 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2430/4776 | Loss: 81.348 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2440/4776 | Loss: 122.850 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2450/4776 | Loss: 108.829 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2460/4776 | Loss: 110.347 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2470/4776 | Loss: 158.775 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 2480/4776 | Loss: 116.188 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2490/4776 | Loss: 124.055 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2500/4776 | Loss: 98.239 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2510/4776 | Loss: 124.224 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2520/4776 | Loss: 112.892 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2530/4776 | Loss: 123.488 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2540/4776 | Loss: 180.567 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2550/4776 | Loss: 143.846 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2560/4776 | Loss: 81.802 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2570/4776 | Loss: 105.762 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2580/4776 | Loss: 124.758 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2590/4776 | Loss: 159.720 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 2600/4776 | Loss: 37.342 | Accuracy: 1.000\n",
      "[Epoch: 51/200] - Step: 2610/4776 | Loss: 116.171 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2620/4776 | Loss: 193.818 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 2630/4776 | Loss: 171.082 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2640/4776 | Loss: 74.275 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2650/4776 | Loss: 112.813 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2660/4776 | Loss: 102.794 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2670/4776 | Loss: 133.723 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2680/4776 | Loss: 127.810 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2690/4776 | Loss: 78.231 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2700/4776 | Loss: 107.178 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2710/4776 | Loss: 133.194 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2720/4776 | Loss: 111.828 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2730/4776 | Loss: 122.922 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2740/4776 | Loss: 109.768 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2750/4776 | Loss: 57.892 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2760/4776 | Loss: 168.565 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2770/4776 | Loss: 142.147 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2780/4776 | Loss: 108.136 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2790/4776 | Loss: 134.243 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2800/4776 | Loss: 100.771 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2810/4776 | Loss: 72.021 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2820/4776 | Loss: 158.033 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2830/4776 | Loss: 102.767 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2840/4776 | Loss: 129.654 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 2850/4776 | Loss: 138.171 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2860/4776 | Loss: 68.095 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 2870/4776 | Loss: 163.497 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2880/4776 | Loss: 121.241 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2890/4776 | Loss: 89.946 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2900/4776 | Loss: 140.231 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2910/4776 | Loss: 131.439 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2920/4776 | Loss: 161.425 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2930/4776 | Loss: 122.975 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2940/4776 | Loss: 146.138 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 2950/4776 | Loss: 110.759 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2960/4776 | Loss: 119.049 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 2970/4776 | Loss: 108.603 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 2980/4776 | Loss: 91.983 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 2990/4776 | Loss: 144.501 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3000/4776 | Loss: 145.346 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3010/4776 | Loss: 121.384 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3020/4776 | Loss: 166.600 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3030/4776 | Loss: 154.764 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 3040/4776 | Loss: 146.902 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3050/4776 | Loss: 137.226 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3060/4776 | Loss: 91.128 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3070/4776 | Loss: 136.492 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3080/4776 | Loss: 118.451 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3090/4776 | Loss: 116.030 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3100/4776 | Loss: 100.902 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3110/4776 | Loss: 138.299 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3120/4776 | Loss: 138.377 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3130/4776 | Loss: 100.815 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3140/4776 | Loss: 202.882 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3150/4776 | Loss: 98.639 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3160/4776 | Loss: 134.304 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3170/4776 | Loss: 108.948 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3180/4776 | Loss: 111.907 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3190/4776 | Loss: 114.547 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3200/4776 | Loss: 101.400 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3210/4776 | Loss: 135.214 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3220/4776 | Loss: 106.385 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3230/4776 | Loss: 183.498 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3240/4776 | Loss: 80.746 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 3250/4776 | Loss: 142.348 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3260/4776 | Loss: 90.041 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3270/4776 | Loss: 132.967 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3280/4776 | Loss: 113.808 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3290/4776 | Loss: 119.427 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3300/4776 | Loss: 77.531 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3310/4776 | Loss: 170.124 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 3320/4776 | Loss: 149.984 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 3330/4776 | Loss: 53.124 | Accuracy: 0.900\n",
      "[Epoch: 51/200] - Step: 3340/4776 | Loss: 131.089 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3350/4776 | Loss: 82.850 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3360/4776 | Loss: 113.787 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3370/4776 | Loss: 176.313 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3380/4776 | Loss: 161.480 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 3390/4776 | Loss: 129.064 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3400/4776 | Loss: 147.347 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3410/4776 | Loss: 89.503 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3420/4776 | Loss: 83.821 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3430/4776 | Loss: 144.877 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3440/4776 | Loss: 143.722 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3450/4776 | Loss: 107.364 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3460/4776 | Loss: 73.377 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3470/4776 | Loss: 107.853 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3480/4776 | Loss: 102.114 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3490/4776 | Loss: 165.802 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 3500/4776 | Loss: 87.945 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3510/4776 | Loss: 107.028 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3520/4776 | Loss: 74.707 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3530/4776 | Loss: 147.304 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3540/4776 | Loss: 109.302 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3550/4776 | Loss: 140.210 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3560/4776 | Loss: 128.036 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3570/4776 | Loss: 87.758 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3580/4776 | Loss: 85.922 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 3590/4776 | Loss: 100.400 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3600/4776 | Loss: 107.513 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3610/4776 | Loss: 96.085 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3620/4776 | Loss: 94.251 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3630/4776 | Loss: 154.893 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3640/4776 | Loss: 105.705 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3650/4776 | Loss: 124.292 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3660/4776 | Loss: 105.281 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3670/4776 | Loss: 120.088 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3680/4776 | Loss: 133.388 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3690/4776 | Loss: 110.691 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3700/4776 | Loss: 94.019 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3710/4776 | Loss: 132.250 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3720/4776 | Loss: 80.514 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3730/4776 | Loss: 166.962 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3740/4776 | Loss: 82.970 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 3750/4776 | Loss: 169.271 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3760/4776 | Loss: 80.812 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3770/4776 | Loss: 86.541 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 3780/4776 | Loss: 111.695 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3790/4776 | Loss: 123.969 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3800/4776 | Loss: 113.913 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3810/4776 | Loss: 90.995 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3820/4776 | Loss: 121.309 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3830/4776 | Loss: 72.849 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3840/4776 | Loss: 148.593 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3850/4776 | Loss: 109.949 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3860/4776 | Loss: 132.049 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3870/4776 | Loss: 138.449 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3880/4776 | Loss: 103.052 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3890/4776 | Loss: 73.312 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 3900/4776 | Loss: 113.670 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3910/4776 | Loss: 79.942 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3920/4776 | Loss: 96.053 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 3930/4776 | Loss: 108.752 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3940/4776 | Loss: 120.294 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3950/4776 | Loss: 130.412 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 3960/4776 | Loss: 125.459 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 3970/4776 | Loss: 158.541 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 3980/4776 | Loss: 122.150 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 3990/4776 | Loss: 99.879 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4000/4776 | Loss: 133.644 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4010/4776 | Loss: 100.214 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4020/4776 | Loss: 99.302 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4030/4776 | Loss: 105.613 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 4040/4776 | Loss: 116.440 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4050/4776 | Loss: 104.512 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4060/4776 | Loss: 135.969 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4070/4776 | Loss: 159.852 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4080/4776 | Loss: 136.995 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4090/4776 | Loss: 94.807 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4100/4776 | Loss: 111.419 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4110/4776 | Loss: 85.839 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4120/4776 | Loss: 135.891 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4130/4776 | Loss: 130.253 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4140/4776 | Loss: 129.999 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4150/4776 | Loss: 147.691 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4160/4776 | Loss: 199.299 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4170/4776 | Loss: 203.430 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4180/4776 | Loss: 195.324 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 4190/4776 | Loss: 194.127 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4200/4776 | Loss: 145.320 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4210/4776 | Loss: 154.325 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4220/4776 | Loss: 135.429 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4230/4776 | Loss: 115.427 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4240/4776 | Loss: 123.626 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4250/4776 | Loss: 102.282 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4260/4776 | Loss: 125.182 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4270/4776 | Loss: 172.277 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4280/4776 | Loss: 165.308 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4290/4776 | Loss: 126.731 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4300/4776 | Loss: 133.059 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4310/4776 | Loss: 106.483 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4320/4776 | Loss: 199.807 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4330/4776 | Loss: 111.071 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4340/4776 | Loss: 126.429 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4350/4776 | Loss: 142.154 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4360/4776 | Loss: 87.534 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 4370/4776 | Loss: 121.235 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4380/4776 | Loss: 104.166 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4390/4776 | Loss: 111.877 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4400/4776 | Loss: 165.428 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4410/4776 | Loss: 95.808 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4420/4776 | Loss: 101.661 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4430/4776 | Loss: 163.876 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4440/4776 | Loss: 124.118 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4450/4776 | Loss: 201.909 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4460/4776 | Loss: 189.772 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4470/4776 | Loss: 135.223 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4480/4776 | Loss: 95.610 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4490/4776 | Loss: 124.350 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4500/4776 | Loss: 84.077 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 4510/4776 | Loss: 75.715 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4520/4776 | Loss: 142.385 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4530/4776 | Loss: 155.128 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4540/4776 | Loss: 165.200 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4550/4776 | Loss: 86.045 | Accuracy: 0.800\n",
      "[Epoch: 51/200] - Step: 4560/4776 | Loss: 133.027 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4570/4776 | Loss: 86.380 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4580/4776 | Loss: 158.393 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4590/4776 | Loss: 179.673 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 4600/4776 | Loss: 115.151 | Accuracy: 0.600\n",
      "[Epoch: 51/200] - Step: 4610/4776 | Loss: 147.414 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4620/4776 | Loss: 117.972 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4630/4776 | Loss: 210.904 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 4640/4776 | Loss: 211.231 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4650/4776 | Loss: 170.913 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4660/4776 | Loss: 96.204 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4670/4776 | Loss: 141.470 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 4680/4776 | Loss: 79.496 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4690/4776 | Loss: 137.722 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4700/4776 | Loss: 110.330 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4710/4776 | Loss: 147.487 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4720/4776 | Loss: 105.024 | Accuracy: 0.700\n",
      "[Epoch: 51/200] - Step: 4730/4776 | Loss: 137.047 | Accuracy: 0.400\n",
      "[Epoch: 51/200] - Step: 4740/4776 | Loss: 123.670 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4750/4776 | Loss: 141.878 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4760/4776 | Loss: 151.926 | Accuracy: 0.500\n",
      "[Epoch: 51/200] - Step: 4770/4776 | Loss: 105.857 | Accuracy: 0.600\n",
      "Accuracy:  0.2098360655737705\n",
      "[Epoch: 52/200] - Step: 10/4776 | Loss: 145.848 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 20/4776 | Loss: 93.502 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 30/4776 | Loss: 118.298 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 40/4776 | Loss: 135.429 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 50/4776 | Loss: 205.134 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 60/4776 | Loss: 155.221 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 70/4776 | Loss: 106.916 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 80/4776 | Loss: 102.757 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 90/4776 | Loss: 149.137 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 100/4776 | Loss: 114.727 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 110/4776 | Loss: 113.002 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 120/4776 | Loss: 72.853 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 130/4776 | Loss: 122.211 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 140/4776 | Loss: 149.260 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 150/4776 | Loss: 132.472 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 160/4776 | Loss: 148.474 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 170/4776 | Loss: 118.656 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 180/4776 | Loss: 125.962 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 190/4776 | Loss: 121.306 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 200/4776 | Loss: 142.077 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 210/4776 | Loss: 87.163 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 220/4776 | Loss: 90.102 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 230/4776 | Loss: 96.345 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 240/4776 | Loss: 76.485 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 250/4776 | Loss: 99.934 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 260/4776 | Loss: 139.934 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 270/4776 | Loss: 120.672 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 280/4776 | Loss: 126.707 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 290/4776 | Loss: 118.020 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 300/4776 | Loss: 113.104 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 310/4776 | Loss: 93.830 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 320/4776 | Loss: 123.695 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 330/4776 | Loss: 119.605 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 340/4776 | Loss: 67.573 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 350/4776 | Loss: 95.524 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 360/4776 | Loss: 117.282 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 370/4776 | Loss: 105.428 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 380/4776 | Loss: 175.806 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 390/4776 | Loss: 117.465 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 400/4776 | Loss: 145.190 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 410/4776 | Loss: 142.391 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 420/4776 | Loss: 70.816 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 430/4776 | Loss: 185.989 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 440/4776 | Loss: 143.281 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 450/4776 | Loss: 81.804 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 460/4776 | Loss: 108.515 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 470/4776 | Loss: 103.125 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 480/4776 | Loss: 74.255 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 490/4776 | Loss: 98.505 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 500/4776 | Loss: 92.551 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 510/4776 | Loss: 145.484 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 520/4776 | Loss: 67.891 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 530/4776 | Loss: 126.410 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 540/4776 | Loss: 107.599 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 550/4776 | Loss: 54.894 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 560/4776 | Loss: 91.647 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 570/4776 | Loss: 70.055 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 580/4776 | Loss: 103.007 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 590/4776 | Loss: 115.615 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 600/4776 | Loss: 82.291 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 610/4776 | Loss: 97.434 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 620/4776 | Loss: 102.705 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 630/4776 | Loss: 153.180 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 640/4776 | Loss: 102.013 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 650/4776 | Loss: 178.300 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 660/4776 | Loss: 134.604 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 670/4776 | Loss: 95.693 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 680/4776 | Loss: 177.504 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 690/4776 | Loss: 102.921 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 700/4776 | Loss: 136.170 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 710/4776 | Loss: 141.770 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 720/4776 | Loss: 155.694 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 730/4776 | Loss: 94.726 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 740/4776 | Loss: 88.278 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 750/4776 | Loss: 54.887 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 760/4776 | Loss: 87.861 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 770/4776 | Loss: 135.279 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 780/4776 | Loss: 89.364 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 790/4776 | Loss: 158.581 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 800/4776 | Loss: 79.257 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 810/4776 | Loss: 95.158 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 820/4776 | Loss: 132.139 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 830/4776 | Loss: 113.036 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 840/4776 | Loss: 60.650 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 850/4776 | Loss: 98.168 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 860/4776 | Loss: 128.333 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 870/4776 | Loss: 50.318 | Accuracy: 1.000\n",
      "[Epoch: 52/200] - Step: 880/4776 | Loss: 81.137 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 890/4776 | Loss: 109.413 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 900/4776 | Loss: 88.974 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 910/4776 | Loss: 95.226 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 920/4776 | Loss: 86.279 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 930/4776 | Loss: 90.169 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 940/4776 | Loss: 146.158 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 950/4776 | Loss: 104.346 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 960/4776 | Loss: 51.970 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 970/4776 | Loss: 189.625 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 980/4776 | Loss: 143.263 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 990/4776 | Loss: 101.673 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1000/4776 | Loss: 120.068 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1010/4776 | Loss: 100.045 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1020/4776 | Loss: 116.495 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1030/4776 | Loss: 107.063 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1040/4776 | Loss: 124.891 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1050/4776 | Loss: 171.899 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1060/4776 | Loss: 157.927 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1070/4776 | Loss: 107.474 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1080/4776 | Loss: 85.961 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1090/4776 | Loss: 93.842 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1100/4776 | Loss: 124.805 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1110/4776 | Loss: 130.093 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1120/4776 | Loss: 151.571 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1130/4776 | Loss: 118.322 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1140/4776 | Loss: 123.221 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1150/4776 | Loss: 98.258 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1160/4776 | Loss: 126.004 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1170/4776 | Loss: 144.859 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1180/4776 | Loss: 81.027 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1190/4776 | Loss: 86.069 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1200/4776 | Loss: 82.649 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1210/4776 | Loss: 160.812 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1220/4776 | Loss: 101.800 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1230/4776 | Loss: 119.283 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1240/4776 | Loss: 76.417 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1250/4776 | Loss: 84.077 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1260/4776 | Loss: 108.351 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1270/4776 | Loss: 119.140 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1280/4776 | Loss: 120.093 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1290/4776 | Loss: 160.037 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1300/4776 | Loss: 73.101 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1310/4776 | Loss: 106.952 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1320/4776 | Loss: 74.276 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1330/4776 | Loss: 70.458 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1340/4776 | Loss: 108.226 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1350/4776 | Loss: 101.827 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1360/4776 | Loss: 123.432 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1370/4776 | Loss: 102.327 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1380/4776 | Loss: 50.690 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1390/4776 | Loss: 151.000 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1400/4776 | Loss: 104.406 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1410/4776 | Loss: 112.012 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1420/4776 | Loss: 93.676 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1430/4776 | Loss: 92.769 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1440/4776 | Loss: 114.038 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1450/4776 | Loss: 122.433 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1460/4776 | Loss: 183.605 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1470/4776 | Loss: 97.013 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1480/4776 | Loss: 113.061 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1490/4776 | Loss: 70.682 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1500/4776 | Loss: 134.932 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1510/4776 | Loss: 141.506 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1520/4776 | Loss: 138.122 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1530/4776 | Loss: 184.735 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1540/4776 | Loss: 92.033 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1550/4776 | Loss: 125.548 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1560/4776 | Loss: 169.957 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1570/4776 | Loss: 134.501 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1580/4776 | Loss: 125.719 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1590/4776 | Loss: 97.505 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1600/4776 | Loss: 132.759 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1610/4776 | Loss: 147.732 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1620/4776 | Loss: 174.218 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1630/4776 | Loss: 119.176 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1640/4776 | Loss: 170.582 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1650/4776 | Loss: 93.502 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1660/4776 | Loss: 65.976 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 1670/4776 | Loss: 146.825 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1680/4776 | Loss: 115.698 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1690/4776 | Loss: 90.042 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1700/4776 | Loss: 121.914 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1710/4776 | Loss: 182.732 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1720/4776 | Loss: 125.089 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1730/4776 | Loss: 136.701 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1740/4776 | Loss: 156.050 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1750/4776 | Loss: 111.485 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1760/4776 | Loss: 64.089 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1770/4776 | Loss: 175.823 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1780/4776 | Loss: 84.542 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1790/4776 | Loss: 46.102 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 1800/4776 | Loss: 150.552 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1810/4776 | Loss: 111.016 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1820/4776 | Loss: 88.641 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1830/4776 | Loss: 91.286 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1840/4776 | Loss: 111.445 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1850/4776 | Loss: 141.605 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1860/4776 | Loss: 68.195 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1870/4776 | Loss: 123.204 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1880/4776 | Loss: 154.505 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1890/4776 | Loss: 142.754 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1900/4776 | Loss: 113.598 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1910/4776 | Loss: 117.865 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 1920/4776 | Loss: 123.073 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 1930/4776 | Loss: 105.246 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1940/4776 | Loss: 126.856 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1950/4776 | Loss: 78.159 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1960/4776 | Loss: 76.171 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 1970/4776 | Loss: 113.973 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 1980/4776 | Loss: 71.356 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 1990/4776 | Loss: 75.077 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2000/4776 | Loss: 138.044 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2010/4776 | Loss: 94.755 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2020/4776 | Loss: 129.417 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2030/4776 | Loss: 125.231 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2040/4776 | Loss: 70.962 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2050/4776 | Loss: 86.736 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2060/4776 | Loss: 122.549 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2070/4776 | Loss: 128.516 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2080/4776 | Loss: 167.695 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 2090/4776 | Loss: 119.209 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2100/4776 | Loss: 112.417 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2110/4776 | Loss: 124.104 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2120/4776 | Loss: 74.134 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2130/4776 | Loss: 169.670 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2140/4776 | Loss: 85.603 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2150/4776 | Loss: 172.673 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2160/4776 | Loss: 136.506 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2170/4776 | Loss: 114.421 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2180/4776 | Loss: 130.984 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2190/4776 | Loss: 102.607 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2200/4776 | Loss: 109.476 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2210/4776 | Loss: 123.904 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2220/4776 | Loss: 122.526 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2230/4776 | Loss: 142.529 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2240/4776 | Loss: 121.463 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2250/4776 | Loss: 149.349 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2260/4776 | Loss: 94.029 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2270/4776 | Loss: 122.418 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2280/4776 | Loss: 124.263 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2290/4776 | Loss: 68.865 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2300/4776 | Loss: 107.751 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2310/4776 | Loss: 144.373 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2320/4776 | Loss: 201.968 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2330/4776 | Loss: 99.157 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2340/4776 | Loss: 132.229 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2350/4776 | Loss: 134.053 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2360/4776 | Loss: 137.536 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2370/4776 | Loss: 106.991 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2380/4776 | Loss: 197.011 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2390/4776 | Loss: 71.222 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2400/4776 | Loss: 132.056 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2410/4776 | Loss: 172.607 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2420/4776 | Loss: 150.004 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2430/4776 | Loss: 89.657 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2440/4776 | Loss: 192.621 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2450/4776 | Loss: 80.717 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2460/4776 | Loss: 104.190 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2470/4776 | Loss: 140.191 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2480/4776 | Loss: 126.047 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2490/4776 | Loss: 144.685 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2500/4776 | Loss: 115.095 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2510/4776 | Loss: 112.400 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2520/4776 | Loss: 113.009 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2530/4776 | Loss: 121.043 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2540/4776 | Loss: 136.536 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2550/4776 | Loss: 60.191 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2560/4776 | Loss: 152.382 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2570/4776 | Loss: 121.352 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2580/4776 | Loss: 105.079 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2590/4776 | Loss: 130.669 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2600/4776 | Loss: 134.206 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2610/4776 | Loss: 109.323 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2620/4776 | Loss: 121.041 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2630/4776 | Loss: 129.002 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2640/4776 | Loss: 77.239 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2650/4776 | Loss: 123.035 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2660/4776 | Loss: 69.041 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2670/4776 | Loss: 80.831 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2680/4776 | Loss: 103.896 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2690/4776 | Loss: 161.270 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2700/4776 | Loss: 89.245 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2710/4776 | Loss: 164.405 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2720/4776 | Loss: 169.964 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 2730/4776 | Loss: 146.619 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 2740/4776 | Loss: 152.960 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2750/4776 | Loss: 94.623 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2760/4776 | Loss: 80.758 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2770/4776 | Loss: 73.213 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2780/4776 | Loss: 121.383 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2790/4776 | Loss: 127.978 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2800/4776 | Loss: 114.905 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2810/4776 | Loss: 117.830 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2820/4776 | Loss: 160.490 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2830/4776 | Loss: 194.634 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 2840/4776 | Loss: 153.864 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2850/4776 | Loss: 163.159 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2860/4776 | Loss: 107.098 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2870/4776 | Loss: 136.372 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2880/4776 | Loss: 154.746 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2890/4776 | Loss: 146.662 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 2900/4776 | Loss: 122.284 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2910/4776 | Loss: 158.956 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2920/4776 | Loss: 118.697 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 2930/4776 | Loss: 105.671 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 2940/4776 | Loss: 139.758 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 2950/4776 | Loss: 78.933 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 2960/4776 | Loss: 111.391 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2970/4776 | Loss: 103.684 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2980/4776 | Loss: 102.052 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 2990/4776 | Loss: 107.654 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3000/4776 | Loss: 78.745 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3010/4776 | Loss: 117.699 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3020/4776 | Loss: 141.510 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3030/4776 | Loss: 177.688 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3040/4776 | Loss: 132.665 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3050/4776 | Loss: 148.310 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3060/4776 | Loss: 112.616 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3070/4776 | Loss: 102.114 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3080/4776 | Loss: 113.296 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3090/4776 | Loss: 138.878 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3100/4776 | Loss: 106.467 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3110/4776 | Loss: 107.211 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3120/4776 | Loss: 120.066 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3130/4776 | Loss: 125.723 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3140/4776 | Loss: 93.084 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3150/4776 | Loss: 190.110 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3160/4776 | Loss: 128.486 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3170/4776 | Loss: 141.676 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3180/4776 | Loss: 112.486 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3190/4776 | Loss: 101.132 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3200/4776 | Loss: 98.836 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3210/4776 | Loss: 92.866 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3220/4776 | Loss: 74.155 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3230/4776 | Loss: 88.585 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3240/4776 | Loss: 80.834 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3250/4776 | Loss: 144.186 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3260/4776 | Loss: 159.543 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3270/4776 | Loss: 132.494 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3280/4776 | Loss: 99.160 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3290/4776 | Loss: 112.178 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3300/4776 | Loss: 120.378 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3310/4776 | Loss: 136.976 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3320/4776 | Loss: 98.098 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3330/4776 | Loss: 111.590 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3340/4776 | Loss: 75.885 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3350/4776 | Loss: 71.020 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3360/4776 | Loss: 128.664 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3370/4776 | Loss: 126.360 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3380/4776 | Loss: 114.445 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3390/4776 | Loss: 147.989 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3400/4776 | Loss: 97.853 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3410/4776 | Loss: 89.574 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3420/4776 | Loss: 96.854 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3430/4776 | Loss: 179.170 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3440/4776 | Loss: 82.607 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3450/4776 | Loss: 120.835 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3460/4776 | Loss: 141.088 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3470/4776 | Loss: 113.178 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3480/4776 | Loss: 104.407 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3490/4776 | Loss: 116.572 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3500/4776 | Loss: 160.387 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3510/4776 | Loss: 154.238 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3520/4776 | Loss: 80.850 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3530/4776 | Loss: 116.678 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3540/4776 | Loss: 110.303 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3550/4776 | Loss: 84.807 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3560/4776 | Loss: 94.484 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3570/4776 | Loss: 112.806 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3580/4776 | Loss: 107.332 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3590/4776 | Loss: 141.423 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3600/4776 | Loss: 138.868 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3610/4776 | Loss: 90.194 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3620/4776 | Loss: 112.437 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3630/4776 | Loss: 112.490 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3640/4776 | Loss: 142.998 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3650/4776 | Loss: 104.745 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3660/4776 | Loss: 126.570 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3670/4776 | Loss: 107.523 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3680/4776 | Loss: 111.107 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3690/4776 | Loss: 166.492 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 3700/4776 | Loss: 105.261 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3710/4776 | Loss: 107.690 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3720/4776 | Loss: 95.877 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3730/4776 | Loss: 116.951 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3740/4776 | Loss: 109.334 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3750/4776 | Loss: 148.710 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3760/4776 | Loss: 120.467 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3770/4776 | Loss: 148.843 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3780/4776 | Loss: 125.760 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 3790/4776 | Loss: 87.207 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3800/4776 | Loss: 103.943 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3810/4776 | Loss: 114.916 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3820/4776 | Loss: 100.251 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3830/4776 | Loss: 153.367 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3840/4776 | Loss: 100.286 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3850/4776 | Loss: 130.379 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3860/4776 | Loss: 169.469 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3870/4776 | Loss: 171.294 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3880/4776 | Loss: 95.254 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3890/4776 | Loss: 120.923 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3900/4776 | Loss: 116.934 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3910/4776 | Loss: 92.085 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3920/4776 | Loss: 77.532 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 3930/4776 | Loss: 152.147 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 3940/4776 | Loss: 114.488 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 3950/4776 | Loss: 144.016 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3960/4776 | Loss: 120.456 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 3970/4776 | Loss: 85.920 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 3980/4776 | Loss: 159.398 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 3990/4776 | Loss: 114.683 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4000/4776 | Loss: 133.565 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4010/4776 | Loss: 82.592 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4020/4776 | Loss: 130.643 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4030/4776 | Loss: 89.145 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4040/4776 | Loss: 86.671 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4050/4776 | Loss: 133.234 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4060/4776 | Loss: 86.391 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4070/4776 | Loss: 137.006 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4080/4776 | Loss: 149.894 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4090/4776 | Loss: 123.910 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4100/4776 | Loss: 160.304 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4110/4776 | Loss: 137.812 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4120/4776 | Loss: 92.259 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4130/4776 | Loss: 67.350 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4140/4776 | Loss: 177.361 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4150/4776 | Loss: 101.205 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4160/4776 | Loss: 211.882 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4170/4776 | Loss: 127.984 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4180/4776 | Loss: 75.597 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 4190/4776 | Loss: 86.561 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4200/4776 | Loss: 42.001 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 4210/4776 | Loss: 148.699 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4220/4776 | Loss: 120.069 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4230/4776 | Loss: 136.631 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4240/4776 | Loss: 157.430 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4250/4776 | Loss: 121.423 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4260/4776 | Loss: 162.061 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4270/4776 | Loss: 88.315 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4280/4776 | Loss: 110.234 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4290/4776 | Loss: 135.394 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4300/4776 | Loss: 240.510 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4310/4776 | Loss: 137.700 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4320/4776 | Loss: 112.344 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4330/4776 | Loss: 154.755 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4340/4776 | Loss: 184.755 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4350/4776 | Loss: 119.727 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4360/4776 | Loss: 139.638 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4370/4776 | Loss: 111.420 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4380/4776 | Loss: 113.860 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4390/4776 | Loss: 131.159 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4400/4776 | Loss: 109.469 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4410/4776 | Loss: 126.504 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4420/4776 | Loss: 143.433 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4430/4776 | Loss: 175.427 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4440/4776 | Loss: 95.939 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4450/4776 | Loss: 64.379 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4460/4776 | Loss: 163.668 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4470/4776 | Loss: 92.966 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4480/4776 | Loss: 78.762 | Accuracy: 0.900\n",
      "[Epoch: 52/200] - Step: 4490/4776 | Loss: 117.945 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4500/4776 | Loss: 108.229 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4510/4776 | Loss: 133.324 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4520/4776 | Loss: 118.605 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4530/4776 | Loss: 145.621 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4540/4776 | Loss: 124.308 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4550/4776 | Loss: 93.652 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4560/4776 | Loss: 99.638 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4570/4776 | Loss: 106.429 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4580/4776 | Loss: 163.304 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4590/4776 | Loss: 182.776 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 4600/4776 | Loss: 105.258 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4610/4776 | Loss: 90.630 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4620/4776 | Loss: 102.850 | Accuracy: 0.800\n",
      "[Epoch: 52/200] - Step: 4630/4776 | Loss: 136.124 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4640/4776 | Loss: 136.407 | Accuracy: 0.700\n",
      "[Epoch: 52/200] - Step: 4650/4776 | Loss: 155.575 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4660/4776 | Loss: 134.550 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4670/4776 | Loss: 160.371 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4680/4776 | Loss: 193.409 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 4690/4776 | Loss: 111.020 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4700/4776 | Loss: 115.823 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 4710/4776 | Loss: 120.428 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4720/4776 | Loss: 199.706 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4730/4776 | Loss: 115.916 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4740/4776 | Loss: 152.487 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4750/4776 | Loss: 122.735 | Accuracy: 0.600\n",
      "[Epoch: 52/200] - Step: 4760/4776 | Loss: 115.640 | Accuracy: 0.500\n",
      "[Epoch: 52/200] - Step: 4770/4776 | Loss: 61.667 | Accuracy: 0.700\n",
      "Accuracy:  0.20327868852459016\n",
      "[Epoch: 53/200] - Step: 10/4776 | Loss: 131.831 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 20/4776 | Loss: 89.454 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 30/4776 | Loss: 52.981 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 40/4776 | Loss: 117.234 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 50/4776 | Loss: 83.933 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 60/4776 | Loss: 83.426 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 70/4776 | Loss: 151.150 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 80/4776 | Loss: 99.543 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 90/4776 | Loss: 112.835 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 100/4776 | Loss: 188.210 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 110/4776 | Loss: 147.663 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 120/4776 | Loss: 142.980 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 130/4776 | Loss: 88.266 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 140/4776 | Loss: 80.746 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 150/4776 | Loss: 114.063 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 160/4776 | Loss: 87.655 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 170/4776 | Loss: 129.920 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 180/4776 | Loss: 109.084 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 190/4776 | Loss: 112.679 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 200/4776 | Loss: 169.217 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 210/4776 | Loss: 125.142 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 220/4776 | Loss: 79.806 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 230/4776 | Loss: 89.354 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 240/4776 | Loss: 105.678 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 250/4776 | Loss: 51.230 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 260/4776 | Loss: 176.989 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 270/4776 | Loss: 113.555 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 280/4776 | Loss: 131.296 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 290/4776 | Loss: 134.048 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 300/4776 | Loss: 169.912 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 310/4776 | Loss: 120.673 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 320/4776 | Loss: 61.606 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 330/4776 | Loss: 118.446 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 340/4776 | Loss: 97.298 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 350/4776 | Loss: 134.642 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 360/4776 | Loss: 130.053 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 370/4776 | Loss: 80.157 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 380/4776 | Loss: 58.354 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 390/4776 | Loss: 106.095 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 400/4776 | Loss: 112.877 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 410/4776 | Loss: 153.069 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 420/4776 | Loss: 87.429 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 430/4776 | Loss: 105.434 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 440/4776 | Loss: 84.579 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 450/4776 | Loss: 108.889 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 460/4776 | Loss: 99.962 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 470/4776 | Loss: 175.569 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 480/4776 | Loss: 88.147 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 490/4776 | Loss: 151.486 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 500/4776 | Loss: 99.527 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 510/4776 | Loss: 111.275 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 520/4776 | Loss: 111.230 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 530/4776 | Loss: 139.397 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 540/4776 | Loss: 143.318 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 550/4776 | Loss: 146.665 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 560/4776 | Loss: 142.832 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 570/4776 | Loss: 118.338 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 580/4776 | Loss: 121.099 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 590/4776 | Loss: 136.150 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 600/4776 | Loss: 99.345 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 610/4776 | Loss: 177.527 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 620/4776 | Loss: 108.954 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 630/4776 | Loss: 105.027 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 640/4776 | Loss: 143.268 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 650/4776 | Loss: 120.121 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 660/4776 | Loss: 56.087 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 670/4776 | Loss: 108.559 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 680/4776 | Loss: 85.995 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 690/4776 | Loss: 89.675 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 700/4776 | Loss: 82.527 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 710/4776 | Loss: 50.028 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 720/4776 | Loss: 102.852 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 730/4776 | Loss: 138.342 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 740/4776 | Loss: 94.950 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 750/4776 | Loss: 119.429 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 760/4776 | Loss: 147.084 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 770/4776 | Loss: 118.887 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 780/4776 | Loss: 49.017 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 790/4776 | Loss: 57.414 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 800/4776 | Loss: 91.178 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 810/4776 | Loss: 72.514 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 820/4776 | Loss: 135.252 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 830/4776 | Loss: 137.672 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 840/4776 | Loss: 101.937 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 850/4776 | Loss: 107.378 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 860/4776 | Loss: 135.783 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 870/4776 | Loss: 131.691 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 880/4776 | Loss: 81.880 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 890/4776 | Loss: 117.445 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 900/4776 | Loss: 95.889 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 910/4776 | Loss: 119.143 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 920/4776 | Loss: 72.783 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 930/4776 | Loss: 114.976 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 940/4776 | Loss: 137.565 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 950/4776 | Loss: 156.461 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 960/4776 | Loss: 105.811 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 970/4776 | Loss: 100.890 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 980/4776 | Loss: 105.859 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 990/4776 | Loss: 51.951 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1000/4776 | Loss: 82.886 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1010/4776 | Loss: 101.211 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1020/4776 | Loss: 107.329 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1030/4776 | Loss: 70.378 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1040/4776 | Loss: 74.004 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1050/4776 | Loss: 97.804 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1060/4776 | Loss: 124.986 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1070/4776 | Loss: 178.363 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 1080/4776 | Loss: 93.274 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1090/4776 | Loss: 57.035 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1100/4776 | Loss: 57.889 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1110/4776 | Loss: 138.507 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1120/4776 | Loss: 131.399 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1130/4776 | Loss: 66.109 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1140/4776 | Loss: 161.662 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1150/4776 | Loss: 158.856 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1160/4776 | Loss: 107.546 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1170/4776 | Loss: 126.256 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1180/4776 | Loss: 134.052 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1190/4776 | Loss: 142.613 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1200/4776 | Loss: 199.801 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1210/4776 | Loss: 152.646 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1220/4776 | Loss: 107.184 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1230/4776 | Loss: 137.972 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1240/4776 | Loss: 123.274 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1250/4776 | Loss: 101.545 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1260/4776 | Loss: 110.603 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1270/4776 | Loss: 143.538 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1280/4776 | Loss: 114.381 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1290/4776 | Loss: 200.162 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 1300/4776 | Loss: 186.767 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1310/4776 | Loss: 85.068 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1320/4776 | Loss: 108.586 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1330/4776 | Loss: 117.204 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1340/4776 | Loss: 183.566 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 1350/4776 | Loss: 114.058 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1360/4776 | Loss: 114.639 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1370/4776 | Loss: 45.646 | Accuracy: 1.000\n",
      "[Epoch: 53/200] - Step: 1380/4776 | Loss: 131.874 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1390/4776 | Loss: 147.856 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1400/4776 | Loss: 165.872 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1410/4776 | Loss: 110.861 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1420/4776 | Loss: 103.227 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1430/4776 | Loss: 121.666 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1440/4776 | Loss: 57.522 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1450/4776 | Loss: 133.842 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1460/4776 | Loss: 70.992 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1470/4776 | Loss: 117.869 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1480/4776 | Loss: 87.592 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1490/4776 | Loss: 135.176 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1500/4776 | Loss: 78.471 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1510/4776 | Loss: 141.314 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1520/4776 | Loss: 123.467 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1530/4776 | Loss: 103.720 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1540/4776 | Loss: 107.805 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1550/4776 | Loss: 134.128 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1560/4776 | Loss: 157.536 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 1570/4776 | Loss: 74.551 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1580/4776 | Loss: 106.275 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1590/4776 | Loss: 144.711 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1600/4776 | Loss: 134.975 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1610/4776 | Loss: 149.445 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1620/4776 | Loss: 155.277 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1630/4776 | Loss: 122.955 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1640/4776 | Loss: 127.327 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1650/4776 | Loss: 162.942 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1660/4776 | Loss: 43.153 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1670/4776 | Loss: 100.003 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1680/4776 | Loss: 105.718 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1690/4776 | Loss: 129.318 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1700/4776 | Loss: 86.176 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1710/4776 | Loss: 166.267 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1720/4776 | Loss: 80.926 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1730/4776 | Loss: 162.885 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1740/4776 | Loss: 145.811 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1750/4776 | Loss: 145.417 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1760/4776 | Loss: 85.979 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1770/4776 | Loss: 97.752 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1780/4776 | Loss: 135.558 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1790/4776 | Loss: 100.962 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1800/4776 | Loss: 111.396 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1810/4776 | Loss: 130.708 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1820/4776 | Loss: 71.091 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1830/4776 | Loss: 124.329 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1840/4776 | Loss: 105.220 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 1850/4776 | Loss: 115.267 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1860/4776 | Loss: 120.639 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1870/4776 | Loss: 147.754 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1880/4776 | Loss: 96.445 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1890/4776 | Loss: 105.327 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1900/4776 | Loss: 90.371 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1910/4776 | Loss: 125.731 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1920/4776 | Loss: 106.356 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1930/4776 | Loss: 112.054 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1940/4776 | Loss: 114.668 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 1950/4776 | Loss: 78.943 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1960/4776 | Loss: 100.812 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 1970/4776 | Loss: 65.688 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 1980/4776 | Loss: 151.950 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 1990/4776 | Loss: 88.550 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2000/4776 | Loss: 121.660 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2010/4776 | Loss: 95.830 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2020/4776 | Loss: 187.360 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 2030/4776 | Loss: 192.346 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2040/4776 | Loss: 258.411 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2050/4776 | Loss: 178.101 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 2060/4776 | Loss: 107.139 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2070/4776 | Loss: 132.685 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 2080/4776 | Loss: 183.750 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2090/4776 | Loss: 76.886 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 2100/4776 | Loss: 98.353 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2110/4776 | Loss: 113.886 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2120/4776 | Loss: 122.660 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2130/4776 | Loss: 95.300 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2140/4776 | Loss: 171.662 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2150/4776 | Loss: 124.289 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2160/4776 | Loss: 85.723 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2170/4776 | Loss: 70.951 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 2180/4776 | Loss: 89.076 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2190/4776 | Loss: 144.427 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2200/4776 | Loss: 106.404 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2210/4776 | Loss: 139.650 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2220/4776 | Loss: 178.534 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 2230/4776 | Loss: 122.580 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2240/4776 | Loss: 62.834 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 2250/4776 | Loss: 116.581 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2260/4776 | Loss: 132.980 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2270/4776 | Loss: 207.977 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2280/4776 | Loss: 63.396 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 2290/4776 | Loss: 154.551 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2300/4776 | Loss: 70.857 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2310/4776 | Loss: 86.448 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2320/4776 | Loss: 133.161 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2330/4776 | Loss: 138.321 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2340/4776 | Loss: 162.937 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2350/4776 | Loss: 163.955 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 2360/4776 | Loss: 124.204 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2370/4776 | Loss: 119.295 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2380/4776 | Loss: 104.089 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2390/4776 | Loss: 113.375 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2400/4776 | Loss: 90.547 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2410/4776 | Loss: 98.634 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2420/4776 | Loss: 98.255 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2430/4776 | Loss: 81.815 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2440/4776 | Loss: 125.113 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2450/4776 | Loss: 152.881 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2460/4776 | Loss: 82.891 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2470/4776 | Loss: 127.374 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2480/4776 | Loss: 110.277 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2490/4776 | Loss: 164.436 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2500/4776 | Loss: 139.475 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2510/4776 | Loss: 87.033 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2520/4776 | Loss: 204.680 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2530/4776 | Loss: 218.672 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2540/4776 | Loss: 119.169 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2550/4776 | Loss: 143.454 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2560/4776 | Loss: 130.483 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2570/4776 | Loss: 124.209 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2580/4776 | Loss: 101.611 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2590/4776 | Loss: 103.805 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2600/4776 | Loss: 158.828 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2610/4776 | Loss: 60.308 | Accuracy: 1.000\n",
      "[Epoch: 53/200] - Step: 2620/4776 | Loss: 136.496 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2630/4776 | Loss: 125.864 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2640/4776 | Loss: 141.553 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2650/4776 | Loss: 73.865 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2660/4776 | Loss: 83.732 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 2670/4776 | Loss: 98.746 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2680/4776 | Loss: 55.868 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 2690/4776 | Loss: 92.802 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2700/4776 | Loss: 77.838 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2710/4776 | Loss: 163.243 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2720/4776 | Loss: 87.884 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2730/4776 | Loss: 73.150 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2740/4776 | Loss: 71.538 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 2750/4776 | Loss: 80.840 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2760/4776 | Loss: 90.944 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2770/4776 | Loss: 84.719 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2780/4776 | Loss: 97.706 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2790/4776 | Loss: 78.830 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2800/4776 | Loss: 128.475 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2810/4776 | Loss: 147.614 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2820/4776 | Loss: 115.869 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2830/4776 | Loss: 94.796 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2840/4776 | Loss: 182.712 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2850/4776 | Loss: 73.531 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2860/4776 | Loss: 138.023 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2870/4776 | Loss: 134.975 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 2880/4776 | Loss: 108.379 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2890/4776 | Loss: 152.795 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2900/4776 | Loss: 174.644 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 2910/4776 | Loss: 96.247 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2920/4776 | Loss: 92.848 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2930/4776 | Loss: 93.738 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2940/4776 | Loss: 112.688 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 2950/4776 | Loss: 111.934 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2960/4776 | Loss: 95.517 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 2970/4776 | Loss: 127.064 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 2980/4776 | Loss: 68.308 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 2990/4776 | Loss: 100.210 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3000/4776 | Loss: 114.234 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3010/4776 | Loss: 106.939 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3020/4776 | Loss: 93.218 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3030/4776 | Loss: 81.343 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3040/4776 | Loss: 132.823 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3050/4776 | Loss: 137.064 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3060/4776 | Loss: 91.420 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3070/4776 | Loss: 101.654 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3080/4776 | Loss: 78.967 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3090/4776 | Loss: 77.532 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3100/4776 | Loss: 110.397 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 3110/4776 | Loss: 172.274 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3120/4776 | Loss: 106.442 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3130/4776 | Loss: 127.809 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3140/4776 | Loss: 107.810 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3150/4776 | Loss: 155.813 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 3160/4776 | Loss: 101.548 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3170/4776 | Loss: 120.428 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3180/4776 | Loss: 139.567 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3190/4776 | Loss: 152.280 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3200/4776 | Loss: 138.310 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3210/4776 | Loss: 116.674 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3220/4776 | Loss: 106.400 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3230/4776 | Loss: 176.922 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3240/4776 | Loss: 136.594 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3250/4776 | Loss: 151.328 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3260/4776 | Loss: 118.977 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3270/4776 | Loss: 136.593 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3280/4776 | Loss: 174.848 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3290/4776 | Loss: 125.447 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3300/4776 | Loss: 102.330 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3310/4776 | Loss: 90.206 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3320/4776 | Loss: 76.889 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3330/4776 | Loss: 99.401 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3340/4776 | Loss: 105.026 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3350/4776 | Loss: 136.455 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3360/4776 | Loss: 113.163 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3370/4776 | Loss: 111.779 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3380/4776 | Loss: 158.128 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3390/4776 | Loss: 113.929 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3400/4776 | Loss: 111.184 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3410/4776 | Loss: 125.682 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3420/4776 | Loss: 90.001 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3430/4776 | Loss: 156.751 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 3440/4776 | Loss: 114.525 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3450/4776 | Loss: 80.586 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3460/4776 | Loss: 88.286 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3470/4776 | Loss: 137.497 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3480/4776 | Loss: 127.985 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3490/4776 | Loss: 124.006 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3500/4776 | Loss: 132.297 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3510/4776 | Loss: 106.137 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3520/4776 | Loss: 116.252 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3530/4776 | Loss: 53.901 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3540/4776 | Loss: 110.751 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3550/4776 | Loss: 140.686 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3560/4776 | Loss: 110.035 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3570/4776 | Loss: 145.732 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3580/4776 | Loss: 110.024 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3590/4776 | Loss: 130.695 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3600/4776 | Loss: 69.022 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3610/4776 | Loss: 133.186 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3620/4776 | Loss: 105.212 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3630/4776 | Loss: 117.115 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3640/4776 | Loss: 145.439 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 3650/4776 | Loss: 105.477 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3660/4776 | Loss: 72.440 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3670/4776 | Loss: 95.497 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3680/4776 | Loss: 66.164 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3690/4776 | Loss: 131.792 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3700/4776 | Loss: 171.562 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3710/4776 | Loss: 132.770 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3720/4776 | Loss: 127.123 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3730/4776 | Loss: 156.041 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3740/4776 | Loss: 110.015 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3750/4776 | Loss: 131.221 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 3760/4776 | Loss: 76.774 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3770/4776 | Loss: 170.131 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 3780/4776 | Loss: 82.287 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3790/4776 | Loss: 115.122 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3800/4776 | Loss: 74.350 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3810/4776 | Loss: 118.227 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3820/4776 | Loss: 93.169 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3830/4776 | Loss: 65.726 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3840/4776 | Loss: 141.824 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3850/4776 | Loss: 116.860 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 3860/4776 | Loss: 169.861 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3870/4776 | Loss: 94.538 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3880/4776 | Loss: 87.583 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3890/4776 | Loss: 64.072 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3900/4776 | Loss: 127.805 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3910/4776 | Loss: 88.302 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3920/4776 | Loss: 125.010 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3930/4776 | Loss: 76.972 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3940/4776 | Loss: 124.715 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3950/4776 | Loss: 77.207 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 3960/4776 | Loss: 151.084 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 3970/4776 | Loss: 119.089 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 3980/4776 | Loss: 78.720 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 3990/4776 | Loss: 116.153 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4000/4776 | Loss: 122.811 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4010/4776 | Loss: 118.349 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4020/4776 | Loss: 111.864 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4030/4776 | Loss: 112.221 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4040/4776 | Loss: 165.097 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 4050/4776 | Loss: 153.832 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 4060/4776 | Loss: 86.042 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 4070/4776 | Loss: 216.177 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4080/4776 | Loss: 133.025 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4090/4776 | Loss: 106.308 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4100/4776 | Loss: 78.258 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 4110/4776 | Loss: 118.805 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4120/4776 | Loss: 146.370 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4130/4776 | Loss: 96.142 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4140/4776 | Loss: 82.219 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4150/4776 | Loss: 123.143 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4160/4776 | Loss: 202.258 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4170/4776 | Loss: 140.808 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4180/4776 | Loss: 117.400 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4190/4776 | Loss: 182.965 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 4200/4776 | Loss: 109.488 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4210/4776 | Loss: 132.278 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4220/4776 | Loss: 125.327 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4230/4776 | Loss: 119.353 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4240/4776 | Loss: 154.208 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4250/4776 | Loss: 137.330 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4260/4776 | Loss: 89.624 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4270/4776 | Loss: 114.588 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4280/4776 | Loss: 94.027 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4290/4776 | Loss: 162.824 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4300/4776 | Loss: 101.578 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4310/4776 | Loss: 112.285 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4320/4776 | Loss: 104.652 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4330/4776 | Loss: 164.401 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4340/4776 | Loss: 137.085 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4350/4776 | Loss: 171.641 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4360/4776 | Loss: 109.924 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4370/4776 | Loss: 156.878 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4380/4776 | Loss: 114.124 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4390/4776 | Loss: 128.937 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4400/4776 | Loss: 94.865 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4410/4776 | Loss: 89.917 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4420/4776 | Loss: 110.704 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4430/4776 | Loss: 89.164 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4440/4776 | Loss: 118.376 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4450/4776 | Loss: 132.613 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4460/4776 | Loss: 100.510 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4470/4776 | Loss: 135.423 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4480/4776 | Loss: 52.824 | Accuracy: 0.900\n",
      "[Epoch: 53/200] - Step: 4490/4776 | Loss: 137.805 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 4500/4776 | Loss: 146.450 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4510/4776 | Loss: 111.488 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4520/4776 | Loss: 89.856 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4530/4776 | Loss: 95.965 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4540/4776 | Loss: 111.643 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4550/4776 | Loss: 131.829 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4560/4776 | Loss: 151.919 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4570/4776 | Loss: 115.513 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4580/4776 | Loss: 70.782 | Accuracy: 0.800\n",
      "[Epoch: 53/200] - Step: 4590/4776 | Loss: 86.440 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4600/4776 | Loss: 99.309 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4610/4776 | Loss: 104.823 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4620/4776 | Loss: 134.801 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4630/4776 | Loss: 63.218 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4640/4776 | Loss: 87.546 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4650/4776 | Loss: 86.874 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4660/4776 | Loss: 122.094 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4670/4776 | Loss: 141.025 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4680/4776 | Loss: 141.908 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4690/4776 | Loss: 79.394 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4700/4776 | Loss: 101.743 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4710/4776 | Loss: 100.791 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4720/4776 | Loss: 60.814 | Accuracy: 0.700\n",
      "[Epoch: 53/200] - Step: 4730/4776 | Loss: 116.184 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4740/4776 | Loss: 105.607 | Accuracy: 0.500\n",
      "[Epoch: 53/200] - Step: 4750/4776 | Loss: 147.365 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 4760/4776 | Loss: 82.787 | Accuracy: 0.600\n",
      "[Epoch: 53/200] - Step: 4770/4776 | Loss: 100.565 | Accuracy: 0.600\n",
      "Accuracy:  0.20491803278688525\n",
      "[Epoch: 54/200] - Step: 10/4776 | Loss: 72.827 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 20/4776 | Loss: 136.257 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 30/4776 | Loss: 148.158 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 40/4776 | Loss: 124.993 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 50/4776 | Loss: 113.492 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 60/4776 | Loss: 99.805 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 70/4776 | Loss: 100.981 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 80/4776 | Loss: 86.222 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 90/4776 | Loss: 81.886 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 100/4776 | Loss: 70.936 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 110/4776 | Loss: 73.658 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 120/4776 | Loss: 108.480 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 130/4776 | Loss: 80.129 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 140/4776 | Loss: 46.031 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 150/4776 | Loss: 95.065 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 160/4776 | Loss: 127.820 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 170/4776 | Loss: 131.929 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 180/4776 | Loss: 104.876 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 190/4776 | Loss: 166.272 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 200/4776 | Loss: 147.488 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 210/4776 | Loss: 172.639 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 220/4776 | Loss: 95.934 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 230/4776 | Loss: 70.831 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 240/4776 | Loss: 97.279 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 250/4776 | Loss: 82.197 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 260/4776 | Loss: 116.312 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 270/4776 | Loss: 74.887 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 280/4776 | Loss: 192.118 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 290/4776 | Loss: 119.381 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 300/4776 | Loss: 106.226 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 310/4776 | Loss: 123.706 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 320/4776 | Loss: 87.072 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 330/4776 | Loss: 76.437 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 340/4776 | Loss: 126.410 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 350/4776 | Loss: 52.157 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 360/4776 | Loss: 110.517 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 370/4776 | Loss: 113.925 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 380/4776 | Loss: 96.988 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 390/4776 | Loss: 79.542 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 400/4776 | Loss: 91.389 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 410/4776 | Loss: 70.468 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 420/4776 | Loss: 64.195 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 430/4776 | Loss: 89.071 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 440/4776 | Loss: 159.990 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 450/4776 | Loss: 104.020 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 460/4776 | Loss: 157.475 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 470/4776 | Loss: 121.396 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 480/4776 | Loss: 93.120 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 490/4776 | Loss: 112.599 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 500/4776 | Loss: 118.601 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 510/4776 | Loss: 118.984 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 520/4776 | Loss: 109.953 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 530/4776 | Loss: 153.497 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 540/4776 | Loss: 135.728 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 550/4776 | Loss: 97.615 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 560/4776 | Loss: 133.293 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 570/4776 | Loss: 127.929 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 580/4776 | Loss: 105.376 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 590/4776 | Loss: 92.101 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 600/4776 | Loss: 61.301 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 610/4776 | Loss: 93.277 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 620/4776 | Loss: 112.607 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 630/4776 | Loss: 130.831 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 640/4776 | Loss: 136.801 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 650/4776 | Loss: 89.526 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 660/4776 | Loss: 98.975 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 670/4776 | Loss: 72.777 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 680/4776 | Loss: 47.634 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 690/4776 | Loss: 90.501 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 700/4776 | Loss: 113.268 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 710/4776 | Loss: 121.884 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 720/4776 | Loss: 111.697 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 730/4776 | Loss: 98.746 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 740/4776 | Loss: 106.998 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 750/4776 | Loss: 95.368 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 760/4776 | Loss: 156.756 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 770/4776 | Loss: 155.664 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 780/4776 | Loss: 270.312 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 790/4776 | Loss: 92.008 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 800/4776 | Loss: 124.837 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 810/4776 | Loss: 159.796 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 820/4776 | Loss: 144.865 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 830/4776 | Loss: 140.012 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 840/4776 | Loss: 54.081 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 850/4776 | Loss: 102.465 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 860/4776 | Loss: 82.365 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 870/4776 | Loss: 87.871 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 880/4776 | Loss: 151.943 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 890/4776 | Loss: 106.732 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 900/4776 | Loss: 122.378 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 910/4776 | Loss: 59.508 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 920/4776 | Loss: 97.525 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 930/4776 | Loss: 145.439 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 940/4776 | Loss: 83.006 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 950/4776 | Loss: 117.271 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 960/4776 | Loss: 99.109 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 970/4776 | Loss: 163.278 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 980/4776 | Loss: 97.270 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 990/4776 | Loss: 94.583 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1000/4776 | Loss: 97.807 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1010/4776 | Loss: 76.304 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1020/4776 | Loss: 156.365 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1030/4776 | Loss: 189.534 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1040/4776 | Loss: 107.433 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1050/4776 | Loss: 125.918 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1060/4776 | Loss: 67.351 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1070/4776 | Loss: 169.871 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1080/4776 | Loss: 105.872 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1090/4776 | Loss: 104.546 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1100/4776 | Loss: 148.655 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1110/4776 | Loss: 102.767 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1120/4776 | Loss: 65.926 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 1130/4776 | Loss: 130.731 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1140/4776 | Loss: 136.797 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1150/4776 | Loss: 148.500 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1160/4776 | Loss: 122.654 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1170/4776 | Loss: 160.773 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1180/4776 | Loss: 120.334 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1190/4776 | Loss: 75.199 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1200/4776 | Loss: 88.927 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1210/4776 | Loss: 108.335 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1220/4776 | Loss: 105.537 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1230/4776 | Loss: 164.746 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1240/4776 | Loss: 84.222 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1250/4776 | Loss: 77.024 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1260/4776 | Loss: 107.010 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1270/4776 | Loss: 104.163 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1280/4776 | Loss: 164.839 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1290/4776 | Loss: 140.784 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1300/4776 | Loss: 139.558 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1310/4776 | Loss: 66.082 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1320/4776 | Loss: 88.022 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1330/4776 | Loss: 98.938 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1340/4776 | Loss: 88.015 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1350/4776 | Loss: 139.886 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1360/4776 | Loss: 144.798 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1370/4776 | Loss: 142.770 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1380/4776 | Loss: 117.361 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1390/4776 | Loss: 114.001 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1400/4776 | Loss: 122.666 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1410/4776 | Loss: 168.102 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1420/4776 | Loss: 82.553 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1430/4776 | Loss: 92.286 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1440/4776 | Loss: 143.755 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1450/4776 | Loss: 82.179 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1460/4776 | Loss: 130.560 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1470/4776 | Loss: 149.009 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1480/4776 | Loss: 161.613 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1490/4776 | Loss: 75.768 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 1500/4776 | Loss: 128.143 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1510/4776 | Loss: 132.761 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1520/4776 | Loss: 175.770 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1530/4776 | Loss: 82.088 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1540/4776 | Loss: 147.366 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1550/4776 | Loss: 136.336 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1560/4776 | Loss: 71.761 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1570/4776 | Loss: 105.776 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1580/4776 | Loss: 117.202 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1590/4776 | Loss: 98.633 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1600/4776 | Loss: 114.246 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1610/4776 | Loss: 148.559 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1620/4776 | Loss: 99.004 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1630/4776 | Loss: 108.340 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1640/4776 | Loss: 105.540 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1650/4776 | Loss: 66.513 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1660/4776 | Loss: 154.671 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1670/4776 | Loss: 127.679 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1680/4776 | Loss: 83.806 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1690/4776 | Loss: 51.754 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1700/4776 | Loss: 154.048 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1710/4776 | Loss: 83.860 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1720/4776 | Loss: 103.322 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1730/4776 | Loss: 98.231 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1740/4776 | Loss: 107.308 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1750/4776 | Loss: 125.997 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1760/4776 | Loss: 57.965 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1770/4776 | Loss: 203.041 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1780/4776 | Loss: 90.237 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1790/4776 | Loss: 73.194 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1800/4776 | Loss: 79.660 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1810/4776 | Loss: 94.864 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1820/4776 | Loss: 89.293 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1830/4776 | Loss: 123.583 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1840/4776 | Loss: 93.323 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1850/4776 | Loss: 64.197 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1860/4776 | Loss: 97.463 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1870/4776 | Loss: 77.017 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1880/4776 | Loss: 150.125 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1890/4776 | Loss: 123.402 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1900/4776 | Loss: 144.763 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1910/4776 | Loss: 138.174 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1920/4776 | Loss: 148.360 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 1930/4776 | Loss: 145.345 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1940/4776 | Loss: 90.648 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 1950/4776 | Loss: 131.029 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 1960/4776 | Loss: 155.547 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1970/4776 | Loss: 140.013 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 1980/4776 | Loss: 68.414 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 1990/4776 | Loss: 110.390 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2000/4776 | Loss: 171.906 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2010/4776 | Loss: 96.156 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2020/4776 | Loss: 110.554 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2030/4776 | Loss: 100.105 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2040/4776 | Loss: 109.006 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2050/4776 | Loss: 88.593 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2060/4776 | Loss: 156.614 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2070/4776 | Loss: 85.638 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2080/4776 | Loss: 105.069 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2090/4776 | Loss: 129.952 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2100/4776 | Loss: 109.162 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2110/4776 | Loss: 143.133 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2120/4776 | Loss: 92.665 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2130/4776 | Loss: 116.214 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2140/4776 | Loss: 71.447 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2150/4776 | Loss: 118.904 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2160/4776 | Loss: 139.689 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2170/4776 | Loss: 77.833 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2180/4776 | Loss: 161.995 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2190/4776 | Loss: 98.662 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2200/4776 | Loss: 155.557 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2210/4776 | Loss: 104.087 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2220/4776 | Loss: 81.301 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2230/4776 | Loss: 110.550 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2240/4776 | Loss: 124.132 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2250/4776 | Loss: 101.253 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2260/4776 | Loss: 95.034 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2270/4776 | Loss: 74.566 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2280/4776 | Loss: 102.201 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2290/4776 | Loss: 72.244 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 2300/4776 | Loss: 78.343 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2310/4776 | Loss: 119.093 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2320/4776 | Loss: 49.585 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 2330/4776 | Loss: 71.701 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 2340/4776 | Loss: 104.383 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2350/4776 | Loss: 117.298 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2360/4776 | Loss: 155.785 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2370/4776 | Loss: 63.148 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2380/4776 | Loss: 87.581 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2390/4776 | Loss: 127.475 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2400/4776 | Loss: 62.340 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2410/4776 | Loss: 139.861 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2420/4776 | Loss: 154.616 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2430/4776 | Loss: 105.429 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2440/4776 | Loss: 105.646 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2450/4776 | Loss: 174.751 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2460/4776 | Loss: 120.617 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2470/4776 | Loss: 123.755 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2480/4776 | Loss: 118.109 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2490/4776 | Loss: 89.545 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2500/4776 | Loss: 63.216 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2510/4776 | Loss: 65.709 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2520/4776 | Loss: 138.682 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2530/4776 | Loss: 65.829 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 2540/4776 | Loss: 138.960 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2550/4776 | Loss: 88.534 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2560/4776 | Loss: 144.794 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2570/4776 | Loss: 98.118 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2580/4776 | Loss: 132.605 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2590/4776 | Loss: 97.959 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2600/4776 | Loss: 150.347 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2610/4776 | Loss: 87.827 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2620/4776 | Loss: 120.462 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2630/4776 | Loss: 130.754 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2640/4776 | Loss: 159.753 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2650/4776 | Loss: 163.687 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2660/4776 | Loss: 102.694 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2670/4776 | Loss: 90.554 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2680/4776 | Loss: 118.865 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2690/4776 | Loss: 168.365 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 2700/4776 | Loss: 87.734 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2710/4776 | Loss: 97.886 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2720/4776 | Loss: 101.887 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2730/4776 | Loss: 128.091 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2740/4776 | Loss: 103.444 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2750/4776 | Loss: 91.401 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2760/4776 | Loss: 89.122 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2770/4776 | Loss: 65.225 | Accuracy: 1.000\n",
      "[Epoch: 54/200] - Step: 2780/4776 | Loss: 60.492 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 2790/4776 | Loss: 85.916 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2800/4776 | Loss: 105.308 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2810/4776 | Loss: 115.483 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2820/4776 | Loss: 81.529 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2830/4776 | Loss: 96.169 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2840/4776 | Loss: 118.871 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2850/4776 | Loss: 94.416 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2860/4776 | Loss: 107.549 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2870/4776 | Loss: 114.011 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 2880/4776 | Loss: 90.781 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2890/4776 | Loss: 103.425 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2900/4776 | Loss: 35.065 | Accuracy: 1.000\n",
      "[Epoch: 54/200] - Step: 2910/4776 | Loss: 99.427 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2920/4776 | Loss: 133.250 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 2930/4776 | Loss: 80.274 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2940/4776 | Loss: 90.318 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2950/4776 | Loss: 130.363 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 2960/4776 | Loss: 85.422 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2970/4776 | Loss: 97.238 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 2980/4776 | Loss: 84.913 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 2990/4776 | Loss: 105.868 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3000/4776 | Loss: 120.274 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3010/4776 | Loss: 152.878 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3020/4776 | Loss: 162.400 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3030/4776 | Loss: 90.196 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3040/4776 | Loss: 86.197 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3050/4776 | Loss: 116.973 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3060/4776 | Loss: 85.000 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3070/4776 | Loss: 122.684 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3080/4776 | Loss: 119.064 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 3090/4776 | Loss: 125.801 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3100/4776 | Loss: 100.387 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3110/4776 | Loss: 146.878 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 3120/4776 | Loss: 118.851 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3130/4776 | Loss: 176.597 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3140/4776 | Loss: 141.636 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3150/4776 | Loss: 96.574 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3160/4776 | Loss: 86.032 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3170/4776 | Loss: 92.683 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3180/4776 | Loss: 110.779 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3190/4776 | Loss: 102.941 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3200/4776 | Loss: 131.031 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3210/4776 | Loss: 155.531 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3220/4776 | Loss: 78.056 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3230/4776 | Loss: 148.248 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3240/4776 | Loss: 169.268 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3250/4776 | Loss: 89.295 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3260/4776 | Loss: 88.035 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3270/4776 | Loss: 160.978 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3280/4776 | Loss: 109.921 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3290/4776 | Loss: 93.612 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3300/4776 | Loss: 170.360 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3310/4776 | Loss: 126.147 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3320/4776 | Loss: 142.645 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3330/4776 | Loss: 78.768 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3340/4776 | Loss: 111.713 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3350/4776 | Loss: 106.251 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3360/4776 | Loss: 100.096 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3370/4776 | Loss: 183.707 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3380/4776 | Loss: 41.280 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3390/4776 | Loss: 128.868 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3400/4776 | Loss: 101.427 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3410/4776 | Loss: 85.966 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3420/4776 | Loss: 143.727 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3430/4776 | Loss: 81.833 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3440/4776 | Loss: 104.871 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3450/4776 | Loss: 115.174 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3460/4776 | Loss: 164.855 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3470/4776 | Loss: 171.500 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3480/4776 | Loss: 155.108 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3490/4776 | Loss: 114.096 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3500/4776 | Loss: 115.189 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3510/4776 | Loss: 90.111 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3520/4776 | Loss: 117.777 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3530/4776 | Loss: 101.051 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3540/4776 | Loss: 62.161 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3550/4776 | Loss: 100.826 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3560/4776 | Loss: 158.188 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3570/4776 | Loss: 109.692 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3580/4776 | Loss: 89.034 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3590/4776 | Loss: 130.697 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3600/4776 | Loss: 106.187 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3610/4776 | Loss: 82.720 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3620/4776 | Loss: 96.445 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3630/4776 | Loss: 62.398 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 3640/4776 | Loss: 163.694 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3650/4776 | Loss: 41.891 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 3660/4776 | Loss: 171.825 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3670/4776 | Loss: 97.537 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3680/4776 | Loss: 77.378 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3690/4776 | Loss: 128.977 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3700/4776 | Loss: 71.848 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3710/4776 | Loss: 119.023 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3720/4776 | Loss: 133.610 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3730/4776 | Loss: 171.877 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 3740/4776 | Loss: 147.923 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3750/4776 | Loss: 92.979 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3760/4776 | Loss: 177.797 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3770/4776 | Loss: 84.058 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3780/4776 | Loss: 164.980 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 3790/4776 | Loss: 81.424 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3800/4776 | Loss: 79.542 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 3810/4776 | Loss: 214.345 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3820/4776 | Loss: 145.227 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3830/4776 | Loss: 119.262 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3840/4776 | Loss: 103.950 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3850/4776 | Loss: 95.660 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3860/4776 | Loss: 108.750 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3870/4776 | Loss: 116.785 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3880/4776 | Loss: 159.200 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3890/4776 | Loss: 96.405 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3900/4776 | Loss: 59.528 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 3910/4776 | Loss: 131.457 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3920/4776 | Loss: 95.261 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3930/4776 | Loss: 130.101 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 3940/4776 | Loss: 147.662 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3950/4776 | Loss: 78.843 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3960/4776 | Loss: 98.145 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 3970/4776 | Loss: 148.932 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 3980/4776 | Loss: 77.909 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 3990/4776 | Loss: 111.921 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4000/4776 | Loss: 85.786 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4010/4776 | Loss: 46.483 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 4020/4776 | Loss: 94.023 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4030/4776 | Loss: 150.327 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4040/4776 | Loss: 186.871 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 4050/4776 | Loss: 127.553 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4060/4776 | Loss: 110.420 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4070/4776 | Loss: 116.498 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4080/4776 | Loss: 105.784 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4090/4776 | Loss: 143.098 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 4100/4776 | Loss: 149.644 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4110/4776 | Loss: 172.076 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 4120/4776 | Loss: 127.028 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4130/4776 | Loss: 152.493 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4140/4776 | Loss: 115.005 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4150/4776 | Loss: 115.026 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4160/4776 | Loss: 86.854 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4170/4776 | Loss: 94.596 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4180/4776 | Loss: 77.778 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4190/4776 | Loss: 56.220 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 4200/4776 | Loss: 104.492 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4210/4776 | Loss: 122.741 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4220/4776 | Loss: 149.150 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4230/4776 | Loss: 97.227 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4240/4776 | Loss: 101.735 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4250/4776 | Loss: 104.965 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4260/4776 | Loss: 178.476 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 4270/4776 | Loss: 84.952 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4280/4776 | Loss: 129.396 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4290/4776 | Loss: 110.147 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4300/4776 | Loss: 134.964 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4310/4776 | Loss: 94.366 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4320/4776 | Loss: 135.663 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4330/4776 | Loss: 83.014 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4340/4776 | Loss: 114.843 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4350/4776 | Loss: 182.178 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4360/4776 | Loss: 89.322 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4370/4776 | Loss: 106.586 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4380/4776 | Loss: 181.906 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4390/4776 | Loss: 171.382 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4400/4776 | Loss: 94.270 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4410/4776 | Loss: 119.623 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4420/4776 | Loss: 99.065 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4430/4776 | Loss: 138.248 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4440/4776 | Loss: 128.795 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4450/4776 | Loss: 119.026 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4460/4776 | Loss: 101.254 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4470/4776 | Loss: 117.226 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4480/4776 | Loss: 97.016 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4490/4776 | Loss: 144.211 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4500/4776 | Loss: 97.389 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4510/4776 | Loss: 68.826 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 4520/4776 | Loss: 85.237 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4530/4776 | Loss: 117.323 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4540/4776 | Loss: 138.627 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 4550/4776 | Loss: 146.669 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 4560/4776 | Loss: 135.089 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4570/4776 | Loss: 94.868 | Accuracy: 0.700\n",
      "[Epoch: 54/200] - Step: 4580/4776 | Loss: 98.058 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4590/4776 | Loss: 122.082 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4600/4776 | Loss: 53.595 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 4610/4776 | Loss: 150.277 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4620/4776 | Loss: 74.129 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 4630/4776 | Loss: 147.821 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4640/4776 | Loss: 109.218 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4650/4776 | Loss: 123.417 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4660/4776 | Loss: 152.160 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4670/4776 | Loss: 107.551 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4680/4776 | Loss: 150.072 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4690/4776 | Loss: 81.151 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 4700/4776 | Loss: 74.185 | Accuracy: 0.900\n",
      "[Epoch: 54/200] - Step: 4710/4776 | Loss: 147.787 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4720/4776 | Loss: 98.470 | Accuracy: 0.800\n",
      "[Epoch: 54/200] - Step: 4730/4776 | Loss: 219.342 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4740/4776 | Loss: 139.908 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 4750/4776 | Loss: 97.485 | Accuracy: 0.600\n",
      "[Epoch: 54/200] - Step: 4760/4776 | Loss: 145.365 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 4770/4776 | Loss: 129.704 | Accuracy: 0.600\n",
      "Accuracy:  0.18032786885245902\n",
      "[Epoch: 55/200] - Step: 10/4776 | Loss: 157.770 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 20/4776 | Loss: 118.488 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 30/4776 | Loss: 58.361 | Accuracy: 1.000\n",
      "[Epoch: 55/200] - Step: 40/4776 | Loss: 109.428 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 50/4776 | Loss: 113.806 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 60/4776 | Loss: 74.781 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 70/4776 | Loss: 132.297 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 80/4776 | Loss: 29.745 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 90/4776 | Loss: 138.543 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 100/4776 | Loss: 73.881 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 110/4776 | Loss: 83.081 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 120/4776 | Loss: 115.963 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 130/4776 | Loss: 167.999 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 140/4776 | Loss: 114.469 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 150/4776 | Loss: 124.201 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 160/4776 | Loss: 97.089 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 170/4776 | Loss: 82.534 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 180/4776 | Loss: 88.097 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 190/4776 | Loss: 109.502 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 200/4776 | Loss: 86.306 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 210/4776 | Loss: 99.479 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 220/4776 | Loss: 34.713 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 230/4776 | Loss: 122.460 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 240/4776 | Loss: 53.836 | Accuracy: 1.000\n",
      "[Epoch: 55/200] - Step: 250/4776 | Loss: 92.850 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 260/4776 | Loss: 140.317 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 270/4776 | Loss: 84.465 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 280/4776 | Loss: 127.232 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 290/4776 | Loss: 159.967 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 300/4776 | Loss: 65.968 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 310/4776 | Loss: 109.764 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 320/4776 | Loss: 122.639 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 330/4776 | Loss: 82.558 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 340/4776 | Loss: 44.446 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 350/4776 | Loss: 86.491 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 360/4776 | Loss: 122.063 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 370/4776 | Loss: 145.184 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 380/4776 | Loss: 122.348 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 390/4776 | Loss: 64.599 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 400/4776 | Loss: 77.892 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 410/4776 | Loss: 57.277 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 420/4776 | Loss: 80.475 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 430/4776 | Loss: 104.062 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 440/4776 | Loss: 78.856 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 450/4776 | Loss: 60.587 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 460/4776 | Loss: 81.053 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 470/4776 | Loss: 106.928 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 480/4776 | Loss: 117.084 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 490/4776 | Loss: 64.566 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 500/4776 | Loss: 115.607 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 510/4776 | Loss: 74.778 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 520/4776 | Loss: 93.502 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 530/4776 | Loss: 74.746 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 540/4776 | Loss: 103.537 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 550/4776 | Loss: 117.467 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 560/4776 | Loss: 49.806 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 570/4776 | Loss: 86.770 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 580/4776 | Loss: 142.337 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 590/4776 | Loss: 113.314 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 600/4776 | Loss: 79.922 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 610/4776 | Loss: 124.835 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 620/4776 | Loss: 106.716 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 630/4776 | Loss: 139.104 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 640/4776 | Loss: 117.722 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 650/4776 | Loss: 108.002 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 660/4776 | Loss: 98.274 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 670/4776 | Loss: 124.148 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 680/4776 | Loss: 107.428 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 690/4776 | Loss: 105.358 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 700/4776 | Loss: 121.122 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 710/4776 | Loss: 120.547 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 720/4776 | Loss: 61.858 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 730/4776 | Loss: 141.265 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 740/4776 | Loss: 117.393 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 750/4776 | Loss: 88.572 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 760/4776 | Loss: 64.655 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 770/4776 | Loss: 109.094 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 780/4776 | Loss: 93.748 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 790/4776 | Loss: 119.220 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 800/4776 | Loss: 114.990 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 810/4776 | Loss: 83.189 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 820/4776 | Loss: 100.916 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 830/4776 | Loss: 100.770 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 840/4776 | Loss: 113.314 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 850/4776 | Loss: 165.673 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 860/4776 | Loss: 83.606 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 870/4776 | Loss: 77.817 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 880/4776 | Loss: 67.293 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 890/4776 | Loss: 56.368 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 900/4776 | Loss: 89.751 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 910/4776 | Loss: 113.664 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 920/4776 | Loss: 127.825 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 930/4776 | Loss: 78.892 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 940/4776 | Loss: 80.946 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 950/4776 | Loss: 102.114 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 960/4776 | Loss: 121.186 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 970/4776 | Loss: 87.186 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 980/4776 | Loss: 74.649 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 990/4776 | Loss: 125.249 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1000/4776 | Loss: 155.166 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1010/4776 | Loss: 135.724 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1020/4776 | Loss: 167.018 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 1030/4776 | Loss: 85.165 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1040/4776 | Loss: 106.211 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1050/4776 | Loss: 130.656 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1060/4776 | Loss: 56.444 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1070/4776 | Loss: 112.971 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1080/4776 | Loss: 123.261 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1090/4776 | Loss: 133.908 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1100/4776 | Loss: 91.548 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1110/4776 | Loss: 68.888 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1120/4776 | Loss: 84.226 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1130/4776 | Loss: 73.664 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1140/4776 | Loss: 87.171 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1150/4776 | Loss: 84.226 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1160/4776 | Loss: 180.411 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1170/4776 | Loss: 162.556 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1180/4776 | Loss: 150.160 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1190/4776 | Loss: 130.882 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1200/4776 | Loss: 58.844 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1210/4776 | Loss: 94.778 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1220/4776 | Loss: 128.424 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1230/4776 | Loss: 92.701 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1240/4776 | Loss: 63.217 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1250/4776 | Loss: 119.766 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1260/4776 | Loss: 95.137 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1270/4776 | Loss: 73.136 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1280/4776 | Loss: 143.528 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1290/4776 | Loss: 143.995 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1300/4776 | Loss: 106.491 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1310/4776 | Loss: 121.407 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1320/4776 | Loss: 140.054 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1330/4776 | Loss: 153.062 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1340/4776 | Loss: 69.633 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1350/4776 | Loss: 90.589 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1360/4776 | Loss: 73.133 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1370/4776 | Loss: 112.191 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1380/4776 | Loss: 100.165 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1390/4776 | Loss: 115.721 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1400/4776 | Loss: 98.403 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1410/4776 | Loss: 115.593 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1420/4776 | Loss: 100.096 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1430/4776 | Loss: 103.524 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1440/4776 | Loss: 83.133 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1450/4776 | Loss: 97.460 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1460/4776 | Loss: 72.103 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1470/4776 | Loss: 135.396 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1480/4776 | Loss: 90.134 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1490/4776 | Loss: 120.154 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1500/4776 | Loss: 49.950 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1510/4776 | Loss: 101.251 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1520/4776 | Loss: 140.230 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1530/4776 | Loss: 95.781 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1540/4776 | Loss: 92.710 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1550/4776 | Loss: 136.933 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1560/4776 | Loss: 86.955 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1570/4776 | Loss: 164.183 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1580/4776 | Loss: 83.491 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1590/4776 | Loss: 97.806 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1600/4776 | Loss: 118.919 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1610/4776 | Loss: 87.978 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1620/4776 | Loss: 167.412 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1630/4776 | Loss: 92.894 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1640/4776 | Loss: 134.265 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1650/4776 | Loss: 77.852 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1660/4776 | Loss: 46.180 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1670/4776 | Loss: 48.232 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 1680/4776 | Loss: 133.733 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1690/4776 | Loss: 85.116 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1700/4776 | Loss: 127.797 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1710/4776 | Loss: 93.526 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1720/4776 | Loss: 74.618 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1730/4776 | Loss: 51.499 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 1740/4776 | Loss: 107.184 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1750/4776 | Loss: 121.620 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1760/4776 | Loss: 107.822 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1770/4776 | Loss: 146.980 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1780/4776 | Loss: 94.473 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1790/4776 | Loss: 137.040 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1800/4776 | Loss: 110.210 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1810/4776 | Loss: 108.899 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1820/4776 | Loss: 101.506 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1830/4776 | Loss: 109.488 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1840/4776 | Loss: 166.802 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1850/4776 | Loss: 85.386 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1860/4776 | Loss: 75.226 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 1870/4776 | Loss: 91.588 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1880/4776 | Loss: 136.888 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1890/4776 | Loss: 132.070 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1900/4776 | Loss: 61.459 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1910/4776 | Loss: 245.909 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 1920/4776 | Loss: 175.981 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1930/4776 | Loss: 111.253 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1940/4776 | Loss: 99.466 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 1950/4776 | Loss: 120.223 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1960/4776 | Loss: 108.842 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1970/4776 | Loss: 105.529 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 1980/4776 | Loss: 129.304 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 1990/4776 | Loss: 58.536 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2000/4776 | Loss: 95.498 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2010/4776 | Loss: 115.128 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2020/4776 | Loss: 99.221 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2030/4776 | Loss: 116.380 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2040/4776 | Loss: 112.494 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2050/4776 | Loss: 85.741 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2060/4776 | Loss: 71.669 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2070/4776 | Loss: 151.627 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 2080/4776 | Loss: 90.929 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2090/4776 | Loss: 103.401 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2100/4776 | Loss: 206.989 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2110/4776 | Loss: 113.878 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2120/4776 | Loss: 90.821 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2130/4776 | Loss: 75.030 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2140/4776 | Loss: 149.255 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2150/4776 | Loss: 63.946 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 2160/4776 | Loss: 75.255 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2170/4776 | Loss: 134.858 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2180/4776 | Loss: 104.610 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2190/4776 | Loss: 149.779 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2200/4776 | Loss: 167.338 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2210/4776 | Loss: 113.075 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2220/4776 | Loss: 95.073 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2230/4776 | Loss: 97.911 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2240/4776 | Loss: 92.105 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2250/4776 | Loss: 189.329 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 2260/4776 | Loss: 182.185 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2270/4776 | Loss: 140.285 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2280/4776 | Loss: 195.199 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2290/4776 | Loss: 176.369 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2300/4776 | Loss: 131.156 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2310/4776 | Loss: 90.691 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2320/4776 | Loss: 118.103 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2330/4776 | Loss: 121.165 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2340/4776 | Loss: 83.042 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2350/4776 | Loss: 79.757 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2360/4776 | Loss: 143.598 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2370/4776 | Loss: 106.311 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2380/4776 | Loss: 92.425 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2390/4776 | Loss: 99.857 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2400/4776 | Loss: 122.900 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2410/4776 | Loss: 88.105 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2420/4776 | Loss: 101.247 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2430/4776 | Loss: 126.858 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2440/4776 | Loss: 91.102 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2450/4776 | Loss: 114.201 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2460/4776 | Loss: 98.673 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2470/4776 | Loss: 87.284 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2480/4776 | Loss: 44.368 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2490/4776 | Loss: 91.314 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2500/4776 | Loss: 75.798 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2510/4776 | Loss: 86.499 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2520/4776 | Loss: 95.720 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2530/4776 | Loss: 122.173 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2540/4776 | Loss: 104.450 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2550/4776 | Loss: 124.219 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2560/4776 | Loss: 101.329 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2570/4776 | Loss: 135.229 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2580/4776 | Loss: 89.731 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2590/4776 | Loss: 85.977 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2600/4776 | Loss: 80.432 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2610/4776 | Loss: 124.930 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2620/4776 | Loss: 144.097 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2630/4776 | Loss: 116.407 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2640/4776 | Loss: 95.182 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2650/4776 | Loss: 73.559 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2660/4776 | Loss: 106.528 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2670/4776 | Loss: 141.617 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2680/4776 | Loss: 108.431 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2690/4776 | Loss: 115.444 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2700/4776 | Loss: 133.928 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 2710/4776 | Loss: 90.833 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2720/4776 | Loss: 90.504 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2730/4776 | Loss: 107.309 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2740/4776 | Loss: 105.769 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2750/4776 | Loss: 118.915 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2760/4776 | Loss: 94.974 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2770/4776 | Loss: 110.783 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2780/4776 | Loss: 52.714 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 2790/4776 | Loss: 78.203 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2800/4776 | Loss: 76.953 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2810/4776 | Loss: 83.854 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2820/4776 | Loss: 111.077 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2830/4776 | Loss: 61.361 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2840/4776 | Loss: 136.012 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2850/4776 | Loss: 169.027 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2860/4776 | Loss: 99.117 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2870/4776 | Loss: 105.743 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2880/4776 | Loss: 54.313 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 2890/4776 | Loss: 98.943 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2900/4776 | Loss: 95.329 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 2910/4776 | Loss: 116.082 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2920/4776 | Loss: 76.309 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 2930/4776 | Loss: 83.978 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 2940/4776 | Loss: 113.857 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2950/4776 | Loss: 127.888 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2960/4776 | Loss: 133.399 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 2970/4776 | Loss: 129.652 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 2980/4776 | Loss: 172.588 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 2990/4776 | Loss: 87.924 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3000/4776 | Loss: 152.500 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3010/4776 | Loss: 88.315 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3020/4776 | Loss: 57.130 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 3030/4776 | Loss: 113.812 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3040/4776 | Loss: 157.266 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3050/4776 | Loss: 124.553 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3060/4776 | Loss: 122.162 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3070/4776 | Loss: 137.684 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3080/4776 | Loss: 69.798 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3090/4776 | Loss: 135.609 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3100/4776 | Loss: 92.305 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3110/4776 | Loss: 87.891 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3120/4776 | Loss: 115.204 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3130/4776 | Loss: 177.176 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3140/4776 | Loss: 108.416 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3150/4776 | Loss: 129.709 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3160/4776 | Loss: 135.766 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3170/4776 | Loss: 99.257 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3180/4776 | Loss: 85.260 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3190/4776 | Loss: 115.229 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3200/4776 | Loss: 157.932 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3210/4776 | Loss: 133.761 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3220/4776 | Loss: 111.791 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3230/4776 | Loss: 115.757 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3240/4776 | Loss: 156.569 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3250/4776 | Loss: 115.532 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3260/4776 | Loss: 116.429 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3270/4776 | Loss: 103.173 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3280/4776 | Loss: 140.263 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3290/4776 | Loss: 89.468 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3300/4776 | Loss: 81.866 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3310/4776 | Loss: 113.586 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3320/4776 | Loss: 85.170 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3330/4776 | Loss: 123.081 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3340/4776 | Loss: 110.067 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3350/4776 | Loss: 118.511 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3360/4776 | Loss: 89.856 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3370/4776 | Loss: 59.085 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3380/4776 | Loss: 115.987 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3390/4776 | Loss: 129.406 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3400/4776 | Loss: 101.903 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3410/4776 | Loss: 77.585 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3420/4776 | Loss: 138.583 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3430/4776 | Loss: 132.602 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3440/4776 | Loss: 128.504 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3450/4776 | Loss: 144.206 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3460/4776 | Loss: 119.451 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3470/4776 | Loss: 82.396 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3480/4776 | Loss: 105.725 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3490/4776 | Loss: 116.140 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3500/4776 | Loss: 89.549 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3510/4776 | Loss: 88.919 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3520/4776 | Loss: 100.724 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3530/4776 | Loss: 68.783 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3540/4776 | Loss: 176.096 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3550/4776 | Loss: 64.358 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 3560/4776 | Loss: 109.223 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3570/4776 | Loss: 136.574 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3580/4776 | Loss: 97.817 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3590/4776 | Loss: 102.794 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3600/4776 | Loss: 109.417 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3610/4776 | Loss: 75.831 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3620/4776 | Loss: 64.284 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3630/4776 | Loss: 127.236 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3640/4776 | Loss: 110.998 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3650/4776 | Loss: 119.304 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3660/4776 | Loss: 125.256 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3670/4776 | Loss: 119.997 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3680/4776 | Loss: 100.330 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3690/4776 | Loss: 92.197 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3700/4776 | Loss: 87.357 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3710/4776 | Loss: 80.671 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3720/4776 | Loss: 128.515 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3730/4776 | Loss: 130.978 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3740/4776 | Loss: 74.380 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3750/4776 | Loss: 154.763 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3760/4776 | Loss: 138.150 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3770/4776 | Loss: 98.456 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3780/4776 | Loss: 78.505 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3790/4776 | Loss: 96.860 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3800/4776 | Loss: 142.148 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3810/4776 | Loss: 68.531 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3820/4776 | Loss: 92.534 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3830/4776 | Loss: 105.348 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3840/4776 | Loss: 97.264 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3850/4776 | Loss: 117.218 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3860/4776 | Loss: 67.876 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3870/4776 | Loss: 150.073 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3880/4776 | Loss: 95.424 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 3890/4776 | Loss: 77.941 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 3900/4776 | Loss: 59.029 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3910/4776 | Loss: 104.381 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3920/4776 | Loss: 96.625 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3930/4776 | Loss: 114.880 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 3940/4776 | Loss: 132.169 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3950/4776 | Loss: 186.797 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 3960/4776 | Loss: 112.782 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 3970/4776 | Loss: 191.914 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3980/4776 | Loss: 145.042 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 3990/4776 | Loss: 85.539 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4000/4776 | Loss: 49.290 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 4010/4776 | Loss: 133.043 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4020/4776 | Loss: 150.182 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4030/4776 | Loss: 76.095 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 4040/4776 | Loss: 124.746 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4050/4776 | Loss: 127.390 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 4060/4776 | Loss: 115.040 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4070/4776 | Loss: 107.272 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4080/4776 | Loss: 178.183 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4090/4776 | Loss: 165.773 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 4100/4776 | Loss: 107.478 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4110/4776 | Loss: 99.011 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4120/4776 | Loss: 110.082 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4130/4776 | Loss: 89.086 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4140/4776 | Loss: 128.612 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4150/4776 | Loss: 73.872 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4160/4776 | Loss: 103.428 | Accuracy: 0.900\n",
      "[Epoch: 55/200] - Step: 4170/4776 | Loss: 165.561 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4180/4776 | Loss: 96.318 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4190/4776 | Loss: 110.056 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4200/4776 | Loss: 136.261 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4210/4776 | Loss: 133.128 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4220/4776 | Loss: 155.433 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4230/4776 | Loss: 68.411 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4240/4776 | Loss: 127.232 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4250/4776 | Loss: 154.682 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 4260/4776 | Loss: 84.721 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4270/4776 | Loss: 94.694 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4280/4776 | Loss: 96.765 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4290/4776 | Loss: 112.133 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4300/4776 | Loss: 103.895 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4310/4776 | Loss: 162.377 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 4320/4776 | Loss: 81.361 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 4330/4776 | Loss: 133.366 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 4340/4776 | Loss: 96.365 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4350/4776 | Loss: 106.894 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4360/4776 | Loss: 118.544 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4370/4776 | Loss: 102.221 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4380/4776 | Loss: 128.394 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4390/4776 | Loss: 148.326 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4400/4776 | Loss: 76.504 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4410/4776 | Loss: 94.661 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4420/4776 | Loss: 150.925 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4430/4776 | Loss: 62.337 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 4440/4776 | Loss: 94.260 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4450/4776 | Loss: 126.921 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4460/4776 | Loss: 91.666 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4470/4776 | Loss: 160.150 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4480/4776 | Loss: 111.831 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4490/4776 | Loss: 120.579 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4500/4776 | Loss: 93.548 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4510/4776 | Loss: 112.228 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4520/4776 | Loss: 154.458 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4530/4776 | Loss: 119.760 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4540/4776 | Loss: 102.698 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4550/4776 | Loss: 104.891 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4560/4776 | Loss: 88.032 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4570/4776 | Loss: 96.020 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4580/4776 | Loss: 135.853 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4590/4776 | Loss: 89.023 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4600/4776 | Loss: 92.830 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4610/4776 | Loss: 91.748 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4620/4776 | Loss: 97.629 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4630/4776 | Loss: 126.476 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4640/4776 | Loss: 147.570 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4650/4776 | Loss: 163.342 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4660/4776 | Loss: 108.352 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4670/4776 | Loss: 92.962 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4680/4776 | Loss: 132.063 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 4690/4776 | Loss: 58.871 | Accuracy: 0.800\n",
      "[Epoch: 55/200] - Step: 4700/4776 | Loss: 84.570 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4710/4776 | Loss: 97.238 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4720/4776 | Loss: 97.274 | Accuracy: 0.500\n",
      "[Epoch: 55/200] - Step: 4730/4776 | Loss: 84.124 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4740/4776 | Loss: 105.074 | Accuracy: 0.600\n",
      "[Epoch: 55/200] - Step: 4750/4776 | Loss: 114.653 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 4760/4776 | Loss: 83.437 | Accuracy: 0.700\n",
      "[Epoch: 55/200] - Step: 4770/4776 | Loss: 61.614 | Accuracy: 0.700\n",
      "Accuracy:  0.21475409836065573\n",
      "[Epoch: 56/200] - Step: 10/4776 | Loss: 66.102 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 20/4776 | Loss: 71.202 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 30/4776 | Loss: 67.413 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 40/4776 | Loss: 66.136 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 50/4776 | Loss: 116.130 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 60/4776 | Loss: 97.403 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 70/4776 | Loss: 149.976 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 80/4776 | Loss: 87.413 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 90/4776 | Loss: 97.119 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 100/4776 | Loss: 71.419 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 110/4776 | Loss: 89.710 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 120/4776 | Loss: 105.122 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 130/4776 | Loss: 92.484 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 140/4776 | Loss: 103.077 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 150/4776 | Loss: 45.095 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 160/4776 | Loss: 107.837 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 170/4776 | Loss: 91.144 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 180/4776 | Loss: 93.909 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 190/4776 | Loss: 187.730 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 200/4776 | Loss: 123.519 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 210/4776 | Loss: 139.925 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 220/4776 | Loss: 54.986 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 230/4776 | Loss: 63.003 | Accuracy: 1.000\n",
      "[Epoch: 56/200] - Step: 240/4776 | Loss: 96.448 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 250/4776 | Loss: 86.006 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 260/4776 | Loss: 81.481 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 270/4776 | Loss: 150.403 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 280/4776 | Loss: 91.032 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 290/4776 | Loss: 73.759 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 300/4776 | Loss: 74.539 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 310/4776 | Loss: 129.070 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 320/4776 | Loss: 101.861 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 330/4776 | Loss: 87.589 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 340/4776 | Loss: 95.001 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 350/4776 | Loss: 108.773 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 360/4776 | Loss: 81.229 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 370/4776 | Loss: 110.587 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 380/4776 | Loss: 73.711 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 390/4776 | Loss: 98.540 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 400/4776 | Loss: 75.321 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 410/4776 | Loss: 119.664 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 420/4776 | Loss: 94.640 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 430/4776 | Loss: 71.831 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 440/4776 | Loss: 91.490 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 450/4776 | Loss: 139.900 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 460/4776 | Loss: 177.057 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 470/4776 | Loss: 56.333 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 480/4776 | Loss: 249.346 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 490/4776 | Loss: 95.823 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 500/4776 | Loss: 118.426 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 510/4776 | Loss: 99.900 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 520/4776 | Loss: 140.287 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 530/4776 | Loss: 84.584 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 540/4776 | Loss: 104.188 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 550/4776 | Loss: 105.147 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 560/4776 | Loss: 104.095 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 570/4776 | Loss: 116.576 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 580/4776 | Loss: 217.390 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 590/4776 | Loss: 100.933 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 600/4776 | Loss: 59.243 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 610/4776 | Loss: 122.039 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 620/4776 | Loss: 157.607 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 630/4776 | Loss: 148.262 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 640/4776 | Loss: 112.762 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 650/4776 | Loss: 139.019 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 660/4776 | Loss: 107.906 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 670/4776 | Loss: 70.420 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 680/4776 | Loss: 86.537 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 690/4776 | Loss: 24.449 | Accuracy: 1.000\n",
      "[Epoch: 56/200] - Step: 700/4776 | Loss: 80.825 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 710/4776 | Loss: 80.068 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 720/4776 | Loss: 110.413 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 730/4776 | Loss: 115.423 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 740/4776 | Loss: 109.945 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 750/4776 | Loss: 97.289 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 760/4776 | Loss: 99.762 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 770/4776 | Loss: 108.913 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 780/4776 | Loss: 78.696 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 790/4776 | Loss: 160.740 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 800/4776 | Loss: 135.534 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 810/4776 | Loss: 147.891 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 820/4776 | Loss: 112.781 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 830/4776 | Loss: 86.551 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 840/4776 | Loss: 78.605 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 850/4776 | Loss: 85.383 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 860/4776 | Loss: 201.074 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 870/4776 | Loss: 72.190 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 880/4776 | Loss: 144.193 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 890/4776 | Loss: 153.704 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 900/4776 | Loss: 60.754 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 910/4776 | Loss: 114.052 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 920/4776 | Loss: 61.969 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 930/4776 | Loss: 137.544 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 940/4776 | Loss: 118.784 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 950/4776 | Loss: 99.540 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 960/4776 | Loss: 60.202 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 970/4776 | Loss: 143.465 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 980/4776 | Loss: 76.170 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 990/4776 | Loss: 142.149 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1000/4776 | Loss: 108.568 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1010/4776 | Loss: 112.609 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1020/4776 | Loss: 52.051 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1030/4776 | Loss: 81.366 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1040/4776 | Loss: 80.319 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1050/4776 | Loss: 153.078 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1060/4776 | Loss: 111.176 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1070/4776 | Loss: 133.359 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1080/4776 | Loss: 110.345 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1090/4776 | Loss: 128.185 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1100/4776 | Loss: 82.753 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1110/4776 | Loss: 135.460 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1120/4776 | Loss: 102.520 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1130/4776 | Loss: 87.361 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1140/4776 | Loss: 57.155 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1150/4776 | Loss: 93.648 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1160/4776 | Loss: 112.242 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1170/4776 | Loss: 124.524 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1180/4776 | Loss: 97.850 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1190/4776 | Loss: 87.341 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1200/4776 | Loss: 117.055 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1210/4776 | Loss: 95.512 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1220/4776 | Loss: 97.408 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1230/4776 | Loss: 98.554 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1240/4776 | Loss: 143.033 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1250/4776 | Loss: 100.557 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1260/4776 | Loss: 132.843 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1270/4776 | Loss: 113.889 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1280/4776 | Loss: 156.667 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1290/4776 | Loss: 108.233 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1300/4776 | Loss: 66.052 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1310/4776 | Loss: 106.928 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1320/4776 | Loss: 133.310 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1330/4776 | Loss: 84.095 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1340/4776 | Loss: 59.611 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1350/4776 | Loss: 84.266 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1360/4776 | Loss: 89.317 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1370/4776 | Loss: 112.331 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1380/4776 | Loss: 72.511 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1390/4776 | Loss: 76.964 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1400/4776 | Loss: 131.053 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1410/4776 | Loss: 166.115 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1420/4776 | Loss: 101.234 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1430/4776 | Loss: 144.195 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1440/4776 | Loss: 66.764 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1450/4776 | Loss: 100.232 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1460/4776 | Loss: 65.622 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1470/4776 | Loss: 64.292 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1480/4776 | Loss: 136.850 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1490/4776 | Loss: 146.271 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1500/4776 | Loss: 117.955 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1510/4776 | Loss: 61.336 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1520/4776 | Loss: 156.326 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1530/4776 | Loss: 109.350 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1540/4776 | Loss: 139.857 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1550/4776 | Loss: 114.923 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1560/4776 | Loss: 98.670 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1570/4776 | Loss: 49.756 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1580/4776 | Loss: 132.987 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1590/4776 | Loss: 58.160 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1600/4776 | Loss: 44.995 | Accuracy: 1.000\n",
      "[Epoch: 56/200] - Step: 1610/4776 | Loss: 132.071 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1620/4776 | Loss: 73.605 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1630/4776 | Loss: 107.765 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1640/4776 | Loss: 147.259 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1650/4776 | Loss: 80.720 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1660/4776 | Loss: 21.773 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 1670/4776 | Loss: 100.273 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1680/4776 | Loss: 98.917 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1690/4776 | Loss: 96.694 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1700/4776 | Loss: 113.941 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1710/4776 | Loss: 89.539 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1720/4776 | Loss: 79.319 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1730/4776 | Loss: 118.329 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1740/4776 | Loss: 62.047 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1750/4776 | Loss: 48.558 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1760/4776 | Loss: 116.601 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 1770/4776 | Loss: 117.523 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1780/4776 | Loss: 80.205 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1790/4776 | Loss: 151.191 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1800/4776 | Loss: 118.133 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1810/4776 | Loss: 73.259 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1820/4776 | Loss: 68.393 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1830/4776 | Loss: 121.093 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1840/4776 | Loss: 135.243 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1850/4776 | Loss: 93.914 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1860/4776 | Loss: 88.972 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1870/4776 | Loss: 139.432 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1880/4776 | Loss: 89.110 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1890/4776 | Loss: 95.575 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1900/4776 | Loss: 93.341 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 1910/4776 | Loss: 177.590 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1920/4776 | Loss: 86.877 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1930/4776 | Loss: 81.227 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1940/4776 | Loss: 105.517 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1950/4776 | Loss: 139.917 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1960/4776 | Loss: 93.130 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 1970/4776 | Loss: 108.408 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1980/4776 | Loss: 77.579 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 1990/4776 | Loss: 100.417 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2000/4776 | Loss: 135.410 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2010/4776 | Loss: 123.310 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2020/4776 | Loss: 83.263 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2030/4776 | Loss: 106.445 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2040/4776 | Loss: 98.111 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2050/4776 | Loss: 79.115 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2060/4776 | Loss: 116.202 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2070/4776 | Loss: 87.820 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2080/4776 | Loss: 72.052 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2090/4776 | Loss: 134.387 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2100/4776 | Loss: 52.354 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 2110/4776 | Loss: 112.879 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2120/4776 | Loss: 121.032 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2130/4776 | Loss: 55.783 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2140/4776 | Loss: 94.875 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2150/4776 | Loss: 59.777 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2160/4776 | Loss: 53.641 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2170/4776 | Loss: 91.021 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2180/4776 | Loss: 130.486 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2190/4776 | Loss: 98.091 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2200/4776 | Loss: 123.269 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2210/4776 | Loss: 96.491 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2220/4776 | Loss: 151.986 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2230/4776 | Loss: 48.864 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2240/4776 | Loss: 127.924 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2250/4776 | Loss: 121.373 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 2260/4776 | Loss: 88.674 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2270/4776 | Loss: 143.046 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2280/4776 | Loss: 106.666 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2290/4776 | Loss: 92.991 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2300/4776 | Loss: 78.332 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2310/4776 | Loss: 163.237 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2320/4776 | Loss: 152.851 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 2330/4776 | Loss: 94.264 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2340/4776 | Loss: 146.105 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 2350/4776 | Loss: 59.633 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2360/4776 | Loss: 105.532 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2370/4776 | Loss: 127.004 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2380/4776 | Loss: 95.348 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2390/4776 | Loss: 106.052 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2400/4776 | Loss: 79.013 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2410/4776 | Loss: 138.537 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2420/4776 | Loss: 92.138 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2430/4776 | Loss: 201.541 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2440/4776 | Loss: 106.154 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2450/4776 | Loss: 90.007 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2460/4776 | Loss: 102.739 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2470/4776 | Loss: 75.482 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2480/4776 | Loss: 150.900 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2490/4776 | Loss: 79.838 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2500/4776 | Loss: 112.010 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2510/4776 | Loss: 122.213 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2520/4776 | Loss: 78.606 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2530/4776 | Loss: 104.154 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2540/4776 | Loss: 138.192 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2550/4776 | Loss: 114.123 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2560/4776 | Loss: 104.243 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2570/4776 | Loss: 101.828 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2580/4776 | Loss: 95.936 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2590/4776 | Loss: 134.623 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 2600/4776 | Loss: 77.181 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2610/4776 | Loss: 306.012 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 2620/4776 | Loss: 147.776 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 2630/4776 | Loss: 130.726 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2640/4776 | Loss: 235.926 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2650/4776 | Loss: 95.504 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2660/4776 | Loss: 95.720 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2670/4776 | Loss: 60.040 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2680/4776 | Loss: 123.899 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2690/4776 | Loss: 101.090 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2700/4776 | Loss: 110.654 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2710/4776 | Loss: 90.932 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2720/4776 | Loss: 89.892 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2730/4776 | Loss: 74.033 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2740/4776 | Loss: 112.194 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2750/4776 | Loss: 154.851 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2760/4776 | Loss: 104.471 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2770/4776 | Loss: 142.850 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2780/4776 | Loss: 126.525 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2790/4776 | Loss: 115.969 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2800/4776 | Loss: 133.975 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2810/4776 | Loss: 60.513 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 2820/4776 | Loss: 58.749 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2830/4776 | Loss: 91.314 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2840/4776 | Loss: 53.411 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2850/4776 | Loss: 126.776 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2860/4776 | Loss: 57.672 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2870/4776 | Loss: 70.242 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2880/4776 | Loss: 107.307 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2890/4776 | Loss: 138.259 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2900/4776 | Loss: 155.480 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2910/4776 | Loss: 119.371 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 2920/4776 | Loss: 98.864 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2930/4776 | Loss: 86.681 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2940/4776 | Loss: 68.296 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 2950/4776 | Loss: 90.136 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 2960/4776 | Loss: 91.486 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2970/4776 | Loss: 89.116 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 2980/4776 | Loss: 94.252 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 2990/4776 | Loss: 87.600 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3000/4776 | Loss: 125.136 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3010/4776 | Loss: 119.561 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3020/4776 | Loss: 150.699 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3030/4776 | Loss: 66.339 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3040/4776 | Loss: 97.064 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3050/4776 | Loss: 100.849 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3060/4776 | Loss: 73.913 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3070/4776 | Loss: 100.265 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3080/4776 | Loss: 95.460 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3090/4776 | Loss: 160.134 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 3100/4776 | Loss: 79.573 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3110/4776 | Loss: 125.372 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3120/4776 | Loss: 79.029 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3130/4776 | Loss: 112.768 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3140/4776 | Loss: 119.964 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3150/4776 | Loss: 140.201 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3160/4776 | Loss: 85.020 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3170/4776 | Loss: 157.888 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 3180/4776 | Loss: 109.674 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3190/4776 | Loss: 69.474 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3200/4776 | Loss: 116.716 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3210/4776 | Loss: 94.874 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3220/4776 | Loss: 90.030 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3230/4776 | Loss: 132.603 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3240/4776 | Loss: 127.496 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3250/4776 | Loss: 62.815 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 3260/4776 | Loss: 113.552 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3270/4776 | Loss: 131.314 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3280/4776 | Loss: 88.710 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3290/4776 | Loss: 77.794 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3300/4776 | Loss: 180.743 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3310/4776 | Loss: 148.392 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 3320/4776 | Loss: 76.689 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3330/4776 | Loss: 98.056 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3340/4776 | Loss: 101.796 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3350/4776 | Loss: 103.279 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3360/4776 | Loss: 123.472 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 3370/4776 | Loss: 101.171 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3380/4776 | Loss: 83.485 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3390/4776 | Loss: 112.102 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3400/4776 | Loss: 157.970 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 3410/4776 | Loss: 93.590 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3420/4776 | Loss: 59.555 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3430/4776 | Loss: 114.195 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3440/4776 | Loss: 112.740 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3450/4776 | Loss: 147.694 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3460/4776 | Loss: 101.373 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3470/4776 | Loss: 165.211 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3480/4776 | Loss: 162.474 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 3490/4776 | Loss: 86.928 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3500/4776 | Loss: 76.606 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3510/4776 | Loss: 129.277 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3520/4776 | Loss: 104.751 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3530/4776 | Loss: 61.332 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3540/4776 | Loss: 147.488 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3550/4776 | Loss: 79.302 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3560/4776 | Loss: 72.627 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3570/4776 | Loss: 135.835 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3580/4776 | Loss: 88.646 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3590/4776 | Loss: 66.105 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3600/4776 | Loss: 123.161 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3610/4776 | Loss: 170.746 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3620/4776 | Loss: 93.478 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3630/4776 | Loss: 67.289 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3640/4776 | Loss: 105.646 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3650/4776 | Loss: 89.892 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3660/4776 | Loss: 107.611 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3670/4776 | Loss: 76.689 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3680/4776 | Loss: 122.933 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3690/4776 | Loss: 100.380 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3700/4776 | Loss: 90.698 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3710/4776 | Loss: 143.561 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3720/4776 | Loss: 146.417 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3730/4776 | Loss: 122.992 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3740/4776 | Loss: 162.782 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3750/4776 | Loss: 163.048 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3760/4776 | Loss: 105.860 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3770/4776 | Loss: 230.883 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 3780/4776 | Loss: 134.481 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 3790/4776 | Loss: 87.951 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3800/4776 | Loss: 128.264 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 3810/4776 | Loss: 88.326 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3820/4776 | Loss: 63.795 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3830/4776 | Loss: 62.090 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3840/4776 | Loss: 105.453 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3850/4776 | Loss: 165.560 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3860/4776 | Loss: 153.968 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 3870/4776 | Loss: 160.235 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3880/4776 | Loss: 117.660 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3890/4776 | Loss: 130.296 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3900/4776 | Loss: 93.066 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3910/4776 | Loss: 113.454 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 3920/4776 | Loss: 118.353 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 3930/4776 | Loss: 90.745 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3940/4776 | Loss: 86.931 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3950/4776 | Loss: 65.482 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3960/4776 | Loss: 109.422 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3970/4776 | Loss: 61.836 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 3980/4776 | Loss: 157.932 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 3990/4776 | Loss: 104.579 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4000/4776 | Loss: 104.004 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4010/4776 | Loss: 115.962 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4020/4776 | Loss: 104.566 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4030/4776 | Loss: 79.086 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4040/4776 | Loss: 79.775 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4050/4776 | Loss: 70.122 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4060/4776 | Loss: 84.956 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4070/4776 | Loss: 80.527 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4080/4776 | Loss: 89.292 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4090/4776 | Loss: 65.647 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4100/4776 | Loss: 42.594 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 4110/4776 | Loss: 160.874 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4120/4776 | Loss: 108.813 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4130/4776 | Loss: 42.802 | Accuracy: 1.000\n",
      "[Epoch: 56/200] - Step: 4140/4776 | Loss: 40.426 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 4150/4776 | Loss: 130.045 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4160/4776 | Loss: 94.500 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4170/4776 | Loss: 119.423 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4180/4776 | Loss: 104.025 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4190/4776 | Loss: 93.127 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4200/4776 | Loss: 115.912 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4210/4776 | Loss: 67.178 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4220/4776 | Loss: 89.606 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4230/4776 | Loss: 83.912 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4240/4776 | Loss: 73.393 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4250/4776 | Loss: 61.854 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4260/4776 | Loss: 124.602 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4270/4776 | Loss: 80.904 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4280/4776 | Loss: 129.581 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4290/4776 | Loss: 111.950 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4300/4776 | Loss: 132.738 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4310/4776 | Loss: 157.767 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4320/4776 | Loss: 76.748 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4330/4776 | Loss: 102.249 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4340/4776 | Loss: 122.933 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4350/4776 | Loss: 124.110 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4360/4776 | Loss: 115.228 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4370/4776 | Loss: 63.566 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 4380/4776 | Loss: 116.916 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4390/4776 | Loss: 95.202 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4400/4776 | Loss: 97.966 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4410/4776 | Loss: 71.843 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4420/4776 | Loss: 113.095 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4430/4776 | Loss: 65.804 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4440/4776 | Loss: 118.830 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4450/4776 | Loss: 114.603 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4460/4776 | Loss: 116.377 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4470/4776 | Loss: 62.591 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4480/4776 | Loss: 97.280 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4490/4776 | Loss: 79.893 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4500/4776 | Loss: 40.878 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 4510/4776 | Loss: 82.705 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4520/4776 | Loss: 63.681 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4530/4776 | Loss: 106.843 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4540/4776 | Loss: 62.178 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4550/4776 | Loss: 69.007 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4560/4776 | Loss: 112.622 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4570/4776 | Loss: 112.527 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4580/4776 | Loss: 151.060 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4590/4776 | Loss: 101.252 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4600/4776 | Loss: 41.195 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4610/4776 | Loss: 76.509 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4620/4776 | Loss: 87.450 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4630/4776 | Loss: 82.107 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4640/4776 | Loss: 145.673 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4650/4776 | Loss: 114.825 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4660/4776 | Loss: 104.766 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4670/4776 | Loss: 95.107 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4680/4776 | Loss: 52.861 | Accuracy: 0.800\n",
      "[Epoch: 56/200] - Step: 4690/4776 | Loss: 64.787 | Accuracy: 0.900\n",
      "[Epoch: 56/200] - Step: 4700/4776 | Loss: 161.200 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4710/4776 | Loss: 177.767 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 4720/4776 | Loss: 135.517 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4730/4776 | Loss: 87.077 | Accuracy: 0.600\n",
      "[Epoch: 56/200] - Step: 4740/4776 | Loss: 106.408 | Accuracy: 0.700\n",
      "[Epoch: 56/200] - Step: 4750/4776 | Loss: 101.906 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 4760/4776 | Loss: 146.776 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 4770/4776 | Loss: 95.251 | Accuracy: 0.600\n",
      "Accuracy:  0.1885245901639344\n",
      "[Epoch: 57/200] - Step: 10/4776 | Loss: 67.372 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 20/4776 | Loss: 106.121 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 30/4776 | Loss: 96.757 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 40/4776 | Loss: 118.251 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 50/4776 | Loss: 111.174 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 60/4776 | Loss: 85.014 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 70/4776 | Loss: 64.960 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 80/4776 | Loss: 85.551 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 90/4776 | Loss: 97.342 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 100/4776 | Loss: 90.710 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 110/4776 | Loss: 64.693 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 120/4776 | Loss: 134.435 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 130/4776 | Loss: 163.258 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 140/4776 | Loss: 96.820 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 150/4776 | Loss: 99.728 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 160/4776 | Loss: 94.798 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 170/4776 | Loss: 85.675 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 180/4776 | Loss: 99.244 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 190/4776 | Loss: 56.029 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 200/4776 | Loss: 46.519 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 210/4776 | Loss: 122.406 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 220/4776 | Loss: 108.095 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 230/4776 | Loss: 140.903 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 240/4776 | Loss: 95.724 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 250/4776 | Loss: 96.183 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 260/4776 | Loss: 75.768 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 270/4776 | Loss: 66.104 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 280/4776 | Loss: 95.510 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 290/4776 | Loss: 106.115 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 300/4776 | Loss: 76.652 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 310/4776 | Loss: 67.021 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 320/4776 | Loss: 119.348 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 330/4776 | Loss: 140.042 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 340/4776 | Loss: 122.505 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 350/4776 | Loss: 102.770 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 360/4776 | Loss: 111.905 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 370/4776 | Loss: 66.537 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 380/4776 | Loss: 179.225 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 390/4776 | Loss: 61.860 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 400/4776 | Loss: 85.181 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 410/4776 | Loss: 140.706 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 420/4776 | Loss: 146.129 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 430/4776 | Loss: 115.774 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 440/4776 | Loss: 97.983 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 450/4776 | Loss: 105.635 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 460/4776 | Loss: 163.528 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 470/4776 | Loss: 149.402 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 480/4776 | Loss: 133.741 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 490/4776 | Loss: 107.312 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 500/4776 | Loss: 142.885 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 510/4776 | Loss: 75.889 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 520/4776 | Loss: 91.791 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 530/4776 | Loss: 71.980 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 540/4776 | Loss: 156.792 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 550/4776 | Loss: 104.926 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 560/4776 | Loss: 59.207 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 570/4776 | Loss: 100.681 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 580/4776 | Loss: 215.020 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 590/4776 | Loss: 91.162 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 600/4776 | Loss: 86.479 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 610/4776 | Loss: 144.358 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 620/4776 | Loss: 82.552 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 630/4776 | Loss: 60.009 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 640/4776 | Loss: 100.906 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 650/4776 | Loss: 74.363 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 660/4776 | Loss: 83.707 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 670/4776 | Loss: 120.488 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 680/4776 | Loss: 141.893 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 690/4776 | Loss: 127.051 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 700/4776 | Loss: 188.646 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 710/4776 | Loss: 107.520 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 720/4776 | Loss: 92.042 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 730/4776 | Loss: 97.670 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 740/4776 | Loss: 114.923 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 750/4776 | Loss: 85.428 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 760/4776 | Loss: 116.211 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 770/4776 | Loss: 116.633 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 780/4776 | Loss: 60.737 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 790/4776 | Loss: 61.635 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 800/4776 | Loss: 110.944 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 810/4776 | Loss: 82.006 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 820/4776 | Loss: 87.933 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 830/4776 | Loss: 119.489 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 840/4776 | Loss: 84.724 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 850/4776 | Loss: 126.646 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 860/4776 | Loss: 76.986 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 870/4776 | Loss: 164.923 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 880/4776 | Loss: 108.467 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 890/4776 | Loss: 118.176 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 900/4776 | Loss: 82.746 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 910/4776 | Loss: 129.063 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 920/4776 | Loss: 107.217 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 930/4776 | Loss: 102.495 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 940/4776 | Loss: 134.475 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 950/4776 | Loss: 142.042 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 960/4776 | Loss: 67.037 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 970/4776 | Loss: 113.732 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 980/4776 | Loss: 158.851 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 990/4776 | Loss: 165.868 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1000/4776 | Loss: 61.743 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 1010/4776 | Loss: 70.460 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1020/4776 | Loss: 66.833 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 1030/4776 | Loss: 168.849 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1040/4776 | Loss: 90.441 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1050/4776 | Loss: 56.136 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 1060/4776 | Loss: 75.826 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1070/4776 | Loss: 127.056 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1080/4776 | Loss: 121.255 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1090/4776 | Loss: 109.694 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1100/4776 | Loss: 126.370 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1110/4776 | Loss: 104.392 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1120/4776 | Loss: 95.348 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1130/4776 | Loss: 82.895 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1140/4776 | Loss: 115.767 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1150/4776 | Loss: 51.713 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 1160/4776 | Loss: 73.636 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1170/4776 | Loss: 124.174 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1180/4776 | Loss: 112.103 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1190/4776 | Loss: 127.896 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1200/4776 | Loss: 129.445 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1210/4776 | Loss: 114.774 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1220/4776 | Loss: 89.848 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1230/4776 | Loss: 101.041 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1240/4776 | Loss: 147.113 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1250/4776 | Loss: 59.960 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1260/4776 | Loss: 39.533 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 1270/4776 | Loss: 81.406 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1280/4776 | Loss: 187.079 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1290/4776 | Loss: 125.388 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1300/4776 | Loss: 101.355 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1310/4776 | Loss: 90.635 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1320/4776 | Loss: 92.090 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1330/4776 | Loss: 165.503 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1340/4776 | Loss: 114.439 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1350/4776 | Loss: 93.727 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1360/4776 | Loss: 74.741 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1370/4776 | Loss: 94.254 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1380/4776 | Loss: 100.609 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1390/4776 | Loss: 116.211 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1400/4776 | Loss: 89.509 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1410/4776 | Loss: 125.873 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1420/4776 | Loss: 134.473 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1430/4776 | Loss: 102.769 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1440/4776 | Loss: 89.544 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1450/4776 | Loss: 35.991 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 1460/4776 | Loss: 131.578 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1470/4776 | Loss: 150.649 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1480/4776 | Loss: 156.428 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1490/4776 | Loss: 65.278 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 1500/4776 | Loss: 80.834 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1510/4776 | Loss: 108.933 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1520/4776 | Loss: 75.626 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1530/4776 | Loss: 96.628 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1540/4776 | Loss: 122.241 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1550/4776 | Loss: 120.390 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1560/4776 | Loss: 79.165 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1570/4776 | Loss: 97.618 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1580/4776 | Loss: 133.529 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1590/4776 | Loss: 105.662 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1600/4776 | Loss: 69.722 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1610/4776 | Loss: 128.963 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1620/4776 | Loss: 132.991 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1630/4776 | Loss: 73.150 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1640/4776 | Loss: 88.530 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1650/4776 | Loss: 70.751 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1660/4776 | Loss: 56.906 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1670/4776 | Loss: 69.102 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1680/4776 | Loss: 135.054 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1690/4776 | Loss: 139.197 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1700/4776 | Loss: 119.631 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1710/4776 | Loss: 105.400 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1720/4776 | Loss: 147.949 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1730/4776 | Loss: 152.776 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1740/4776 | Loss: 114.425 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1750/4776 | Loss: 115.427 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1760/4776 | Loss: 41.414 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1770/4776 | Loss: 148.937 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1780/4776 | Loss: 64.441 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 1790/4776 | Loss: 114.755 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1800/4776 | Loss: 123.278 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1810/4776 | Loss: 79.169 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1820/4776 | Loss: 144.996 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1830/4776 | Loss: 96.409 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 1840/4776 | Loss: 63.938 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1850/4776 | Loss: 84.618 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1860/4776 | Loss: 119.976 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1870/4776 | Loss: 55.187 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1880/4776 | Loss: 100.564 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1890/4776 | Loss: 74.808 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 1900/4776 | Loss: 172.994 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 1910/4776 | Loss: 141.449 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1920/4776 | Loss: 93.953 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1930/4776 | Loss: 122.470 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1940/4776 | Loss: 114.071 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1950/4776 | Loss: 129.500 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1960/4776 | Loss: 76.678 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1970/4776 | Loss: 81.205 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 1980/4776 | Loss: 102.485 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 1990/4776 | Loss: 105.254 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2000/4776 | Loss: 133.472 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2010/4776 | Loss: 79.676 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2020/4776 | Loss: 54.925 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 2030/4776 | Loss: 162.436 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 2040/4776 | Loss: 97.598 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2050/4776 | Loss: 54.854 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 2060/4776 | Loss: 81.110 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2070/4776 | Loss: 103.149 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2080/4776 | Loss: 78.107 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2090/4776 | Loss: 54.084 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2100/4776 | Loss: 89.422 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2110/4776 | Loss: 87.152 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2120/4776 | Loss: 54.106 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2130/4776 | Loss: 109.185 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2140/4776 | Loss: 87.085 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2150/4776 | Loss: 143.658 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2160/4776 | Loss: 142.956 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2170/4776 | Loss: 79.169 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2180/4776 | Loss: 133.222 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 2190/4776 | Loss: 190.942 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 2200/4776 | Loss: 89.756 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2210/4776 | Loss: 125.048 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2220/4776 | Loss: 133.420 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2230/4776 | Loss: 131.605 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2240/4776 | Loss: 90.487 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2250/4776 | Loss: 138.664 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2260/4776 | Loss: 115.535 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2270/4776 | Loss: 116.235 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2280/4776 | Loss: 75.432 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2290/4776 | Loss: 113.465 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2300/4776 | Loss: 91.251 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2310/4776 | Loss: 128.745 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2320/4776 | Loss: 139.686 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2330/4776 | Loss: 101.134 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2340/4776 | Loss: 100.988 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2350/4776 | Loss: 123.403 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2360/4776 | Loss: 183.742 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2370/4776 | Loss: 132.337 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2380/4776 | Loss: 179.698 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 2390/4776 | Loss: 78.800 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2400/4776 | Loss: 138.586 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 2410/4776 | Loss: 106.427 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2420/4776 | Loss: 118.477 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2430/4776 | Loss: 120.730 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 2440/4776 | Loss: 53.603 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2450/4776 | Loss: 118.110 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2460/4776 | Loss: 121.544 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2470/4776 | Loss: 92.063 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2480/4776 | Loss: 53.278 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2490/4776 | Loss: 113.955 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2500/4776 | Loss: 136.693 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2510/4776 | Loss: 105.873 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2520/4776 | Loss: 68.932 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2530/4776 | Loss: 66.920 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2540/4776 | Loss: 79.336 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2550/4776 | Loss: 99.118 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2560/4776 | Loss: 66.523 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2570/4776 | Loss: 105.920 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2580/4776 | Loss: 44.056 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 2590/4776 | Loss: 44.802 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 2600/4776 | Loss: 107.675 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2610/4776 | Loss: 82.508 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2620/4776 | Loss: 142.898 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2630/4776 | Loss: 119.448 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2640/4776 | Loss: 81.709 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2650/4776 | Loss: 74.953 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2660/4776 | Loss: 93.440 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2670/4776 | Loss: 144.330 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2680/4776 | Loss: 92.852 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2690/4776 | Loss: 81.293 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2700/4776 | Loss: 39.887 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 2710/4776 | Loss: 111.386 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2720/4776 | Loss: 97.729 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2730/4776 | Loss: 90.661 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2740/4776 | Loss: 45.088 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2750/4776 | Loss: 64.243 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2760/4776 | Loss: 133.275 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2770/4776 | Loss: 105.248 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2780/4776 | Loss: 104.809 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2790/4776 | Loss: 57.799 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2800/4776 | Loss: 118.014 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2810/4776 | Loss: 84.838 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2820/4776 | Loss: 92.623 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2830/4776 | Loss: 131.005 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2840/4776 | Loss: 76.491 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2850/4776 | Loss: 125.428 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2860/4776 | Loss: 89.410 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2870/4776 | Loss: 217.026 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2880/4776 | Loss: 93.115 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2890/4776 | Loss: 70.380 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 2900/4776 | Loss: 169.227 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2910/4776 | Loss: 127.051 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 2920/4776 | Loss: 87.460 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2930/4776 | Loss: 89.118 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2940/4776 | Loss: 77.059 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2950/4776 | Loss: 102.384 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 2960/4776 | Loss: 46.984 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 2970/4776 | Loss: 103.139 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2980/4776 | Loss: 138.567 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 2990/4776 | Loss: 73.834 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3000/4776 | Loss: 98.860 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3010/4776 | Loss: 66.140 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3020/4776 | Loss: 137.950 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3030/4776 | Loss: 135.567 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3040/4776 | Loss: 163.511 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3050/4776 | Loss: 178.859 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3060/4776 | Loss: 132.661 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3070/4776 | Loss: 89.934 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3080/4776 | Loss: 71.140 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3090/4776 | Loss: 137.456 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3100/4776 | Loss: 162.932 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3110/4776 | Loss: 201.465 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3120/4776 | Loss: 70.330 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3130/4776 | Loss: 132.037 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3140/4776 | Loss: 109.171 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3150/4776 | Loss: 90.205 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3160/4776 | Loss: 83.525 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3170/4776 | Loss: 127.354 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3180/4776 | Loss: 100.606 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3190/4776 | Loss: 110.871 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3200/4776 | Loss: 112.769 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3210/4776 | Loss: 108.029 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3220/4776 | Loss: 121.312 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3230/4776 | Loss: 59.859 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3240/4776 | Loss: 66.083 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3250/4776 | Loss: 76.993 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3260/4776 | Loss: 59.570 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3270/4776 | Loss: 103.450 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3280/4776 | Loss: 110.476 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3290/4776 | Loss: 116.914 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3300/4776 | Loss: 75.378 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3310/4776 | Loss: 104.608 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3320/4776 | Loss: 70.708 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3330/4776 | Loss: 80.206 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3340/4776 | Loss: 109.188 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3350/4776 | Loss: 74.362 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3360/4776 | Loss: 98.099 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3370/4776 | Loss: 69.134 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3380/4776 | Loss: 238.118 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 3390/4776 | Loss: 89.431 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3400/4776 | Loss: 113.016 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3410/4776 | Loss: 115.373 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3420/4776 | Loss: 88.976 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3430/4776 | Loss: 72.760 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3440/4776 | Loss: 107.000 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3450/4776 | Loss: 92.189 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3460/4776 | Loss: 76.853 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3470/4776 | Loss: 148.998 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 3480/4776 | Loss: 102.008 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3490/4776 | Loss: 126.658 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3500/4776 | Loss: 112.634 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3510/4776 | Loss: 130.882 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3520/4776 | Loss: 66.754 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3530/4776 | Loss: 152.599 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3540/4776 | Loss: 63.159 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3550/4776 | Loss: 66.563 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 3560/4776 | Loss: 149.008 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3570/4776 | Loss: 97.976 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3580/4776 | Loss: 92.478 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3590/4776 | Loss: 112.350 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3600/4776 | Loss: 128.060 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3610/4776 | Loss: 120.162 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3620/4776 | Loss: 118.249 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3630/4776 | Loss: 64.147 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3640/4776 | Loss: 118.185 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3650/4776 | Loss: 58.487 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 3660/4776 | Loss: 122.798 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3670/4776 | Loss: 115.957 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3680/4776 | Loss: 127.934 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3690/4776 | Loss: 123.768 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3700/4776 | Loss: 45.231 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3710/4776 | Loss: 119.518 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3720/4776 | Loss: 105.426 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3730/4776 | Loss: 90.022 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3740/4776 | Loss: 71.168 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3750/4776 | Loss: 145.770 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3760/4776 | Loss: 123.830 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3770/4776 | Loss: 120.159 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3780/4776 | Loss: 132.332 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3790/4776 | Loss: 89.580 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3800/4776 | Loss: 57.621 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3810/4776 | Loss: 112.883 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3820/4776 | Loss: 173.250 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3830/4776 | Loss: 94.332 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3840/4776 | Loss: 114.888 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3850/4776 | Loss: 85.095 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3860/4776 | Loss: 65.869 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 3870/4776 | Loss: 111.743 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3880/4776 | Loss: 105.213 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3890/4776 | Loss: 90.277 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 3900/4776 | Loss: 78.882 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3910/4776 | Loss: 100.438 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3920/4776 | Loss: 104.062 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 3930/4776 | Loss: 136.783 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3940/4776 | Loss: 93.610 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3950/4776 | Loss: 114.253 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 3960/4776 | Loss: 32.665 | Accuracy: 1.000\n",
      "[Epoch: 57/200] - Step: 3970/4776 | Loss: 135.042 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 3980/4776 | Loss: 126.663 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 3990/4776 | Loss: 101.013 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4000/4776 | Loss: 97.444 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4010/4776 | Loss: 108.530 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4020/4776 | Loss: 126.043 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4030/4776 | Loss: 111.255 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4040/4776 | Loss: 69.358 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4050/4776 | Loss: 131.585 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4060/4776 | Loss: 97.848 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4070/4776 | Loss: 254.957 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 4080/4776 | Loss: 147.962 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4090/4776 | Loss: 63.317 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4100/4776 | Loss: 66.240 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4110/4776 | Loss: 105.552 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4120/4776 | Loss: 117.851 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4130/4776 | Loss: 119.163 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4140/4776 | Loss: 95.654 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4150/4776 | Loss: 75.489 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4160/4776 | Loss: 134.101 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 4170/4776 | Loss: 129.878 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4180/4776 | Loss: 182.224 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4190/4776 | Loss: 115.752 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4200/4776 | Loss: 76.828 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4210/4776 | Loss: 92.995 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4220/4776 | Loss: 83.772 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4230/4776 | Loss: 61.727 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 4240/4776 | Loss: 92.981 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4250/4776 | Loss: 140.698 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4260/4776 | Loss: 74.391 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 4270/4776 | Loss: 57.173 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 4280/4776 | Loss: 121.139 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4290/4776 | Loss: 84.916 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4300/4776 | Loss: 101.206 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4310/4776 | Loss: 90.444 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4320/4776 | Loss: 79.254 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4330/4776 | Loss: 63.182 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4340/4776 | Loss: 90.103 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4350/4776 | Loss: 64.066 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4360/4776 | Loss: 73.363 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4370/4776 | Loss: 107.353 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4380/4776 | Loss: 30.664 | Accuracy: 0.900\n",
      "[Epoch: 57/200] - Step: 4390/4776 | Loss: 138.992 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4400/4776 | Loss: 137.649 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4410/4776 | Loss: 104.879 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4420/4776 | Loss: 64.745 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4430/4776 | Loss: 78.446 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4440/4776 | Loss: 161.624 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 4450/4776 | Loss: 83.838 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4460/4776 | Loss: 79.068 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4470/4776 | Loss: 167.054 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 4480/4776 | Loss: 70.231 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4490/4776 | Loss: 165.161 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4500/4776 | Loss: 60.058 | Accuracy: 0.800\n",
      "[Epoch: 57/200] - Step: 4510/4776 | Loss: 127.560 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4520/4776 | Loss: 129.839 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4530/4776 | Loss: 76.518 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4540/4776 | Loss: 113.639 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4550/4776 | Loss: 116.063 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4560/4776 | Loss: 93.758 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4570/4776 | Loss: 61.713 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4580/4776 | Loss: 89.760 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4590/4776 | Loss: 106.063 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4600/4776 | Loss: 72.100 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4610/4776 | Loss: 88.961 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4620/4776 | Loss: 89.043 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4630/4776 | Loss: 85.345 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4640/4776 | Loss: 77.744 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4650/4776 | Loss: 82.738 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4660/4776 | Loss: 128.689 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 4670/4776 | Loss: 148.029 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 4680/4776 | Loss: 90.772 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4690/4776 | Loss: 136.066 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 4700/4776 | Loss: 92.414 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4710/4776 | Loss: 148.355 | Accuracy: 0.600\n",
      "[Epoch: 57/200] - Step: 4720/4776 | Loss: 117.520 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4730/4776 | Loss: 165.442 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 4740/4776 | Loss: 76.303 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4750/4776 | Loss: 81.008 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4760/4776 | Loss: 109.429 | Accuracy: 0.700\n",
      "[Epoch: 57/200] - Step: 4770/4776 | Loss: 130.396 | Accuracy: 0.300\n",
      "Accuracy:  0.19508196721311474\n",
      "[Epoch: 58/200] - Step: 10/4776 | Loss: 80.114 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 20/4776 | Loss: 114.577 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 30/4776 | Loss: 114.532 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 40/4776 | Loss: 87.693 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 50/4776 | Loss: 182.836 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 60/4776 | Loss: 70.095 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 70/4776 | Loss: 131.984 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 80/4776 | Loss: 99.655 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 90/4776 | Loss: 114.620 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 100/4776 | Loss: 99.002 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 110/4776 | Loss: 81.506 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 120/4776 | Loss: 93.910 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 130/4776 | Loss: 142.400 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 140/4776 | Loss: 114.822 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 150/4776 | Loss: 117.490 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 160/4776 | Loss: 85.121 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 170/4776 | Loss: 100.451 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 180/4776 | Loss: 123.087 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 190/4776 | Loss: 117.003 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 200/4776 | Loss: 102.004 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 210/4776 | Loss: 76.020 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 220/4776 | Loss: 85.204 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 230/4776 | Loss: 115.922 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 240/4776 | Loss: 109.841 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 250/4776 | Loss: 72.508 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 260/4776 | Loss: 75.596 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 270/4776 | Loss: 107.379 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 280/4776 | Loss: 73.081 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 290/4776 | Loss: 67.300 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 300/4776 | Loss: 94.824 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 310/4776 | Loss: 70.019 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 320/4776 | Loss: 54.931 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 330/4776 | Loss: 107.005 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 340/4776 | Loss: 65.345 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 350/4776 | Loss: 71.665 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 360/4776 | Loss: 106.654 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 370/4776 | Loss: 94.444 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 380/4776 | Loss: 142.635 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 390/4776 | Loss: 100.809 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 400/4776 | Loss: 73.764 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 410/4776 | Loss: 76.591 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 420/4776 | Loss: 104.718 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 430/4776 | Loss: 127.711 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 440/4776 | Loss: 184.965 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 450/4776 | Loss: 153.526 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 460/4776 | Loss: 119.057 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 470/4776 | Loss: 106.715 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 480/4776 | Loss: 117.544 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 490/4776 | Loss: 166.197 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 500/4776 | Loss: 92.955 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 510/4776 | Loss: 91.182 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 520/4776 | Loss: 59.051 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 530/4776 | Loss: 77.971 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 540/4776 | Loss: 97.122 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 550/4776 | Loss: 93.857 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 560/4776 | Loss: 88.808 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 570/4776 | Loss: 104.845 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 580/4776 | Loss: 64.765 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 590/4776 | Loss: 91.077 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 600/4776 | Loss: 47.992 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 610/4776 | Loss: 96.290 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 620/4776 | Loss: 126.258 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 630/4776 | Loss: 61.619 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 640/4776 | Loss: 69.385 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 650/4776 | Loss: 140.980 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 660/4776 | Loss: 77.225 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 670/4776 | Loss: 160.741 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 680/4776 | Loss: 99.448 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 690/4776 | Loss: 166.035 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 700/4776 | Loss: 144.390 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 710/4776 | Loss: 115.377 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 720/4776 | Loss: 115.376 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 730/4776 | Loss: 117.193 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 740/4776 | Loss: 89.281 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 750/4776 | Loss: 99.178 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 760/4776 | Loss: 81.737 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 770/4776 | Loss: 63.543 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 780/4776 | Loss: 85.945 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 790/4776 | Loss: 103.313 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 800/4776 | Loss: 94.851 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 810/4776 | Loss: 116.551 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 820/4776 | Loss: 90.908 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 830/4776 | Loss: 87.430 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 840/4776 | Loss: 101.259 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 850/4776 | Loss: 147.413 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 860/4776 | Loss: 97.700 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 870/4776 | Loss: 55.431 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 880/4776 | Loss: 106.657 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 890/4776 | Loss: 73.083 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 900/4776 | Loss: 101.542 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 910/4776 | Loss: 85.292 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 920/4776 | Loss: 73.141 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 930/4776 | Loss: 121.336 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 940/4776 | Loss: 78.812 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 950/4776 | Loss: 112.592 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 960/4776 | Loss: 107.519 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 970/4776 | Loss: 136.713 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 980/4776 | Loss: 126.322 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 990/4776 | Loss: 119.237 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1000/4776 | Loss: 95.925 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1010/4776 | Loss: 178.866 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1020/4776 | Loss: 78.722 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1030/4776 | Loss: 123.128 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1040/4776 | Loss: 47.415 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1050/4776 | Loss: 169.051 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1060/4776 | Loss: 106.884 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1070/4776 | Loss: 120.561 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1080/4776 | Loss: 87.397 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1090/4776 | Loss: 102.689 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1100/4776 | Loss: 163.615 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1110/4776 | Loss: 80.690 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1120/4776 | Loss: 44.457 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1130/4776 | Loss: 87.199 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1140/4776 | Loss: 105.489 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1150/4776 | Loss: 158.089 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1160/4776 | Loss: 123.178 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1170/4776 | Loss: 172.625 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1180/4776 | Loss: 79.119 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1190/4776 | Loss: 96.777 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1200/4776 | Loss: 112.929 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1210/4776 | Loss: 65.578 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1220/4776 | Loss: 87.831 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1230/4776 | Loss: 112.995 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1240/4776 | Loss: 143.833 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 1250/4776 | Loss: 120.052 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1260/4776 | Loss: 99.070 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1270/4776 | Loss: 77.132 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1280/4776 | Loss: 87.726 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1290/4776 | Loss: 72.850 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1300/4776 | Loss: 80.022 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1310/4776 | Loss: 133.109 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1320/4776 | Loss: 113.638 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1330/4776 | Loss: 125.148 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1340/4776 | Loss: 78.171 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1350/4776 | Loss: 31.903 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1360/4776 | Loss: 90.484 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1370/4776 | Loss: 87.999 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1380/4776 | Loss: 84.301 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1390/4776 | Loss: 68.956 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1400/4776 | Loss: 85.468 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1410/4776 | Loss: 107.176 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1420/4776 | Loss: 93.812 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1430/4776 | Loss: 120.628 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1440/4776 | Loss: 89.827 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1450/4776 | Loss: 86.061 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1460/4776 | Loss: 70.969 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1470/4776 | Loss: 62.675 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1480/4776 | Loss: 116.844 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1490/4776 | Loss: 84.516 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1500/4776 | Loss: 108.478 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1510/4776 | Loss: 65.275 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1520/4776 | Loss: 90.295 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1530/4776 | Loss: 75.672 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1540/4776 | Loss: 127.769 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1550/4776 | Loss: 108.224 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1560/4776 | Loss: 55.924 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1570/4776 | Loss: 139.514 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 1580/4776 | Loss: 60.751 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1590/4776 | Loss: 128.526 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1600/4776 | Loss: 90.316 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1610/4776 | Loss: 75.508 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1620/4776 | Loss: 121.186 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1630/4776 | Loss: 95.960 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1640/4776 | Loss: 105.039 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1650/4776 | Loss: 133.171 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 1660/4776 | Loss: 116.383 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1670/4776 | Loss: 66.304 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1680/4776 | Loss: 82.949 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1690/4776 | Loss: 63.847 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1700/4776 | Loss: 113.128 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1710/4776 | Loss: 56.235 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1720/4776 | Loss: 51.210 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1730/4776 | Loss: 145.472 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1740/4776 | Loss: 63.348 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1750/4776 | Loss: 49.862 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1760/4776 | Loss: 298.966 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1770/4776 | Loss: 265.597 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1780/4776 | Loss: 121.208 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1790/4776 | Loss: 84.765 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1800/4776 | Loss: 165.252 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1810/4776 | Loss: 124.708 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1820/4776 | Loss: 58.939 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1830/4776 | Loss: 125.179 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1840/4776 | Loss: 100.311 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1850/4776 | Loss: 116.463 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1860/4776 | Loss: 102.607 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1870/4776 | Loss: 125.893 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1880/4776 | Loss: 114.769 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1890/4776 | Loss: 65.070 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1900/4776 | Loss: 85.417 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1910/4776 | Loss: 105.957 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1920/4776 | Loss: 105.316 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1930/4776 | Loss: 81.813 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 1940/4776 | Loss: 111.044 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 1950/4776 | Loss: 92.013 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1960/4776 | Loss: 71.039 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 1970/4776 | Loss: 113.653 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 1980/4776 | Loss: 57.521 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 1990/4776 | Loss: 119.879 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2000/4776 | Loss: 110.685 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2010/4776 | Loss: 70.728 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2020/4776 | Loss: 90.170 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2030/4776 | Loss: 58.316 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2040/4776 | Loss: 71.494 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2050/4776 | Loss: 65.380 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2060/4776 | Loss: 73.524 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 2070/4776 | Loss: 53.544 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2080/4776 | Loss: 87.819 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2090/4776 | Loss: 92.050 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2100/4776 | Loss: 114.957 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2110/4776 | Loss: 75.454 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2120/4776 | Loss: 97.506 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2130/4776 | Loss: 43.867 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 2140/4776 | Loss: 90.829 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2150/4776 | Loss: 92.438 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2160/4776 | Loss: 73.512 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2170/4776 | Loss: 127.672 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2180/4776 | Loss: 132.567 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2190/4776 | Loss: 111.277 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2200/4776 | Loss: 85.075 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2210/4776 | Loss: 93.247 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2220/4776 | Loss: 60.554 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2230/4776 | Loss: 112.246 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2240/4776 | Loss: 80.114 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2250/4776 | Loss: 87.232 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2260/4776 | Loss: 50.233 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2270/4776 | Loss: 91.334 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2280/4776 | Loss: 74.866 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2290/4776 | Loss: 95.424 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2300/4776 | Loss: 98.655 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2310/4776 | Loss: 111.975 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2320/4776 | Loss: 71.350 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2330/4776 | Loss: 93.853 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2340/4776 | Loss: 137.062 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2350/4776 | Loss: 156.948 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2360/4776 | Loss: 94.451 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2370/4776 | Loss: 78.836 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2380/4776 | Loss: 99.862 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2390/4776 | Loss: 118.016 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2400/4776 | Loss: 135.344 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2410/4776 | Loss: 95.247 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2420/4776 | Loss: 144.758 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 2430/4776 | Loss: 124.189 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2440/4776 | Loss: 83.587 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2450/4776 | Loss: 118.093 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2460/4776 | Loss: 116.498 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 2470/4776 | Loss: 117.573 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2480/4776 | Loss: 82.156 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2490/4776 | Loss: 62.923 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2500/4776 | Loss: 96.058 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2510/4776 | Loss: 158.563 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2520/4776 | Loss: 98.729 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2530/4776 | Loss: 135.993 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2540/4776 | Loss: 119.733 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2550/4776 | Loss: 125.110 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2560/4776 | Loss: 81.453 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2570/4776 | Loss: 106.928 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2580/4776 | Loss: 69.502 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2590/4776 | Loss: 82.605 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2600/4776 | Loss: 85.234 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2610/4776 | Loss: 96.786 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2620/4776 | Loss: 71.375 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2630/4776 | Loss: 74.708 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2640/4776 | Loss: 63.254 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2650/4776 | Loss: 104.295 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2660/4776 | Loss: 88.504 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2670/4776 | Loss: 99.400 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2680/4776 | Loss: 94.215 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2690/4776 | Loss: 99.545 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2700/4776 | Loss: 147.849 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2710/4776 | Loss: 130.463 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2720/4776 | Loss: 66.270 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2730/4776 | Loss: 90.052 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2740/4776 | Loss: 32.732 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 2750/4776 | Loss: 139.233 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2760/4776 | Loss: 126.061 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2770/4776 | Loss: 88.982 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2780/4776 | Loss: 140.305 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2790/4776 | Loss: 110.450 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2800/4776 | Loss: 180.136 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2810/4776 | Loss: 135.839 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2820/4776 | Loss: 93.220 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2830/4776 | Loss: 163.320 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2840/4776 | Loss: 53.258 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2850/4776 | Loss: 93.975 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 2860/4776 | Loss: 90.237 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2870/4776 | Loss: 113.282 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2880/4776 | Loss: 84.318 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2890/4776 | Loss: 79.287 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 2900/4776 | Loss: 68.898 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2910/4776 | Loss: 70.984 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2920/4776 | Loss: 105.470 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2930/4776 | Loss: 98.010 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 2940/4776 | Loss: 48.210 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 2950/4776 | Loss: 124.445 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 2960/4776 | Loss: 168.270 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 2970/4776 | Loss: 148.272 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 2980/4776 | Loss: 56.866 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 2990/4776 | Loss: 106.737 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3000/4776 | Loss: 67.722 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3010/4776 | Loss: 93.449 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3020/4776 | Loss: 107.768 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3030/4776 | Loss: 127.303 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3040/4776 | Loss: 68.649 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3050/4776 | Loss: 101.691 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3060/4776 | Loss: 86.328 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3070/4776 | Loss: 132.552 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3080/4776 | Loss: 62.093 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3090/4776 | Loss: 100.761 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3100/4776 | Loss: 44.377 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3110/4776 | Loss: 99.686 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3120/4776 | Loss: 118.852 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3130/4776 | Loss: 90.063 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3140/4776 | Loss: 93.852 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3150/4776 | Loss: 116.145 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3160/4776 | Loss: 59.826 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3170/4776 | Loss: 51.228 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3180/4776 | Loss: 134.985 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3190/4776 | Loss: 134.185 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3200/4776 | Loss: 91.379 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3210/4776 | Loss: 144.360 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 3220/4776 | Loss: 93.022 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3230/4776 | Loss: 113.618 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3240/4776 | Loss: 74.329 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3250/4776 | Loss: 117.438 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3260/4776 | Loss: 100.245 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3270/4776 | Loss: 90.225 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3280/4776 | Loss: 78.239 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3290/4776 | Loss: 128.781 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3300/4776 | Loss: 81.271 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3310/4776 | Loss: 126.439 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3320/4776 | Loss: 85.475 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3330/4776 | Loss: 67.435 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3340/4776 | Loss: 106.206 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3350/4776 | Loss: 89.901 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3360/4776 | Loss: 140.901 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3370/4776 | Loss: 103.199 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3380/4776 | Loss: 157.154 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3390/4776 | Loss: 94.757 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3400/4776 | Loss: 79.108 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3410/4776 | Loss: 82.858 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3420/4776 | Loss: 85.773 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3430/4776 | Loss: 163.318 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3440/4776 | Loss: 108.057 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3450/4776 | Loss: 114.131 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3460/4776 | Loss: 88.024 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3470/4776 | Loss: 178.011 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3480/4776 | Loss: 103.906 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3490/4776 | Loss: 103.818 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3500/4776 | Loss: 62.719 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3510/4776 | Loss: 82.293 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3520/4776 | Loss: 117.644 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3530/4776 | Loss: 76.192 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3540/4776 | Loss: 181.072 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 3550/4776 | Loss: 68.547 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3560/4776 | Loss: 77.453 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3570/4776 | Loss: 77.436 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3580/4776 | Loss: 75.218 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3590/4776 | Loss: 66.384 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3600/4776 | Loss: 115.207 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3610/4776 | Loss: 104.488 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3620/4776 | Loss: 84.387 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3630/4776 | Loss: 64.524 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3640/4776 | Loss: 28.240 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 3650/4776 | Loss: 108.403 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3660/4776 | Loss: 97.128 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3670/4776 | Loss: 68.921 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3680/4776 | Loss: 72.409 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3690/4776 | Loss: 115.740 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3700/4776 | Loss: 105.367 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3710/4776 | Loss: 101.576 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3720/4776 | Loss: 120.206 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3730/4776 | Loss: 133.178 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3740/4776 | Loss: 71.359 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3750/4776 | Loss: 99.400 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3760/4776 | Loss: 90.231 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3770/4776 | Loss: 106.824 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3780/4776 | Loss: 53.978 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 3790/4776 | Loss: 127.385 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3800/4776 | Loss: 94.012 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3810/4776 | Loss: 141.863 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3820/4776 | Loss: 118.259 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3830/4776 | Loss: 111.475 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 3840/4776 | Loss: 127.749 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3850/4776 | Loss: 63.090 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3860/4776 | Loss: 108.576 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3870/4776 | Loss: 65.362 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3880/4776 | Loss: 116.287 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3890/4776 | Loss: 108.786 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3900/4776 | Loss: 98.772 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3910/4776 | Loss: 87.562 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3920/4776 | Loss: 182.040 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 3930/4776 | Loss: 84.266 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3940/4776 | Loss: 64.430 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3950/4776 | Loss: 175.886 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 3960/4776 | Loss: 121.591 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 3970/4776 | Loss: 80.164 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 3980/4776 | Loss: 49.568 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 3990/4776 | Loss: 117.324 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4000/4776 | Loss: 88.146 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4010/4776 | Loss: 109.874 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4020/4776 | Loss: 119.799 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4030/4776 | Loss: 96.312 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4040/4776 | Loss: 85.581 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4050/4776 | Loss: 160.822 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4060/4776 | Loss: 112.800 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4070/4776 | Loss: 143.079 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4080/4776 | Loss: 57.954 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4090/4776 | Loss: 102.886 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4100/4776 | Loss: 79.548 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 4110/4776 | Loss: 141.307 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4120/4776 | Loss: 147.922 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4130/4776 | Loss: 95.665 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4140/4776 | Loss: 135.793 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4150/4776 | Loss: 75.649 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4160/4776 | Loss: 192.079 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4170/4776 | Loss: 124.303 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4180/4776 | Loss: 162.782 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4190/4776 | Loss: 122.506 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4200/4776 | Loss: 183.374 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4210/4776 | Loss: 60.906 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4220/4776 | Loss: 138.556 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4230/4776 | Loss: 71.568 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4240/4776 | Loss: 88.738 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4250/4776 | Loss: 142.103 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 4260/4776 | Loss: 78.852 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4270/4776 | Loss: 65.649 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4280/4776 | Loss: 96.717 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4290/4776 | Loss: 89.903 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4300/4776 | Loss: 97.833 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4310/4776 | Loss: 115.145 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4320/4776 | Loss: 77.752 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4330/4776 | Loss: 68.446 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4340/4776 | Loss: 49.200 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4350/4776 | Loss: 103.589 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4360/4776 | Loss: 134.091 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4370/4776 | Loss: 101.356 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4380/4776 | Loss: 115.395 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4390/4776 | Loss: 67.623 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 4400/4776 | Loss: 121.829 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4410/4776 | Loss: 143.954 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4420/4776 | Loss: 118.302 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4430/4776 | Loss: 109.178 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4440/4776 | Loss: 65.193 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4450/4776 | Loss: 118.216 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4460/4776 | Loss: 82.828 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4470/4776 | Loss: 98.541 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4480/4776 | Loss: 58.586 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4490/4776 | Loss: 79.856 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4500/4776 | Loss: 83.318 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4510/4776 | Loss: 154.232 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 4520/4776 | Loss: 105.985 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 4530/4776 | Loss: 57.593 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4540/4776 | Loss: 106.176 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4550/4776 | Loss: 71.781 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4560/4776 | Loss: 117.953 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4570/4776 | Loss: 76.369 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4580/4776 | Loss: 54.688 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 4590/4776 | Loss: 70.905 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4600/4776 | Loss: 84.125 | Accuracy: 0.800\n",
      "[Epoch: 58/200] - Step: 4610/4776 | Loss: 172.631 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4620/4776 | Loss: 82.031 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4630/4776 | Loss: 118.995 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4640/4776 | Loss: 72.527 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4650/4776 | Loss: 73.816 | Accuracy: 0.700\n",
      "[Epoch: 58/200] - Step: 4660/4776 | Loss: 74.299 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4670/4776 | Loss: 67.699 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4680/4776 | Loss: 103.391 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4690/4776 | Loss: 88.181 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4700/4776 | Loss: 112.747 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4710/4776 | Loss: 62.106 | Accuracy: 0.900\n",
      "[Epoch: 58/200] - Step: 4720/4776 | Loss: 100.276 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4730/4776 | Loss: 78.774 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4740/4776 | Loss: 77.142 | Accuracy: 0.600\n",
      "[Epoch: 58/200] - Step: 4750/4776 | Loss: 86.597 | Accuracy: 0.500\n",
      "[Epoch: 58/200] - Step: 4760/4776 | Loss: 131.647 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 4770/4776 | Loss: 92.583 | Accuracy: 0.700\n",
      "Accuracy:  0.20327868852459016\n",
      "[Epoch: 59/200] - Step: 10/4776 | Loss: 69.668 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 20/4776 | Loss: 107.042 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 30/4776 | Loss: 92.030 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 40/4776 | Loss: 50.741 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 50/4776 | Loss: 107.289 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 60/4776 | Loss: 79.785 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 70/4776 | Loss: 124.755 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 80/4776 | Loss: 104.992 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 90/4776 | Loss: 83.905 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 100/4776 | Loss: 150.279 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 110/4776 | Loss: 92.545 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 120/4776 | Loss: 138.696 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 130/4776 | Loss: 86.214 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 140/4776 | Loss: 105.701 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 150/4776 | Loss: 148.965 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 160/4776 | Loss: 107.336 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 170/4776 | Loss: 59.416 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 180/4776 | Loss: 100.304 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 190/4776 | Loss: 96.918 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 200/4776 | Loss: 67.164 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 210/4776 | Loss: 66.443 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 220/4776 | Loss: 94.211 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 230/4776 | Loss: 61.940 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 240/4776 | Loss: 43.171 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 250/4776 | Loss: 78.118 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 260/4776 | Loss: 92.151 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 270/4776 | Loss: 120.571 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 280/4776 | Loss: 95.200 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 290/4776 | Loss: 87.038 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 300/4776 | Loss: 98.836 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 310/4776 | Loss: 73.315 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 320/4776 | Loss: 126.125 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 330/4776 | Loss: 100.927 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 340/4776 | Loss: 51.576 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 350/4776 | Loss: 103.991 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 360/4776 | Loss: 43.666 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 370/4776 | Loss: 62.357 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 380/4776 | Loss: 49.085 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 390/4776 | Loss: 99.635 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 400/4776 | Loss: 128.378 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 410/4776 | Loss: 117.386 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 420/4776 | Loss: 140.239 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 430/4776 | Loss: 53.702 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 440/4776 | Loss: 98.320 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 450/4776 | Loss: 99.063 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 460/4776 | Loss: 153.786 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 470/4776 | Loss: 119.958 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 480/4776 | Loss: 114.152 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 490/4776 | Loss: 76.699 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 500/4776 | Loss: 54.428 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 510/4776 | Loss: 95.878 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 520/4776 | Loss: 57.403 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 530/4776 | Loss: 60.907 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 540/4776 | Loss: 105.065 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 550/4776 | Loss: 66.319 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 560/4776 | Loss: 92.620 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 570/4776 | Loss: 81.540 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 580/4776 | Loss: 131.379 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 590/4776 | Loss: 53.584 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 600/4776 | Loss: 95.362 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 610/4776 | Loss: 143.727 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 620/4776 | Loss: 105.186 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 630/4776 | Loss: 44.729 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 640/4776 | Loss: 76.682 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 650/4776 | Loss: 78.872 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 660/4776 | Loss: 163.637 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 670/4776 | Loss: 62.638 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 680/4776 | Loss: 131.921 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 690/4776 | Loss: 135.069 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 700/4776 | Loss: 87.176 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 710/4776 | Loss: 66.822 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 720/4776 | Loss: 68.238 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 730/4776 | Loss: 79.330 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 740/4776 | Loss: 64.401 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 750/4776 | Loss: 81.561 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 760/4776 | Loss: 87.749 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 770/4776 | Loss: 88.413 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 780/4776 | Loss: 60.586 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 790/4776 | Loss: 130.545 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 800/4776 | Loss: 90.595 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 810/4776 | Loss: 32.831 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 820/4776 | Loss: 67.278 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 830/4776 | Loss: 117.508 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 840/4776 | Loss: 62.141 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 850/4776 | Loss: 75.287 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 860/4776 | Loss: 129.644 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 870/4776 | Loss: 134.618 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 880/4776 | Loss: 120.170 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 890/4776 | Loss: 74.391 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 900/4776 | Loss: 78.238 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 910/4776 | Loss: 80.836 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 920/4776 | Loss: 70.371 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 930/4776 | Loss: 71.547 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 940/4776 | Loss: 123.052 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 950/4776 | Loss: 54.988 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 960/4776 | Loss: 88.894 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 970/4776 | Loss: 124.148 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 980/4776 | Loss: 75.979 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 990/4776 | Loss: 66.643 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1000/4776 | Loss: 77.784 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1010/4776 | Loss: 76.588 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1020/4776 | Loss: 113.910 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1030/4776 | Loss: 99.622 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1040/4776 | Loss: 105.674 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1050/4776 | Loss: 82.259 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1060/4776 | Loss: 121.470 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1070/4776 | Loss: 78.799 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1080/4776 | Loss: 104.715 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1090/4776 | Loss: 72.829 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1100/4776 | Loss: 51.135 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 1110/4776 | Loss: 147.760 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1120/4776 | Loss: 83.065 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1130/4776 | Loss: 51.154 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1140/4776 | Loss: 46.950 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 1150/4776 | Loss: 214.079 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 1160/4776 | Loss: 103.818 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1170/4776 | Loss: 138.791 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1180/4776 | Loss: 60.347 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1190/4776 | Loss: 63.244 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1200/4776 | Loss: 84.420 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1210/4776 | Loss: 81.972 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1220/4776 | Loss: 119.624 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1230/4776 | Loss: 127.532 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1240/4776 | Loss: 71.542 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1250/4776 | Loss: 131.769 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1260/4776 | Loss: 119.682 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1270/4776 | Loss: 109.888 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1280/4776 | Loss: 110.603 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1290/4776 | Loss: 76.644 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1300/4776 | Loss: 107.068 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1310/4776 | Loss: 104.635 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1320/4776 | Loss: 101.168 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1330/4776 | Loss: 70.579 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1340/4776 | Loss: 114.887 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1350/4776 | Loss: 111.570 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1360/4776 | Loss: 59.577 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1370/4776 | Loss: 86.769 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1380/4776 | Loss: 113.259 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1390/4776 | Loss: 85.165 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1400/4776 | Loss: 75.284 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1410/4776 | Loss: 77.748 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1420/4776 | Loss: 99.195 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1430/4776 | Loss: 58.106 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1440/4776 | Loss: 73.383 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1450/4776 | Loss: 96.851 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1460/4776 | Loss: 73.232 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1470/4776 | Loss: 69.422 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1480/4776 | Loss: 76.184 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1490/4776 | Loss: 125.265 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1500/4776 | Loss: 99.349 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1510/4776 | Loss: 101.771 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1520/4776 | Loss: 64.618 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1530/4776 | Loss: 154.990 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1540/4776 | Loss: 84.930 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1550/4776 | Loss: 80.290 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1560/4776 | Loss: 160.767 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1570/4776 | Loss: 69.594 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1580/4776 | Loss: 58.347 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1590/4776 | Loss: 105.419 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1600/4776 | Loss: 96.200 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1610/4776 | Loss: 97.218 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1620/4776 | Loss: 86.566 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1630/4776 | Loss: 101.384 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1640/4776 | Loss: 154.130 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1650/4776 | Loss: 98.059 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1660/4776 | Loss: 84.799 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1670/4776 | Loss: 180.974 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1680/4776 | Loss: 65.946 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1690/4776 | Loss: 129.901 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1700/4776 | Loss: 130.543 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1710/4776 | Loss: 82.724 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1720/4776 | Loss: 150.598 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1730/4776 | Loss: 53.964 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1740/4776 | Loss: 123.103 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1750/4776 | Loss: 155.516 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1760/4776 | Loss: 90.051 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1770/4776 | Loss: 75.265 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1780/4776 | Loss: 95.797 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1790/4776 | Loss: 54.477 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1800/4776 | Loss: 109.337 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1810/4776 | Loss: 119.296 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1820/4776 | Loss: 99.735 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1830/4776 | Loss: 107.538 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1840/4776 | Loss: 50.428 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1850/4776 | Loss: 81.415 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 1860/4776 | Loss: 61.091 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1870/4776 | Loss: 21.365 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 1880/4776 | Loss: 62.557 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1890/4776 | Loss: 103.572 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1900/4776 | Loss: 118.097 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1910/4776 | Loss: 114.916 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1920/4776 | Loss: 124.202 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1930/4776 | Loss: 69.911 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 1940/4776 | Loss: 130.198 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1950/4776 | Loss: 91.898 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1960/4776 | Loss: 113.088 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 1970/4776 | Loss: 134.377 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1980/4776 | Loss: 55.210 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 1990/4776 | Loss: 59.945 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2000/4776 | Loss: 106.298 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 2010/4776 | Loss: 79.413 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2020/4776 | Loss: 87.386 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2030/4776 | Loss: 125.043 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2040/4776 | Loss: 94.039 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2050/4776 | Loss: 76.004 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2060/4776 | Loss: 87.792 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2070/4776 | Loss: 66.835 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2080/4776 | Loss: 101.100 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2090/4776 | Loss: 96.909 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2100/4776 | Loss: 98.518 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2110/4776 | Loss: 47.822 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2120/4776 | Loss: 40.326 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2130/4776 | Loss: 101.882 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2140/4776 | Loss: 54.803 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2150/4776 | Loss: 91.437 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2160/4776 | Loss: 106.297 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2170/4776 | Loss: 59.990 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2180/4776 | Loss: 119.310 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2190/4776 | Loss: 39.595 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2200/4776 | Loss: 127.264 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2210/4776 | Loss: 100.449 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2220/4776 | Loss: 113.504 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2230/4776 | Loss: 159.739 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 2240/4776 | Loss: 141.058 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2250/4776 | Loss: 95.972 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2260/4776 | Loss: 119.191 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2270/4776 | Loss: 116.576 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2280/4776 | Loss: 88.012 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2290/4776 | Loss: 107.901 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2300/4776 | Loss: 108.129 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2310/4776 | Loss: 94.898 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2320/4776 | Loss: 212.392 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 2330/4776 | Loss: 137.303 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2340/4776 | Loss: 84.226 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2350/4776 | Loss: 92.525 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2360/4776 | Loss: 70.068 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2370/4776 | Loss: 101.397 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2380/4776 | Loss: 149.838 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 2390/4776 | Loss: 63.805 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2400/4776 | Loss: 93.348 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2410/4776 | Loss: 65.921 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2420/4776 | Loss: 144.478 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2430/4776 | Loss: 62.115 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2440/4776 | Loss: 137.887 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2450/4776 | Loss: 58.103 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2460/4776 | Loss: 147.047 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2470/4776 | Loss: 135.080 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2480/4776 | Loss: 113.887 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2490/4776 | Loss: 126.867 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2500/4776 | Loss: 73.044 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2510/4776 | Loss: 58.938 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2520/4776 | Loss: 39.950 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2530/4776 | Loss: 58.627 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2540/4776 | Loss: 79.058 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2550/4776 | Loss: 56.774 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2560/4776 | Loss: 108.762 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2570/4776 | Loss: 122.289 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2580/4776 | Loss: 115.741 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2590/4776 | Loss: 50.576 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2600/4776 | Loss: 143.272 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2610/4776 | Loss: 78.497 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2620/4776 | Loss: 96.683 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2630/4776 | Loss: 161.601 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2640/4776 | Loss: 43.815 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2650/4776 | Loss: 105.306 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2660/4776 | Loss: 58.763 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 2670/4776 | Loss: 94.010 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2680/4776 | Loss: 123.615 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 2690/4776 | Loss: 91.766 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2700/4776 | Loss: 73.254 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2710/4776 | Loss: 61.693 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2720/4776 | Loss: 127.455 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2730/4776 | Loss: 87.520 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2740/4776 | Loss: 120.083 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 2750/4776 | Loss: 61.311 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2760/4776 | Loss: 81.720 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2770/4776 | Loss: 90.617 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2780/4776 | Loss: 113.527 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2790/4776 | Loss: 56.565 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2800/4776 | Loss: 109.784 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2810/4776 | Loss: 80.304 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2820/4776 | Loss: 105.614 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2830/4776 | Loss: 79.318 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2840/4776 | Loss: 107.857 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2850/4776 | Loss: 96.304 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2860/4776 | Loss: 69.732 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 2870/4776 | Loss: 89.221 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2880/4776 | Loss: 89.657 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2890/4776 | Loss: 90.327 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2900/4776 | Loss: 122.688 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2910/4776 | Loss: 121.197 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2920/4776 | Loss: 48.869 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2930/4776 | Loss: 98.884 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 2940/4776 | Loss: 108.170 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2950/4776 | Loss: 102.337 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 2960/4776 | Loss: 68.884 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2970/4776 | Loss: 49.771 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 2980/4776 | Loss: 101.222 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 2990/4776 | Loss: 107.026 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3000/4776 | Loss: 68.991 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3010/4776 | Loss: 74.228 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3020/4776 | Loss: 81.930 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3030/4776 | Loss: 83.822 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3040/4776 | Loss: 152.125 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 3050/4776 | Loss: 68.316 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3060/4776 | Loss: 130.480 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3070/4776 | Loss: 94.200 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3080/4776 | Loss: 128.489 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3090/4776 | Loss: 71.901 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3100/4776 | Loss: 142.060 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3110/4776 | Loss: 102.761 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3120/4776 | Loss: 146.335 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3130/4776 | Loss: 64.572 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3140/4776 | Loss: 153.459 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3150/4776 | Loss: 56.031 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3160/4776 | Loss: 113.780 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3170/4776 | Loss: 68.870 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3180/4776 | Loss: 120.048 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3190/4776 | Loss: 139.905 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3200/4776 | Loss: 106.889 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3210/4776 | Loss: 102.541 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3220/4776 | Loss: 98.434 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3230/4776 | Loss: 50.800 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3240/4776 | Loss: 43.936 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3250/4776 | Loss: 98.258 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3260/4776 | Loss: 102.112 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3270/4776 | Loss: 141.985 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3280/4776 | Loss: 51.743 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3290/4776 | Loss: 94.910 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3300/4776 | Loss: 111.159 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3310/4776 | Loss: 139.570 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3320/4776 | Loss: 138.509 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3330/4776 | Loss: 156.967 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3340/4776 | Loss: 82.212 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3350/4776 | Loss: 143.456 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3360/4776 | Loss: 96.717 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3370/4776 | Loss: 64.004 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3380/4776 | Loss: 88.677 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3390/4776 | Loss: 118.755 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3400/4776 | Loss: 61.287 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3410/4776 | Loss: 119.744 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3420/4776 | Loss: 159.081 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3430/4776 | Loss: 103.120 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3440/4776 | Loss: 115.774 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3450/4776 | Loss: 49.614 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3460/4776 | Loss: 58.838 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3470/4776 | Loss: 121.760 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3480/4776 | Loss: 64.272 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3490/4776 | Loss: 109.062 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3500/4776 | Loss: 81.223 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3510/4776 | Loss: 116.895 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 3520/4776 | Loss: 93.006 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3530/4776 | Loss: 88.542 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3540/4776 | Loss: 129.771 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 3550/4776 | Loss: 112.244 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3560/4776 | Loss: 73.355 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3570/4776 | Loss: 77.989 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3580/4776 | Loss: 95.182 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3590/4776 | Loss: 76.465 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3600/4776 | Loss: 111.290 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3610/4776 | Loss: 174.873 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 3620/4776 | Loss: 53.364 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3630/4776 | Loss: 113.244 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3640/4776 | Loss: 116.032 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3650/4776 | Loss: 84.436 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3660/4776 | Loss: 67.517 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3670/4776 | Loss: 69.309 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3680/4776 | Loss: 86.571 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3690/4776 | Loss: 131.960 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3700/4776 | Loss: 104.578 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3710/4776 | Loss: 93.181 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3720/4776 | Loss: 80.797 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3730/4776 | Loss: 98.935 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3740/4776 | Loss: 74.718 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3750/4776 | Loss: 85.501 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3760/4776 | Loss: 95.005 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3770/4776 | Loss: 79.883 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3780/4776 | Loss: 45.509 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3790/4776 | Loss: 83.295 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3800/4776 | Loss: 77.656 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3810/4776 | Loss: 43.787 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 3820/4776 | Loss: 95.530 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3830/4776 | Loss: 95.834 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3840/4776 | Loss: 129.991 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3850/4776 | Loss: 49.797 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 3860/4776 | Loss: 67.335 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3870/4776 | Loss: 98.195 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3880/4776 | Loss: 106.228 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3890/4776 | Loss: 105.301 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3900/4776 | Loss: 80.849 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 3910/4776 | Loss: 107.401 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3920/4776 | Loss: 135.292 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 3930/4776 | Loss: 114.713 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3940/4776 | Loss: 92.133 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 3950/4776 | Loss: 110.384 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3960/4776 | Loss: 94.676 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 3970/4776 | Loss: 82.058 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3980/4776 | Loss: 136.435 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 3990/4776 | Loss: 71.361 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4000/4776 | Loss: 118.988 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4010/4776 | Loss: 74.791 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4020/4776 | Loss: 186.988 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 4030/4776 | Loss: 117.489 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4040/4776 | Loss: 73.311 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4050/4776 | Loss: 111.972 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4060/4776 | Loss: 59.629 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4070/4776 | Loss: 63.775 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4080/4776 | Loss: 69.714 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4090/4776 | Loss: 97.355 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4100/4776 | Loss: 66.120 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 4110/4776 | Loss: 81.019 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4120/4776 | Loss: 90.172 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4130/4776 | Loss: 86.501 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 4140/4776 | Loss: 145.607 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4150/4776 | Loss: 150.090 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4160/4776 | Loss: 90.830 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4170/4776 | Loss: 75.483 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4180/4776 | Loss: 124.440 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 4190/4776 | Loss: 118.693 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4200/4776 | Loss: 160.938 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4210/4776 | Loss: 104.993 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4220/4776 | Loss: 84.550 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4230/4776 | Loss: 56.654 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 4240/4776 | Loss: 110.493 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 4250/4776 | Loss: 149.100 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4260/4776 | Loss: 52.338 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4270/4776 | Loss: 49.959 | Accuracy: 0.900\n",
      "[Epoch: 59/200] - Step: 4280/4776 | Loss: 72.968 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4290/4776 | Loss: 94.414 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4300/4776 | Loss: 143.553 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4310/4776 | Loss: 118.331 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4320/4776 | Loss: 115.627 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4330/4776 | Loss: 64.330 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4340/4776 | Loss: 144.195 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 4350/4776 | Loss: 87.542 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4360/4776 | Loss: 30.258 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 4370/4776 | Loss: 152.458 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4380/4776 | Loss: 134.552 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4390/4776 | Loss: 104.806 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4400/4776 | Loss: 60.083 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4410/4776 | Loss: 108.287 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4420/4776 | Loss: 129.170 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 4430/4776 | Loss: 80.927 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4440/4776 | Loss: 87.100 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4450/4776 | Loss: 109.887 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4460/4776 | Loss: 76.351 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4470/4776 | Loss: 102.902 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4480/4776 | Loss: 80.783 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4490/4776 | Loss: 100.788 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4500/4776 | Loss: 112.850 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4510/4776 | Loss: 101.691 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4520/4776 | Loss: 85.483 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4530/4776 | Loss: 90.059 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4540/4776 | Loss: 78.006 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4550/4776 | Loss: 50.029 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4560/4776 | Loss: 36.340 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4570/4776 | Loss: 84.836 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4580/4776 | Loss: 98.336 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4590/4776 | Loss: 109.771 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 4600/4776 | Loss: 50.409 | Accuracy: 0.800\n",
      "[Epoch: 59/200] - Step: 4610/4776 | Loss: 110.080 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4620/4776 | Loss: 117.048 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4630/4776 | Loss: 29.230 | Accuracy: 1.000\n",
      "[Epoch: 59/200] - Step: 4640/4776 | Loss: 69.025 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4650/4776 | Loss: 77.084 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4660/4776 | Loss: 84.512 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4670/4776 | Loss: 100.094 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4680/4776 | Loss: 122.125 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4690/4776 | Loss: 116.692 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4700/4776 | Loss: 94.241 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4710/4776 | Loss: 78.463 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4720/4776 | Loss: 90.945 | Accuracy: 0.600\n",
      "[Epoch: 59/200] - Step: 4730/4776 | Loss: 98.525 | Accuracy: 0.500\n",
      "[Epoch: 59/200] - Step: 4740/4776 | Loss: 86.920 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4750/4776 | Loss: 159.631 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 4760/4776 | Loss: 119.506 | Accuracy: 0.700\n",
      "[Epoch: 59/200] - Step: 4770/4776 | Loss: 79.810 | Accuracy: 0.700\n",
      "Accuracy:  0.21147540983606558\n",
      "[Epoch: 60/200] - Step: 10/4776 | Loss: 115.647 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 20/4776 | Loss: 112.808 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 30/4776 | Loss: 94.168 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 40/4776 | Loss: 87.799 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 50/4776 | Loss: 65.013 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 60/4776 | Loss: 99.705 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 70/4776 | Loss: 77.727 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 80/4776 | Loss: 68.338 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 90/4776 | Loss: 109.163 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 100/4776 | Loss: 118.223 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 110/4776 | Loss: 55.522 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 120/4776 | Loss: 71.251 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 130/4776 | Loss: 25.645 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 140/4776 | Loss: 123.840 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 150/4776 | Loss: 117.013 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 160/4776 | Loss: 82.023 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 170/4776 | Loss: 109.144 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 180/4776 | Loss: 118.922 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 190/4776 | Loss: 71.129 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 200/4776 | Loss: 57.468 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 210/4776 | Loss: 91.021 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 220/4776 | Loss: 115.046 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 230/4776 | Loss: 97.228 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 240/4776 | Loss: 87.190 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 250/4776 | Loss: 48.451 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 260/4776 | Loss: 81.983 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 270/4776 | Loss: 51.911 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 280/4776 | Loss: 151.184 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 290/4776 | Loss: 99.228 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 300/4776 | Loss: 152.431 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 310/4776 | Loss: 128.770 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 320/4776 | Loss: 124.717 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 330/4776 | Loss: 148.550 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 340/4776 | Loss: 92.337 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 350/4776 | Loss: 89.609 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 360/4776 | Loss: 91.453 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 370/4776 | Loss: 68.353 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 380/4776 | Loss: 157.314 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 390/4776 | Loss: 81.668 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 400/4776 | Loss: 98.626 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 410/4776 | Loss: 122.209 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 420/4776 | Loss: 75.463 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 430/4776 | Loss: 147.116 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 440/4776 | Loss: 71.745 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 450/4776 | Loss: 90.189 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 460/4776 | Loss: 85.546 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 470/4776 | Loss: 109.878 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 480/4776 | Loss: 162.611 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 490/4776 | Loss: 85.363 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 500/4776 | Loss: 177.516 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 510/4776 | Loss: 144.873 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 520/4776 | Loss: 164.276 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 530/4776 | Loss: 171.724 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 540/4776 | Loss: 110.876 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 550/4776 | Loss: 107.454 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 560/4776 | Loss: 113.816 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 570/4776 | Loss: 66.888 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 580/4776 | Loss: 92.223 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 590/4776 | Loss: 93.297 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 600/4776 | Loss: 173.668 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 610/4776 | Loss: 116.556 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 620/4776 | Loss: 103.976 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 630/4776 | Loss: 235.875 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 640/4776 | Loss: 110.085 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 650/4776 | Loss: 126.163 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 660/4776 | Loss: 118.109 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 670/4776 | Loss: 86.348 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 680/4776 | Loss: 118.815 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 690/4776 | Loss: 91.146 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 700/4776 | Loss: 114.533 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 710/4776 | Loss: 97.777 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 720/4776 | Loss: 111.156 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 730/4776 | Loss: 97.974 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 740/4776 | Loss: 111.377 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 750/4776 | Loss: 125.020 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 760/4776 | Loss: 89.926 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 770/4776 | Loss: 70.240 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 780/4776 | Loss: 35.281 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 790/4776 | Loss: 56.602 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 800/4776 | Loss: 83.204 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 810/4776 | Loss: 182.260 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 820/4776 | Loss: 67.193 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 830/4776 | Loss: 125.233 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 840/4776 | Loss: 153.237 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 850/4776 | Loss: 134.267 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 860/4776 | Loss: 118.404 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 870/4776 | Loss: 98.754 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 880/4776 | Loss: 103.783 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 890/4776 | Loss: 66.176 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 900/4776 | Loss: 46.110 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 910/4776 | Loss: 130.844 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 920/4776 | Loss: 89.688 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 930/4776 | Loss: 64.246 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 940/4776 | Loss: 96.464 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 950/4776 | Loss: 112.491 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 960/4776 | Loss: 107.050 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 970/4776 | Loss: 96.163 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 980/4776 | Loss: 64.970 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 990/4776 | Loss: 56.428 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1000/4776 | Loss: 96.078 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1010/4776 | Loss: 69.364 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1020/4776 | Loss: 57.570 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1030/4776 | Loss: 51.219 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1040/4776 | Loss: 27.040 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 1050/4776 | Loss: 72.622 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1060/4776 | Loss: 104.060 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1070/4776 | Loss: 86.064 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1080/4776 | Loss: 99.983 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1090/4776 | Loss: 123.240 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1100/4776 | Loss: 69.249 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1110/4776 | Loss: 78.089 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1120/4776 | Loss: 126.876 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1130/4776 | Loss: 124.165 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1140/4776 | Loss: 171.659 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1150/4776 | Loss: 127.372 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1160/4776 | Loss: 60.559 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1170/4776 | Loss: 98.726 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1180/4776 | Loss: 105.520 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1190/4776 | Loss: 106.519 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1200/4776 | Loss: 118.811 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1210/4776 | Loss: 55.918 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1220/4776 | Loss: 95.166 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1230/4776 | Loss: 114.618 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1240/4776 | Loss: 78.653 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1250/4776 | Loss: 98.627 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1260/4776 | Loss: 84.116 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1270/4776 | Loss: 66.191 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1280/4776 | Loss: 54.894 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1290/4776 | Loss: 151.028 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 1300/4776 | Loss: 61.346 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1310/4776 | Loss: 85.567 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1320/4776 | Loss: 76.587 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1330/4776 | Loss: 85.868 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1340/4776 | Loss: 163.429 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 1350/4776 | Loss: 106.394 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1360/4776 | Loss: 109.476 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1370/4776 | Loss: 71.322 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1380/4776 | Loss: 70.311 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1390/4776 | Loss: 93.585 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1400/4776 | Loss: 147.172 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 1410/4776 | Loss: 102.912 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1420/4776 | Loss: 79.186 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1430/4776 | Loss: 93.458 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1440/4776 | Loss: 32.227 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1450/4776 | Loss: 127.722 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1460/4776 | Loss: 101.225 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1470/4776 | Loss: 166.219 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 1480/4776 | Loss: 89.432 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1490/4776 | Loss: 97.705 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1500/4776 | Loss: 114.913 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 1510/4776 | Loss: 137.621 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 1520/4776 | Loss: 118.359 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1530/4776 | Loss: 72.162 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1540/4776 | Loss: 58.648 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1550/4776 | Loss: 144.100 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1560/4776 | Loss: 75.214 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1570/4776 | Loss: 87.243 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1580/4776 | Loss: 85.059 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1590/4776 | Loss: 53.919 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1600/4776 | Loss: 110.788 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1610/4776 | Loss: 96.652 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1620/4776 | Loss: 79.126 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1630/4776 | Loss: 69.967 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1640/4776 | Loss: 89.923 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1650/4776 | Loss: 52.686 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1660/4776 | Loss: 21.187 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 1670/4776 | Loss: 54.367 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1680/4776 | Loss: 30.963 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 1690/4776 | Loss: 71.717 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1700/4776 | Loss: 60.736 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1710/4776 | Loss: 126.457 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1720/4776 | Loss: 70.420 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1730/4776 | Loss: 86.675 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1740/4776 | Loss: 106.157 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1750/4776 | Loss: 60.910 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1760/4776 | Loss: 29.297 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1770/4776 | Loss: 157.041 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1780/4776 | Loss: 81.214 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1790/4776 | Loss: 127.435 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1800/4776 | Loss: 120.387 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1810/4776 | Loss: 44.632 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 1820/4776 | Loss: 95.071 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1830/4776 | Loss: 125.320 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1840/4776 | Loss: 77.206 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1850/4776 | Loss: 78.252 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1860/4776 | Loss: 148.446 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1870/4776 | Loss: 85.082 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1880/4776 | Loss: 85.643 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1890/4776 | Loss: 128.131 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1900/4776 | Loss: 57.457 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1910/4776 | Loss: 85.160 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1920/4776 | Loss: 52.113 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 1930/4776 | Loss: 67.476 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1940/4776 | Loss: 92.416 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 1950/4776 | Loss: 121.102 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1960/4776 | Loss: 101.956 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 1970/4776 | Loss: 36.687 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 1980/4776 | Loss: 106.426 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 1990/4776 | Loss: 81.638 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2000/4776 | Loss: 37.802 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 2010/4776 | Loss: 81.209 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2020/4776 | Loss: 117.236 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2030/4776 | Loss: 79.116 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2040/4776 | Loss: 84.267 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2050/4776 | Loss: 67.723 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2060/4776 | Loss: 114.498 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2070/4776 | Loss: 48.330 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 2080/4776 | Loss: 87.616 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2090/4776 | Loss: 37.306 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 2100/4776 | Loss: 73.243 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2110/4776 | Loss: 62.825 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 2120/4776 | Loss: 66.980 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2130/4776 | Loss: 56.721 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2140/4776 | Loss: 88.160 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2150/4776 | Loss: 62.597 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2160/4776 | Loss: 56.148 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2170/4776 | Loss: 138.309 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2180/4776 | Loss: 135.303 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2190/4776 | Loss: 91.089 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2200/4776 | Loss: 106.577 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2210/4776 | Loss: 90.615 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2220/4776 | Loss: 96.114 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2230/4776 | Loss: 124.502 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2240/4776 | Loss: 84.450 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2250/4776 | Loss: 136.351 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2260/4776 | Loss: 70.366 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2270/4776 | Loss: 52.942 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 2280/4776 | Loss: 105.654 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2290/4776 | Loss: 81.161 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2300/4776 | Loss: 52.615 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2310/4776 | Loss: 73.771 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2320/4776 | Loss: 49.104 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2330/4776 | Loss: 91.888 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2340/4776 | Loss: 151.892 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2350/4776 | Loss: 48.139 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2360/4776 | Loss: 105.904 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2370/4776 | Loss: 87.729 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2380/4776 | Loss: 128.155 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2390/4776 | Loss: 77.901 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2400/4776 | Loss: 115.697 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2410/4776 | Loss: 46.143 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2420/4776 | Loss: 86.266 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2430/4776 | Loss: 163.524 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2440/4776 | Loss: 168.692 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2450/4776 | Loss: 59.807 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2460/4776 | Loss: 166.644 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2470/4776 | Loss: 118.402 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2480/4776 | Loss: 88.615 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2490/4776 | Loss: 92.560 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2500/4776 | Loss: 54.035 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2510/4776 | Loss: 102.958 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2520/4776 | Loss: 81.842 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2530/4776 | Loss: 140.402 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2540/4776 | Loss: 80.641 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2550/4776 | Loss: 95.957 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2560/4776 | Loss: 97.069 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2570/4776 | Loss: 66.046 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2580/4776 | Loss: 83.061 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2590/4776 | Loss: 127.142 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2600/4776 | Loss: 90.240 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2610/4776 | Loss: 146.690 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 2620/4776 | Loss: 68.882 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2630/4776 | Loss: 135.410 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2640/4776 | Loss: 87.181 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2650/4776 | Loss: 119.239 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2660/4776 | Loss: 121.465 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2670/4776 | Loss: 142.014 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2680/4776 | Loss: 180.694 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 2690/4776 | Loss: 97.318 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2700/4776 | Loss: 183.726 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2710/4776 | Loss: 80.783 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2720/4776 | Loss: 112.888 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2730/4776 | Loss: 83.367 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2740/4776 | Loss: 79.055 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2750/4776 | Loss: 75.004 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2760/4776 | Loss: 125.109 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2770/4776 | Loss: 107.816 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2780/4776 | Loss: 49.411 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2790/4776 | Loss: 110.415 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2800/4776 | Loss: 83.356 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2810/4776 | Loss: 146.296 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 2820/4776 | Loss: 102.103 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2830/4776 | Loss: 139.759 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2840/4776 | Loss: 85.339 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2850/4776 | Loss: 114.489 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2860/4776 | Loss: 77.180 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2870/4776 | Loss: 105.324 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2880/4776 | Loss: 73.560 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2890/4776 | Loss: 61.357 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2900/4776 | Loss: 126.915 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2910/4776 | Loss: 57.827 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2920/4776 | Loss: 177.015 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 2930/4776 | Loss: 66.594 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2940/4776 | Loss: 111.421 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 2950/4776 | Loss: 61.481 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 2960/4776 | Loss: 118.371 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 2970/4776 | Loss: 145.217 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 2980/4776 | Loss: 82.700 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 2990/4776 | Loss: 91.586 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3000/4776 | Loss: 77.486 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3010/4776 | Loss: 58.084 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3020/4776 | Loss: 148.381 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3030/4776 | Loss: 90.513 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3040/4776 | Loss: 83.313 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3050/4776 | Loss: 69.971 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3060/4776 | Loss: 48.392 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3070/4776 | Loss: 83.855 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3080/4776 | Loss: 67.409 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 3090/4776 | Loss: 93.983 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3100/4776 | Loss: 82.556 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3110/4776 | Loss: 75.689 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 3120/4776 | Loss: 45.365 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3130/4776 | Loss: 34.255 | Accuracy: 1.000\n",
      "[Epoch: 60/200] - Step: 3140/4776 | Loss: 90.946 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3150/4776 | Loss: 64.312 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3160/4776 | Loss: 118.214 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3170/4776 | Loss: 149.125 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3180/4776 | Loss: 133.984 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3190/4776 | Loss: 118.842 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3200/4776 | Loss: 118.588 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3210/4776 | Loss: 82.707 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3220/4776 | Loss: 57.096 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 3230/4776 | Loss: 68.941 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3240/4776 | Loss: 89.369 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3250/4776 | Loss: 74.874 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3260/4776 | Loss: 80.358 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3270/4776 | Loss: 75.892 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3280/4776 | Loss: 184.428 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3290/4776 | Loss: 81.187 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3300/4776 | Loss: 70.016 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3310/4776 | Loss: 82.870 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3320/4776 | Loss: 96.209 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3330/4776 | Loss: 73.509 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3340/4776 | Loss: 114.807 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3350/4776 | Loss: 185.282 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3360/4776 | Loss: 47.742 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 3370/4776 | Loss: 82.935 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3380/4776 | Loss: 107.466 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3390/4776 | Loss: 130.374 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3400/4776 | Loss: 158.140 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3410/4776 | Loss: 127.139 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3420/4776 | Loss: 81.009 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3430/4776 | Loss: 95.032 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3440/4776 | Loss: 86.280 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3450/4776 | Loss: 78.535 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3460/4776 | Loss: 76.716 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3470/4776 | Loss: 83.397 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3480/4776 | Loss: 69.587 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3490/4776 | Loss: 92.154 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3500/4776 | Loss: 65.105 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3510/4776 | Loss: 91.674 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3520/4776 | Loss: 52.849 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3530/4776 | Loss: 93.962 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3540/4776 | Loss: 31.273 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 3550/4776 | Loss: 139.962 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3560/4776 | Loss: 51.897 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3570/4776 | Loss: 101.256 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3580/4776 | Loss: 84.119 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3590/4776 | Loss: 63.491 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3600/4776 | Loss: 57.273 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3610/4776 | Loss: 112.308 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3620/4776 | Loss: 75.301 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3630/4776 | Loss: 63.103 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3640/4776 | Loss: 114.679 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 3650/4776 | Loss: 105.855 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3660/4776 | Loss: 81.474 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3670/4776 | Loss: 109.919 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3680/4776 | Loss: 54.110 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3690/4776 | Loss: 125.308 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3700/4776 | Loss: 97.609 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3710/4776 | Loss: 74.372 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3720/4776 | Loss: 154.940 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3730/4776 | Loss: 88.251 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3740/4776 | Loss: 72.987 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3750/4776 | Loss: 113.614 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3760/4776 | Loss: 73.512 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3770/4776 | Loss: 111.222 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3780/4776 | Loss: 65.223 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3790/4776 | Loss: 50.873 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3800/4776 | Loss: 99.740 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3810/4776 | Loss: 74.931 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3820/4776 | Loss: 68.561 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3830/4776 | Loss: 70.215 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3840/4776 | Loss: 63.464 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3850/4776 | Loss: 121.444 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3860/4776 | Loss: 39.595 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3870/4776 | Loss: 146.807 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3880/4776 | Loss: 97.529 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3890/4776 | Loss: 143.693 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3900/4776 | Loss: 93.845 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3910/4776 | Loss: 75.409 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3920/4776 | Loss: 106.893 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 3930/4776 | Loss: 81.376 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3940/4776 | Loss: 154.726 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3950/4776 | Loss: 66.287 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 3960/4776 | Loss: 118.040 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3970/4776 | Loss: 97.965 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 3980/4776 | Loss: 116.660 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 3990/4776 | Loss: 70.540 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4000/4776 | Loss: 113.088 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4010/4776 | Loss: 139.997 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4020/4776 | Loss: 75.057 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4030/4776 | Loss: 81.698 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4040/4776 | Loss: 82.334 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4050/4776 | Loss: 91.566 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4060/4776 | Loss: 51.227 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4070/4776 | Loss: 149.956 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4080/4776 | Loss: 101.101 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4090/4776 | Loss: 68.278 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4100/4776 | Loss: 80.307 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4110/4776 | Loss: 97.468 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4120/4776 | Loss: 118.392 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4130/4776 | Loss: 159.179 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 4140/4776 | Loss: 95.488 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4150/4776 | Loss: 179.257 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 4160/4776 | Loss: 77.793 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4170/4776 | Loss: 97.395 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4180/4776 | Loss: 130.819 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4190/4776 | Loss: 112.594 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4200/4776 | Loss: 54.145 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4210/4776 | Loss: 59.808 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4220/4776 | Loss: 98.404 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4230/4776 | Loss: 113.517 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4240/4776 | Loss: 90.820 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4250/4776 | Loss: 149.191 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 4260/4776 | Loss: 119.934 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4270/4776 | Loss: 117.939 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4280/4776 | Loss: 94.438 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4290/4776 | Loss: 109.020 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4300/4776 | Loss: 64.670 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4310/4776 | Loss: 42.755 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4320/4776 | Loss: 113.858 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4330/4776 | Loss: 107.585 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4340/4776 | Loss: 87.977 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4350/4776 | Loss: 127.170 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4360/4776 | Loss: 40.977 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4370/4776 | Loss: 41.859 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4380/4776 | Loss: 100.560 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4390/4776 | Loss: 72.342 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4400/4776 | Loss: 81.764 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4410/4776 | Loss: 111.909 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 4420/4776 | Loss: 72.870 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4430/4776 | Loss: 79.055 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4440/4776 | Loss: 126.368 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4450/4776 | Loss: 33.729 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4460/4776 | Loss: 38.822 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4470/4776 | Loss: 121.863 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4480/4776 | Loss: 87.847 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4490/4776 | Loss: 60.035 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4500/4776 | Loss: 96.798 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4510/4776 | Loss: 76.809 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4520/4776 | Loss: 86.743 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4530/4776 | Loss: 68.815 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4540/4776 | Loss: 90.843 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4550/4776 | Loss: 127.287 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 4560/4776 | Loss: 81.054 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4570/4776 | Loss: 115.786 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4580/4776 | Loss: 95.296 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4590/4776 | Loss: 70.430 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4600/4776 | Loss: 67.699 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4610/4776 | Loss: 70.399 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4620/4776 | Loss: 90.510 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4630/4776 | Loss: 72.909 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4640/4776 | Loss: 98.407 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4650/4776 | Loss: 54.819 | Accuracy: 0.800\n",
      "[Epoch: 60/200] - Step: 4660/4776 | Loss: 77.617 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4670/4776 | Loss: 103.952 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4680/4776 | Loss: 72.670 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4690/4776 | Loss: 91.244 | Accuracy: 0.600\n",
      "[Epoch: 60/200] - Step: 4700/4776 | Loss: 49.270 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4710/4776 | Loss: 137.233 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4720/4776 | Loss: 73.504 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4730/4776 | Loss: 88.908 | Accuracy: 0.700\n",
      "[Epoch: 60/200] - Step: 4740/4776 | Loss: 138.405 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4750/4776 | Loss: 97.102 | Accuracy: 0.500\n",
      "[Epoch: 60/200] - Step: 4760/4776 | Loss: 36.443 | Accuracy: 0.900\n",
      "[Epoch: 60/200] - Step: 4770/4776 | Loss: 87.027 | Accuracy: 0.600\n",
      "Accuracy:  0.21311475409836064\n",
      "[Epoch: 61/200] - Step: 10/4776 | Loss: 56.942 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 20/4776 | Loss: 112.588 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 30/4776 | Loss: 86.135 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 40/4776 | Loss: 48.047 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 50/4776 | Loss: 143.817 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 60/4776 | Loss: 85.911 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 70/4776 | Loss: 49.637 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 80/4776 | Loss: 195.530 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 90/4776 | Loss: 55.927 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 100/4776 | Loss: 92.004 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 110/4776 | Loss: 136.668 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 120/4776 | Loss: 93.944 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 130/4776 | Loss: 71.564 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 140/4776 | Loss: 110.183 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 150/4776 | Loss: 65.750 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 160/4776 | Loss: 108.326 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 170/4776 | Loss: 71.773 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 180/4776 | Loss: 58.620 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 190/4776 | Loss: 116.785 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 200/4776 | Loss: 103.668 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 210/4776 | Loss: 127.310 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 220/4776 | Loss: 85.305 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 230/4776 | Loss: 45.377 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 240/4776 | Loss: 94.867 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 250/4776 | Loss: 199.384 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 260/4776 | Loss: 152.484 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 270/4776 | Loss: 132.219 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 280/4776 | Loss: 105.403 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 290/4776 | Loss: 128.378 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 300/4776 | Loss: 40.724 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 310/4776 | Loss: 88.600 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 320/4776 | Loss: 83.381 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 330/4776 | Loss: 112.896 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 340/4776 | Loss: 71.420 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 350/4776 | Loss: 76.764 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 360/4776 | Loss: 88.184 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 370/4776 | Loss: 81.580 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 380/4776 | Loss: 68.551 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 390/4776 | Loss: 79.497 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 400/4776 | Loss: 87.724 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 410/4776 | Loss: 62.728 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 420/4776 | Loss: 117.317 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 430/4776 | Loss: 64.966 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 440/4776 | Loss: 134.869 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 450/4776 | Loss: 97.198 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 460/4776 | Loss: 151.030 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 470/4776 | Loss: 46.303 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 480/4776 | Loss: 84.247 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 490/4776 | Loss: 81.719 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 500/4776 | Loss: 55.202 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 510/4776 | Loss: 64.124 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 520/4776 | Loss: 72.942 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 530/4776 | Loss: 54.124 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 540/4776 | Loss: 71.387 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 550/4776 | Loss: 67.821 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 560/4776 | Loss: 91.943 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 570/4776 | Loss: 83.939 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 580/4776 | Loss: 63.551 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 590/4776 | Loss: 84.821 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 600/4776 | Loss: 101.753 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 610/4776 | Loss: 39.458 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 620/4776 | Loss: 74.011 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 630/4776 | Loss: 64.007 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 640/4776 | Loss: 112.846 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 650/4776 | Loss: 49.861 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 660/4776 | Loss: 70.717 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 670/4776 | Loss: 76.273 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 680/4776 | Loss: 82.078 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 690/4776 | Loss: 75.711 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 700/4776 | Loss: 148.090 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 710/4776 | Loss: 114.201 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 720/4776 | Loss: 31.414 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 730/4776 | Loss: 41.576 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 740/4776 | Loss: 89.695 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 750/4776 | Loss: 103.427 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 760/4776 | Loss: 138.403 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 770/4776 | Loss: 61.143 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 780/4776 | Loss: 187.289 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 790/4776 | Loss: 110.206 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 800/4776 | Loss: 132.427 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 810/4776 | Loss: 86.760 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 820/4776 | Loss: 66.951 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 830/4776 | Loss: 123.191 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 840/4776 | Loss: 126.959 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 850/4776 | Loss: 78.948 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 860/4776 | Loss: 71.060 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 870/4776 | Loss: 79.041 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 880/4776 | Loss: 119.124 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 890/4776 | Loss: 73.720 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 900/4776 | Loss: 67.515 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 910/4776 | Loss: 74.375 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 920/4776 | Loss: 105.408 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 930/4776 | Loss: 88.876 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 940/4776 | Loss: 96.205 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 950/4776 | Loss: 70.738 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 960/4776 | Loss: 65.781 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 970/4776 | Loss: 99.914 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 980/4776 | Loss: 99.036 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 990/4776 | Loss: 95.565 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1000/4776 | Loss: 100.384 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1010/4776 | Loss: 44.998 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1020/4776 | Loss: 36.288 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1030/4776 | Loss: 108.748 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1040/4776 | Loss: 122.844 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1050/4776 | Loss: 119.457 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1060/4776 | Loss: 171.831 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 1070/4776 | Loss: 153.199 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1080/4776 | Loss: 45.449 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1090/4776 | Loss: 152.355 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 1100/4776 | Loss: 91.904 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1110/4776 | Loss: 84.637 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1120/4776 | Loss: 73.727 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1130/4776 | Loss: 41.611 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1140/4776 | Loss: 54.195 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1150/4776 | Loss: 90.604 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1160/4776 | Loss: 72.445 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1170/4776 | Loss: 102.538 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1180/4776 | Loss: 90.074 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1190/4776 | Loss: 35.010 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1200/4776 | Loss: 112.235 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1210/4776 | Loss: 103.131 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1220/4776 | Loss: 98.615 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1230/4776 | Loss: 77.553 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1240/4776 | Loss: 87.040 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1250/4776 | Loss: 82.024 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1260/4776 | Loss: 96.200 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1270/4776 | Loss: 86.357 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1280/4776 | Loss: 72.914 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1290/4776 | Loss: 175.203 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1300/4776 | Loss: 93.819 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1310/4776 | Loss: 68.347 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1320/4776 | Loss: 67.605 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1330/4776 | Loss: 81.962 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1340/4776 | Loss: 108.072 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1350/4776 | Loss: 39.121 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1360/4776 | Loss: 79.047 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1370/4776 | Loss: 99.407 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1380/4776 | Loss: 111.472 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 1390/4776 | Loss: 46.353 | Accuracy: 1.000\n",
      "[Epoch: 61/200] - Step: 1400/4776 | Loss: 79.503 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1410/4776 | Loss: 90.045 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1420/4776 | Loss: 75.736 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1430/4776 | Loss: 129.920 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1440/4776 | Loss: 172.187 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1450/4776 | Loss: 68.514 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1460/4776 | Loss: 85.652 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1470/4776 | Loss: 93.908 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1480/4776 | Loss: 88.063 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1490/4776 | Loss: 149.494 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 1500/4776 | Loss: 110.367 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1510/4776 | Loss: 64.051 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1520/4776 | Loss: 32.816 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1530/4776 | Loss: 97.328 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1540/4776 | Loss: 81.639 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1550/4776 | Loss: 62.549 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1560/4776 | Loss: 66.801 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1570/4776 | Loss: 100.294 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1580/4776 | Loss: 93.276 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1590/4776 | Loss: 66.666 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1600/4776 | Loss: 124.305 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1610/4776 | Loss: 89.104 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1620/4776 | Loss: 74.403 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1630/4776 | Loss: 112.754 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1640/4776 | Loss: 89.124 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1650/4776 | Loss: 53.428 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1660/4776 | Loss: 125.936 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1670/4776 | Loss: 80.810 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1680/4776 | Loss: 157.419 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1690/4776 | Loss: 84.942 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1700/4776 | Loss: 131.351 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1710/4776 | Loss: 127.718 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1720/4776 | Loss: 104.732 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1730/4776 | Loss: 133.807 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1740/4776 | Loss: 120.271 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1750/4776 | Loss: 78.388 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1760/4776 | Loss: 106.233 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1770/4776 | Loss: 106.841 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1780/4776 | Loss: 127.359 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1790/4776 | Loss: 89.716 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1800/4776 | Loss: 77.620 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1810/4776 | Loss: 95.316 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1820/4776 | Loss: 98.254 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1830/4776 | Loss: 132.701 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1840/4776 | Loss: 112.625 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1850/4776 | Loss: 127.053 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1860/4776 | Loss: 91.197 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1870/4776 | Loss: 86.914 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1880/4776 | Loss: 108.973 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1890/4776 | Loss: 76.427 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1900/4776 | Loss: 69.524 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1910/4776 | Loss: 51.993 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1920/4776 | Loss: 51.963 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1930/4776 | Loss: 33.162 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 1940/4776 | Loss: 65.102 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 1950/4776 | Loss: 56.691 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 1960/4776 | Loss: 101.969 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1970/4776 | Loss: 83.153 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 1980/4776 | Loss: 92.607 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 1990/4776 | Loss: 94.428 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2000/4776 | Loss: 71.858 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2010/4776 | Loss: 97.486 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2020/4776 | Loss: 61.162 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2030/4776 | Loss: 84.610 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2040/4776 | Loss: 41.683 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2050/4776 | Loss: 53.942 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2060/4776 | Loss: 90.337 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2070/4776 | Loss: 94.856 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2080/4776 | Loss: 80.598 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2090/4776 | Loss: 94.012 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2100/4776 | Loss: 35.319 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2110/4776 | Loss: 74.322 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2120/4776 | Loss: 81.745 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2130/4776 | Loss: 85.300 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2140/4776 | Loss: 97.323 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2150/4776 | Loss: 61.218 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2160/4776 | Loss: 33.793 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2170/4776 | Loss: 206.355 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2180/4776 | Loss: 78.227 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2190/4776 | Loss: 53.428 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2200/4776 | Loss: 116.891 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2210/4776 | Loss: 64.952 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2220/4776 | Loss: 81.476 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2230/4776 | Loss: 130.015 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2240/4776 | Loss: 127.931 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2250/4776 | Loss: 95.654 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2260/4776 | Loss: 128.341 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2270/4776 | Loss: 105.247 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 2280/4776 | Loss: 69.828 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2290/4776 | Loss: 80.168 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2300/4776 | Loss: 73.660 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2310/4776 | Loss: 43.475 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2320/4776 | Loss: 59.093 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2330/4776 | Loss: 93.533 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2340/4776 | Loss: 171.018 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 2350/4776 | Loss: 59.205 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2360/4776 | Loss: 139.988 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 2370/4776 | Loss: 92.154 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2380/4776 | Loss: 114.815 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2390/4776 | Loss: 46.348 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2400/4776 | Loss: 56.520 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2410/4776 | Loss: 60.278 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2420/4776 | Loss: 107.281 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2430/4776 | Loss: 98.171 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2440/4776 | Loss: 91.446 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2450/4776 | Loss: 103.647 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2460/4776 | Loss: 80.143 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2470/4776 | Loss: 82.639 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2480/4776 | Loss: 72.536 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2490/4776 | Loss: 82.887 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2500/4776 | Loss: 74.506 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2510/4776 | Loss: 78.566 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2520/4776 | Loss: 43.356 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2530/4776 | Loss: 93.416 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2540/4776 | Loss: 127.660 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2550/4776 | Loss: 85.897 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2560/4776 | Loss: 69.017 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2570/4776 | Loss: 55.876 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2580/4776 | Loss: 110.437 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2590/4776 | Loss: 55.312 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2600/4776 | Loss: 88.819 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2610/4776 | Loss: 76.775 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2620/4776 | Loss: 51.910 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2630/4776 | Loss: 102.195 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2640/4776 | Loss: 83.342 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2650/4776 | Loss: 74.235 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2660/4776 | Loss: 96.317 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2670/4776 | Loss: 71.173 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2680/4776 | Loss: 194.040 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2690/4776 | Loss: 144.786 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 2700/4776 | Loss: 58.781 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 2710/4776 | Loss: 104.230 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2720/4776 | Loss: 68.909 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2730/4776 | Loss: 147.851 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 2740/4776 | Loss: 59.858 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2750/4776 | Loss: 118.995 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2760/4776 | Loss: 129.613 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 2770/4776 | Loss: 82.417 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2780/4776 | Loss: 85.021 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2790/4776 | Loss: 16.866 | Accuracy: 1.000\n",
      "[Epoch: 61/200] - Step: 2800/4776 | Loss: 103.841 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2810/4776 | Loss: 128.933 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 2820/4776 | Loss: 41.341 | Accuracy: 1.000\n",
      "[Epoch: 61/200] - Step: 2830/4776 | Loss: 107.645 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2840/4776 | Loss: 95.349 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2850/4776 | Loss: 48.896 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2860/4776 | Loss: 71.131 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2870/4776 | Loss: 60.308 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2880/4776 | Loss: 88.967 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2890/4776 | Loss: 115.108 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 2900/4776 | Loss: 93.017 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2910/4776 | Loss: 74.471 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2920/4776 | Loss: 133.755 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2930/4776 | Loss: 53.380 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2940/4776 | Loss: 93.219 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2950/4776 | Loss: 72.456 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2960/4776 | Loss: 79.366 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 2970/4776 | Loss: 71.874 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 2980/4776 | Loss: 112.468 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 2990/4776 | Loss: 107.945 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3000/4776 | Loss: 109.855 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3010/4776 | Loss: 89.948 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3020/4776 | Loss: 114.477 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3030/4776 | Loss: 59.357 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3040/4776 | Loss: 57.273 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3050/4776 | Loss: 100.905 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3060/4776 | Loss: 68.060 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3070/4776 | Loss: 117.766 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3080/4776 | Loss: 78.821 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3090/4776 | Loss: 119.187 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3100/4776 | Loss: 130.747 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 3110/4776 | Loss: 123.443 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 3120/4776 | Loss: 88.153 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3130/4776 | Loss: 124.829 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 3140/4776 | Loss: 90.578 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3150/4776 | Loss: 100.705 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3160/4776 | Loss: 73.617 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3170/4776 | Loss: 66.081 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3180/4776 | Loss: 79.423 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3190/4776 | Loss: 84.752 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3200/4776 | Loss: 110.768 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3210/4776 | Loss: 91.435 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3220/4776 | Loss: 52.453 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3230/4776 | Loss: 96.908 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3240/4776 | Loss: 92.632 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3250/4776 | Loss: 81.967 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3260/4776 | Loss: 50.821 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3270/4776 | Loss: 52.314 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3280/4776 | Loss: 47.917 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3290/4776 | Loss: 86.670 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3300/4776 | Loss: 86.210 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3310/4776 | Loss: 67.350 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3320/4776 | Loss: 86.662 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3330/4776 | Loss: 64.743 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3340/4776 | Loss: 50.607 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3350/4776 | Loss: 69.893 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3360/4776 | Loss: 84.370 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3370/4776 | Loss: 113.286 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3380/4776 | Loss: 78.431 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3390/4776 | Loss: 86.896 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3400/4776 | Loss: 97.165 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3410/4776 | Loss: 114.531 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 3420/4776 | Loss: 92.672 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3430/4776 | Loss: 67.879 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3440/4776 | Loss: 52.371 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3450/4776 | Loss: 94.242 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 3460/4776 | Loss: 75.570 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3470/4776 | Loss: 68.861 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3480/4776 | Loss: 79.332 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3490/4776 | Loss: 92.871 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3500/4776 | Loss: 43.355 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3510/4776 | Loss: 58.809 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3520/4776 | Loss: 105.656 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3530/4776 | Loss: 46.963 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3540/4776 | Loss: 117.907 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3550/4776 | Loss: 89.422 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3560/4776 | Loss: 48.361 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3570/4776 | Loss: 96.771 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3580/4776 | Loss: 51.440 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3590/4776 | Loss: 57.295 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3600/4776 | Loss: 109.063 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3610/4776 | Loss: 69.538 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3620/4776 | Loss: 102.248 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3630/4776 | Loss: 152.785 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3640/4776 | Loss: 124.276 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3650/4776 | Loss: 78.981 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3660/4776 | Loss: 74.498 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3670/4776 | Loss: 69.493 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3680/4776 | Loss: 66.553 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3690/4776 | Loss: 72.153 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3700/4776 | Loss: 99.083 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3710/4776 | Loss: 50.123 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3720/4776 | Loss: 90.230 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3730/4776 | Loss: 58.326 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3740/4776 | Loss: 119.365 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 3750/4776 | Loss: 152.058 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 3760/4776 | Loss: 92.715 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3770/4776 | Loss: 63.424 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3780/4776 | Loss: 115.939 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3790/4776 | Loss: 119.815 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3800/4776 | Loss: 61.572 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3810/4776 | Loss: 83.760 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3820/4776 | Loss: 81.744 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3830/4776 | Loss: 135.851 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3840/4776 | Loss: 93.677 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3850/4776 | Loss: 90.320 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3860/4776 | Loss: 105.636 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3870/4776 | Loss: 105.543 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3880/4776 | Loss: 122.339 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3890/4776 | Loss: 84.873 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3900/4776 | Loss: 57.912 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3910/4776 | Loss: 72.102 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3920/4776 | Loss: 131.194 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 3930/4776 | Loss: 94.082 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 3940/4776 | Loss: 109.214 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3950/4776 | Loss: 56.098 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3960/4776 | Loss: 120.346 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 3970/4776 | Loss: 93.164 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 3980/4776 | Loss: 52.843 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 3990/4776 | Loss: 91.315 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4000/4776 | Loss: 56.567 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4010/4776 | Loss: 92.582 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4020/4776 | Loss: 99.633 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4030/4776 | Loss: 64.649 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 4040/4776 | Loss: 70.494 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4050/4776 | Loss: 100.260 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4060/4776 | Loss: 44.005 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 4070/4776 | Loss: 136.647 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 4080/4776 | Loss: 97.592 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4090/4776 | Loss: 47.222 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4100/4776 | Loss: 100.778 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4110/4776 | Loss: 114.163 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4120/4776 | Loss: 58.221 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4130/4776 | Loss: 36.161 | Accuracy: 1.000\n",
      "[Epoch: 61/200] - Step: 4140/4776 | Loss: 105.486 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4150/4776 | Loss: 91.210 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4160/4776 | Loss: 81.366 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4170/4776 | Loss: 53.576 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4180/4776 | Loss: 87.754 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4190/4776 | Loss: 87.501 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4200/4776 | Loss: 75.442 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4210/4776 | Loss: 148.713 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4220/4776 | Loss: 43.494 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 4230/4776 | Loss: 42.791 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4240/4776 | Loss: 110.468 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4250/4776 | Loss: 43.475 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 4260/4776 | Loss: 84.655 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4270/4776 | Loss: 84.909 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4280/4776 | Loss: 89.592 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4290/4776 | Loss: 103.326 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4300/4776 | Loss: 63.826 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4310/4776 | Loss: 98.062 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4320/4776 | Loss: 93.140 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4330/4776 | Loss: 72.904 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4340/4776 | Loss: 111.951 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4350/4776 | Loss: 70.060 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4360/4776 | Loss: 67.617 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4370/4776 | Loss: 115.958 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4380/4776 | Loss: 69.813 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4390/4776 | Loss: 45.955 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4400/4776 | Loss: 133.850 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4410/4776 | Loss: 56.492 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4420/4776 | Loss: 89.499 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4430/4776 | Loss: 85.664 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4440/4776 | Loss: 115.526 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4450/4776 | Loss: 117.110 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4460/4776 | Loss: 49.067 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4470/4776 | Loss: 81.175 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4480/4776 | Loss: 143.660 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4490/4776 | Loss: 171.041 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 4500/4776 | Loss: 75.238 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4510/4776 | Loss: 85.868 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4520/4776 | Loss: 96.310 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4530/4776 | Loss: 69.141 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4540/4776 | Loss: 76.146 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4550/4776 | Loss: 118.322 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4560/4776 | Loss: 90.075 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4570/4776 | Loss: 139.882 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4580/4776 | Loss: 136.770 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4590/4776 | Loss: 110.224 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4600/4776 | Loss: 126.940 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4610/4776 | Loss: 144.981 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 4620/4776 | Loss: 97.860 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4630/4776 | Loss: 69.047 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4640/4776 | Loss: 67.881 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4650/4776 | Loss: 82.997 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4660/4776 | Loss: 141.881 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4670/4776 | Loss: 92.788 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4680/4776 | Loss: 136.981 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 4690/4776 | Loss: 58.695 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4700/4776 | Loss: 65.237 | Accuracy: 0.900\n",
      "[Epoch: 61/200] - Step: 4710/4776 | Loss: 63.673 | Accuracy: 0.700\n",
      "[Epoch: 61/200] - Step: 4720/4776 | Loss: 57.545 | Accuracy: 0.800\n",
      "[Epoch: 61/200] - Step: 4730/4776 | Loss: 133.558 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 4740/4776 | Loss: 187.120 | Accuracy: 0.500\n",
      "[Epoch: 61/200] - Step: 4750/4776 | Loss: 134.388 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4760/4776 | Loss: 134.857 | Accuracy: 0.600\n",
      "[Epoch: 61/200] - Step: 4770/4776 | Loss: 85.783 | Accuracy: 0.800\n",
      "Accuracy:  0.2081967213114754\n",
      "[Epoch: 62/200] - Step: 10/4776 | Loss: 140.148 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 20/4776 | Loss: 90.760 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 30/4776 | Loss: 106.580 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 40/4776 | Loss: 78.949 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 50/4776 | Loss: 34.960 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 60/4776 | Loss: 58.784 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 70/4776 | Loss: 147.700 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 80/4776 | Loss: 72.523 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 90/4776 | Loss: 53.700 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 100/4776 | Loss: 74.146 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 110/4776 | Loss: 69.277 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 120/4776 | Loss: 138.950 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 130/4776 | Loss: 85.567 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 140/4776 | Loss: 65.859 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 150/4776 | Loss: 79.073 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 160/4776 | Loss: 44.349 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 170/4776 | Loss: 86.779 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 180/4776 | Loss: 56.073 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 190/4776 | Loss: 56.943 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 200/4776 | Loss: 27.649 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 210/4776 | Loss: 74.674 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 220/4776 | Loss: 103.068 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 230/4776 | Loss: 71.465 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 240/4776 | Loss: 116.079 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 250/4776 | Loss: 65.224 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 260/4776 | Loss: 98.734 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 270/4776 | Loss: 78.478 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 280/4776 | Loss: 101.617 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 290/4776 | Loss: 73.405 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 300/4776 | Loss: 142.987 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 310/4776 | Loss: 88.615 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 320/4776 | Loss: 61.460 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 330/4776 | Loss: 87.843 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 340/4776 | Loss: 18.885 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 350/4776 | Loss: 34.705 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 360/4776 | Loss: 45.081 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 370/4776 | Loss: 114.708 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 380/4776 | Loss: 65.213 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 390/4776 | Loss: 101.562 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 400/4776 | Loss: 74.552 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 410/4776 | Loss: 118.093 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 420/4776 | Loss: 112.867 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 430/4776 | Loss: 77.692 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 440/4776 | Loss: 92.813 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 450/4776 | Loss: 35.516 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 460/4776 | Loss: 116.294 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 470/4776 | Loss: 39.833 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 480/4776 | Loss: 70.825 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 490/4776 | Loss: 64.059 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 500/4776 | Loss: 73.533 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 510/4776 | Loss: 106.295 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 520/4776 | Loss: 118.826 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 530/4776 | Loss: 61.505 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 540/4776 | Loss: 102.627 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 550/4776 | Loss: 122.324 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 560/4776 | Loss: 95.718 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 570/4776 | Loss: 72.448 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 580/4776 | Loss: 294.047 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 590/4776 | Loss: 129.715 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 600/4776 | Loss: 124.294 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 610/4776 | Loss: 90.300 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 620/4776 | Loss: 117.121 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 630/4776 | Loss: 107.078 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 640/4776 | Loss: 40.948 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 650/4776 | Loss: 115.538 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 660/4776 | Loss: 156.149 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 670/4776 | Loss: 88.010 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 680/4776 | Loss: 98.259 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 690/4776 | Loss: 106.989 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 700/4776 | Loss: 86.886 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 710/4776 | Loss: 76.793 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 720/4776 | Loss: 38.355 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 730/4776 | Loss: 56.300 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 740/4776 | Loss: 53.222 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 750/4776 | Loss: 93.246 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 760/4776 | Loss: 80.759 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 770/4776 | Loss: 48.063 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 780/4776 | Loss: 70.642 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 790/4776 | Loss: 48.028 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 800/4776 | Loss: 72.636 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 810/4776 | Loss: 82.152 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 820/4776 | Loss: 167.082 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 830/4776 | Loss: 64.774 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 840/4776 | Loss: 61.946 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 850/4776 | Loss: 84.927 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 860/4776 | Loss: 107.714 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 870/4776 | Loss: 111.840 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 880/4776 | Loss: 82.498 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 890/4776 | Loss: 54.995 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 900/4776 | Loss: 88.733 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 910/4776 | Loss: 121.932 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 920/4776 | Loss: 103.438 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 930/4776 | Loss: 77.249 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 940/4776 | Loss: 48.854 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 950/4776 | Loss: 96.747 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 960/4776 | Loss: 101.011 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 970/4776 | Loss: 67.991 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 980/4776 | Loss: 64.170 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 990/4776 | Loss: 80.658 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1000/4776 | Loss: 95.331 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1010/4776 | Loss: 131.820 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 1020/4776 | Loss: 63.700 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1030/4776 | Loss: 56.900 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1040/4776 | Loss: 71.133 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1050/4776 | Loss: 63.470 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1060/4776 | Loss: 94.363 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1070/4776 | Loss: 90.387 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1080/4776 | Loss: 69.787 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1090/4776 | Loss: 91.410 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1100/4776 | Loss: 141.069 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1110/4776 | Loss: 85.020 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1120/4776 | Loss: 80.573 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1130/4776 | Loss: 54.011 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1140/4776 | Loss: 134.792 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1150/4776 | Loss: 171.382 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1160/4776 | Loss: 102.118 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1170/4776 | Loss: 102.145 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1180/4776 | Loss: 72.010 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1190/4776 | Loss: 87.755 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1200/4776 | Loss: 134.651 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1210/4776 | Loss: 95.637 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1220/4776 | Loss: 78.598 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1230/4776 | Loss: 117.725 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1240/4776 | Loss: 77.619 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1250/4776 | Loss: 52.855 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1260/4776 | Loss: 72.495 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1270/4776 | Loss: 129.537 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1280/4776 | Loss: 51.948 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1290/4776 | Loss: 60.517 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1300/4776 | Loss: 106.301 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1310/4776 | Loss: 32.433 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1320/4776 | Loss: 54.771 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1330/4776 | Loss: 74.727 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1340/4776 | Loss: 122.918 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1350/4776 | Loss: 68.584 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1360/4776 | Loss: 71.649 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1370/4776 | Loss: 65.838 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1380/4776 | Loss: 47.551 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1390/4776 | Loss: 74.026 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1400/4776 | Loss: 86.786 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1410/4776 | Loss: 67.285 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1420/4776 | Loss: 122.300 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1430/4776 | Loss: 40.273 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1440/4776 | Loss: 201.011 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 1450/4776 | Loss: 66.905 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1460/4776 | Loss: 123.554 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1470/4776 | Loss: 30.709 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1480/4776 | Loss: 88.030 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1490/4776 | Loss: 183.346 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 1500/4776 | Loss: 181.682 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 1510/4776 | Loss: 59.813 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1520/4776 | Loss: 70.550 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1530/4776 | Loss: 149.048 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1540/4776 | Loss: 91.292 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1550/4776 | Loss: 140.204 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1560/4776 | Loss: 120.281 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1570/4776 | Loss: 213.273 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1580/4776 | Loss: 126.240 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1590/4776 | Loss: 149.415 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1600/4776 | Loss: 129.104 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 1610/4776 | Loss: 69.018 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1620/4776 | Loss: 128.606 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1630/4776 | Loss: 106.117 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1640/4776 | Loss: 44.727 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1650/4776 | Loss: 93.077 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1660/4776 | Loss: 69.201 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1670/4776 | Loss: 48.077 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1680/4776 | Loss: 96.289 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1690/4776 | Loss: 101.115 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1700/4776 | Loss: 71.009 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1710/4776 | Loss: 49.141 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1720/4776 | Loss: 117.848 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1730/4776 | Loss: 50.258 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1740/4776 | Loss: 87.915 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1750/4776 | Loss: 100.212 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1760/4776 | Loss: 92.725 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1770/4776 | Loss: 119.352 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1780/4776 | Loss: 91.429 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1790/4776 | Loss: 123.046 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 1800/4776 | Loss: 62.414 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1810/4776 | Loss: 103.260 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1820/4776 | Loss: 115.970 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1830/4776 | Loss: 88.065 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1840/4776 | Loss: 51.983 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1850/4776 | Loss: 58.613 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1860/4776 | Loss: 79.967 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1870/4776 | Loss: 92.296 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1880/4776 | Loss: 137.988 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1890/4776 | Loss: 73.234 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 1900/4776 | Loss: 55.967 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1910/4776 | Loss: 135.067 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 1920/4776 | Loss: 101.775 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1930/4776 | Loss: 83.685 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1940/4776 | Loss: 107.567 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1950/4776 | Loss: 84.793 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1960/4776 | Loss: 43.297 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 1970/4776 | Loss: 61.047 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 1980/4776 | Loss: 95.136 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 1990/4776 | Loss: 81.190 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2000/4776 | Loss: 54.137 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2010/4776 | Loss: 125.609 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2020/4776 | Loss: 73.407 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2030/4776 | Loss: 10.222 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 2040/4776 | Loss: 73.354 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2050/4776 | Loss: 102.547 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2060/4776 | Loss: 89.308 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2070/4776 | Loss: 109.576 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2080/4776 | Loss: 91.260 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2090/4776 | Loss: 45.635 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2100/4776 | Loss: 58.590 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2110/4776 | Loss: 47.016 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2120/4776 | Loss: 62.342 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2130/4776 | Loss: 109.906 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2140/4776 | Loss: 78.245 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2150/4776 | Loss: 72.245 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2160/4776 | Loss: 109.182 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2170/4776 | Loss: 63.220 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2180/4776 | Loss: 115.170 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2190/4776 | Loss: 109.354 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2200/4776 | Loss: 83.366 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2210/4776 | Loss: 75.589 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2220/4776 | Loss: 149.664 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2230/4776 | Loss: 100.189 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2240/4776 | Loss: 78.970 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2250/4776 | Loss: 30.271 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2260/4776 | Loss: 74.668 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2270/4776 | Loss: 48.466 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2280/4776 | Loss: 71.522 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2290/4776 | Loss: 63.168 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2300/4776 | Loss: 57.242 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2310/4776 | Loss: 59.790 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2320/4776 | Loss: 70.194 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2330/4776 | Loss: 69.367 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2340/4776 | Loss: 63.064 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2350/4776 | Loss: 59.238 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2360/4776 | Loss: 125.965 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2370/4776 | Loss: 78.138 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2380/4776 | Loss: 33.577 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2390/4776 | Loss: 100.138 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2400/4776 | Loss: 117.812 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2410/4776 | Loss: 121.477 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2420/4776 | Loss: 118.074 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2430/4776 | Loss: 53.604 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2440/4776 | Loss: 94.711 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2450/4776 | Loss: 46.410 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2460/4776 | Loss: 140.683 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2470/4776 | Loss: 48.306 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2480/4776 | Loss: 65.975 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2490/4776 | Loss: 123.084 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2500/4776 | Loss: 60.181 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2510/4776 | Loss: 112.662 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2520/4776 | Loss: 43.029 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2530/4776 | Loss: 141.351 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 2540/4776 | Loss: 130.859 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2550/4776 | Loss: 126.869 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 2560/4776 | Loss: 39.151 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 2570/4776 | Loss: 89.977 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2580/4776 | Loss: 72.111 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2590/4776 | Loss: 49.729 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2600/4776 | Loss: 84.081 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2610/4776 | Loss: 94.039 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2620/4776 | Loss: 94.304 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2630/4776 | Loss: 64.663 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2640/4776 | Loss: 108.458 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2650/4776 | Loss: 45.314 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2660/4776 | Loss: 86.066 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2670/4776 | Loss: 50.843 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2680/4776 | Loss: 118.218 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2690/4776 | Loss: 83.893 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2700/4776 | Loss: 63.966 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2710/4776 | Loss: 29.565 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2720/4776 | Loss: 58.328 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2730/4776 | Loss: 68.528 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2740/4776 | Loss: 80.243 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2750/4776 | Loss: 32.110 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2760/4776 | Loss: 109.688 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2770/4776 | Loss: 91.335 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2780/4776 | Loss: 41.001 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2790/4776 | Loss: 62.068 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2800/4776 | Loss: 39.076 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2810/4776 | Loss: 44.731 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2820/4776 | Loss: 128.425 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2830/4776 | Loss: 42.448 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2840/4776 | Loss: 62.556 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2850/4776 | Loss: 127.236 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2860/4776 | Loss: 107.833 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2870/4776 | Loss: 87.742 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2880/4776 | Loss: 77.053 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2890/4776 | Loss: 57.584 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2900/4776 | Loss: 86.012 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2910/4776 | Loss: 82.453 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2920/4776 | Loss: 58.524 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 2930/4776 | Loss: 78.331 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2940/4776 | Loss: 40.262 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 2950/4776 | Loss: 72.880 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2960/4776 | Loss: 102.733 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 2970/4776 | Loss: 101.413 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 2980/4776 | Loss: 93.712 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 2990/4776 | Loss: 60.114 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3000/4776 | Loss: 63.813 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3010/4776 | Loss: 90.097 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3020/4776 | Loss: 128.558 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3030/4776 | Loss: 76.473 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3040/4776 | Loss: 106.421 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3050/4776 | Loss: 37.835 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3060/4776 | Loss: 74.267 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3070/4776 | Loss: 80.154 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3080/4776 | Loss: 36.510 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3090/4776 | Loss: 83.109 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3100/4776 | Loss: 70.128 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3110/4776 | Loss: 83.171 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3120/4776 | Loss: 88.624 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3130/4776 | Loss: 56.664 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3140/4776 | Loss: 131.968 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3150/4776 | Loss: 137.013 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3160/4776 | Loss: 61.146 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3170/4776 | Loss: 52.063 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3180/4776 | Loss: 102.328 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3190/4776 | Loss: 106.127 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3200/4776 | Loss: 100.137 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3210/4776 | Loss: 55.201 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3220/4776 | Loss: 70.946 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3230/4776 | Loss: 80.686 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3240/4776 | Loss: 78.837 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3250/4776 | Loss: 113.802 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3260/4776 | Loss: 110.097 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3270/4776 | Loss: 32.108 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 3280/4776 | Loss: 174.010 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3290/4776 | Loss: 73.148 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3300/4776 | Loss: 85.818 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3310/4776 | Loss: 76.976 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3320/4776 | Loss: 105.451 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3330/4776 | Loss: 137.701 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3340/4776 | Loss: 97.984 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3350/4776 | Loss: 60.075 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3360/4776 | Loss: 168.181 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3370/4776 | Loss: 73.881 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3380/4776 | Loss: 46.652 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3390/4776 | Loss: 19.582 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 3400/4776 | Loss: 106.652 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3410/4776 | Loss: 42.321 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3420/4776 | Loss: 97.920 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3430/4776 | Loss: 118.620 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3440/4776 | Loss: 77.977 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3450/4776 | Loss: 76.685 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3460/4776 | Loss: 142.225 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3470/4776 | Loss: 135.855 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3480/4776 | Loss: 170.199 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 3490/4776 | Loss: 70.188 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3500/4776 | Loss: 82.800 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3510/4776 | Loss: 97.717 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3520/4776 | Loss: 91.436 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3530/4776 | Loss: 94.036 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3540/4776 | Loss: 98.194 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3550/4776 | Loss: 71.896 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3560/4776 | Loss: 88.944 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3570/4776 | Loss: 113.762 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3580/4776 | Loss: 52.738 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3590/4776 | Loss: 42.150 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 3600/4776 | Loss: 63.042 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3610/4776 | Loss: 67.771 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3620/4776 | Loss: 68.974 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3630/4776 | Loss: 113.468 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3640/4776 | Loss: 117.416 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3650/4776 | Loss: 152.900 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3660/4776 | Loss: 104.498 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3670/4776 | Loss: 140.039 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3680/4776 | Loss: 76.267 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3690/4776 | Loss: 122.245 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3700/4776 | Loss: 118.355 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3710/4776 | Loss: 89.494 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3720/4776 | Loss: 61.302 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3730/4776 | Loss: 112.499 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3740/4776 | Loss: 35.629 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3750/4776 | Loss: 84.797 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3760/4776 | Loss: 58.944 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3770/4776 | Loss: 33.995 | Accuracy: 1.000\n",
      "[Epoch: 62/200] - Step: 3780/4776 | Loss: 68.197 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3790/4776 | Loss: 99.836 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3800/4776 | Loss: 56.895 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3810/4776 | Loss: 25.334 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3820/4776 | Loss: 57.098 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3830/4776 | Loss: 128.016 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3840/4776 | Loss: 41.653 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3850/4776 | Loss: 108.484 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3860/4776 | Loss: 50.579 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 3870/4776 | Loss: 79.801 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3880/4776 | Loss: 113.948 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3890/4776 | Loss: 100.940 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3900/4776 | Loss: 156.497 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3910/4776 | Loss: 62.797 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3920/4776 | Loss: 166.484 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3930/4776 | Loss: 56.994 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3940/4776 | Loss: 124.176 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 3950/4776 | Loss: 50.670 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 3960/4776 | Loss: 79.299 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 3970/4776 | Loss: 113.324 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 3980/4776 | Loss: 143.952 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 3990/4776 | Loss: 68.135 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4000/4776 | Loss: 62.017 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4010/4776 | Loss: 198.489 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4020/4776 | Loss: 60.568 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 4030/4776 | Loss: 86.828 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4040/4776 | Loss: 61.755 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4050/4776 | Loss: 139.567 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4060/4776 | Loss: 64.649 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4070/4776 | Loss: 74.764 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4080/4776 | Loss: 115.260 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4090/4776 | Loss: 75.893 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4100/4776 | Loss: 97.227 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4110/4776 | Loss: 76.104 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4120/4776 | Loss: 68.650 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4130/4776 | Loss: 59.140 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4140/4776 | Loss: 84.806 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4150/4776 | Loss: 102.979 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4160/4776 | Loss: 65.195 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4170/4776 | Loss: 104.524 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4180/4776 | Loss: 58.312 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4190/4776 | Loss: 72.760 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4200/4776 | Loss: 112.059 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4210/4776 | Loss: 106.359 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4220/4776 | Loss: 69.836 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4230/4776 | Loss: 102.581 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4240/4776 | Loss: 55.899 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4250/4776 | Loss: 124.939 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4260/4776 | Loss: 79.472 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4270/4776 | Loss: 95.077 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4280/4776 | Loss: 147.731 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4290/4776 | Loss: 65.362 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4300/4776 | Loss: 76.394 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4310/4776 | Loss: 395.270 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4320/4776 | Loss: 135.754 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4330/4776 | Loss: 138.921 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4340/4776 | Loss: 224.113 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4350/4776 | Loss: 252.287 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 4360/4776 | Loss: 151.154 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4370/4776 | Loss: 175.704 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 4380/4776 | Loss: 122.122 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4390/4776 | Loss: 153.995 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 4400/4776 | Loss: 137.768 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4410/4776 | Loss: 108.635 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4420/4776 | Loss: 55.356 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4430/4776 | Loss: 92.799 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4440/4776 | Loss: 59.606 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4450/4776 | Loss: 199.086 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 4460/4776 | Loss: 95.422 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4470/4776 | Loss: 92.563 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4480/4776 | Loss: 86.373 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4490/4776 | Loss: 123.323 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4500/4776 | Loss: 151.858 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4510/4776 | Loss: 93.910 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4520/4776 | Loss: 73.995 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4530/4776 | Loss: 60.059 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4540/4776 | Loss: 105.971 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4550/4776 | Loss: 87.905 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4560/4776 | Loss: 96.744 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4570/4776 | Loss: 48.964 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4580/4776 | Loss: 68.412 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4590/4776 | Loss: 109.596 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4600/4776 | Loss: 111.026 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4610/4776 | Loss: 105.598 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4620/4776 | Loss: 84.159 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4630/4776 | Loss: 75.680 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4640/4776 | Loss: 77.794 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4650/4776 | Loss: 83.525 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4660/4776 | Loss: 85.757 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4670/4776 | Loss: 83.371 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4680/4776 | Loss: 122.813 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 4690/4776 | Loss: 161.782 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4700/4776 | Loss: 92.201 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4710/4776 | Loss: 108.711 | Accuracy: 0.600\n",
      "[Epoch: 62/200] - Step: 4720/4776 | Loss: 42.159 | Accuracy: 0.900\n",
      "[Epoch: 62/200] - Step: 4730/4776 | Loss: 165.884 | Accuracy: 0.500\n",
      "[Epoch: 62/200] - Step: 4740/4776 | Loss: 55.435 | Accuracy: 0.800\n",
      "[Epoch: 62/200] - Step: 4750/4776 | Loss: 135.437 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 4760/4776 | Loss: 86.346 | Accuracy: 0.700\n",
      "[Epoch: 62/200] - Step: 4770/4776 | Loss: 87.842 | Accuracy: 0.600\n",
      "Accuracy:  0.22131147540983606\n",
      "[Epoch: 63/200] - Step: 10/4776 | Loss: 49.691 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 20/4776 | Loss: 113.062 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 30/4776 | Loss: 69.939 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 40/4776 | Loss: 84.991 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 50/4776 | Loss: 107.516 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 60/4776 | Loss: 68.401 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 70/4776 | Loss: 65.637 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 80/4776 | Loss: 36.447 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 90/4776 | Loss: 80.520 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 100/4776 | Loss: 61.742 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 110/4776 | Loss: 67.845 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 120/4776 | Loss: 102.648 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 130/4776 | Loss: 99.678 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 140/4776 | Loss: 49.905 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 150/4776 | Loss: 70.391 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 160/4776 | Loss: 52.977 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 170/4776 | Loss: 94.775 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 180/4776 | Loss: 34.275 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 190/4776 | Loss: 84.416 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 200/4776 | Loss: 101.877 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 210/4776 | Loss: 29.988 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 220/4776 | Loss: 18.217 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 230/4776 | Loss: 70.843 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 240/4776 | Loss: 80.778 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 250/4776 | Loss: 65.933 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 260/4776 | Loss: 71.752 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 270/4776 | Loss: 44.499 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 280/4776 | Loss: 82.805 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 290/4776 | Loss: 65.198 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 300/4776 | Loss: 82.242 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 310/4776 | Loss: 74.036 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 320/4776 | Loss: 52.843 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 330/4776 | Loss: 38.054 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 340/4776 | Loss: 151.609 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 350/4776 | Loss: 99.092 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 360/4776 | Loss: 60.419 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 370/4776 | Loss: 78.762 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 380/4776 | Loss: 82.529 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 390/4776 | Loss: 60.316 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 400/4776 | Loss: 49.769 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 410/4776 | Loss: 57.637 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 420/4776 | Loss: 51.494 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 430/4776 | Loss: 104.724 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 440/4776 | Loss: 150.563 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 450/4776 | Loss: 124.932 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 460/4776 | Loss: 116.264 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 470/4776 | Loss: 162.775 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 480/4776 | Loss: 68.029 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 490/4776 | Loss: 99.486 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 500/4776 | Loss: 64.766 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 510/4776 | Loss: 40.945 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 520/4776 | Loss: 88.133 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 530/4776 | Loss: 104.951 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 540/4776 | Loss: 31.346 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 550/4776 | Loss: 72.804 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 560/4776 | Loss: 92.971 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 570/4776 | Loss: 116.119 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 580/4776 | Loss: 98.891 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 590/4776 | Loss: 84.102 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 600/4776 | Loss: 69.758 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 610/4776 | Loss: 55.026 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 620/4776 | Loss: 159.756 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 630/4776 | Loss: 39.234 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 640/4776 | Loss: 87.071 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 650/4776 | Loss: 76.102 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 660/4776 | Loss: 97.596 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 670/4776 | Loss: 52.449 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 680/4776 | Loss: 89.688 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 690/4776 | Loss: 40.969 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 700/4776 | Loss: 80.199 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 710/4776 | Loss: 77.241 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 720/4776 | Loss: 109.925 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 730/4776 | Loss: 120.231 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 740/4776 | Loss: 42.297 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 750/4776 | Loss: 62.624 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 760/4776 | Loss: 53.740 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 770/4776 | Loss: 76.288 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 780/4776 | Loss: 64.061 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 790/4776 | Loss: 41.226 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 800/4776 | Loss: 72.711 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 810/4776 | Loss: 88.441 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 820/4776 | Loss: 40.038 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 830/4776 | Loss: 68.496 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 840/4776 | Loss: 33.398 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 850/4776 | Loss: 83.619 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 860/4776 | Loss: 86.253 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 870/4776 | Loss: 111.145 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 880/4776 | Loss: 49.033 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 890/4776 | Loss: 97.960 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 900/4776 | Loss: 62.811 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 910/4776 | Loss: 86.133 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 920/4776 | Loss: 137.231 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 930/4776 | Loss: 93.495 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 940/4776 | Loss: 91.003 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 950/4776 | Loss: 109.463 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 960/4776 | Loss: 79.181 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 970/4776 | Loss: 101.263 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 980/4776 | Loss: 85.195 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 990/4776 | Loss: 89.729 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1000/4776 | Loss: 70.954 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1010/4776 | Loss: 48.255 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1020/4776 | Loss: 87.573 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1030/4776 | Loss: 107.250 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1040/4776 | Loss: 87.833 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1050/4776 | Loss: 86.789 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1060/4776 | Loss: 67.555 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1070/4776 | Loss: 105.711 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1080/4776 | Loss: 60.201 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1090/4776 | Loss: 71.716 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1100/4776 | Loss: 41.771 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1110/4776 | Loss: 85.319 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1120/4776 | Loss: 108.630 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1130/4776 | Loss: 60.094 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1140/4776 | Loss: 73.272 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1150/4776 | Loss: 62.163 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1160/4776 | Loss: 160.955 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 1170/4776 | Loss: 65.057 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1180/4776 | Loss: 148.551 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1190/4776 | Loss: 121.733 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1200/4776 | Loss: 96.293 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1210/4776 | Loss: 101.614 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 1220/4776 | Loss: 31.699 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1230/4776 | Loss: 88.836 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1240/4776 | Loss: 68.863 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1250/4776 | Loss: 125.556 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1260/4776 | Loss: 65.782 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1270/4776 | Loss: 59.550 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1280/4776 | Loss: 59.632 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1290/4776 | Loss: 73.436 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1300/4776 | Loss: 33.121 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1310/4776 | Loss: 84.529 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1320/4776 | Loss: 83.484 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1330/4776 | Loss: 119.022 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1340/4776 | Loss: 78.374 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1350/4776 | Loss: 90.898 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1360/4776 | Loss: 66.947 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1370/4776 | Loss: 119.016 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1380/4776 | Loss: 53.518 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1390/4776 | Loss: 74.875 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1400/4776 | Loss: 74.452 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1410/4776 | Loss: 89.580 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1420/4776 | Loss: 112.886 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1430/4776 | Loss: 92.849 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1440/4776 | Loss: 83.350 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1450/4776 | Loss: 120.659 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 1460/4776 | Loss: 93.933 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1470/4776 | Loss: 62.448 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1480/4776 | Loss: 39.244 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1490/4776 | Loss: 76.716 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1500/4776 | Loss: 106.180 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1510/4776 | Loss: 82.930 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1520/4776 | Loss: 89.223 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1530/4776 | Loss: 42.473 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1540/4776 | Loss: 130.487 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1550/4776 | Loss: 129.480 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1560/4776 | Loss: 109.800 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1570/4776 | Loss: 66.585 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1580/4776 | Loss: 109.736 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1590/4776 | Loss: 77.143 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1600/4776 | Loss: 63.690 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1610/4776 | Loss: 51.277 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1620/4776 | Loss: 59.870 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1630/4776 | Loss: 71.902 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1640/4776 | Loss: 70.406 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1650/4776 | Loss: 143.576 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1660/4776 | Loss: 80.700 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1670/4776 | Loss: 59.063 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1680/4776 | Loss: 99.426 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1690/4776 | Loss: 92.452 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1700/4776 | Loss: 66.178 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1710/4776 | Loss: 73.054 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1720/4776 | Loss: 147.222 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 1730/4776 | Loss: 113.828 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 1740/4776 | Loss: 23.960 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1750/4776 | Loss: 112.303 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1760/4776 | Loss: 79.830 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1770/4776 | Loss: 98.201 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1780/4776 | Loss: 65.864 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1790/4776 | Loss: 113.616 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1800/4776 | Loss: 51.622 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1810/4776 | Loss: 103.471 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1820/4776 | Loss: 34.942 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 1830/4776 | Loss: 134.961 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1840/4776 | Loss: 67.593 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1850/4776 | Loss: 26.315 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1860/4776 | Loss: 45.685 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 1870/4776 | Loss: 139.274 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1880/4776 | Loss: 89.775 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1890/4776 | Loss: 82.691 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1900/4776 | Loss: 94.407 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 1910/4776 | Loss: 80.192 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1920/4776 | Loss: 68.936 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1930/4776 | Loss: 194.956 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1940/4776 | Loss: 67.836 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 1950/4776 | Loss: 62.976 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 1960/4776 | Loss: 97.923 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1970/4776 | Loss: 125.152 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1980/4776 | Loss: 121.416 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 1990/4776 | Loss: 70.499 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2000/4776 | Loss: 84.257 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2010/4776 | Loss: 49.786 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2020/4776 | Loss: 117.973 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2030/4776 | Loss: 92.164 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2040/4776 | Loss: 153.921 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2050/4776 | Loss: 144.094 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2060/4776 | Loss: 51.123 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2070/4776 | Loss: 134.343 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 2080/4776 | Loss: 62.498 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2090/4776 | Loss: 96.137 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2100/4776 | Loss: 46.005 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2110/4776 | Loss: 61.227 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2120/4776 | Loss: 108.016 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2130/4776 | Loss: 67.232 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2140/4776 | Loss: 81.491 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2150/4776 | Loss: 94.337 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2160/4776 | Loss: 129.055 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2170/4776 | Loss: 99.346 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2180/4776 | Loss: 86.354 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2190/4776 | Loss: 128.319 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2200/4776 | Loss: 83.951 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2210/4776 | Loss: 105.977 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2220/4776 | Loss: 69.097 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2230/4776 | Loss: 55.788 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2240/4776 | Loss: 43.879 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2250/4776 | Loss: 97.571 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2260/4776 | Loss: 86.400 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2270/4776 | Loss: 106.216 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2280/4776 | Loss: 43.733 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 2290/4776 | Loss: 114.276 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 2300/4776 | Loss: 99.444 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2310/4776 | Loss: 81.688 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2320/4776 | Loss: 92.906 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2330/4776 | Loss: 72.486 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2340/4776 | Loss: 68.723 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2350/4776 | Loss: 103.229 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2360/4776 | Loss: 56.168 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2370/4776 | Loss: 60.201 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2380/4776 | Loss: 42.602 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 2390/4776 | Loss: 91.601 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2400/4776 | Loss: 89.705 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2410/4776 | Loss: 64.698 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2420/4776 | Loss: 63.210 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2430/4776 | Loss: 88.473 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2440/4776 | Loss: 76.132 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2450/4776 | Loss: 64.504 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2460/4776 | Loss: 90.156 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2470/4776 | Loss: 139.062 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2480/4776 | Loss: 64.882 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2490/4776 | Loss: 85.903 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2500/4776 | Loss: 101.995 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2510/4776 | Loss: 125.332 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 2520/4776 | Loss: 138.611 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2530/4776 | Loss: 69.772 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2540/4776 | Loss: 59.742 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2550/4776 | Loss: 107.895 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 2560/4776 | Loss: 59.180 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2570/4776 | Loss: 46.130 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 2580/4776 | Loss: 13.741 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 2590/4776 | Loss: 85.668 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2600/4776 | Loss: 119.502 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2610/4776 | Loss: 73.830 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2620/4776 | Loss: 97.582 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2630/4776 | Loss: 47.192 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2640/4776 | Loss: 137.315 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2650/4776 | Loss: 57.656 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2660/4776 | Loss: 64.578 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 2670/4776 | Loss: 40.103 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2680/4776 | Loss: 77.548 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2690/4776 | Loss: 136.253 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2700/4776 | Loss: 24.751 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 2710/4776 | Loss: 114.386 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 2720/4776 | Loss: 110.304 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 2730/4776 | Loss: 101.987 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2740/4776 | Loss: 122.174 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2750/4776 | Loss: 71.464 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 2760/4776 | Loss: 89.762 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2770/4776 | Loss: 152.959 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2780/4776 | Loss: 223.543 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 2790/4776 | Loss: 54.517 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2800/4776 | Loss: 72.850 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2810/4776 | Loss: 96.817 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2820/4776 | Loss: 52.198 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2830/4776 | Loss: 101.436 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2840/4776 | Loss: 66.608 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2850/4776 | Loss: 45.470 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2860/4776 | Loss: 126.045 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 2870/4776 | Loss: 73.251 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2880/4776 | Loss: 174.103 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2890/4776 | Loss: 119.037 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2900/4776 | Loss: 63.091 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2910/4776 | Loss: 99.479 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 2920/4776 | Loss: 46.409 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2930/4776 | Loss: 62.186 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2940/4776 | Loss: 33.353 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 2950/4776 | Loss: 63.900 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 2960/4776 | Loss: 71.500 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 2970/4776 | Loss: 42.883 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2980/4776 | Loss: 55.368 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 2990/4776 | Loss: 116.495 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3000/4776 | Loss: 77.653 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3010/4776 | Loss: 77.504 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3020/4776 | Loss: 40.180 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3030/4776 | Loss: 82.224 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3040/4776 | Loss: 121.106 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3050/4776 | Loss: 66.347 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3060/4776 | Loss: 108.737 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3070/4776 | Loss: 68.176 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3080/4776 | Loss: 48.817 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 3090/4776 | Loss: 40.322 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3100/4776 | Loss: 41.245 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3110/4776 | Loss: 49.914 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3120/4776 | Loss: 61.947 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3130/4776 | Loss: 128.949 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3140/4776 | Loss: 138.584 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 3150/4776 | Loss: 116.761 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3160/4776 | Loss: 74.718 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3170/4776 | Loss: 79.696 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3180/4776 | Loss: 108.103 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3190/4776 | Loss: 101.982 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3200/4776 | Loss: 148.986 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 3210/4776 | Loss: 100.701 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3220/4776 | Loss: 82.142 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3230/4776 | Loss: 184.955 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 3240/4776 | Loss: 127.479 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3250/4776 | Loss: 53.098 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3260/4776 | Loss: 62.515 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3270/4776 | Loss: 92.993 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3280/4776 | Loss: 73.355 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3290/4776 | Loss: 123.950 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3300/4776 | Loss: 55.809 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3310/4776 | Loss: 57.560 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3320/4776 | Loss: 78.230 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3330/4776 | Loss: 79.630 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3340/4776 | Loss: 37.560 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3350/4776 | Loss: 126.408 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3360/4776 | Loss: 54.009 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3370/4776 | Loss: 113.059 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3380/4776 | Loss: 51.140 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3390/4776 | Loss: 69.793 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3400/4776 | Loss: 154.374 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 3410/4776 | Loss: 91.337 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3420/4776 | Loss: 86.843 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3430/4776 | Loss: 66.588 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3440/4776 | Loss: 140.969 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3450/4776 | Loss: 120.065 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3460/4776 | Loss: 81.208 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3470/4776 | Loss: 110.019 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3480/4776 | Loss: 78.074 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3490/4776 | Loss: 90.472 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3500/4776 | Loss: 94.212 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3510/4776 | Loss: 82.069 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3520/4776 | Loss: 150.481 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 3530/4776 | Loss: 66.157 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3540/4776 | Loss: 110.135 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3550/4776 | Loss: 99.869 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3560/4776 | Loss: 83.123 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3570/4776 | Loss: 133.126 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3580/4776 | Loss: 102.666 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3590/4776 | Loss: 75.336 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3600/4776 | Loss: 137.649 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 3610/4776 | Loss: 94.054 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3620/4776 | Loss: 70.991 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3630/4776 | Loss: 124.128 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 3640/4776 | Loss: 123.321 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3650/4776 | Loss: 78.517 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3660/4776 | Loss: 58.578 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3670/4776 | Loss: 98.908 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3680/4776 | Loss: 77.968 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3690/4776 | Loss: 71.342 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3700/4776 | Loss: 79.955 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3710/4776 | Loss: 102.560 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3720/4776 | Loss: 94.907 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3730/4776 | Loss: 97.770 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3740/4776 | Loss: 69.920 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3750/4776 | Loss: 61.829 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3760/4776 | Loss: 129.936 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3770/4776 | Loss: 39.185 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3780/4776 | Loss: 67.885 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3790/4776 | Loss: 47.415 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3800/4776 | Loss: 92.567 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 3810/4776 | Loss: 81.315 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3820/4776 | Loss: 120.235 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3830/4776 | Loss: 60.338 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3840/4776 | Loss: 51.852 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3850/4776 | Loss: 70.771 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3860/4776 | Loss: 73.973 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3870/4776 | Loss: 91.315 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3880/4776 | Loss: 89.716 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3890/4776 | Loss: 28.198 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 3900/4776 | Loss: 37.306 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3910/4776 | Loss: 35.569 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 3920/4776 | Loss: 65.713 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3930/4776 | Loss: 89.728 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3940/4776 | Loss: 52.807 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3950/4776 | Loss: 75.025 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3960/4776 | Loss: 55.760 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 3970/4776 | Loss: 68.212 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 3980/4776 | Loss: 44.578 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 3990/4776 | Loss: 83.072 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4000/4776 | Loss: 36.666 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4010/4776 | Loss: 109.045 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4020/4776 | Loss: 39.734 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4030/4776 | Loss: 65.055 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4040/4776 | Loss: 100.886 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4050/4776 | Loss: 109.954 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4060/4776 | Loss: 114.041 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4070/4776 | Loss: 53.816 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4080/4776 | Loss: 115.877 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4090/4776 | Loss: 133.381 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 4100/4776 | Loss: 121.379 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4110/4776 | Loss: 89.975 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4120/4776 | Loss: 74.229 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4130/4776 | Loss: 47.389 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4140/4776 | Loss: 50.109 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4150/4776 | Loss: 67.486 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4160/4776 | Loss: 74.657 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4170/4776 | Loss: 40.519 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4180/4776 | Loss: 67.273 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4190/4776 | Loss: 65.990 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4200/4776 | Loss: 134.767 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4210/4776 | Loss: 83.926 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4220/4776 | Loss: 78.533 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4230/4776 | Loss: 62.063 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4240/4776 | Loss: 58.514 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4250/4776 | Loss: 107.257 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4260/4776 | Loss: 92.230 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4270/4776 | Loss: 91.735 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4280/4776 | Loss: 121.245 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 4290/4776 | Loss: 91.674 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4300/4776 | Loss: 136.422 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 4310/4776 | Loss: 47.788 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4320/4776 | Loss: 76.332 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4330/4776 | Loss: 112.080 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4340/4776 | Loss: 61.226 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4350/4776 | Loss: 67.890 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4360/4776 | Loss: 40.772 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4370/4776 | Loss: 55.333 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4380/4776 | Loss: 31.972 | Accuracy: 1.000\n",
      "[Epoch: 63/200] - Step: 4390/4776 | Loss: 83.594 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4400/4776 | Loss: 85.496 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4410/4776 | Loss: 72.851 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4420/4776 | Loss: 58.955 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4430/4776 | Loss: 92.026 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4440/4776 | Loss: 63.073 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4450/4776 | Loss: 52.998 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4460/4776 | Loss: 97.930 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4470/4776 | Loss: 130.756 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4480/4776 | Loss: 47.038 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4490/4776 | Loss: 98.915 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4500/4776 | Loss: 43.755 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4510/4776 | Loss: 103.766 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4520/4776 | Loss: 61.698 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4530/4776 | Loss: 88.408 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4540/4776 | Loss: 56.655 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4550/4776 | Loss: 131.846 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4560/4776 | Loss: 89.043 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4570/4776 | Loss: 82.249 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4580/4776 | Loss: 72.053 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4590/4776 | Loss: 39.768 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4600/4776 | Loss: 130.158 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4610/4776 | Loss: 46.545 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4620/4776 | Loss: 162.744 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4630/4776 | Loss: 105.002 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4640/4776 | Loss: 72.577 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4650/4776 | Loss: 61.838 | Accuracy: 0.700\n",
      "[Epoch: 63/200] - Step: 4660/4776 | Loss: 52.319 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4670/4776 | Loss: 144.893 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4680/4776 | Loss: 68.297 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4690/4776 | Loss: 115.395 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4700/4776 | Loss: 95.995 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4710/4776 | Loss: 98.968 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 4720/4776 | Loss: 51.707 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4730/4776 | Loss: 61.052 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4740/4776 | Loss: 27.476 | Accuracy: 0.900\n",
      "[Epoch: 63/200] - Step: 4750/4776 | Loss: 92.371 | Accuracy: 0.600\n",
      "[Epoch: 63/200] - Step: 4760/4776 | Loss: 41.439 | Accuracy: 0.800\n",
      "[Epoch: 63/200] - Step: 4770/4776 | Loss: 43.402 | Accuracy: 0.900\n",
      "Accuracy:  0.22950819672131148\n",
      "Model saved!\n",
      "[Epoch: 64/200] - Step: 10/4776 | Loss: 59.381 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 20/4776 | Loss: 88.484 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 30/4776 | Loss: 98.556 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 40/4776 | Loss: 109.605 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 50/4776 | Loss: 104.080 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 60/4776 | Loss: 33.183 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 70/4776 | Loss: 67.046 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 80/4776 | Loss: 105.029 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 90/4776 | Loss: 46.395 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 100/4776 | Loss: 69.260 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 110/4776 | Loss: 51.815 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 120/4776 | Loss: 85.519 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 130/4776 | Loss: 85.757 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 140/4776 | Loss: 69.115 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 150/4776 | Loss: 74.363 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 160/4776 | Loss: 58.690 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 170/4776 | Loss: 97.134 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 180/4776 | Loss: 70.921 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 190/4776 | Loss: 133.513 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 200/4776 | Loss: 48.066 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 210/4776 | Loss: 91.697 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 220/4776 | Loss: 92.522 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 230/4776 | Loss: 90.357 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 240/4776 | Loss: 89.742 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 250/4776 | Loss: 36.300 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 260/4776 | Loss: 55.947 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 270/4776 | Loss: 137.938 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 280/4776 | Loss: 49.821 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 290/4776 | Loss: 53.127 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 300/4776 | Loss: 75.718 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 310/4776 | Loss: 90.594 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 320/4776 | Loss: 48.470 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 330/4776 | Loss: 60.988 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 340/4776 | Loss: 57.706 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 350/4776 | Loss: 130.115 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 360/4776 | Loss: 68.428 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 370/4776 | Loss: 89.962 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 380/4776 | Loss: 149.992 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 390/4776 | Loss: 30.603 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 400/4776 | Loss: 98.075 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 410/4776 | Loss: 132.708 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 420/4776 | Loss: 107.192 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 430/4776 | Loss: 109.606 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 440/4776 | Loss: 69.246 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 450/4776 | Loss: 114.789 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 460/4776 | Loss: 115.709 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 470/4776 | Loss: 108.606 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 480/4776 | Loss: 99.210 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 490/4776 | Loss: 64.276 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 500/4776 | Loss: 58.829 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 510/4776 | Loss: 100.919 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 520/4776 | Loss: 57.209 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 530/4776 | Loss: 58.855 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 540/4776 | Loss: 78.837 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 550/4776 | Loss: 87.162 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 560/4776 | Loss: 71.102 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 570/4776 | Loss: 28.406 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 580/4776 | Loss: 76.821 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 590/4776 | Loss: 78.254 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 600/4776 | Loss: 80.277 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 610/4776 | Loss: 43.996 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 620/4776 | Loss: 56.825 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 630/4776 | Loss: 67.765 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 640/4776 | Loss: 99.037 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 650/4776 | Loss: 82.958 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 660/4776 | Loss: 59.757 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 670/4776 | Loss: 83.864 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 680/4776 | Loss: 89.001 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 690/4776 | Loss: 114.690 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 700/4776 | Loss: 40.696 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 710/4776 | Loss: 10.230 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 720/4776 | Loss: 41.256 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 730/4776 | Loss: 53.184 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 740/4776 | Loss: 136.252 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 750/4776 | Loss: 49.310 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 760/4776 | Loss: 69.908 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 770/4776 | Loss: 66.911 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 780/4776 | Loss: 61.804 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 790/4776 | Loss: 105.238 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 800/4776 | Loss: 111.634 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 810/4776 | Loss: 42.218 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 820/4776 | Loss: 32.555 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 830/4776 | Loss: 136.054 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 840/4776 | Loss: 54.443 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 850/4776 | Loss: 67.497 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 860/4776 | Loss: 97.569 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 870/4776 | Loss: 48.408 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 880/4776 | Loss: 75.504 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 890/4776 | Loss: 91.241 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 900/4776 | Loss: 62.093 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 910/4776 | Loss: 139.631 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 920/4776 | Loss: 106.761 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 930/4776 | Loss: 137.181 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 940/4776 | Loss: 116.195 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 950/4776 | Loss: 82.572 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 960/4776 | Loss: 99.605 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 970/4776 | Loss: 123.596 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 980/4776 | Loss: 76.858 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 990/4776 | Loss: 67.699 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1000/4776 | Loss: 113.390 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1010/4776 | Loss: 83.638 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1020/4776 | Loss: 56.235 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1030/4776 | Loss: 80.497 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1040/4776 | Loss: 73.975 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1050/4776 | Loss: 71.723 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1060/4776 | Loss: 58.974 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1070/4776 | Loss: 188.093 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1080/4776 | Loss: 113.989 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1090/4776 | Loss: 51.673 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1100/4776 | Loss: 61.783 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1110/4776 | Loss: 69.095 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1120/4776 | Loss: 35.159 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 1130/4776 | Loss: 101.754 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1140/4776 | Loss: 42.503 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1150/4776 | Loss: 109.443 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1160/4776 | Loss: 48.623 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1170/4776 | Loss: 108.038 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1180/4776 | Loss: 74.012 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1190/4776 | Loss: 98.796 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1200/4776 | Loss: 128.294 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1210/4776 | Loss: 69.114 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1220/4776 | Loss: 54.698 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1230/4776 | Loss: 93.531 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1240/4776 | Loss: 135.922 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1250/4776 | Loss: 48.576 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1260/4776 | Loss: 132.484 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1270/4776 | Loss: 53.239 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1280/4776 | Loss: 74.780 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1290/4776 | Loss: 85.493 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1300/4776 | Loss: 79.596 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1310/4776 | Loss: 80.147 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1320/4776 | Loss: 37.075 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 1330/4776 | Loss: 116.221 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1340/4776 | Loss: 45.668 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1350/4776 | Loss: 95.726 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1360/4776 | Loss: 85.406 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1370/4776 | Loss: 102.275 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1380/4776 | Loss: 89.744 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1390/4776 | Loss: 195.373 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 1400/4776 | Loss: 40.339 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1410/4776 | Loss: 53.997 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1420/4776 | Loss: 98.243 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1430/4776 | Loss: 65.424 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1440/4776 | Loss: 53.487 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1450/4776 | Loss: 98.833 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1460/4776 | Loss: 76.167 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1470/4776 | Loss: 74.263 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1480/4776 | Loss: 49.607 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1490/4776 | Loss: 48.909 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1500/4776 | Loss: 76.955 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1510/4776 | Loss: 89.616 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1520/4776 | Loss: 73.619 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1530/4776 | Loss: 25.568 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1540/4776 | Loss: 66.706 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1550/4776 | Loss: 117.296 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1560/4776 | Loss: 132.867 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1570/4776 | Loss: 56.561 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1580/4776 | Loss: 85.721 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1590/4776 | Loss: 64.259 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1600/4776 | Loss: 83.723 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1610/4776 | Loss: 101.376 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1620/4776 | Loss: 104.184 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1630/4776 | Loss: 56.214 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1640/4776 | Loss: 81.221 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1650/4776 | Loss: 110.843 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1660/4776 | Loss: 74.588 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1670/4776 | Loss: 115.576 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1680/4776 | Loss: 68.209 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1690/4776 | Loss: 110.226 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1700/4776 | Loss: 103.520 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1710/4776 | Loss: 58.197 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1720/4776 | Loss: 54.155 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1730/4776 | Loss: 72.370 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1740/4776 | Loss: 14.785 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 1750/4776 | Loss: 106.272 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1760/4776 | Loss: 43.973 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1770/4776 | Loss: 98.362 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1780/4776 | Loss: 91.827 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1790/4776 | Loss: 51.653 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1800/4776 | Loss: 91.635 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1810/4776 | Loss: 54.107 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1820/4776 | Loss: 68.623 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1830/4776 | Loss: 57.394 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1840/4776 | Loss: 95.822 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1850/4776 | Loss: 118.584 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1860/4776 | Loss: 99.221 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 1870/4776 | Loss: 106.179 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1880/4776 | Loss: 47.798 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 1890/4776 | Loss: 72.540 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 1900/4776 | Loss: 29.912 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 1910/4776 | Loss: 92.057 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1920/4776 | Loss: 93.896 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1930/4776 | Loss: 96.127 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1940/4776 | Loss: 73.732 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1950/4776 | Loss: 133.284 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 1960/4776 | Loss: 64.844 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1970/4776 | Loss: 59.825 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1980/4776 | Loss: 91.410 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 1990/4776 | Loss: 96.551 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2000/4776 | Loss: 88.189 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2010/4776 | Loss: 103.690 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2020/4776 | Loss: 63.795 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2030/4776 | Loss: 102.257 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2040/4776 | Loss: 80.296 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2050/4776 | Loss: 87.450 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2060/4776 | Loss: 43.202 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2070/4776 | Loss: 38.849 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2080/4776 | Loss: 77.107 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2090/4776 | Loss: 89.683 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2100/4776 | Loss: 92.197 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2110/4776 | Loss: 109.821 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2120/4776 | Loss: 104.867 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2130/4776 | Loss: 69.349 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2140/4776 | Loss: 50.852 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2150/4776 | Loss: 68.866 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2160/4776 | Loss: 72.343 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2170/4776 | Loss: 118.462 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2180/4776 | Loss: 90.028 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2190/4776 | Loss: 118.557 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2200/4776 | Loss: 88.014 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2210/4776 | Loss: 89.890 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2220/4776 | Loss: 133.190 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 2230/4776 | Loss: 84.134 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2240/4776 | Loss: 88.191 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2250/4776 | Loss: 108.726 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2260/4776 | Loss: 147.171 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2270/4776 | Loss: 33.542 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2280/4776 | Loss: 123.211 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2290/4776 | Loss: 65.325 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2300/4776 | Loss: 94.403 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2310/4776 | Loss: 54.615 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2320/4776 | Loss: 69.964 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2330/4776 | Loss: 133.554 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2340/4776 | Loss: 50.683 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2350/4776 | Loss: 154.938 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2360/4776 | Loss: 98.688 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2370/4776 | Loss: 104.553 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2380/4776 | Loss: 111.635 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 2390/4776 | Loss: 81.798 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2400/4776 | Loss: 175.167 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2410/4776 | Loss: 78.430 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2420/4776 | Loss: 99.435 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2430/4776 | Loss: 31.065 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2440/4776 | Loss: 99.219 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2450/4776 | Loss: 77.666 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2460/4776 | Loss: 117.680 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2470/4776 | Loss: 101.023 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2480/4776 | Loss: 191.213 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 2490/4776 | Loss: 73.871 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2500/4776 | Loss: 58.423 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2510/4776 | Loss: 50.226 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2520/4776 | Loss: 96.406 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2530/4776 | Loss: 47.301 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2540/4776 | Loss: 166.205 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 2550/4776 | Loss: 90.934 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2560/4776 | Loss: 42.220 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2570/4776 | Loss: 68.118 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2580/4776 | Loss: 98.239 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2590/4776 | Loss: 78.018 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2600/4776 | Loss: 58.142 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2610/4776 | Loss: 81.917 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2620/4776 | Loss: 50.256 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2630/4776 | Loss: 87.939 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2640/4776 | Loss: 101.185 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2650/4776 | Loss: 82.613 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2660/4776 | Loss: 108.259 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2670/4776 | Loss: 80.095 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2680/4776 | Loss: 94.268 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2690/4776 | Loss: 72.585 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2700/4776 | Loss: 60.349 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2710/4776 | Loss: 20.093 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2720/4776 | Loss: 34.163 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 2730/4776 | Loss: 66.166 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2740/4776 | Loss: 72.945 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2750/4776 | Loss: 61.701 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2760/4776 | Loss: 46.323 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2770/4776 | Loss: 82.475 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2780/4776 | Loss: 111.458 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2790/4776 | Loss: 47.173 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2800/4776 | Loss: 121.666 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2810/4776 | Loss: 63.231 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2820/4776 | Loss: 128.034 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2830/4776 | Loss: 43.940 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2840/4776 | Loss: 69.682 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2850/4776 | Loss: 26.738 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 2860/4776 | Loss: 57.680 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2870/4776 | Loss: 48.161 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2880/4776 | Loss: 219.089 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2890/4776 | Loss: 58.852 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2900/4776 | Loss: 91.949 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2910/4776 | Loss: 78.051 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2920/4776 | Loss: 85.528 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 2930/4776 | Loss: 43.269 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 2940/4776 | Loss: 80.595 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 2950/4776 | Loss: 71.241 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2960/4776 | Loss: 89.683 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2970/4776 | Loss: 83.712 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 2980/4776 | Loss: 81.360 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 2990/4776 | Loss: 72.760 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3000/4776 | Loss: 57.026 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3010/4776 | Loss: 55.217 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3020/4776 | Loss: 96.111 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3030/4776 | Loss: 101.799 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3040/4776 | Loss: 60.212 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3050/4776 | Loss: 59.216 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3060/4776 | Loss: 97.719 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3070/4776 | Loss: 113.036 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3080/4776 | Loss: 98.556 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3090/4776 | Loss: 56.082 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3100/4776 | Loss: 124.247 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3110/4776 | Loss: 24.702 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 3120/4776 | Loss: 41.744 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3130/4776 | Loss: 110.270 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3140/4776 | Loss: 133.904 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3150/4776 | Loss: 101.366 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3160/4776 | Loss: 155.762 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3170/4776 | Loss: 105.295 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3180/4776 | Loss: 104.817 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3190/4776 | Loss: 58.961 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3200/4776 | Loss: 100.121 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3210/4776 | Loss: 127.086 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3220/4776 | Loss: 102.893 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3230/4776 | Loss: 74.139 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3240/4776 | Loss: 55.317 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3250/4776 | Loss: 48.645 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3260/4776 | Loss: 82.518 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3270/4776 | Loss: 74.872 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3280/4776 | Loss: 127.720 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3290/4776 | Loss: 140.840 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3300/4776 | Loss: 99.430 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3310/4776 | Loss: 93.805 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3320/4776 | Loss: 104.176 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3330/4776 | Loss: 90.583 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3340/4776 | Loss: 64.402 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3350/4776 | Loss: 48.658 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3360/4776 | Loss: 66.330 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3370/4776 | Loss: 68.194 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3380/4776 | Loss: 107.583 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3390/4776 | Loss: 136.898 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3400/4776 | Loss: 87.595 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3410/4776 | Loss: 144.283 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3420/4776 | Loss: 87.103 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3430/4776 | Loss: 84.855 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3440/4776 | Loss: 88.387 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3450/4776 | Loss: 108.562 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3460/4776 | Loss: 120.972 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3470/4776 | Loss: 64.029 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3480/4776 | Loss: 83.863 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3490/4776 | Loss: 76.252 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3500/4776 | Loss: 83.649 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3510/4776 | Loss: 75.310 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3520/4776 | Loss: 68.194 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3530/4776 | Loss: 115.559 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3540/4776 | Loss: 78.373 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3550/4776 | Loss: 69.471 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3560/4776 | Loss: 111.031 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3570/4776 | Loss: 47.764 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3580/4776 | Loss: 108.579 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3590/4776 | Loss: 106.809 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3600/4776 | Loss: 38.880 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3610/4776 | Loss: 105.263 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3620/4776 | Loss: 92.578 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3630/4776 | Loss: 74.664 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3640/4776 | Loss: 47.892 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3650/4776 | Loss: 82.250 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3660/4776 | Loss: 87.911 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3670/4776 | Loss: 72.317 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3680/4776 | Loss: 42.219 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3690/4776 | Loss: 90.356 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3700/4776 | Loss: 63.850 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3710/4776 | Loss: 25.277 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3720/4776 | Loss: 86.066 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3730/4776 | Loss: 120.998 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3740/4776 | Loss: 47.644 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3750/4776 | Loss: 28.292 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3760/4776 | Loss: 129.561 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 3770/4776 | Loss: 114.769 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3780/4776 | Loss: 94.728 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3790/4776 | Loss: 37.694 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3800/4776 | Loss: 39.118 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 3810/4776 | Loss: 52.888 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3820/4776 | Loss: 59.645 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3830/4776 | Loss: 66.214 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3840/4776 | Loss: 81.874 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3850/4776 | Loss: 112.734 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3860/4776 | Loss: 99.257 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3870/4776 | Loss: 85.814 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3880/4776 | Loss: 100.124 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 3890/4776 | Loss: 52.206 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3900/4776 | Loss: 82.685 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3910/4776 | Loss: 138.710 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3920/4776 | Loss: 36.679 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 3930/4776 | Loss: 178.084 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 3940/4776 | Loss: 37.985 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 3950/4776 | Loss: 69.378 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3960/4776 | Loss: 99.906 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3970/4776 | Loss: 61.422 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 3980/4776 | Loss: 103.099 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 3990/4776 | Loss: 57.713 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4000/4776 | Loss: 49.301 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4010/4776 | Loss: 85.759 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4020/4776 | Loss: 45.594 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4030/4776 | Loss: 28.396 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 4040/4776 | Loss: 77.548 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4050/4776 | Loss: 26.122 | Accuracy: 1.000\n",
      "[Epoch: 64/200] - Step: 4060/4776 | Loss: 46.818 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4070/4776 | Loss: 48.455 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4080/4776 | Loss: 53.327 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4090/4776 | Loss: 85.828 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4100/4776 | Loss: 51.344 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4110/4776 | Loss: 55.862 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4120/4776 | Loss: 56.534 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4130/4776 | Loss: 164.828 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 4140/4776 | Loss: 121.073 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 4150/4776 | Loss: 70.448 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4160/4776 | Loss: 72.639 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4170/4776 | Loss: 45.276 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4180/4776 | Loss: 56.648 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4190/4776 | Loss: 33.029 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 4200/4776 | Loss: 89.459 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4210/4776 | Loss: 74.172 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4220/4776 | Loss: 53.877 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4230/4776 | Loss: 22.195 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 4240/4776 | Loss: 122.834 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4250/4776 | Loss: 126.063 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4260/4776 | Loss: 69.607 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4270/4776 | Loss: 80.623 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4280/4776 | Loss: 81.700 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4290/4776 | Loss: 84.397 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4300/4776 | Loss: 34.391 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 4310/4776 | Loss: 67.531 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4320/4776 | Loss: 51.984 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 4330/4776 | Loss: 67.073 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4340/4776 | Loss: 71.011 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4350/4776 | Loss: 115.310 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4360/4776 | Loss: 86.378 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4370/4776 | Loss: 137.047 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4380/4776 | Loss: 63.153 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4390/4776 | Loss: 67.994 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4400/4776 | Loss: 132.126 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 4410/4776 | Loss: 68.530 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4420/4776 | Loss: 106.922 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 4430/4776 | Loss: 81.391 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4440/4776 | Loss: 70.254 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4450/4776 | Loss: 55.783 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4460/4776 | Loss: 82.522 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4470/4776 | Loss: 68.807 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4480/4776 | Loss: 72.764 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4490/4776 | Loss: 134.585 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4500/4776 | Loss: 94.052 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4510/4776 | Loss: 70.969 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4520/4776 | Loss: 184.692 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 4530/4776 | Loss: 120.920 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4540/4776 | Loss: 109.029 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4550/4776 | Loss: 143.546 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4560/4776 | Loss: 104.043 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4570/4776 | Loss: 73.600 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4580/4776 | Loss: 120.977 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4590/4776 | Loss: 61.551 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4600/4776 | Loss: 171.862 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4610/4776 | Loss: 75.222 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4620/4776 | Loss: 105.927 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4630/4776 | Loss: 141.808 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4640/4776 | Loss: 69.480 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4650/4776 | Loss: 66.864 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4660/4776 | Loss: 112.213 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4670/4776 | Loss: 34.684 | Accuracy: 0.900\n",
      "[Epoch: 64/200] - Step: 4680/4776 | Loss: 67.647 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4690/4776 | Loss: 104.148 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4700/4776 | Loss: 93.878 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4710/4776 | Loss: 84.816 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4720/4776 | Loss: 109.295 | Accuracy: 0.700\n",
      "[Epoch: 64/200] - Step: 4730/4776 | Loss: 87.348 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4740/4776 | Loss: 112.225 | Accuracy: 0.500\n",
      "[Epoch: 64/200] - Step: 4750/4776 | Loss: 72.011 | Accuracy: 0.800\n",
      "[Epoch: 64/200] - Step: 4760/4776 | Loss: 102.518 | Accuracy: 0.600\n",
      "[Epoch: 64/200] - Step: 4770/4776 | Loss: 86.674 | Accuracy: 0.900\n",
      "Accuracy:  0.21147540983606558\n",
      "[Epoch: 65/200] - Step: 10/4776 | Loss: 73.652 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 20/4776 | Loss: 65.982 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 30/4776 | Loss: 35.883 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 40/4776 | Loss: 54.271 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 50/4776 | Loss: 52.665 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 60/4776 | Loss: 63.035 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 70/4776 | Loss: 37.471 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 80/4776 | Loss: 94.335 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 90/4776 | Loss: 62.825 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 100/4776 | Loss: 75.382 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 110/4776 | Loss: 83.155 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 120/4776 | Loss: 63.368 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 130/4776 | Loss: 53.703 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 140/4776 | Loss: 112.653 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 150/4776 | Loss: 77.799 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 160/4776 | Loss: 94.590 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 170/4776 | Loss: 54.753 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 180/4776 | Loss: 92.497 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 190/4776 | Loss: 51.275 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 200/4776 | Loss: 79.307 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 210/4776 | Loss: 92.126 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 220/4776 | Loss: 62.892 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 230/4776 | Loss: 42.105 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 240/4776 | Loss: 106.873 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 250/4776 | Loss: 30.076 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 260/4776 | Loss: 75.231 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 270/4776 | Loss: 63.971 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 280/4776 | Loss: 55.190 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 290/4776 | Loss: 89.903 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 300/4776 | Loss: 75.361 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 310/4776 | Loss: 50.801 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 320/4776 | Loss: 79.467 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 330/4776 | Loss: 50.642 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 340/4776 | Loss: 70.205 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 350/4776 | Loss: 66.595 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 360/4776 | Loss: 55.513 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 370/4776 | Loss: 38.138 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 380/4776 | Loss: 81.000 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 390/4776 | Loss: 20.639 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 400/4776 | Loss: 73.111 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 410/4776 | Loss: 54.388 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 420/4776 | Loss: 123.370 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 430/4776 | Loss: 50.564 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 440/4776 | Loss: 91.344 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 450/4776 | Loss: 124.711 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 460/4776 | Loss: 68.147 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 470/4776 | Loss: 55.014 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 480/4776 | Loss: 95.246 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 490/4776 | Loss: 128.457 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 500/4776 | Loss: 114.878 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 510/4776 | Loss: 79.860 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 520/4776 | Loss: 78.752 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 530/4776 | Loss: 28.828 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 540/4776 | Loss: 71.607 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 550/4776 | Loss: 73.406 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 560/4776 | Loss: 40.208 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 570/4776 | Loss: 60.517 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 580/4776 | Loss: 64.033 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 590/4776 | Loss: 59.463 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 600/4776 | Loss: 97.079 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 610/4776 | Loss: 144.724 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 620/4776 | Loss: 99.079 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 630/4776 | Loss: 111.568 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 640/4776 | Loss: 114.638 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 650/4776 | Loss: 75.285 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 660/4776 | Loss: 80.159 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 670/4776 | Loss: 120.209 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 680/4776 | Loss: 77.260 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 690/4776 | Loss: 44.291 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 700/4776 | Loss: 67.203 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 710/4776 | Loss: 72.414 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 720/4776 | Loss: 59.045 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 730/4776 | Loss: 86.730 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 740/4776 | Loss: 22.264 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 750/4776 | Loss: 118.449 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 760/4776 | Loss: 47.091 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 770/4776 | Loss: 11.839 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 780/4776 | Loss: 43.406 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 790/4776 | Loss: 49.755 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 800/4776 | Loss: 58.256 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 810/4776 | Loss: 42.980 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 820/4776 | Loss: 34.412 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 830/4776 | Loss: 72.016 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 840/4776 | Loss: 50.151 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 850/4776 | Loss: 42.066 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 860/4776 | Loss: 71.119 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 870/4776 | Loss: 44.846 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 880/4776 | Loss: 76.901 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 890/4776 | Loss: 47.783 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 900/4776 | Loss: 23.795 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 910/4776 | Loss: 76.339 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 920/4776 | Loss: 47.292 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 930/4776 | Loss: 84.178 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 940/4776 | Loss: 69.474 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 950/4776 | Loss: 93.135 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 960/4776 | Loss: 59.441 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 970/4776 | Loss: 114.589 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 980/4776 | Loss: 83.686 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 990/4776 | Loss: 64.550 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1000/4776 | Loss: 83.194 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1010/4776 | Loss: 91.990 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1020/4776 | Loss: 95.321 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1030/4776 | Loss: 77.201 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1040/4776 | Loss: 83.412 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1050/4776 | Loss: 35.523 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1060/4776 | Loss: 99.311 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1070/4776 | Loss: 38.036 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1080/4776 | Loss: 114.219 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1090/4776 | Loss: 82.794 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1100/4776 | Loss: 97.124 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1110/4776 | Loss: 96.546 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 1120/4776 | Loss: 112.437 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1130/4776 | Loss: 87.184 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1140/4776 | Loss: 120.665 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1150/4776 | Loss: 54.531 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1160/4776 | Loss: 46.128 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1170/4776 | Loss: 116.748 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1180/4776 | Loss: 117.232 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 1190/4776 | Loss: 58.825 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1200/4776 | Loss: 125.218 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1210/4776 | Loss: 170.782 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 1220/4776 | Loss: 142.964 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1230/4776 | Loss: 67.701 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1240/4776 | Loss: 111.556 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1250/4776 | Loss: 66.706 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1260/4776 | Loss: 121.596 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1270/4776 | Loss: 106.562 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1280/4776 | Loss: 120.386 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1290/4776 | Loss: 76.092 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1300/4776 | Loss: 63.722 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1310/4776 | Loss: 27.194 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 1320/4776 | Loss: 111.604 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1330/4776 | Loss: 78.355 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1340/4776 | Loss: 45.482 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1350/4776 | Loss: 72.083 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1360/4776 | Loss: 43.072 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1370/4776 | Loss: 62.610 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1380/4776 | Loss: 29.051 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1390/4776 | Loss: 140.776 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1400/4776 | Loss: 30.944 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1410/4776 | Loss: 74.102 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1420/4776 | Loss: 62.269 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1430/4776 | Loss: 77.756 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1440/4776 | Loss: 111.600 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1450/4776 | Loss: 55.623 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1460/4776 | Loss: 56.414 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1470/4776 | Loss: 103.100 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1480/4776 | Loss: 31.595 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1490/4776 | Loss: 36.164 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1500/4776 | Loss: 41.393 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1510/4776 | Loss: 119.386 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1520/4776 | Loss: 107.724 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1530/4776 | Loss: 115.382 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1540/4776 | Loss: 45.867 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1550/4776 | Loss: 82.322 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1560/4776 | Loss: 54.373 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1570/4776 | Loss: 73.946 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1580/4776 | Loss: 72.964 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1590/4776 | Loss: 87.872 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1600/4776 | Loss: 88.273 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1610/4776 | Loss: 129.124 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1620/4776 | Loss: 107.228 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1630/4776 | Loss: 70.169 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1640/4776 | Loss: 71.863 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1650/4776 | Loss: 141.175 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 1660/4776 | Loss: 28.242 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1670/4776 | Loss: 113.888 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1680/4776 | Loss: 84.928 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1690/4776 | Loss: 120.507 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1700/4776 | Loss: 51.456 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1710/4776 | Loss: 123.187 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 1720/4776 | Loss: 101.598 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1730/4776 | Loss: 131.393 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1740/4776 | Loss: 79.371 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1750/4776 | Loss: 72.658 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1760/4776 | Loss: 158.391 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 1770/4776 | Loss: 88.666 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1780/4776 | Loss: 106.130 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1790/4776 | Loss: 36.790 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1800/4776 | Loss: 157.578 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1810/4776 | Loss: 87.992 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1820/4776 | Loss: 80.971 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1830/4776 | Loss: 78.137 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1840/4776 | Loss: 102.610 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1850/4776 | Loss: 44.209 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1860/4776 | Loss: 29.906 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 1870/4776 | Loss: 154.195 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 1880/4776 | Loss: 87.562 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 1890/4776 | Loss: 104.324 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 1900/4776 | Loss: 84.325 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1910/4776 | Loss: 31.796 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1920/4776 | Loss: 85.633 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1930/4776 | Loss: 96.286 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1940/4776 | Loss: 96.740 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 1950/4776 | Loss: 41.457 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1960/4776 | Loss: 63.770 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 1970/4776 | Loss: 53.361 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1980/4776 | Loss: 34.322 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 1990/4776 | Loss: 45.966 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2000/4776 | Loss: 178.918 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2010/4776 | Loss: 128.860 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2020/4776 | Loss: 38.384 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2030/4776 | Loss: 108.358 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2040/4776 | Loss: 71.728 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2050/4776 | Loss: 118.998 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2060/4776 | Loss: 90.344 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2070/4776 | Loss: 60.875 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2080/4776 | Loss: 156.017 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2090/4776 | Loss: 94.053 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2100/4776 | Loss: 47.020 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2110/4776 | Loss: 73.430 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2120/4776 | Loss: 46.454 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2130/4776 | Loss: 39.676 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2140/4776 | Loss: 115.082 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2150/4776 | Loss: 47.559 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2160/4776 | Loss: 120.382 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 2170/4776 | Loss: 48.657 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2180/4776 | Loss: 17.738 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 2190/4776 | Loss: 47.538 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2200/4776 | Loss: 52.548 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2210/4776 | Loss: 116.394 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2220/4776 | Loss: 51.055 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2230/4776 | Loss: 67.113 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2240/4776 | Loss: 88.333 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2250/4776 | Loss: 126.477 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2260/4776 | Loss: 94.610 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2270/4776 | Loss: 104.507 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2280/4776 | Loss: 97.221 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2290/4776 | Loss: 67.455 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2300/4776 | Loss: 86.408 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2310/4776 | Loss: 47.771 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2320/4776 | Loss: 104.697 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2330/4776 | Loss: 50.492 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2340/4776 | Loss: 62.628 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2350/4776 | Loss: 41.805 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 2360/4776 | Loss: 155.554 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 2370/4776 | Loss: 48.854 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2380/4776 | Loss: 97.747 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2390/4776 | Loss: 81.848 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2400/4776 | Loss: 59.570 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2410/4776 | Loss: 98.722 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2420/4776 | Loss: 88.759 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2430/4776 | Loss: 126.116 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2440/4776 | Loss: 149.724 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 2450/4776 | Loss: 76.497 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2460/4776 | Loss: 33.711 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2470/4776 | Loss: 49.018 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2480/4776 | Loss: 87.420 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2490/4776 | Loss: 70.989 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2500/4776 | Loss: 54.124 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2510/4776 | Loss: 69.420 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2520/4776 | Loss: 76.920 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2530/4776 | Loss: 52.836 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2540/4776 | Loss: 52.934 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2550/4776 | Loss: 106.439 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2560/4776 | Loss: 43.727 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2570/4776 | Loss: 100.892 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2580/4776 | Loss: 59.988 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2590/4776 | Loss: 57.632 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2600/4776 | Loss: 25.303 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 2610/4776 | Loss: 56.646 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2620/4776 | Loss: 75.465 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2630/4776 | Loss: 95.522 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 2640/4776 | Loss: 76.735 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2650/4776 | Loss: 47.720 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2660/4776 | Loss: 103.643 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2670/4776 | Loss: 62.661 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2680/4776 | Loss: 153.159 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2690/4776 | Loss: 73.693 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2700/4776 | Loss: 105.014 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2710/4776 | Loss: 99.304 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2720/4776 | Loss: 72.308 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2730/4776 | Loss: 42.474 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2740/4776 | Loss: 47.966 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2750/4776 | Loss: 49.703 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2760/4776 | Loss: 126.201 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2770/4776 | Loss: 122.682 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2780/4776 | Loss: 64.310 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2790/4776 | Loss: 68.987 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2800/4776 | Loss: 98.603 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2810/4776 | Loss: 109.746 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2820/4776 | Loss: 58.284 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2830/4776 | Loss: 52.221 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2840/4776 | Loss: 55.743 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2850/4776 | Loss: 48.829 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2860/4776 | Loss: 74.610 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2870/4776 | Loss: 71.796 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2880/4776 | Loss: 121.969 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2890/4776 | Loss: 77.938 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2900/4776 | Loss: 65.300 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2910/4776 | Loss: 59.815 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2920/4776 | Loss: 46.700 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2930/4776 | Loss: 45.027 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2940/4776 | Loss: 71.187 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 2950/4776 | Loss: 55.753 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 2960/4776 | Loss: 144.262 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 2970/4776 | Loss: 55.252 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 2980/4776 | Loss: 77.544 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 2990/4776 | Loss: 53.286 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3000/4776 | Loss: 95.714 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3010/4776 | Loss: 65.073 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3020/4776 | Loss: 97.372 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3030/4776 | Loss: 150.922 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3040/4776 | Loss: 65.330 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3050/4776 | Loss: 106.863 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3060/4776 | Loss: 98.433 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3070/4776 | Loss: 88.958 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3080/4776 | Loss: 40.484 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3090/4776 | Loss: 103.023 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3100/4776 | Loss: 49.700 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3110/4776 | Loss: 70.134 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3120/4776 | Loss: 57.789 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3130/4776 | Loss: 82.427 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3140/4776 | Loss: 45.129 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3150/4776 | Loss: 71.874 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3160/4776 | Loss: 54.417 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3170/4776 | Loss: 102.102 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3180/4776 | Loss: 95.662 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3190/4776 | Loss: 79.690 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3200/4776 | Loss: 26.376 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3210/4776 | Loss: 106.885 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3220/4776 | Loss: 53.579 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3230/4776 | Loss: 119.648 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3240/4776 | Loss: 69.800 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3250/4776 | Loss: 78.891 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3260/4776 | Loss: 127.795 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3270/4776 | Loss: 50.825 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3280/4776 | Loss: 75.761 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3290/4776 | Loss: 53.297 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3300/4776 | Loss: 50.473 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3310/4776 | Loss: 61.027 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3320/4776 | Loss: 74.417 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3330/4776 | Loss: 133.084 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3340/4776 | Loss: 94.173 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3350/4776 | Loss: 60.095 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3360/4776 | Loss: 107.359 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3370/4776 | Loss: 87.967 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3380/4776 | Loss: 33.603 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3390/4776 | Loss: 73.363 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3400/4776 | Loss: 29.916 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 3410/4776 | Loss: 163.992 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3420/4776 | Loss: 76.268 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3430/4776 | Loss: 29.350 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3440/4776 | Loss: 109.398 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 3450/4776 | Loss: 37.914 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3460/4776 | Loss: 72.781 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3470/4776 | Loss: 52.887 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3480/4776 | Loss: 156.897 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3490/4776 | Loss: 55.285 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3500/4776 | Loss: 58.778 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3510/4776 | Loss: 76.326 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3520/4776 | Loss: 60.284 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3530/4776 | Loss: 46.751 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3540/4776 | Loss: 95.046 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3550/4776 | Loss: 54.575 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3560/4776 | Loss: 60.709 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3570/4776 | Loss: 28.265 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3580/4776 | Loss: 83.029 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3590/4776 | Loss: 56.583 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3600/4776 | Loss: 92.462 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3610/4776 | Loss: 76.653 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3620/4776 | Loss: 63.473 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3630/4776 | Loss: 114.185 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3640/4776 | Loss: 90.163 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3650/4776 | Loss: 24.819 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3660/4776 | Loss: 72.029 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3670/4776 | Loss: 79.105 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3680/4776 | Loss: 71.389 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3690/4776 | Loss: 79.821 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3700/4776 | Loss: 115.617 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3710/4776 | Loss: 40.982 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3720/4776 | Loss: 47.460 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3730/4776 | Loss: 40.363 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3740/4776 | Loss: 124.186 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3750/4776 | Loss: 51.816 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3760/4776 | Loss: 42.189 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3770/4776 | Loss: 63.567 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3780/4776 | Loss: 102.995 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3790/4776 | Loss: 87.107 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3800/4776 | Loss: 92.794 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3810/4776 | Loss: 123.137 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 3820/4776 | Loss: 77.303 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3830/4776 | Loss: 52.948 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3840/4776 | Loss: 100.882 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 3850/4776 | Loss: 107.862 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3860/4776 | Loss: 70.099 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3870/4776 | Loss: 72.912 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3880/4776 | Loss: 68.215 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3890/4776 | Loss: 180.775 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 3900/4776 | Loss: 58.416 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3910/4776 | Loss: 104.017 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3920/4776 | Loss: 140.860 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3930/4776 | Loss: 51.975 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 3940/4776 | Loss: 96.001 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 3950/4776 | Loss: 132.631 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 3960/4776 | Loss: 59.780 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 3970/4776 | Loss: 118.235 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 3980/4776 | Loss: 123.642 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 3990/4776 | Loss: 42.476 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4000/4776 | Loss: 133.288 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4010/4776 | Loss: 31.007 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 4020/4776 | Loss: 132.726 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4030/4776 | Loss: 45.352 | Accuracy: 1.000\n",
      "[Epoch: 65/200] - Step: 4040/4776 | Loss: 169.889 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 4050/4776 | Loss: 103.151 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4060/4776 | Loss: 92.071 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4070/4776 | Loss: 51.883 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 4080/4776 | Loss: 75.853 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4090/4776 | Loss: 94.407 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4100/4776 | Loss: 70.832 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4110/4776 | Loss: 73.270 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4120/4776 | Loss: 83.112 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4130/4776 | Loss: 90.719 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4140/4776 | Loss: 85.299 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4150/4776 | Loss: 75.634 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4160/4776 | Loss: 103.425 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4170/4776 | Loss: 87.551 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4180/4776 | Loss: 62.442 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4190/4776 | Loss: 89.162 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4200/4776 | Loss: 96.562 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4210/4776 | Loss: 122.001 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4220/4776 | Loss: 78.425 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4230/4776 | Loss: 90.088 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4240/4776 | Loss: 132.814 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4250/4776 | Loss: 78.557 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4260/4776 | Loss: 91.793 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4270/4776 | Loss: 122.937 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 4280/4776 | Loss: 87.198 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4290/4776 | Loss: 106.078 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4300/4776 | Loss: 105.866 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 4310/4776 | Loss: 88.859 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4320/4776 | Loss: 88.831 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4330/4776 | Loss: 63.328 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 4340/4776 | Loss: 131.140 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4350/4776 | Loss: 94.455 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 4360/4776 | Loss: 107.127 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4370/4776 | Loss: 108.259 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4380/4776 | Loss: 125.531 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4390/4776 | Loss: 86.777 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4400/4776 | Loss: 132.897 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 4410/4776 | Loss: 111.487 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4420/4776 | Loss: 94.993 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4430/4776 | Loss: 117.615 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4440/4776 | Loss: 111.608 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4450/4776 | Loss: 59.375 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4460/4776 | Loss: 64.441 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4470/4776 | Loss: 91.569 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4480/4776 | Loss: 97.394 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4490/4776 | Loss: 93.342 | Accuracy: 0.500\n",
      "[Epoch: 65/200] - Step: 4500/4776 | Loss: 100.487 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4510/4776 | Loss: 93.823 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4520/4776 | Loss: 89.739 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4530/4776 | Loss: 85.973 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4540/4776 | Loss: 114.046 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 4550/4776 | Loss: 54.496 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4560/4776 | Loss: 62.199 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4570/4776 | Loss: 48.342 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 4580/4776 | Loss: 48.400 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4590/4776 | Loss: 61.690 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4600/4776 | Loss: 106.987 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4610/4776 | Loss: 69.787 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4620/4776 | Loss: 93.663 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4630/4776 | Loss: 82.975 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4640/4776 | Loss: 65.392 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4650/4776 | Loss: 82.038 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4660/4776 | Loss: 78.796 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4670/4776 | Loss: 74.873 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4680/4776 | Loss: 53.573 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4690/4776 | Loss: 46.601 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4700/4776 | Loss: 88.414 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4710/4776 | Loss: 63.006 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 4720/4776 | Loss: 75.588 | Accuracy: 0.800\n",
      "[Epoch: 65/200] - Step: 4730/4776 | Loss: 85.815 | Accuracy: 0.600\n",
      "[Epoch: 65/200] - Step: 4740/4776 | Loss: 44.361 | Accuracy: 0.900\n",
      "[Epoch: 65/200] - Step: 4750/4776 | Loss: 83.767 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4760/4776 | Loss: 62.658 | Accuracy: 0.700\n",
      "[Epoch: 65/200] - Step: 4770/4776 | Loss: 72.475 | Accuracy: 0.800\n",
      "Accuracy:  0.19672131147540983\n",
      "[Epoch: 66/200] - Step: 10/4776 | Loss: 41.620 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 20/4776 | Loss: 74.411 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 30/4776 | Loss: 71.993 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 40/4776 | Loss: 42.516 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 50/4776 | Loss: 55.341 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 60/4776 | Loss: 79.873 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 70/4776 | Loss: 71.773 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 80/4776 | Loss: 116.312 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 90/4776 | Loss: 123.062 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 100/4776 | Loss: 58.363 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 110/4776 | Loss: 124.218 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 120/4776 | Loss: 107.269 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 130/4776 | Loss: 87.619 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 140/4776 | Loss: 74.485 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 150/4776 | Loss: 50.788 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 160/4776 | Loss: 60.193 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 170/4776 | Loss: 79.308 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 180/4776 | Loss: 85.951 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 190/4776 | Loss: 58.393 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 200/4776 | Loss: 171.104 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 210/4776 | Loss: 60.817 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 220/4776 | Loss: 102.145 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 230/4776 | Loss: 55.163 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 240/4776 | Loss: 96.975 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 250/4776 | Loss: 117.805 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 260/4776 | Loss: 33.497 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 270/4776 | Loss: 79.988 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 280/4776 | Loss: 45.372 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 290/4776 | Loss: 50.082 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 300/4776 | Loss: 81.046 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 310/4776 | Loss: 107.612 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 320/4776 | Loss: 43.696 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 330/4776 | Loss: 25.718 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 340/4776 | Loss: 54.455 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 350/4776 | Loss: 126.510 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 360/4776 | Loss: 88.754 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 370/4776 | Loss: 48.386 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 380/4776 | Loss: 148.948 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 390/4776 | Loss: 43.943 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 400/4776 | Loss: 40.571 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 410/4776 | Loss: 80.284 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 420/4776 | Loss: 70.099 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 430/4776 | Loss: 51.540 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 440/4776 | Loss: 50.478 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 450/4776 | Loss: 55.275 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 460/4776 | Loss: 67.149 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 470/4776 | Loss: 42.035 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 480/4776 | Loss: 76.191 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 490/4776 | Loss: 131.140 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 500/4776 | Loss: 103.222 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 510/4776 | Loss: 55.002 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 520/4776 | Loss: 38.459 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 530/4776 | Loss: 89.912 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 540/4776 | Loss: 36.891 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 550/4776 | Loss: 34.780 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 560/4776 | Loss: 79.647 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 570/4776 | Loss: 97.109 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 580/4776 | Loss: 86.249 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 590/4776 | Loss: 86.087 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 600/4776 | Loss: 72.836 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 610/4776 | Loss: 102.531 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 620/4776 | Loss: 39.706 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 630/4776 | Loss: 166.700 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 640/4776 | Loss: 121.279 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 650/4776 | Loss: 143.144 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 660/4776 | Loss: 149.846 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 670/4776 | Loss: 68.997 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 680/4776 | Loss: 62.053 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 690/4776 | Loss: 125.581 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 700/4776 | Loss: 93.212 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 710/4776 | Loss: 85.721 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 720/4776 | Loss: 86.617 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 730/4776 | Loss: 127.852 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 740/4776 | Loss: 50.232 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 750/4776 | Loss: 86.310 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 760/4776 | Loss: 62.121 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 770/4776 | Loss: 79.027 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 780/4776 | Loss: 61.496 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 790/4776 | Loss: 106.537 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 800/4776 | Loss: 105.852 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 810/4776 | Loss: 106.219 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 820/4776 | Loss: 63.848 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 830/4776 | Loss: 86.614 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 840/4776 | Loss: 72.074 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 850/4776 | Loss: 138.243 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 860/4776 | Loss: 88.504 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 870/4776 | Loss: 146.498 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 880/4776 | Loss: 87.956 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 890/4776 | Loss: 26.057 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 900/4776 | Loss: 115.381 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 910/4776 | Loss: 73.859 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 920/4776 | Loss: 60.256 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 930/4776 | Loss: 49.754 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 940/4776 | Loss: 40.649 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 950/4776 | Loss: 66.914 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 960/4776 | Loss: 70.018 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 970/4776 | Loss: 89.916 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 980/4776 | Loss: 77.132 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 990/4776 | Loss: 88.116 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1000/4776 | Loss: 87.990 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1010/4776 | Loss: 77.075 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1020/4776 | Loss: 109.207 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1030/4776 | Loss: 59.666 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1040/4776 | Loss: 45.934 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1050/4776 | Loss: 62.435 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1060/4776 | Loss: 99.444 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1070/4776 | Loss: 30.206 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 1080/4776 | Loss: 52.286 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1090/4776 | Loss: 87.913 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1100/4776 | Loss: 41.927 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1110/4776 | Loss: 52.986 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1120/4776 | Loss: 48.829 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1130/4776 | Loss: 33.932 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1140/4776 | Loss: 56.454 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1150/4776 | Loss: 52.198 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1160/4776 | Loss: 62.559 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1170/4776 | Loss: 64.539 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1180/4776 | Loss: 45.334 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1190/4776 | Loss: 60.919 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1200/4776 | Loss: 55.563 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1210/4776 | Loss: 50.794 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1220/4776 | Loss: 105.305 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1230/4776 | Loss: 115.543 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1240/4776 | Loss: 67.461 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1250/4776 | Loss: 66.858 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1260/4776 | Loss: 69.772 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1270/4776 | Loss: 100.509 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1280/4776 | Loss: 103.045 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1290/4776 | Loss: 208.795 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1300/4776 | Loss: 113.125 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1310/4776 | Loss: 30.554 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1320/4776 | Loss: 53.779 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1330/4776 | Loss: 73.822 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1340/4776 | Loss: 203.611 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1350/4776 | Loss: 94.811 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1360/4776 | Loss: 92.357 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1370/4776 | Loss: 44.778 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1380/4776 | Loss: 69.510 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1390/4776 | Loss: 22.305 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 1400/4776 | Loss: 130.459 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1410/4776 | Loss: 75.276 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1420/4776 | Loss: 77.222 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1430/4776 | Loss: 77.702 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1440/4776 | Loss: 69.107 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1450/4776 | Loss: 39.432 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1460/4776 | Loss: 55.067 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1470/4776 | Loss: 91.244 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1480/4776 | Loss: 49.051 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1490/4776 | Loss: 66.763 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1500/4776 | Loss: 47.681 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 1510/4776 | Loss: 30.103 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1520/4776 | Loss: 56.748 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1530/4776 | Loss: 90.377 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1540/4776 | Loss: 64.322 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1550/4776 | Loss: 72.536 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1560/4776 | Loss: 119.088 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1570/4776 | Loss: 76.833 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1580/4776 | Loss: 70.799 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1590/4776 | Loss: 33.250 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1600/4776 | Loss: 36.552 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1610/4776 | Loss: 65.569 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1620/4776 | Loss: 62.135 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1630/4776 | Loss: 68.150 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1640/4776 | Loss: 31.271 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1650/4776 | Loss: 118.931 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1660/4776 | Loss: 93.982 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1670/4776 | Loss: 160.446 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 1680/4776 | Loss: 89.978 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1690/4776 | Loss: 68.371 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1700/4776 | Loss: 55.566 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1710/4776 | Loss: 111.021 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 1720/4776 | Loss: 52.197 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1730/4776 | Loss: 63.103 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1740/4776 | Loss: 60.134 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1750/4776 | Loss: 135.524 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 1760/4776 | Loss: 89.626 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1770/4776 | Loss: 95.032 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1780/4776 | Loss: 85.232 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1790/4776 | Loss: 29.769 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 1800/4776 | Loss: 80.010 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1810/4776 | Loss: 80.143 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1820/4776 | Loss: 137.629 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1830/4776 | Loss: 114.009 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 1840/4776 | Loss: 103.872 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1850/4776 | Loss: 113.737 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1860/4776 | Loss: 77.487 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 1870/4776 | Loss: 65.729 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1880/4776 | Loss: 105.609 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 1890/4776 | Loss: 51.472 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1900/4776 | Loss: 74.368 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1910/4776 | Loss: 83.425 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1920/4776 | Loss: 54.600 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1930/4776 | Loss: 59.998 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 1940/4776 | Loss: 72.077 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1950/4776 | Loss: 149.408 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1960/4776 | Loss: 54.670 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1970/4776 | Loss: 90.456 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 1980/4776 | Loss: 68.315 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 1990/4776 | Loss: 74.835 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2000/4776 | Loss: 90.748 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2010/4776 | Loss: 98.923 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2020/4776 | Loss: 99.732 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2030/4776 | Loss: 49.816 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2040/4776 | Loss: 95.319 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2050/4776 | Loss: 58.554 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2060/4776 | Loss: 63.633 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2070/4776 | Loss: 70.293 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2080/4776 | Loss: 45.389 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2090/4776 | Loss: 115.224 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2100/4776 | Loss: 106.524 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2110/4776 | Loss: 60.930 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2120/4776 | Loss: 87.197 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2130/4776 | Loss: 97.876 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2140/4776 | Loss: 121.043 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2150/4776 | Loss: 41.612 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2160/4776 | Loss: 99.504 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2170/4776 | Loss: 113.329 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2180/4776 | Loss: 52.548 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2190/4776 | Loss: 46.633 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2200/4776 | Loss: 67.010 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2210/4776 | Loss: 57.588 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2220/4776 | Loss: 59.867 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2230/4776 | Loss: 60.653 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2240/4776 | Loss: 28.059 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 2250/4776 | Loss: 53.958 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2260/4776 | Loss: 47.690 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2270/4776 | Loss: 152.312 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2280/4776 | Loss: 72.223 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2290/4776 | Loss: 85.940 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2300/4776 | Loss: 87.620 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2310/4776 | Loss: 34.410 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2320/4776 | Loss: 83.653 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2330/4776 | Loss: 30.030 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2340/4776 | Loss: 66.610 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2350/4776 | Loss: 64.963 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2360/4776 | Loss: 55.241 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2370/4776 | Loss: 69.684 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2380/4776 | Loss: 115.287 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2390/4776 | Loss: 27.534 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2400/4776 | Loss: 89.179 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2410/4776 | Loss: 58.967 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2420/4776 | Loss: 24.934 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2430/4776 | Loss: 113.148 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2440/4776 | Loss: 129.903 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2450/4776 | Loss: 68.743 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2460/4776 | Loss: 116.145 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2470/4776 | Loss: 107.991 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 2480/4776 | Loss: 97.218 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2490/4776 | Loss: 49.352 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2500/4776 | Loss: 133.179 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2510/4776 | Loss: 88.536 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2520/4776 | Loss: 60.652 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2530/4776 | Loss: 71.936 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2540/4776 | Loss: 68.672 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2550/4776 | Loss: 43.489 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2560/4776 | Loss: 87.682 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2570/4776 | Loss: 45.021 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2580/4776 | Loss: 133.856 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2590/4776 | Loss: 71.967 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2600/4776 | Loss: 58.624 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2610/4776 | Loss: 18.711 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 2620/4776 | Loss: 57.981 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2630/4776 | Loss: 96.351 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2640/4776 | Loss: 108.475 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2650/4776 | Loss: 72.285 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2660/4776 | Loss: 53.550 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2670/4776 | Loss: 81.506 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2680/4776 | Loss: 111.357 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2690/4776 | Loss: 63.884 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2700/4776 | Loss: 60.604 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2710/4776 | Loss: 102.769 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2720/4776 | Loss: 57.552 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2730/4776 | Loss: 73.463 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2740/4776 | Loss: 62.400 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2750/4776 | Loss: 31.354 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2760/4776 | Loss: 89.813 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2770/4776 | Loss: 68.633 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2780/4776 | Loss: 77.501 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2790/4776 | Loss: 27.959 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2800/4776 | Loss: 115.160 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2810/4776 | Loss: 96.873 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2820/4776 | Loss: 103.978 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2830/4776 | Loss: 127.807 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2840/4776 | Loss: 71.341 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2850/4776 | Loss: 95.807 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2860/4776 | Loss: 45.124 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 2870/4776 | Loss: 134.142 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2880/4776 | Loss: 36.351 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2890/4776 | Loss: 75.213 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2900/4776 | Loss: 43.243 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 2910/4776 | Loss: 143.105 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2920/4776 | Loss: 84.192 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 2930/4776 | Loss: 87.359 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2940/4776 | Loss: 56.709 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2950/4776 | Loss: 101.499 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 2960/4776 | Loss: 107.450 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2970/4776 | Loss: 18.743 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 2980/4776 | Loss: 71.860 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 2990/4776 | Loss: 55.073 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3000/4776 | Loss: 101.978 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3010/4776 | Loss: 50.014 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3020/4776 | Loss: 107.845 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 3030/4776 | Loss: 57.546 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3040/4776 | Loss: 64.584 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3050/4776 | Loss: 72.951 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3060/4776 | Loss: 59.322 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3070/4776 | Loss: 79.190 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3080/4776 | Loss: 87.347 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3090/4776 | Loss: 42.223 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3100/4776 | Loss: 72.006 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3110/4776 | Loss: 66.857 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3120/4776 | Loss: 121.307 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3130/4776 | Loss: 99.728 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3140/4776 | Loss: 91.402 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3150/4776 | Loss: 10.392 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 3160/4776 | Loss: 110.463 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3170/4776 | Loss: 117.051 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3180/4776 | Loss: 146.881 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 3190/4776 | Loss: 51.981 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3200/4776 | Loss: 64.968 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3210/4776 | Loss: 92.513 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3220/4776 | Loss: 47.526 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3230/4776 | Loss: 129.068 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3240/4776 | Loss: 104.819 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3250/4776 | Loss: 66.573 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3260/4776 | Loss: 46.958 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3270/4776 | Loss: 72.772 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3280/4776 | Loss: 132.624 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3290/4776 | Loss: 30.970 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3300/4776 | Loss: 63.032 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3310/4776 | Loss: 103.367 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3320/4776 | Loss: 58.329 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3330/4776 | Loss: 83.214 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3340/4776 | Loss: 112.041 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3350/4776 | Loss: 101.337 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3360/4776 | Loss: 72.383 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3370/4776 | Loss: 82.068 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3380/4776 | Loss: 87.733 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3390/4776 | Loss: 101.128 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3400/4776 | Loss: 78.448 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3410/4776 | Loss: 33.881 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3420/4776 | Loss: 48.974 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3430/4776 | Loss: 67.372 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3440/4776 | Loss: 69.154 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3450/4776 | Loss: 80.162 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3460/4776 | Loss: 30.262 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3470/4776 | Loss: 92.180 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3480/4776 | Loss: 95.649 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3490/4776 | Loss: 41.727 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3500/4776 | Loss: 78.014 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3510/4776 | Loss: 102.822 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3520/4776 | Loss: 110.412 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3530/4776 | Loss: 33.761 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3540/4776 | Loss: 64.313 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3550/4776 | Loss: 59.340 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3560/4776 | Loss: 55.890 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3570/4776 | Loss: 67.629 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3580/4776 | Loss: 109.421 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3590/4776 | Loss: 56.872 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3600/4776 | Loss: 68.961 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3610/4776 | Loss: 50.501 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3620/4776 | Loss: 70.245 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3630/4776 | Loss: 68.756 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3640/4776 | Loss: 63.955 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3650/4776 | Loss: 78.862 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3660/4776 | Loss: 59.247 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3670/4776 | Loss: 28.858 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3680/4776 | Loss: 89.035 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3690/4776 | Loss: 59.114 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3700/4776 | Loss: 27.836 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 3710/4776 | Loss: 58.822 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3720/4776 | Loss: 43.620 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3730/4776 | Loss: 40.230 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3740/4776 | Loss: 42.456 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 3750/4776 | Loss: 124.079 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3760/4776 | Loss: 107.794 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3770/4776 | Loss: 115.272 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3780/4776 | Loss: 106.937 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3790/4776 | Loss: 74.822 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3800/4776 | Loss: 117.360 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3810/4776 | Loss: 121.779 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 3820/4776 | Loss: 71.056 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3830/4776 | Loss: 72.133 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3840/4776 | Loss: 59.612 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3850/4776 | Loss: 58.102 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3860/4776 | Loss: 56.477 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3870/4776 | Loss: 97.107 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3880/4776 | Loss: 57.118 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3890/4776 | Loss: 82.616 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3900/4776 | Loss: 89.494 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3910/4776 | Loss: 42.988 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 3920/4776 | Loss: 99.222 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3930/4776 | Loss: 148.360 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3940/4776 | Loss: 107.722 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3950/4776 | Loss: 76.246 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 3960/4776 | Loss: 106.300 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 3970/4776 | Loss: 126.143 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 3980/4776 | Loss: 99.761 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 3990/4776 | Loss: 76.374 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4000/4776 | Loss: 91.719 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4010/4776 | Loss: 41.521 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4020/4776 | Loss: 128.497 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4030/4776 | Loss: 92.989 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4040/4776 | Loss: 43.720 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4050/4776 | Loss: 118.774 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4060/4776 | Loss: 228.283 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 4070/4776 | Loss: 137.211 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4080/4776 | Loss: 80.254 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4090/4776 | Loss: 64.414 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4100/4776 | Loss: 103.686 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4110/4776 | Loss: 225.130 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4120/4776 | Loss: 116.139 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4130/4776 | Loss: 141.006 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4140/4776 | Loss: 48.591 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 4150/4776 | Loss: 102.129 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4160/4776 | Loss: 90.761 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4170/4776 | Loss: 67.905 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4180/4776 | Loss: 88.229 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4190/4776 | Loss: 62.602 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4200/4776 | Loss: 33.431 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 4210/4776 | Loss: 53.257 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4220/4776 | Loss: 114.951 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4230/4776 | Loss: 122.935 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4240/4776 | Loss: 111.097 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4250/4776 | Loss: 97.934 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4260/4776 | Loss: 153.087 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4270/4776 | Loss: 138.039 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4280/4776 | Loss: 96.666 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4290/4776 | Loss: 95.232 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4300/4776 | Loss: 109.496 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4310/4776 | Loss: 92.255 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4320/4776 | Loss: 147.831 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4330/4776 | Loss: 73.803 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4340/4776 | Loss: 150.249 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4350/4776 | Loss: 129.151 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4360/4776 | Loss: 124.544 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4370/4776 | Loss: 86.402 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4380/4776 | Loss: 36.845 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4390/4776 | Loss: 147.767 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4400/4776 | Loss: 107.439 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4410/4776 | Loss: 90.394 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4420/4776 | Loss: 93.290 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4430/4776 | Loss: 41.576 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4440/4776 | Loss: 110.202 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4450/4776 | Loss: 104.288 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4460/4776 | Loss: 78.475 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4470/4776 | Loss: 73.148 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4480/4776 | Loss: 63.032 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4490/4776 | Loss: 95.664 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4500/4776 | Loss: 41.945 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4510/4776 | Loss: 114.041 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4520/4776 | Loss: 15.112 | Accuracy: 1.000\n",
      "[Epoch: 66/200] - Step: 4530/4776 | Loss: 137.827 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4540/4776 | Loss: 101.761 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4550/4776 | Loss: 96.368 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4560/4776 | Loss: 106.144 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4570/4776 | Loss: 46.063 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4580/4776 | Loss: 85.174 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4590/4776 | Loss: 45.782 | Accuracy: 0.800\n",
      "[Epoch: 66/200] - Step: 4600/4776 | Loss: 47.199 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4610/4776 | Loss: 87.476 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4620/4776 | Loss: 37.769 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4630/4776 | Loss: 69.836 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4640/4776 | Loss: 112.932 | Accuracy: 0.500\n",
      "[Epoch: 66/200] - Step: 4650/4776 | Loss: 91.805 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4660/4776 | Loss: 43.280 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4670/4776 | Loss: 112.447 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4680/4776 | Loss: 31.875 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4690/4776 | Loss: 70.318 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4700/4776 | Loss: 118.742 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4710/4776 | Loss: 86.780 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4720/4776 | Loss: 84.014 | Accuracy: 0.700\n",
      "[Epoch: 66/200] - Step: 4730/4776 | Loss: 68.301 | Accuracy: 0.600\n",
      "[Epoch: 66/200] - Step: 4740/4776 | Loss: 43.824 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4750/4776 | Loss: 51.332 | Accuracy: 0.900\n",
      "[Epoch: 66/200] - Step: 4760/4776 | Loss: 100.876 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 4770/4776 | Loss: 96.706 | Accuracy: 0.600\n",
      "Accuracy:  0.1885245901639344\n",
      "[Epoch: 67/200] - Step: 10/4776 | Loss: 71.055 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 20/4776 | Loss: 41.921 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 30/4776 | Loss: 32.117 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 40/4776 | Loss: 46.303 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 50/4776 | Loss: 24.048 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 60/4776 | Loss: 50.146 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 70/4776 | Loss: 37.831 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 80/4776 | Loss: 41.279 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 90/4776 | Loss: 29.483 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 100/4776 | Loss: 84.226 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 110/4776 | Loss: 61.072 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 120/4776 | Loss: 68.611 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 130/4776 | Loss: 72.818 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 140/4776 | Loss: 63.832 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 150/4776 | Loss: 145.476 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 160/4776 | Loss: 118.243 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 170/4776 | Loss: 66.452 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 180/4776 | Loss: 39.369 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 190/4776 | Loss: 40.342 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 200/4776 | Loss: 73.995 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 210/4776 | Loss: 50.463 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 220/4776 | Loss: 36.041 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 230/4776 | Loss: 75.918 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 240/4776 | Loss: 127.959 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 250/4776 | Loss: 129.190 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 260/4776 | Loss: 59.957 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 270/4776 | Loss: 45.581 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 280/4776 | Loss: 70.635 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 290/4776 | Loss: 67.032 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 300/4776 | Loss: 63.323 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 310/4776 | Loss: 32.543 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 320/4776 | Loss: 48.929 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 330/4776 | Loss: 79.512 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 340/4776 | Loss: 117.905 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 350/4776 | Loss: 81.121 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 360/4776 | Loss: 102.611 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 370/4776 | Loss: 46.609 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 380/4776 | Loss: 65.278 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 390/4776 | Loss: 64.663 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 400/4776 | Loss: 61.822 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 410/4776 | Loss: 52.227 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 420/4776 | Loss: 44.971 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 430/4776 | Loss: 92.628 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 440/4776 | Loss: 62.388 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 450/4776 | Loss: 33.524 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 460/4776 | Loss: 70.547 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 470/4776 | Loss: 67.389 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 480/4776 | Loss: 44.638 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 490/4776 | Loss: 60.479 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 500/4776 | Loss: 86.678 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 510/4776 | Loss: 91.453 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 520/4776 | Loss: 74.302 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 530/4776 | Loss: 101.953 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 540/4776 | Loss: 86.934 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 550/4776 | Loss: 47.380 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 560/4776 | Loss: 39.403 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 570/4776 | Loss: 51.728 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 580/4776 | Loss: 44.379 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 590/4776 | Loss: 32.998 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 600/4776 | Loss: 47.623 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 610/4776 | Loss: 55.497 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 620/4776 | Loss: 75.712 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 630/4776 | Loss: 86.201 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 640/4776 | Loss: 64.987 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 650/4776 | Loss: 59.671 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 660/4776 | Loss: 80.799 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 670/4776 | Loss: 43.800 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 680/4776 | Loss: 69.486 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 690/4776 | Loss: 123.115 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 700/4776 | Loss: 83.625 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 710/4776 | Loss: 92.283 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 720/4776 | Loss: 149.946 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 730/4776 | Loss: 139.295 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 740/4776 | Loss: 85.057 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 750/4776 | Loss: 50.901 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 760/4776 | Loss: 75.402 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 770/4776 | Loss: 101.569 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 780/4776 | Loss: 54.494 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 790/4776 | Loss: 108.935 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 800/4776 | Loss: 60.176 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 810/4776 | Loss: 83.356 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 820/4776 | Loss: 105.260 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 830/4776 | Loss: 58.931 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 840/4776 | Loss: 131.510 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 850/4776 | Loss: 51.048 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 860/4776 | Loss: 53.415 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 870/4776 | Loss: 115.803 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 880/4776 | Loss: 86.525 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 890/4776 | Loss: 101.215 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 900/4776 | Loss: 42.605 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 910/4776 | Loss: 82.392 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 920/4776 | Loss: 103.626 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 930/4776 | Loss: 35.213 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 940/4776 | Loss: 51.529 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 950/4776 | Loss: 89.323 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 960/4776 | Loss: 59.697 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 970/4776 | Loss: 84.368 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 980/4776 | Loss: 54.637 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 990/4776 | Loss: 83.369 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1000/4776 | Loss: 154.181 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1010/4776 | Loss: 66.743 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1020/4776 | Loss: 105.464 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1030/4776 | Loss: 52.256 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1040/4776 | Loss: 106.895 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 1050/4776 | Loss: 61.071 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1060/4776 | Loss: 58.298 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1070/4776 | Loss: 14.089 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 1080/4776 | Loss: 156.691 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1090/4776 | Loss: 98.788 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1100/4776 | Loss: 93.039 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1110/4776 | Loss: 87.485 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1120/4776 | Loss: 140.623 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1130/4776 | Loss: 128.123 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1140/4776 | Loss: 95.515 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1150/4776 | Loss: 39.154 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1160/4776 | Loss: 21.769 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 1170/4776 | Loss: 57.250 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1180/4776 | Loss: 47.060 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1190/4776 | Loss: 40.661 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1200/4776 | Loss: 75.083 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1210/4776 | Loss: 48.359 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1220/4776 | Loss: 79.168 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1230/4776 | Loss: 49.633 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1240/4776 | Loss: 138.010 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1250/4776 | Loss: 21.599 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1260/4776 | Loss: 88.279 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1270/4776 | Loss: 131.861 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1280/4776 | Loss: 104.353 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1290/4776 | Loss: 85.753 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1300/4776 | Loss: 71.392 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1310/4776 | Loss: 57.172 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1320/4776 | Loss: 35.820 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1330/4776 | Loss: 31.281 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 1340/4776 | Loss: 99.179 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1350/4776 | Loss: 87.406 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1360/4776 | Loss: 78.003 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1370/4776 | Loss: 155.873 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 1380/4776 | Loss: 98.548 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1390/4776 | Loss: 64.727 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1400/4776 | Loss: 65.721 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1410/4776 | Loss: 84.106 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1420/4776 | Loss: 27.737 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1430/4776 | Loss: 118.169 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1440/4776 | Loss: 42.426 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1450/4776 | Loss: 36.858 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1460/4776 | Loss: 70.530 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1470/4776 | Loss: 78.802 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1480/4776 | Loss: 14.803 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1490/4776 | Loss: 62.978 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1500/4776 | Loss: 83.303 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1510/4776 | Loss: 51.503 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1520/4776 | Loss: 68.874 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1530/4776 | Loss: 63.764 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1540/4776 | Loss: 39.452 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1550/4776 | Loss: 109.527 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1560/4776 | Loss: 80.635 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1570/4776 | Loss: 74.046 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1580/4776 | Loss: 62.040 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1590/4776 | Loss: 88.923 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1600/4776 | Loss: 92.575 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1610/4776 | Loss: 138.630 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1620/4776 | Loss: 132.947 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 1630/4776 | Loss: 53.098 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1640/4776 | Loss: 96.300 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1650/4776 | Loss: 76.038 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1660/4776 | Loss: 145.515 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1670/4776 | Loss: 66.847 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1680/4776 | Loss: 72.832 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1690/4776 | Loss: 42.876 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 1700/4776 | Loss: 99.665 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1710/4776 | Loss: 96.433 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1720/4776 | Loss: 115.918 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1730/4776 | Loss: 58.284 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1740/4776 | Loss: 74.580 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1750/4776 | Loss: 115.344 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1760/4776 | Loss: 22.864 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 1770/4776 | Loss: 69.304 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1780/4776 | Loss: 36.791 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1790/4776 | Loss: 73.968 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1800/4776 | Loss: 49.091 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1810/4776 | Loss: 40.964 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1820/4776 | Loss: 144.640 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1830/4776 | Loss: 72.762 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1840/4776 | Loss: 128.462 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1850/4776 | Loss: 67.158 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1860/4776 | Loss: 95.202 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1870/4776 | Loss: 77.009 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1880/4776 | Loss: 48.717 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1890/4776 | Loss: 77.966 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1900/4776 | Loss: 76.289 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 1910/4776 | Loss: 81.552 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1920/4776 | Loss: 117.068 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 1930/4776 | Loss: 58.037 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1940/4776 | Loss: 86.314 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 1950/4776 | Loss: 28.228 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1960/4776 | Loss: 86.881 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1970/4776 | Loss: 57.272 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 1980/4776 | Loss: 58.966 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 1990/4776 | Loss: 47.332 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2000/4776 | Loss: 23.720 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2010/4776 | Loss: 84.828 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2020/4776 | Loss: 57.855 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2030/4776 | Loss: 135.057 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2040/4776 | Loss: 113.245 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2050/4776 | Loss: 75.356 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2060/4776 | Loss: 52.554 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2070/4776 | Loss: 28.788 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2080/4776 | Loss: 74.530 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 2090/4776 | Loss: 121.189 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2100/4776 | Loss: 45.970 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2110/4776 | Loss: 62.532 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2120/4776 | Loss: 55.109 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2130/4776 | Loss: 55.323 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2140/4776 | Loss: 46.346 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2150/4776 | Loss: 96.119 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2160/4776 | Loss: 59.510 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2170/4776 | Loss: 94.398 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2180/4776 | Loss: 117.332 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 2190/4776 | Loss: 82.222 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2200/4776 | Loss: 61.263 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2210/4776 | Loss: 80.883 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2220/4776 | Loss: 51.514 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2230/4776 | Loss: 45.409 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 2240/4776 | Loss: 102.465 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2250/4776 | Loss: 82.685 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2260/4776 | Loss: 73.384 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2270/4776 | Loss: 32.497 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2280/4776 | Loss: 56.748 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2290/4776 | Loss: 79.527 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2300/4776 | Loss: 92.976 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2310/4776 | Loss: 66.364 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2320/4776 | Loss: 112.782 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2330/4776 | Loss: 94.668 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2340/4776 | Loss: 94.815 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2350/4776 | Loss: 30.039 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2360/4776 | Loss: 84.401 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2370/4776 | Loss: 42.308 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2380/4776 | Loss: 62.414 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2390/4776 | Loss: 62.616 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2400/4776 | Loss: 74.712 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2410/4776 | Loss: 80.851 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2420/4776 | Loss: 81.041 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2430/4776 | Loss: 92.630 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2440/4776 | Loss: 96.476 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2450/4776 | Loss: 52.692 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2460/4776 | Loss: 22.419 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 2470/4776 | Loss: 88.018 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2480/4776 | Loss: 95.501 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2490/4776 | Loss: 59.037 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2500/4776 | Loss: 81.791 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2510/4776 | Loss: 3.293 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 2520/4776 | Loss: 96.228 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2530/4776 | Loss: 45.258 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2540/4776 | Loss: 52.319 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2550/4776 | Loss: 101.447 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2560/4776 | Loss: 41.611 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2570/4776 | Loss: 93.508 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2580/4776 | Loss: 133.316 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2590/4776 | Loss: 43.458 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2600/4776 | Loss: 73.766 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2610/4776 | Loss: 72.979 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2620/4776 | Loss: 99.987 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2630/4776 | Loss: 83.421 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2640/4776 | Loss: 92.807 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2650/4776 | Loss: 66.996 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2660/4776 | Loss: 70.374 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2670/4776 | Loss: 45.742 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2680/4776 | Loss: 63.107 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2690/4776 | Loss: 67.812 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2700/4776 | Loss: 130.554 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2710/4776 | Loss: 90.722 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2720/4776 | Loss: 66.044 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2730/4776 | Loss: 50.267 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2740/4776 | Loss: 108.504 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2750/4776 | Loss: 106.043 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2760/4776 | Loss: 72.825 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2770/4776 | Loss: 76.527 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2780/4776 | Loss: 56.311 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 2790/4776 | Loss: 120.608 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2800/4776 | Loss: 90.722 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2810/4776 | Loss: 136.241 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 2820/4776 | Loss: 28.353 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2830/4776 | Loss: 78.295 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2840/4776 | Loss: 96.250 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2850/4776 | Loss: 67.488 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2860/4776 | Loss: 166.229 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2870/4776 | Loss: 126.848 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2880/4776 | Loss: 106.864 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2890/4776 | Loss: 46.182 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2900/4776 | Loss: 50.454 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 2910/4776 | Loss: 111.213 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2920/4776 | Loss: 150.480 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2930/4776 | Loss: 126.470 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2940/4776 | Loss: 22.543 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 2950/4776 | Loss: 106.710 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2960/4776 | Loss: 89.081 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 2970/4776 | Loss: 88.256 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 2980/4776 | Loss: 77.096 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 2990/4776 | Loss: 58.394 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3000/4776 | Loss: 66.533 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3010/4776 | Loss: 84.074 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3020/4776 | Loss: 80.395 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3030/4776 | Loss: 74.485 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3040/4776 | Loss: 98.988 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3050/4776 | Loss: 43.526 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3060/4776 | Loss: 64.778 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3070/4776 | Loss: 61.318 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3080/4776 | Loss: 87.394 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3090/4776 | Loss: 90.904 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3100/4776 | Loss: 84.196 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3110/4776 | Loss: 52.509 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3120/4776 | Loss: 64.660 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3130/4776 | Loss: 63.027 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3140/4776 | Loss: 76.346 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3150/4776 | Loss: 56.302 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3160/4776 | Loss: 50.941 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3170/4776 | Loss: 76.394 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3180/4776 | Loss: 74.579 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3190/4776 | Loss: 37.092 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3200/4776 | Loss: 35.950 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3210/4776 | Loss: 35.945 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3220/4776 | Loss: 56.692 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3230/4776 | Loss: 50.939 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3240/4776 | Loss: 73.919 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3250/4776 | Loss: 44.113 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3260/4776 | Loss: 54.663 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3270/4776 | Loss: 89.541 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3280/4776 | Loss: 57.874 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3290/4776 | Loss: 57.520 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3300/4776 | Loss: 37.284 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3310/4776 | Loss: 51.128 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3320/4776 | Loss: 77.477 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3330/4776 | Loss: 97.706 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3340/4776 | Loss: 66.586 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3350/4776 | Loss: 29.123 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3360/4776 | Loss: 38.699 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3370/4776 | Loss: 23.494 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 3380/4776 | Loss: 99.028 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3390/4776 | Loss: 47.484 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3400/4776 | Loss: 143.483 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3410/4776 | Loss: 41.081 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3420/4776 | Loss: 27.465 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3430/4776 | Loss: 50.977 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3440/4776 | Loss: 59.147 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3450/4776 | Loss: 74.542 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3460/4776 | Loss: 56.436 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3470/4776 | Loss: 77.218 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3480/4776 | Loss: 130.016 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3490/4776 | Loss: 55.060 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3500/4776 | Loss: 84.765 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3510/4776 | Loss: 67.602 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3520/4776 | Loss: 79.331 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3530/4776 | Loss: 108.332 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3540/4776 | Loss: 113.249 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3550/4776 | Loss: 36.860 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3560/4776 | Loss: 61.538 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3570/4776 | Loss: 120.578 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3580/4776 | Loss: 76.469 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3590/4776 | Loss: 53.951 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3600/4776 | Loss: 24.382 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3610/4776 | Loss: 44.155 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3620/4776 | Loss: 56.407 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3630/4776 | Loss: 41.065 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3640/4776 | Loss: 44.960 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3650/4776 | Loss: 114.121 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 3660/4776 | Loss: 34.943 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 3670/4776 | Loss: 75.117 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3680/4776 | Loss: 55.123 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3690/4776 | Loss: 30.578 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3700/4776 | Loss: 60.115 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3710/4776 | Loss: 96.357 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3720/4776 | Loss: 103.717 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3730/4776 | Loss: 44.964 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3740/4776 | Loss: 130.880 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3750/4776 | Loss: 45.492 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3760/4776 | Loss: 80.945 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3770/4776 | Loss: 133.404 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3780/4776 | Loss: 136.897 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3790/4776 | Loss: 78.701 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3800/4776 | Loss: 104.423 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3810/4776 | Loss: 121.970 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 3820/4776 | Loss: 32.780 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 3830/4776 | Loss: 76.601 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3840/4776 | Loss: 60.916 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3850/4776 | Loss: 83.994 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3860/4776 | Loss: 63.706 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3870/4776 | Loss: 104.077 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3880/4776 | Loss: 68.769 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3890/4776 | Loss: 76.221 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3900/4776 | Loss: 72.790 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3910/4776 | Loss: 113.009 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3920/4776 | Loss: 58.099 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3930/4776 | Loss: 52.487 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 3940/4776 | Loss: 112.874 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 3950/4776 | Loss: 88.845 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 3960/4776 | Loss: 62.068 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3970/4776 | Loss: 64.577 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3980/4776 | Loss: 76.271 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 3990/4776 | Loss: 115.378 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 4000/4776 | Loss: 67.334 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4010/4776 | Loss: 119.768 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4020/4776 | Loss: 53.135 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4030/4776 | Loss: 81.249 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4040/4776 | Loss: 135.631 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 4050/4776 | Loss: 52.109 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4060/4776 | Loss: 58.401 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4070/4776 | Loss: 104.913 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 4080/4776 | Loss: 77.307 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4090/4776 | Loss: 73.175 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4100/4776 | Loss: 124.920 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 4110/4776 | Loss: 60.410 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4120/4776 | Loss: 89.880 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4130/4776 | Loss: 92.517 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4140/4776 | Loss: 86.592 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4150/4776 | Loss: 57.072 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4160/4776 | Loss: 76.305 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4170/4776 | Loss: 82.343 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4180/4776 | Loss: 65.804 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4190/4776 | Loss: 54.013 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4200/4776 | Loss: 48.097 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4210/4776 | Loss: 76.542 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4220/4776 | Loss: 51.390 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4230/4776 | Loss: 63.648 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4240/4776 | Loss: 104.122 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 4250/4776 | Loss: 34.459 | Accuracy: 1.000\n",
      "[Epoch: 67/200] - Step: 4260/4776 | Loss: 97.423 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4270/4776 | Loss: 83.556 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4280/4776 | Loss: 77.677 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4290/4776 | Loss: 47.138 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4300/4776 | Loss: 80.078 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4310/4776 | Loss: 86.888 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4320/4776 | Loss: 83.943 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4330/4776 | Loss: 71.819 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4340/4776 | Loss: 27.510 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4350/4776 | Loss: 44.019 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4360/4776 | Loss: 45.866 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4370/4776 | Loss: 132.756 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 4380/4776 | Loss: 95.386 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4390/4776 | Loss: 83.573 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4400/4776 | Loss: 73.034 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4410/4776 | Loss: 96.807 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4420/4776 | Loss: 59.189 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4430/4776 | Loss: 44.181 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4440/4776 | Loss: 56.589 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4450/4776 | Loss: 123.455 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4460/4776 | Loss: 77.457 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4470/4776 | Loss: 88.673 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4480/4776 | Loss: 115.324 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4490/4776 | Loss: 83.649 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4500/4776 | Loss: 109.340 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4510/4776 | Loss: 41.032 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4520/4776 | Loss: 57.534 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4530/4776 | Loss: 85.454 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4540/4776 | Loss: 96.109 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4550/4776 | Loss: 65.327 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4560/4776 | Loss: 57.725 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4570/4776 | Loss: 87.683 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4580/4776 | Loss: 119.765 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 4590/4776 | Loss: 81.076 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4600/4776 | Loss: 78.575 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4610/4776 | Loss: 103.930 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4620/4776 | Loss: 72.814 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4630/4776 | Loss: 140.753 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 4640/4776 | Loss: 29.058 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4650/4776 | Loss: 60.647 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4660/4776 | Loss: 71.041 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4670/4776 | Loss: 41.442 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4680/4776 | Loss: 91.494 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4690/4776 | Loss: 56.401 | Accuracy: 0.900\n",
      "[Epoch: 67/200] - Step: 4700/4776 | Loss: 89.169 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4710/4776 | Loss: 77.507 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4720/4776 | Loss: 62.451 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4730/4776 | Loss: 98.953 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4740/4776 | Loss: 43.855 | Accuracy: 0.800\n",
      "[Epoch: 67/200] - Step: 4750/4776 | Loss: 77.517 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 4760/4776 | Loss: 71.526 | Accuracy: 0.700\n",
      "[Epoch: 67/200] - Step: 4770/4776 | Loss: 68.563 | Accuracy: 0.600\n",
      "Accuracy:  0.21311475409836064\n",
      "[Epoch: 68/200] - Step: 10/4776 | Loss: 46.148 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 20/4776 | Loss: 41.469 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 30/4776 | Loss: 62.728 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 40/4776 | Loss: 66.920 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 50/4776 | Loss: 51.304 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 60/4776 | Loss: 71.701 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 70/4776 | Loss: 64.319 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 80/4776 | Loss: 100.059 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 90/4776 | Loss: 48.345 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 100/4776 | Loss: 111.365 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 110/4776 | Loss: 102.776 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 120/4776 | Loss: 48.206 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 130/4776 | Loss: 85.263 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 140/4776 | Loss: 42.310 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 150/4776 | Loss: 49.567 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 160/4776 | Loss: 106.463 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 170/4776 | Loss: 83.423 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 180/4776 | Loss: 78.125 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 190/4776 | Loss: 41.863 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 200/4776 | Loss: 142.505 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 210/4776 | Loss: 78.810 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 220/4776 | Loss: 81.192 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 230/4776 | Loss: 62.175 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 240/4776 | Loss: 78.275 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 250/4776 | Loss: 52.786 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 260/4776 | Loss: 52.016 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 270/4776 | Loss: 182.723 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 280/4776 | Loss: 84.403 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 290/4776 | Loss: 94.186 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 300/4776 | Loss: 115.380 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 310/4776 | Loss: 79.289 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 320/4776 | Loss: 74.227 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 330/4776 | Loss: 60.752 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 340/4776 | Loss: 109.397 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 350/4776 | Loss: 47.332 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 360/4776 | Loss: 60.112 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 370/4776 | Loss: 49.980 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 380/4776 | Loss: 69.110 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 390/4776 | Loss: 91.774 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 400/4776 | Loss: 145.638 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 410/4776 | Loss: 31.751 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 420/4776 | Loss: 48.781 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 430/4776 | Loss: 50.064 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 440/4776 | Loss: 133.784 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 450/4776 | Loss: 21.956 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 460/4776 | Loss: 63.073 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 470/4776 | Loss: 126.605 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 480/4776 | Loss: 111.892 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 490/4776 | Loss: 82.581 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 500/4776 | Loss: 72.061 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 510/4776 | Loss: 97.891 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 520/4776 | Loss: 14.427 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 530/4776 | Loss: 80.752 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 540/4776 | Loss: 79.225 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 550/4776 | Loss: 138.506 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 560/4776 | Loss: 76.923 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 570/4776 | Loss: 30.189 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 580/4776 | Loss: 62.516 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 590/4776 | Loss: 56.835 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 600/4776 | Loss: 40.869 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 610/4776 | Loss: 34.395 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 620/4776 | Loss: 48.183 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 630/4776 | Loss: 90.315 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 640/4776 | Loss: 69.253 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 650/4776 | Loss: 127.295 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 660/4776 | Loss: 34.706 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 670/4776 | Loss: 34.036 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 680/4776 | Loss: 57.099 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 690/4776 | Loss: 73.954 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 700/4776 | Loss: 89.232 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 710/4776 | Loss: 97.163 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 720/4776 | Loss: 60.029 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 730/4776 | Loss: 104.657 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 740/4776 | Loss: 156.364 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 750/4776 | Loss: 50.893 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 760/4776 | Loss: 85.967 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 770/4776 | Loss: 74.944 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 780/4776 | Loss: 116.858 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 790/4776 | Loss: 64.047 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 800/4776 | Loss: 108.783 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 810/4776 | Loss: 38.372 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 820/4776 | Loss: 67.610 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 830/4776 | Loss: 75.639 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 840/4776 | Loss: 116.630 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 850/4776 | Loss: 66.434 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 860/4776 | Loss: 67.040 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 870/4776 | Loss: 90.125 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 880/4776 | Loss: 64.482 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 890/4776 | Loss: 65.715 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 900/4776 | Loss: 38.894 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 910/4776 | Loss: 108.128 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 920/4776 | Loss: 39.971 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 930/4776 | Loss: 35.121 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 940/4776 | Loss: 72.850 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 950/4776 | Loss: 124.883 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 960/4776 | Loss: 123.210 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 970/4776 | Loss: 81.218 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 980/4776 | Loss: 47.596 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 990/4776 | Loss: 57.564 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1000/4776 | Loss: 95.483 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1010/4776 | Loss: 78.028 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1020/4776 | Loss: 52.686 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1030/4776 | Loss: 25.193 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1040/4776 | Loss: 68.224 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1050/4776 | Loss: 75.229 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1060/4776 | Loss: 28.525 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1070/4776 | Loss: 62.644 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1080/4776 | Loss: 40.991 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1090/4776 | Loss: 98.808 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1100/4776 | Loss: 99.558 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1110/4776 | Loss: 14.632 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1120/4776 | Loss: 105.530 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1130/4776 | Loss: 30.531 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1140/4776 | Loss: 81.181 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1150/4776 | Loss: 28.670 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1160/4776 | Loss: 40.336 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1170/4776 | Loss: 34.843 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1180/4776 | Loss: 98.744 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1190/4776 | Loss: 48.300 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1200/4776 | Loss: 49.344 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1210/4776 | Loss: 78.655 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1220/4776 | Loss: 95.017 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1230/4776 | Loss: 169.828 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 1240/4776 | Loss: 109.034 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1250/4776 | Loss: 62.728 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1260/4776 | Loss: 52.544 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1270/4776 | Loss: 75.275 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1280/4776 | Loss: 61.829 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1290/4776 | Loss: 45.860 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1300/4776 | Loss: 27.449 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1310/4776 | Loss: 66.934 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1320/4776 | Loss: 101.751 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1330/4776 | Loss: 180.979 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1340/4776 | Loss: 21.484 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1350/4776 | Loss: 100.930 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1360/4776 | Loss: 48.927 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1370/4776 | Loss: 42.627 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1380/4776 | Loss: 82.097 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1390/4776 | Loss: 60.479 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1400/4776 | Loss: 35.289 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1410/4776 | Loss: 64.788 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1420/4776 | Loss: 60.189 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1430/4776 | Loss: 15.888 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1440/4776 | Loss: 114.887 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1450/4776 | Loss: 112.974 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1460/4776 | Loss: 31.661 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1470/4776 | Loss: 55.282 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1480/4776 | Loss: 50.650 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1490/4776 | Loss: 33.627 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1500/4776 | Loss: 38.350 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1510/4776 | Loss: 71.056 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1520/4776 | Loss: 173.110 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1530/4776 | Loss: 53.349 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1540/4776 | Loss: 39.079 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1550/4776 | Loss: 83.036 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1560/4776 | Loss: 71.966 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1570/4776 | Loss: 43.319 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1580/4776 | Loss: 40.990 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1590/4776 | Loss: 55.767 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1600/4776 | Loss: 67.916 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1610/4776 | Loss: 64.747 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1620/4776 | Loss: 80.511 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1630/4776 | Loss: 118.976 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1640/4776 | Loss: 47.605 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1650/4776 | Loss: 102.251 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1660/4776 | Loss: 145.335 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1670/4776 | Loss: 82.793 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1680/4776 | Loss: 68.553 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1690/4776 | Loss: 27.367 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1700/4776 | Loss: 70.634 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1710/4776 | Loss: 11.163 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 1720/4776 | Loss: 23.466 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1730/4776 | Loss: 54.067 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1740/4776 | Loss: 47.629 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1750/4776 | Loss: 87.030 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1760/4776 | Loss: 88.278 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1770/4776 | Loss: 97.259 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1780/4776 | Loss: 93.773 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1790/4776 | Loss: 126.003 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1800/4776 | Loss: 41.363 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1810/4776 | Loss: 90.162 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1820/4776 | Loss: 81.973 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1830/4776 | Loss: 95.065 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1840/4776 | Loss: 94.068 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1850/4776 | Loss: 104.593 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1860/4776 | Loss: 52.416 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1870/4776 | Loss: 36.330 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1880/4776 | Loss: 47.762 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1890/4776 | Loss: 33.095 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1900/4776 | Loss: 80.333 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1910/4776 | Loss: 63.136 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1920/4776 | Loss: 68.760 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 1930/4776 | Loss: 62.177 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1940/4776 | Loss: 44.073 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 1950/4776 | Loss: 108.200 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1960/4776 | Loss: 142.319 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 1970/4776 | Loss: 132.619 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1980/4776 | Loss: 85.913 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 1990/4776 | Loss: 105.443 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2000/4776 | Loss: 87.983 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2010/4776 | Loss: 112.509 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2020/4776 | Loss: 133.370 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2030/4776 | Loss: 129.401 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2040/4776 | Loss: 54.400 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2050/4776 | Loss: 68.755 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2060/4776 | Loss: 37.475 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2070/4776 | Loss: 69.571 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2080/4776 | Loss: 88.098 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2090/4776 | Loss: 89.862 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2100/4776 | Loss: 50.832 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2110/4776 | Loss: 92.642 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2120/4776 | Loss: 68.863 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2130/4776 | Loss: 55.066 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2140/4776 | Loss: 74.023 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2150/4776 | Loss: 46.424 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2160/4776 | Loss: 29.735 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2170/4776 | Loss: 40.423 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2180/4776 | Loss: 99.962 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2190/4776 | Loss: 80.680 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2200/4776 | Loss: 111.231 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2210/4776 | Loss: 52.570 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2220/4776 | Loss: 117.627 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2230/4776 | Loss: 100.520 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2240/4776 | Loss: 105.679 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2250/4776 | Loss: 99.075 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 2260/4776 | Loss: 53.442 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2270/4776 | Loss: 82.592 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2280/4776 | Loss: 66.525 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2290/4776 | Loss: 57.999 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2300/4776 | Loss: 64.276 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2310/4776 | Loss: 68.430 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2320/4776 | Loss: 43.726 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2330/4776 | Loss: 44.518 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2340/4776 | Loss: 68.881 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2350/4776 | Loss: 56.146 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2360/4776 | Loss: 117.731 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2370/4776 | Loss: 33.584 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2380/4776 | Loss: 59.796 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2390/4776 | Loss: 43.962 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2400/4776 | Loss: 85.469 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2410/4776 | Loss: 53.200 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2420/4776 | Loss: 63.882 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2430/4776 | Loss: 63.340 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2440/4776 | Loss: 88.142 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2450/4776 | Loss: 72.470 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2460/4776 | Loss: 82.154 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2470/4776 | Loss: 29.111 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2480/4776 | Loss: 61.271 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2490/4776 | Loss: 93.104 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2500/4776 | Loss: 79.194 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2510/4776 | Loss: 29.443 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 2520/4776 | Loss: 87.209 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2530/4776 | Loss: 82.688 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2540/4776 | Loss: 69.909 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2550/4776 | Loss: 54.628 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2560/4776 | Loss: 66.018 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2570/4776 | Loss: 45.393 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2580/4776 | Loss: 101.869 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2590/4776 | Loss: 69.553 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2600/4776 | Loss: 64.425 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2610/4776 | Loss: 51.961 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2620/4776 | Loss: 123.766 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2630/4776 | Loss: 134.632 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2640/4776 | Loss: 67.827 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2650/4776 | Loss: 74.192 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2660/4776 | Loss: 113.225 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2670/4776 | Loss: 10.836 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 2680/4776 | Loss: 42.492 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2690/4776 | Loss: 58.934 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2700/4776 | Loss: 46.495 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2710/4776 | Loss: 48.336 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2720/4776 | Loss: 40.811 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2730/4776 | Loss: 109.094 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2740/4776 | Loss: 48.637 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2750/4776 | Loss: 160.306 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 2760/4776 | Loss: 39.838 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2770/4776 | Loss: 96.942 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2780/4776 | Loss: 89.899 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2790/4776 | Loss: 65.270 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2800/4776 | Loss: 96.498 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2810/4776 | Loss: 95.478 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2820/4776 | Loss: 64.746 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2830/4776 | Loss: 51.740 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 2840/4776 | Loss: 42.689 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2850/4776 | Loss: 80.951 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2860/4776 | Loss: 54.356 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2870/4776 | Loss: 23.937 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 2880/4776 | Loss: 88.122 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2890/4776 | Loss: 71.485 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2900/4776 | Loss: 103.801 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2910/4776 | Loss: 90.414 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 2920/4776 | Loss: 32.080 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2930/4776 | Loss: 84.939 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2940/4776 | Loss: 90.147 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2950/4776 | Loss: 64.955 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 2960/4776 | Loss: 59.098 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2970/4776 | Loss: 102.059 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 2980/4776 | Loss: 55.777 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 2990/4776 | Loss: 99.789 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3000/4776 | Loss: 64.048 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3010/4776 | Loss: 46.703 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3020/4776 | Loss: 24.966 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3030/4776 | Loss: 109.034 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3040/4776 | Loss: 89.263 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3050/4776 | Loss: 58.949 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3060/4776 | Loss: 81.869 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3070/4776 | Loss: 66.195 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3080/4776 | Loss: 77.335 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3090/4776 | Loss: 85.721 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3100/4776 | Loss: 48.559 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3110/4776 | Loss: 14.950 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3120/4776 | Loss: 48.785 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3130/4776 | Loss: 73.133 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3140/4776 | Loss: 123.775 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3150/4776 | Loss: 152.358 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3160/4776 | Loss: 32.426 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3170/4776 | Loss: 220.636 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 3180/4776 | Loss: 55.263 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3190/4776 | Loss: 58.321 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3200/4776 | Loss: 92.510 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3210/4776 | Loss: 62.143 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3220/4776 | Loss: 92.717 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3230/4776 | Loss: 41.222 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3240/4776 | Loss: 55.398 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3250/4776 | Loss: 61.135 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3260/4776 | Loss: 51.656 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3270/4776 | Loss: 46.503 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3280/4776 | Loss: 45.983 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3290/4776 | Loss: 82.438 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3300/4776 | Loss: 51.807 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3310/4776 | Loss: 47.416 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3320/4776 | Loss: 110.616 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3330/4776 | Loss: 94.837 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3340/4776 | Loss: 82.770 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3350/4776 | Loss: 48.859 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3360/4776 | Loss: 42.349 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3370/4776 | Loss: 56.485 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3380/4776 | Loss: 29.864 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3390/4776 | Loss: 122.069 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 3400/4776 | Loss: 36.689 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3410/4776 | Loss: 48.362 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3420/4776 | Loss: 58.309 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3430/4776 | Loss: 89.885 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3440/4776 | Loss: 77.087 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3450/4776 | Loss: 23.026 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 3460/4776 | Loss: 75.184 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3470/4776 | Loss: 45.974 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3480/4776 | Loss: 128.761 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3490/4776 | Loss: 54.114 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3500/4776 | Loss: 44.840 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3510/4776 | Loss: 149.867 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 3520/4776 | Loss: 23.802 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 3530/4776 | Loss: 103.322 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3540/4776 | Loss: 88.864 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3550/4776 | Loss: 162.380 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 3560/4776 | Loss: 63.964 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3570/4776 | Loss: 118.760 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 3580/4776 | Loss: 187.357 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 3590/4776 | Loss: 89.274 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3600/4776 | Loss: 154.447 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3610/4776 | Loss: 42.497 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3620/4776 | Loss: 104.421 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3630/4776 | Loss: 89.087 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3640/4776 | Loss: 92.312 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3650/4776 | Loss: 66.188 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3660/4776 | Loss: 92.011 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3670/4776 | Loss: 127.133 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3680/4776 | Loss: 89.119 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3690/4776 | Loss: 67.914 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3700/4776 | Loss: 110.020 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3710/4776 | Loss: 83.275 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3720/4776 | Loss: 98.483 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3730/4776 | Loss: 46.859 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3740/4776 | Loss: 43.599 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3750/4776 | Loss: 72.095 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3760/4776 | Loss: 116.286 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3770/4776 | Loss: 106.569 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3780/4776 | Loss: 126.944 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 3790/4776 | Loss: 80.713 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3800/4776 | Loss: 155.487 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3810/4776 | Loss: 41.470 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 3820/4776 | Loss: 114.547 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3830/4776 | Loss: 73.912 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3840/4776 | Loss: 88.045 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3850/4776 | Loss: 79.402 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3860/4776 | Loss: 93.728 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3870/4776 | Loss: 64.668 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3880/4776 | Loss: 80.086 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3890/4776 | Loss: 71.915 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3900/4776 | Loss: 38.595 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3910/4776 | Loss: 27.053 | Accuracy: 1.000\n",
      "[Epoch: 68/200] - Step: 3920/4776 | Loss: 54.919 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3930/4776 | Loss: 84.856 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 3940/4776 | Loss: 37.557 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3950/4776 | Loss: 91.071 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3960/4776 | Loss: 65.998 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3970/4776 | Loss: 72.630 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 3980/4776 | Loss: 46.047 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 3990/4776 | Loss: 133.517 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4000/4776 | Loss: 91.795 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4010/4776 | Loss: 79.019 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4020/4776 | Loss: 92.713 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4030/4776 | Loss: 28.793 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 4040/4776 | Loss: 75.383 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4050/4776 | Loss: 66.688 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4060/4776 | Loss: 106.456 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4070/4776 | Loss: 40.712 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 4080/4776 | Loss: 58.669 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4090/4776 | Loss: 125.295 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4100/4776 | Loss: 40.857 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4110/4776 | Loss: 42.748 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4120/4776 | Loss: 87.040 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4130/4776 | Loss: 115.827 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4140/4776 | Loss: 50.999 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4150/4776 | Loss: 108.908 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4160/4776 | Loss: 66.724 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4170/4776 | Loss: 68.812 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4180/4776 | Loss: 70.021 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4190/4776 | Loss: 68.079 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 4200/4776 | Loss: 189.987 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4210/4776 | Loss: 79.204 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4220/4776 | Loss: 72.550 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4230/4776 | Loss: 55.813 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4240/4776 | Loss: 99.973 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4250/4776 | Loss: 48.628 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4260/4776 | Loss: 103.697 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4270/4776 | Loss: 144.176 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 4280/4776 | Loss: 71.866 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4290/4776 | Loss: 45.992 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4300/4776 | Loss: 89.448 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4310/4776 | Loss: 44.030 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4320/4776 | Loss: 95.741 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4330/4776 | Loss: 110.263 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4340/4776 | Loss: 99.212 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4350/4776 | Loss: 86.273 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4360/4776 | Loss: 78.033 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4370/4776 | Loss: 40.021 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4380/4776 | Loss: 55.160 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4390/4776 | Loss: 96.111 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4400/4776 | Loss: 73.657 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4410/4776 | Loss: 64.218 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4420/4776 | Loss: 74.334 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4430/4776 | Loss: 83.257 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4440/4776 | Loss: 73.431 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4450/4776 | Loss: 78.284 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4460/4776 | Loss: 104.968 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4470/4776 | Loss: 90.532 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4480/4776 | Loss: 58.880 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 4490/4776 | Loss: 91.633 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4500/4776 | Loss: 60.558 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4510/4776 | Loss: 59.508 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4520/4776 | Loss: 93.560 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4530/4776 | Loss: 78.206 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4540/4776 | Loss: 75.734 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4550/4776 | Loss: 117.476 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4560/4776 | Loss: 46.228 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4570/4776 | Loss: 41.156 | Accuracy: 0.900\n",
      "[Epoch: 68/200] - Step: 4580/4776 | Loss: 69.153 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4590/4776 | Loss: 91.565 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4600/4776 | Loss: 130.854 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4610/4776 | Loss: 87.561 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4620/4776 | Loss: 93.094 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4630/4776 | Loss: 87.226 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4640/4776 | Loss: 112.683 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4650/4776 | Loss: 110.381 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 4660/4776 | Loss: 128.779 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 4670/4776 | Loss: 93.051 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4680/4776 | Loss: 122.523 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 4690/4776 | Loss: 70.514 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4700/4776 | Loss: 74.459 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4710/4776 | Loss: 117.628 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 4720/4776 | Loss: 82.643 | Accuracy: 0.700\n",
      "[Epoch: 68/200] - Step: 4730/4776 | Loss: 72.425 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4740/4776 | Loss: 39.850 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4750/4776 | Loss: 123.752 | Accuracy: 0.600\n",
      "[Epoch: 68/200] - Step: 4760/4776 | Loss: 62.940 | Accuracy: 0.800\n",
      "[Epoch: 68/200] - Step: 4770/4776 | Loss: 50.892 | Accuracy: 0.800\n",
      "Accuracy:  0.1885245901639344\n",
      "[Epoch: 69/200] - Step: 10/4776 | Loss: 109.238 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 20/4776 | Loss: 108.076 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 30/4776 | Loss: 49.983 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 40/4776 | Loss: 58.855 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 50/4776 | Loss: 101.638 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 60/4776 | Loss: 60.804 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 70/4776 | Loss: 47.538 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 80/4776 | Loss: 88.689 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 90/4776 | Loss: 38.707 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 100/4776 | Loss: 45.216 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 110/4776 | Loss: 121.975 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 120/4776 | Loss: 72.904 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 130/4776 | Loss: 45.002 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 140/4776 | Loss: 49.949 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 150/4776 | Loss: 7.480 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 160/4776 | Loss: 41.598 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 170/4776 | Loss: 75.539 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 180/4776 | Loss: 99.607 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 190/4776 | Loss: 37.704 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 200/4776 | Loss: 113.587 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 210/4776 | Loss: 52.733 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 220/4776 | Loss: 62.573 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 230/4776 | Loss: 40.873 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 240/4776 | Loss: 101.271 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 250/4776 | Loss: 9.703 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 260/4776 | Loss: 55.492 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 270/4776 | Loss: 88.936 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 280/4776 | Loss: 83.606 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 290/4776 | Loss: 37.129 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 300/4776 | Loss: 89.690 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 310/4776 | Loss: 75.559 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 320/4776 | Loss: 39.243 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 330/4776 | Loss: 93.033 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 340/4776 | Loss: 17.070 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 350/4776 | Loss: 74.892 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 360/4776 | Loss: 84.517 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 370/4776 | Loss: 22.549 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 380/4776 | Loss: 206.290 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 390/4776 | Loss: 64.818 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 400/4776 | Loss: 65.082 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 410/4776 | Loss: 92.347 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 420/4776 | Loss: 98.756 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 430/4776 | Loss: 77.681 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 440/4776 | Loss: 76.933 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 450/4776 | Loss: 101.424 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 460/4776 | Loss: 76.747 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 470/4776 | Loss: 81.070 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 480/4776 | Loss: 117.043 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 490/4776 | Loss: 89.778 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 500/4776 | Loss: 73.794 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 510/4776 | Loss: 69.303 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 520/4776 | Loss: 76.588 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 530/4776 | Loss: 136.803 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 540/4776 | Loss: 54.948 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 550/4776 | Loss: 86.559 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 560/4776 | Loss: 50.154 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 570/4776 | Loss: 66.308 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 580/4776 | Loss: 28.844 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 590/4776 | Loss: 56.221 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 600/4776 | Loss: 44.091 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 610/4776 | Loss: 89.254 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 620/4776 | Loss: 74.660 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 630/4776 | Loss: 70.827 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 640/4776 | Loss: 74.234 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 650/4776 | Loss: 62.137 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 660/4776 | Loss: 71.178 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 670/4776 | Loss: 33.103 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 680/4776 | Loss: 74.760 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 690/4776 | Loss: 37.938 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 700/4776 | Loss: 63.432 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 710/4776 | Loss: 90.434 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 720/4776 | Loss: 42.353 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 730/4776 | Loss: 50.471 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 740/4776 | Loss: 59.213 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 750/4776 | Loss: 56.656 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 760/4776 | Loss: 67.269 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 770/4776 | Loss: 59.307 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 780/4776 | Loss: 36.742 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 790/4776 | Loss: 133.870 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 800/4776 | Loss: 50.862 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 810/4776 | Loss: 37.023 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 820/4776 | Loss: 50.656 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 830/4776 | Loss: 54.146 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 840/4776 | Loss: 71.488 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 850/4776 | Loss: 60.482 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 860/4776 | Loss: 20.655 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 870/4776 | Loss: 41.847 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 880/4776 | Loss: 54.491 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 890/4776 | Loss: 60.854 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 900/4776 | Loss: 48.726 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 910/4776 | Loss: 126.638 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 920/4776 | Loss: 40.014 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 930/4776 | Loss: 18.233 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 940/4776 | Loss: 110.974 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 950/4776 | Loss: 67.419 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 960/4776 | Loss: 51.189 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 970/4776 | Loss: 101.193 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 980/4776 | Loss: 89.877 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 990/4776 | Loss: 64.971 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1000/4776 | Loss: 51.245 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1010/4776 | Loss: 113.677 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1020/4776 | Loss: 156.763 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 1030/4776 | Loss: 105.988 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1040/4776 | Loss: 93.049 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1050/4776 | Loss: 118.595 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1060/4776 | Loss: 24.972 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1070/4776 | Loss: 50.291 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1080/4776 | Loss: 82.888 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1090/4776 | Loss: 48.428 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1100/4776 | Loss: 26.196 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 1110/4776 | Loss: 35.968 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1120/4776 | Loss: 105.744 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1130/4776 | Loss: 44.188 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1140/4776 | Loss: 71.467 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1150/4776 | Loss: 65.884 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1160/4776 | Loss: 24.453 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1170/4776 | Loss: 28.917 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1180/4776 | Loss: 82.764 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1190/4776 | Loss: 82.110 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1200/4776 | Loss: 61.128 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1210/4776 | Loss: 85.995 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1220/4776 | Loss: 26.162 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1230/4776 | Loss: 53.136 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1240/4776 | Loss: 58.539 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1250/4776 | Loss: 53.348 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1260/4776 | Loss: 35.234 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1270/4776 | Loss: 58.896 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1280/4776 | Loss: 49.193 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1290/4776 | Loss: 102.525 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1300/4776 | Loss: 22.432 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1310/4776 | Loss: 76.548 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1320/4776 | Loss: 93.092 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1330/4776 | Loss: 69.493 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1340/4776 | Loss: 38.497 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1350/4776 | Loss: 53.238 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1360/4776 | Loss: 22.373 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1370/4776 | Loss: 65.603 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1380/4776 | Loss: 87.619 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1390/4776 | Loss: 103.555 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1400/4776 | Loss: 41.441 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1410/4776 | Loss: 114.186 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1420/4776 | Loss: 71.495 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1430/4776 | Loss: 73.718 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1440/4776 | Loss: 207.570 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1450/4776 | Loss: 81.856 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1460/4776 | Loss: 103.735 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1470/4776 | Loss: 83.530 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1480/4776 | Loss: 46.790 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1490/4776 | Loss: 97.413 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1500/4776 | Loss: 67.580 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1510/4776 | Loss: 114.227 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1520/4776 | Loss: 69.024 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1530/4776 | Loss: 55.964 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1540/4776 | Loss: 85.796 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1550/4776 | Loss: 74.442 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1560/4776 | Loss: 144.352 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1570/4776 | Loss: 64.432 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1580/4776 | Loss: 81.778 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1590/4776 | Loss: 106.067 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1600/4776 | Loss: 130.846 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1610/4776 | Loss: 32.253 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 1620/4776 | Loss: 129.452 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1630/4776 | Loss: 51.440 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1640/4776 | Loss: 154.030 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1650/4776 | Loss: 58.044 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1660/4776 | Loss: 149.553 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1670/4776 | Loss: 152.193 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1680/4776 | Loss: 62.522 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1690/4776 | Loss: 107.630 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1700/4776 | Loss: 71.883 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1710/4776 | Loss: 136.958 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 1720/4776 | Loss: 95.224 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1730/4776 | Loss: 79.278 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1740/4776 | Loss: 47.708 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1750/4776 | Loss: 56.136 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1760/4776 | Loss: 96.212 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1770/4776 | Loss: 102.094 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1780/4776 | Loss: 29.624 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1790/4776 | Loss: 32.168 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1800/4776 | Loss: 27.237 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1810/4776 | Loss: 65.785 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1820/4776 | Loss: 130.543 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1830/4776 | Loss: 71.634 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1840/4776 | Loss: 40.829 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1850/4776 | Loss: 59.297 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1860/4776 | Loss: 171.712 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1870/4776 | Loss: 121.907 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1880/4776 | Loss: 90.550 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1890/4776 | Loss: 72.208 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1900/4776 | Loss: 96.776 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 1910/4776 | Loss: 61.601 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1920/4776 | Loss: 28.507 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 1930/4776 | Loss: 93.440 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1940/4776 | Loss: 118.725 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1950/4776 | Loss: 88.870 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1960/4776 | Loss: 90.940 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 1970/4776 | Loss: 35.429 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 1980/4776 | Loss: 192.382 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 1990/4776 | Loss: 10.303 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2000/4776 | Loss: 119.468 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 2010/4776 | Loss: 46.157 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2020/4776 | Loss: 112.025 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 2030/4776 | Loss: 67.979 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2040/4776 | Loss: 95.779 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2050/4776 | Loss: 56.041 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2060/4776 | Loss: 76.169 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2070/4776 | Loss: 35.094 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2080/4776 | Loss: 124.348 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 2090/4776 | Loss: 71.415 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2100/4776 | Loss: 79.632 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2110/4776 | Loss: 152.710 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2120/4776 | Loss: 76.482 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2130/4776 | Loss: 111.979 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2140/4776 | Loss: 29.651 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2150/4776 | Loss: 35.000 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2160/4776 | Loss: 100.173 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2170/4776 | Loss: 64.530 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2180/4776 | Loss: 82.729 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2190/4776 | Loss: 54.886 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2200/4776 | Loss: 41.489 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2210/4776 | Loss: 40.246 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2220/4776 | Loss: 63.222 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2230/4776 | Loss: 78.054 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2240/4776 | Loss: 101.335 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2250/4776 | Loss: 89.405 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2260/4776 | Loss: 96.972 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2270/4776 | Loss: 97.146 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2280/4776 | Loss: 79.434 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2290/4776 | Loss: 44.445 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2300/4776 | Loss: 71.751 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2310/4776 | Loss: 37.422 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2320/4776 | Loss: 46.748 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2330/4776 | Loss: 29.470 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2340/4776 | Loss: 53.405 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2350/4776 | Loss: 60.677 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2360/4776 | Loss: 30.932 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2370/4776 | Loss: 98.291 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2380/4776 | Loss: 103.309 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 2390/4776 | Loss: 109.270 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2400/4776 | Loss: 67.074 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2410/4776 | Loss: 78.751 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2420/4776 | Loss: 26.557 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2430/4776 | Loss: 50.039 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2440/4776 | Loss: 76.569 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2450/4776 | Loss: 77.701 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2460/4776 | Loss: 23.883 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2470/4776 | Loss: 76.948 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2480/4776 | Loss: 117.176 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 2490/4776 | Loss: 48.690 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2500/4776 | Loss: 40.239 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2510/4776 | Loss: 86.956 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2520/4776 | Loss: 45.038 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2530/4776 | Loss: 32.396 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2540/4776 | Loss: 31.949 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2550/4776 | Loss: 65.955 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2560/4776 | Loss: 17.880 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2570/4776 | Loss: 28.302 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2580/4776 | Loss: 65.918 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2590/4776 | Loss: 116.317 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2600/4776 | Loss: 75.593 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2610/4776 | Loss: 58.112 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2620/4776 | Loss: 97.799 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2630/4776 | Loss: 60.769 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2640/4776 | Loss: 86.618 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2650/4776 | Loss: 13.871 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2660/4776 | Loss: 107.599 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2670/4776 | Loss: 183.846 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 2680/4776 | Loss: 106.261 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2690/4776 | Loss: 71.227 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2700/4776 | Loss: 89.430 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2710/4776 | Loss: 34.325 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2720/4776 | Loss: 52.637 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2730/4776 | Loss: 25.409 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2740/4776 | Loss: 85.170 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2750/4776 | Loss: 50.497 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2760/4776 | Loss: 68.223 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2770/4776 | Loss: 32.048 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 2780/4776 | Loss: 52.263 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2790/4776 | Loss: 56.256 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2800/4776 | Loss: 30.341 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2810/4776 | Loss: 59.937 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2820/4776 | Loss: 73.832 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2830/4776 | Loss: 35.679 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2840/4776 | Loss: 74.957 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2850/4776 | Loss: 131.053 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 2860/4776 | Loss: 58.646 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2870/4776 | Loss: 106.334 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2880/4776 | Loss: 61.201 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2890/4776 | Loss: 56.168 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2900/4776 | Loss: 72.036 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2910/4776 | Loss: 73.388 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2920/4776 | Loss: 71.079 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2930/4776 | Loss: 40.763 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2940/4776 | Loss: 69.361 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2950/4776 | Loss: 42.440 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 2960/4776 | Loss: 80.144 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 2970/4776 | Loss: 42.131 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 2980/4776 | Loss: 79.117 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 2990/4776 | Loss: 50.227 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3000/4776 | Loss: 124.412 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3010/4776 | Loss: 113.794 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 3020/4776 | Loss: 121.312 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3030/4776 | Loss: 92.256 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3040/4776 | Loss: 154.641 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 3050/4776 | Loss: 91.869 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3060/4776 | Loss: 44.051 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3070/4776 | Loss: 33.011 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3080/4776 | Loss: 75.272 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3090/4776 | Loss: 59.561 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3100/4776 | Loss: 83.712 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3110/4776 | Loss: 54.763 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3120/4776 | Loss: 102.669 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3130/4776 | Loss: 36.631 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3140/4776 | Loss: 86.593 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3150/4776 | Loss: 48.546 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3160/4776 | Loss: 50.869 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3170/4776 | Loss: 51.282 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3180/4776 | Loss: 45.837 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3190/4776 | Loss: 78.516 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3200/4776 | Loss: 52.050 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3210/4776 | Loss: 111.548 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3220/4776 | Loss: 57.735 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3230/4776 | Loss: 100.161 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3240/4776 | Loss: 67.959 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3250/4776 | Loss: 100.444 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3260/4776 | Loss: 22.059 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3270/4776 | Loss: 55.998 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3280/4776 | Loss: 80.215 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3290/4776 | Loss: 66.975 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3300/4776 | Loss: 55.682 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3310/4776 | Loss: 28.816 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3320/4776 | Loss: 72.290 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3330/4776 | Loss: 30.809 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3340/4776 | Loss: 30.531 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3350/4776 | Loss: 83.600 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 3360/4776 | Loss: 67.877 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3370/4776 | Loss: 45.459 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3380/4776 | Loss: 65.004 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3390/4776 | Loss: 64.462 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3400/4776 | Loss: 51.662 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3410/4776 | Loss: 69.165 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3420/4776 | Loss: 94.526 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3430/4776 | Loss: 88.651 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3440/4776 | Loss: 90.984 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 3450/4776 | Loss: 32.422 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3460/4776 | Loss: 164.378 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3470/4776 | Loss: 52.468 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3480/4776 | Loss: 57.646 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3490/4776 | Loss: 67.498 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3500/4776 | Loss: 66.995 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3510/4776 | Loss: 150.923 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3520/4776 | Loss: 95.846 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3530/4776 | Loss: 23.841 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 3540/4776 | Loss: 134.861 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 3550/4776 | Loss: 42.778 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3560/4776 | Loss: 51.688 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3570/4776 | Loss: 44.870 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3580/4776 | Loss: 68.870 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3590/4776 | Loss: 21.373 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 3600/4776 | Loss: 40.351 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3610/4776 | Loss: 92.377 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3620/4776 | Loss: 72.297 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3630/4776 | Loss: 73.977 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3640/4776 | Loss: 70.017 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3650/4776 | Loss: 53.666 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3660/4776 | Loss: 102.959 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3670/4776 | Loss: 44.060 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3680/4776 | Loss: 108.158 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3690/4776 | Loss: 174.233 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 3700/4776 | Loss: 33.816 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3710/4776 | Loss: 134.104 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 3720/4776 | Loss: 110.695 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3730/4776 | Loss: 34.911 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3740/4776 | Loss: 53.881 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3750/4776 | Loss: 40.538 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3760/4776 | Loss: 28.104 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3770/4776 | Loss: 56.954 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3780/4776 | Loss: 74.424 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3790/4776 | Loss: 54.585 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3800/4776 | Loss: 100.644 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3810/4776 | Loss: 13.078 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 3820/4776 | Loss: 66.257 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3830/4776 | Loss: 91.124 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3840/4776 | Loss: 46.077 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3850/4776 | Loss: 17.511 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 3860/4776 | Loss: 115.598 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3870/4776 | Loss: 64.045 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 3880/4776 | Loss: 124.187 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3890/4776 | Loss: 102.397 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3900/4776 | Loss: 45.983 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3910/4776 | Loss: 38.700 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3920/4776 | Loss: 82.283 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3930/4776 | Loss: 75.550 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 3940/4776 | Loss: 50.174 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3950/4776 | Loss: 87.171 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3960/4776 | Loss: 98.146 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 3970/4776 | Loss: 148.550 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 3980/4776 | Loss: 65.306 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 3990/4776 | Loss: 107.897 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 4000/4776 | Loss: 109.832 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4010/4776 | Loss: 91.158 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4020/4776 | Loss: 114.972 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 4030/4776 | Loss: 49.532 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4040/4776 | Loss: 43.592 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4050/4776 | Loss: 48.188 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4060/4776 | Loss: 23.881 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4070/4776 | Loss: 69.771 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4080/4776 | Loss: 57.876 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4090/4776 | Loss: 80.151 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4100/4776 | Loss: 59.218 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4110/4776 | Loss: 50.421 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4120/4776 | Loss: 82.916 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4130/4776 | Loss: 85.431 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 4140/4776 | Loss: 81.144 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4150/4776 | Loss: 76.544 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4160/4776 | Loss: 76.137 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4170/4776 | Loss: 28.967 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4180/4776 | Loss: 65.314 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4190/4776 | Loss: 62.909 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4200/4776 | Loss: 134.449 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4210/4776 | Loss: 53.792 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4220/4776 | Loss: 106.023 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 4230/4776 | Loss: 114.400 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4240/4776 | Loss: 25.253 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4250/4776 | Loss: 22.942 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4260/4776 | Loss: 36.441 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4270/4776 | Loss: 64.314 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4280/4776 | Loss: 36.533 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4290/4776 | Loss: 45.276 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4300/4776 | Loss: 114.941 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4310/4776 | Loss: 51.481 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4320/4776 | Loss: 26.560 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4330/4776 | Loss: 57.465 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4340/4776 | Loss: 37.761 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4350/4776 | Loss: 41.036 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4360/4776 | Loss: 104.445 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4370/4776 | Loss: 67.255 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4380/4776 | Loss: 46.904 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4390/4776 | Loss: 145.580 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 4400/4776 | Loss: 23.363 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4410/4776 | Loss: 110.057 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4420/4776 | Loss: 51.955 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4430/4776 | Loss: 82.639 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4440/4776 | Loss: 36.847 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4450/4776 | Loss: 97.246 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4460/4776 | Loss: 62.252 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4470/4776 | Loss: 44.600 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4480/4776 | Loss: 70.176 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4490/4776 | Loss: 60.807 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4500/4776 | Loss: 40.326 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4510/4776 | Loss: 53.028 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4520/4776 | Loss: 58.552 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4530/4776 | Loss: 58.439 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4540/4776 | Loss: 30.419 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4550/4776 | Loss: 44.845 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4560/4776 | Loss: 48.126 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4570/4776 | Loss: 65.396 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4580/4776 | Loss: 117.384 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4590/4776 | Loss: 17.573 | Accuracy: 1.000\n",
      "[Epoch: 69/200] - Step: 4600/4776 | Loss: 81.954 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4610/4776 | Loss: 32.790 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4620/4776 | Loss: 62.158 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4630/4776 | Loss: 61.865 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4640/4776 | Loss: 46.078 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4650/4776 | Loss: 143.772 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4660/4776 | Loss: 71.315 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4670/4776 | Loss: 94.705 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4680/4776 | Loss: 117.726 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4690/4776 | Loss: 120.140 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4700/4776 | Loss: 72.664 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4710/4776 | Loss: 62.152 | Accuracy: 0.800\n",
      "[Epoch: 69/200] - Step: 4720/4776 | Loss: 104.266 | Accuracy: 0.500\n",
      "[Epoch: 69/200] - Step: 4730/4776 | Loss: 95.711 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4740/4776 | Loss: 57.855 | Accuracy: 0.600\n",
      "[Epoch: 69/200] - Step: 4750/4776 | Loss: 30.734 | Accuracy: 0.900\n",
      "[Epoch: 69/200] - Step: 4760/4776 | Loss: 65.584 | Accuracy: 0.700\n",
      "[Epoch: 69/200] - Step: 4770/4776 | Loss: 46.371 | Accuracy: 0.900\n",
      "Accuracy:  0.21639344262295082\n",
      "[Epoch: 70/200] - Step: 10/4776 | Loss: 122.731 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 20/4776 | Loss: 96.388 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 30/4776 | Loss: 66.005 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 40/4776 | Loss: 57.683 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 50/4776 | Loss: 50.924 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 60/4776 | Loss: 76.770 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 70/4776 | Loss: 94.485 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 80/4776 | Loss: 53.900 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 90/4776 | Loss: 85.128 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 100/4776 | Loss: 60.409 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 110/4776 | Loss: 62.421 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 120/4776 | Loss: 73.227 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 130/4776 | Loss: 99.541 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 140/4776 | Loss: 90.617 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 150/4776 | Loss: 41.204 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 160/4776 | Loss: 92.762 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 170/4776 | Loss: 100.215 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 180/4776 | Loss: 130.027 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 190/4776 | Loss: 35.912 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 200/4776 | Loss: 82.694 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 210/4776 | Loss: 58.203 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 220/4776 | Loss: 108.234 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 230/4776 | Loss: 31.882 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 240/4776 | Loss: 59.294 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 250/4776 | Loss: 53.054 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 260/4776 | Loss: 53.540 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 270/4776 | Loss: 23.490 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 280/4776 | Loss: 47.435 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 290/4776 | Loss: 40.935 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 300/4776 | Loss: 73.569 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 310/4776 | Loss: 42.306 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 320/4776 | Loss: 60.182 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 330/4776 | Loss: 42.711 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 340/4776 | Loss: 120.425 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 350/4776 | Loss: 89.010 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 360/4776 | Loss: 51.084 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 370/4776 | Loss: 94.438 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 380/4776 | Loss: 75.166 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 390/4776 | Loss: 71.170 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 400/4776 | Loss: 56.795 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 410/4776 | Loss: 57.355 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 420/4776 | Loss: 88.062 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 430/4776 | Loss: 67.091 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 440/4776 | Loss: 91.757 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 450/4776 | Loss: 49.292 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 460/4776 | Loss: 65.492 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 470/4776 | Loss: 82.946 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 480/4776 | Loss: 64.751 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 490/4776 | Loss: 41.481 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 500/4776 | Loss: 72.064 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 510/4776 | Loss: 80.587 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 520/4776 | Loss: 80.114 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 530/4776 | Loss: 74.376 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 540/4776 | Loss: 102.172 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 550/4776 | Loss: 77.649 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 560/4776 | Loss: 74.583 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 570/4776 | Loss: 59.390 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 580/4776 | Loss: 87.872 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 590/4776 | Loss: 122.554 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 600/4776 | Loss: 50.177 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 610/4776 | Loss: 53.712 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 620/4776 | Loss: 62.577 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 630/4776 | Loss: 60.623 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 640/4776 | Loss: 84.048 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 650/4776 | Loss: 77.023 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 660/4776 | Loss: 69.094 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 670/4776 | Loss: 46.364 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 680/4776 | Loss: 63.001 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 690/4776 | Loss: 86.535 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 700/4776 | Loss: 71.116 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 710/4776 | Loss: 68.135 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 720/4776 | Loss: 92.247 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 730/4776 | Loss: 79.375 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 740/4776 | Loss: 19.055 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 750/4776 | Loss: 89.181 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 760/4776 | Loss: 36.481 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 770/4776 | Loss: 44.776 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 780/4776 | Loss: 49.896 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 790/4776 | Loss: 63.822 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 800/4776 | Loss: 37.032 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 810/4776 | Loss: 30.838 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 820/4776 | Loss: 79.155 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 830/4776 | Loss: 82.769 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 840/4776 | Loss: 84.800 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 850/4776 | Loss: 13.806 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 860/4776 | Loss: 77.916 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 870/4776 | Loss: 55.975 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 880/4776 | Loss: 76.891 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 890/4776 | Loss: 35.706 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 900/4776 | Loss: 114.835 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 910/4776 | Loss: 103.434 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 920/4776 | Loss: 59.171 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 930/4776 | Loss: 145.926 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 940/4776 | Loss: 68.873 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 950/4776 | Loss: 67.108 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 960/4776 | Loss: 73.785 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 970/4776 | Loss: 74.042 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 980/4776 | Loss: 56.741 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 990/4776 | Loss: 77.680 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1000/4776 | Loss: 60.787 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1010/4776 | Loss: 48.854 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1020/4776 | Loss: 124.237 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1030/4776 | Loss: 19.176 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1040/4776 | Loss: 23.510 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1050/4776 | Loss: 106.818 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1060/4776 | Loss: 38.611 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1070/4776 | Loss: 34.729 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1080/4776 | Loss: 59.634 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1090/4776 | Loss: 61.754 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1100/4776 | Loss: 8.443 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1110/4776 | Loss: 38.617 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1120/4776 | Loss: 78.003 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1130/4776 | Loss: 46.809 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1140/4776 | Loss: 30.116 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1150/4776 | Loss: 64.003 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1160/4776 | Loss: 77.457 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1170/4776 | Loss: 69.467 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1180/4776 | Loss: 77.276 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1190/4776 | Loss: 77.835 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1200/4776 | Loss: 35.508 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1210/4776 | Loss: 73.754 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1220/4776 | Loss: 41.421 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1230/4776 | Loss: 39.461 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1240/4776 | Loss: 54.068 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1250/4776 | Loss: 71.979 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1260/4776 | Loss: 128.696 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1270/4776 | Loss: 40.111 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1280/4776 | Loss: 9.683 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1290/4776 | Loss: 63.814 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1300/4776 | Loss: 41.251 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1310/4776 | Loss: 41.250 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1320/4776 | Loss: 95.271 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1330/4776 | Loss: 38.366 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1340/4776 | Loss: 30.746 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1350/4776 | Loss: 75.225 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1360/4776 | Loss: 45.849 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1370/4776 | Loss: 48.089 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1380/4776 | Loss: 86.749 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1390/4776 | Loss: 104.521 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1400/4776 | Loss: 50.310 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1410/4776 | Loss: 22.854 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1420/4776 | Loss: 70.161 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1430/4776 | Loss: 135.287 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1440/4776 | Loss: 86.312 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1450/4776 | Loss: 69.754 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1460/4776 | Loss: 34.448 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1470/4776 | Loss: 52.635 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1480/4776 | Loss: 54.121 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1490/4776 | Loss: 51.817 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1500/4776 | Loss: 50.296 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1510/4776 | Loss: 6.423 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1520/4776 | Loss: 97.692 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1530/4776 | Loss: 24.671 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1540/4776 | Loss: 3.797 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1550/4776 | Loss: 114.843 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1560/4776 | Loss: 22.961 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 1570/4776 | Loss: 56.419 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1580/4776 | Loss: 55.796 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1590/4776 | Loss: 56.560 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1600/4776 | Loss: 20.858 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1610/4776 | Loss: 29.445 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1620/4776 | Loss: 96.873 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1630/4776 | Loss: 59.472 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1640/4776 | Loss: 137.668 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1650/4776 | Loss: 39.750 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1660/4776 | Loss: 65.748 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1670/4776 | Loss: 122.917 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1680/4776 | Loss: 66.598 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1690/4776 | Loss: 187.043 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1700/4776 | Loss: 135.967 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 1710/4776 | Loss: 34.533 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1720/4776 | Loss: 46.222 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1730/4776 | Loss: 95.637 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1740/4776 | Loss: 93.981 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1750/4776 | Loss: 153.292 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 1760/4776 | Loss: 126.852 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 1770/4776 | Loss: 62.989 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1780/4776 | Loss: 33.694 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 1790/4776 | Loss: 61.681 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1800/4776 | Loss: 64.307 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1810/4776 | Loss: 102.017 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1820/4776 | Loss: 101.176 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1830/4776 | Loss: 98.588 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1840/4776 | Loss: 68.857 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1850/4776 | Loss: 112.344 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1860/4776 | Loss: 76.918 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1870/4776 | Loss: 134.734 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1880/4776 | Loss: 157.056 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 1890/4776 | Loss: 63.602 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1900/4776 | Loss: 124.376 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 1910/4776 | Loss: 43.423 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1920/4776 | Loss: 58.823 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1930/4776 | Loss: 106.156 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 1940/4776 | Loss: 33.561 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1950/4776 | Loss: 65.099 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1960/4776 | Loss: 54.892 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1970/4776 | Loss: 52.625 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 1980/4776 | Loss: 47.973 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 1990/4776 | Loss: 79.955 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2000/4776 | Loss: 40.836 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2010/4776 | Loss: 87.272 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2020/4776 | Loss: 94.947 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2030/4776 | Loss: 65.809 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2040/4776 | Loss: 101.308 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2050/4776 | Loss: 94.796 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2060/4776 | Loss: 38.941 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2070/4776 | Loss: 63.723 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2080/4776 | Loss: 20.671 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 2090/4776 | Loss: 84.949 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2100/4776 | Loss: 130.484 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2110/4776 | Loss: 132.707 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 2120/4776 | Loss: 91.455 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2130/4776 | Loss: 110.159 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2140/4776 | Loss: 84.910 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2150/4776 | Loss: 110.176 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2160/4776 | Loss: 181.716 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2170/4776 | Loss: 33.434 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2180/4776 | Loss: 65.456 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2190/4776 | Loss: 58.313 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2200/4776 | Loss: 38.996 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2210/4776 | Loss: 65.971 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2220/4776 | Loss: 76.199 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2230/4776 | Loss: 77.495 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2240/4776 | Loss: 61.912 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2250/4776 | Loss: 114.331 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2260/4776 | Loss: 102.210 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2270/4776 | Loss: 156.930 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 2280/4776 | Loss: 110.784 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 2290/4776 | Loss: 71.109 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2300/4776 | Loss: 78.042 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2310/4776 | Loss: 80.293 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2320/4776 | Loss: 87.386 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2330/4776 | Loss: 41.620 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2340/4776 | Loss: 72.358 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2350/4776 | Loss: 119.625 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2360/4776 | Loss: 92.522 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2370/4776 | Loss: 69.872 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2380/4776 | Loss: 101.779 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2390/4776 | Loss: 74.422 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2400/4776 | Loss: 41.388 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2410/4776 | Loss: 73.473 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2420/4776 | Loss: 98.424 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2430/4776 | Loss: 115.470 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2440/4776 | Loss: 31.434 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2450/4776 | Loss: 53.486 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2460/4776 | Loss: 109.726 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2470/4776 | Loss: 56.006 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2480/4776 | Loss: 102.657 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2490/4776 | Loss: 75.815 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2500/4776 | Loss: 71.450 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2510/4776 | Loss: 50.437 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2520/4776 | Loss: 36.625 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2530/4776 | Loss: 57.422 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2540/4776 | Loss: 39.425 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2550/4776 | Loss: 105.302 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2560/4776 | Loss: 25.630 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 2570/4776 | Loss: 98.385 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2580/4776 | Loss: 46.256 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2590/4776 | Loss: 68.192 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2600/4776 | Loss: 105.306 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2610/4776 | Loss: 47.101 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2620/4776 | Loss: 32.947 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2630/4776 | Loss: 45.382 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2640/4776 | Loss: 74.300 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2650/4776 | Loss: 65.484 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2660/4776 | Loss: 98.304 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2670/4776 | Loss: 86.247 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2680/4776 | Loss: 52.703 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2690/4776 | Loss: 94.089 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2700/4776 | Loss: 46.819 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2710/4776 | Loss: 58.031 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2720/4776 | Loss: 48.294 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2730/4776 | Loss: 116.427 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2740/4776 | Loss: 131.433 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 2750/4776 | Loss: 115.222 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2760/4776 | Loss: 60.713 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2770/4776 | Loss: 35.558 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2780/4776 | Loss: 42.242 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2790/4776 | Loss: 61.679 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2800/4776 | Loss: 26.831 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 2810/4776 | Loss: 101.233 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2820/4776 | Loss: 60.845 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 2830/4776 | Loss: 89.154 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2840/4776 | Loss: 35.435 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2850/4776 | Loss: 80.233 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2860/4776 | Loss: 83.808 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2870/4776 | Loss: 77.607 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2880/4776 | Loss: 12.898 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 2890/4776 | Loss: 69.750 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2900/4776 | Loss: 87.535 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2910/4776 | Loss: 118.499 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2920/4776 | Loss: 37.885 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2930/4776 | Loss: 44.950 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2940/4776 | Loss: 109.774 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2950/4776 | Loss: 72.386 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 2960/4776 | Loss: 59.989 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 2970/4776 | Loss: 88.786 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 2980/4776 | Loss: 131.377 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 2990/4776 | Loss: 87.047 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3000/4776 | Loss: 44.425 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3010/4776 | Loss: 121.815 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 3020/4776 | Loss: 185.284 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3030/4776 | Loss: 35.931 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3040/4776 | Loss: 68.034 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3050/4776 | Loss: 73.077 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3060/4776 | Loss: 32.060 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3070/4776 | Loss: 54.088 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3080/4776 | Loss: 31.834 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3090/4776 | Loss: 80.079 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3100/4776 | Loss: 76.669 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3110/4776 | Loss: 25.009 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3120/4776 | Loss: 33.152 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3130/4776 | Loss: 58.957 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3140/4776 | Loss: 19.162 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3150/4776 | Loss: 115.537 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3160/4776 | Loss: 133.745 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3170/4776 | Loss: 126.472 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 3180/4776 | Loss: 38.063 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3190/4776 | Loss: 57.749 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3200/4776 | Loss: 39.246 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3210/4776 | Loss: 25.858 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3220/4776 | Loss: 55.784 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3230/4776 | Loss: 34.646 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3240/4776 | Loss: 69.608 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3250/4776 | Loss: 62.083 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3260/4776 | Loss: 24.698 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3270/4776 | Loss: 116.856 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3280/4776 | Loss: 96.104 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3290/4776 | Loss: 49.331 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3300/4776 | Loss: 64.384 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3310/4776 | Loss: 97.332 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3320/4776 | Loss: 39.011 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3330/4776 | Loss: 53.871 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3340/4776 | Loss: 20.466 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3350/4776 | Loss: 97.583 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3360/4776 | Loss: 43.436 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3370/4776 | Loss: 109.348 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3380/4776 | Loss: 69.860 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3390/4776 | Loss: 62.091 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3400/4776 | Loss: 79.266 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3410/4776 | Loss: 86.612 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3420/4776 | Loss: 85.006 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3430/4776 | Loss: 104.061 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 3440/4776 | Loss: 44.352 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3450/4776 | Loss: 60.914 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3460/4776 | Loss: 107.491 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3470/4776 | Loss: 90.587 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3480/4776 | Loss: 100.372 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3490/4776 | Loss: 57.981 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3500/4776 | Loss: 83.635 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3510/4776 | Loss: 38.502 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3520/4776 | Loss: 72.879 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3530/4776 | Loss: 61.380 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3540/4776 | Loss: 25.590 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3550/4776 | Loss: 23.342 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3560/4776 | Loss: 60.067 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3570/4776 | Loss: 39.157 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3580/4776 | Loss: 64.142 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3590/4776 | Loss: 180.997 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 3600/4776 | Loss: 76.812 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3610/4776 | Loss: 73.145 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3620/4776 | Loss: 28.832 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3630/4776 | Loss: 124.648 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 3640/4776 | Loss: 63.838 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3650/4776 | Loss: 78.525 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3660/4776 | Loss: 41.504 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3670/4776 | Loss: 94.672 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3680/4776 | Loss: 114.460 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 3690/4776 | Loss: 61.083 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3700/4776 | Loss: 62.262 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3710/4776 | Loss: 42.582 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3720/4776 | Loss: 25.801 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3730/4776 | Loss: 51.057 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3740/4776 | Loss: 94.968 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3750/4776 | Loss: 50.641 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3760/4776 | Loss: 102.013 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3770/4776 | Loss: 93.912 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3780/4776 | Loss: 60.024 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3790/4776 | Loss: 30.719 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3800/4776 | Loss: 48.913 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3810/4776 | Loss: 66.301 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3820/4776 | Loss: 40.759 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3830/4776 | Loss: 45.662 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3840/4776 | Loss: 82.718 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3850/4776 | Loss: 77.070 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3860/4776 | Loss: 62.933 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 3870/4776 | Loss: 47.254 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3880/4776 | Loss: 43.615 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3890/4776 | Loss: 32.327 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3900/4776 | Loss: 42.980 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3910/4776 | Loss: 85.275 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3920/4776 | Loss: 33.568 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3930/4776 | Loss: 81.594 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3940/4776 | Loss: 73.853 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 3950/4776 | Loss: 39.578 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3960/4776 | Loss: 45.007 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 3970/4776 | Loss: 29.552 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 3980/4776 | Loss: 65.226 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 3990/4776 | Loss: 71.822 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4000/4776 | Loss: 83.801 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4010/4776 | Loss: 83.757 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4020/4776 | Loss: 25.880 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4030/4776 | Loss: 57.588 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4040/4776 | Loss: 31.904 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4050/4776 | Loss: 80.064 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4060/4776 | Loss: 63.045 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4070/4776 | Loss: 17.482 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 4080/4776 | Loss: 105.940 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4090/4776 | Loss: 58.052 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4100/4776 | Loss: 56.073 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4110/4776 | Loss: 9.492 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 4120/4776 | Loss: 65.127 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4130/4776 | Loss: 26.977 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4140/4776 | Loss: 33.084 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4150/4776 | Loss: 42.481 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4160/4776 | Loss: 85.367 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4170/4776 | Loss: 82.408 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4180/4776 | Loss: 48.676 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4190/4776 | Loss: 70.837 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4200/4776 | Loss: 64.726 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4210/4776 | Loss: 96.730 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4220/4776 | Loss: 110.483 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4230/4776 | Loss: 84.790 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4240/4776 | Loss: 42.406 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4250/4776 | Loss: 41.533 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4260/4776 | Loss: 67.012 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4270/4776 | Loss: 33.387 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4280/4776 | Loss: 65.834 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4290/4776 | Loss: 39.400 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4300/4776 | Loss: 58.216 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4310/4776 | Loss: 43.369 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4320/4776 | Loss: 58.292 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4330/4776 | Loss: 54.063 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4340/4776 | Loss: 51.627 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4350/4776 | Loss: 71.074 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4360/4776 | Loss: 46.130 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4370/4776 | Loss: 131.856 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4380/4776 | Loss: 62.033 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4390/4776 | Loss: 113.960 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4400/4776 | Loss: 27.034 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4410/4776 | Loss: 16.246 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4420/4776 | Loss: 40.893 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4430/4776 | Loss: 85.250 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4440/4776 | Loss: 55.980 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4450/4776 | Loss: 31.785 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4460/4776 | Loss: 79.716 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4470/4776 | Loss: 55.273 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4480/4776 | Loss: 44.323 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4490/4776 | Loss: 36.352 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4500/4776 | Loss: 47.002 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4510/4776 | Loss: 101.140 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4520/4776 | Loss: 59.365 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4530/4776 | Loss: 52.410 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4540/4776 | Loss: 88.729 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4550/4776 | Loss: 66.424 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4560/4776 | Loss: 70.501 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4570/4776 | Loss: 48.625 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4580/4776 | Loss: 76.436 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4590/4776 | Loss: 98.114 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4600/4776 | Loss: 173.191 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4610/4776 | Loss: 109.240 | Accuracy: 0.600\n",
      "[Epoch: 70/200] - Step: 4620/4776 | Loss: 59.163 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4630/4776 | Loss: 38.528 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4640/4776 | Loss: 73.173 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4650/4776 | Loss: 118.898 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4660/4776 | Loss: 79.200 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4670/4776 | Loss: 98.097 | Accuracy: 0.700\n",
      "[Epoch: 70/200] - Step: 4680/4776 | Loss: 25.194 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 4690/4776 | Loss: 70.457 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4700/4776 | Loss: 200.545 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4710/4776 | Loss: 94.738 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4720/4776 | Loss: 69.640 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4730/4776 | Loss: 15.812 | Accuracy: 1.000\n",
      "[Epoch: 70/200] - Step: 4740/4776 | Loss: 41.788 | Accuracy: 0.900\n",
      "[Epoch: 70/200] - Step: 4750/4776 | Loss: 52.225 | Accuracy: 0.800\n",
      "[Epoch: 70/200] - Step: 4760/4776 | Loss: 85.949 | Accuracy: 0.500\n",
      "[Epoch: 70/200] - Step: 4770/4776 | Loss: 69.001 | Accuracy: 0.800\n",
      "Accuracy:  0.19672131147540983\n",
      "[Epoch: 71/200] - Step: 10/4776 | Loss: 103.715 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 20/4776 | Loss: 31.859 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 30/4776 | Loss: 67.784 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 40/4776 | Loss: 35.840 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 50/4776 | Loss: 44.353 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 60/4776 | Loss: 81.466 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 70/4776 | Loss: 61.213 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 80/4776 | Loss: 11.583 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 90/4776 | Loss: 38.575 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 100/4776 | Loss: 124.533 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 110/4776 | Loss: 115.492 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 120/4776 | Loss: 27.121 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 130/4776 | Loss: 56.617 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 140/4776 | Loss: 51.313 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 150/4776 | Loss: 37.896 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 160/4776 | Loss: 51.212 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 170/4776 | Loss: 87.274 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 180/4776 | Loss: 147.453 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 190/4776 | Loss: 69.789 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 200/4776 | Loss: 83.631 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 210/4776 | Loss: 94.891 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 220/4776 | Loss: 88.707 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 230/4776 | Loss: 101.214 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 240/4776 | Loss: 57.981 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 250/4776 | Loss: 105.580 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 260/4776 | Loss: 34.669 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 270/4776 | Loss: 27.298 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 280/4776 | Loss: 72.526 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 290/4776 | Loss: 115.310 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 300/4776 | Loss: 44.705 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 310/4776 | Loss: 145.382 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 320/4776 | Loss: 100.026 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 330/4776 | Loss: 80.006 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 340/4776 | Loss: 80.998 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 350/4776 | Loss: 52.782 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 360/4776 | Loss: 149.210 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 370/4776 | Loss: 82.774 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 380/4776 | Loss: 67.238 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 390/4776 | Loss: 39.377 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 400/4776 | Loss: 120.434 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 410/4776 | Loss: 102.009 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 420/4776 | Loss: 75.024 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 430/4776 | Loss: 66.417 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 440/4776 | Loss: 56.345 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 450/4776 | Loss: 56.632 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 460/4776 | Loss: 48.167 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 470/4776 | Loss: 63.908 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 480/4776 | Loss: 38.559 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 490/4776 | Loss: 47.243 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 500/4776 | Loss: 26.326 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 510/4776 | Loss: 45.327 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 520/4776 | Loss: 76.543 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 530/4776 | Loss: 84.992 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 540/4776 | Loss: 8.623 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 550/4776 | Loss: 69.875 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 560/4776 | Loss: 107.840 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 570/4776 | Loss: 68.559 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 580/4776 | Loss: 85.808 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 590/4776 | Loss: 138.463 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 600/4776 | Loss: 79.304 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 610/4776 | Loss: 97.173 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 620/4776 | Loss: 51.324 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 630/4776 | Loss: 49.767 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 640/4776 | Loss: 54.182 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 650/4776 | Loss: 73.117 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 660/4776 | Loss: 66.018 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 670/4776 | Loss: 70.429 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 680/4776 | Loss: 139.212 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 690/4776 | Loss: 42.597 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 700/4776 | Loss: 136.803 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 710/4776 | Loss: 168.560 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 720/4776 | Loss: 37.839 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 730/4776 | Loss: 36.720 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 740/4776 | Loss: 69.178 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 750/4776 | Loss: 67.537 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 760/4776 | Loss: 62.030 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 770/4776 | Loss: 60.404 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 780/4776 | Loss: 47.772 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 790/4776 | Loss: 39.189 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 800/4776 | Loss: 54.769 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 810/4776 | Loss: 101.738 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 820/4776 | Loss: 82.779 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 830/4776 | Loss: 51.977 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 840/4776 | Loss: 35.747 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 850/4776 | Loss: 108.091 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 860/4776 | Loss: 96.251 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 870/4776 | Loss: 76.667 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 880/4776 | Loss: 51.834 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 890/4776 | Loss: 53.207 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 900/4776 | Loss: 59.337 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 910/4776 | Loss: 63.909 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 920/4776 | Loss: 115.774 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 930/4776 | Loss: 78.823 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 940/4776 | Loss: 27.605 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 950/4776 | Loss: 89.863 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 960/4776 | Loss: 101.360 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 970/4776 | Loss: 65.464 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 980/4776 | Loss: 106.093 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 990/4776 | Loss: 73.675 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1000/4776 | Loss: 69.514 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1010/4776 | Loss: 127.390 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1020/4776 | Loss: 122.211 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1030/4776 | Loss: 18.542 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1040/4776 | Loss: 71.166 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1050/4776 | Loss: 42.036 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1060/4776 | Loss: 128.189 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1070/4776 | Loss: 55.885 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1080/4776 | Loss: 57.310 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1090/4776 | Loss: 23.116 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1100/4776 | Loss: 29.202 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1110/4776 | Loss: 61.826 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1120/4776 | Loss: 52.807 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1130/4776 | Loss: 28.132 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1140/4776 | Loss: 35.293 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 1150/4776 | Loss: 41.752 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1160/4776 | Loss: 93.348 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1170/4776 | Loss: 61.921 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1180/4776 | Loss: 105.310 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1190/4776 | Loss: 73.022 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1200/4776 | Loss: 8.743 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 1210/4776 | Loss: 40.029 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1220/4776 | Loss: 83.736 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1230/4776 | Loss: 53.330 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1240/4776 | Loss: 53.496 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1250/4776 | Loss: 82.954 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1260/4776 | Loss: 66.940 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1270/4776 | Loss: 76.018 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1280/4776 | Loss: 44.657 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1290/4776 | Loss: 44.750 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1300/4776 | Loss: 56.163 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1310/4776 | Loss: 124.685 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1320/4776 | Loss: 57.434 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1330/4776 | Loss: 45.485 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1340/4776 | Loss: 93.137 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1350/4776 | Loss: 94.229 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1360/4776 | Loss: 124.440 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 1370/4776 | Loss: 106.939 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 1380/4776 | Loss: 51.058 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1390/4776 | Loss: 63.869 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1400/4776 | Loss: 47.557 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1410/4776 | Loss: 78.307 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1420/4776 | Loss: 137.061 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1430/4776 | Loss: 71.685 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1440/4776 | Loss: 66.416 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1450/4776 | Loss: 105.442 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1460/4776 | Loss: 120.584 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 1470/4776 | Loss: 39.956 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1480/4776 | Loss: 81.399 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1490/4776 | Loss: 64.096 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1500/4776 | Loss: 12.698 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1510/4776 | Loss: 58.913 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1520/4776 | Loss: 75.933 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1530/4776 | Loss: 38.786 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1540/4776 | Loss: 57.533 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1550/4776 | Loss: 42.659 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1560/4776 | Loss: 96.160 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1570/4776 | Loss: 37.896 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1580/4776 | Loss: 68.688 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1590/4776 | Loss: 85.878 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1600/4776 | Loss: 90.213 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1610/4776 | Loss: 127.316 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1620/4776 | Loss: 55.561 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1630/4776 | Loss: 35.060 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1640/4776 | Loss: 62.177 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1650/4776 | Loss: 62.454 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1660/4776 | Loss: 60.685 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1670/4776 | Loss: 35.681 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1680/4776 | Loss: 64.410 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1690/4776 | Loss: 30.530 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1700/4776 | Loss: 72.770 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1710/4776 | Loss: 20.873 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 1720/4776 | Loss: 91.565 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1730/4776 | Loss: 62.660 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1740/4776 | Loss: 75.063 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1750/4776 | Loss: 83.737 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1760/4776 | Loss: 52.829 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1770/4776 | Loss: 34.881 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1780/4776 | Loss: 32.660 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1790/4776 | Loss: 45.885 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1800/4776 | Loss: 62.036 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1810/4776 | Loss: 44.541 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 1820/4776 | Loss: 45.206 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1830/4776 | Loss: 46.235 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1840/4776 | Loss: 48.859 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1850/4776 | Loss: 117.154 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 1860/4776 | Loss: 74.548 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 1870/4776 | Loss: 47.711 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1880/4776 | Loss: 63.395 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1890/4776 | Loss: 70.497 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1900/4776 | Loss: 15.450 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 1910/4776 | Loss: 49.496 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 1920/4776 | Loss: 115.395 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 1930/4776 | Loss: 63.651 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1940/4776 | Loss: 46.383 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1950/4776 | Loss: 91.494 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1960/4776 | Loss: 49.157 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1970/4776 | Loss: 78.201 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 1980/4776 | Loss: 69.213 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 1990/4776 | Loss: 28.490 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2000/4776 | Loss: 42.662 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2010/4776 | Loss: 97.993 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2020/4776 | Loss: 29.286 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 2030/4776 | Loss: 87.773 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2040/4776 | Loss: 50.082 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2050/4776 | Loss: 78.329 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2060/4776 | Loss: 107.969 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2070/4776 | Loss: 101.678 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2080/4776 | Loss: 180.621 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2090/4776 | Loss: 127.830 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2100/4776 | Loss: 141.309 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2110/4776 | Loss: 116.061 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2120/4776 | Loss: 69.113 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2130/4776 | Loss: 104.137 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2140/4776 | Loss: 55.087 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2150/4776 | Loss: 49.907 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2160/4776 | Loss: 85.905 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2170/4776 | Loss: 79.874 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2180/4776 | Loss: 96.082 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2190/4776 | Loss: 56.979 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2200/4776 | Loss: 49.237 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2210/4776 | Loss: 47.649 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2220/4776 | Loss: 47.937 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2230/4776 | Loss: 82.503 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2240/4776 | Loss: 25.964 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2250/4776 | Loss: 78.454 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2260/4776 | Loss: 51.085 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2270/4776 | Loss: 79.864 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2280/4776 | Loss: 32.574 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2290/4776 | Loss: 96.762 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2300/4776 | Loss: 92.300 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2310/4776 | Loss: 24.655 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 2320/4776 | Loss: 53.698 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2330/4776 | Loss: 78.108 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2340/4776 | Loss: 49.057 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2350/4776 | Loss: 62.674 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2360/4776 | Loss: 97.451 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2370/4776 | Loss: 24.855 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2380/4776 | Loss: 71.770 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2390/4776 | Loss: 39.604 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2400/4776 | Loss: 38.077 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2410/4776 | Loss: 42.145 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2420/4776 | Loss: 81.506 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2430/4776 | Loss: 99.554 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2440/4776 | Loss: 32.270 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2450/4776 | Loss: 73.195 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2460/4776 | Loss: 54.628 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2470/4776 | Loss: 57.289 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2480/4776 | Loss: 102.252 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2490/4776 | Loss: 87.218 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2500/4776 | Loss: 95.821 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2510/4776 | Loss: 37.846 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2520/4776 | Loss: 50.267 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2530/4776 | Loss: 34.743 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2540/4776 | Loss: 43.425 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2550/4776 | Loss: 49.562 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2560/4776 | Loss: 77.482 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2570/4776 | Loss: 96.865 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2580/4776 | Loss: 36.162 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2590/4776 | Loss: 91.187 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2600/4776 | Loss: 96.891 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2610/4776 | Loss: 82.105 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2620/4776 | Loss: 258.577 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2630/4776 | Loss: 82.519 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2640/4776 | Loss: 124.327 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2650/4776 | Loss: 92.769 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2660/4776 | Loss: 61.572 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2670/4776 | Loss: 61.748 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2680/4776 | Loss: 52.490 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2690/4776 | Loss: 67.234 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2700/4776 | Loss: 14.510 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2710/4776 | Loss: 64.787 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2720/4776 | Loss: 53.613 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2730/4776 | Loss: 18.598 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2740/4776 | Loss: 36.531 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2750/4776 | Loss: 81.643 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2760/4776 | Loss: 39.099 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2770/4776 | Loss: 84.335 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2780/4776 | Loss: 65.106 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2790/4776 | Loss: 115.337 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2800/4776 | Loss: 34.439 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2810/4776 | Loss: 109.536 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2820/4776 | Loss: 115.200 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2830/4776 | Loss: 96.411 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 2840/4776 | Loss: 55.551 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2850/4776 | Loss: 61.089 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2860/4776 | Loss: 87.877 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2870/4776 | Loss: 127.862 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 2880/4776 | Loss: 61.570 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2890/4776 | Loss: 54.725 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2900/4776 | Loss: 66.316 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2910/4776 | Loss: 96.884 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 2920/4776 | Loss: 46.295 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2930/4776 | Loss: 110.713 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2940/4776 | Loss: 60.753 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2950/4776 | Loss: 265.284 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 2960/4776 | Loss: 54.203 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 2970/4776 | Loss: 56.565 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2980/4776 | Loss: 45.117 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 2990/4776 | Loss: 63.115 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3000/4776 | Loss: 55.289 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3010/4776 | Loss: 67.762 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3020/4776 | Loss: 108.783 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3030/4776 | Loss: 45.995 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3040/4776 | Loss: 34.824 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3050/4776 | Loss: 63.263 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3060/4776 | Loss: 57.760 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3070/4776 | Loss: 131.897 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 3080/4776 | Loss: 97.444 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3090/4776 | Loss: 95.210 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3100/4776 | Loss: 55.941 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3110/4776 | Loss: 71.927 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3120/4776 | Loss: 108.811 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3130/4776 | Loss: 141.319 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3140/4776 | Loss: 38.225 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3150/4776 | Loss: 63.444 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3160/4776 | Loss: 70.034 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3170/4776 | Loss: 39.917 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3180/4776 | Loss: 74.327 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3190/4776 | Loss: 57.905 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3200/4776 | Loss: 79.781 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3210/4776 | Loss: 74.147 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3220/4776 | Loss: 171.874 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 3230/4776 | Loss: 84.729 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3240/4776 | Loss: 48.183 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3250/4776 | Loss: 32.347 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3260/4776 | Loss: 24.293 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3270/4776 | Loss: 45.630 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3280/4776 | Loss: 39.415 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3290/4776 | Loss: 68.908 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3300/4776 | Loss: 74.186 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3310/4776 | Loss: 33.025 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3320/4776 | Loss: 69.086 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3330/4776 | Loss: 46.092 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3340/4776 | Loss: 99.071 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3350/4776 | Loss: 41.725 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3360/4776 | Loss: 51.644 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3370/4776 | Loss: 26.383 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 3380/4776 | Loss: 92.634 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3390/4776 | Loss: 63.285 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3400/4776 | Loss: 79.185 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3410/4776 | Loss: 77.304 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3420/4776 | Loss: 34.543 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3430/4776 | Loss: 39.918 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3440/4776 | Loss: 81.171 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3450/4776 | Loss: 48.312 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3460/4776 | Loss: 53.719 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3470/4776 | Loss: 62.375 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3480/4776 | Loss: 55.813 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3490/4776 | Loss: 100.836 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3500/4776 | Loss: 96.274 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3510/4776 | Loss: 161.565 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3520/4776 | Loss: 54.485 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3530/4776 | Loss: 93.189 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3540/4776 | Loss: 71.347 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3550/4776 | Loss: 85.078 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3560/4776 | Loss: 153.549 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 3570/4776 | Loss: 53.632 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3580/4776 | Loss: 43.650 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3590/4776 | Loss: 92.939 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3600/4776 | Loss: 67.595 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3610/4776 | Loss: 87.139 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3620/4776 | Loss: 68.180 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3630/4776 | Loss: 56.321 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3640/4776 | Loss: 85.499 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3650/4776 | Loss: 39.565 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3660/4776 | Loss: 28.342 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3670/4776 | Loss: 46.018 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3680/4776 | Loss: 66.709 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3690/4776 | Loss: 93.425 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3700/4776 | Loss: 104.079 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3710/4776 | Loss: 26.906 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3720/4776 | Loss: 57.689 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3730/4776 | Loss: 58.697 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3740/4776 | Loss: 53.395 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3750/4776 | Loss: 35.178 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3760/4776 | Loss: 84.970 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3770/4776 | Loss: 46.931 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3780/4776 | Loss: 40.772 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3790/4776 | Loss: 68.985 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3800/4776 | Loss: 82.544 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3810/4776 | Loss: 60.980 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3820/4776 | Loss: 123.498 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3830/4776 | Loss: 67.216 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3840/4776 | Loss: 61.210 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3850/4776 | Loss: 91.383 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3860/4776 | Loss: 59.040 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3870/4776 | Loss: 158.607 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 3880/4776 | Loss: 22.475 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 3890/4776 | Loss: 71.377 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3900/4776 | Loss: 129.177 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3910/4776 | Loss: 65.943 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 3920/4776 | Loss: 44.399 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 3930/4776 | Loss: 90.915 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3940/4776 | Loss: 61.311 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 3950/4776 | Loss: 93.853 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 3960/4776 | Loss: 129.074 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3970/4776 | Loss: 152.602 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 3980/4776 | Loss: 110.037 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 3990/4776 | Loss: 93.077 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4000/4776 | Loss: 64.623 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4010/4776 | Loss: 92.335 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4020/4776 | Loss: 42.690 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4030/4776 | Loss: 113.151 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4040/4776 | Loss: 68.414 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4050/4776 | Loss: 83.020 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4060/4776 | Loss: 109.884 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4070/4776 | Loss: 58.722 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4080/4776 | Loss: 64.517 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4090/4776 | Loss: 65.906 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4100/4776 | Loss: 64.711 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4110/4776 | Loss: 56.424 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4120/4776 | Loss: 169.551 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4130/4776 | Loss: 56.366 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4140/4776 | Loss: 64.046 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4150/4776 | Loss: 55.414 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4160/4776 | Loss: 70.855 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4170/4776 | Loss: 43.923 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4180/4776 | Loss: 43.357 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4190/4776 | Loss: 24.170 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 4200/4776 | Loss: 45.965 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4210/4776 | Loss: 30.427 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4220/4776 | Loss: 103.379 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4230/4776 | Loss: 31.989 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4240/4776 | Loss: 29.935 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4250/4776 | Loss: 27.847 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4260/4776 | Loss: 70.682 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4270/4776 | Loss: 58.135 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4280/4776 | Loss: 73.084 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4290/4776 | Loss: 100.853 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4300/4776 | Loss: 44.651 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4310/4776 | Loss: 64.192 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4320/4776 | Loss: 118.232 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4330/4776 | Loss: 113.039 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4340/4776 | Loss: 44.475 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4350/4776 | Loss: 75.875 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4360/4776 | Loss: 31.704 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4370/4776 | Loss: 104.399 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 4380/4776 | Loss: 66.498 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4390/4776 | Loss: 77.125 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4400/4776 | Loss: 8.823 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 4410/4776 | Loss: 96.283 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4420/4776 | Loss: 160.274 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 4430/4776 | Loss: 27.795 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4440/4776 | Loss: 70.085 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4450/4776 | Loss: 206.008 | Accuracy: 0.400\n",
      "[Epoch: 71/200] - Step: 4460/4776 | Loss: 45.960 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4470/4776 | Loss: 37.858 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4480/4776 | Loss: 61.951 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4490/4776 | Loss: 68.916 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4500/4776 | Loss: 47.048 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4510/4776 | Loss: 40.285 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4520/4776 | Loss: 53.318 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4530/4776 | Loss: 59.152 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4540/4776 | Loss: 66.533 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4550/4776 | Loss: 77.647 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4560/4776 | Loss: 40.867 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4570/4776 | Loss: 43.723 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4580/4776 | Loss: 101.646 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4590/4776 | Loss: 44.238 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4600/4776 | Loss: 66.538 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4610/4776 | Loss: 75.113 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4620/4776 | Loss: 48.717 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4630/4776 | Loss: 68.289 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4640/4776 | Loss: 64.428 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4650/4776 | Loss: 53.485 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4660/4776 | Loss: 114.096 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4670/4776 | Loss: 26.405 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4680/4776 | Loss: 104.838 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4690/4776 | Loss: 84.853 | Accuracy: 0.600\n",
      "[Epoch: 71/200] - Step: 4700/4776 | Loss: 45.846 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4710/4776 | Loss: 53.204 | Accuracy: 0.800\n",
      "[Epoch: 71/200] - Step: 4720/4776 | Loss: 21.941 | Accuracy: 1.000\n",
      "[Epoch: 71/200] - Step: 4730/4776 | Loss: 81.608 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4740/4776 | Loss: 54.889 | Accuracy: 0.900\n",
      "[Epoch: 71/200] - Step: 4750/4776 | Loss: 163.594 | Accuracy: 0.500\n",
      "[Epoch: 71/200] - Step: 4760/4776 | Loss: 62.047 | Accuracy: 0.700\n",
      "[Epoch: 71/200] - Step: 4770/4776 | Loss: 66.499 | Accuracy: 0.800\n",
      "Accuracy:  0.20327868852459016\n",
      "[Epoch: 72/200] - Step: 10/4776 | Loss: 38.799 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 20/4776 | Loss: 82.588 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 30/4776 | Loss: 43.895 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 40/4776 | Loss: 47.390 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 50/4776 | Loss: 49.846 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 60/4776 | Loss: 38.830 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 70/4776 | Loss: 46.407 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 80/4776 | Loss: 96.494 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 90/4776 | Loss: 73.477 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 100/4776 | Loss: 47.387 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 110/4776 | Loss: 155.021 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 120/4776 | Loss: 45.091 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 130/4776 | Loss: 105.090 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 140/4776 | Loss: 31.018 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 150/4776 | Loss: 24.065 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 160/4776 | Loss: 83.799 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 170/4776 | Loss: 38.247 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 180/4776 | Loss: 114.119 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 190/4776 | Loss: 31.527 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 200/4776 | Loss: 47.318 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 210/4776 | Loss: 44.758 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 220/4776 | Loss: 21.875 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 230/4776 | Loss: 21.196 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 240/4776 | Loss: 49.223 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 250/4776 | Loss: 93.305 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 260/4776 | Loss: 125.480 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 270/4776 | Loss: 119.426 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 280/4776 | Loss: 99.238 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 290/4776 | Loss: 55.464 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 300/4776 | Loss: 67.983 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 310/4776 | Loss: 73.786 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 320/4776 | Loss: 71.810 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 330/4776 | Loss: 15.957 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 340/4776 | Loss: 48.412 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 350/4776 | Loss: 53.664 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 360/4776 | Loss: 83.264 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 370/4776 | Loss: 13.181 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 380/4776 | Loss: 75.009 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 390/4776 | Loss: 64.203 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 400/4776 | Loss: 126.073 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 410/4776 | Loss: 68.355 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 420/4776 | Loss: 125.703 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 430/4776 | Loss: 54.633 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 440/4776 | Loss: 81.219 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 450/4776 | Loss: 65.766 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 460/4776 | Loss: 67.227 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 470/4776 | Loss: 100.078 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 480/4776 | Loss: 66.509 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 490/4776 | Loss: 46.121 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 500/4776 | Loss: 42.034 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 510/4776 | Loss: 65.676 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 520/4776 | Loss: 116.360 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 530/4776 | Loss: 50.336 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 540/4776 | Loss: 60.451 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 550/4776 | Loss: 93.873 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 560/4776 | Loss: 75.700 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 570/4776 | Loss: 67.379 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 580/4776 | Loss: 108.370 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 590/4776 | Loss: 137.230 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 600/4776 | Loss: 72.871 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 610/4776 | Loss: 123.252 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 620/4776 | Loss: 67.748 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 630/4776 | Loss: 91.124 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 640/4776 | Loss: 57.626 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 650/4776 | Loss: 97.878 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 660/4776 | Loss: 73.213 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 670/4776 | Loss: 66.217 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 680/4776 | Loss: 63.637 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 690/4776 | Loss: 74.722 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 700/4776 | Loss: 119.209 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 710/4776 | Loss: 27.228 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 720/4776 | Loss: 64.780 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 730/4776 | Loss: 56.577 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 740/4776 | Loss: 82.764 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 750/4776 | Loss: 26.731 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 760/4776 | Loss: 63.980 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 770/4776 | Loss: 17.433 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 780/4776 | Loss: 68.773 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 790/4776 | Loss: 80.204 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 800/4776 | Loss: 63.283 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 810/4776 | Loss: 37.689 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 820/4776 | Loss: 33.720 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 830/4776 | Loss: 56.939 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 840/4776 | Loss: 43.396 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 850/4776 | Loss: 43.910 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 860/4776 | Loss: 11.436 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 870/4776 | Loss: 85.397 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 880/4776 | Loss: 76.070 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 890/4776 | Loss: 51.077 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 900/4776 | Loss: 68.345 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 910/4776 | Loss: 38.077 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 920/4776 | Loss: 62.582 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 930/4776 | Loss: 74.814 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 940/4776 | Loss: 99.684 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 950/4776 | Loss: 70.900 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 960/4776 | Loss: 125.465 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 970/4776 | Loss: 49.793 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 980/4776 | Loss: 63.746 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 990/4776 | Loss: 85.737 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1000/4776 | Loss: 120.548 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 1010/4776 | Loss: 32.479 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1020/4776 | Loss: 68.811 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1030/4776 | Loss: 82.126 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1040/4776 | Loss: 60.815 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1050/4776 | Loss: 46.443 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1060/4776 | Loss: 42.078 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1070/4776 | Loss: 56.061 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1080/4776 | Loss: 51.076 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1090/4776 | Loss: 68.849 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1100/4776 | Loss: 32.615 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1110/4776 | Loss: 33.382 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1120/4776 | Loss: 45.596 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1130/4776 | Loss: 71.147 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1140/4776 | Loss: 108.950 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1150/4776 | Loss: 73.073 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1160/4776 | Loss: 18.183 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1170/4776 | Loss: 20.281 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1180/4776 | Loss: 53.799 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1190/4776 | Loss: 55.759 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1200/4776 | Loss: 67.285 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1210/4776 | Loss: 84.823 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1220/4776 | Loss: 62.977 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1230/4776 | Loss: 47.955 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1240/4776 | Loss: 82.498 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1250/4776 | Loss: 18.420 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1260/4776 | Loss: 105.586 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1270/4776 | Loss: 33.111 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1280/4776 | Loss: 103.178 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1290/4776 | Loss: 79.862 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1300/4776 | Loss: 25.213 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1310/4776 | Loss: 91.053 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1320/4776 | Loss: 66.174 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1330/4776 | Loss: 64.463 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1340/4776 | Loss: 56.647 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1350/4776 | Loss: 85.262 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1360/4776 | Loss: 109.784 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 1370/4776 | Loss: 70.260 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1380/4776 | Loss: 51.887 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1390/4776 | Loss: 41.317 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1400/4776 | Loss: 22.388 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1410/4776 | Loss: 52.208 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1420/4776 | Loss: 39.823 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1430/4776 | Loss: 53.306 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1440/4776 | Loss: 67.037 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1450/4776 | Loss: 134.810 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1460/4776 | Loss: 57.567 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1470/4776 | Loss: 26.844 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1480/4776 | Loss: 58.385 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1490/4776 | Loss: 111.652 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 1500/4776 | Loss: 76.226 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1510/4776 | Loss: 34.166 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1520/4776 | Loss: 37.364 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1530/4776 | Loss: 94.004 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1540/4776 | Loss: 59.761 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1550/4776 | Loss: 27.716 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1560/4776 | Loss: 45.718 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1570/4776 | Loss: 42.026 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1580/4776 | Loss: 90.548 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1590/4776 | Loss: 38.251 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1600/4776 | Loss: 76.957 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1610/4776 | Loss: 23.774 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1620/4776 | Loss: 43.565 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1630/4776 | Loss: 61.671 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1640/4776 | Loss: 32.510 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1650/4776 | Loss: 44.199 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1660/4776 | Loss: 72.816 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1670/4776 | Loss: 93.478 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1680/4776 | Loss: 74.010 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1690/4776 | Loss: 93.201 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1700/4776 | Loss: 92.859 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1710/4776 | Loss: 43.741 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1720/4776 | Loss: 58.261 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1730/4776 | Loss: 68.357 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1740/4776 | Loss: 79.645 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1750/4776 | Loss: 89.796 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1760/4776 | Loss: 141.386 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 1770/4776 | Loss: 44.775 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1780/4776 | Loss: 94.004 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 1790/4776 | Loss: 26.868 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1800/4776 | Loss: 26.661 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1810/4776 | Loss: 89.221 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1820/4776 | Loss: 27.829 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1830/4776 | Loss: 82.781 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1840/4776 | Loss: 65.442 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1850/4776 | Loss: 84.684 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1860/4776 | Loss: 159.577 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 1870/4776 | Loss: 59.954 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1880/4776 | Loss: 40.117 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1890/4776 | Loss: 84.607 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1900/4776 | Loss: 73.564 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1910/4776 | Loss: 104.963 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 1920/4776 | Loss: 70.576 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1930/4776 | Loss: 56.435 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1940/4776 | Loss: 24.377 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1950/4776 | Loss: 101.083 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 1960/4776 | Loss: 43.211 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 1970/4776 | Loss: 22.458 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 1980/4776 | Loss: 32.446 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 1990/4776 | Loss: 119.890 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2000/4776 | Loss: 27.303 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2010/4776 | Loss: 94.874 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2020/4776 | Loss: 57.208 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2030/4776 | Loss: 84.964 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2040/4776 | Loss: 41.831 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2050/4776 | Loss: 105.401 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2060/4776 | Loss: 59.370 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2070/4776 | Loss: 92.101 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2080/4776 | Loss: 85.576 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2090/4776 | Loss: 78.955 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2100/4776 | Loss: 93.614 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2110/4776 | Loss: 50.379 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2120/4776 | Loss: 78.727 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2130/4776 | Loss: 80.319 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2140/4776 | Loss: 77.236 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2150/4776 | Loss: 20.850 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2160/4776 | Loss: 57.192 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2170/4776 | Loss: 84.232 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2180/4776 | Loss: 134.994 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2190/4776 | Loss: 24.863 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2200/4776 | Loss: 15.536 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2210/4776 | Loss: 31.150 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2220/4776 | Loss: 122.056 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2230/4776 | Loss: 22.512 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2240/4776 | Loss: 45.315 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2250/4776 | Loss: 23.307 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2260/4776 | Loss: 44.019 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2270/4776 | Loss: 62.954 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2280/4776 | Loss: 48.668 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2290/4776 | Loss: 49.228 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2300/4776 | Loss: 138.603 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2310/4776 | Loss: 74.727 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2320/4776 | Loss: 16.313 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2330/4776 | Loss: 111.288 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2340/4776 | Loss: 66.313 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2350/4776 | Loss: 51.959 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2360/4776 | Loss: 54.641 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2370/4776 | Loss: 124.985 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2380/4776 | Loss: 54.017 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2390/4776 | Loss: 21.625 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2400/4776 | Loss: 63.155 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2410/4776 | Loss: 64.335 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2420/4776 | Loss: 27.815 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2430/4776 | Loss: 71.758 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2440/4776 | Loss: 28.144 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2450/4776 | Loss: 53.912 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2460/4776 | Loss: 114.797 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2470/4776 | Loss: 68.190 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2480/4776 | Loss: 30.004 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2490/4776 | Loss: 210.280 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2500/4776 | Loss: 58.494 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2510/4776 | Loss: 85.219 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2520/4776 | Loss: 122.111 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 2530/4776 | Loss: 60.633 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2540/4776 | Loss: 98.912 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2550/4776 | Loss: 35.788 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2560/4776 | Loss: 47.205 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2570/4776 | Loss: 82.163 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2580/4776 | Loss: 27.478 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2590/4776 | Loss: 64.527 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2600/4776 | Loss: 77.839 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2610/4776 | Loss: 97.672 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2620/4776 | Loss: 47.317 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2630/4776 | Loss: 53.331 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2640/4776 | Loss: 58.843 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2650/4776 | Loss: 84.621 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2660/4776 | Loss: 70.508 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2670/4776 | Loss: 118.023 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2680/4776 | Loss: 90.494 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2690/4776 | Loss: 42.814 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2700/4776 | Loss: 136.269 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 2710/4776 | Loss: 76.076 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2720/4776 | Loss: 76.743 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2730/4776 | Loss: 28.224 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2740/4776 | Loss: 65.841 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2750/4776 | Loss: 56.124 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2760/4776 | Loss: 71.698 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2770/4776 | Loss: 75.870 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2780/4776 | Loss: 28.159 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2790/4776 | Loss: 23.730 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2800/4776 | Loss: 33.647 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2810/4776 | Loss: 77.512 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2820/4776 | Loss: 93.003 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2830/4776 | Loss: 93.620 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2840/4776 | Loss: 80.296 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2850/4776 | Loss: 33.381 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2860/4776 | Loss: 89.993 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 2870/4776 | Loss: 72.439 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2880/4776 | Loss: 47.842 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2890/4776 | Loss: 85.811 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2900/4776 | Loss: 39.789 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 2910/4776 | Loss: 45.228 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 2920/4776 | Loss: 57.056 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2930/4776 | Loss: 68.785 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2940/4776 | Loss: 54.690 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2950/4776 | Loss: 80.397 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2960/4776 | Loss: 23.350 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 2970/4776 | Loss: 85.291 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 2980/4776 | Loss: 50.197 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 2990/4776 | Loss: 89.604 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3000/4776 | Loss: 34.176 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3010/4776 | Loss: 42.422 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3020/4776 | Loss: 91.350 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3030/4776 | Loss: 68.396 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3040/4776 | Loss: 58.903 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3050/4776 | Loss: 45.617 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3060/4776 | Loss: 46.466 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3070/4776 | Loss: 55.886 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3080/4776 | Loss: 50.255 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3090/4776 | Loss: 38.759 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3100/4776 | Loss: 62.943 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3110/4776 | Loss: 58.627 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3120/4776 | Loss: 56.532 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3130/4776 | Loss: 29.049 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3140/4776 | Loss: 89.685 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3150/4776 | Loss: 42.850 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3160/4776 | Loss: 74.069 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3170/4776 | Loss: 84.837 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3180/4776 | Loss: 71.964 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3190/4776 | Loss: 152.954 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 3200/4776 | Loss: 69.833 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3210/4776 | Loss: 51.237 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3220/4776 | Loss: 97.694 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3230/4776 | Loss: 138.060 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3240/4776 | Loss: 66.991 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3250/4776 | Loss: 86.088 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3260/4776 | Loss: 100.915 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3270/4776 | Loss: 64.084 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3280/4776 | Loss: 71.496 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3290/4776 | Loss: 43.193 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3300/4776 | Loss: 59.488 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3310/4776 | Loss: 87.297 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3320/4776 | Loss: 51.077 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3330/4776 | Loss: 78.035 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3340/4776 | Loss: 52.522 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3350/4776 | Loss: 77.027 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3360/4776 | Loss: 99.943 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3370/4776 | Loss: 124.093 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 3380/4776 | Loss: 82.963 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3390/4776 | Loss: 46.591 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3400/4776 | Loss: 55.738 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3410/4776 | Loss: 101.690 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3420/4776 | Loss: 64.478 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3430/4776 | Loss: 105.103 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3440/4776 | Loss: 47.220 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3450/4776 | Loss: 52.036 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3460/4776 | Loss: 78.991 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3470/4776 | Loss: 150.038 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3480/4776 | Loss: 155.756 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 3490/4776 | Loss: 100.137 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3500/4776 | Loss: 74.921 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3510/4776 | Loss: 42.445 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 3520/4776 | Loss: 75.338 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3530/4776 | Loss: 56.168 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3540/4776 | Loss: 50.416 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3550/4776 | Loss: 92.390 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3560/4776 | Loss: 61.379 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3570/4776 | Loss: 150.143 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 3580/4776 | Loss: 76.059 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3590/4776 | Loss: 46.033 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3600/4776 | Loss: 140.778 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3610/4776 | Loss: 61.991 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3620/4776 | Loss: 130.875 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3630/4776 | Loss: 70.725 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3640/4776 | Loss: 115.562 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 3650/4776 | Loss: 78.475 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3660/4776 | Loss: 47.446 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3670/4776 | Loss: 90.525 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3680/4776 | Loss: 55.145 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3690/4776 | Loss: 78.007 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3700/4776 | Loss: 75.386 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3710/4776 | Loss: 103.499 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3720/4776 | Loss: 44.159 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3730/4776 | Loss: 33.486 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3740/4776 | Loss: 97.648 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3750/4776 | Loss: 92.989 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 3760/4776 | Loss: 121.746 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3770/4776 | Loss: 83.378 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3780/4776 | Loss: 39.472 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3790/4776 | Loss: 58.969 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3800/4776 | Loss: 84.987 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3810/4776 | Loss: 22.156 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3820/4776 | Loss: 61.725 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3830/4776 | Loss: 61.453 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3840/4776 | Loss: 50.491 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3850/4776 | Loss: 80.856 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3860/4776 | Loss: 89.341 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 3870/4776 | Loss: 80.762 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 3880/4776 | Loss: 76.743 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3890/4776 | Loss: 33.349 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3900/4776 | Loss: 32.556 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3910/4776 | Loss: 41.102 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3920/4776 | Loss: 48.071 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3930/4776 | Loss: 51.718 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3940/4776 | Loss: 53.835 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3950/4776 | Loss: 47.489 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3960/4776 | Loss: 29.849 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3970/4776 | Loss: 74.359 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 3980/4776 | Loss: 31.246 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 3990/4776 | Loss: 76.868 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4000/4776 | Loss: 55.590 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4010/4776 | Loss: 99.534 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 4020/4776 | Loss: 67.401 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4030/4776 | Loss: 28.951 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4040/4776 | Loss: 59.882 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4050/4776 | Loss: 186.902 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4060/4776 | Loss: 79.937 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4070/4776 | Loss: 70.272 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4080/4776 | Loss: 63.765 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4090/4776 | Loss: 161.409 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 4100/4776 | Loss: 71.879 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4110/4776 | Loss: 168.590 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 4120/4776 | Loss: 58.339 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4130/4776 | Loss: 85.613 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4140/4776 | Loss: 82.421 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4150/4776 | Loss: 187.949 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4160/4776 | Loss: 56.269 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4170/4776 | Loss: 59.989 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4180/4776 | Loss: 106.531 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4190/4776 | Loss: 93.809 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4200/4776 | Loss: 52.543 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4210/4776 | Loss: 22.946 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4220/4776 | Loss: 45.270 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4230/4776 | Loss: 33.861 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4240/4776 | Loss: 32.750 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4250/4776 | Loss: 38.633 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4260/4776 | Loss: 54.210 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4270/4776 | Loss: 69.313 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4280/4776 | Loss: 70.294 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4290/4776 | Loss: 91.162 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4300/4776 | Loss: 60.641 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4310/4776 | Loss: 119.864 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4320/4776 | Loss: 60.500 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4330/4776 | Loss: 51.449 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4340/4776 | Loss: 96.925 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4350/4776 | Loss: 61.660 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4360/4776 | Loss: 73.114 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4370/4776 | Loss: 101.333 | Accuracy: 0.400\n",
      "[Epoch: 72/200] - Step: 4380/4776 | Loss: 44.219 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4390/4776 | Loss: 81.085 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4400/4776 | Loss: 78.998 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4410/4776 | Loss: 60.743 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4420/4776 | Loss: 76.068 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4430/4776 | Loss: 103.524 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4440/4776 | Loss: 60.881 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4450/4776 | Loss: 58.455 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4460/4776 | Loss: 50.158 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4470/4776 | Loss: 16.497 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4480/4776 | Loss: 47.318 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4490/4776 | Loss: 29.180 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 4500/4776 | Loss: 72.732 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4510/4776 | Loss: 68.680 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4520/4776 | Loss: 71.727 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4530/4776 | Loss: 91.285 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4540/4776 | Loss: 54.305 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4550/4776 | Loss: 32.180 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 4560/4776 | Loss: 70.492 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4570/4776 | Loss: 24.477 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 4580/4776 | Loss: 40.263 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4590/4776 | Loss: 67.903 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4600/4776 | Loss: 95.296 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4610/4776 | Loss: 50.883 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4620/4776 | Loss: 56.707 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4630/4776 | Loss: 63.607 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4640/4776 | Loss: 77.173 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4650/4776 | Loss: 27.161 | Accuracy: 0.900\n",
      "[Epoch: 72/200] - Step: 4660/4776 | Loss: 22.091 | Accuracy: 1.000\n",
      "[Epoch: 72/200] - Step: 4670/4776 | Loss: 65.520 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4680/4776 | Loss: 60.774 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4690/4776 | Loss: 60.009 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4700/4776 | Loss: 91.174 | Accuracy: 0.800\n",
      "[Epoch: 72/200] - Step: 4710/4776 | Loss: 72.587 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4720/4776 | Loss: 76.675 | Accuracy: 0.500\n",
      "[Epoch: 72/200] - Step: 4730/4776 | Loss: 54.755 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4740/4776 | Loss: 143.064 | Accuracy: 0.600\n",
      "[Epoch: 72/200] - Step: 4750/4776 | Loss: 64.821 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4760/4776 | Loss: 58.202 | Accuracy: 0.700\n",
      "[Epoch: 72/200] - Step: 4770/4776 | Loss: 52.466 | Accuracy: 0.800\n",
      "Accuracy:  0.22459016393442624\n",
      "[Epoch: 73/200] - Step: 10/4776 | Loss: 69.298 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 20/4776 | Loss: 37.039 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 30/4776 | Loss: 43.259 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 40/4776 | Loss: 85.169 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 50/4776 | Loss: 55.459 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 60/4776 | Loss: 20.347 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 70/4776 | Loss: 55.094 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 80/4776 | Loss: 11.515 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 90/4776 | Loss: 29.636 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 100/4776 | Loss: 40.600 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 110/4776 | Loss: 51.194 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 120/4776 | Loss: 29.086 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 130/4776 | Loss: 28.602 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 140/4776 | Loss: 80.401 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 150/4776 | Loss: 105.352 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 160/4776 | Loss: 31.783 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 170/4776 | Loss: 46.538 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 180/4776 | Loss: 93.408 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 190/4776 | Loss: 133.452 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 200/4776 | Loss: 77.917 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 210/4776 | Loss: 101.650 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 220/4776 | Loss: 144.139 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 230/4776 | Loss: 87.981 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 240/4776 | Loss: 112.809 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 250/4776 | Loss: 54.000 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 260/4776 | Loss: 43.397 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 270/4776 | Loss: 108.696 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 280/4776 | Loss: 53.017 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 290/4776 | Loss: 67.219 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 300/4776 | Loss: 43.101 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 310/4776 | Loss: 68.032 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 320/4776 | Loss: 95.249 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 330/4776 | Loss: 57.469 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 340/4776 | Loss: 33.077 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 350/4776 | Loss: 46.019 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 360/4776 | Loss: 92.838 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 370/4776 | Loss: 37.608 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 380/4776 | Loss: 40.898 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 390/4776 | Loss: 40.158 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 400/4776 | Loss: 76.389 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 410/4776 | Loss: 77.607 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 420/4776 | Loss: 36.601 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 430/4776 | Loss: 43.540 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 440/4776 | Loss: 55.096 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 450/4776 | Loss: 41.739 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 460/4776 | Loss: 5.127 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 470/4776 | Loss: 48.612 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 480/4776 | Loss: 29.800 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 490/4776 | Loss: 57.612 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 500/4776 | Loss: 72.593 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 510/4776 | Loss: 26.506 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 520/4776 | Loss: 42.651 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 530/4776 | Loss: 50.305 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 540/4776 | Loss: 23.174 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 550/4776 | Loss: 29.211 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 560/4776 | Loss: 33.825 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 570/4776 | Loss: 85.285 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 580/4776 | Loss: 206.903 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 590/4776 | Loss: 63.806 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 600/4776 | Loss: 57.353 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 610/4776 | Loss: 67.691 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 620/4776 | Loss: 27.074 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 630/4776 | Loss: 78.910 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 640/4776 | Loss: 71.657 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 650/4776 | Loss: 66.859 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 660/4776 | Loss: 75.136 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 670/4776 | Loss: 106.752 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 680/4776 | Loss: 64.451 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 690/4776 | Loss: 39.863 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 700/4776 | Loss: 20.497 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 710/4776 | Loss: 78.232 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 720/4776 | Loss: 79.150 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 730/4776 | Loss: 40.846 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 740/4776 | Loss: 60.925 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 750/4776 | Loss: 28.288 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 760/4776 | Loss: 10.560 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 770/4776 | Loss: 45.733 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 780/4776 | Loss: 40.932 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 790/4776 | Loss: 82.233 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 800/4776 | Loss: 47.010 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 810/4776 | Loss: 79.834 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 820/4776 | Loss: 128.611 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 830/4776 | Loss: 49.400 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 840/4776 | Loss: 67.115 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 850/4776 | Loss: 58.275 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 860/4776 | Loss: 41.037 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 870/4776 | Loss: 47.591 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 880/4776 | Loss: 149.405 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 890/4776 | Loss: 74.717 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 900/4776 | Loss: 70.101 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 910/4776 | Loss: 37.161 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 920/4776 | Loss: 64.118 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 930/4776 | Loss: 158.157 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 940/4776 | Loss: 76.824 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 950/4776 | Loss: 40.237 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 960/4776 | Loss: 41.963 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 970/4776 | Loss: 48.501 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 980/4776 | Loss: 28.929 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 990/4776 | Loss: 112.240 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1000/4776 | Loss: 66.976 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1010/4776 | Loss: 20.292 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1020/4776 | Loss: 63.999 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1030/4776 | Loss: 10.832 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1040/4776 | Loss: 107.371 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1050/4776 | Loss: 45.964 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1060/4776 | Loss: 65.319 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1070/4776 | Loss: 37.568 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1080/4776 | Loss: 54.392 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1090/4776 | Loss: 112.051 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 1100/4776 | Loss: 93.192 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1110/4776 | Loss: 35.236 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1120/4776 | Loss: 79.410 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1130/4776 | Loss: 88.280 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1140/4776 | Loss: 69.473 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1150/4776 | Loss: 17.927 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1160/4776 | Loss: 19.463 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1170/4776 | Loss: 21.067 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1180/4776 | Loss: 48.149 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1190/4776 | Loss: 38.184 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1200/4776 | Loss: 74.535 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1210/4776 | Loss: 73.669 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1220/4776 | Loss: 56.361 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1230/4776 | Loss: 115.764 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1240/4776 | Loss: 26.185 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1250/4776 | Loss: 7.760 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1260/4776 | Loss: 81.983 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1270/4776 | Loss: 33.946 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1280/4776 | Loss: 66.829 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1290/4776 | Loss: 64.546 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1300/4776 | Loss: 41.309 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1310/4776 | Loss: 67.467 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1320/4776 | Loss: 39.102 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1330/4776 | Loss: 16.590 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1340/4776 | Loss: 105.746 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1350/4776 | Loss: 38.821 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1360/4776 | Loss: 33.428 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1370/4776 | Loss: 59.570 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1380/4776 | Loss: 61.620 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1390/4776 | Loss: 69.197 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1400/4776 | Loss: 63.565 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1410/4776 | Loss: 69.822 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1420/4776 | Loss: 149.107 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 1430/4776 | Loss: 169.526 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1440/4776 | Loss: 43.606 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1450/4776 | Loss: 89.265 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1460/4776 | Loss: 87.909 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1470/4776 | Loss: 81.071 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 1480/4776 | Loss: 56.077 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1490/4776 | Loss: 171.191 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 1500/4776 | Loss: 40.713 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1510/4776 | Loss: 159.556 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1520/4776 | Loss: 57.996 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1530/4776 | Loss: 60.811 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1540/4776 | Loss: 96.339 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1550/4776 | Loss: 85.532 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1560/4776 | Loss: 26.522 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1570/4776 | Loss: 65.485 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1580/4776 | Loss: 46.302 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1590/4776 | Loss: 78.111 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1600/4776 | Loss: 76.593 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1610/4776 | Loss: 79.828 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1620/4776 | Loss: 83.236 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1630/4776 | Loss: 68.470 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1640/4776 | Loss: 178.721 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1650/4776 | Loss: 94.773 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1660/4776 | Loss: 53.316 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1670/4776 | Loss: 107.615 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1680/4776 | Loss: 81.843 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1690/4776 | Loss: 85.594 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1700/4776 | Loss: 63.144 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1710/4776 | Loss: 50.443 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1720/4776 | Loss: 90.202 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1730/4776 | Loss: 44.229 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1740/4776 | Loss: 96.066 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1750/4776 | Loss: 40.551 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1760/4776 | Loss: 7.517 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1770/4776 | Loss: 104.015 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1780/4776 | Loss: 37.225 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1790/4776 | Loss: 21.323 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1800/4776 | Loss: 119.950 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 1810/4776 | Loss: 118.552 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1820/4776 | Loss: 78.336 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1830/4776 | Loss: 75.313 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1840/4776 | Loss: 12.411 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1850/4776 | Loss: 151.993 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1860/4776 | Loss: 67.464 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1870/4776 | Loss: 98.195 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1880/4776 | Loss: 89.138 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1890/4776 | Loss: 94.790 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 1900/4776 | Loss: 55.857 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1910/4776 | Loss: 73.456 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1920/4776 | Loss: 47.011 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1930/4776 | Loss: 44.827 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 1940/4776 | Loss: 18.392 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 1950/4776 | Loss: 50.027 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1960/4776 | Loss: 45.604 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 1970/4776 | Loss: 127.085 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 1980/4776 | Loss: 107.930 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 1990/4776 | Loss: 26.349 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2000/4776 | Loss: 63.603 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2010/4776 | Loss: 30.883 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2020/4776 | Loss: 105.189 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2030/4776 | Loss: 11.884 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2040/4776 | Loss: 63.374 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2050/4776 | Loss: 62.310 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2060/4776 | Loss: 82.838 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2070/4776 | Loss: 45.660 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2080/4776 | Loss: 42.306 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2090/4776 | Loss: 52.305 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2100/4776 | Loss: 29.662 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2110/4776 | Loss: 123.011 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2120/4776 | Loss: 26.654 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2130/4776 | Loss: 53.376 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2140/4776 | Loss: 37.272 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2150/4776 | Loss: 59.477 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2160/4776 | Loss: 95.676 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2170/4776 | Loss: 42.519 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2180/4776 | Loss: 166.194 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2190/4776 | Loss: 58.360 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2200/4776 | Loss: 37.259 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2210/4776 | Loss: 97.373 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2220/4776 | Loss: 103.750 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2230/4776 | Loss: 93.389 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2240/4776 | Loss: 14.095 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2250/4776 | Loss: 8.290 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2260/4776 | Loss: 97.061 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2270/4776 | Loss: 78.124 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2280/4776 | Loss: 112.817 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2290/4776 | Loss: 71.101 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2300/4776 | Loss: 54.066 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2310/4776 | Loss: 53.836 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2320/4776 | Loss: 37.958 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2330/4776 | Loss: 34.909 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2340/4776 | Loss: 58.804 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2350/4776 | Loss: 7.532 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2360/4776 | Loss: 132.386 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2370/4776 | Loss: 103.743 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2380/4776 | Loss: 91.305 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2390/4776 | Loss: 61.803 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2400/4776 | Loss: 87.102 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2410/4776 | Loss: 80.619 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2420/4776 | Loss: 69.782 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2430/4776 | Loss: 97.135 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2440/4776 | Loss: 55.409 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2450/4776 | Loss: 40.507 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2460/4776 | Loss: 193.005 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2470/4776 | Loss: 48.757 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2480/4776 | Loss: 125.143 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 2490/4776 | Loss: 66.126 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2500/4776 | Loss: 39.801 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2510/4776 | Loss: 96.420 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2520/4776 | Loss: 124.991 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2530/4776 | Loss: 60.601 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2540/4776 | Loss: 48.685 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2550/4776 | Loss: 72.558 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2560/4776 | Loss: 75.718 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2570/4776 | Loss: 48.025 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2580/4776 | Loss: 21.723 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2590/4776 | Loss: 52.115 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2600/4776 | Loss: 170.640 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2610/4776 | Loss: 106.974 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2620/4776 | Loss: 61.010 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2630/4776 | Loss: 19.273 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 2640/4776 | Loss: 89.358 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 2650/4776 | Loss: 55.200 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2660/4776 | Loss: 106.111 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2670/4776 | Loss: 26.394 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2680/4776 | Loss: 58.928 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2690/4776 | Loss: 45.873 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2700/4776 | Loss: 61.984 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2710/4776 | Loss: 50.261 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2720/4776 | Loss: 25.816 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2730/4776 | Loss: 98.578 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2740/4776 | Loss: 46.146 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2750/4776 | Loss: 107.104 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 2760/4776 | Loss: 102.116 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2770/4776 | Loss: 36.899 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2780/4776 | Loss: 76.255 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2790/4776 | Loss: 75.956 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2800/4776 | Loss: 130.239 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2810/4776 | Loss: 24.445 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2820/4776 | Loss: 31.328 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2830/4776 | Loss: 24.538 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2840/4776 | Loss: 60.743 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2850/4776 | Loss: 68.755 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2860/4776 | Loss: 41.977 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2870/4776 | Loss: 58.135 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2880/4776 | Loss: 82.749 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2890/4776 | Loss: 51.992 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2900/4776 | Loss: 136.894 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2910/4776 | Loss: 26.622 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2920/4776 | Loss: 41.289 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2930/4776 | Loss: 73.396 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 2940/4776 | Loss: 72.216 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2950/4776 | Loss: 53.885 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 2960/4776 | Loss: 22.027 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2970/4776 | Loss: 46.903 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 2980/4776 | Loss: 39.887 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 2990/4776 | Loss: 35.177 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3000/4776 | Loss: 48.452 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3010/4776 | Loss: 27.354 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3020/4776 | Loss: 54.331 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3030/4776 | Loss: 50.272 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3040/4776 | Loss: 50.171 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3050/4776 | Loss: 99.506 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 3060/4776 | Loss: 46.235 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3070/4776 | Loss: 67.876 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3080/4776 | Loss: 54.030 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3090/4776 | Loss: 40.317 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3100/4776 | Loss: 34.402 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3110/4776 | Loss: 54.517 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3120/4776 | Loss: 48.893 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3130/4776 | Loss: 71.848 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3140/4776 | Loss: 38.925 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3150/4776 | Loss: 25.363 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3160/4776 | Loss: 54.879 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3170/4776 | Loss: 76.621 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3180/4776 | Loss: 114.054 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 3190/4776 | Loss: 94.760 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3200/4776 | Loss: 37.012 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3210/4776 | Loss: 16.193 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3220/4776 | Loss: 26.146 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3230/4776 | Loss: 32.275 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3240/4776 | Loss: 45.782 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3250/4776 | Loss: 20.694 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3260/4776 | Loss: 29.408 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3270/4776 | Loss: 37.408 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3280/4776 | Loss: 47.076 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3290/4776 | Loss: 37.043 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3300/4776 | Loss: 130.892 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3310/4776 | Loss: 54.395 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3320/4776 | Loss: 33.108 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3330/4776 | Loss: 98.716 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 3340/4776 | Loss: 34.964 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3350/4776 | Loss: 7.821 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3360/4776 | Loss: 55.867 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3370/4776 | Loss: 86.180 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3380/4776 | Loss: 6.297 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3390/4776 | Loss: 32.023 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3400/4776 | Loss: 29.913 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3410/4776 | Loss: 26.734 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3420/4776 | Loss: 44.029 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3430/4776 | Loss: 43.212 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3440/4776 | Loss: 52.421 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3450/4776 | Loss: 56.584 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3460/4776 | Loss: 69.129 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3470/4776 | Loss: 96.490 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3480/4776 | Loss: 55.030 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3490/4776 | Loss: 36.819 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3500/4776 | Loss: 63.459 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3510/4776 | Loss: 29.460 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3520/4776 | Loss: 60.517 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3530/4776 | Loss: 62.812 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3540/4776 | Loss: 109.370 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3550/4776 | Loss: 22.873 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3560/4776 | Loss: 104.432 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3570/4776 | Loss: 82.268 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3580/4776 | Loss: 60.432 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3590/4776 | Loss: 73.612 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3600/4776 | Loss: 137.122 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3610/4776 | Loss: 61.084 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3620/4776 | Loss: 150.398 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3630/4776 | Loss: 67.462 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3640/4776 | Loss: 25.300 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3650/4776 | Loss: 117.374 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3660/4776 | Loss: 71.934 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3670/4776 | Loss: 40.039 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3680/4776 | Loss: 92.528 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3690/4776 | Loss: 107.644 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3700/4776 | Loss: 54.035 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3710/4776 | Loss: 73.760 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3720/4776 | Loss: 53.692 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3730/4776 | Loss: 16.896 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 3740/4776 | Loss: 51.033 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3750/4776 | Loss: 57.288 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3760/4776 | Loss: 40.881 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3770/4776 | Loss: 69.299 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3780/4776 | Loss: 52.691 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3790/4776 | Loss: 74.896 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3800/4776 | Loss: 112.145 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3810/4776 | Loss: 38.368 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3820/4776 | Loss: 73.239 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3830/4776 | Loss: 39.136 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3840/4776 | Loss: 42.095 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3850/4776 | Loss: 76.607 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 3860/4776 | Loss: 128.407 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3870/4776 | Loss: 82.786 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3880/4776 | Loss: 62.805 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3890/4776 | Loss: 89.723 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3900/4776 | Loss: 105.524 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 3910/4776 | Loss: 26.663 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3920/4776 | Loss: 82.156 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3930/4776 | Loss: 53.382 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 3940/4776 | Loss: 57.059 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3950/4776 | Loss: 117.250 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3960/4776 | Loss: 83.450 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3970/4776 | Loss: 102.054 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 3980/4776 | Loss: 61.903 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 3990/4776 | Loss: 68.524 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4000/4776 | Loss: 56.247 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4010/4776 | Loss: 52.060 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4020/4776 | Loss: 52.693 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4030/4776 | Loss: 99.361 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4040/4776 | Loss: 35.502 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4050/4776 | Loss: 64.161 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4060/4776 | Loss: 142.467 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4070/4776 | Loss: 47.880 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4080/4776 | Loss: 156.225 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 4090/4776 | Loss: 84.967 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4100/4776 | Loss: 61.308 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4110/4776 | Loss: 112.632 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 4120/4776 | Loss: 71.764 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4130/4776 | Loss: 137.837 | Accuracy: 0.500\n",
      "[Epoch: 73/200] - Step: 4140/4776 | Loss: 69.701 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4150/4776 | Loss: 95.839 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4160/4776 | Loss: 52.315 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4170/4776 | Loss: 77.028 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4180/4776 | Loss: 59.970 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4190/4776 | Loss: 56.638 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4200/4776 | Loss: 21.831 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 4210/4776 | Loss: 58.773 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4220/4776 | Loss: 97.361 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4230/4776 | Loss: 91.414 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4240/4776 | Loss: 85.843 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4250/4776 | Loss: 65.910 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4260/4776 | Loss: 60.004 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4270/4776 | Loss: 35.495 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4280/4776 | Loss: 27.552 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4290/4776 | Loss: 28.973 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4300/4776 | Loss: 21.218 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 4310/4776 | Loss: 43.076 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4320/4776 | Loss: 107.788 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4330/4776 | Loss: 34.424 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4340/4776 | Loss: 217.932 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 4350/4776 | Loss: 46.436 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4360/4776 | Loss: 47.725 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4370/4776 | Loss: 71.224 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4380/4776 | Loss: 93.792 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4390/4776 | Loss: 61.614 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4400/4776 | Loss: 67.445 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4410/4776 | Loss: 30.161 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4420/4776 | Loss: 73.641 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4430/4776 | Loss: 42.643 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4440/4776 | Loss: 130.433 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 4450/4776 | Loss: 90.769 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4460/4776 | Loss: 238.607 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 4470/4776 | Loss: 96.239 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4480/4776 | Loss: 32.037 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 4490/4776 | Loss: 125.832 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4500/4776 | Loss: 134.832 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 4510/4776 | Loss: 100.886 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 4520/4776 | Loss: 63.385 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4530/4776 | Loss: 85.222 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4540/4776 | Loss: 44.937 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4550/4776 | Loss: 93.737 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4560/4776 | Loss: 52.617 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4570/4776 | Loss: 64.316 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4580/4776 | Loss: 115.323 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4590/4776 | Loss: 53.470 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4600/4776 | Loss: 82.685 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4610/4776 | Loss: 93.289 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4620/4776 | Loss: 54.146 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4630/4776 | Loss: 57.768 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4640/4776 | Loss: 149.879 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4650/4776 | Loss: 78.638 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4660/4776 | Loss: 55.055 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4670/4776 | Loss: 54.562 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4680/4776 | Loss: 74.239 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4690/4776 | Loss: 46.298 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4700/4776 | Loss: 74.845 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4710/4776 | Loss: 26.184 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4720/4776 | Loss: 31.242 | Accuracy: 0.900\n",
      "[Epoch: 73/200] - Step: 4730/4776 | Loss: 75.035 | Accuracy: 0.600\n",
      "[Epoch: 73/200] - Step: 4740/4776 | Loss: 39.721 | Accuracy: 0.800\n",
      "[Epoch: 73/200] - Step: 4750/4776 | Loss: 63.469 | Accuracy: 0.700\n",
      "[Epoch: 73/200] - Step: 4760/4776 | Loss: 21.049 | Accuracy: 1.000\n",
      "[Epoch: 73/200] - Step: 4770/4776 | Loss: 50.918 | Accuracy: 0.900\n",
      "Accuracy:  0.20327868852459016\n",
      "[Epoch: 74/200] - Step: 10/4776 | Loss: 147.891 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 20/4776 | Loss: 36.179 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 30/4776 | Loss: 41.848 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 40/4776 | Loss: 59.405 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 50/4776 | Loss: 160.066 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 60/4776 | Loss: 43.000 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 70/4776 | Loss: 87.079 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 80/4776 | Loss: 53.342 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 90/4776 | Loss: 64.905 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 100/4776 | Loss: 37.017 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 110/4776 | Loss: 49.628 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 120/4776 | Loss: 75.250 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 130/4776 | Loss: 65.393 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 140/4776 | Loss: 32.530 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 150/4776 | Loss: 88.718 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 160/4776 | Loss: 60.192 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 170/4776 | Loss: 65.854 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 180/4776 | Loss: 43.808 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 190/4776 | Loss: 48.522 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 200/4776 | Loss: 91.919 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 210/4776 | Loss: 70.568 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 220/4776 | Loss: 31.334 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 230/4776 | Loss: 46.401 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 240/4776 | Loss: 73.535 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 250/4776 | Loss: 69.788 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 260/4776 | Loss: 71.687 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 270/4776 | Loss: 77.616 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 280/4776 | Loss: 10.483 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 290/4776 | Loss: 57.808 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 300/4776 | Loss: 60.167 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 310/4776 | Loss: 34.926 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 320/4776 | Loss: 12.852 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 330/4776 | Loss: 35.281 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 340/4776 | Loss: 55.439 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 350/4776 | Loss: 47.245 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 360/4776 | Loss: 82.363 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 370/4776 | Loss: 78.438 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 380/4776 | Loss: 34.704 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 390/4776 | Loss: 68.788 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 400/4776 | Loss: 84.548 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 410/4776 | Loss: 81.723 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 420/4776 | Loss: 44.210 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 430/4776 | Loss: 40.505 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 440/4776 | Loss: 41.931 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 450/4776 | Loss: 95.280 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 460/4776 | Loss: 98.482 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 470/4776 | Loss: 49.947 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 480/4776 | Loss: 38.709 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 490/4776 | Loss: 27.190 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 500/4776 | Loss: 31.091 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 510/4776 | Loss: 50.305 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 520/4776 | Loss: 47.703 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 530/4776 | Loss: 61.573 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 540/4776 | Loss: 60.902 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 550/4776 | Loss: 47.113 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 560/4776 | Loss: 41.859 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 570/4776 | Loss: 75.048 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 580/4776 | Loss: 22.832 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 590/4776 | Loss: 27.879 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 600/4776 | Loss: 34.212 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 610/4776 | Loss: 60.020 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 620/4776 | Loss: 98.726 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 630/4776 | Loss: 13.542 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 640/4776 | Loss: 20.887 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 650/4776 | Loss: 17.993 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 660/4776 | Loss: 21.765 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 670/4776 | Loss: 51.037 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 680/4776 | Loss: 73.408 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 690/4776 | Loss: 59.305 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 700/4776 | Loss: 41.709 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 710/4776 | Loss: 52.264 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 720/4776 | Loss: 34.171 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 730/4776 | Loss: 58.890 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 740/4776 | Loss: 84.447 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 750/4776 | Loss: 79.786 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 760/4776 | Loss: 38.719 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 770/4776 | Loss: 81.352 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 780/4776 | Loss: 56.754 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 790/4776 | Loss: 27.958 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 800/4776 | Loss: 54.761 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 810/4776 | Loss: 19.098 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 820/4776 | Loss: 35.549 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 830/4776 | Loss: 5.705 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 840/4776 | Loss: 31.629 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 850/4776 | Loss: 76.613 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 860/4776 | Loss: 36.236 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 870/4776 | Loss: 76.007 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 880/4776 | Loss: 26.642 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 890/4776 | Loss: 75.115 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 900/4776 | Loss: 30.796 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 910/4776 | Loss: 59.003 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 920/4776 | Loss: 14.613 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 930/4776 | Loss: 64.184 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 940/4776 | Loss: 135.008 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 950/4776 | Loss: 52.968 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 960/4776 | Loss: 42.681 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 970/4776 | Loss: 56.034 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 980/4776 | Loss: 98.545 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 990/4776 | Loss: 98.181 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1000/4776 | Loss: 46.843 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1010/4776 | Loss: 59.142 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1020/4776 | Loss: 28.367 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1030/4776 | Loss: 94.275 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1040/4776 | Loss: 28.712 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1050/4776 | Loss: 38.097 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1060/4776 | Loss: 78.723 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1070/4776 | Loss: 36.402 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1080/4776 | Loss: 16.177 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1090/4776 | Loss: 101.337 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1100/4776 | Loss: 93.188 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1110/4776 | Loss: 91.282 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1120/4776 | Loss: 61.908 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1130/4776 | Loss: 51.975 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1140/4776 | Loss: 50.688 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1150/4776 | Loss: 42.172 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1160/4776 | Loss: 34.419 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1170/4776 | Loss: 35.395 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1180/4776 | Loss: 70.058 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1190/4776 | Loss: 38.042 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1200/4776 | Loss: 51.794 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1210/4776 | Loss: 53.616 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1220/4776 | Loss: 111.167 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1230/4776 | Loss: 92.329 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1240/4776 | Loss: 57.872 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1250/4776 | Loss: 98.592 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1260/4776 | Loss: 110.992 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1270/4776 | Loss: 77.137 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1280/4776 | Loss: 13.474 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1290/4776 | Loss: 62.870 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1300/4776 | Loss: 108.882 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1310/4776 | Loss: 69.467 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1320/4776 | Loss: 48.889 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1330/4776 | Loss: 26.144 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1340/4776 | Loss: 104.124 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1350/4776 | Loss: 64.128 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1360/4776 | Loss: 49.602 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1370/4776 | Loss: 44.005 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1380/4776 | Loss: 150.859 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1390/4776 | Loss: 94.192 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1400/4776 | Loss: 61.400 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1410/4776 | Loss: 52.297 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1420/4776 | Loss: 89.562 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1430/4776 | Loss: 97.877 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1440/4776 | Loss: 21.438 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1450/4776 | Loss: 35.179 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1460/4776 | Loss: 137.121 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1470/4776 | Loss: 42.232 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1480/4776 | Loss: 49.400 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1490/4776 | Loss: 44.324 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1500/4776 | Loss: 51.623 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1510/4776 | Loss: 87.634 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1520/4776 | Loss: 113.041 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1530/4776 | Loss: 56.995 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1540/4776 | Loss: 55.066 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1550/4776 | Loss: 94.510 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1560/4776 | Loss: 11.994 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1570/4776 | Loss: 38.550 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1580/4776 | Loss: 43.708 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1590/4776 | Loss: 51.889 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1600/4776 | Loss: 68.412 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1610/4776 | Loss: 90.989 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1620/4776 | Loss: 56.917 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1630/4776 | Loss: 69.399 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1640/4776 | Loss: 105.539 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1650/4776 | Loss: 133.826 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1660/4776 | Loss: 70.702 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1670/4776 | Loss: 114.179 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1680/4776 | Loss: 105.909 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 1690/4776 | Loss: 58.007 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1700/4776 | Loss: 118.971 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 1710/4776 | Loss: 48.894 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1720/4776 | Loss: 49.283 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1730/4776 | Loss: 40.956 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1740/4776 | Loss: 53.450 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1750/4776 | Loss: 56.422 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1760/4776 | Loss: 72.514 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1770/4776 | Loss: 63.493 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1780/4776 | Loss: 44.374 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1790/4776 | Loss: 86.981 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1800/4776 | Loss: 106.229 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1810/4776 | Loss: 73.711 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1820/4776 | Loss: 54.485 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1830/4776 | Loss: 60.717 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1840/4776 | Loss: 60.150 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1850/4776 | Loss: 40.929 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1860/4776 | Loss: 86.970 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1870/4776 | Loss: 5.621 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1880/4776 | Loss: 74.089 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1890/4776 | Loss: 93.969 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1900/4776 | Loss: 23.897 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1910/4776 | Loss: 105.002 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1920/4776 | Loss: 79.502 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1930/4776 | Loss: 34.387 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 1940/4776 | Loss: 65.893 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 1950/4776 | Loss: 111.195 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 1960/4776 | Loss: 81.923 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 1970/4776 | Loss: 82.841 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 1980/4776 | Loss: 63.403 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 1990/4776 | Loss: 80.808 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2000/4776 | Loss: 58.416 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2010/4776 | Loss: 85.175 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2020/4776 | Loss: 58.105 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2030/4776 | Loss: 45.558 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2040/4776 | Loss: 25.555 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2050/4776 | Loss: 49.262 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2060/4776 | Loss: 107.487 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2070/4776 | Loss: 102.205 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2080/4776 | Loss: 48.544 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2090/4776 | Loss: 26.034 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2100/4776 | Loss: 57.569 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2110/4776 | Loss: 55.077 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2120/4776 | Loss: 20.429 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2130/4776 | Loss: 33.096 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2140/4776 | Loss: 46.473 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2150/4776 | Loss: 79.009 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2160/4776 | Loss: 66.622 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2170/4776 | Loss: 44.649 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2180/4776 | Loss: 33.108 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2190/4776 | Loss: 86.618 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2200/4776 | Loss: 45.823 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2210/4776 | Loss: 28.423 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2220/4776 | Loss: 86.999 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2230/4776 | Loss: 51.357 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2240/4776 | Loss: 73.512 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2250/4776 | Loss: 59.388 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2260/4776 | Loss: 74.053 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2270/4776 | Loss: 37.069 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2280/4776 | Loss: 28.632 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2290/4776 | Loss: 52.971 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2300/4776 | Loss: 65.823 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2310/4776 | Loss: 39.697 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2320/4776 | Loss: 22.084 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2330/4776 | Loss: 42.061 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2340/4776 | Loss: 53.010 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2350/4776 | Loss: 143.824 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2360/4776 | Loss: 55.889 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2370/4776 | Loss: 98.527 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2380/4776 | Loss: 69.391 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2390/4776 | Loss: 154.769 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2400/4776 | Loss: 169.617 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 2410/4776 | Loss: 130.299 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2420/4776 | Loss: 167.650 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2430/4776 | Loss: 70.589 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2440/4776 | Loss: 45.188 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2450/4776 | Loss: 78.904 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2460/4776 | Loss: 124.007 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2470/4776 | Loss: 70.582 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2480/4776 | Loss: 32.872 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2490/4776 | Loss: 60.289 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2500/4776 | Loss: 146.714 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2510/4776 | Loss: 42.449 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2520/4776 | Loss: 64.027 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2530/4776 | Loss: 20.162 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2540/4776 | Loss: 56.199 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2550/4776 | Loss: 42.999 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2560/4776 | Loss: 123.943 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2570/4776 | Loss: 65.085 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2580/4776 | Loss: 69.479 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2590/4776 | Loss: 56.435 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2600/4776 | Loss: 55.598 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2610/4776 | Loss: 29.230 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2620/4776 | Loss: 12.403 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2630/4776 | Loss: 28.113 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2640/4776 | Loss: 23.961 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2650/4776 | Loss: 90.401 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2660/4776 | Loss: 91.998 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2670/4776 | Loss: 38.279 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2680/4776 | Loss: 60.733 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2690/4776 | Loss: 52.304 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2700/4776 | Loss: 36.213 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2710/4776 | Loss: 35.451 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2720/4776 | Loss: 111.219 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2730/4776 | Loss: 30.649 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2740/4776 | Loss: 76.181 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2750/4776 | Loss: 74.765 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2760/4776 | Loss: 73.359 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2770/4776 | Loss: 50.311 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2780/4776 | Loss: 31.742 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2790/4776 | Loss: 99.216 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2800/4776 | Loss: 71.739 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2810/4776 | Loss: 27.804 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2820/4776 | Loss: 101.089 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2830/4776 | Loss: 61.508 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2840/4776 | Loss: 38.033 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 2850/4776 | Loss: 56.017 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2860/4776 | Loss: 92.201 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2870/4776 | Loss: 67.057 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2880/4776 | Loss: 156.781 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 2890/4776 | Loss: 50.674 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2900/4776 | Loss: 46.509 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2910/4776 | Loss: 31.724 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2920/4776 | Loss: 60.519 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2930/4776 | Loss: 60.597 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2940/4776 | Loss: 70.665 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2950/4776 | Loss: 123.493 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 2960/4776 | Loss: 49.238 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 2970/4776 | Loss: 55.165 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 2980/4776 | Loss: 19.737 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 2990/4776 | Loss: 66.636 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3000/4776 | Loss: 64.239 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3010/4776 | Loss: 48.310 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3020/4776 | Loss: 56.677 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3030/4776 | Loss: 68.914 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3040/4776 | Loss: 44.211 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3050/4776 | Loss: 47.630 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3060/4776 | Loss: 22.014 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3070/4776 | Loss: 57.567 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3080/4776 | Loss: 50.683 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3090/4776 | Loss: 64.177 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3100/4776 | Loss: 77.036 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3110/4776 | Loss: 56.173 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3120/4776 | Loss: 72.908 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3130/4776 | Loss: 56.712 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3140/4776 | Loss: 18.197 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3150/4776 | Loss: 8.201 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3160/4776 | Loss: 19.579 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3170/4776 | Loss: 75.385 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3180/4776 | Loss: 56.637 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3190/4776 | Loss: 72.263 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3200/4776 | Loss: 43.499 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3210/4776 | Loss: 67.717 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3220/4776 | Loss: 85.499 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3230/4776 | Loss: 50.938 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3240/4776 | Loss: 65.567 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3250/4776 | Loss: 63.143 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3260/4776 | Loss: 71.883 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3270/4776 | Loss: 55.812 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3280/4776 | Loss: 55.143 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3290/4776 | Loss: 53.533 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3300/4776 | Loss: 16.995 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3310/4776 | Loss: 49.852 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3320/4776 | Loss: 119.892 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3330/4776 | Loss: 69.437 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3340/4776 | Loss: 74.881 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3350/4776 | Loss: 7.707 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3360/4776 | Loss: 11.554 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3370/4776 | Loss: 28.430 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3380/4776 | Loss: 73.369 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3390/4776 | Loss: 80.413 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3400/4776 | Loss: 98.043 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3410/4776 | Loss: 22.702 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3420/4776 | Loss: 69.543 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3430/4776 | Loss: 67.864 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3440/4776 | Loss: 21.606 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3450/4776 | Loss: 77.451 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3460/4776 | Loss: 58.656 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3470/4776 | Loss: 61.285 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3480/4776 | Loss: 127.719 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3490/4776 | Loss: 131.686 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3500/4776 | Loss: 27.724 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3510/4776 | Loss: 33.944 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3520/4776 | Loss: 15.820 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3530/4776 | Loss: 36.910 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3540/4776 | Loss: 78.045 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3550/4776 | Loss: 22.738 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3560/4776 | Loss: 2.648 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3570/4776 | Loss: 100.591 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3580/4776 | Loss: 90.881 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3590/4776 | Loss: 31.098 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3600/4776 | Loss: 64.361 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3610/4776 | Loss: 48.509 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3620/4776 | Loss: 55.875 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3630/4776 | Loss: 54.802 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3640/4776 | Loss: 94.945 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3650/4776 | Loss: 116.302 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3660/4776 | Loss: 68.357 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3670/4776 | Loss: 50.956 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3680/4776 | Loss: 116.139 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3690/4776 | Loss: 15.851 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3700/4776 | Loss: 35.832 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3710/4776 | Loss: 23.414 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3720/4776 | Loss: 56.119 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3730/4776 | Loss: 17.707 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3740/4776 | Loss: 81.660 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3750/4776 | Loss: 73.112 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3760/4776 | Loss: 137.814 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3770/4776 | Loss: 26.549 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3780/4776 | Loss: 74.426 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3790/4776 | Loss: 44.640 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3800/4776 | Loss: 116.182 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3810/4776 | Loss: 59.802 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3820/4776 | Loss: 60.687 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3830/4776 | Loss: 41.742 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3840/4776 | Loss: 123.628 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3850/4776 | Loss: 98.150 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3860/4776 | Loss: 68.267 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 3870/4776 | Loss: 143.181 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3880/4776 | Loss: 66.208 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3890/4776 | Loss: 101.644 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3900/4776 | Loss: 48.291 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3910/4776 | Loss: 54.992 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3920/4776 | Loss: 96.439 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3930/4776 | Loss: 21.901 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 3940/4776 | Loss: 33.755 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3950/4776 | Loss: 75.548 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 3960/4776 | Loss: 81.862 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 3970/4776 | Loss: 115.253 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 3980/4776 | Loss: 56.383 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 3990/4776 | Loss: 62.503 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4000/4776 | Loss: 80.402 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4010/4776 | Loss: 123.470 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4020/4776 | Loss: 156.404 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4030/4776 | Loss: 129.422 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4040/4776 | Loss: 37.842 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4050/4776 | Loss: 80.306 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4060/4776 | Loss: 67.780 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4070/4776 | Loss: 50.747 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4080/4776 | Loss: 105.127 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4090/4776 | Loss: 31.745 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4100/4776 | Loss: 62.934 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4110/4776 | Loss: 38.795 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4120/4776 | Loss: 44.396 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4130/4776 | Loss: 68.870 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4140/4776 | Loss: 61.222 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4150/4776 | Loss: 82.525 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4160/4776 | Loss: 92.621 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4170/4776 | Loss: 44.459 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4180/4776 | Loss: 88.384 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4190/4776 | Loss: 52.310 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4200/4776 | Loss: 76.414 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4210/4776 | Loss: 50.836 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4220/4776 | Loss: 66.056 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4230/4776 | Loss: 9.356 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4240/4776 | Loss: 73.256 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4250/4776 | Loss: 75.541 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4260/4776 | Loss: 116.829 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4270/4776 | Loss: 86.500 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4280/4776 | Loss: 76.683 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4290/4776 | Loss: 41.309 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4300/4776 | Loss: 105.202 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4310/4776 | Loss: 30.761 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4320/4776 | Loss: 53.115 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4330/4776 | Loss: 36.674 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4340/4776 | Loss: 23.573 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4350/4776 | Loss: 61.262 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4360/4776 | Loss: 49.132 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4370/4776 | Loss: 132.705 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4380/4776 | Loss: 62.723 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4390/4776 | Loss: 110.135 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 4400/4776 | Loss: 27.652 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4410/4776 | Loss: 27.929 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4420/4776 | Loss: 64.912 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4430/4776 | Loss: 59.413 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4440/4776 | Loss: 47.377 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4450/4776 | Loss: 105.551 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4460/4776 | Loss: 74.070 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4470/4776 | Loss: 41.055 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4480/4776 | Loss: 66.035 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4490/4776 | Loss: 86.843 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4500/4776 | Loss: 105.684 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4510/4776 | Loss: 39.399 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4520/4776 | Loss: 61.678 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4530/4776 | Loss: 34.369 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4540/4776 | Loss: 21.259 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4550/4776 | Loss: 129.664 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4560/4776 | Loss: 51.829 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4570/4776 | Loss: 106.497 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4580/4776 | Loss: 120.961 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 4590/4776 | Loss: 27.491 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4600/4776 | Loss: 68.186 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4610/4776 | Loss: 28.439 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4620/4776 | Loss: 72.994 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4630/4776 | Loss: 44.755 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4640/4776 | Loss: 67.224 | Accuracy: 0.600\n",
      "[Epoch: 74/200] - Step: 4650/4776 | Loss: 40.599 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4660/4776 | Loss: 58.323 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4670/4776 | Loss: 59.171 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4680/4776 | Loss: 27.181 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4690/4776 | Loss: 65.116 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4700/4776 | Loss: 17.416 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4710/4776 | Loss: 59.308 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4720/4776 | Loss: 85.495 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4730/4776 | Loss: 22.498 | Accuracy: 1.000\n",
      "[Epoch: 74/200] - Step: 4740/4776 | Loss: 67.721 | Accuracy: 0.800\n",
      "[Epoch: 74/200] - Step: 4750/4776 | Loss: 34.302 | Accuracy: 0.900\n",
      "[Epoch: 74/200] - Step: 4760/4776 | Loss: 100.211 | Accuracy: 0.700\n",
      "[Epoch: 74/200] - Step: 4770/4776 | Loss: 64.780 | Accuracy: 0.700\n",
      "Accuracy:  0.20655737704918034\n",
      "[Epoch: 75/200] - Step: 10/4776 | Loss: 31.039 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 20/4776 | Loss: 75.462 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 30/4776 | Loss: 35.545 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 40/4776 | Loss: 32.763 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 50/4776 | Loss: 65.704 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 60/4776 | Loss: 71.014 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 70/4776 | Loss: 48.581 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 80/4776 | Loss: 54.037 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 90/4776 | Loss: 52.442 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 100/4776 | Loss: 85.894 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 110/4776 | Loss: 94.569 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 120/4776 | Loss: 66.910 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 130/4776 | Loss: 61.619 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 140/4776 | Loss: 42.307 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 150/4776 | Loss: 51.868 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 160/4776 | Loss: 98.222 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 170/4776 | Loss: 52.283 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 180/4776 | Loss: 58.531 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 190/4776 | Loss: 81.169 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 200/4776 | Loss: 103.190 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 210/4776 | Loss: 73.612 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 220/4776 | Loss: 53.118 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 230/4776 | Loss: 38.736 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 240/4776 | Loss: 88.430 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 250/4776 | Loss: 71.043 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 260/4776 | Loss: 43.625 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 270/4776 | Loss: 72.903 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 280/4776 | Loss: 54.129 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 290/4776 | Loss: 83.191 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 300/4776 | Loss: 163.743 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 310/4776 | Loss: 29.640 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 320/4776 | Loss: 47.628 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 330/4776 | Loss: 91.579 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 340/4776 | Loss: 80.352 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 350/4776 | Loss: 62.576 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 360/4776 | Loss: 50.471 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 370/4776 | Loss: 17.307 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 380/4776 | Loss: 16.649 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 390/4776 | Loss: 72.989 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 400/4776 | Loss: 70.748 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 410/4776 | Loss: 28.789 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 420/4776 | Loss: 91.801 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 430/4776 | Loss: 44.189 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 440/4776 | Loss: 34.280 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 450/4776 | Loss: 58.578 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 460/4776 | Loss: 33.221 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 470/4776 | Loss: 48.132 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 480/4776 | Loss: 77.260 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 490/4776 | Loss: 55.181 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 500/4776 | Loss: 54.877 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 510/4776 | Loss: 50.548 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 520/4776 | Loss: 78.090 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 530/4776 | Loss: 58.796 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 540/4776 | Loss: 62.438 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 550/4776 | Loss: 90.338 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 560/4776 | Loss: 46.137 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 570/4776 | Loss: 64.687 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 580/4776 | Loss: 35.193 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 590/4776 | Loss: 85.196 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 600/4776 | Loss: 102.000 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 610/4776 | Loss: 97.167 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 620/4776 | Loss: 56.457 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 630/4776 | Loss: 52.089 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 640/4776 | Loss: 48.821 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 650/4776 | Loss: 48.947 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 660/4776 | Loss: 52.963 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 670/4776 | Loss: 44.656 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 680/4776 | Loss: 123.123 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 690/4776 | Loss: 56.287 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 700/4776 | Loss: 47.915 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 710/4776 | Loss: 58.587 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 720/4776 | Loss: 109.307 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 730/4776 | Loss: 80.614 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 740/4776 | Loss: 33.301 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 750/4776 | Loss: 39.231 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 760/4776 | Loss: 51.017 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 770/4776 | Loss: 75.676 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 780/4776 | Loss: 22.568 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 790/4776 | Loss: 126.643 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 800/4776 | Loss: 68.385 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 810/4776 | Loss: 77.547 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 820/4776 | Loss: 109.537 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 830/4776 | Loss: 33.775 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 840/4776 | Loss: 64.041 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 850/4776 | Loss: 66.116 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 860/4776 | Loss: 24.721 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 870/4776 | Loss: 70.072 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 880/4776 | Loss: 45.384 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 890/4776 | Loss: 65.212 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 900/4776 | Loss: 76.659 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 910/4776 | Loss: 47.023 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 920/4776 | Loss: 41.843 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 930/4776 | Loss: 81.995 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 940/4776 | Loss: 103.827 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 950/4776 | Loss: 24.769 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 960/4776 | Loss: 40.832 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 970/4776 | Loss: 14.563 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 980/4776 | Loss: 81.304 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 990/4776 | Loss: 40.570 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1000/4776 | Loss: 113.929 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1010/4776 | Loss: 42.403 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1020/4776 | Loss: 22.521 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1030/4776 | Loss: 50.653 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1040/4776 | Loss: 110.359 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1050/4776 | Loss: 9.679 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 1060/4776 | Loss: 24.595 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1070/4776 | Loss: 79.424 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1080/4776 | Loss: 81.379 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1090/4776 | Loss: 61.329 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1100/4776 | Loss: 14.632 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1110/4776 | Loss: 59.237 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1120/4776 | Loss: 21.682 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1130/4776 | Loss: 48.163 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1140/4776 | Loss: 37.104 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1150/4776 | Loss: 22.260 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1160/4776 | Loss: 32.704 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1170/4776 | Loss: 34.906 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1180/4776 | Loss: 47.743 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1190/4776 | Loss: 31.354 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1200/4776 | Loss: 40.341 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1210/4776 | Loss: 32.385 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1220/4776 | Loss: 22.072 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1230/4776 | Loss: 69.945 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1240/4776 | Loss: 15.337 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 1250/4776 | Loss: 71.701 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1260/4776 | Loss: 26.615 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1270/4776 | Loss: 71.371 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1280/4776 | Loss: 49.226 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1290/4776 | Loss: 75.162 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1300/4776 | Loss: 43.470 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1310/4776 | Loss: 105.369 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1320/4776 | Loss: 119.621 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1330/4776 | Loss: 75.492 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1340/4776 | Loss: 70.142 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1350/4776 | Loss: 87.246 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1360/4776 | Loss: 30.606 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1370/4776 | Loss: 36.842 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1380/4776 | Loss: 80.054 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1390/4776 | Loss: 51.592 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1400/4776 | Loss: 56.908 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1410/4776 | Loss: 84.622 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1420/4776 | Loss: 57.174 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1430/4776 | Loss: 98.196 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1440/4776 | Loss: 42.425 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1450/4776 | Loss: 52.794 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1460/4776 | Loss: 42.840 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1470/4776 | Loss: 79.737 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1480/4776 | Loss: 122.474 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1490/4776 | Loss: 37.586 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1500/4776 | Loss: 76.587 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1510/4776 | Loss: 77.168 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1520/4776 | Loss: 40.667 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1530/4776 | Loss: 17.245 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1540/4776 | Loss: 22.829 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1550/4776 | Loss: 29.184 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1560/4776 | Loss: 73.176 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1570/4776 | Loss: 58.974 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1580/4776 | Loss: 50.215 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1590/4776 | Loss: 36.240 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1600/4776 | Loss: 93.819 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 1610/4776 | Loss: 136.947 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 1620/4776 | Loss: 39.871 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1630/4776 | Loss: 69.945 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1640/4776 | Loss: 86.704 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 1650/4776 | Loss: 47.141 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1660/4776 | Loss: 81.223 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1670/4776 | Loss: 49.965 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1680/4776 | Loss: 43.220 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1690/4776 | Loss: 5.719 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 1700/4776 | Loss: 68.853 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1710/4776 | Loss: 37.589 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1720/4776 | Loss: 119.463 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1730/4776 | Loss: 80.890 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1740/4776 | Loss: 75.014 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1750/4776 | Loss: 51.874 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1760/4776 | Loss: 57.194 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1770/4776 | Loss: 147.231 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1780/4776 | Loss: 18.399 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 1790/4776 | Loss: 119.818 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 1800/4776 | Loss: 46.951 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1810/4776 | Loss: 72.415 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1820/4776 | Loss: 18.734 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1830/4776 | Loss: 26.755 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1840/4776 | Loss: 77.316 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1850/4776 | Loss: 56.358 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1860/4776 | Loss: 56.578 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1870/4776 | Loss: 103.564 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1880/4776 | Loss: 104.030 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1890/4776 | Loss: 30.607 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1900/4776 | Loss: 21.567 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1910/4776 | Loss: 45.109 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 1920/4776 | Loss: 67.263 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1930/4776 | Loss: 119.648 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1940/4776 | Loss: 73.960 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 1950/4776 | Loss: 88.956 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 1960/4776 | Loss: 152.096 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 1970/4776 | Loss: 99.482 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 1980/4776 | Loss: 22.224 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 1990/4776 | Loss: 129.305 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 2000/4776 | Loss: 34.746 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2010/4776 | Loss: 123.521 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 2020/4776 | Loss: 29.956 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2030/4776 | Loss: 78.300 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2040/4776 | Loss: 111.301 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2050/4776 | Loss: 77.154 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2060/4776 | Loss: 62.076 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2070/4776 | Loss: 49.616 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2080/4776 | Loss: 38.468 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2090/4776 | Loss: 107.950 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2100/4776 | Loss: 75.736 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2110/4776 | Loss: 55.985 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2120/4776 | Loss: 78.857 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2130/4776 | Loss: 74.476 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2140/4776 | Loss: 44.529 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2150/4776 | Loss: 37.116 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2160/4776 | Loss: 65.153 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2170/4776 | Loss: 54.126 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2180/4776 | Loss: 46.259 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2190/4776 | Loss: 69.363 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2200/4776 | Loss: 26.775 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 2210/4776 | Loss: 6.651 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 2220/4776 | Loss: 42.544 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2230/4776 | Loss: 38.595 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2240/4776 | Loss: 44.640 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2250/4776 | Loss: 30.970 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2260/4776 | Loss: 35.160 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2270/4776 | Loss: 110.404 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2280/4776 | Loss: 92.611 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2290/4776 | Loss: 37.248 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2300/4776 | Loss: 130.775 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 2310/4776 | Loss: 55.307 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2320/4776 | Loss: 87.331 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2330/4776 | Loss: 110.018 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2340/4776 | Loss: 65.437 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2350/4776 | Loss: 58.995 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2360/4776 | Loss: 81.957 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2370/4776 | Loss: 25.214 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2380/4776 | Loss: 54.179 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2390/4776 | Loss: 89.708 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2400/4776 | Loss: 77.917 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2410/4776 | Loss: 64.498 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2420/4776 | Loss: 42.738 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2430/4776 | Loss: 17.582 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 2440/4776 | Loss: 109.427 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 2450/4776 | Loss: 53.075 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2460/4776 | Loss: 72.740 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2470/4776 | Loss: 141.232 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2480/4776 | Loss: 27.182 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2490/4776 | Loss: 46.001 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2500/4776 | Loss: 92.500 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2510/4776 | Loss: 62.399 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2520/4776 | Loss: 69.381 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2530/4776 | Loss: 116.514 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 2540/4776 | Loss: 93.698 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2550/4776 | Loss: 61.515 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2560/4776 | Loss: 168.819 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 2570/4776 | Loss: 60.826 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2580/4776 | Loss: 76.791 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 2590/4776 | Loss: 57.427 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2600/4776 | Loss: 24.958 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2610/4776 | Loss: 13.842 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 2620/4776 | Loss: 51.357 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2630/4776 | Loss: 49.064 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2640/4776 | Loss: 64.768 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2650/4776 | Loss: 34.322 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2660/4776 | Loss: 88.862 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2670/4776 | Loss: 33.534 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2680/4776 | Loss: 90.580 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2690/4776 | Loss: 48.747 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2700/4776 | Loss: 48.010 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2710/4776 | Loss: 96.982 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2720/4776 | Loss: 67.990 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2730/4776 | Loss: 58.822 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2740/4776 | Loss: 69.227 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2750/4776 | Loss: 104.200 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 2760/4776 | Loss: 64.935 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2770/4776 | Loss: 30.896 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2780/4776 | Loss: 76.221 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2790/4776 | Loss: 46.019 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2800/4776 | Loss: 95.713 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 2810/4776 | Loss: 33.320 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2820/4776 | Loss: 81.898 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2830/4776 | Loss: 37.903 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2840/4776 | Loss: 89.968 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2850/4776 | Loss: 52.832 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2860/4776 | Loss: 57.869 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2870/4776 | Loss: 76.789 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2880/4776 | Loss: 56.841 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2890/4776 | Loss: 9.082 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 2900/4776 | Loss: 57.480 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2910/4776 | Loss: 112.528 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 2920/4776 | Loss: 36.124 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 2930/4776 | Loss: 66.773 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2940/4776 | Loss: 89.544 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2950/4776 | Loss: 66.945 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 2960/4776 | Loss: 65.286 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2970/4776 | Loss: 65.365 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 2980/4776 | Loss: 63.137 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 2990/4776 | Loss: 113.295 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 3000/4776 | Loss: 47.229 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3010/4776 | Loss: 60.969 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3020/4776 | Loss: 63.937 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3030/4776 | Loss: 46.425 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3040/4776 | Loss: 133.693 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3050/4776 | Loss: 39.472 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3060/4776 | Loss: 84.947 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3070/4776 | Loss: 20.336 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 3080/4776 | Loss: 69.133 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3090/4776 | Loss: 64.360 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3100/4776 | Loss: 81.914 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3110/4776 | Loss: 103.765 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 3120/4776 | Loss: 59.290 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3130/4776 | Loss: 23.879 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3140/4776 | Loss: 36.328 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3150/4776 | Loss: 81.829 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3160/4776 | Loss: 91.929 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3170/4776 | Loss: 64.182 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3180/4776 | Loss: 13.316 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 3190/4776 | Loss: 46.833 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3200/4776 | Loss: 63.232 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3210/4776 | Loss: 35.898 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3220/4776 | Loss: 28.608 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3230/4776 | Loss: 184.158 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 3240/4776 | Loss: 37.156 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3250/4776 | Loss: 68.520 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3260/4776 | Loss: 65.178 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3270/4776 | Loss: 37.517 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3280/4776 | Loss: 55.156 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3290/4776 | Loss: 63.254 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3300/4776 | Loss: 40.008 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3310/4776 | Loss: 48.847 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3320/4776 | Loss: 28.479 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3330/4776 | Loss: 70.537 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3340/4776 | Loss: 69.779 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3350/4776 | Loss: 49.027 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3360/4776 | Loss: 38.378 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3370/4776 | Loss: 44.731 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3380/4776 | Loss: 32.158 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3390/4776 | Loss: 62.950 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3400/4776 | Loss: 34.023 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3410/4776 | Loss: 49.900 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3420/4776 | Loss: 90.697 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3430/4776 | Loss: 23.581 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3440/4776 | Loss: 85.307 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3450/4776 | Loss: 67.720 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3460/4776 | Loss: 56.436 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3470/4776 | Loss: 57.250 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3480/4776 | Loss: 25.308 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3490/4776 | Loss: 62.643 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3500/4776 | Loss: 15.228 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 3510/4776 | Loss: 115.457 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3520/4776 | Loss: 46.665 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3530/4776 | Loss: 100.812 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3540/4776 | Loss: 66.905 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3550/4776 | Loss: 62.467 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3560/4776 | Loss: 48.940 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3570/4776 | Loss: 79.369 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3580/4776 | Loss: 80.264 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3590/4776 | Loss: 61.173 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3600/4776 | Loss: 43.703 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3610/4776 | Loss: 68.060 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3620/4776 | Loss: 107.092 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3630/4776 | Loss: 44.573 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3640/4776 | Loss: 70.156 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3650/4776 | Loss: 21.838 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3660/4776 | Loss: 57.950 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3670/4776 | Loss: 27.390 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3680/4776 | Loss: 110.987 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 3690/4776 | Loss: 73.532 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3700/4776 | Loss: 64.702 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3710/4776 | Loss: 46.960 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3720/4776 | Loss: 139.084 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3730/4776 | Loss: 27.785 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3740/4776 | Loss: 39.656 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3750/4776 | Loss: 56.281 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3760/4776 | Loss: 52.132 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3770/4776 | Loss: 74.600 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3780/4776 | Loss: 66.518 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3790/4776 | Loss: 53.570 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3800/4776 | Loss: 89.087 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 3810/4776 | Loss: 62.264 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3820/4776 | Loss: 56.588 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3830/4776 | Loss: 105.400 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3840/4776 | Loss: 101.466 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 3850/4776 | Loss: 65.802 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3860/4776 | Loss: 208.340 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 3870/4776 | Loss: 77.716 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3880/4776 | Loss: 60.988 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3890/4776 | Loss: 74.453 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3900/4776 | Loss: 70.767 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3910/4776 | Loss: 64.371 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3920/4776 | Loss: 79.321 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 3930/4776 | Loss: 69.511 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3940/4776 | Loss: 92.968 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 3950/4776 | Loss: 40.626 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 3960/4776 | Loss: 54.693 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3970/4776 | Loss: 32.166 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3980/4776 | Loss: 36.945 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 3990/4776 | Loss: 134.313 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4000/4776 | Loss: 54.342 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4010/4776 | Loss: 66.920 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4020/4776 | Loss: 135.000 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4030/4776 | Loss: 133.207 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4040/4776 | Loss: 45.522 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4050/4776 | Loss: 80.545 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4060/4776 | Loss: 29.230 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4070/4776 | Loss: 36.854 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4080/4776 | Loss: 131.343 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4090/4776 | Loss: 57.256 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4100/4776 | Loss: 110.177 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4110/4776 | Loss: 89.550 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4120/4776 | Loss: 54.323 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4130/4776 | Loss: 20.713 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4140/4776 | Loss: 45.093 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4150/4776 | Loss: 90.113 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4160/4776 | Loss: 116.520 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4170/4776 | Loss: 74.512 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4180/4776 | Loss: 67.316 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4190/4776 | Loss: 59.576 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4200/4776 | Loss: 38.399 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4210/4776 | Loss: 103.986 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4220/4776 | Loss: 82.245 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4230/4776 | Loss: 15.483 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4240/4776 | Loss: 80.943 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4250/4776 | Loss: 3.873 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4260/4776 | Loss: 89.592 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4270/4776 | Loss: 18.141 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4280/4776 | Loss: 66.495 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4290/4776 | Loss: 45.827 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4300/4776 | Loss: 63.998 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4310/4776 | Loss: 99.087 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4320/4776 | Loss: 91.956 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4330/4776 | Loss: 63.833 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4340/4776 | Loss: 32.525 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4350/4776 | Loss: 12.850 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4360/4776 | Loss: 26.677 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4370/4776 | Loss: 42.313 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4380/4776 | Loss: 44.997 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4390/4776 | Loss: 67.648 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4400/4776 | Loss: 20.441 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4410/4776 | Loss: 23.415 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4420/4776 | Loss: 51.718 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4430/4776 | Loss: 33.426 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4440/4776 | Loss: 33.002 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4450/4776 | Loss: 86.117 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4460/4776 | Loss: 64.941 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4470/4776 | Loss: 65.696 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4480/4776 | Loss: 37.747 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4490/4776 | Loss: 4.843 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4500/4776 | Loss: 5.858 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4510/4776 | Loss: 30.902 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4520/4776 | Loss: 36.442 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4530/4776 | Loss: 39.141 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4540/4776 | Loss: 59.460 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4550/4776 | Loss: 65.883 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4560/4776 | Loss: 25.272 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4570/4776 | Loss: 57.806 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4580/4776 | Loss: 62.347 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4590/4776 | Loss: 10.298 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4600/4776 | Loss: 37.875 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4610/4776 | Loss: 31.992 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4620/4776 | Loss: 54.465 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4630/4776 | Loss: 19.626 | Accuracy: 1.000\n",
      "[Epoch: 75/200] - Step: 4640/4776 | Loss: 248.674 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4650/4776 | Loss: 91.144 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4660/4776 | Loss: 105.929 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4670/4776 | Loss: 34.302 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4680/4776 | Loss: 109.243 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 4690/4776 | Loss: 39.364 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4700/4776 | Loss: 72.474 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4710/4776 | Loss: 78.082 | Accuracy: 0.600\n",
      "[Epoch: 75/200] - Step: 4720/4776 | Loss: 60.048 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4730/4776 | Loss: 33.592 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4740/4776 | Loss: 94.297 | Accuracy: 0.700\n",
      "[Epoch: 75/200] - Step: 4750/4776 | Loss: 33.539 | Accuracy: 0.900\n",
      "[Epoch: 75/200] - Step: 4760/4776 | Loss: 61.264 | Accuracy: 0.800\n",
      "[Epoch: 75/200] - Step: 4770/4776 | Loss: 52.897 | Accuracy: 0.800\n",
      "Accuracy:  0.19672131147540983\n",
      "[Epoch: 76/200] - Step: 10/4776 | Loss: 44.952 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 20/4776 | Loss: 56.767 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 30/4776 | Loss: 35.958 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 40/4776 | Loss: 56.297 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 50/4776 | Loss: 75.102 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 60/4776 | Loss: 62.795 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 70/4776 | Loss: 50.426 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 80/4776 | Loss: 50.216 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 90/4776 | Loss: 36.758 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 100/4776 | Loss: 36.753 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 110/4776 | Loss: 67.612 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 120/4776 | Loss: 20.032 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 130/4776 | Loss: 21.310 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 140/4776 | Loss: 86.671 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 150/4776 | Loss: 48.768 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 160/4776 | Loss: 87.288 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 170/4776 | Loss: 60.891 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 180/4776 | Loss: 89.340 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 190/4776 | Loss: 39.840 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 200/4776 | Loss: 48.776 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 210/4776 | Loss: 31.101 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 220/4776 | Loss: 71.405 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 230/4776 | Loss: 45.076 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 240/4776 | Loss: 20.509 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 250/4776 | Loss: 12.789 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 260/4776 | Loss: 18.662 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 270/4776 | Loss: 151.972 | Accuracy: 0.400\n",
      "[Epoch: 76/200] - Step: 280/4776 | Loss: 38.445 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 290/4776 | Loss: 50.795 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 300/4776 | Loss: 95.450 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 310/4776 | Loss: 27.577 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 320/4776 | Loss: 70.895 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 330/4776 | Loss: 39.326 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 340/4776 | Loss: 37.533 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 350/4776 | Loss: 41.006 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 360/4776 | Loss: 65.470 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 370/4776 | Loss: 121.499 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 380/4776 | Loss: 32.281 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 390/4776 | Loss: 86.101 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 400/4776 | Loss: 109.858 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 410/4776 | Loss: 33.067 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 420/4776 | Loss: 61.373 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 430/4776 | Loss: 54.639 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 440/4776 | Loss: 83.474 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 450/4776 | Loss: 55.426 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 460/4776 | Loss: 87.496 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 470/4776 | Loss: 48.863 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 480/4776 | Loss: 59.132 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 490/4776 | Loss: 52.805 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 500/4776 | Loss: 23.676 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 510/4776 | Loss: 3.510 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 520/4776 | Loss: 84.122 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 530/4776 | Loss: 89.831 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 540/4776 | Loss: 10.889 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 550/4776 | Loss: 38.670 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 560/4776 | Loss: 45.731 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 570/4776 | Loss: 26.792 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 580/4776 | Loss: 22.733 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 590/4776 | Loss: 62.283 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 600/4776 | Loss: 65.111 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 610/4776 | Loss: 25.125 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 620/4776 | Loss: 60.943 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 630/4776 | Loss: 65.690 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 640/4776 | Loss: 89.668 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 650/4776 | Loss: 70.139 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 660/4776 | Loss: 46.638 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 670/4776 | Loss: 68.382 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 680/4776 | Loss: 73.695 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 690/4776 | Loss: 29.761 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 700/4776 | Loss: 91.078 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 710/4776 | Loss: 103.296 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 720/4776 | Loss: 143.915 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 730/4776 | Loss: 50.447 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 740/4776 | Loss: 48.530 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 750/4776 | Loss: 126.884 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 760/4776 | Loss: 77.455 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 770/4776 | Loss: 63.793 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 780/4776 | Loss: 35.352 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 790/4776 | Loss: 17.492 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 800/4776 | Loss: 74.684 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 810/4776 | Loss: 102.316 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 820/4776 | Loss: 47.937 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 830/4776 | Loss: 34.776 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 840/4776 | Loss: 36.209 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 850/4776 | Loss: 34.726 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 860/4776 | Loss: 97.065 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 870/4776 | Loss: 79.657 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 880/4776 | Loss: 69.689 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 890/4776 | Loss: 59.764 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 900/4776 | Loss: 35.797 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 910/4776 | Loss: 27.719 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 920/4776 | Loss: 56.264 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 930/4776 | Loss: 113.007 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 940/4776 | Loss: 72.041 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 950/4776 | Loss: 22.630 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 960/4776 | Loss: 43.816 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 970/4776 | Loss: 53.558 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 980/4776 | Loss: 0.765 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 990/4776 | Loss: 69.827 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1000/4776 | Loss: 68.045 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1010/4776 | Loss: 18.290 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1020/4776 | Loss: 38.385 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1030/4776 | Loss: 40.332 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1040/4776 | Loss: 17.638 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1050/4776 | Loss: 40.409 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1060/4776 | Loss: 23.983 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1070/4776 | Loss: 37.153 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1080/4776 | Loss: 31.621 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1090/4776 | Loss: 66.340 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1100/4776 | Loss: 80.796 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1110/4776 | Loss: 122.109 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1120/4776 | Loss: 42.960 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1130/4776 | Loss: 122.687 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1140/4776 | Loss: 8.657 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1150/4776 | Loss: 14.719 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1160/4776 | Loss: 90.621 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1170/4776 | Loss: 76.185 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1180/4776 | Loss: 108.662 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1190/4776 | Loss: 92.800 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1200/4776 | Loss: 92.412 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1210/4776 | Loss: 47.405 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1220/4776 | Loss: 24.738 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1230/4776 | Loss: 48.115 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1240/4776 | Loss: 33.009 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1250/4776 | Loss: 110.445 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1260/4776 | Loss: 98.541 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1270/4776 | Loss: 31.384 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1280/4776 | Loss: 32.506 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1290/4776 | Loss: 59.743 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1300/4776 | Loss: 32.327 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1310/4776 | Loss: 48.353 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1320/4776 | Loss: 63.287 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1330/4776 | Loss: 30.444 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1340/4776 | Loss: 34.014 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1350/4776 | Loss: 37.078 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1360/4776 | Loss: 79.770 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1370/4776 | Loss: 144.319 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1380/4776 | Loss: 140.807 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1390/4776 | Loss: 106.106 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1400/4776 | Loss: 45.983 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1410/4776 | Loss: 80.188 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1420/4776 | Loss: 53.563 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1430/4776 | Loss: 53.504 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1440/4776 | Loss: 80.466 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1450/4776 | Loss: 51.539 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1460/4776 | Loss: 51.092 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1470/4776 | Loss: 91.183 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1480/4776 | Loss: 70.017 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1490/4776 | Loss: 44.260 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1500/4776 | Loss: 60.366 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1510/4776 | Loss: 31.509 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1520/4776 | Loss: 101.129 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1530/4776 | Loss: 72.452 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1540/4776 | Loss: 18.748 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1550/4776 | Loss: 148.531 | Accuracy: 0.400\n",
      "[Epoch: 76/200] - Step: 1560/4776 | Loss: 52.193 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1570/4776 | Loss: 44.110 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1580/4776 | Loss: 80.352 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1590/4776 | Loss: 82.431 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1600/4776 | Loss: 48.950 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1610/4776 | Loss: 110.563 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1620/4776 | Loss: 23.301 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1630/4776 | Loss: 164.745 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1640/4776 | Loss: 116.956 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1650/4776 | Loss: 130.245 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 1660/4776 | Loss: 51.604 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1670/4776 | Loss: 98.677 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1680/4776 | Loss: 51.766 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1690/4776 | Loss: 40.942 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1700/4776 | Loss: 75.417 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1710/4776 | Loss: 68.251 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1720/4776 | Loss: 50.818 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1730/4776 | Loss: 87.419 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1740/4776 | Loss: 89.638 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1750/4776 | Loss: 87.527 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1760/4776 | Loss: 102.891 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1770/4776 | Loss: 114.640 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1780/4776 | Loss: 23.276 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1790/4776 | Loss: 43.825 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1800/4776 | Loss: 55.941 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1810/4776 | Loss: 102.167 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1820/4776 | Loss: 61.671 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1830/4776 | Loss: 78.199 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1840/4776 | Loss: 74.528 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1850/4776 | Loss: 12.712 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 1860/4776 | Loss: 53.226 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1870/4776 | Loss: 41.568 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1880/4776 | Loss: 78.467 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1890/4776 | Loss: 94.713 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1900/4776 | Loss: 23.423 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1910/4776 | Loss: 62.571 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1920/4776 | Loss: 43.703 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1930/4776 | Loss: 79.312 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 1940/4776 | Loss: 110.451 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 1950/4776 | Loss: 23.868 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1960/4776 | Loss: 54.397 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1970/4776 | Loss: 28.569 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 1980/4776 | Loss: 56.836 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 1990/4776 | Loss: 70.679 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2000/4776 | Loss: 55.441 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2010/4776 | Loss: 136.098 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 2020/4776 | Loss: 51.639 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2030/4776 | Loss: 30.023 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2040/4776 | Loss: 10.429 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2050/4776 | Loss: 70.114 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2060/4776 | Loss: 59.757 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2070/4776 | Loss: 50.158 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2080/4776 | Loss: 102.612 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2090/4776 | Loss: 67.902 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2100/4776 | Loss: 31.627 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2110/4776 | Loss: 43.745 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2120/4776 | Loss: 90.611 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2130/4776 | Loss: 46.194 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2140/4776 | Loss: 90.134 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2150/4776 | Loss: 56.539 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2160/4776 | Loss: 58.478 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2170/4776 | Loss: 58.266 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2180/4776 | Loss: 103.023 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2190/4776 | Loss: 45.305 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2200/4776 | Loss: 59.097 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2210/4776 | Loss: 30.935 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2220/4776 | Loss: 136.636 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2230/4776 | Loss: 73.805 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2240/4776 | Loss: 101.111 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2250/4776 | Loss: 45.624 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2260/4776 | Loss: 85.660 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2270/4776 | Loss: 131.159 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2280/4776 | Loss: 76.153 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 2290/4776 | Loss: 103.893 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2300/4776 | Loss: 87.221 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2310/4776 | Loss: 60.477 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2320/4776 | Loss: 23.398 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2330/4776 | Loss: 45.359 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2340/4776 | Loss: 128.063 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2350/4776 | Loss: 44.083 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2360/4776 | Loss: 57.410 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2370/4776 | Loss: 19.914 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2380/4776 | Loss: 49.606 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2390/4776 | Loss: 21.036 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2400/4776 | Loss: 5.895 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2410/4776 | Loss: 39.645 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2420/4776 | Loss: 70.193 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2430/4776 | Loss: 84.788 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2440/4776 | Loss: 41.425 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2450/4776 | Loss: 76.371 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2460/4776 | Loss: 100.284 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2470/4776 | Loss: 42.224 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2480/4776 | Loss: 40.828 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2490/4776 | Loss: 47.859 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2500/4776 | Loss: 55.758 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2510/4776 | Loss: 41.588 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2520/4776 | Loss: 10.246 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2530/4776 | Loss: 51.837 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2540/4776 | Loss: 7.116 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2550/4776 | Loss: 43.442 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2560/4776 | Loss: 31.855 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2570/4776 | Loss: 89.706 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2580/4776 | Loss: 40.622 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2590/4776 | Loss: 46.538 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2600/4776 | Loss: 13.618 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2610/4776 | Loss: 131.742 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2620/4776 | Loss: 25.340 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2630/4776 | Loss: 65.118 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2640/4776 | Loss: 81.932 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2650/4776 | Loss: 107.075 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2660/4776 | Loss: 14.955 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2670/4776 | Loss: 66.788 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 2680/4776 | Loss: 21.830 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2690/4776 | Loss: 59.988 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2700/4776 | Loss: 55.452 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2710/4776 | Loss: 69.965 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2720/4776 | Loss: 35.620 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2730/4776 | Loss: 44.302 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2740/4776 | Loss: 46.740 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2750/4776 | Loss: 68.966 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2760/4776 | Loss: 10.882 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2770/4776 | Loss: 57.925 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2780/4776 | Loss: 31.744 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2790/4776 | Loss: 79.432 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2800/4776 | Loss: 71.464 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2810/4776 | Loss: 68.356 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2820/4776 | Loss: 51.463 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2830/4776 | Loss: 72.864 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2840/4776 | Loss: 33.487 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2850/4776 | Loss: 35.826 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2860/4776 | Loss: 42.640 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2870/4776 | Loss: 37.125 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2880/4776 | Loss: 82.930 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2890/4776 | Loss: 94.401 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2900/4776 | Loss: 51.090 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 2910/4776 | Loss: 37.087 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2920/4776 | Loss: 32.074 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2930/4776 | Loss: 36.930 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 2940/4776 | Loss: 10.226 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2950/4776 | Loss: 10.326 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2960/4776 | Loss: 19.116 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 2970/4776 | Loss: 81.428 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 2980/4776 | Loss: 136.101 | Accuracy: 0.400\n",
      "[Epoch: 76/200] - Step: 2990/4776 | Loss: 71.474 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3000/4776 | Loss: 135.850 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3010/4776 | Loss: 22.367 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3020/4776 | Loss: 26.284 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3030/4776 | Loss: 35.606 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3040/4776 | Loss: 54.118 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3050/4776 | Loss: 79.746 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3060/4776 | Loss: 86.358 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3070/4776 | Loss: 78.229 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3080/4776 | Loss: 56.926 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3090/4776 | Loss: 61.467 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3100/4776 | Loss: 59.053 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3110/4776 | Loss: 103.950 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3120/4776 | Loss: 53.419 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3130/4776 | Loss: 73.623 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3140/4776 | Loss: 54.886 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3150/4776 | Loss: 113.138 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3160/4776 | Loss: 72.096 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3170/4776 | Loss: 120.367 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3180/4776 | Loss: 89.068 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3190/4776 | Loss: 99.245 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3200/4776 | Loss: 63.849 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3210/4776 | Loss: 98.364 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3220/4776 | Loss: 38.895 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3230/4776 | Loss: 49.278 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3240/4776 | Loss: 42.854 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3250/4776 | Loss: 9.384 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3260/4776 | Loss: 52.381 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3270/4776 | Loss: 83.557 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3280/4776 | Loss: 42.629 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3290/4776 | Loss: 30.730 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3300/4776 | Loss: 105.478 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3310/4776 | Loss: 79.912 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3320/4776 | Loss: 108.642 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3330/4776 | Loss: 57.704 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3340/4776 | Loss: 114.703 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3350/4776 | Loss: 22.778 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3360/4776 | Loss: 58.538 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3370/4776 | Loss: 64.495 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3380/4776 | Loss: 28.639 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3390/4776 | Loss: 124.457 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3400/4776 | Loss: 45.413 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3410/4776 | Loss: 76.890 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3420/4776 | Loss: 61.901 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3430/4776 | Loss: 134.113 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 3440/4776 | Loss: 41.485 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3450/4776 | Loss: 74.833 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3460/4776 | Loss: 27.175 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3470/4776 | Loss: 30.640 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3480/4776 | Loss: 73.267 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3490/4776 | Loss: 24.956 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3500/4776 | Loss: 93.524 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3510/4776 | Loss: 70.595 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3520/4776 | Loss: 85.886 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3530/4776 | Loss: 77.570 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3540/4776 | Loss: 89.134 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3550/4776 | Loss: 60.604 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3560/4776 | Loss: 43.566 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3570/4776 | Loss: 76.099 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3580/4776 | Loss: 49.809 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3590/4776 | Loss: 67.071 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3600/4776 | Loss: 54.104 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3610/4776 | Loss: 12.777 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3620/4776 | Loss: 61.697 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3630/4776 | Loss: 55.323 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3640/4776 | Loss: 49.458 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3650/4776 | Loss: 45.428 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3660/4776 | Loss: 101.344 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3670/4776 | Loss: 88.717 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3680/4776 | Loss: 33.933 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3690/4776 | Loss: 44.562 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3700/4776 | Loss: 110.445 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3710/4776 | Loss: 34.897 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 3720/4776 | Loss: 48.276 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3730/4776 | Loss: 63.587 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3740/4776 | Loss: 70.277 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3750/4776 | Loss: 75.398 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3760/4776 | Loss: 142.441 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3770/4776 | Loss: 163.158 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3780/4776 | Loss: 44.391 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3790/4776 | Loss: 84.796 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3800/4776 | Loss: 89.280 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3810/4776 | Loss: 122.272 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3820/4776 | Loss: 156.464 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3830/4776 | Loss: 69.850 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3840/4776 | Loss: 48.459 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3850/4776 | Loss: 67.323 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3860/4776 | Loss: 56.866 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3870/4776 | Loss: 32.715 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3880/4776 | Loss: 98.621 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 3890/4776 | Loss: 69.154 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3900/4776 | Loss: 60.844 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3910/4776 | Loss: 28.165 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3920/4776 | Loss: 55.901 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3930/4776 | Loss: 99.577 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3940/4776 | Loss: 64.167 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 3950/4776 | Loss: 55.055 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3960/4776 | Loss: 113.774 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 3970/4776 | Loss: 83.970 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 3980/4776 | Loss: 65.059 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 3990/4776 | Loss: 72.979 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4000/4776 | Loss: 50.402 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4010/4776 | Loss: 66.140 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4020/4776 | Loss: 71.372 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4030/4776 | Loss: 53.829 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4040/4776 | Loss: 47.797 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4050/4776 | Loss: 72.165 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4060/4776 | Loss: 67.520 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4070/4776 | Loss: 63.585 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4080/4776 | Loss: 84.826 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4090/4776 | Loss: 30.140 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4100/4776 | Loss: 27.362 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4110/4776 | Loss: 33.432 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4120/4776 | Loss: 18.118 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4130/4776 | Loss: 37.038 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4140/4776 | Loss: 70.990 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4150/4776 | Loss: 11.888 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4160/4776 | Loss: 87.554 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4170/4776 | Loss: 55.728 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4180/4776 | Loss: 27.675 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4190/4776 | Loss: 71.446 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4200/4776 | Loss: 96.542 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4210/4776 | Loss: 43.144 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4220/4776 | Loss: 47.816 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4230/4776 | Loss: 74.091 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4240/4776 | Loss: 119.322 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 4250/4776 | Loss: 48.279 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4260/4776 | Loss: 45.226 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4270/4776 | Loss: 49.202 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4280/4776 | Loss: 62.701 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4290/4776 | Loss: 72.765 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4300/4776 | Loss: 67.702 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4310/4776 | Loss: 66.892 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4320/4776 | Loss: 93.846 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4330/4776 | Loss: 54.221 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4340/4776 | Loss: 32.676 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4350/4776 | Loss: 59.414 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4360/4776 | Loss: 19.515 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4370/4776 | Loss: 98.199 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4380/4776 | Loss: 35.183 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4390/4776 | Loss: 35.337 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4400/4776 | Loss: 111.142 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4410/4776 | Loss: 37.545 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4420/4776 | Loss: 53.904 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4430/4776 | Loss: 22.304 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4440/4776 | Loss: 33.555 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4450/4776 | Loss: 71.687 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4460/4776 | Loss: 35.308 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4470/4776 | Loss: 65.260 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4480/4776 | Loss: 47.896 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4490/4776 | Loss: 62.402 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4500/4776 | Loss: 41.919 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4510/4776 | Loss: 109.843 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4520/4776 | Loss: 77.485 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4530/4776 | Loss: 50.462 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4540/4776 | Loss: 76.878 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4550/4776 | Loss: 69.880 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4560/4776 | Loss: 47.824 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4570/4776 | Loss: 11.421 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4580/4776 | Loss: 25.066 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4590/4776 | Loss: 27.997 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4600/4776 | Loss: 28.776 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4610/4776 | Loss: 14.211 | Accuracy: 1.000\n",
      "[Epoch: 76/200] - Step: 4620/4776 | Loss: 35.088 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4630/4776 | Loss: 53.224 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4640/4776 | Loss: 72.843 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4650/4776 | Loss: 64.190 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4660/4776 | Loss: 103.447 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4670/4776 | Loss: 122.126 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4680/4776 | Loss: 80.961 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4690/4776 | Loss: 60.763 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4700/4776 | Loss: 58.502 | Accuracy: 0.900\n",
      "[Epoch: 76/200] - Step: 4710/4776 | Loss: 71.690 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4720/4776 | Loss: 122.294 | Accuracy: 0.500\n",
      "[Epoch: 76/200] - Step: 4730/4776 | Loss: 110.698 | Accuracy: 0.700\n",
      "[Epoch: 76/200] - Step: 4740/4776 | Loss: 76.038 | Accuracy: 0.600\n",
      "[Epoch: 76/200] - Step: 4750/4776 | Loss: 62.836 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4760/4776 | Loss: 53.624 | Accuracy: 0.800\n",
      "[Epoch: 76/200] - Step: 4770/4776 | Loss: 65.135 | Accuracy: 0.700\n",
      "Accuracy:  0.20163934426229507\n",
      "[Epoch: 77/200] - Step: 10/4776 | Loss: 92.626 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 20/4776 | Loss: 42.991 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 30/4776 | Loss: 38.734 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 40/4776 | Loss: 85.870 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 50/4776 | Loss: 22.064 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 60/4776 | Loss: 87.341 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 70/4776 | Loss: 78.020 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 80/4776 | Loss: 90.952 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 90/4776 | Loss: 41.466 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 100/4776 | Loss: 35.891 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 110/4776 | Loss: 25.881 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 120/4776 | Loss: 89.602 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 130/4776 | Loss: 46.557 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 140/4776 | Loss: 37.217 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 150/4776 | Loss: 85.057 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 160/4776 | Loss: 72.108 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 170/4776 | Loss: 37.504 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 180/4776 | Loss: 49.510 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 190/4776 | Loss: 51.896 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 200/4776 | Loss: 23.121 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 210/4776 | Loss: 50.486 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 220/4776 | Loss: 103.542 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 230/4776 | Loss: 68.376 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 240/4776 | Loss: 66.572 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 250/4776 | Loss: 47.799 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 260/4776 | Loss: 99.055 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 270/4776 | Loss: 39.964 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 280/4776 | Loss: 99.138 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 290/4776 | Loss: 69.566 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 300/4776 | Loss: 309.879 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 310/4776 | Loss: 30.904 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 320/4776 | Loss: 60.205 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 330/4776 | Loss: 81.079 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 340/4776 | Loss: 90.459 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 350/4776 | Loss: 52.572 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 360/4776 | Loss: 63.092 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 370/4776 | Loss: 90.989 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 380/4776 | Loss: 252.789 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 390/4776 | Loss: 63.770 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 400/4776 | Loss: 162.436 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 410/4776 | Loss: 80.189 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 420/4776 | Loss: 75.486 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 430/4776 | Loss: 149.022 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 440/4776 | Loss: 122.791 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 450/4776 | Loss: 102.928 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 460/4776 | Loss: 45.618 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 470/4776 | Loss: 65.463 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 480/4776 | Loss: 74.550 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 490/4776 | Loss: 73.365 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 500/4776 | Loss: 55.912 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 510/4776 | Loss: 63.529 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 520/4776 | Loss: 57.611 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 530/4776 | Loss: 35.826 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 540/4776 | Loss: 52.695 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 550/4776 | Loss: 114.932 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 560/4776 | Loss: 97.144 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 570/4776 | Loss: 98.256 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 580/4776 | Loss: 65.220 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 590/4776 | Loss: 68.804 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 600/4776 | Loss: 69.644 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 610/4776 | Loss: 40.164 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 620/4776 | Loss: 53.567 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 630/4776 | Loss: 129.217 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 640/4776 | Loss: 16.757 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 650/4776 | Loss: 37.346 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 660/4776 | Loss: 81.895 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 670/4776 | Loss: 45.042 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 680/4776 | Loss: 109.443 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 690/4776 | Loss: 41.378 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 700/4776 | Loss: 83.907 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 710/4776 | Loss: 27.660 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 720/4776 | Loss: 79.509 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 730/4776 | Loss: 61.435 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 740/4776 | Loss: 34.514 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 750/4776 | Loss: 26.571 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 760/4776 | Loss: 70.473 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 770/4776 | Loss: 77.651 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 780/4776 | Loss: 38.766 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 790/4776 | Loss: 76.539 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 800/4776 | Loss: 73.274 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 810/4776 | Loss: 81.167 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 820/4776 | Loss: 34.315 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 830/4776 | Loss: 95.655 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 840/4776 | Loss: 36.696 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 850/4776 | Loss: 35.384 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 860/4776 | Loss: 21.172 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 870/4776 | Loss: 64.822 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 880/4776 | Loss: 80.231 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 890/4776 | Loss: 56.732 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 900/4776 | Loss: 6.390 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 910/4776 | Loss: 65.253 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 920/4776 | Loss: 64.368 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 930/4776 | Loss: 20.370 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 940/4776 | Loss: 25.522 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 950/4776 | Loss: 74.081 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 960/4776 | Loss: 53.958 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 970/4776 | Loss: 60.894 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 980/4776 | Loss: 74.303 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 990/4776 | Loss: 42.877 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1000/4776 | Loss: 29.732 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1010/4776 | Loss: 25.624 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1020/4776 | Loss: 45.309 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1030/4776 | Loss: 23.159 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1040/4776 | Loss: 114.353 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 1050/4776 | Loss: 58.737 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1060/4776 | Loss: 30.919 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1070/4776 | Loss: 56.104 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1080/4776 | Loss: 25.379 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1090/4776 | Loss: 69.290 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1100/4776 | Loss: 78.039 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1110/4776 | Loss: 23.956 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1120/4776 | Loss: 45.103 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1130/4776 | Loss: 38.767 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1140/4776 | Loss: 50.408 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1150/4776 | Loss: 59.546 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1160/4776 | Loss: 28.432 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1170/4776 | Loss: 125.549 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 1180/4776 | Loss: 54.245 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1190/4776 | Loss: 88.569 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1200/4776 | Loss: 159.733 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1210/4776 | Loss: 44.437 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1220/4776 | Loss: 25.907 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1230/4776 | Loss: 66.992 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1240/4776 | Loss: 65.205 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1250/4776 | Loss: 89.497 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1260/4776 | Loss: 29.209 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1270/4776 | Loss: 53.661 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1280/4776 | Loss: 56.837 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1290/4776 | Loss: 12.272 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1300/4776 | Loss: 55.693 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1310/4776 | Loss: 58.118 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1320/4776 | Loss: 39.893 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1330/4776 | Loss: 41.096 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1340/4776 | Loss: 20.944 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1350/4776 | Loss: 97.289 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 1360/4776 | Loss: 41.256 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1370/4776 | Loss: 45.049 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1380/4776 | Loss: 18.935 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1390/4776 | Loss: 67.047 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1400/4776 | Loss: 83.900 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1410/4776 | Loss: 40.790 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1420/4776 | Loss: 65.719 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1430/4776 | Loss: 29.369 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1440/4776 | Loss: 55.202 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1450/4776 | Loss: 83.732 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1460/4776 | Loss: 40.896 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1470/4776 | Loss: 94.749 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1480/4776 | Loss: 48.058 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1490/4776 | Loss: 98.458 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1500/4776 | Loss: 25.230 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1510/4776 | Loss: 85.465 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1520/4776 | Loss: 41.314 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1530/4776 | Loss: 32.946 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1540/4776 | Loss: 130.084 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1550/4776 | Loss: 6.955 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1560/4776 | Loss: 37.252 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1570/4776 | Loss: 99.043 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1580/4776 | Loss: 45.964 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1590/4776 | Loss: 75.593 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1600/4776 | Loss: 29.540 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1610/4776 | Loss: 21.463 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1620/4776 | Loss: 43.044 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1630/4776 | Loss: 151.057 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 1640/4776 | Loss: 52.140 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1650/4776 | Loss: 27.387 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1660/4776 | Loss: 23.879 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1670/4776 | Loss: 73.087 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1680/4776 | Loss: 43.237 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1690/4776 | Loss: 30.844 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1700/4776 | Loss: 85.129 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1710/4776 | Loss: 8.288 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1720/4776 | Loss: 106.822 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1730/4776 | Loss: 64.484 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1740/4776 | Loss: 44.154 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1750/4776 | Loss: 55.362 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1760/4776 | Loss: 19.682 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1770/4776 | Loss: 47.935 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1780/4776 | Loss: 46.787 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1790/4776 | Loss: 61.479 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1800/4776 | Loss: 21.819 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1810/4776 | Loss: 46.100 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1820/4776 | Loss: 47.952 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1830/4776 | Loss: 80.041 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 1840/4776 | Loss: 36.891 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1850/4776 | Loss: 20.641 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1860/4776 | Loss: 25.730 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1870/4776 | Loss: 56.994 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1880/4776 | Loss: 74.754 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1890/4776 | Loss: 45.673 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1900/4776 | Loss: 24.994 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1910/4776 | Loss: 19.060 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 1920/4776 | Loss: 89.784 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1930/4776 | Loss: 55.371 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1940/4776 | Loss: 35.903 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 1950/4776 | Loss: 76.256 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1960/4776 | Loss: 26.143 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1970/4776 | Loss: 81.856 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 1980/4776 | Loss: 80.261 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 1990/4776 | Loss: 59.176 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2000/4776 | Loss: 65.970 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2010/4776 | Loss: 46.374 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2020/4776 | Loss: 55.437 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2030/4776 | Loss: 47.574 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2040/4776 | Loss: 57.662 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2050/4776 | Loss: 22.711 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2060/4776 | Loss: 39.329 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2070/4776 | Loss: 50.365 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2080/4776 | Loss: 47.004 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2090/4776 | Loss: 56.307 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2100/4776 | Loss: 62.163 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2110/4776 | Loss: 46.951 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2120/4776 | Loss: 80.189 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2130/4776 | Loss: 55.999 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2140/4776 | Loss: 65.310 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2150/4776 | Loss: 31.534 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 2160/4776 | Loss: 91.294 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2170/4776 | Loss: 55.261 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2180/4776 | Loss: 85.581 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2190/4776 | Loss: 109.272 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2200/4776 | Loss: 56.190 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2210/4776 | Loss: 52.491 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2220/4776 | Loss: 127.989 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 2230/4776 | Loss: 56.173 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2240/4776 | Loss: 43.129 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2250/4776 | Loss: 24.618 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2260/4776 | Loss: 43.448 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2270/4776 | Loss: 24.229 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2280/4776 | Loss: 59.834 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2290/4776 | Loss: 59.702 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2300/4776 | Loss: 78.989 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2310/4776 | Loss: 71.648 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2320/4776 | Loss: 31.997 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2330/4776 | Loss: 60.277 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2340/4776 | Loss: 11.011 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2350/4776 | Loss: 57.628 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2360/4776 | Loss: 101.530 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2370/4776 | Loss: 44.500 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2380/4776 | Loss: 48.027 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2390/4776 | Loss: 57.980 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2400/4776 | Loss: 38.806 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2410/4776 | Loss: 36.271 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2420/4776 | Loss: 113.873 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2430/4776 | Loss: 28.778 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2440/4776 | Loss: 77.436 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2450/4776 | Loss: 108.436 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 2460/4776 | Loss: 48.692 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2470/4776 | Loss: 31.854 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2480/4776 | Loss: 35.226 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2490/4776 | Loss: 49.852 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2500/4776 | Loss: 74.352 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2510/4776 | Loss: 101.428 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2520/4776 | Loss: 64.579 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2530/4776 | Loss: 33.156 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2540/4776 | Loss: 53.486 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2550/4776 | Loss: 60.799 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2560/4776 | Loss: 24.359 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2570/4776 | Loss: 16.553 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2580/4776 | Loss: 55.994 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2590/4776 | Loss: 47.617 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2600/4776 | Loss: 29.221 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2610/4776 | Loss: 33.197 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2620/4776 | Loss: 48.369 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2630/4776 | Loss: 48.226 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2640/4776 | Loss: 106.920 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 2650/4776 | Loss: 18.456 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2660/4776 | Loss: 37.953 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2670/4776 | Loss: 9.105 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 2680/4776 | Loss: 34.825 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 2690/4776 | Loss: 89.486 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2700/4776 | Loss: 71.818 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2710/4776 | Loss: 49.297 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2720/4776 | Loss: 37.834 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2730/4776 | Loss: 114.993 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2740/4776 | Loss: 26.459 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2750/4776 | Loss: 77.480 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2760/4776 | Loss: 39.889 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2770/4776 | Loss: 42.304 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2780/4776 | Loss: 4.231 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 2790/4776 | Loss: 51.238 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2800/4776 | Loss: 31.605 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2810/4776 | Loss: 96.223 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2820/4776 | Loss: 21.234 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2830/4776 | Loss: 29.066 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2840/4776 | Loss: 105.917 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2850/4776 | Loss: 87.775 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2860/4776 | Loss: 67.785 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2870/4776 | Loss: 79.635 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2880/4776 | Loss: 167.400 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 2890/4776 | Loss: 52.633 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2900/4776 | Loss: 37.179 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2910/4776 | Loss: 64.664 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2920/4776 | Loss: 65.893 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2930/4776 | Loss: 49.026 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2940/4776 | Loss: 13.086 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 2950/4776 | Loss: 119.084 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 2960/4776 | Loss: 95.866 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 2970/4776 | Loss: 49.653 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 2980/4776 | Loss: 14.604 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 2990/4776 | Loss: 65.319 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3000/4776 | Loss: 33.474 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3010/4776 | Loss: 17.191 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3020/4776 | Loss: 36.921 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3030/4776 | Loss: 48.454 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3040/4776 | Loss: 59.978 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3050/4776 | Loss: 69.287 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3060/4776 | Loss: 109.035 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3070/4776 | Loss: 125.282 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3080/4776 | Loss: 103.534 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3090/4776 | Loss: 78.975 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3100/4776 | Loss: 29.223 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3110/4776 | Loss: 15.057 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3120/4776 | Loss: 31.945 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3130/4776 | Loss: 56.493 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3140/4776 | Loss: 111.662 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3150/4776 | Loss: 30.644 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3160/4776 | Loss: 61.567 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3170/4776 | Loss: 68.000 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3180/4776 | Loss: 22.625 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3190/4776 | Loss: 90.836 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3200/4776 | Loss: 55.198 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3210/4776 | Loss: 66.011 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3220/4776 | Loss: 198.310 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3230/4776 | Loss: 50.690 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3240/4776 | Loss: 48.124 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3250/4776 | Loss: 69.430 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3260/4776 | Loss: 19.452 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3270/4776 | Loss: 147.519 | Accuracy: 0.300\n",
      "[Epoch: 77/200] - Step: 3280/4776 | Loss: 50.965 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3290/4776 | Loss: 47.918 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3300/4776 | Loss: 49.101 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3310/4776 | Loss: 35.078 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3320/4776 | Loss: 72.923 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3330/4776 | Loss: 122.749 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3340/4776 | Loss: 61.345 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3350/4776 | Loss: 65.765 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3360/4776 | Loss: 105.505 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3370/4776 | Loss: 132.161 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3380/4776 | Loss: 85.590 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3390/4776 | Loss: 42.900 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3400/4776 | Loss: 46.599 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3410/4776 | Loss: 46.656 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3420/4776 | Loss: 89.328 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3430/4776 | Loss: 66.443 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3440/4776 | Loss: 36.411 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3450/4776 | Loss: 80.013 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3460/4776 | Loss: 156.402 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3470/4776 | Loss: 96.510 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3480/4776 | Loss: 152.194 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3490/4776 | Loss: 71.753 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3500/4776 | Loss: 34.651 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3510/4776 | Loss: 96.005 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3520/4776 | Loss: 66.155 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3530/4776 | Loss: 36.412 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3540/4776 | Loss: 75.581 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3550/4776 | Loss: 57.071 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3560/4776 | Loss: 77.245 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3570/4776 | Loss: 115.088 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3580/4776 | Loss: 54.110 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3590/4776 | Loss: 92.582 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3600/4776 | Loss: 45.926 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3610/4776 | Loss: 11.498 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3620/4776 | Loss: 71.617 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3630/4776 | Loss: 42.216 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3640/4776 | Loss: 90.714 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3650/4776 | Loss: 9.764 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3660/4776 | Loss: 97.034 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3670/4776 | Loss: 70.371 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3680/4776 | Loss: 124.583 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3690/4776 | Loss: 72.996 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3700/4776 | Loss: 114.939 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 3710/4776 | Loss: 37.032 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3720/4776 | Loss: 55.858 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3730/4776 | Loss: 16.211 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3740/4776 | Loss: 119.839 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3750/4776 | Loss: 34.658 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3760/4776 | Loss: 142.553 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 3770/4776 | Loss: 102.622 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3780/4776 | Loss: 83.367 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3790/4776 | Loss: 28.004 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3800/4776 | Loss: 53.745 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3810/4776 | Loss: 81.691 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3820/4776 | Loss: 62.011 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3830/4776 | Loss: 35.907 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3840/4776 | Loss: 48.070 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3850/4776 | Loss: 58.460 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3860/4776 | Loss: 77.913 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3870/4776 | Loss: 44.077 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3880/4776 | Loss: 15.518 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3890/4776 | Loss: 24.620 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3900/4776 | Loss: 71.132 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3910/4776 | Loss: 17.311 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 3920/4776 | Loss: 129.246 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 3930/4776 | Loss: 60.338 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3940/4776 | Loss: 108.134 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 3950/4776 | Loss: 55.185 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3960/4776 | Loss: 90.082 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3970/4776 | Loss: 41.922 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 3980/4776 | Loss: 47.283 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 3990/4776 | Loss: 61.438 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4000/4776 | Loss: 21.261 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4010/4776 | Loss: 55.187 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4020/4776 | Loss: 12.249 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 4030/4776 | Loss: 68.149 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4040/4776 | Loss: 53.474 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4050/4776 | Loss: 25.467 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4060/4776 | Loss: 56.147 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4070/4776 | Loss: 44.774 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4080/4776 | Loss: 67.179 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4090/4776 | Loss: 59.331 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4100/4776 | Loss: 11.072 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 4110/4776 | Loss: 35.008 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4120/4776 | Loss: 29.394 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4130/4776 | Loss: 45.661 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4140/4776 | Loss: 103.740 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4150/4776 | Loss: 62.240 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4160/4776 | Loss: 104.431 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 4170/4776 | Loss: 98.593 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4180/4776 | Loss: 16.425 | Accuracy: 1.000\n",
      "[Epoch: 77/200] - Step: 4190/4776 | Loss: 22.210 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4200/4776 | Loss: 28.221 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4210/4776 | Loss: 23.680 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4220/4776 | Loss: 52.508 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4230/4776 | Loss: 62.069 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4240/4776 | Loss: 57.147 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4250/4776 | Loss: 95.126 | Accuracy: 0.500\n",
      "[Epoch: 77/200] - Step: 4260/4776 | Loss: 39.849 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4270/4776 | Loss: 46.354 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4280/4776 | Loss: 18.982 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4290/4776 | Loss: 36.909 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4300/4776 | Loss: 33.517 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4310/4776 | Loss: 82.681 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4320/4776 | Loss: 58.713 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4330/4776 | Loss: 39.380 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4340/4776 | Loss: 28.717 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4350/4776 | Loss: 84.044 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4360/4776 | Loss: 49.409 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4370/4776 | Loss: 44.616 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4380/4776 | Loss: 53.180 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4390/4776 | Loss: 45.628 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4400/4776 | Loss: 47.817 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4410/4776 | Loss: 56.573 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4420/4776 | Loss: 70.996 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4430/4776 | Loss: 23.014 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4440/4776 | Loss: 24.709 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4450/4776 | Loss: 39.184 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4460/4776 | Loss: 32.827 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4470/4776 | Loss: 33.379 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4480/4776 | Loss: 93.503 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4490/4776 | Loss: 67.058 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4500/4776 | Loss: 75.952 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4510/4776 | Loss: 62.262 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4520/4776 | Loss: 135.842 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 4530/4776 | Loss: 51.408 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4540/4776 | Loss: 38.380 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4550/4776 | Loss: 104.549 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4560/4776 | Loss: 94.810 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4570/4776 | Loss: 27.274 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4580/4776 | Loss: 57.600 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4590/4776 | Loss: 58.041 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4600/4776 | Loss: 38.866 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4610/4776 | Loss: 49.683 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4620/4776 | Loss: 79.790 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4630/4776 | Loss: 44.348 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4640/4776 | Loss: 22.769 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4650/4776 | Loss: 79.125 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4660/4776 | Loss: 46.106 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4670/4776 | Loss: 44.887 | Accuracy: 0.900\n",
      "[Epoch: 77/200] - Step: 4680/4776 | Loss: 62.648 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4690/4776 | Loss: 39.474 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4700/4776 | Loss: 106.103 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4710/4776 | Loss: 67.493 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4720/4776 | Loss: 62.723 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4730/4776 | Loss: 32.612 | Accuracy: 0.800\n",
      "[Epoch: 77/200] - Step: 4740/4776 | Loss: 213.705 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 4750/4776 | Loss: 127.796 | Accuracy: 0.600\n",
      "[Epoch: 77/200] - Step: 4760/4776 | Loss: 83.342 | Accuracy: 0.700\n",
      "[Epoch: 77/200] - Step: 4770/4776 | Loss: 47.508 | Accuracy: 0.800\n",
      "Accuracy:  0.19344262295081968\n",
      "[Epoch: 78/200] - Step: 10/4776 | Loss: 82.608 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 20/4776 | Loss: 73.472 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 30/4776 | Loss: 104.169 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 40/4776 | Loss: 28.365 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 50/4776 | Loss: 31.086 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 60/4776 | Loss: 32.708 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 70/4776 | Loss: 41.879 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 80/4776 | Loss: 56.865 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 90/4776 | Loss: 69.016 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 100/4776 | Loss: 16.174 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 110/4776 | Loss: 84.477 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 120/4776 | Loss: 54.309 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 130/4776 | Loss: 45.418 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 140/4776 | Loss: 124.230 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 150/4776 | Loss: 13.867 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 160/4776 | Loss: 80.423 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 170/4776 | Loss: 119.371 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 180/4776 | Loss: 47.885 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 190/4776 | Loss: 83.396 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 200/4776 | Loss: 35.017 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 210/4776 | Loss: 60.159 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 220/4776 | Loss: 76.858 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 230/4776 | Loss: 25.863 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 240/4776 | Loss: 57.034 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 250/4776 | Loss: 37.431 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 260/4776 | Loss: 50.801 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 270/4776 | Loss: 52.475 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 280/4776 | Loss: 7.602 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 290/4776 | Loss: 63.852 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 300/4776 | Loss: 23.984 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 310/4776 | Loss: 38.902 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 320/4776 | Loss: 30.302 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 330/4776 | Loss: 34.955 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 340/4776 | Loss: 48.178 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 350/4776 | Loss: 97.405 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 360/4776 | Loss: 25.579 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 370/4776 | Loss: 33.032 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 380/4776 | Loss: 47.567 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 390/4776 | Loss: 14.714 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 400/4776 | Loss: 73.089 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 410/4776 | Loss: 27.099 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 420/4776 | Loss: 34.545 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 430/4776 | Loss: 59.380 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 440/4776 | Loss: 28.657 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 450/4776 | Loss: 38.669 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 460/4776 | Loss: 63.313 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 470/4776 | Loss: 49.589 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 480/4776 | Loss: 20.491 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 490/4776 | Loss: 43.759 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 500/4776 | Loss: 77.299 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 510/4776 | Loss: 61.290 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 520/4776 | Loss: 26.295 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 530/4776 | Loss: 62.322 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 540/4776 | Loss: 41.855 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 550/4776 | Loss: 50.281 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 560/4776 | Loss: 59.766 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 570/4776 | Loss: 29.710 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 580/4776 | Loss: 1.902 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 590/4776 | Loss: 71.150 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 600/4776 | Loss: 56.005 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 610/4776 | Loss: 77.200 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 620/4776 | Loss: 32.900 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 630/4776 | Loss: 71.365 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 640/4776 | Loss: 33.724 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 650/4776 | Loss: 32.426 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 660/4776 | Loss: 24.084 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 670/4776 | Loss: 28.917 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 680/4776 | Loss: 46.492 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 690/4776 | Loss: 34.325 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 700/4776 | Loss: 29.090 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 710/4776 | Loss: 61.064 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 720/4776 | Loss: 52.093 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 730/4776 | Loss: 84.281 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 740/4776 | Loss: 135.407 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 750/4776 | Loss: 23.697 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 760/4776 | Loss: 75.383 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 770/4776 | Loss: 142.156 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 780/4776 | Loss: 149.393 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 790/4776 | Loss: 116.424 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 800/4776 | Loss: 139.858 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 810/4776 | Loss: 64.120 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 820/4776 | Loss: 80.723 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 830/4776 | Loss: 73.889 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 840/4776 | Loss: 108.428 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 850/4776 | Loss: 47.633 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 860/4776 | Loss: 69.517 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 870/4776 | Loss: 47.696 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 880/4776 | Loss: 44.274 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 890/4776 | Loss: 102.745 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 900/4776 | Loss: 66.016 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 910/4776 | Loss: 18.293 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 920/4776 | Loss: 81.464 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 930/4776 | Loss: 71.991 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 940/4776 | Loss: 52.550 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 950/4776 | Loss: 60.080 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 960/4776 | Loss: 43.312 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 970/4776 | Loss: 37.290 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 980/4776 | Loss: 24.950 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 990/4776 | Loss: 123.026 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 1000/4776 | Loss: 94.318 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1010/4776 | Loss: 24.897 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1020/4776 | Loss: 73.752 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1030/4776 | Loss: 54.086 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1040/4776 | Loss: 22.576 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1050/4776 | Loss: 88.624 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1060/4776 | Loss: 72.756 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1070/4776 | Loss: 51.675 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1080/4776 | Loss: 12.348 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1090/4776 | Loss: 72.376 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1100/4776 | Loss: 53.461 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1110/4776 | Loss: 19.944 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1120/4776 | Loss: 72.926 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1130/4776 | Loss: 69.214 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1140/4776 | Loss: 28.581 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1150/4776 | Loss: 63.895 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1160/4776 | Loss: 35.420 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1170/4776 | Loss: 78.807 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1180/4776 | Loss: 93.818 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 1190/4776 | Loss: 56.873 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1200/4776 | Loss: 111.889 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1210/4776 | Loss: 51.371 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1220/4776 | Loss: 38.870 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1230/4776 | Loss: 13.671 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1240/4776 | Loss: 31.750 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1250/4776 | Loss: 94.486 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 1260/4776 | Loss: 32.296 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1270/4776 | Loss: 49.713 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1280/4776 | Loss: 49.361 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1290/4776 | Loss: 80.320 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1300/4776 | Loss: 73.505 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1310/4776 | Loss: 42.544 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1320/4776 | Loss: 147.179 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1330/4776 | Loss: 47.995 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1340/4776 | Loss: 49.975 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1350/4776 | Loss: 22.611 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1360/4776 | Loss: 67.699 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1370/4776 | Loss: 49.663 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1380/4776 | Loss: 132.610 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 1390/4776 | Loss: 140.373 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1400/4776 | Loss: 17.490 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1410/4776 | Loss: 193.862 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1420/4776 | Loss: 39.400 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1430/4776 | Loss: 111.421 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1440/4776 | Loss: 135.071 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1450/4776 | Loss: 35.517 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1460/4776 | Loss: 52.220 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1470/4776 | Loss: 128.911 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1480/4776 | Loss: 45.626 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1490/4776 | Loss: 20.810 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1500/4776 | Loss: 17.001 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1510/4776 | Loss: 17.835 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1520/4776 | Loss: 59.947 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1530/4776 | Loss: 79.230 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1540/4776 | Loss: 65.077 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1550/4776 | Loss: 119.656 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1560/4776 | Loss: 45.123 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1570/4776 | Loss: 122.170 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1580/4776 | Loss: 131.417 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1590/4776 | Loss: 48.831 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1600/4776 | Loss: 89.273 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1610/4776 | Loss: 76.419 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1620/4776 | Loss: 49.614 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1630/4776 | Loss: 45.962 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1640/4776 | Loss: 37.485 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1650/4776 | Loss: 66.733 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1660/4776 | Loss: 87.107 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1670/4776 | Loss: 45.713 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1680/4776 | Loss: 85.997 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1690/4776 | Loss: 57.207 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1700/4776 | Loss: 115.089 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1710/4776 | Loss: 83.883 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1720/4776 | Loss: 55.989 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1730/4776 | Loss: 108.938 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1740/4776 | Loss: 40.739 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1750/4776 | Loss: 66.304 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1760/4776 | Loss: 40.368 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1770/4776 | Loss: 76.799 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1780/4776 | Loss: 24.337 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1790/4776 | Loss: 83.639 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1800/4776 | Loss: 25.709 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1810/4776 | Loss: 24.172 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1820/4776 | Loss: 24.600 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1830/4776 | Loss: 46.371 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1840/4776 | Loss: 88.279 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 1850/4776 | Loss: 29.918 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1860/4776 | Loss: 37.478 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1870/4776 | Loss: 49.784 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1880/4776 | Loss: 15.694 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1890/4776 | Loss: 58.669 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1900/4776 | Loss: 84.846 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 1910/4776 | Loss: 37.380 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1920/4776 | Loss: 38.823 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 1930/4776 | Loss: 41.516 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1940/4776 | Loss: 42.752 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1950/4776 | Loss: 17.520 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1960/4776 | Loss: 49.342 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 1970/4776 | Loss: 74.308 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1980/4776 | Loss: 27.147 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 1990/4776 | Loss: 69.393 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2000/4776 | Loss: 68.335 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2010/4776 | Loss: 25.568 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2020/4776 | Loss: 61.766 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2030/4776 | Loss: 43.154 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2040/4776 | Loss: 33.716 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2050/4776 | Loss: 57.757 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2060/4776 | Loss: 45.915 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2070/4776 | Loss: 75.099 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2080/4776 | Loss: 106.330 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2090/4776 | Loss: 88.805 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2100/4776 | Loss: 82.825 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2110/4776 | Loss: 29.543 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2120/4776 | Loss: 63.908 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2130/4776 | Loss: 39.575 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2140/4776 | Loss: 71.628 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2150/4776 | Loss: 40.623 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2160/4776 | Loss: 52.230 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2170/4776 | Loss: 42.907 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2180/4776 | Loss: 48.613 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2190/4776 | Loss: 12.935 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2200/4776 | Loss: 38.675 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2210/4776 | Loss: 61.908 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2220/4776 | Loss: 63.606 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2230/4776 | Loss: 4.826 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2240/4776 | Loss: 35.370 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2250/4776 | Loss: 63.663 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2260/4776 | Loss: 43.829 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2270/4776 | Loss: 78.760 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2280/4776 | Loss: 7.042 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2290/4776 | Loss: 27.494 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2300/4776 | Loss: 20.348 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2310/4776 | Loss: 25.593 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2320/4776 | Loss: 38.644 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2330/4776 | Loss: 14.360 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2340/4776 | Loss: 65.144 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2350/4776 | Loss: 5.827 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2360/4776 | Loss: 40.469 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2370/4776 | Loss: 37.597 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2380/4776 | Loss: 19.892 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2390/4776 | Loss: 58.042 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2400/4776 | Loss: 68.897 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2410/4776 | Loss: 41.859 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2420/4776 | Loss: 114.313 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2430/4776 | Loss: 24.809 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2440/4776 | Loss: 58.813 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2450/4776 | Loss: 142.430 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2460/4776 | Loss: 43.683 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2470/4776 | Loss: 112.419 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2480/4776 | Loss: 152.761 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2490/4776 | Loss: 57.840 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2500/4776 | Loss: 24.224 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2510/4776 | Loss: 101.864 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2520/4776 | Loss: 53.906 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2530/4776 | Loss: 87.851 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2540/4776 | Loss: 22.199 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2550/4776 | Loss: 49.301 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2560/4776 | Loss: 66.136 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2570/4776 | Loss: 34.587 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2580/4776 | Loss: 15.459 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2590/4776 | Loss: 75.618 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2600/4776 | Loss: 40.695 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2610/4776 | Loss: 18.316 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2620/4776 | Loss: 158.155 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2630/4776 | Loss: 67.230 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2640/4776 | Loss: 69.454 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2650/4776 | Loss: 95.596 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2660/4776 | Loss: 63.168 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2670/4776 | Loss: 39.624 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2680/4776 | Loss: 86.413 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2690/4776 | Loss: 138.825 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2700/4776 | Loss: 55.064 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2710/4776 | Loss: 59.866 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2720/4776 | Loss: 37.294 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2730/4776 | Loss: 37.961 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2740/4776 | Loss: 23.067 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2750/4776 | Loss: 51.338 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2760/4776 | Loss: 70.178 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2770/4776 | Loss: 87.918 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2780/4776 | Loss: 61.958 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2790/4776 | Loss: 18.790 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2800/4776 | Loss: 28.923 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2810/4776 | Loss: 66.603 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2820/4776 | Loss: 147.879 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 2830/4776 | Loss: 120.238 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 2840/4776 | Loss: 17.250 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 2850/4776 | Loss: 85.399 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2860/4776 | Loss: 193.249 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 2870/4776 | Loss: 86.527 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2880/4776 | Loss: 54.318 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2890/4776 | Loss: 113.775 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2900/4776 | Loss: 31.369 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2910/4776 | Loss: 70.782 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2920/4776 | Loss: 46.615 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 2930/4776 | Loss: 85.970 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2940/4776 | Loss: 60.221 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2950/4776 | Loss: 88.696 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 2960/4776 | Loss: 65.221 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 2970/4776 | Loss: 66.145 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2980/4776 | Loss: 70.789 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 2990/4776 | Loss: 99.227 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 3000/4776 | Loss: 22.700 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3010/4776 | Loss: 51.809 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3020/4776 | Loss: 39.335 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3030/4776 | Loss: 117.743 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3040/4776 | Loss: 80.081 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3050/4776 | Loss: 44.651 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3060/4776 | Loss: 13.687 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3070/4776 | Loss: 80.950 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3080/4776 | Loss: 54.967 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3090/4776 | Loss: 67.585 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3100/4776 | Loss: 111.306 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3110/4776 | Loss: 64.533 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3120/4776 | Loss: 18.927 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3130/4776 | Loss: 94.884 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3140/4776 | Loss: 57.811 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3150/4776 | Loss: 17.079 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3160/4776 | Loss: 101.493 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3170/4776 | Loss: 47.557 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3180/4776 | Loss: 8.263 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3190/4776 | Loss: 76.257 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3200/4776 | Loss: 58.577 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3210/4776 | Loss: 137.195 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 3220/4776 | Loss: 38.703 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3230/4776 | Loss: 57.263 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3240/4776 | Loss: 30.872 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3250/4776 | Loss: 28.389 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3260/4776 | Loss: 97.797 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3270/4776 | Loss: 19.153 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3280/4776 | Loss: 52.445 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3290/4776 | Loss: 17.593 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3300/4776 | Loss: 31.538 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3310/4776 | Loss: 48.828 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3320/4776 | Loss: 18.396 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3330/4776 | Loss: 61.875 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3340/4776 | Loss: 4.722 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3350/4776 | Loss: 118.741 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3360/4776 | Loss: 59.163 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3370/4776 | Loss: 100.803 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3380/4776 | Loss: 17.559 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3390/4776 | Loss: 61.659 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3400/4776 | Loss: 54.488 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3410/4776 | Loss: 69.962 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3420/4776 | Loss: 127.357 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 3430/4776 | Loss: 22.199 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3440/4776 | Loss: 44.163 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3450/4776 | Loss: 62.448 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3460/4776 | Loss: 71.152 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3470/4776 | Loss: 45.946 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3480/4776 | Loss: 83.385 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3490/4776 | Loss: 20.279 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3500/4776 | Loss: 24.461 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3510/4776 | Loss: 76.435 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3520/4776 | Loss: 30.549 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3530/4776 | Loss: 33.080 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3540/4776 | Loss: 79.933 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3550/4776 | Loss: 56.833 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3560/4776 | Loss: 123.064 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 3570/4776 | Loss: 94.796 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3580/4776 | Loss: 92.042 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3590/4776 | Loss: 51.258 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3600/4776 | Loss: 41.161 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3610/4776 | Loss: 75.257 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3620/4776 | Loss: 34.687 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3630/4776 | Loss: 56.956 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3640/4776 | Loss: 67.923 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3650/4776 | Loss: 16.136 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3660/4776 | Loss: 31.451 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3670/4776 | Loss: 24.556 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3680/4776 | Loss: 98.339 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3690/4776 | Loss: 31.732 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3700/4776 | Loss: 55.201 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3710/4776 | Loss: 38.176 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3720/4776 | Loss: 43.477 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3730/4776 | Loss: 108.513 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3740/4776 | Loss: 59.516 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3750/4776 | Loss: 89.294 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3760/4776 | Loss: 105.151 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3770/4776 | Loss: 47.478 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3780/4776 | Loss: 116.623 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3790/4776 | Loss: 71.138 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3800/4776 | Loss: 87.232 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3810/4776 | Loss: 134.099 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3820/4776 | Loss: 46.132 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3830/4776 | Loss: 46.467 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3840/4776 | Loss: 44.758 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3850/4776 | Loss: 33.084 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3860/4776 | Loss: 54.699 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3870/4776 | Loss: 15.063 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3880/4776 | Loss: 16.296 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 3890/4776 | Loss: 25.630 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3900/4776 | Loss: 44.636 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 3910/4776 | Loss: 76.179 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3920/4776 | Loss: 85.641 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3930/4776 | Loss: 90.389 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3940/4776 | Loss: 121.045 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 3950/4776 | Loss: 53.198 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3960/4776 | Loss: 51.829 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 3970/4776 | Loss: 132.884 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 3980/4776 | Loss: 145.668 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 3990/4776 | Loss: 72.802 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4000/4776 | Loss: 62.265 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4010/4776 | Loss: 37.747 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4020/4776 | Loss: 64.755 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4030/4776 | Loss: 52.209 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4040/4776 | Loss: 50.065 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4050/4776 | Loss: 46.381 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4060/4776 | Loss: 51.866 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4070/4776 | Loss: 60.594 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4080/4776 | Loss: 79.306 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4090/4776 | Loss: 61.189 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4100/4776 | Loss: 106.576 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4110/4776 | Loss: 93.338 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 4120/4776 | Loss: 89.260 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4130/4776 | Loss: 47.055 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4140/4776 | Loss: 93.792 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4150/4776 | Loss: 56.974 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4160/4776 | Loss: 70.728 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4170/4776 | Loss: 165.877 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 4180/4776 | Loss: 84.003 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4190/4776 | Loss: 101.344 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4200/4776 | Loss: 140.183 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4210/4776 | Loss: 158.097 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4220/4776 | Loss: 95.721 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4230/4776 | Loss: 89.125 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4240/4776 | Loss: 35.077 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4250/4776 | Loss: 75.610 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4260/4776 | Loss: 66.133 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4270/4776 | Loss: 75.381 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4280/4776 | Loss: 90.940 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 4290/4776 | Loss: 71.987 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4300/4776 | Loss: 75.115 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4310/4776 | Loss: 48.706 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4320/4776 | Loss: 175.024 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4330/4776 | Loss: 88.085 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4340/4776 | Loss: 42.355 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4350/4776 | Loss: 45.076 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4360/4776 | Loss: 68.465 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4370/4776 | Loss: 78.465 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4380/4776 | Loss: 52.170 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4390/4776 | Loss: 101.683 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4400/4776 | Loss: 113.966 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 4410/4776 | Loss: 79.145 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4420/4776 | Loss: 72.606 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4430/4776 | Loss: 8.863 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 4440/4776 | Loss: 42.844 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4450/4776 | Loss: 55.004 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4460/4776 | Loss: 43.117 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4470/4776 | Loss: 76.103 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4480/4776 | Loss: 68.233 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4490/4776 | Loss: 105.668 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 4500/4776 | Loss: 73.545 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4510/4776 | Loss: 58.506 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4520/4776 | Loss: 69.612 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4530/4776 | Loss: 51.271 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4540/4776 | Loss: 56.375 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4550/4776 | Loss: 39.364 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4560/4776 | Loss: 77.162 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4570/4776 | Loss: 65.449 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4580/4776 | Loss: 46.465 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4590/4776 | Loss: 109.765 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4600/4776 | Loss: 29.102 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4610/4776 | Loss: 76.882 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4620/4776 | Loss: 16.681 | Accuracy: 1.000\n",
      "[Epoch: 78/200] - Step: 4630/4776 | Loss: 91.337 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 4640/4776 | Loss: 40.994 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4650/4776 | Loss: 58.622 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4660/4776 | Loss: 32.187 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4670/4776 | Loss: 54.451 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4680/4776 | Loss: 43.194 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4690/4776 | Loss: 46.771 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4700/4776 | Loss: 56.517 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4710/4776 | Loss: 21.082 | Accuracy: 0.900\n",
      "[Epoch: 78/200] - Step: 4720/4776 | Loss: 98.363 | Accuracy: 0.700\n",
      "[Epoch: 78/200] - Step: 4730/4776 | Loss: 136.732 | Accuracy: 0.400\n",
      "[Epoch: 78/200] - Step: 4740/4776 | Loss: 76.971 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 4750/4776 | Loss: 58.173 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4760/4776 | Loss: 69.849 | Accuracy: 0.800\n",
      "[Epoch: 78/200] - Step: 4770/4776 | Loss: 34.753 | Accuracy: 0.900\n",
      "Accuracy:  0.22459016393442624\n",
      "[Epoch: 79/200] - Step: 10/4776 | Loss: 32.363 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 20/4776 | Loss: 127.676 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 30/4776 | Loss: 135.208 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 40/4776 | Loss: 78.793 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 50/4776 | Loss: 47.784 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 60/4776 | Loss: 52.449 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 70/4776 | Loss: 84.143 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 80/4776 | Loss: 25.973 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 90/4776 | Loss: 36.664 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 100/4776 | Loss: 56.038 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 110/4776 | Loss: 48.856 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 120/4776 | Loss: 64.955 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 130/4776 | Loss: 38.857 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 140/4776 | Loss: 103.859 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 150/4776 | Loss: 62.939 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 160/4776 | Loss: 75.812 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 170/4776 | Loss: 109.607 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 180/4776 | Loss: 33.843 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 190/4776 | Loss: 38.612 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 200/4776 | Loss: 48.719 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 210/4776 | Loss: 42.633 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 220/4776 | Loss: 44.004 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 230/4776 | Loss: 26.269 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 240/4776 | Loss: 49.432 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 250/4776 | Loss: 25.406 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 260/4776 | Loss: 11.324 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 270/4776 | Loss: 33.903 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 280/4776 | Loss: 6.286 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 290/4776 | Loss: 26.342 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 300/4776 | Loss: 60.285 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 310/4776 | Loss: 40.970 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 320/4776 | Loss: 3.658 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 330/4776 | Loss: 35.597 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 340/4776 | Loss: 87.901 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 350/4776 | Loss: 69.689 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 360/4776 | Loss: 17.467 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 370/4776 | Loss: 68.679 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 380/4776 | Loss: 70.069 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 390/4776 | Loss: 59.167 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 400/4776 | Loss: 77.048 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 410/4776 | Loss: 25.151 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 420/4776 | Loss: 42.017 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 430/4776 | Loss: 64.784 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 440/4776 | Loss: 55.060 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 450/4776 | Loss: 41.582 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 460/4776 | Loss: 38.874 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 470/4776 | Loss: 63.340 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 480/4776 | Loss: 49.442 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 490/4776 | Loss: 22.469 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 500/4776 | Loss: 15.007 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 510/4776 | Loss: 76.143 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 520/4776 | Loss: 48.956 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 530/4776 | Loss: 51.222 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 540/4776 | Loss: 40.065 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 550/4776 | Loss: 70.942 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 560/4776 | Loss: 22.887 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 570/4776 | Loss: 61.687 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 580/4776 | Loss: 22.315 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 590/4776 | Loss: 47.835 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 600/4776 | Loss: 65.322 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 610/4776 | Loss: 61.267 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 620/4776 | Loss: 93.861 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 630/4776 | Loss: 26.361 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 640/4776 | Loss: 114.710 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 650/4776 | Loss: 40.036 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 660/4776 | Loss: 73.331 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 670/4776 | Loss: 27.426 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 680/4776 | Loss: 82.624 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 690/4776 | Loss: 71.055 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 700/4776 | Loss: 82.665 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 710/4776 | Loss: 25.629 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 720/4776 | Loss: 78.295 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 730/4776 | Loss: 101.074 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 740/4776 | Loss: 24.647 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 750/4776 | Loss: 48.371 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 760/4776 | Loss: 37.528 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 770/4776 | Loss: 78.298 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 780/4776 | Loss: 56.776 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 790/4776 | Loss: 31.811 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 800/4776 | Loss: 50.176 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 810/4776 | Loss: 109.308 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 820/4776 | Loss: 80.331 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 830/4776 | Loss: 91.253 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 840/4776 | Loss: 60.435 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 850/4776 | Loss: 61.307 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 860/4776 | Loss: 35.567 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 870/4776 | Loss: 29.561 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 880/4776 | Loss: 42.325 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 890/4776 | Loss: 66.792 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 900/4776 | Loss: 40.986 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 910/4776 | Loss: 91.499 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 920/4776 | Loss: 44.262 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 930/4776 | Loss: 33.264 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 940/4776 | Loss: 60.241 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 950/4776 | Loss: 24.730 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 960/4776 | Loss: 53.002 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 970/4776 | Loss: 34.035 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 980/4776 | Loss: 15.756 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 990/4776 | Loss: 30.440 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1000/4776 | Loss: 34.935 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1010/4776 | Loss: 25.971 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1020/4776 | Loss: 58.484 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1030/4776 | Loss: 21.144 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1040/4776 | Loss: 18.318 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1050/4776 | Loss: 91.171 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1060/4776 | Loss: 89.058 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1070/4776 | Loss: 88.170 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 1080/4776 | Loss: 71.159 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1090/4776 | Loss: 74.023 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1100/4776 | Loss: 34.536 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1110/4776 | Loss: 100.721 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1120/4776 | Loss: 81.969 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1130/4776 | Loss: 16.492 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1140/4776 | Loss: 69.842 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1150/4776 | Loss: 45.069 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1160/4776 | Loss: 94.086 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1170/4776 | Loss: 95.075 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1180/4776 | Loss: 29.210 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1190/4776 | Loss: 8.345 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1200/4776 | Loss: 95.366 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1210/4776 | Loss: 7.375 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1220/4776 | Loss: 57.606 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1230/4776 | Loss: 22.506 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1240/4776 | Loss: 24.199 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1250/4776 | Loss: 35.943 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1260/4776 | Loss: 78.074 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1270/4776 | Loss: 24.290 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1280/4776 | Loss: 46.005 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1290/4776 | Loss: 37.566 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1300/4776 | Loss: 48.540 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1310/4776 | Loss: 68.651 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1320/4776 | Loss: 88.210 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1330/4776 | Loss: 102.295 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1340/4776 | Loss: 88.212 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1350/4776 | Loss: 44.442 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1360/4776 | Loss: 7.252 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1370/4776 | Loss: 58.821 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1380/4776 | Loss: 40.652 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1390/4776 | Loss: 82.787 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1400/4776 | Loss: 86.428 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1410/4776 | Loss: 84.789 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1420/4776 | Loss: 50.350 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1430/4776 | Loss: 16.246 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1440/4776 | Loss: 98.012 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1450/4776 | Loss: 60.508 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1460/4776 | Loss: 43.657 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1470/4776 | Loss: 23.996 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1480/4776 | Loss: 33.921 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1490/4776 | Loss: 38.813 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1500/4776 | Loss: 22.819 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1510/4776 | Loss: 32.278 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1520/4776 | Loss: 50.376 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1530/4776 | Loss: 76.171 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1540/4776 | Loss: 100.770 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 1550/4776 | Loss: 42.284 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1560/4776 | Loss: 32.641 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1570/4776 | Loss: 144.557 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1580/4776 | Loss: 94.372 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 1590/4776 | Loss: 126.144 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1600/4776 | Loss: 33.843 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1610/4776 | Loss: 44.824 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1620/4776 | Loss: 36.846 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1630/4776 | Loss: 45.826 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1640/4776 | Loss: 40.531 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1650/4776 | Loss: 72.194 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1660/4776 | Loss: 122.160 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 1670/4776 | Loss: 137.716 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1680/4776 | Loss: 23.237 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1690/4776 | Loss: 37.583 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1700/4776 | Loss: 59.865 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1710/4776 | Loss: 103.557 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1720/4776 | Loss: 84.258 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1730/4776 | Loss: 6.542 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1740/4776 | Loss: 33.023 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1750/4776 | Loss: 54.137 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1760/4776 | Loss: 58.593 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1770/4776 | Loss: 27.979 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1780/4776 | Loss: 98.128 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1790/4776 | Loss: 52.243 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1800/4776 | Loss: 59.254 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1810/4776 | Loss: 19.377 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 1820/4776 | Loss: 88.735 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1830/4776 | Loss: 43.571 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1840/4776 | Loss: 25.737 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1850/4776 | Loss: 59.743 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 1860/4776 | Loss: 75.245 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1870/4776 | Loss: 100.254 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1880/4776 | Loss: 37.920 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1890/4776 | Loss: 37.868 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1900/4776 | Loss: 50.246 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1910/4776 | Loss: 93.302 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 1920/4776 | Loss: 78.845 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1930/4776 | Loss: 51.962 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1940/4776 | Loss: 50.801 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1950/4776 | Loss: 77.112 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 1960/4776 | Loss: 49.385 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1970/4776 | Loss: 70.570 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1980/4776 | Loss: 49.210 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 1990/4776 | Loss: 91.237 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2000/4776 | Loss: 43.934 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2010/4776 | Loss: 59.673 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2020/4776 | Loss: 65.051 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2030/4776 | Loss: 97.829 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2040/4776 | Loss: 75.083 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2050/4776 | Loss: 32.609 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2060/4776 | Loss: 44.361 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2070/4776 | Loss: 76.162 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2080/4776 | Loss: 61.330 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2090/4776 | Loss: 72.205 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2100/4776 | Loss: 46.328 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2110/4776 | Loss: 53.674 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2120/4776 | Loss: 22.640 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2130/4776 | Loss: 44.281 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2140/4776 | Loss: 72.568 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2150/4776 | Loss: 94.952 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2160/4776 | Loss: 18.002 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2170/4776 | Loss: 85.714 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2180/4776 | Loss: 41.593 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2190/4776 | Loss: 96.617 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2200/4776 | Loss: 79.185 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2210/4776 | Loss: 68.201 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2220/4776 | Loss: 59.916 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2230/4776 | Loss: 56.804 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2240/4776 | Loss: 96.369 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2250/4776 | Loss: 97.434 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2260/4776 | Loss: 87.929 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2270/4776 | Loss: 99.671 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2280/4776 | Loss: 84.791 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2290/4776 | Loss: 119.502 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 2300/4776 | Loss: 31.421 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2310/4776 | Loss: 59.372 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2320/4776 | Loss: 71.651 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2330/4776 | Loss: 85.907 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2340/4776 | Loss: 114.211 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2350/4776 | Loss: 26.399 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2360/4776 | Loss: 72.160 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2370/4776 | Loss: 27.844 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2380/4776 | Loss: 72.493 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2390/4776 | Loss: 75.706 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2400/4776 | Loss: 51.605 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2410/4776 | Loss: 63.793 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2420/4776 | Loss: 91.634 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2430/4776 | Loss: 133.767 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2440/4776 | Loss: 25.765 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2450/4776 | Loss: 58.550 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2460/4776 | Loss: 57.776 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2470/4776 | Loss: 113.652 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2480/4776 | Loss: 50.815 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2490/4776 | Loss: 37.617 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2500/4776 | Loss: 82.044 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2510/4776 | Loss: 101.878 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2520/4776 | Loss: 150.915 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 2530/4776 | Loss: 42.689 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2540/4776 | Loss: 94.211 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2550/4776 | Loss: 78.300 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2560/4776 | Loss: 107.254 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2570/4776 | Loss: 100.432 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2580/4776 | Loss: 83.040 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2590/4776 | Loss: 89.248 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2600/4776 | Loss: 39.892 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2610/4776 | Loss: 94.244 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2620/4776 | Loss: 57.515 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2630/4776 | Loss: 51.209 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2640/4776 | Loss: 57.669 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2650/4776 | Loss: 12.693 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2660/4776 | Loss: 12.772 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2670/4776 | Loss: 87.289 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2680/4776 | Loss: 67.959 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2690/4776 | Loss: 56.608 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2700/4776 | Loss: 42.848 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2710/4776 | Loss: 34.159 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2720/4776 | Loss: 32.173 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2730/4776 | Loss: 47.110 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2740/4776 | Loss: 36.496 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2750/4776 | Loss: 40.392 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2760/4776 | Loss: 73.936 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2770/4776 | Loss: 99.377 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2780/4776 | Loss: 22.295 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2790/4776 | Loss: 65.435 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2800/4776 | Loss: 25.202 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2810/4776 | Loss: 80.748 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2820/4776 | Loss: 117.817 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 2830/4776 | Loss: 54.580 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2840/4776 | Loss: 67.839 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2850/4776 | Loss: 49.701 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2860/4776 | Loss: 73.819 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2870/4776 | Loss: 70.145 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2880/4776 | Loss: 21.220 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2890/4776 | Loss: 42.025 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2900/4776 | Loss: 53.011 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2910/4776 | Loss: 77.913 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2920/4776 | Loss: 11.626 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 2930/4776 | Loss: 47.887 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2940/4776 | Loss: 27.036 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 2950/4776 | Loss: 117.435 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 2960/4776 | Loss: 51.080 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2970/4776 | Loss: 34.643 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 2980/4776 | Loss: 72.947 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 2990/4776 | Loss: 72.024 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3000/4776 | Loss: 18.088 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3010/4776 | Loss: 41.754 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3020/4776 | Loss: 98.222 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3030/4776 | Loss: 30.550 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3040/4776 | Loss: 50.250 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3050/4776 | Loss: 104.842 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3060/4776 | Loss: 63.114 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3070/4776 | Loss: 52.420 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3080/4776 | Loss: 76.301 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3090/4776 | Loss: 64.476 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3100/4776 | Loss: 52.907 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3110/4776 | Loss: 61.506 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3120/4776 | Loss: 75.733 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3130/4776 | Loss: 9.253 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3140/4776 | Loss: 26.143 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3150/4776 | Loss: 26.222 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3160/4776 | Loss: 97.788 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3170/4776 | Loss: 20.133 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3180/4776 | Loss: 103.641 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3190/4776 | Loss: 35.807 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3200/4776 | Loss: 30.984 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3210/4776 | Loss: 57.976 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3220/4776 | Loss: 19.130 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3230/4776 | Loss: 27.832 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3240/4776 | Loss: 36.725 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3250/4776 | Loss: 26.068 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3260/4776 | Loss: 22.750 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3270/4776 | Loss: 103.668 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3280/4776 | Loss: 97.250 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3290/4776 | Loss: 16.156 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3300/4776 | Loss: 71.186 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3310/4776 | Loss: 56.655 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3320/4776 | Loss: 37.263 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3330/4776 | Loss: 71.216 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3340/4776 | Loss: 7.700 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3350/4776 | Loss: 24.011 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3360/4776 | Loss: 62.171 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3370/4776 | Loss: 30.555 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3380/4776 | Loss: 19.389 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3390/4776 | Loss: 70.813 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3400/4776 | Loss: 17.475 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3410/4776 | Loss: 46.110 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3420/4776 | Loss: 87.829 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3430/4776 | Loss: 51.194 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3440/4776 | Loss: 51.182 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3450/4776 | Loss: 33.145 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3460/4776 | Loss: 87.025 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3470/4776 | Loss: 6.596 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3480/4776 | Loss: 48.383 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3490/4776 | Loss: 37.292 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3500/4776 | Loss: 34.446 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3510/4776 | Loss: 34.433 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3520/4776 | Loss: 65.249 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3530/4776 | Loss: 159.090 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 3540/4776 | Loss: 42.019 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3550/4776 | Loss: 34.243 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3560/4776 | Loss: 19.619 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3570/4776 | Loss: 51.171 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3580/4776 | Loss: 82.806 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3590/4776 | Loss: 73.012 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3600/4776 | Loss: 42.615 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3610/4776 | Loss: 82.695 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3620/4776 | Loss: 77.048 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3630/4776 | Loss: 29.096 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3640/4776 | Loss: 83.283 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3650/4776 | Loss: 75.912 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3660/4776 | Loss: 67.720 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3670/4776 | Loss: 42.707 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3680/4776 | Loss: 98.801 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3690/4776 | Loss: 31.243 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3700/4776 | Loss: 94.488 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 3710/4776 | Loss: 48.514 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3720/4776 | Loss: 29.701 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3730/4776 | Loss: 49.798 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3740/4776 | Loss: 52.113 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3750/4776 | Loss: 56.889 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3760/4776 | Loss: 41.503 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3770/4776 | Loss: 12.154 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3780/4776 | Loss: 21.637 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3790/4776 | Loss: 38.244 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3800/4776 | Loss: 30.522 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3810/4776 | Loss: 23.244 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3820/4776 | Loss: 16.353 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3830/4776 | Loss: 35.537 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3840/4776 | Loss: 48.473 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3850/4776 | Loss: 91.228 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3860/4776 | Loss: 12.030 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3870/4776 | Loss: 64.321 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3880/4776 | Loss: 49.959 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3890/4776 | Loss: 135.767 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 3900/4776 | Loss: 30.846 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3910/4776 | Loss: 51.006 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3920/4776 | Loss: 46.524 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 3930/4776 | Loss: 47.054 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3940/4776 | Loss: 45.512 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3950/4776 | Loss: 85.715 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 3960/4776 | Loss: 7.779 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 3970/4776 | Loss: 70.440 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 3980/4776 | Loss: 31.356 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 3990/4776 | Loss: 48.267 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4000/4776 | Loss: 11.225 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4010/4776 | Loss: 22.291 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4020/4776 | Loss: 64.384 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4030/4776 | Loss: 52.492 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4040/4776 | Loss: 59.042 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4050/4776 | Loss: 88.556 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4060/4776 | Loss: 4.410 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4070/4776 | Loss: 38.288 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4080/4776 | Loss: 118.173 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 4090/4776 | Loss: 28.238 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4100/4776 | Loss: 55.400 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4110/4776 | Loss: 67.796 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4120/4776 | Loss: 92.165 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4130/4776 | Loss: 37.515 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4140/4776 | Loss: 24.895 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4150/4776 | Loss: 92.873 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4160/4776 | Loss: 9.314 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4170/4776 | Loss: 66.289 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4180/4776 | Loss: 61.725 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4190/4776 | Loss: 85.789 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4200/4776 | Loss: 38.873 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4210/4776 | Loss: 21.281 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4220/4776 | Loss: 98.006 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4230/4776 | Loss: 66.728 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4240/4776 | Loss: 41.630 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4250/4776 | Loss: 11.400 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4260/4776 | Loss: 131.670 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4270/4776 | Loss: 109.626 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4280/4776 | Loss: 71.710 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4290/4776 | Loss: 79.234 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4300/4776 | Loss: 31.994 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4310/4776 | Loss: 108.612 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4320/4776 | Loss: 85.202 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4330/4776 | Loss: 64.727 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4340/4776 | Loss: 56.284 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4350/4776 | Loss: 68.078 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4360/4776 | Loss: 42.789 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4370/4776 | Loss: 35.650 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4380/4776 | Loss: 45.256 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4390/4776 | Loss: 40.047 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4400/4776 | Loss: 32.317 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4410/4776 | Loss: 72.460 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4420/4776 | Loss: 25.447 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4430/4776 | Loss: 52.814 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4440/4776 | Loss: 32.104 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4450/4776 | Loss: 21.008 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4460/4776 | Loss: 17.298 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4470/4776 | Loss: 53.913 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4480/4776 | Loss: 133.061 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 4490/4776 | Loss: 53.808 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4500/4776 | Loss: 62.512 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4510/4776 | Loss: 36.624 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4520/4776 | Loss: 66.729 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4530/4776 | Loss: 14.467 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4540/4776 | Loss: 35.198 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4550/4776 | Loss: 29.686 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4560/4776 | Loss: 2.885 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4570/4776 | Loss: 87.141 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4580/4776 | Loss: 53.374 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4590/4776 | Loss: 42.314 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4600/4776 | Loss: 100.795 | Accuracy: 0.600\n",
      "[Epoch: 79/200] - Step: 4610/4776 | Loss: 47.671 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4620/4776 | Loss: 28.055 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4630/4776 | Loss: 23.252 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4640/4776 | Loss: 81.841 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4650/4776 | Loss: 51.505 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4660/4776 | Loss: 18.144 | Accuracy: 1.000\n",
      "[Epoch: 79/200] - Step: 4670/4776 | Loss: 32.406 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4680/4776 | Loss: 37.857 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4690/4776 | Loss: 48.892 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4700/4776 | Loss: 39.867 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4710/4776 | Loss: 109.007 | Accuracy: 0.700\n",
      "[Epoch: 79/200] - Step: 4720/4776 | Loss: 55.088 | Accuracy: 0.800\n",
      "[Epoch: 79/200] - Step: 4730/4776 | Loss: 45.103 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4740/4776 | Loss: 33.528 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4750/4776 | Loss: 135.106 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 4760/4776 | Loss: 18.674 | Accuracy: 0.900\n",
      "[Epoch: 79/200] - Step: 4770/4776 | Loss: 134.731 | Accuracy: 0.600\n",
      "Accuracy:  0.20491803278688525\n",
      "[Epoch: 80/200] - Step: 10/4776 | Loss: 106.356 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 20/4776 | Loss: 51.677 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 30/4776 | Loss: 54.925 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 40/4776 | Loss: 40.732 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 50/4776 | Loss: 38.772 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 60/4776 | Loss: 136.223 | Accuracy: 0.400\n",
      "[Epoch: 80/200] - Step: 70/4776 | Loss: 73.101 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 80/4776 | Loss: 75.239 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 90/4776 | Loss: 52.153 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 100/4776 | Loss: 69.736 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 110/4776 | Loss: 43.901 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 120/4776 | Loss: 62.524 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 130/4776 | Loss: 73.661 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 140/4776 | Loss: 53.898 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 150/4776 | Loss: 44.121 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 160/4776 | Loss: 95.226 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 170/4776 | Loss: 48.161 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 180/4776 | Loss: 118.051 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 190/4776 | Loss: 93.975 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 200/4776 | Loss: 17.910 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 210/4776 | Loss: 55.413 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 220/4776 | Loss: 93.348 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 230/4776 | Loss: 41.531 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 240/4776 | Loss: 35.876 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 250/4776 | Loss: 50.129 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 260/4776 | Loss: 94.490 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 270/4776 | Loss: 51.722 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 280/4776 | Loss: 73.531 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 290/4776 | Loss: 42.060 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 300/4776 | Loss: 112.284 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 310/4776 | Loss: 56.098 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 320/4776 | Loss: 31.169 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 330/4776 | Loss: 49.491 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 340/4776 | Loss: 82.761 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 350/4776 | Loss: 40.867 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 360/4776 | Loss: 125.839 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 370/4776 | Loss: 68.722 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 380/4776 | Loss: 83.177 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 390/4776 | Loss: 79.277 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 400/4776 | Loss: 34.678 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 410/4776 | Loss: 83.022 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 420/4776 | Loss: 115.666 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 430/4776 | Loss: 27.812 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 440/4776 | Loss: 107.572 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 450/4776 | Loss: 90.303 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 460/4776 | Loss: 34.807 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 470/4776 | Loss: 45.798 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 480/4776 | Loss: 66.581 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 490/4776 | Loss: 53.954 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 500/4776 | Loss: 58.259 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 510/4776 | Loss: 75.085 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 520/4776 | Loss: 25.295 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 530/4776 | Loss: 24.761 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 540/4776 | Loss: 56.163 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 550/4776 | Loss: 104.063 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 560/4776 | Loss: 56.795 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 570/4776 | Loss: 15.726 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 580/4776 | Loss: 71.870 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 590/4776 | Loss: 51.406 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 600/4776 | Loss: 42.629 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 610/4776 | Loss: 131.716 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 620/4776 | Loss: 15.344 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 630/4776 | Loss: 38.676 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 640/4776 | Loss: 11.962 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 650/4776 | Loss: 65.931 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 660/4776 | Loss: 77.725 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 670/4776 | Loss: 72.023 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 680/4776 | Loss: 86.962 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 690/4776 | Loss: 57.365 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 700/4776 | Loss: 38.620 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 710/4776 | Loss: 57.389 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 720/4776 | Loss: 27.688 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 730/4776 | Loss: 28.320 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 740/4776 | Loss: 38.280 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 750/4776 | Loss: 72.621 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 760/4776 | Loss: 45.763 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 770/4776 | Loss: 73.895 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 780/4776 | Loss: 115.389 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 790/4776 | Loss: 104.623 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 800/4776 | Loss: 57.396 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 810/4776 | Loss: 45.315 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 820/4776 | Loss: 16.673 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 830/4776 | Loss: 20.888 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 840/4776 | Loss: 39.807 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 850/4776 | Loss: 18.669 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 860/4776 | Loss: 69.329 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 870/4776 | Loss: 35.555 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 880/4776 | Loss: 32.320 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 890/4776 | Loss: 12.788 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 900/4776 | Loss: 125.457 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 910/4776 | Loss: 23.647 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 920/4776 | Loss: 31.071 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 930/4776 | Loss: 98.987 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 940/4776 | Loss: 70.495 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 950/4776 | Loss: 55.427 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 960/4776 | Loss: 96.390 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 970/4776 | Loss: 54.934 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 980/4776 | Loss: 46.160 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 990/4776 | Loss: 62.061 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1000/4776 | Loss: 42.627 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1010/4776 | Loss: 77.035 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1020/4776 | Loss: 82.652 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1030/4776 | Loss: 47.381 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1040/4776 | Loss: 84.353 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1050/4776 | Loss: 48.267 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1060/4776 | Loss: 59.023 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1070/4776 | Loss: 22.589 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1080/4776 | Loss: 26.346 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1090/4776 | Loss: 44.890 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1100/4776 | Loss: 18.868 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1110/4776 | Loss: 39.151 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1120/4776 | Loss: 11.275 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1130/4776 | Loss: 26.903 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1140/4776 | Loss: 105.274 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1150/4776 | Loss: 55.519 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1160/4776 | Loss: 75.104 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1170/4776 | Loss: 74.686 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1180/4776 | Loss: 57.805 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1190/4776 | Loss: 44.262 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1200/4776 | Loss: 99.114 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1210/4776 | Loss: 44.049 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1220/4776 | Loss: 36.901 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1230/4776 | Loss: 95.831 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1240/4776 | Loss: 18.042 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1250/4776 | Loss: 78.749 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1260/4776 | Loss: 53.704 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1270/4776 | Loss: 47.014 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1280/4776 | Loss: 96.855 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1290/4776 | Loss: 12.215 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1300/4776 | Loss: 55.629 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1310/4776 | Loss: 34.372 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1320/4776 | Loss: 101.796 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1330/4776 | Loss: 66.098 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1340/4776 | Loss: 136.841 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1350/4776 | Loss: 34.700 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1360/4776 | Loss: 16.614 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1370/4776 | Loss: 55.795 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1380/4776 | Loss: 24.799 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1390/4776 | Loss: 76.323 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1400/4776 | Loss: 24.179 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1410/4776 | Loss: 35.251 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1420/4776 | Loss: 28.851 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1430/4776 | Loss: 58.486 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1440/4776 | Loss: 46.868 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1450/4776 | Loss: 31.932 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1460/4776 | Loss: 67.568 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1470/4776 | Loss: 27.760 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1480/4776 | Loss: 12.813 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1490/4776 | Loss: 36.359 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1500/4776 | Loss: 93.297 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1510/4776 | Loss: 135.774 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1520/4776 | Loss: 78.584 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1530/4776 | Loss: 68.422 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1540/4776 | Loss: 97.359 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1550/4776 | Loss: 18.351 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1560/4776 | Loss: 95.709 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1570/4776 | Loss: 110.990 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1580/4776 | Loss: 14.375 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 1590/4776 | Loss: 57.097 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1600/4776 | Loss: 22.155 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1610/4776 | Loss: 69.686 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1620/4776 | Loss: 28.532 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1630/4776 | Loss: 43.007 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1640/4776 | Loss: 20.705 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1650/4776 | Loss: 46.864 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1660/4776 | Loss: 65.533 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1670/4776 | Loss: 48.970 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1680/4776 | Loss: 44.512 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1690/4776 | Loss: 23.811 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1700/4776 | Loss: 35.067 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1710/4776 | Loss: 46.181 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1720/4776 | Loss: 32.954 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1730/4776 | Loss: 39.487 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1740/4776 | Loss: 118.763 | Accuracy: 0.400\n",
      "[Epoch: 80/200] - Step: 1750/4776 | Loss: 35.268 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1760/4776 | Loss: 36.204 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1770/4776 | Loss: 72.145 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1780/4776 | Loss: 33.266 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1790/4776 | Loss: 30.975 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1800/4776 | Loss: 86.593 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1810/4776 | Loss: 36.109 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1820/4776 | Loss: 74.078 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1830/4776 | Loss: 50.745 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1840/4776 | Loss: 66.572 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1850/4776 | Loss: 45.484 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1860/4776 | Loss: 83.070 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1870/4776 | Loss: 109.418 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 1880/4776 | Loss: 69.945 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1890/4776 | Loss: 41.302 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1900/4776 | Loss: 75.276 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1910/4776 | Loss: 56.579 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1920/4776 | Loss: 103.052 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1930/4776 | Loss: 57.875 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1940/4776 | Loss: 93.684 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1950/4776 | Loss: 60.772 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 1960/4776 | Loss: 109.548 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 1970/4776 | Loss: 57.298 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 1980/4776 | Loss: 39.778 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 1990/4776 | Loss: 55.869 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2000/4776 | Loss: 33.962 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2010/4776 | Loss: 37.280 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2020/4776 | Loss: 23.452 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2030/4776 | Loss: 59.247 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2040/4776 | Loss: 79.120 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2050/4776 | Loss: 27.460 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2060/4776 | Loss: 43.852 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2070/4776 | Loss: 50.769 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2080/4776 | Loss: 25.493 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2090/4776 | Loss: 59.051 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2100/4776 | Loss: 5.647 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2110/4776 | Loss: 52.911 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2120/4776 | Loss: 50.207 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2130/4776 | Loss: 11.703 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2140/4776 | Loss: 26.281 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2150/4776 | Loss: 13.920 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2160/4776 | Loss: 45.013 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2170/4776 | Loss: 53.810 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2180/4776 | Loss: 94.432 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2190/4776 | Loss: 43.045 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2200/4776 | Loss: 78.864 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2210/4776 | Loss: 135.324 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2220/4776 | Loss: 28.396 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2230/4776 | Loss: 63.245 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2240/4776 | Loss: 90.881 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2250/4776 | Loss: 109.410 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2260/4776 | Loss: 68.304 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2270/4776 | Loss: 40.782 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2280/4776 | Loss: 50.387 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2290/4776 | Loss: 22.249 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2300/4776 | Loss: 92.856 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2310/4776 | Loss: 34.057 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2320/4776 | Loss: 33.953 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2330/4776 | Loss: 84.718 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2340/4776 | Loss: 112.155 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2350/4776 | Loss: 94.441 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2360/4776 | Loss: 109.853 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2370/4776 | Loss: 34.285 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2380/4776 | Loss: 46.141 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2390/4776 | Loss: 84.685 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2400/4776 | Loss: 37.247 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2410/4776 | Loss: 46.182 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2420/4776 | Loss: 25.645 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2430/4776 | Loss: 58.764 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2440/4776 | Loss: 15.137 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2450/4776 | Loss: 17.038 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2460/4776 | Loss: 35.240 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2470/4776 | Loss: 122.339 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2480/4776 | Loss: 110.850 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2490/4776 | Loss: 28.074 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2500/4776 | Loss: 28.089 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2510/4776 | Loss: 24.944 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2520/4776 | Loss: 36.057 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2530/4776 | Loss: 77.835 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2540/4776 | Loss: 37.222 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2550/4776 | Loss: 90.381 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2560/4776 | Loss: 145.329 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2570/4776 | Loss: 88.304 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2580/4776 | Loss: 132.625 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 2590/4776 | Loss: 109.975 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2600/4776 | Loss: 88.616 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2610/4776 | Loss: 75.518 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2620/4776 | Loss: 46.873 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2630/4776 | Loss: 22.943 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2640/4776 | Loss: 78.344 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2650/4776 | Loss: 46.568 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2660/4776 | Loss: 146.643 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2670/4776 | Loss: 25.858 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2680/4776 | Loss: 39.375 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2690/4776 | Loss: 64.542 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2700/4776 | Loss: 45.601 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2710/4776 | Loss: 44.684 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2720/4776 | Loss: 74.994 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2730/4776 | Loss: 19.107 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2740/4776 | Loss: 71.666 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2750/4776 | Loss: 93.850 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2760/4776 | Loss: 43.139 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2770/4776 | Loss: 37.595 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2780/4776 | Loss: 3.046 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2790/4776 | Loss: 28.882 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2800/4776 | Loss: 23.349 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2810/4776 | Loss: 45.773 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2820/4776 | Loss: 69.287 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2830/4776 | Loss: 54.410 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2840/4776 | Loss: 46.179 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2850/4776 | Loss: 38.214 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2860/4776 | Loss: 40.872 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2870/4776 | Loss: 42.612 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2880/4776 | Loss: 39.918 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2890/4776 | Loss: 49.082 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2900/4776 | Loss: 68.712 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2910/4776 | Loss: 72.319 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2920/4776 | Loss: 45.283 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2930/4776 | Loss: 95.574 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 2940/4776 | Loss: 70.525 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 2950/4776 | Loss: 42.187 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2960/4776 | Loss: 31.479 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 2970/4776 | Loss: 69.637 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 2980/4776 | Loss: 19.393 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 2990/4776 | Loss: 76.055 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3000/4776 | Loss: 18.101 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3010/4776 | Loss: 47.508 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3020/4776 | Loss: 81.690 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3030/4776 | Loss: 35.534 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3040/4776 | Loss: 54.398 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3050/4776 | Loss: 43.868 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3060/4776 | Loss: 73.718 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3070/4776 | Loss: 30.162 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3080/4776 | Loss: 48.748 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3090/4776 | Loss: 60.418 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3100/4776 | Loss: 80.671 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3110/4776 | Loss: 65.942 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3120/4776 | Loss: 85.199 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3130/4776 | Loss: 55.749 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3140/4776 | Loss: 57.339 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3150/4776 | Loss: 35.719 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3160/4776 | Loss: 42.716 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3170/4776 | Loss: 67.221 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3180/4776 | Loss: 2.577 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3190/4776 | Loss: 15.839 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3200/4776 | Loss: 44.343 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3210/4776 | Loss: 78.146 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3220/4776 | Loss: 41.098 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3230/4776 | Loss: 103.272 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3240/4776 | Loss: 43.396 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3250/4776 | Loss: 33.989 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3260/4776 | Loss: 211.646 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 3270/4776 | Loss: 97.253 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3280/4776 | Loss: 70.424 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3290/4776 | Loss: 98.180 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 3300/4776 | Loss: 15.936 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3310/4776 | Loss: 19.507 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3320/4776 | Loss: 48.362 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3330/4776 | Loss: 48.866 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3340/4776 | Loss: 125.553 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3350/4776 | Loss: 16.475 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3360/4776 | Loss: 88.526 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3370/4776 | Loss: 82.356 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3380/4776 | Loss: 127.640 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 3390/4776 | Loss: 20.457 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3400/4776 | Loss: 33.759 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3410/4776 | Loss: 75.776 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3420/4776 | Loss: 20.112 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3430/4776 | Loss: 90.444 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3440/4776 | Loss: 33.020 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3450/4776 | Loss: 28.519 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3460/4776 | Loss: 46.417 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3470/4776 | Loss: 28.376 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3480/4776 | Loss: 43.191 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3490/4776 | Loss: 47.154 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3500/4776 | Loss: 64.526 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3510/4776 | Loss: 88.711 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3520/4776 | Loss: 33.595 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3530/4776 | Loss: 56.668 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3540/4776 | Loss: 34.628 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3550/4776 | Loss: 57.087 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3560/4776 | Loss: 68.629 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3570/4776 | Loss: 20.340 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3580/4776 | Loss: 73.731 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3590/4776 | Loss: 73.383 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3600/4776 | Loss: 52.999 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3610/4776 | Loss: 54.569 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3620/4776 | Loss: 134.002 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3630/4776 | Loss: 77.421 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3640/4776 | Loss: 76.107 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3650/4776 | Loss: 65.872 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3660/4776 | Loss: 115.936 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3670/4776 | Loss: 79.374 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3680/4776 | Loss: 365.214 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3690/4776 | Loss: 89.111 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 3700/4776 | Loss: 82.904 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3710/4776 | Loss: 49.242 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3720/4776 | Loss: 119.120 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3730/4776 | Loss: 70.162 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3740/4776 | Loss: 54.080 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3750/4776 | Loss: 26.115 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3760/4776 | Loss: 12.225 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3770/4776 | Loss: 122.008 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3780/4776 | Loss: 99.483 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3790/4776 | Loss: 29.389 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3800/4776 | Loss: 63.943 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3810/4776 | Loss: 53.977 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3820/4776 | Loss: 49.091 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3830/4776 | Loss: 45.952 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3840/4776 | Loss: 65.636 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3850/4776 | Loss: 25.470 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3860/4776 | Loss: 106.623 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3870/4776 | Loss: 140.856 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 3880/4776 | Loss: 99.387 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 3890/4776 | Loss: 59.598 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3900/4776 | Loss: 53.927 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3910/4776 | Loss: 19.668 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 3920/4776 | Loss: 83.845 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3930/4776 | Loss: 75.068 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3940/4776 | Loss: 84.739 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3950/4776 | Loss: 73.105 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 3960/4776 | Loss: 28.134 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 3970/4776 | Loss: 28.622 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3980/4776 | Loss: 69.371 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 3990/4776 | Loss: 97.663 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4000/4776 | Loss: 107.435 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 4010/4776 | Loss: 37.233 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4020/4776 | Loss: 81.501 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4030/4776 | Loss: 81.774 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4040/4776 | Loss: 43.593 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4050/4776 | Loss: 64.255 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4060/4776 | Loss: 29.340 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4070/4776 | Loss: 67.315 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4080/4776 | Loss: 91.416 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4090/4776 | Loss: 18.140 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4100/4776 | Loss: 34.700 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4110/4776 | Loss: 34.113 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4120/4776 | Loss: 46.971 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4130/4776 | Loss: 19.403 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4140/4776 | Loss: 41.477 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4150/4776 | Loss: 97.883 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4160/4776 | Loss: 81.013 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4170/4776 | Loss: 32.521 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4180/4776 | Loss: 105.414 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4190/4776 | Loss: 34.410 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4200/4776 | Loss: 79.567 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4210/4776 | Loss: 33.540 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4220/4776 | Loss: 66.182 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4230/4776 | Loss: 20.188 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4240/4776 | Loss: 29.909 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4250/4776 | Loss: 35.305 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4260/4776 | Loss: 31.416 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4270/4776 | Loss: 48.947 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4280/4776 | Loss: 57.406 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4290/4776 | Loss: 27.441 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4300/4776 | Loss: 47.335 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4310/4776 | Loss: 32.057 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4320/4776 | Loss: 47.450 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4330/4776 | Loss: 54.535 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4340/4776 | Loss: 35.041 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4350/4776 | Loss: 77.751 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 4360/4776 | Loss: 28.551 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4370/4776 | Loss: 43.363 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4380/4776 | Loss: 39.659 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4390/4776 | Loss: 62.709 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4400/4776 | Loss: 73.599 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4410/4776 | Loss: 57.000 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4420/4776 | Loss: 59.445 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4430/4776 | Loss: 24.707 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4440/4776 | Loss: 18.503 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4450/4776 | Loss: 121.230 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 4460/4776 | Loss: 26.245 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4470/4776 | Loss: 81.742 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4480/4776 | Loss: 69.003 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 4490/4776 | Loss: 51.722 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4500/4776 | Loss: 61.125 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4510/4776 | Loss: 117.424 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4520/4776 | Loss: 59.719 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4530/4776 | Loss: 50.534 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4540/4776 | Loss: 47.941 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4550/4776 | Loss: 19.015 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4560/4776 | Loss: 105.332 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 4570/4776 | Loss: 93.243 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 4580/4776 | Loss: 7.879 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4590/4776 | Loss: 58.543 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4600/4776 | Loss: 47.270 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4610/4776 | Loss: 75.940 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4620/4776 | Loss: 64.890 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4630/4776 | Loss: 74.355 | Accuracy: 0.600\n",
      "[Epoch: 80/200] - Step: 4640/4776 | Loss: 31.667 | Accuracy: 1.000\n",
      "[Epoch: 80/200] - Step: 4650/4776 | Loss: 61.685 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4660/4776 | Loss: 34.732 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4670/4776 | Loss: 49.735 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4680/4776 | Loss: 95.718 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4690/4776 | Loss: 75.542 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4700/4776 | Loss: 76.712 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4710/4776 | Loss: 61.504 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4720/4776 | Loss: 38.001 | Accuracy: 0.900\n",
      "[Epoch: 80/200] - Step: 4730/4776 | Loss: 83.080 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4740/4776 | Loss: 63.623 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4750/4776 | Loss: 69.630 | Accuracy: 0.700\n",
      "[Epoch: 80/200] - Step: 4760/4776 | Loss: 63.084 | Accuracy: 0.800\n",
      "[Epoch: 80/200] - Step: 4770/4776 | Loss: 52.632 | Accuracy: 0.800\n",
      "Accuracy:  0.22295081967213115\n",
      "[Epoch: 81/200] - Step: 10/4776 | Loss: 60.271 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 20/4776 | Loss: 98.397 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 30/4776 | Loss: 46.785 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 40/4776 | Loss: 104.426 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 50/4776 | Loss: 64.792 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 60/4776 | Loss: 66.778 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 70/4776 | Loss: 25.494 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 80/4776 | Loss: 47.149 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 90/4776 | Loss: 28.100 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 100/4776 | Loss: 60.488 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 110/4776 | Loss: 91.037 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 120/4776 | Loss: 48.955 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 130/4776 | Loss: 40.671 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 140/4776 | Loss: 32.905 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 150/4776 | Loss: 39.947 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 160/4776 | Loss: 48.235 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 170/4776 | Loss: 100.269 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 180/4776 | Loss: 11.077 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 190/4776 | Loss: 70.882 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 200/4776 | Loss: 57.853 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 210/4776 | Loss: 55.947 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 220/4776 | Loss: 14.617 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 230/4776 | Loss: 68.145 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 240/4776 | Loss: 150.756 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 250/4776 | Loss: 42.710 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 260/4776 | Loss: 62.653 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 270/4776 | Loss: 59.551 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 280/4776 | Loss: 41.045 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 290/4776 | Loss: 93.122 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 300/4776 | Loss: 28.608 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 310/4776 | Loss: 19.167 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 320/4776 | Loss: 86.995 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 330/4776 | Loss: 38.147 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 340/4776 | Loss: 12.236 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 350/4776 | Loss: 26.052 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 360/4776 | Loss: 60.702 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 370/4776 | Loss: 29.684 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 380/4776 | Loss: 6.656 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 390/4776 | Loss: 46.806 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 400/4776 | Loss: 40.554 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 410/4776 | Loss: 48.126 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 420/4776 | Loss: 34.649 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 430/4776 | Loss: 16.171 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 440/4776 | Loss: 39.633 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 450/4776 | Loss: 32.276 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 460/4776 | Loss: 27.394 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 470/4776 | Loss: 99.451 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 480/4776 | Loss: 39.187 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 490/4776 | Loss: 64.996 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 500/4776 | Loss: 118.226 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 510/4776 | Loss: 35.339 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 520/4776 | Loss: 34.035 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 530/4776 | Loss: 51.013 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 540/4776 | Loss: 80.222 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 550/4776 | Loss: 48.074 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 560/4776 | Loss: 80.600 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 570/4776 | Loss: 51.289 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 580/4776 | Loss: 95.506 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 590/4776 | Loss: 69.307 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 600/4776 | Loss: 104.288 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 610/4776 | Loss: 11.078 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 620/4776 | Loss: 76.727 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 630/4776 | Loss: 126.529 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 640/4776 | Loss: 41.287 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 650/4776 | Loss: 41.641 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 660/4776 | Loss: 33.796 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 670/4776 | Loss: 37.690 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 680/4776 | Loss: 43.194 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 690/4776 | Loss: 38.781 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 700/4776 | Loss: 49.942 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 710/4776 | Loss: 10.466 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 720/4776 | Loss: 41.427 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 730/4776 | Loss: 37.069 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 740/4776 | Loss: 58.012 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 750/4776 | Loss: 27.589 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 760/4776 | Loss: 59.450 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 770/4776 | Loss: 105.459 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 780/4776 | Loss: 34.782 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 790/4776 | Loss: 58.923 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 800/4776 | Loss: 66.277 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 810/4776 | Loss: 89.486 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 820/4776 | Loss: 38.817 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 830/4776 | Loss: 58.392 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 840/4776 | Loss: 43.004 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 850/4776 | Loss: 81.344 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 860/4776 | Loss: 81.848 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 870/4776 | Loss: 13.387 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 880/4776 | Loss: 117.374 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 890/4776 | Loss: 26.279 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 900/4776 | Loss: 74.096 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 910/4776 | Loss: 65.793 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 920/4776 | Loss: 95.324 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 930/4776 | Loss: 21.675 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 940/4776 | Loss: 103.645 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 950/4776 | Loss: 91.219 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 960/4776 | Loss: 44.384 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 970/4776 | Loss: 133.647 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 980/4776 | Loss: 15.921 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 990/4776 | Loss: 37.073 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1000/4776 | Loss: 34.765 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1010/4776 | Loss: 89.040 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1020/4776 | Loss: 101.392 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1030/4776 | Loss: 71.898 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1040/4776 | Loss: 80.312 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1050/4776 | Loss: 101.337 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 1060/4776 | Loss: 44.333 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1070/4776 | Loss: 91.033 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 1080/4776 | Loss: 5.848 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1090/4776 | Loss: 71.440 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1100/4776 | Loss: 79.980 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1110/4776 | Loss: 29.615 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1120/4776 | Loss: 68.517 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1130/4776 | Loss: 31.168 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1140/4776 | Loss: 145.519 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1150/4776 | Loss: 47.280 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1160/4776 | Loss: 58.625 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1170/4776 | Loss: 36.943 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1180/4776 | Loss: 57.829 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1190/4776 | Loss: 91.331 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1200/4776 | Loss: 53.855 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1210/4776 | Loss: 102.527 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 1220/4776 | Loss: 28.141 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1230/4776 | Loss: 42.827 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1240/4776 | Loss: 63.374 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1250/4776 | Loss: 5.166 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1260/4776 | Loss: 18.483 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1270/4776 | Loss: 15.278 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1280/4776 | Loss: 105.201 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1290/4776 | Loss: 79.591 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1300/4776 | Loss: 126.728 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1310/4776 | Loss: 4.453 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1320/4776 | Loss: 46.165 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1330/4776 | Loss: 15.134 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1340/4776 | Loss: 28.559 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1350/4776 | Loss: 26.051 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1360/4776 | Loss: 41.424 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1370/4776 | Loss: 64.508 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1380/4776 | Loss: 47.703 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1390/4776 | Loss: 96.341 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 1400/4776 | Loss: 78.964 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1410/4776 | Loss: 17.282 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1420/4776 | Loss: 41.968 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1430/4776 | Loss: 64.150 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1440/4776 | Loss: 66.471 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1450/4776 | Loss: 15.945 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1460/4776 | Loss: 52.876 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1470/4776 | Loss: 38.949 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1480/4776 | Loss: 83.400 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1490/4776 | Loss: 61.302 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1500/4776 | Loss: 41.526 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1510/4776 | Loss: 51.478 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1520/4776 | Loss: 24.215 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1530/4776 | Loss: 100.794 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1540/4776 | Loss: 131.594 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 1550/4776 | Loss: 83.202 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1560/4776 | Loss: 58.252 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1570/4776 | Loss: 27.926 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1580/4776 | Loss: 49.993 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1590/4776 | Loss: 32.251 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1600/4776 | Loss: 62.555 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1610/4776 | Loss: 56.445 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1620/4776 | Loss: 94.652 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1630/4776 | Loss: 82.122 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1640/4776 | Loss: 96.537 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1650/4776 | Loss: 69.106 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1660/4776 | Loss: 84.811 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1670/4776 | Loss: 67.769 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1680/4776 | Loss: 44.477 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1690/4776 | Loss: 35.754 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1700/4776 | Loss: 50.920 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1710/4776 | Loss: 35.374 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1720/4776 | Loss: 66.607 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1730/4776 | Loss: 25.949 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1740/4776 | Loss: 45.215 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1750/4776 | Loss: 38.461 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1760/4776 | Loss: 75.129 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1770/4776 | Loss: 64.478 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1780/4776 | Loss: 24.280 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1790/4776 | Loss: 27.916 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1800/4776 | Loss: 58.650 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1810/4776 | Loss: 68.042 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1820/4776 | Loss: 14.703 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 1830/4776 | Loss: 23.446 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1840/4776 | Loss: 30.333 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1850/4776 | Loss: 28.859 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1860/4776 | Loss: 37.219 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1870/4776 | Loss: 142.665 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1880/4776 | Loss: 62.486 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1890/4776 | Loss: 92.554 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1900/4776 | Loss: 173.049 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 1910/4776 | Loss: 136.573 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1920/4776 | Loss: 57.835 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1930/4776 | Loss: 110.023 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1940/4776 | Loss: 33.372 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1950/4776 | Loss: 74.340 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1960/4776 | Loss: 37.470 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 1970/4776 | Loss: 40.577 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 1980/4776 | Loss: 128.338 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 1990/4776 | Loss: 50.063 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2000/4776 | Loss: 44.815 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2010/4776 | Loss: 62.271 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2020/4776 | Loss: 112.214 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2030/4776 | Loss: 25.733 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 2040/4776 | Loss: 76.217 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2050/4776 | Loss: 41.042 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2060/4776 | Loss: 17.066 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 2070/4776 | Loss: 49.765 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2080/4776 | Loss: 66.178 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 2090/4776 | Loss: 67.015 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2100/4776 | Loss: 90.284 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2110/4776 | Loss: 78.939 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2120/4776 | Loss: 61.404 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2130/4776 | Loss: 86.368 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2140/4776 | Loss: 25.991 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2150/4776 | Loss: 70.110 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2160/4776 | Loss: 3.291 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 2170/4776 | Loss: 56.508 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2180/4776 | Loss: 38.881 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2190/4776 | Loss: 29.007 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2200/4776 | Loss: 2.196 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 2210/4776 | Loss: 51.381 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2220/4776 | Loss: 85.983 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2230/4776 | Loss: 44.644 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2240/4776 | Loss: 56.640 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2250/4776 | Loss: 64.075 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2260/4776 | Loss: 64.297 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2270/4776 | Loss: 97.478 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2280/4776 | Loss: 48.224 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2290/4776 | Loss: 63.532 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2300/4776 | Loss: 52.645 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2310/4776 | Loss: 22.489 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2320/4776 | Loss: 42.301 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2330/4776 | Loss: 41.342 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2340/4776 | Loss: 82.835 | Accuracy: 0.500\n",
      "[Epoch: 81/200] - Step: 2350/4776 | Loss: 100.294 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2360/4776 | Loss: 39.765 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2370/4776 | Loss: 55.065 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2380/4776 | Loss: 42.082 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2390/4776 | Loss: 42.924 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2400/4776 | Loss: 55.242 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2410/4776 | Loss: 60.003 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2420/4776 | Loss: 25.798 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2430/4776 | Loss: 78.926 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2440/4776 | Loss: 73.235 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2450/4776 | Loss: 41.123 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2460/4776 | Loss: 75.192 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2470/4776 | Loss: 117.254 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2480/4776 | Loss: 104.426 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2490/4776 | Loss: 61.200 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2500/4776 | Loss: 6.607 | Accuracy: 1.000\n",
      "[Epoch: 81/200] - Step: 2510/4776 | Loss: 107.566 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2520/4776 | Loss: 22.052 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2530/4776 | Loss: 49.137 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2540/4776 | Loss: 48.121 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2550/4776 | Loss: 88.186 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2560/4776 | Loss: 81.116 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2570/4776 | Loss: 32.167 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2580/4776 | Loss: 59.034 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2590/4776 | Loss: 25.298 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2600/4776 | Loss: 48.566 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2610/4776 | Loss: 57.364 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2620/4776 | Loss: 61.435 | Accuracy: 0.700\n",
      "[Epoch: 81/200] - Step: 2630/4776 | Loss: 47.428 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2640/4776 | Loss: 33.406 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2650/4776 | Loss: 25.176 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2660/4776 | Loss: 38.807 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2670/4776 | Loss: 35.390 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2680/4776 | Loss: 31.789 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2690/4776 | Loss: 39.121 | Accuracy: 0.800\n",
      "[Epoch: 81/200] - Step: 2700/4776 | Loss: 63.972 | Accuracy: 0.600\n",
      "[Epoch: 81/200] - Step: 2710/4776 | Loss: 21.053 | Accuracy: 0.900\n",
      "[Epoch: 81/200] - Step: 2720/4776 | Loss: 33.156 | Accuracy: 0.900\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "    # Let's build our model\n",
    "    train(200,device,net)\n",
    "    print('Finished Training')\n",
    "\n",
    "    #Epochごとのlossの保存\n",
    "    #torch.save(net, \"./result/\"+casename+\"/\"+casename+\".pt\")\n",
    "    # 保存网络中的参数, 速度快，占空间少\n",
    "    #torch.save(net.state_dict(),'case-1-p.pt')\n",
    "    #--------------------------------------------------\n",
    "    #针对上面一般的保存方法，加载的方法分别是：\n",
    "    # model_dict=torch.load(PATH)\n",
    "    # model_dict=model.load_state_dict(torch.load(PATH))\n",
    "    # Test which classes performed well\n",
    "    valid(net, device, valid_loader, classes)\n",
    "    # Let's load the model we just created and test the accuracy per label\n",
    "    # model = net()\n",
    "    # path = \"myFirstModel.pth\"\n",
    "    # model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed in:  0.3254041909822263  seconds\n",
      "[21] tensor([14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0787\n",
      "Precision: 0.1514\n",
      "Recall: 0.0787\n",
      "F1 Score: 0.0640\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0-10       0.00      0.00      0.00         0\n",
      "       10-20       0.00      0.00      0.00         0\n",
      "       20-30       0.00      0.00      0.00         0\n",
      "       30-40       0.00      0.00      0.00         4\n",
      "       40-50       0.00      0.00      0.00        22\n",
      "       50-60       0.00      0.00      0.00        13\n",
      "       60-70       0.00      0.00      0.00        12\n",
      "       70-80       0.16      0.30      0.21        20\n",
      "       80-90       0.00      0.00      0.00        14\n",
      "      90-100       0.00      0.00      0.00         8\n",
      "     100-110       0.00      0.00      0.00        17\n",
      "     110-120       0.00      0.00      0.00        11\n",
      "     120-130       0.00      0.00      0.00        10\n",
      "     130-140       0.00      0.00      0.00         9\n",
      "     140-150       0.00      0.00      0.00        10\n",
      "     150-160       0.17      0.25      0.20        16\n",
      "     160-170       0.25      0.07      0.11        15\n",
      "     170-180       0.03      0.10      0.04        10\n",
      "     180-190       0.03      0.20      0.06        15\n",
      "     190-200       0.06      0.27      0.09        15\n",
      "     200-210       0.50      0.05      0.09        21\n",
      "     210-220       0.14      0.09      0.11        22\n",
      "     220-230       0.67      0.06      0.11        32\n",
      "     230-240       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.08      0.08      0.08       305\n",
      "   macro avg       0.08      0.06      0.04       305\n",
      "weighted avg       0.15      0.08      0.06       305\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.07868852459016394,\n",
       " 0.1513948113976228,\n",
       " 0.07868852459016394,\n",
       " 0.06404489201858853,\n",
       " array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "          0,  1,  0,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  9,  1,  1,  0,  0,  0,  0,  0,  0,\n",
       "          0,  2,  3,  6,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  6,  0,  2,  0,  1,  0,  0,  0,  0,\n",
       "          0,  0,  2,  2,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  2,\n",
       "          0,  0,  1,  7,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  1,  0,  6,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "          1,  2,  2,  7,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "          1,  1,  1,  3,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "          0,  1,  1,  2,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  4,  3,  8,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "          0,  0,  7,  2,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,\n",
       "          0,  3,  3,  1,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  3,  4,  1,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1,  4,  4,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,\n",
       "          0,  3,  5,  3,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "          1,  2,  7,  2,  0,  0,  1,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  1,\n",
       "          0,  1,  5,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,\n",
       "          0,  3,  3,  7,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  3,\n",
       "          0,  2,  5,  4,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  2,\n",
       "          0,  3,  8,  4,  1,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  2,\n",
       "          1,  3, 10,  2,  0,  2,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  3,\n",
       "          0,  0, 14,  4,  1,  4,  2,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  3,\n",
       "          0,  0,  1,  1,  0,  2,  0,  0]]),\n",
       " '              precision    recall  f1-score   support\\n\\n        0-10       0.00      0.00      0.00         0\\n       10-20       0.00      0.00      0.00         0\\n       20-30       0.00      0.00      0.00         0\\n       30-40       0.00      0.00      0.00         4\\n       40-50       0.00      0.00      0.00        22\\n       50-60       0.00      0.00      0.00        13\\n       60-70       0.00      0.00      0.00        12\\n       70-80       0.16      0.30      0.21        20\\n       80-90       0.00      0.00      0.00        14\\n      90-100       0.00      0.00      0.00         8\\n     100-110       0.00      0.00      0.00        17\\n     110-120       0.00      0.00      0.00        11\\n     120-130       0.00      0.00      0.00        10\\n     130-140       0.00      0.00      0.00         9\\n     140-150       0.00      0.00      0.00        10\\n     150-160       0.17      0.25      0.20        16\\n     160-170       0.25      0.07      0.11        15\\n     170-180       0.03      0.10      0.04        10\\n     180-190       0.03      0.20      0.06        15\\n     190-200       0.06      0.27      0.09        15\\n     200-210       0.50      0.05      0.09        21\\n     210-220       0.14      0.09      0.11        22\\n     220-230       0.67      0.06      0.11        32\\n     230-240       0.00      0.00      0.00         9\\n\\n   micro avg       0.08      0.08      0.08       305\\n   macro avg       0.08      0.06      0.04       305\\nweighted avg       0.15      0.08      0.06       305\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "net.to(device)\n",
    "net.eval()\n",
    "predictions = []\n",
    "label1 = []\n",
    "dataiter=iter(valid_loader)\n",
    "images, label0 = dataiter.__next__()\n",
    "\n",
    "start_time = time.process_time()\n",
    "with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"Prediction completed in: \", (end_time - start_time), \" seconds\")\n",
    "\n",
    "print(predictions, label0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
