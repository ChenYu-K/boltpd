{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os,random\n",
    "import torchvision.transforms as T\n",
    "import csv\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#my imports\n",
    "import mynet\n",
    "import train\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter #tensorboard --logdir log --bind_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径: /home/br-python/Documents/chen/boltpd\n"
     ]
    }
   ],
   "source": [
    "# 获取当前路径\n",
    "current_directory = os.getcwd()\n",
    "print(\"当前路径:\", current_directory)\n",
    "\n",
    "# 定义要变更的目标路径\n",
    "#target_directory = \"D:/AI/boltpd\"\n",
    "\n",
    "# 使用os.chdir()来变更路径\n",
    "#os.chdir(target_directory)\n",
    "\n",
    "# 再次获取当前路径，此时它应该是目标路径\n",
    "#new_current_directory = os.getcwd()\n",
    "#print(\"变更后的路径:\", new_current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.tensor([1, 2, 3]).to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dir):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    pathDir = os.listdir(dir)    #取图片的原始路径\n",
    "    filenumber=len(pathDir)\n",
    "    rate=1    #自定义抽取图片的比例，比方说100张抽10张，那就是0.1\n",
    "    picknumber=int(filenumber*rate) #按照rate比例从文件夹中取一定数量图片\n",
    "    sample = random.sample(pathDir, picknumber)  #随机选取picknumber数量的样本图片\n",
    "\n",
    "    file = pd.read_csv(r'./label/label-2024pretension.csv')\n",
    "    file=np.array(file)\n",
    "    labels=[]\n",
    "    img_data = []\n",
    "    f0 = None\n",
    "    for file_name in sample:\n",
    "        if f0 is None:\n",
    "            f0 = os.path.join(dir, file_name)\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            if int(file_name[-9:-4]) > 9900 or int(file_name[-9:-4]) < 106:\n",
    "                img_dir = os.path.join(dir, file_name)\n",
    "                img = cv2.imread(img_dir)\n",
    "                #ref_img = cv2.imread('./database/c_data/bolt1/DSC01686.JPG')\n",
    "                #img = cv2.subtract(img, ref_img)\n",
    "                #img1 = cv2.subtract(img,cv2.imread(f0))\n",
    "                img = cv2.resize(img, (800, 800))   # /5 resize img\n",
    "                #img_gray = cv.cvtColor(img,cv.COLOR_RniGB2GRAY)\n",
    "                pimg = Image.fromarray(img)\n",
    "                img_data.append(pimg)\n",
    "                for item in file:       #add label, from 1row\n",
    "                    sh = item[1]\n",
    "                    if file_name[-9:-4] == sh[-9:-4]:\n",
    "                        labels.append(item[0]/230)#\n",
    "    labels = torch.tensor(labels)\n",
    "    labels = labels.type(torch.FloatTensor)\n",
    "    labels = labels.unsqueeze(1)\n",
    "    return img_data,labels\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i])#.to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m traindir\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./database/2024preten/inputdata/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m validdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./database/2024preten/testdata/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_rdata, train_label \u001b[38;5;241m=\u001b[39m generate_dataset(traindir)\n\u001b[1;32m      4\u001b[0m valid_rdata, valid_label \u001b[38;5;241m=\u001b[39m generate_dataset(validdir)\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(file_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m9900\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(file_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m106\u001b[39m:\n\u001b[1;32m     21\u001b[0m     img_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, file_name)\n\u001b[0;32m---> 22\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_dir)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#ref_img = cv2.imread('./database/c_data/bolt1/DSC01686.JPG')\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#img = cv2.subtract(img, ref_img)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#img1 = cv2.subtract(img,cv2.imread(f0))\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m800\u001b[39m, \u001b[38;5;241m800\u001b[39m))   \u001b[38;5;66;03m# /5 resize img\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "normMean = [0.5]\n",
    "normStd = [0.5]\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize(450),\n",
    "    #transforms.CenterCrop(448),\n",
    "    transforms.Grayscale(num_output_channels=1), #彩色图像转灰度图像num_output_channels默认1\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    #transforms.Normalize(normMean, normStd)\n",
    "    ])\n",
    "\n",
    "traindir= './database/2024preten/inputdata/'\n",
    "validdir='./database/2024preten/testdata/'\n",
    "train_rdata, train_label = generate_dataset(traindir)\n",
    "valid_rdata, valid_label = generate_dataset(validdir)\n",
    "# 也可以再定义train_transform加入一些数据增强\n",
    "train_data = MyDataset(train_rdata, train_label, transform=transform)\n",
    "valid_data = MyDataset(valid_rdata, valid_label, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=1, shuffle=True)\n",
    "\n",
    "print(len(valid_rdata),len(valid_label))\n",
    "print(len(train_rdata),len(train_label))\n",
    "\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "topic = T.ToPILImage()\n",
    "imm1 = topic(images[0])\n",
    "vimg, vlabels = dataiter.__next__()\n",
    "plt.imshow(topic(vimg[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from net import ResNet, Bottleneck\n",
    "#from SEBlock import SEBlock\n",
    "from loss_func import HuberLossPena\n",
    "#import net\n",
    "\n",
    "    \n",
    "# 输入输出的数据维度，这里都是1维\n",
    "INPUT_FEATURE_DIM = 5000\n",
    "# 隐含层中神经元的个数\n",
    "#NEURON_NUM = 500\n",
    "#OUTPUT_FEATURE_DIM = 1\n",
    "# 学习率，越大学的越快，但也容易造成不稳定，准确率上下波动的情况\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 定义模型\n",
    "\n",
    "net = mynet.ModResnet(block=mynet.Bottleneck, block_num=[3,4,6,3],num_classes=1)\n",
    "#net = ResNet152(block=Bottleneck152,layers=[3, 4, 36, 3],num_classes=1,in_dim=1)\n",
    "casename='case1'\n",
    "writer = SummaryWriter(\"./log/\"+casename) #tensorboard\n",
    "\n",
    "#print(net)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()\n",
    "\n",
    "# 训练网络\n",
    "# 这里也可以使用其它的优化方法\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = torch.optim.SGD(net.parameters(),lr=LEARNING_RATE)\n",
    "# 定义一个误差计算方法\n",
    "loss_func = HuberLossPena(delta=0.01, penalty_weight=3.0)\n",
    "#loss_func = nn.MSELoss()\n",
    "#loss_func = nn.CrossEntropyLoss() #定义交叉熵损失函数 交叉熵损失函数是用来衡量两个概率分布之间的距离的#nn.MSELoss()\n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCUETE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    # Let's build our model\n",
    "    train.train(100,device)\n",
    "    print('Finished Training')\n",
    "    #Epochごとのlossの保存\n",
    "    torch.save(net, \"./result/\"+casename+\"/\"+casename+\".pt\")\n",
    "    # 保存网络中的参数, 速度快，占空间少\n",
    "    #torch.save(net.state_dict(),'case-1-p.pt')\n",
    "    #--------------------------------------------------\n",
    "    #针对上面一般的保存方法，加载的方法分别是：\n",
    "    # model_dict=torch.load(PATH)\n",
    "    # model_dict=model.load_state_dict(torch.load(PATH))\n",
    "    # Test which classes performed well\n",
    "    train.testAccuracy()\n",
    "\n",
    "    # Let's load the model we just created and test the accuracy per label\n",
    "    # model = net()\n",
    "    # path = \"myFirstModel.pth\"\n",
    "    # model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "np.array(x)\n",
    "np.array(y)\n",
    "# net=torch.load('')\n",
    "torch.cuda.empty_cache()\n",
    "net.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "video=cv2.VideoWriter('./multibolt/video/valid.avi',-1,20,(448,448))  \n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(valid_loader, 0):\n",
    "        #images, labels = dataiter.next()\n",
    "        # 输入数据进行预测\n",
    "        # get the inputs\n",
    "        images = Variable(images.to(device))\n",
    "        labels = Variable(labels.to(device))\n",
    "        predata = net(images)\n",
    "        #predata, labedata = predict(net, valid_loader)\n",
    "        loss=loss_func(predata, labels)\n",
    "        loss += loss.item()\n",
    "        x=np.append(x,[i[0] for i in labels.data.cpu().numpy()])\n",
    "        y=np.append(y,np.array([i[0] for i in predata.data.cpu().numpy()]))\n",
    "        preloss=loss/(i+1)\n",
    "\n",
    "x0=x*116\n",
    "y0=y*116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=np.linspace(0,120,120)\n",
    "y=np.linspace(0,120,120)\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "import uncertainties.unumpy as unp\n",
    "import uncertainties as unc\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.xlim(0,120)\n",
    "plt.ylim(0,120)\n",
    "#y_err1=1.1*train_label.data.cpu().numpy()\n",
    "#y_err2=0.9*train_label.data.cpu().numpy()\n",
    "#n = len(y)\n",
    "xx=x0\n",
    "yy=y0\n",
    "n = len(yy)\n",
    "\n",
    "def f(x, a, b):\n",
    "    return np.multiply(a, x) + b\n",
    "\n",
    "#popt, pcov = curve_fit(f, x, y)\n",
    "popt, pcov = curve_fit(f, xx, yy)\n",
    "\n",
    "# retrieve parameter values\n",
    "a = popt[0]\n",
    "b = popt[1]\n",
    "print('Optimal Values')\n",
    "print('a: ' + str(a))\n",
    "print('b: ' + str(b))\n",
    "\n",
    "# compute r^2\n",
    "#r2 = 1.0-(sum((y0-f(x0,a,b))**2.0)/((n-1.0)*np.var(y,ddof=1)))\n",
    "r2 = 1.0-(sum((yy-f(xx,a,b))**2.0)/((n-1.0)*np.var(y,ddof=1)))\n",
    "print('R^2: ' + str(r2))\n",
    "print('testdataNum:' + str(i+1))\n",
    "print('preloss:' + str(preloss))\n",
    "\n",
    "# calculate parameter confidence interval\n",
    "a,b = unc.correlated_values(popt, pcov)\n",
    "print('Uncertainty')\n",
    "print('a: ' + str(a))\n",
    "print('b: ' + str(b))\n",
    "\n",
    "\n",
    "\n",
    "mse = np.mean((x0 - y0) ** 2)\n",
    "rmse = np.sqrt(np.mean((x0 - y0) ** 2))\n",
    "msle = np.mean((np.log1p(x0) - np.log1p(y0))** 2)\n",
    "mae = np.mean(np.abs(x0 - y0))\n",
    "r2 = 1 - np.mean((x0 - y0) ** 2) / np.mean((x0 - x0.mean()) ** 2)\n",
    "print('MSE:=',mse,'| RMSE:',rmse,'|msle:',msle,'|mae:',mae,'|r2:',r2)\n",
    "\n",
    "# calculate regression confidence interval\n",
    "px=np.linspace(0,120,120)\n",
    "py=a*px+b\n",
    "nom = unp.nominal_values(py)\n",
    "std = unp.std_devs(py)\n",
    "\n",
    "def predband(x, xd, yd, p, func, conf=0.95):\n",
    "    # x = requested points\n",
    "    # xd = x data\n",
    "    # yd = y data\n",
    "    # p = parameters\n",
    "    # func = function name\n",
    "    alpha = 1.0 - conf    # significance\n",
    "    N = xd.size          # data sample size\n",
    "    var_n = len(p)  # number of parameters\n",
    "    # Quantile of Student's t distribution for p=(1-alpha/2)\n",
    "    q = stats.t.ppf(1.0 - alpha / 2.0, N - var_n)\n",
    "    # Stdev of an individual measurement\n",
    "    se = np.sqrt(1. / (N - var_n) * \\\n",
    "                 np.sum((yd - func(xd, *p)) ** 2))\n",
    "    # Auxiliary definitions\n",
    "    sx = (x - xd.mean()) ** 2\n",
    "    sxd = np.sum((xd - xd.mean()) ** 2)\n",
    "    # Predicted values (best-fit model)\n",
    "    yp = func(x, *p)\n",
    "    # Prediction band\n",
    "    dy = q * se * np.sqrt(1.0+ (1.0/N) + (sx/sxd))\n",
    "    # Upper & lower prediction bands.\n",
    "    lpb, upb = yp - dy, yp + dy\n",
    "    return lpb, upb\n",
    "\n",
    "#plt.fill_between(df['temperature'], predictions['obs_ci_lower'], predictions['obs_ci_upper'], alpha=.1, label='Prediction interval')\n",
    "# prediction band (95% confidence)\n",
    "\n",
    "# plot the regression\n",
    "#plt.plot(px, nom, c='black', label='Regression Line')\n",
    "\n",
    "lpb, upb = predband(px, xx, yy, popt, f, conf=0.95)\n",
    "\n",
    "\n",
    "#lpb=[x+25 for x in px]\n",
    "#upb=[x-25 for x in px]\n",
    "\n",
    "# uncertainty lines (95% confidence)\n",
    "#plt.plot(px, nom - 1.96 * std, c='orange',\\\n",
    "#        label='95% Confidence Region')\n",
    "#plt.plot(px, nom + 1.96 * std, c='orange')\n",
    "\n",
    "# prediction band (95% confidence)\n",
    "#plt.plot(px, lpb, 'k--',label='95% Prediction Band')\n",
    "#plt.plot(px, upb, 'k--')\n",
    "#plt.fill_between(px,lpb,upb, alpha=.1,)\n",
    "\n",
    "# plot data\n",
    "\n",
    "plt.plot(x0,y0,'ko',alpha=0.6,label='Data', mfc='none')\n",
    "\n",
    "\n",
    "plt.plot(x, y, c='black')\n",
    "#plt.plot(x*0.9,y,'k--',label='90% Error interval')\n",
    "#plt.plot(x*1.1,y,'k--')\n",
    "#plt.fill_between(x,x*1.1,x*0.9, alpha=.1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Label data',fontsize=16)\n",
    "plt.ylabel('Prediction data',fontsize=16)\n",
    "text='$R^2$: {:.2f} \\n$MSE$: {:.1f} \\n$RMSE$: {:.1f} \\n$MAE$: {:.1f}'.format(r2,mse,rmse,mae)\n",
    "plt.text(5,85,text)\n",
    "plt.savefig(\"./result/\"+casename+\"/\"+casename+'predictpreload.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rdata, test_label = generate_dataset(testdir)\n",
    "test_data = MyDataset(test_rdata, test_label, transform=transform)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True)\n",
    "x=[]\n",
    "y=[]\n",
    "np.array(x)\n",
    "np.array(y)\n",
    "net.eval()\n",
    "# net=torch.load('')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader, 0):\n",
    "        #images, labels = dataiter.next()\n",
    "        # 输入数据进行预测\n",
    "        # get the inputs\n",
    "        images = Variable(images.to(device))\n",
    "        labels = Variable(labels.to(device))\n",
    "        predata = net(images)\n",
    "        #predata, labedata = predict(net, valid_loader)\n",
    "        loss=loss_func(predata, labels)\n",
    "        loss += loss.item()\n",
    "        x=np.append(x,[i[0] for i in labels.data.cpu().numpy()])\n",
    "        y=np.append(y,np.array([i[0] for i in predata.data.cpu().numpy()]))\n",
    "        preloss=loss/(i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=np.linspace(0,120,120)\n",
    "y0=np.linspace(0,120,120)\n",
    "plt.plot(x0, y0, c='black')\n",
    "plt.plot(x*116,y*116,'ko',alpha=0.6,label='Data', mfc='none')\n",
    "plt.xlabel('Label data',fontsize=16)\n",
    "plt.ylabel('Prediction data',fontsize=16)\n",
    "plt.show\n",
    "plt.savefig(\"./result/\"+casename+\"/\"+casename+'testother.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case27=torch.load('./result/case2-7/case2-7.pt')\n",
    "print(case27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net27=torch.load('./result/case2-7/case2-7.pt')\n",
    "x=[]\n",
    "y=[]\n",
    "np.array(x)\n",
    "np.array(y)\n",
    "# net=torch.load('')\n",
    "torch.cuda.empty_cache()\n",
    "net.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "codec = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "video=cv2.VideoWriter('valid.avi',fourcc,10,(448,448))  \n",
    "c = (0,0,255)\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(valid_loader, 0):\n",
    "        #images, labels = dataiter.next()\n",
    "        # 输入数据进行预测\n",
    "        # get the inputs\n",
    "        images = Variable(images.to(device))\n",
    "        \n",
    "        labels = Variable(labels.to(device))\n",
    "        predata = net27(images)\n",
    "        #predata, labedata = predict(net, valid_loader)\n",
    "        outproload=predata*116\n",
    "        outlabel=labels*116\n",
    "        erro=(outlabel-outproload)*100/outproload\n",
    "        loss=loss_func(predata, labels)\n",
    "        loss += loss.item()\n",
    "        tmp = images[0,:,:,:].permute(1, 2, 0)\n",
    "        rgb=tmp.to('cpu').detach().numpy()\n",
    "        rgb = (rgb*255.0).astype(np.uint8)\n",
    "        img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        x=np.append(x,[i[0] for i in labels.data.cpu().numpy()])\n",
    "        y=np.append(y,np.array([i[0] for i in predata.data.cpu().numpy()]))\n",
    "        preloss=loss/(i+1)\n",
    "        txt1 = 'Axial Force='+str(np.round(outproload.data.cpu().numpy()))+'/'+str(np.round(outlabel.data.cpu().numpy()))\n",
    "        txt2= ' Error='+str(np.round(erro.data.cpu().numpy()))+'%'\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cat_size = cv2.getTextSize(txt, font, 2, 5)[0]\n",
    "        cv2.rectangle(img, (25, 15), (430, 420), c , 2)\n",
    "        #cv2.rectangle(img,(50,50 - cat_size[1] - 2),(box[0] + cat_size[0],400 - 2), c, -1)\n",
    "        cv2.putText(img, txt1, (20, 50), font, 1, (255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(img, txt2, (20, 80), font, 1, (255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        #plt.figure(figsize=(450,450))\n",
    "        plt.imshow(img)\n",
    "        video.write(img)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnorm(img, mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]):\n",
    "    for t, m, s in zip(img, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return img \n",
    "\n",
    "i, (images, labels) = enumerate(valid_loader, 0)\n",
    "#a= unnorm(images[14,:,:,:]).permute(1, 2, 0)\n",
    "print(images.shape)\n",
    "print(a.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
