{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os,random\n",
    "import torchvision.transforms as T\n",
    "import csv\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "#my imports\n",
    "\n",
    "import train\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter #tensorboard --logdir log --bind_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径: /home/br-python/Documents/chen/boltpd\n",
      "2.0.0+cu117\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"当前路径:\", current_directory)\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# x = torch.tensor([1, 2, 3]).to(device)\n",
    "# print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def classify_force(force):\n",
    "        # 将轴力分为10个单位一类的标签，并确保标签在0-23之间\n",
    "        return min(int(force // 10), 23)\n",
    "\n",
    "label=classify_force(125)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def generate_dataset(dir):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    pathDir = os.listdir(dir)    #取图片的原始路径\n",
    "    filenumber=len(pathDir)\n",
    "    rate=1    #自定义抽取图片的比例，比方说100张抽10张，那就是0.1\n",
    "    picknumber=int(filenumber*rate) #按照rate比例从文件夹中取一定数量图片\n",
    "    sample = random.sample(pathDir, picknumber)  #随机选取picknumber数量的样本图片\n",
    "\n",
    "    file = pd.read_csv(r'./label/AI-bolt-color-202404-inkan.csv') # 读取csv数据\n",
    "    file=np.array(file)#注意数据会跳过第一行，第一行为索引标题\n",
    "    labels=[]\n",
    "    img_data = []\n",
    "    f0 = None\n",
    "    def classify_force(force):\n",
    "        # 将轴力分为10个单位一类的标签\n",
    "        return min((force // 10) ,23)\n",
    "\n",
    "    for file_name in sample:\n",
    "        if f0 is None:\n",
    "            f0 = os.path.join(dir, file_name)\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            if int(file_name[-9:-4]) > 2097 and int(file_name[-9:-4]) < 3597:\n",
    "                img_dir = os.path.join(dir, file_name)\n",
    "                img = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "                ref_img = cv2.imread('database/202404-inkan/output-resize/DSC02098.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Apply Fourier Transform to both images\n",
    "                f_transform_initial = fft2(img)\n",
    "                f_shift_initial = fftshift(f_transform_initial)\n",
    "                phase_spectrum_initial = np.angle(f_shift_initial)\n",
    "\n",
    "                f_transform_ref = fft2(ref_img)\n",
    "                f_shift_ref = fftshift(f_transform_ref)\n",
    "                phase_spectrum_ref = np.angle(f_shift_ref)\n",
    "\n",
    "                # Subtract the phase spectrum of the reference image from the initial image\n",
    "                phase_spectrum_diff = phase_spectrum_initial - phase_spectrum_ref\n",
    "\n",
    "                # Apply a high-pass filter to the phase difference (optional)\n",
    "                rows, cols = image.shape\n",
    "                crow, ccol = rows // 2 , cols // 2\n",
    "                mask = np.ones((rows, cols), np.uint8)\n",
    "                r = 30  # Radius of the high-pass filter\n",
    "                center = [crow, ccol]\n",
    "                x, y = np.ogrid[:rows, :cols]\n",
    "                mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n",
    "                mask[mask_area] = 0\n",
    "\n",
    "                # Apply the mask\n",
    "                f_shift_diff = fftshift(fft2(phase_spectrum_diff)) * mask\n",
    "\n",
    "                ## Reconstruct the image using the phase spectrum difference\n",
    "                #f_transform_diff = np.abs(f_shift_initial) * np.exp(1j * phase_spectrum_diff)\n",
    "\n",
    "                # Inverse Fourier Transform\n",
    "                img_diff_pa = np.abs(ifft2(ifftshift(f_shift_diff )))\n",
    "\n",
    "                img_data.append(img_diff_pa)\n",
    "                #img_data.append(file_name)\n",
    "                for item in file:       #add label, from 1row\n",
    "                    sh = item[1]\n",
    "                    if file_name[-9:-4] == sh[-9:-4]:\n",
    "                        force = item[0]\n",
    "                        label = classify_force(force)\n",
    "                        labels.append(label)\n",
    "    # 将标签转换为one-hot编码\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    #labels = torch.nn.functional.one_hot(labels, num_classes=24)  # 23类分类，外加1类(即24类)\n",
    "    return img_data, labels\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i]) #.to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Custom transform for adding Gaussian noise\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "        return tensor + noise\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(mean={self.mean}, std={self.std})'\n",
    "\n",
    "# Data augmentation transform\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Resize(1200),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(mean=0.0, std=0.1),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Original transform\n",
    "original_transform = transforms.Compose([\n",
    "    transforms.Resize(1200),\n",
    "    transforms.CenterCrop(800),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def generate_augmented_dataset(dir, csv_file, augment_times=5):\n",
    "    pathDir = os.listdir(dir)\n",
    "    filenumber = len(pathDir)\n",
    "    sample = random.sample(pathDir, filenumber)\n",
    "    \n",
    "    file = pd.read_csv(csv_file)\n",
    "    file = np.array(file)\n",
    "    labels = []\n",
    "    img_data = []\n",
    "\n",
    "    def classify_force(force):\n",
    "        return min((force // 10), 23)\n",
    "\n",
    "    for file_name in sample:\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            if int(file_name[-9:-4]) > 2097 and int(file_name[-9:-4]) < 3597:\n",
    "                img_dir = os.path.join(dir, file_name)\n",
    "                img = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "                ref_img = cv2.imread('database/202404-inkan/output-resize/DSC02098.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Apply Fourier Transform to both images\n",
    "                f_transform_initial = fft2(img)\n",
    "                f_shift_initial = fftshift(f_transform_initial)\n",
    "                phase_spectrum_initial = np.angle(f_shift_initial)\n",
    "\n",
    "                f_transform_ref = fft2(ref_img)\n",
    "                f_shift_ref = fftshift(f_transform_ref)\n",
    "                phase_spectrum_ref = np.angle(f_shift_ref)\n",
    "\n",
    "                # Subtract the phase spectrum of the reference image from the initial image\n",
    "                phase_spectrum_diff = phase_spectrum_initial - phase_spectrum_ref\n",
    "\n",
    "                # Apply a high-pass filter to the phase difference (optional)\n",
    "                rows, cols = img.shape\n",
    "                crow, ccol = rows // 2 , cols // 2\n",
    "                mask = np.ones((rows, cols), np.uint8)\n",
    "                r = 30  # Radius of the high-pass filter\n",
    "                center = [crow, ccol]\n",
    "                x, y = np.ogrid[:rows, :cols]\n",
    "                mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n",
    "                mask[mask_area] = 0\n",
    "\n",
    "                # Apply the mask\n",
    "                f_shift_diff = fftshift(fft2(phase_spectrum_diff)) * mask\n",
    "\n",
    "                ## Reconstruct the image using the phase spectrum difference\n",
    "                #f_transform_diff = np.abs(f_shift_initial) * np.exp(1j * phase_spectrum_diff)\n",
    "\n",
    "                # Inverse Fourier Transform\n",
    "                img_diff_pa = np.abs(ifft2(fftshift(f_shift_diff )))\n",
    "\n",
    "                pimg = Image.fromarray(phase_spectrum_diff)\n",
    "                pimg = original_transform(pimg)\n",
    "                img_data.append(pimg)\n",
    "\n",
    "                for item in file:\n",
    "                    sh = item[1]\n",
    "                    if file_name[-9:-4] == sh[-9:-4]:\n",
    "                        force = item[0]\n",
    "                        label = classify_force(force)\n",
    "                        labels.extend([label] * (augment_times + 1))\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return img_data, labels\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.imgs = list(zip(data, labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "traindir = 'database/202404-inkan/output-resize/'\n",
    "validdir = 'database/202404-inkan/valid-or/'\n",
    "csv_file = './label/AI-bolt-color-202404-inkan.csv'\n",
    "\n",
    "train_rdata, train_label = generate_augmented_dataset(traindir, csv_file, augment_times=0)\n",
    "valid_rdata, valid_label = generate_augmented_dataset(validdir, csv_file, augment_times=0)\n",
    "\n",
    "train_data = MyDataset(train_rdata, train_label)\n",
    "valid_data = MyDataset(valid_rdata, valid_label)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194 1194\n",
      "305 305\n",
      "torch.Size([1, 1, 800, 800])\n",
      "tensor([8])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7737c43ad010>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_rdata), len(train_label))\n",
    "print(len(valid_rdata), len(valid_label))\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "topic = T.ToPILImage()\n",
    "imm1 = topic(images[0])\n",
    "vimg, vlabels = dataiter.__next__()\n",
    "plt.imshow(topic(vimg[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        in_channel：残差块输入通道数\n",
    "        out_channel：残差块输出通道数\n",
    "        stride：卷积步长\n",
    "        downsample：在_make_layer函数中赋值，用于控制shortcut图片下采样 H/2 W/2\n",
    "    \"\"\"\n",
    "    expansion = 4   # 残差块第3个卷积层的通道膨胀倍率\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)   # H,W不变。C: in_channel -> out_channel\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, bias=False, padding=1)  # H/2，W/2。C不变\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*self.expansion, kernel_size=1, stride=1, bias=False)   # H,W不变。C: out_channel -> 4*out_channel\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Add SEBlock\n",
    "        self.seblock = SEBlock(out_channel*self.expansion)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x    # 将原始输入暂存为shortcut的输出\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)   # 如果需要下采样，那么shortcut后:H/2，W/2。C: out_channel -> 4*out_channel(见ResNet中的downsample实现)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        #Apply SEBlock\n",
    "        out = self.seblock(out)\n",
    "\n",
    "        out += identity     # 残差连接0 n\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ModResdic(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        block: 堆叠的基本模块\n",
    "        block_num: 基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        num_classes: 全连接之后的分类特征维度\n",
    "\n",
    "    _make_layer\n",
    "        block: 堆叠的基本模块\n",
    "        channel: 每个stage中堆叠模块的第一个卷积的卷积核个数，对resnet50分别是:64,128,256,512\n",
    "        block_num: 当期stage堆叠block个数\n",
    "        stride: 默认卷积步长\n",
    "    \"\"\"\n",
    "    def __init__(self, block, block_num, num_classes, num_attention_heads=4):\n",
    "        super(ModResdic, self).__init__()\n",
    "        self.in_channel = 64    # conv1的输出维度\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3, bias=False)     # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     # H/2,W/2。C不变\n",
    "        self.layer1 = self._make_layer(block=block, channel=64, block_num=block_num[0], stride=1)   # H,W不变。downsample控制的shortcut，out_channel=64x4=256\n",
    "        self.layer2 = self._make_layer(block=block, channel=128, block_num=block_num[1], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=128x4=512\n",
    "        self.layer3 = self._make_layer(block=block, channel=256, block_num=block_num[2], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=256x4=1024\n",
    "        self.layer4 = self._make_layer(block=block, channel=512, block_num=block_num[3], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=512x4=2048\n",
    "\n",
    "        # 添加自注意力层\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=2048, num_heads=num_attention_heads)\n",
    "\n",
    "        # Add SEBlocks after each residual block in the feature extraction layers\n",
    "        self.seblock1 = SEBlock(64 * block.expansion)\n",
    "        self.seblock2 = SEBlock(128 * block.expansion)\n",
    "        self.seblock3 = SEBlock(256 * block.expansion)\n",
    "        self.seblock4 = SEBlock(512 * block.expansion)\n",
    "\n",
    "        self.fusion4 = MultiScaleFusion(1024 * block.expansion)\n",
    "        self.fusion3 = MultiScaleFusion(512 * block.expansion)\n",
    "        self.fusion2 = MultiScaleFusion(256 * block.expansion)\n",
    "        self.fusion1 = MultiScaleFusion(128 * block.expansion)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc1 = nn.Linear(in_features=512*block.expansion, out_features=1024) #in=2048,out=1024\n",
    "        self.dropout = nn.Dropout(0.8) #dropout rate\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=1024) #in=1024, out=1\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=num_classes) #in=512, out=1\n",
    "        #self.fc4 = nn.Linear(in_features=64, out_features=num_classes) #in=128, out=1\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Upsampling layers for feature fusion\n",
    "        self.upsample = lambda x: nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=None).to(x.device)\n",
    "        #self.upsample = nn.functional.interpolate(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        for m in self.modules():    # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None   # 用于控制shorcut路的\n",
    "        if stride != 1 or self.in_channel != channel*block.expansion:   # 对resnet50：conv2中特征图尺寸H,W不需要下采样/2，但是通道数x4，因此shortcut通道数也需要x4。对其余conv3,4,5，既要特征图尺寸H,W/2，又要shortcut维度x4\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel*block.expansion, kernel_size=1, stride=stride, bias=False), # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel*block.expansion))\n",
    "\n",
    "        layers = []  # 每一个convi_x的结构保存在一个layers列表中，i={2,3,4,5}\n",
    "        layers.append(block(in_channel=self.in_channel, out_channel=channel, downsample=downsample, stride=stride)) # 定义convi_x中的第一个残差块，只有第一个需要设置downsample和stride\n",
    "        self.in_channel = channel*block.expansion   # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            layers.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "\n",
    "        return nn.Sequential(*layers)   # '*'的作用是将list转换为非关键字参数传入\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x1 = self.fusion1(x1)\n",
    "        x1 = self.seblock1(x1)\n",
    "        x2 = self.layer2(x1)\n",
    "        #x2 = self.seblock2(x2)\n",
    "        #x2 = self.fusion2(x2)\n",
    "        x3 = self.layer3(x2)\n",
    "        #x3 = self.seblock3(x3)\n",
    "        #x3 = self.fusion3(x3)\n",
    "        x4 = self.layer4(x3)\n",
    "        x4 = self.seblock4(x4)\n",
    "        x4 = self.fusion4(x4)\n",
    "\n",
    "        x = self.avgpool(x4)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 添加自注意力层\n",
    "        x, _ = self.self_attention(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))\n",
    "        x = x.squeeze(0)  # 移除添加的维度以适应全连接层的输入要求\n",
    "\n",
    "        #x = x.unsqueeze(0)  # 添加一个维度以适应自注意力层的输入要求\n",
    "        #x, _ = self.self_attention(x, x, x)\n",
    "        \n",
    "        #x = self.relu(self.fc1(x))\n",
    "        #x = self.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MultiScaleFusion(nn.Module):\n",
    "    def __init__(self,out_channels):\n",
    "        super(MultiScaleFusion, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义融合的卷积层\n",
    "        self.fusion_conv = nn.Conv2d(4*out_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        out = torch.cat([x,x1, x2, x3], dim=1)\n",
    "        # 对融合的特征图进行卷积操作\n",
    "        out = self.fusion_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ModResv2(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        block: 堆叠的基本模块\n",
    "        block_num: 基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        num_classes: 全连接之后的分类特征维度\n",
    "\n",
    "    _make_layer\n",
    "        block: 堆叠的基本模块\n",
    "        channel: 每个stage中堆叠模块的第一个卷积的卷积核个数，对resnet50分别是:64,128,256,512\n",
    "        block_num: 当期stage堆叠block个数\n",
    "        stride: 默认卷积步长\n",
    "    \"\"\"\n",
    "    def __init__(self, block, block_num, num_classes, num_attention_heads=4):\n",
    "        super(ModResv2, self).__init__()\n",
    "        self.in_channel = 64    # conv1的输出维度\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3, bias=False)     # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     # H/2,W/2。C不变\n",
    "        self.layer1 = self._make_layer(block=block, channel=64, block_num=block_num[0], stride=1)   # H,W不变。downsample控制的shortcut，out_channel=64x4=256\n",
    "        self.layer2 = self._make_layer(block=block, channel=128, block_num=block_num[1], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=128x4=512\n",
    "        self.layer3 = self._make_layer(block=block, channel=256, block_num=block_num[2], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=256x4=1024\n",
    "        self.layer4 = self._make_layer(block=block, channel=512, block_num=block_num[3], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=512x4=2048\n",
    "        \n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=2048, num_heads=num_attention_heads)\n",
    "\n",
    "        # Add SEBlocks after each residual block in the feature extraction layers\n",
    "        self.seblock1 = SEBlock(64 * block.expansion)\n",
    "        self.seblock2 = SEBlock(128 * block.expansion)\n",
    "        self.seblock3 = SEBlock(256 * block.expansion)\n",
    "        self.seblock4 = SEBlock(512 * block.expansion)\n",
    "\n",
    "        self.fusion4 = MultiScaleFusion(512 * block.expansion)\n",
    "        #self.fusion3 = MultiScaleFusion(256 * block.expansion)\n",
    "        #self.fusion2 = MultiScaleFusion(128 * block.expansion)\n",
    "        self.fusion1 = MultiScaleFusion(64 * block.expansion)\n",
    "\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc1 = nn.Linear(in_features=512*block.expansion, out_features=1024) #in=2048,out=1024\n",
    "        self.dropout = nn.Dropout(0.6) #dropout rate\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=num_classes) #in=1024, out=1\n",
    "        #self.fc3 = nn.Linear(in_features=512, out_features=num_classes) #in=512, out=1\n",
    "        #self.fc4 = nn.Linear(in_features=64, out_features=num_classes) #in=128, out=1\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Upsampling layers for feature fusion\n",
    "        self.upsample = lambda x: nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=None).to(x.device)\n",
    "        #self.upsample = nn.functional.interpolate(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        for m in self.modules():    # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None   # 用于控制shorcut路的\n",
    "        if stride != 1 or self.in_channel != channel*block.expansion:   # 对resnet50：conv2中特征图尺寸H,W不需要下采样/2，但是通道数x4，因此shortcut通道数也需要x4。对其余conv3,4,5，既要特征图尺寸H,W/2，又要shortcut维度x4\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel*block.expansion, kernel_size=1, stride=stride, bias=False), # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel*block.expansion))\n",
    "\n",
    "        layers = []  # 每一个convi_x的结构保存在一个layers列表中，i={2,3,4,5}\n",
    "        layers.append(block(in_channel=self.in_channel, out_channel=channel, downsample=downsample, stride=stride)) # 定义convi_x中的第一个残差块，只有第一个需要设置downsample和stride\n",
    "        self.in_channel = channel*block.expansion   # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            layers.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "\n",
    "        return nn.Sequential(*layers)   # '*'的作用是将list转换为非关键字参数传入\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x1 = self.seblock1(x1)\n",
    "        x1 = self.fusion1(x1)\n",
    "        x2 = self.layer2(x1)\n",
    "        x2 = self.seblock2(x2)\n",
    "        x3 = self.layer3(x2)\n",
    "        x3 = self.seblock3(x3)\n",
    "        x4 = self.layer4(x3)\n",
    "        x4 = self.seblock4(x4)\n",
    "        x4 = self.fusion4(x4)\n",
    "\n",
    "        x = self.avgpool(x4)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 添加自注意力层\n",
    "        x, _ = self.self_attention(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))\n",
    "        x = x.squeeze(0) \n",
    "\n",
    "        #x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        #x = self.activation(self.fc2(x))\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy():\n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valid_loader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = accuracy / total\n",
    "    print('Accuracy: ', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def valid(model, device, valid_loader, classes):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # 计算各项指标\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted', labels=np.arange(24))\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=np.arange(24))\n",
    "    class_report = classification_report(all_labels, all_predictions, target_names=classes, labels=np.arange(24))\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print('\\nClassification Report:\\n', class_report)\n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, conf_matrix, class_report\n",
    "\n",
    "def train(num_epochs,device,net):\n",
    "    import time\n",
    "    start_time = time.process_time()\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    k=0\n",
    "    predata=[]\n",
    "    labeldata=[]\n",
    "    mseloss=[]\n",
    "    trainnum=[]\n",
    "    epochout=[]\n",
    "    epochV=[]\n",
    "    vloss=[]\n",
    "    vr2=[]\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    net.to(device)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            prediction = net(images)\n",
    "            loss = loss_func(prediction, labels)*100\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            running_corrects += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                avg_loss = running_loss / 10\n",
    "                avg_acc = running_corrects / total_samples\n",
    "                \n",
    "                print(f'[Epoch: {epoch+1}/{num_epochs}] - Step: {i+1}/{len(train_loader)} | Loss: {avg_loss:.3f} | Accuracy: {avg_acc:.3f}')\n",
    "\n",
    "                mseloss.append(running_loss/10)\n",
    "                trainnum.append(i+1)\n",
    "                epochout.append(epoch+1)\n",
    "                result=pd.DataFrame({'epoch':epochout,'trainnum':trainnum,'loss':mseloss})\n",
    "                result.to_csv(\"./result/\"+casename+\"/\"+casename+\"-result.csv\",index=False,sep=',')\n",
    "\n",
    "                # Tensorboard\n",
    "                writer.add_scalar('Training loss', avg_loss, epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('ACC', avg_acc, epoch * len(train_loader) + i)\n",
    "\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0.0\n",
    "                total_samples = 0\n",
    "\n",
    "            predata.append(prediction.data.cpu().numpy()[0])\n",
    "            labeldata.append(labels.data.cpu().numpy()[0])\n",
    "\n",
    "        valid_accuracy = testAccuracy()\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "            print('Model saved!')\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    print(\"Training completed in: \", (end_time - start_time) / 3600, \" hours\")\n",
    "\n",
    "def predict(net, device, dataloader):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModResv2(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.01)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (seblock): SEBlock(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=2048, out_features=2048, bias=True)\n",
      "  )\n",
      "  (seblock1): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock2): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock3): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=64, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=1024, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (seblock4): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=128, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=128, out_features=2048, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (fusion4): MultiScaleFusion(\n",
      "    (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(2048, 2048, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (fusion_conv): Conv2d(8192, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (fusion1): MultiScaleFusion(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (fusion_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=24, bias=True)\n",
      "  (fc): Linear(in_features=2048, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#from net import ResNet, Bottleneck\n",
    "#from SEBlock import SEBlock\n",
    "from loss_func import HuberLossPena\n",
    "\n",
    "classes = [f'{i*10}-{i*10+10}' for i in range(24)]\n",
    "    \n",
    "# 输入输出的数据维度，这里都是1维\n",
    "INPUT_FEATURE_DIM = 5000\n",
    "# 隐含层中神经元的个数\n",
    "#NEURON_NUM = 500\n",
    "#OUTPUT_FEATURE_DIM = 1\n",
    "# 学习率，越大学的越快，但也容易造成不稳定，准确率上下波动的情况\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# 定义模型\n",
    "net = ModResv2(block=Bottleneck, block_num=[3,4,6,3],num_classes=24) #152 (3,4,36,3)\n",
    "\n",
    "# 训练网络\n",
    "# 这里也可以使用其它的优化方法\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = torch.optim.SGD(net.parameters(),lr=LEARNING_RATE)\n",
    "# 定义一个误差计算方法\n",
    "#loss_func = HuberLossPena(delta=0.1, penalty_weight=5.0)\n",
    "#loss_func = nn.MSELoss()\n",
    "loss_func = nn.CrossEntropyLoss() #定义交叉熵损失函数 交叉熵损失函数是用来衡量两个概率分布之间的距离的#nn.MSELoss()\n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "\n",
    "\n",
    "casename='202406-pa'\n",
    "writer = SummaryWriter(\"./log/\"+casename) #tensorboard\n",
    "\n",
    "print(net)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCUETE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1/200] - Step: 10/1194 | Loss: 309.269 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 20/1194 | Loss: 322.748 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 30/1194 | Loss: 311.121 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 40/1194 | Loss: 294.275 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 50/1194 | Loss: 275.106 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 60/1194 | Loss: 349.641 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 70/1194 | Loss: 266.993 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 80/1194 | Loss: 326.312 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 90/1194 | Loss: 262.356 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 100/1194 | Loss: 320.846 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 110/1194 | Loss: 291.276 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 120/1194 | Loss: 321.864 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 130/1194 | Loss: 290.334 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 140/1194 | Loss: 323.740 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 150/1194 | Loss: 324.089 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 160/1194 | Loss: 320.819 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 170/1194 | Loss: 303.148 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 180/1194 | Loss: 311.706 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 190/1194 | Loss: 295.304 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 200/1194 | Loss: 309.060 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 210/1194 | Loss: 299.374 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 220/1194 | Loss: 342.310 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 230/1194 | Loss: 273.198 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 240/1194 | Loss: 313.745 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 250/1194 | Loss: 318.963 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 260/1194 | Loss: 284.215 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 270/1194 | Loss: 308.253 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 280/1194 | Loss: 330.277 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 290/1194 | Loss: 316.696 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 300/1194 | Loss: 293.683 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 310/1194 | Loss: 314.170 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 320/1194 | Loss: 336.873 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 330/1194 | Loss: 314.456 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 340/1194 | Loss: 310.712 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 350/1194 | Loss: 313.054 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 360/1194 | Loss: 318.690 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 370/1194 | Loss: 306.365 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 380/1194 | Loss: 286.628 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 390/1194 | Loss: 303.080 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 400/1194 | Loss: 325.452 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 410/1194 | Loss: 310.500 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 420/1194 | Loss: 319.038 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 430/1194 | Loss: 309.452 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 440/1194 | Loss: 308.813 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 450/1194 | Loss: 307.887 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 460/1194 | Loss: 308.271 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 470/1194 | Loss: 308.008 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 480/1194 | Loss: 310.571 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 490/1194 | Loss: 295.755 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 500/1194 | Loss: 296.249 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 510/1194 | Loss: 290.103 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 520/1194 | Loss: 293.541 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 530/1194 | Loss: 324.125 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 540/1194 | Loss: 294.308 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 550/1194 | Loss: 284.744 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 560/1194 | Loss: 314.828 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 570/1194 | Loss: 293.920 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 580/1194 | Loss: 303.901 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 590/1194 | Loss: 317.994 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 600/1194 | Loss: 310.917 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 610/1194 | Loss: 309.187 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 620/1194 | Loss: 310.047 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 630/1194 | Loss: 284.799 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 640/1194 | Loss: 305.720 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 650/1194 | Loss: 277.802 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 660/1194 | Loss: 326.714 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 670/1194 | Loss: 291.324 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 680/1194 | Loss: 302.705 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 690/1194 | Loss: 311.176 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 700/1194 | Loss: 292.428 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 710/1194 | Loss: 303.761 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 720/1194 | Loss: 288.193 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 730/1194 | Loss: 291.697 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 740/1194 | Loss: 274.046 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 750/1194 | Loss: 313.338 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 760/1194 | Loss: 285.228 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 770/1194 | Loss: 318.748 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 780/1194 | Loss: 293.042 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 790/1194 | Loss: 308.965 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 800/1194 | Loss: 312.917 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 810/1194 | Loss: 309.988 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 820/1194 | Loss: 339.238 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 830/1194 | Loss: 310.664 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 840/1194 | Loss: 302.842 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 850/1194 | Loss: 310.826 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 860/1194 | Loss: 302.355 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 870/1194 | Loss: 285.664 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 880/1194 | Loss: 304.691 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 890/1194 | Loss: 297.416 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 900/1194 | Loss: 285.805 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 910/1194 | Loss: 287.860 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 920/1194 | Loss: 298.543 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 930/1194 | Loss: 295.405 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 940/1194 | Loss: 296.134 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 950/1194 | Loss: 291.000 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 960/1194 | Loss: 334.046 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 970/1194 | Loss: 266.946 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 980/1194 | Loss: 299.861 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 990/1194 | Loss: 298.873 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1000/1194 | Loss: 316.894 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1010/1194 | Loss: 293.024 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1020/1194 | Loss: 319.944 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1030/1194 | Loss: 302.311 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1040/1194 | Loss: 297.931 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1050/1194 | Loss: 283.684 | Accuracy: 0.300\n",
      "[Epoch: 1/200] - Step: 1060/1194 | Loss: 314.510 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1070/1194 | Loss: 280.925 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1080/1194 | Loss: 315.921 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1090/1194 | Loss: 309.195 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1100/1194 | Loss: 319.938 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1110/1194 | Loss: 291.836 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1120/1194 | Loss: 300.800 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1130/1194 | Loss: 309.902 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1140/1194 | Loss: 286.187 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1150/1194 | Loss: 313.934 | Accuracy: 0.100\n",
      "[Epoch: 1/200] - Step: 1160/1194 | Loss: 304.609 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1170/1194 | Loss: 314.020 | Accuracy: 0.000\n",
      "[Epoch: 1/200] - Step: 1180/1194 | Loss: 292.825 | Accuracy: 0.200\n",
      "[Epoch: 1/200] - Step: 1190/1194 | Loss: 306.539 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "Model saved!\n",
      "[Epoch: 2/200] - Step: 10/1194 | Loss: 633.512 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 20/1194 | Loss: 307.997 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 30/1194 | Loss: 330.636 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 40/1194 | Loss: 296.283 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 50/1194 | Loss: 302.633 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 60/1194 | Loss: 314.210 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 70/1194 | Loss: 313.143 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 80/1194 | Loss: 303.989 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 90/1194 | Loss: 300.282 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 100/1194 | Loss: 271.677 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 110/1194 | Loss: 311.278 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 120/1194 | Loss: 303.703 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 130/1194 | Loss: 309.342 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 140/1194 | Loss: 268.958 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 150/1194 | Loss: 322.596 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 160/1194 | Loss: 315.118 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 170/1194 | Loss: 295.042 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 180/1194 | Loss: 290.251 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 190/1194 | Loss: 299.049 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 200/1194 | Loss: 301.733 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 210/1194 | Loss: 318.149 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 220/1194 | Loss: 305.692 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 230/1194 | Loss: 298.194 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 240/1194 | Loss: 297.098 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 250/1194 | Loss: 305.041 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 260/1194 | Loss: 296.566 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 270/1194 | Loss: 316.435 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 280/1194 | Loss: 302.039 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 290/1194 | Loss: 309.580 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 300/1194 | Loss: 303.401 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 310/1194 | Loss: 306.366 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 320/1194 | Loss: 310.456 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 330/1194 | Loss: 290.633 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 340/1194 | Loss: 306.722 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 350/1194 | Loss: 278.446 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 360/1194 | Loss: 277.693 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 370/1194 | Loss: 311.736 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 380/1194 | Loss: 324.419 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 390/1194 | Loss: 281.482 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 400/1194 | Loss: 318.262 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 410/1194 | Loss: 304.034 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 420/1194 | Loss: 269.912 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 430/1194 | Loss: 319.914 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 440/1194 | Loss: 315.485 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 450/1194 | Loss: 309.328 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 460/1194 | Loss: 290.464 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 470/1194 | Loss: 299.084 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 480/1194 | Loss: 288.249 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 490/1194 | Loss: 266.567 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 500/1194 | Loss: 306.537 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 510/1194 | Loss: 306.334 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 520/1194 | Loss: 319.189 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 530/1194 | Loss: 277.858 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 540/1194 | Loss: 292.276 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 550/1194 | Loss: 274.491 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 560/1194 | Loss: 330.794 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 570/1194 | Loss: 328.525 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 580/1194 | Loss: 311.920 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 590/1194 | Loss: 301.717 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 600/1194 | Loss: 312.116 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 610/1194 | Loss: 317.913 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 620/1194 | Loss: 291.281 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 630/1194 | Loss: 306.109 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 640/1194 | Loss: 299.959 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 650/1194 | Loss: 294.186 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 660/1194 | Loss: 301.716 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 670/1194 | Loss: 307.836 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 680/1194 | Loss: 295.154 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 690/1194 | Loss: 314.824 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 700/1194 | Loss: 297.053 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 710/1194 | Loss: 286.224 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 720/1194 | Loss: 309.171 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 730/1194 | Loss: 288.094 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 740/1194 | Loss: 330.213 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 750/1194 | Loss: 311.792 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 760/1194 | Loss: 311.331 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 770/1194 | Loss: 304.666 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 780/1194 | Loss: 321.623 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 790/1194 | Loss: 306.142 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 800/1194 | Loss: 300.681 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 810/1194 | Loss: 308.420 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 820/1194 | Loss: 308.173 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 830/1194 | Loss: 294.980 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 840/1194 | Loss: 300.550 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 850/1194 | Loss: 316.748 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 860/1194 | Loss: 309.522 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 870/1194 | Loss: 302.842 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 880/1194 | Loss: 300.398 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 890/1194 | Loss: 297.270 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 900/1194 | Loss: 295.074 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 910/1194 | Loss: 269.039 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 920/1194 | Loss: 317.906 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 930/1194 | Loss: 315.422 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 940/1194 | Loss: 299.019 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 950/1194 | Loss: 309.860 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 960/1194 | Loss: 298.708 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 970/1194 | Loss: 297.645 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 980/1194 | Loss: 307.374 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 990/1194 | Loss: 294.450 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1000/1194 | Loss: 285.298 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1010/1194 | Loss: 338.137 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1020/1194 | Loss: 335.673 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1030/1194 | Loss: 296.920 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1040/1194 | Loss: 289.920 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1050/1194 | Loss: 300.821 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1060/1194 | Loss: 299.727 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1070/1194 | Loss: 299.566 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1080/1194 | Loss: 293.069 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1090/1194 | Loss: 293.340 | Accuracy: 0.300\n",
      "[Epoch: 2/200] - Step: 1100/1194 | Loss: 303.959 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1110/1194 | Loss: 308.771 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1120/1194 | Loss: 296.531 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1130/1194 | Loss: 304.195 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1140/1194 | Loss: 331.025 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1150/1194 | Loss: 291.965 | Accuracy: 0.200\n",
      "[Epoch: 2/200] - Step: 1160/1194 | Loss: 310.288 | Accuracy: 0.100\n",
      "[Epoch: 2/200] - Step: 1170/1194 | Loss: 311.960 | Accuracy: 0.000\n",
      "[Epoch: 2/200] - Step: 1180/1194 | Loss: 279.755 | Accuracy: 0.400\n",
      "[Epoch: 2/200] - Step: 1190/1194 | Loss: 260.970 | Accuracy: 0.400\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 3/200] - Step: 10/1194 | Loss: 313.663 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 20/1194 | Loss: 292.887 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 30/1194 | Loss: 305.502 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 40/1194 | Loss: 307.919 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 50/1194 | Loss: 275.687 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 60/1194 | Loss: 309.559 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 70/1194 | Loss: 309.253 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 80/1194 | Loss: 313.938 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 90/1194 | Loss: 305.765 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 100/1194 | Loss: 310.744 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 110/1194 | Loss: 295.170 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 120/1194 | Loss: 290.520 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 130/1194 | Loss: 290.027 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 140/1194 | Loss: 291.571 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 150/1194 | Loss: 300.092 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 160/1194 | Loss: 280.889 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 170/1194 | Loss: 294.253 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 180/1194 | Loss: 300.044 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 190/1194 | Loss: 365.392 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 200/1194 | Loss: 289.523 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 210/1194 | Loss: 301.857 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 220/1194 | Loss: 290.462 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 230/1194 | Loss: 270.862 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 240/1194 | Loss: 300.378 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 250/1194 | Loss: 316.154 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 260/1194 | Loss: 324.069 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 270/1194 | Loss: 297.502 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 280/1194 | Loss: 309.921 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 290/1194 | Loss: 316.135 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 300/1194 | Loss: 292.186 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 310/1194 | Loss: 302.322 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 320/1194 | Loss: 293.717 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 330/1194 | Loss: 302.029 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 340/1194 | Loss: 293.081 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 350/1194 | Loss: 310.829 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 360/1194 | Loss: 290.493 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 370/1194 | Loss: 292.824 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 380/1194 | Loss: 311.611 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 390/1194 | Loss: 306.148 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 400/1194 | Loss: 290.573 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 410/1194 | Loss: 302.461 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 420/1194 | Loss: 280.960 | Accuracy: 0.400\n",
      "[Epoch: 3/200] - Step: 430/1194 | Loss: 265.469 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 440/1194 | Loss: 307.203 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 450/1194 | Loss: 308.287 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 460/1194 | Loss: 313.837 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 470/1194 | Loss: 315.804 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 480/1194 | Loss: 293.088 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 490/1194 | Loss: 302.089 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 500/1194 | Loss: 300.643 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 510/1194 | Loss: 306.517 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 520/1194 | Loss: 289.390 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 530/1194 | Loss: 285.377 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 540/1194 | Loss: 298.325 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 550/1194 | Loss: 317.241 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 560/1194 | Loss: 288.033 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 570/1194 | Loss: 308.609 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 580/1194 | Loss: 302.360 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 590/1194 | Loss: 315.182 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 600/1194 | Loss: 321.758 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 610/1194 | Loss: 308.274 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 620/1194 | Loss: 300.265 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 630/1194 | Loss: 309.355 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 640/1194 | Loss: 298.910 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 650/1194 | Loss: 302.424 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 660/1194 | Loss: 290.092 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 670/1194 | Loss: 313.261 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 680/1194 | Loss: 292.949 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 690/1194 | Loss: 304.539 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 700/1194 | Loss: 285.009 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 710/1194 | Loss: 315.505 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 720/1194 | Loss: 318.106 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 730/1194 | Loss: 282.798 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 740/1194 | Loss: 289.454 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 750/1194 | Loss: 285.239 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 760/1194 | Loss: 295.706 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 770/1194 | Loss: 297.247 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 780/1194 | Loss: 299.077 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 790/1194 | Loss: 291.150 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 800/1194 | Loss: 300.593 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 810/1194 | Loss: 326.388 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 820/1194 | Loss: 298.710 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 830/1194 | Loss: 305.703 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 840/1194 | Loss: 314.590 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 850/1194 | Loss: 297.881 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 860/1194 | Loss: 312.540 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 870/1194 | Loss: 290.579 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 880/1194 | Loss: 304.744 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 890/1194 | Loss: 305.256 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 900/1194 | Loss: 293.622 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 910/1194 | Loss: 292.066 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 920/1194 | Loss: 295.890 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 930/1194 | Loss: 299.172 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 940/1194 | Loss: 305.749 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 950/1194 | Loss: 310.170 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 960/1194 | Loss: 303.730 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 970/1194 | Loss: 302.059 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 980/1194 | Loss: 308.723 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 990/1194 | Loss: 300.481 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1000/1194 | Loss: 291.854 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1010/1194 | Loss: 285.910 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1020/1194 | Loss: 305.461 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1030/1194 | Loss: 286.088 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1040/1194 | Loss: 316.561 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1050/1194 | Loss: 296.930 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1060/1194 | Loss: 303.152 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1070/1194 | Loss: 295.914 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1080/1194 | Loss: 302.537 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1090/1194 | Loss: 309.466 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1100/1194 | Loss: 306.649 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1110/1194 | Loss: 287.600 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1120/1194 | Loss: 325.893 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1130/1194 | Loss: 298.117 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1140/1194 | Loss: 277.830 | Accuracy: 0.300\n",
      "[Epoch: 3/200] - Step: 1150/1194 | Loss: 304.802 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1160/1194 | Loss: 299.274 | Accuracy: 0.100\n",
      "[Epoch: 3/200] - Step: 1170/1194 | Loss: 306.736 | Accuracy: 0.000\n",
      "[Epoch: 3/200] - Step: 1180/1194 | Loss: 290.977 | Accuracy: 0.200\n",
      "[Epoch: 3/200] - Step: 1190/1194 | Loss: 298.839 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 4/200] - Step: 10/1194 | Loss: 300.785 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 20/1194 | Loss: 279.144 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 30/1194 | Loss: 289.340 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 40/1194 | Loss: 310.343 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 50/1194 | Loss: 316.521 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 60/1194 | Loss: 311.357 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 70/1194 | Loss: 313.569 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 80/1194 | Loss: 289.318 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 90/1194 | Loss: 301.473 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 100/1194 | Loss: 289.623 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 110/1194 | Loss: 284.653 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 120/1194 | Loss: 301.352 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 130/1194 | Loss: 299.929 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 140/1194 | Loss: 289.809 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 150/1194 | Loss: 279.792 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 160/1194 | Loss: 282.222 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 170/1194 | Loss: 319.553 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 180/1194 | Loss: 309.403 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 190/1194 | Loss: 276.364 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 200/1194 | Loss: 299.867 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 210/1194 | Loss: 311.948 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 220/1194 | Loss: 273.712 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 230/1194 | Loss: 327.793 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 240/1194 | Loss: 314.805 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 250/1194 | Loss: 281.627 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 260/1194 | Loss: 312.202 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 270/1194 | Loss: 277.748 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 280/1194 | Loss: 307.874 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 290/1194 | Loss: 288.921 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 300/1194 | Loss: 284.242 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 310/1194 | Loss: 303.776 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 320/1194 | Loss: 318.321 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 330/1194 | Loss: 297.765 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 340/1194 | Loss: 289.071 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 350/1194 | Loss: 309.661 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 360/1194 | Loss: 306.206 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 370/1194 | Loss: 322.538 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 380/1194 | Loss: 296.035 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 390/1194 | Loss: 322.778 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 400/1194 | Loss: 302.033 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 410/1194 | Loss: 309.136 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 420/1194 | Loss: 288.954 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 430/1194 | Loss: 292.540 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 440/1194 | Loss: 282.287 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 450/1194 | Loss: 294.242 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 460/1194 | Loss: 315.423 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 470/1194 | Loss: 314.817 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 480/1194 | Loss: 314.847 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 490/1194 | Loss: 281.833 | Accuracy: 0.400\n",
      "[Epoch: 4/200] - Step: 500/1194 | Loss: 317.862 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 510/1194 | Loss: 306.371 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 520/1194 | Loss: 310.049 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 530/1194 | Loss: 293.262 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 540/1194 | Loss: 304.798 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 550/1194 | Loss: 311.375 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 560/1194 | Loss: 295.503 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 570/1194 | Loss: 294.973 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 580/1194 | Loss: 291.991 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 590/1194 | Loss: 285.076 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 600/1194 | Loss: 303.408 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 610/1194 | Loss: 320.113 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 620/1194 | Loss: 288.187 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 630/1194 | Loss: 293.562 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 640/1194 | Loss: 307.607 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 650/1194 | Loss: 302.785 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 660/1194 | Loss: 311.339 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 670/1194 | Loss: 304.759 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 680/1194 | Loss: 299.163 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 690/1194 | Loss: 334.394 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 700/1194 | Loss: 284.656 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 710/1194 | Loss: 306.182 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 720/1194 | Loss: 291.817 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 730/1194 | Loss: 282.422 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 740/1194 | Loss: 291.870 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 750/1194 | Loss: 290.204 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 760/1194 | Loss: 297.130 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 770/1194 | Loss: 308.446 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 780/1194 | Loss: 282.063 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 790/1194 | Loss: 332.065 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 800/1194 | Loss: 307.435 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 810/1194 | Loss: 312.374 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 820/1194 | Loss: 293.475 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 830/1194 | Loss: 297.121 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 840/1194 | Loss: 314.713 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 850/1194 | Loss: 298.440 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 860/1194 | Loss: 301.596 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 870/1194 | Loss: 311.516 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 880/1194 | Loss: 285.257 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 890/1194 | Loss: 297.530 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 900/1194 | Loss: 307.577 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 910/1194 | Loss: 274.955 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 920/1194 | Loss: 305.883 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 930/1194 | Loss: 315.265 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 940/1194 | Loss: 289.647 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 950/1194 | Loss: 287.282 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 960/1194 | Loss: 304.464 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 970/1194 | Loss: 304.265 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 980/1194 | Loss: 305.330 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 990/1194 | Loss: 284.509 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1000/1194 | Loss: 300.986 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1010/1194 | Loss: 305.265 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1020/1194 | Loss: 291.672 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1030/1194 | Loss: 287.836 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1040/1194 | Loss: 303.852 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1050/1194 | Loss: 287.080 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1060/1194 | Loss: 304.874 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1070/1194 | Loss: 307.114 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1080/1194 | Loss: 301.987 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1090/1194 | Loss: 290.937 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1100/1194 | Loss: 275.985 | Accuracy: 0.300\n",
      "[Epoch: 4/200] - Step: 1110/1194 | Loss: 313.438 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1120/1194 | Loss: 302.828 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1130/1194 | Loss: 312.277 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1140/1194 | Loss: 295.464 | Accuracy: 0.000\n",
      "[Epoch: 4/200] - Step: 1150/1194 | Loss: 283.214 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1160/1194 | Loss: 270.878 | Accuracy: 0.200\n",
      "[Epoch: 4/200] - Step: 1170/1194 | Loss: 299.926 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1180/1194 | Loss: 293.306 | Accuracy: 0.100\n",
      "[Epoch: 4/200] - Step: 1190/1194 | Loss: 312.483 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 5/200] - Step: 10/1194 | Loss: 301.900 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 20/1194 | Loss: 292.561 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 30/1194 | Loss: 320.524 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 40/1194 | Loss: 297.929 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 50/1194 | Loss: 314.717 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 60/1194 | Loss: 276.802 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 70/1194 | Loss: 283.942 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 80/1194 | Loss: 288.864 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 90/1194 | Loss: 297.307 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 100/1194 | Loss: 295.740 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 110/1194 | Loss: 314.624 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 120/1194 | Loss: 308.908 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 130/1194 | Loss: 306.435 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 140/1194 | Loss: 298.636 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 150/1194 | Loss: 296.108 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 160/1194 | Loss: 348.607 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 170/1194 | Loss: 306.430 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 180/1194 | Loss: 291.598 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 190/1194 | Loss: 300.498 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 200/1194 | Loss: 322.309 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 210/1194 | Loss: 305.245 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 220/1194 | Loss: 297.043 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 230/1194 | Loss: 294.661 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 240/1194 | Loss: 295.556 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 250/1194 | Loss: 298.498 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 260/1194 | Loss: 260.310 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 270/1194 | Loss: 309.217 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 280/1194 | Loss: 312.148 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 290/1194 | Loss: 292.052 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 300/1194 | Loss: 293.568 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 310/1194 | Loss: 314.811 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 320/1194 | Loss: 301.070 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 330/1194 | Loss: 304.484 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 340/1194 | Loss: 291.393 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 350/1194 | Loss: 303.105 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 360/1194 | Loss: 311.286 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 370/1194 | Loss: 296.682 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 380/1194 | Loss: 288.279 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 390/1194 | Loss: 298.887 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 400/1194 | Loss: 309.676 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 410/1194 | Loss: 284.452 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 420/1194 | Loss: 301.263 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 430/1194 | Loss: 292.694 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 440/1194 | Loss: 295.128 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 450/1194 | Loss: 302.645 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 460/1194 | Loss: 290.126 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 470/1194 | Loss: 292.909 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 480/1194 | Loss: 307.734 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 490/1194 | Loss: 310.484 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 500/1194 | Loss: 296.282 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 510/1194 | Loss: 296.757 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 520/1194 | Loss: 291.680 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 530/1194 | Loss: 300.962 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 540/1194 | Loss: 320.675 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 550/1194 | Loss: 314.701 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 560/1194 | Loss: 296.332 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 570/1194 | Loss: 302.023 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 580/1194 | Loss: 289.830 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 590/1194 | Loss: 303.273 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 600/1194 | Loss: 303.627 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 610/1194 | Loss: 304.664 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 620/1194 | Loss: 279.866 | Accuracy: 0.400\n",
      "[Epoch: 5/200] - Step: 630/1194 | Loss: 305.473 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 640/1194 | Loss: 284.670 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 650/1194 | Loss: 315.009 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 660/1194 | Loss: 312.736 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 670/1194 | Loss: 303.186 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 680/1194 | Loss: 298.507 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 690/1194 | Loss: 292.536 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 700/1194 | Loss: 304.532 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 710/1194 | Loss: 267.621 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 720/1194 | Loss: 291.161 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 730/1194 | Loss: 305.834 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 740/1194 | Loss: 295.677 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 750/1194 | Loss: 280.194 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 760/1194 | Loss: 303.472 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 770/1194 | Loss: 289.697 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 780/1194 | Loss: 300.315 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 790/1194 | Loss: 292.570 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 800/1194 | Loss: 287.042 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 810/1194 | Loss: 291.289 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 820/1194 | Loss: 300.369 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 830/1194 | Loss: 315.616 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 840/1194 | Loss: 298.457 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 850/1194 | Loss: 297.425 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 860/1194 | Loss: 301.438 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 870/1194 | Loss: 309.789 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 880/1194 | Loss: 288.669 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 890/1194 | Loss: 302.004 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 900/1194 | Loss: 289.702 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 910/1194 | Loss: 316.443 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 920/1194 | Loss: 284.178 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 930/1194 | Loss: 291.144 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 940/1194 | Loss: 311.971 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 950/1194 | Loss: 291.994 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 960/1194 | Loss: 286.783 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 970/1194 | Loss: 317.773 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 980/1194 | Loss: 288.904 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 990/1194 | Loss: 307.091 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1000/1194 | Loss: 317.258 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1010/1194 | Loss: 308.139 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1020/1194 | Loss: 306.315 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1030/1194 | Loss: 308.955 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1040/1194 | Loss: 297.545 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1050/1194 | Loss: 283.729 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 1060/1194 | Loss: 296.465 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1070/1194 | Loss: 311.765 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1080/1194 | Loss: 288.277 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 1090/1194 | Loss: 310.683 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1100/1194 | Loss: 320.232 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1110/1194 | Loss: 281.541 | Accuracy: 0.300\n",
      "[Epoch: 5/200] - Step: 1120/1194 | Loss: 289.352 | Accuracy: 0.200\n",
      "[Epoch: 5/200] - Step: 1130/1194 | Loss: 299.338 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1140/1194 | Loss: 307.851 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1150/1194 | Loss: 290.517 | Accuracy: 0.000\n",
      "[Epoch: 5/200] - Step: 1160/1194 | Loss: 289.712 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1170/1194 | Loss: 304.368 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1180/1194 | Loss: 309.203 | Accuracy: 0.100\n",
      "[Epoch: 5/200] - Step: 1190/1194 | Loss: 288.393 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 6/200] - Step: 10/1194 | Loss: 308.679 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 20/1194 | Loss: 301.813 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 30/1194 | Loss: 308.815 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 40/1194 | Loss: 327.568 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 50/1194 | Loss: 298.834 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 60/1194 | Loss: 302.784 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 70/1194 | Loss: 305.418 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 80/1194 | Loss: 294.076 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 90/1194 | Loss: 292.960 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 100/1194 | Loss: 317.662 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 110/1194 | Loss: 307.718 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 120/1194 | Loss: 312.258 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 130/1194 | Loss: 318.940 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 140/1194 | Loss: 302.137 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 150/1194 | Loss: 306.989 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 160/1194 | Loss: 311.662 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 170/1194 | Loss: 310.268 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 180/1194 | Loss: 299.334 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 190/1194 | Loss: 277.931 | Accuracy: 0.500\n",
      "[Epoch: 6/200] - Step: 200/1194 | Loss: 282.883 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 210/1194 | Loss: 307.778 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 220/1194 | Loss: 293.452 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 230/1194 | Loss: 314.303 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 240/1194 | Loss: 291.775 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 250/1194 | Loss: 286.895 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 260/1194 | Loss: 321.211 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 270/1194 | Loss: 315.035 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 280/1194 | Loss: 311.458 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 290/1194 | Loss: 296.589 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 300/1194 | Loss: 296.172 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 310/1194 | Loss: 327.273 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 320/1194 | Loss: 294.048 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 330/1194 | Loss: 286.268 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 340/1194 | Loss: 298.932 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 350/1194 | Loss: 309.960 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 360/1194 | Loss: 291.804 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 370/1194 | Loss: 299.897 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 380/1194 | Loss: 294.234 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 390/1194 | Loss: 291.274 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 400/1194 | Loss: 301.844 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 410/1194 | Loss: 296.470 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 420/1194 | Loss: 281.730 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 430/1194 | Loss: 314.943 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 440/1194 | Loss: 308.184 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 450/1194 | Loss: 303.290 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 460/1194 | Loss: 286.358 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 470/1194 | Loss: 314.786 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 480/1194 | Loss: 297.819 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 490/1194 | Loss: 298.877 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 500/1194 | Loss: 303.827 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 510/1194 | Loss: 298.278 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 520/1194 | Loss: 293.903 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 530/1194 | Loss: 305.268 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 540/1194 | Loss: 312.817 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 550/1194 | Loss: 318.740 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 560/1194 | Loss: 298.951 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 570/1194 | Loss: 303.808 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 580/1194 | Loss: 300.279 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 590/1194 | Loss: 297.055 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 600/1194 | Loss: 287.331 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 610/1194 | Loss: 305.232 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 620/1194 | Loss: 283.437 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 630/1194 | Loss: 285.377 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 640/1194 | Loss: 301.140 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 650/1194 | Loss: 273.879 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 660/1194 | Loss: 297.396 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 670/1194 | Loss: 310.153 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 680/1194 | Loss: 276.439 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 690/1194 | Loss: 293.980 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 700/1194 | Loss: 313.841 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 710/1194 | Loss: 288.717 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 720/1194 | Loss: 277.696 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 730/1194 | Loss: 285.503 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 740/1194 | Loss: 313.969 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 750/1194 | Loss: 290.954 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 760/1194 | Loss: 283.081 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 770/1194 | Loss: 289.526 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 780/1194 | Loss: 303.842 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 790/1194 | Loss: 308.044 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 800/1194 | Loss: 314.787 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 810/1194 | Loss: 287.767 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 820/1194 | Loss: 274.665 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 830/1194 | Loss: 308.839 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 840/1194 | Loss: 297.124 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 850/1194 | Loss: 280.808 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 860/1194 | Loss: 278.660 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 870/1194 | Loss: 290.758 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 880/1194 | Loss: 307.269 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 890/1194 | Loss: 291.598 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 900/1194 | Loss: 273.331 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 910/1194 | Loss: 286.944 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 920/1194 | Loss: 294.298 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 930/1194 | Loss: 313.793 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 940/1194 | Loss: 311.827 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 950/1194 | Loss: 277.605 | Accuracy: 0.300\n",
      "[Epoch: 6/200] - Step: 960/1194 | Loss: 301.681 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 970/1194 | Loss: 310.566 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 980/1194 | Loss: 293.549 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 990/1194 | Loss: 293.428 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1000/1194 | Loss: 313.461 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1010/1194 | Loss: 283.689 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1020/1194 | Loss: 301.436 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1030/1194 | Loss: 297.375 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1040/1194 | Loss: 296.972 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1050/1194 | Loss: 295.248 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1060/1194 | Loss: 293.690 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1070/1194 | Loss: 306.902 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1080/1194 | Loss: 306.640 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1090/1194 | Loss: 316.147 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1100/1194 | Loss: 302.807 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1110/1194 | Loss: 303.764 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1120/1194 | Loss: 299.408 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1130/1194 | Loss: 303.473 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1140/1194 | Loss: 292.826 | Accuracy: 0.200\n",
      "[Epoch: 6/200] - Step: 1150/1194 | Loss: 292.278 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1160/1194 | Loss: 283.155 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1170/1194 | Loss: 284.693 | Accuracy: 0.000\n",
      "[Epoch: 6/200] - Step: 1180/1194 | Loss: 302.508 | Accuracy: 0.100\n",
      "[Epoch: 6/200] - Step: 1190/1194 | Loss: 303.227 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 7/200] - Step: 10/1194 | Loss: 299.041 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 20/1194 | Loss: 321.756 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 30/1194 | Loss: 283.313 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 40/1194 | Loss: 292.553 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 50/1194 | Loss: 289.666 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 60/1194 | Loss: 288.098 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 70/1194 | Loss: 302.059 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 80/1194 | Loss: 304.029 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 90/1194 | Loss: 308.035 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 100/1194 | Loss: 296.775 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 110/1194 | Loss: 297.578 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 120/1194 | Loss: 295.897 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 130/1194 | Loss: 284.922 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 140/1194 | Loss: 305.368 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 150/1194 | Loss: 279.255 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 160/1194 | Loss: 296.840 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 170/1194 | Loss: 307.454 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 180/1194 | Loss: 326.334 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 190/1194 | Loss: 309.012 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 200/1194 | Loss: 286.466 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 210/1194 | Loss: 274.036 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 220/1194 | Loss: 297.790 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 230/1194 | Loss: 319.675 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 240/1194 | Loss: 310.125 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 250/1194 | Loss: 289.099 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 260/1194 | Loss: 300.102 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 270/1194 | Loss: 303.533 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 280/1194 | Loss: 296.922 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 290/1194 | Loss: 299.794 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 300/1194 | Loss: 289.375 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 310/1194 | Loss: 303.251 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 320/1194 | Loss: 327.471 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 330/1194 | Loss: 308.362 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 340/1194 | Loss: 307.873 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 350/1194 | Loss: 296.465 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 360/1194 | Loss: 300.227 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 370/1194 | Loss: 298.623 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 380/1194 | Loss: 295.955 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 390/1194 | Loss: 300.169 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 400/1194 | Loss: 285.548 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 410/1194 | Loss: 296.849 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 420/1194 | Loss: 309.325 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 430/1194 | Loss: 287.146 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 440/1194 | Loss: 291.993 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 450/1194 | Loss: 275.330 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 460/1194 | Loss: 294.696 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 470/1194 | Loss: 292.549 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 480/1194 | Loss: 299.199 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 490/1194 | Loss: 306.485 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 500/1194 | Loss: 280.423 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 510/1194 | Loss: 317.348 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 520/1194 | Loss: 292.060 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 530/1194 | Loss: 296.246 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 540/1194 | Loss: 295.702 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 550/1194 | Loss: 287.524 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 560/1194 | Loss: 290.120 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 570/1194 | Loss: 312.429 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 580/1194 | Loss: 293.844 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 590/1194 | Loss: 299.748 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 600/1194 | Loss: 310.930 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 610/1194 | Loss: 298.553 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 620/1194 | Loss: 291.345 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 630/1194 | Loss: 268.194 | Accuracy: 0.400\n",
      "[Epoch: 7/200] - Step: 640/1194 | Loss: 292.911 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 650/1194 | Loss: 306.759 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 660/1194 | Loss: 295.736 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 670/1194 | Loss: 301.429 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 680/1194 | Loss: 312.369 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 690/1194 | Loss: 302.383 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 700/1194 | Loss: 289.641 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 710/1194 | Loss: 318.434 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 720/1194 | Loss: 296.039 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 730/1194 | Loss: 310.721 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 740/1194 | Loss: 308.519 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 750/1194 | Loss: 310.893 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 760/1194 | Loss: 303.294 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 770/1194 | Loss: 308.645 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 780/1194 | Loss: 301.994 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 790/1194 | Loss: 294.582 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 800/1194 | Loss: 292.011 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 810/1194 | Loss: 331.915 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 820/1194 | Loss: 304.872 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 830/1194 | Loss: 288.272 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 840/1194 | Loss: 298.268 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 850/1194 | Loss: 296.344 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 860/1194 | Loss: 308.544 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 870/1194 | Loss: 285.445 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 880/1194 | Loss: 292.509 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 890/1194 | Loss: 307.721 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 900/1194 | Loss: 290.500 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 910/1194 | Loss: 312.414 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 920/1194 | Loss: 287.024 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 930/1194 | Loss: 283.068 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 940/1194 | Loss: 305.039 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 950/1194 | Loss: 288.006 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 960/1194 | Loss: 336.410 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 970/1194 | Loss: 310.348 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 980/1194 | Loss: 293.147 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 990/1194 | Loss: 289.564 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1000/1194 | Loss: 306.484 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1010/1194 | Loss: 308.642 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1020/1194 | Loss: 307.257 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1030/1194 | Loss: 302.610 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1040/1194 | Loss: 313.431 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1050/1194 | Loss: 294.836 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1060/1194 | Loss: 300.559 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1070/1194 | Loss: 304.240 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1080/1194 | Loss: 286.717 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1090/1194 | Loss: 287.192 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1100/1194 | Loss: 311.056 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1110/1194 | Loss: 295.882 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1120/1194 | Loss: 296.184 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1130/1194 | Loss: 268.410 | Accuracy: 0.300\n",
      "[Epoch: 7/200] - Step: 1140/1194 | Loss: 303.645 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1150/1194 | Loss: 294.900 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1160/1194 | Loss: 281.402 | Accuracy: 0.200\n",
      "[Epoch: 7/200] - Step: 1170/1194 | Loss: 315.914 | Accuracy: 0.000\n",
      "[Epoch: 7/200] - Step: 1180/1194 | Loss: 298.669 | Accuracy: 0.100\n",
      "[Epoch: 7/200] - Step: 1190/1194 | Loss: 287.083 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 8/200] - Step: 10/1194 | Loss: 323.373 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 20/1194 | Loss: 300.952 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 30/1194 | Loss: 277.182 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 40/1194 | Loss: 293.909 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 50/1194 | Loss: 303.576 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 60/1194 | Loss: 301.876 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 70/1194 | Loss: 271.450 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 80/1194 | Loss: 317.473 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 90/1194 | Loss: 310.383 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 100/1194 | Loss: 301.134 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 110/1194 | Loss: 288.142 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 120/1194 | Loss: 290.340 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 130/1194 | Loss: 308.686 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 140/1194 | Loss: 294.482 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 150/1194 | Loss: 269.492 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 160/1194 | Loss: 328.425 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 170/1194 | Loss: 314.994 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 180/1194 | Loss: 302.181 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 190/1194 | Loss: 310.439 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 200/1194 | Loss: 298.308 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 210/1194 | Loss: 292.753 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 220/1194 | Loss: 309.157 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 230/1194 | Loss: 319.339 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 240/1194 | Loss: 288.361 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 250/1194 | Loss: 292.640 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 260/1194 | Loss: 290.709 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 270/1194 | Loss: 283.594 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 280/1194 | Loss: 303.378 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 290/1194 | Loss: 300.856 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 300/1194 | Loss: 306.288 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 310/1194 | Loss: 283.852 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 320/1194 | Loss: 315.154 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 330/1194 | Loss: 284.714 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 340/1194 | Loss: 296.604 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 350/1194 | Loss: 299.750 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 360/1194 | Loss: 313.439 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 370/1194 | Loss: 299.119 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 380/1194 | Loss: 273.375 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 390/1194 | Loss: 277.066 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 400/1194 | Loss: 295.072 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 410/1194 | Loss: 270.662 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 420/1194 | Loss: 289.500 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 430/1194 | Loss: 300.739 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 440/1194 | Loss: 304.890 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 450/1194 | Loss: 297.947 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 460/1194 | Loss: 278.569 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 470/1194 | Loss: 292.051 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 480/1194 | Loss: 316.054 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 490/1194 | Loss: 316.698 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 500/1194 | Loss: 299.334 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 510/1194 | Loss: 296.526 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 520/1194 | Loss: 297.363 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 530/1194 | Loss: 293.580 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 540/1194 | Loss: 302.879 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 550/1194 | Loss: 280.636 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 560/1194 | Loss: 280.598 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 570/1194 | Loss: 297.123 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 580/1194 | Loss: 298.167 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 590/1194 | Loss: 297.521 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 600/1194 | Loss: 296.675 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 610/1194 | Loss: 273.899 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 620/1194 | Loss: 306.094 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 630/1194 | Loss: 287.463 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 640/1194 | Loss: 335.560 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 650/1194 | Loss: 283.768 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 660/1194 | Loss: 298.277 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 670/1194 | Loss: 306.096 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 680/1194 | Loss: 303.848 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 690/1194 | Loss: 297.451 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 700/1194 | Loss: 290.967 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 710/1194 | Loss: 287.939 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 720/1194 | Loss: 304.441 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 730/1194 | Loss: 307.783 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 740/1194 | Loss: 309.580 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 750/1194 | Loss: 294.633 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 760/1194 | Loss: 300.315 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 770/1194 | Loss: 303.095 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 780/1194 | Loss: 305.541 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 790/1194 | Loss: 317.135 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 800/1194 | Loss: 300.425 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 810/1194 | Loss: 294.004 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 820/1194 | Loss: 302.548 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 830/1194 | Loss: 309.142 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 840/1194 | Loss: 287.088 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 850/1194 | Loss: 301.145 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 860/1194 | Loss: 296.009 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 870/1194 | Loss: 302.531 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 880/1194 | Loss: 288.865 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 890/1194 | Loss: 297.318 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 900/1194 | Loss: 283.330 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 910/1194 | Loss: 307.609 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 920/1194 | Loss: 297.420 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 930/1194 | Loss: 313.514 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 940/1194 | Loss: 286.724 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 950/1194 | Loss: 312.846 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 960/1194 | Loss: 274.565 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 970/1194 | Loss: 314.489 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 980/1194 | Loss: 314.659 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 990/1194 | Loss: 272.068 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1000/1194 | Loss: 297.843 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1010/1194 | Loss: 314.013 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1020/1194 | Loss: 305.038 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1030/1194 | Loss: 305.723 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1040/1194 | Loss: 309.838 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1050/1194 | Loss: 288.231 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1060/1194 | Loss: 301.027 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1070/1194 | Loss: 289.153 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1080/1194 | Loss: 279.340 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1090/1194 | Loss: 296.631 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1100/1194 | Loss: 316.832 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1110/1194 | Loss: 309.983 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1120/1194 | Loss: 279.945 | Accuracy: 0.300\n",
      "[Epoch: 8/200] - Step: 1130/1194 | Loss: 299.325 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1140/1194 | Loss: 304.560 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1150/1194 | Loss: 325.463 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1160/1194 | Loss: 296.701 | Accuracy: 0.200\n",
      "[Epoch: 8/200] - Step: 1170/1194 | Loss: 302.708 | Accuracy: 0.100\n",
      "[Epoch: 8/200] - Step: 1180/1194 | Loss: 302.613 | Accuracy: 0.000\n",
      "[Epoch: 8/200] - Step: 1190/1194 | Loss: 308.131 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 9/200] - Step: 10/1194 | Loss: 295.055 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 20/1194 | Loss: 307.443 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 30/1194 | Loss: 295.778 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 40/1194 | Loss: 288.226 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 50/1194 | Loss: 282.241 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 60/1194 | Loss: 303.614 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 70/1194 | Loss: 310.148 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 80/1194 | Loss: 302.742 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 90/1194 | Loss: 291.029 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 100/1194 | Loss: 308.150 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 110/1194 | Loss: 297.203 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 120/1194 | Loss: 282.488 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 130/1194 | Loss: 308.157 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 140/1194 | Loss: 299.970 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 150/1194 | Loss: 295.794 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 160/1194 | Loss: 308.214 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 170/1194 | Loss: 296.126 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 180/1194 | Loss: 301.947 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 190/1194 | Loss: 311.853 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 200/1194 | Loss: 313.392 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 210/1194 | Loss: 306.618 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 220/1194 | Loss: 301.658 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 230/1194 | Loss: 297.104 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 240/1194 | Loss: 309.076 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 250/1194 | Loss: 318.250 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 260/1194 | Loss: 304.850 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 270/1194 | Loss: 311.095 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 280/1194 | Loss: 294.672 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 290/1194 | Loss: 305.602 | Accuracy: 0.400\n",
      "[Epoch: 9/200] - Step: 300/1194 | Loss: 299.410 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 310/1194 | Loss: 291.894 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 320/1194 | Loss: 298.423 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 330/1194 | Loss: 298.804 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 340/1194 | Loss: 301.782 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 350/1194 | Loss: 279.430 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 360/1194 | Loss: 306.202 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 370/1194 | Loss: 311.653 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 380/1194 | Loss: 286.683 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 390/1194 | Loss: 290.936 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 400/1194 | Loss: 297.201 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 410/1194 | Loss: 310.673 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 420/1194 | Loss: 273.956 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 430/1194 | Loss: 283.934 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 440/1194 | Loss: 312.774 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 450/1194 | Loss: 294.734 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 460/1194 | Loss: 302.710 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 470/1194 | Loss: 293.466 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 480/1194 | Loss: 307.709 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 490/1194 | Loss: 300.796 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 500/1194 | Loss: 303.467 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 510/1194 | Loss: 303.280 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 520/1194 | Loss: 309.148 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 530/1194 | Loss: 296.867 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 540/1194 | Loss: 296.573 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 550/1194 | Loss: 282.639 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 560/1194 | Loss: 292.931 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 570/1194 | Loss: 301.103 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 580/1194 | Loss: 292.617 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 590/1194 | Loss: 304.400 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 600/1194 | Loss: 278.193 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 610/1194 | Loss: 307.701 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 620/1194 | Loss: 295.157 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 630/1194 | Loss: 285.934 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 640/1194 | Loss: 305.920 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 650/1194 | Loss: 304.545 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 660/1194 | Loss: 287.740 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 670/1194 | Loss: 288.621 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 680/1194 | Loss: 297.204 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 690/1194 | Loss: 297.137 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 700/1194 | Loss: 321.470 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 710/1194 | Loss: 295.437 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 720/1194 | Loss: 279.343 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 730/1194 | Loss: 305.401 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 740/1194 | Loss: 291.952 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 750/1194 | Loss: 316.460 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 760/1194 | Loss: 291.722 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 770/1194 | Loss: 288.423 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 780/1194 | Loss: 291.215 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 790/1194 | Loss: 299.523 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 800/1194 | Loss: 306.610 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 810/1194 | Loss: 302.934 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 820/1194 | Loss: 281.154 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 830/1194 | Loss: 283.506 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 840/1194 | Loss: 303.825 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 850/1194 | Loss: 294.256 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 860/1194 | Loss: 297.259 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 870/1194 | Loss: 277.281 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 880/1194 | Loss: 302.824 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 890/1194 | Loss: 292.100 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 900/1194 | Loss: 284.783 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 910/1194 | Loss: 302.434 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 920/1194 | Loss: 295.711 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 930/1194 | Loss: 314.022 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 940/1194 | Loss: 305.349 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 950/1194 | Loss: 329.631 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 960/1194 | Loss: 285.689 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 970/1194 | Loss: 291.561 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 980/1194 | Loss: 308.356 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 990/1194 | Loss: 289.554 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1000/1194 | Loss: 311.902 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1010/1194 | Loss: 303.643 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1020/1194 | Loss: 302.531 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1030/1194 | Loss: 288.458 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1040/1194 | Loss: 291.491 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1050/1194 | Loss: 285.652 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1060/1194 | Loss: 299.155 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1070/1194 | Loss: 330.006 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1080/1194 | Loss: 282.670 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1090/1194 | Loss: 293.733 | Accuracy: 0.200\n",
      "[Epoch: 9/200] - Step: 1100/1194 | Loss: 285.041 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1110/1194 | Loss: 274.620 | Accuracy: 0.300\n",
      "[Epoch: 9/200] - Step: 1120/1194 | Loss: 306.571 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1130/1194 | Loss: 312.872 | Accuracy: 0.000\n",
      "[Epoch: 9/200] - Step: 1140/1194 | Loss: 300.607 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1150/1194 | Loss: 298.014 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1160/1194 | Loss: 293.806 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1170/1194 | Loss: 307.618 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1180/1194 | Loss: 303.258 | Accuracy: 0.100\n",
      "[Epoch: 9/200] - Step: 1190/1194 | Loss: 306.515 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 10/200] - Step: 10/1194 | Loss: 296.794 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 20/1194 | Loss: 275.533 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 30/1194 | Loss: 305.494 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 40/1194 | Loss: 305.114 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 50/1194 | Loss: 287.768 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 60/1194 | Loss: 301.347 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 70/1194 | Loss: 334.416 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 80/1194 | Loss: 306.602 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 90/1194 | Loss: 273.714 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 100/1194 | Loss: 323.711 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 110/1194 | Loss: 301.007 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 120/1194 | Loss: 297.404 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 130/1194 | Loss: 297.002 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 140/1194 | Loss: 302.358 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 150/1194 | Loss: 292.288 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 160/1194 | Loss: 292.337 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 170/1194 | Loss: 319.583 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 180/1194 | Loss: 302.075 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 190/1194 | Loss: 293.609 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 200/1194 | Loss: 280.252 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 210/1194 | Loss: 279.654 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 220/1194 | Loss: 297.430 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 230/1194 | Loss: 263.618 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 240/1194 | Loss: 308.557 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 250/1194 | Loss: 292.025 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 260/1194 | Loss: 298.252 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 270/1194 | Loss: 287.641 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 280/1194 | Loss: 263.103 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 290/1194 | Loss: 282.051 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 300/1194 | Loss: 325.886 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 310/1194 | Loss: 300.596 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 320/1194 | Loss: 302.126 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 330/1194 | Loss: 317.428 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 340/1194 | Loss: 304.130 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 350/1194 | Loss: 302.537 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 360/1194 | Loss: 304.734 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 370/1194 | Loss: 292.082 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 380/1194 | Loss: 300.961 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 390/1194 | Loss: 303.339 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 400/1194 | Loss: 309.703 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 410/1194 | Loss: 305.040 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 420/1194 | Loss: 284.814 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 430/1194 | Loss: 305.570 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 440/1194 | Loss: 313.010 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 450/1194 | Loss: 292.637 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 460/1194 | Loss: 304.860 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 470/1194 | Loss: 293.065 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 480/1194 | Loss: 286.262 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 490/1194 | Loss: 294.100 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 500/1194 | Loss: 277.709 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 510/1194 | Loss: 314.812 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 520/1194 | Loss: 294.614 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 530/1194 | Loss: 316.695 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 540/1194 | Loss: 307.858 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 550/1194 | Loss: 313.816 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 560/1194 | Loss: 303.625 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 570/1194 | Loss: 303.030 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 580/1194 | Loss: 301.531 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 590/1194 | Loss: 315.397 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 600/1194 | Loss: 300.303 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 610/1194 | Loss: 306.859 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 620/1194 | Loss: 303.204 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 630/1194 | Loss: 283.793 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 640/1194 | Loss: 298.606 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 650/1194 | Loss: 318.976 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 660/1194 | Loss: 295.643 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 670/1194 | Loss: 299.431 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 680/1194 | Loss: 297.231 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 690/1194 | Loss: 308.335 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 700/1194 | Loss: 304.777 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 710/1194 | Loss: 303.990 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 720/1194 | Loss: 305.415 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 730/1194 | Loss: 293.347 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 740/1194 | Loss: 294.780 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 750/1194 | Loss: 302.496 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 760/1194 | Loss: 272.739 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 770/1194 | Loss: 306.003 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 780/1194 | Loss: 307.625 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 790/1194 | Loss: 287.005 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 800/1194 | Loss: 293.107 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 810/1194 | Loss: 324.312 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 820/1194 | Loss: 292.269 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 830/1194 | Loss: 287.528 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 840/1194 | Loss: 306.181 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 850/1194 | Loss: 298.331 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 860/1194 | Loss: 283.406 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 870/1194 | Loss: 310.499 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 880/1194 | Loss: 306.660 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 890/1194 | Loss: 279.136 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 900/1194 | Loss: 278.151 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 910/1194 | Loss: 293.526 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 920/1194 | Loss: 314.365 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 930/1194 | Loss: 311.783 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 940/1194 | Loss: 307.924 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 950/1194 | Loss: 311.645 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 960/1194 | Loss: 301.154 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 970/1194 | Loss: 308.453 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 980/1194 | Loss: 304.476 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 990/1194 | Loss: 293.282 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1000/1194 | Loss: 294.466 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1010/1194 | Loss: 308.316 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1020/1194 | Loss: 282.381 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1030/1194 | Loss: 294.201 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1040/1194 | Loss: 293.411 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1050/1194 | Loss: 309.071 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1060/1194 | Loss: 308.858 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1070/1194 | Loss: 295.962 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1080/1194 | Loss: 300.352 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1090/1194 | Loss: 301.939 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1100/1194 | Loss: 295.455 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1110/1194 | Loss: 259.397 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 1120/1194 | Loss: 269.198 | Accuracy: 0.400\n",
      "[Epoch: 10/200] - Step: 1130/1194 | Loss: 272.749 | Accuracy: 0.300\n",
      "[Epoch: 10/200] - Step: 1140/1194 | Loss: 317.783 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1150/1194 | Loss: 279.678 | Accuracy: 0.200\n",
      "[Epoch: 10/200] - Step: 1160/1194 | Loss: 296.175 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1170/1194 | Loss: 296.083 | Accuracy: 0.100\n",
      "[Epoch: 10/200] - Step: 1180/1194 | Loss: 309.257 | Accuracy: 0.000\n",
      "[Epoch: 10/200] - Step: 1190/1194 | Loss: 299.290 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 11/200] - Step: 10/1194 | Loss: 297.754 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 20/1194 | Loss: 286.355 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 30/1194 | Loss: 282.520 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 40/1194 | Loss: 296.592 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 50/1194 | Loss: 296.641 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 60/1194 | Loss: 290.081 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 70/1194 | Loss: 294.703 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 80/1194 | Loss: 304.959 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 90/1194 | Loss: 286.167 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 100/1194 | Loss: 307.601 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 110/1194 | Loss: 306.215 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 120/1194 | Loss: 301.551 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 130/1194 | Loss: 295.995 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 140/1194 | Loss: 299.730 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 150/1194 | Loss: 307.783 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 160/1194 | Loss: 292.963 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 170/1194 | Loss: 285.727 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 180/1194 | Loss: 303.475 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 190/1194 | Loss: 295.420 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 200/1194 | Loss: 295.753 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 210/1194 | Loss: 282.523 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 220/1194 | Loss: 295.568 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 230/1194 | Loss: 284.884 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 240/1194 | Loss: 296.233 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 250/1194 | Loss: 295.958 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 260/1194 | Loss: 301.020 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 270/1194 | Loss: 314.421 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 280/1194 | Loss: 293.861 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 290/1194 | Loss: 300.469 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 300/1194 | Loss: 288.742 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 310/1194 | Loss: 302.569 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 320/1194 | Loss: 294.180 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 330/1194 | Loss: 291.911 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 340/1194 | Loss: 297.758 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 350/1194 | Loss: 302.756 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 360/1194 | Loss: 326.561 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 370/1194 | Loss: 302.596 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 380/1194 | Loss: 296.140 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 390/1194 | Loss: 305.468 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 400/1194 | Loss: 296.034 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 410/1194 | Loss: 298.334 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 420/1194 | Loss: 319.540 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 430/1194 | Loss: 292.012 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 440/1194 | Loss: 302.825 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 450/1194 | Loss: 300.696 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 460/1194 | Loss: 297.048 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 470/1194 | Loss: 303.735 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 480/1194 | Loss: 280.557 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 490/1194 | Loss: 289.190 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 500/1194 | Loss: 301.046 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 510/1194 | Loss: 295.889 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 520/1194 | Loss: 285.167 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 530/1194 | Loss: 295.396 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 540/1194 | Loss: 297.046 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 550/1194 | Loss: 286.925 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 560/1194 | Loss: 296.222 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 570/1194 | Loss: 305.349 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 580/1194 | Loss: 304.504 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 590/1194 | Loss: 300.804 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 600/1194 | Loss: 276.960 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 610/1194 | Loss: 291.724 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 620/1194 | Loss: 305.731 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 630/1194 | Loss: 291.268 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 640/1194 | Loss: 303.058 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 650/1194 | Loss: 307.085 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 660/1194 | Loss: 294.106 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 670/1194 | Loss: 290.460 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 680/1194 | Loss: 302.211 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 690/1194 | Loss: 280.918 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 700/1194 | Loss: 290.817 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 710/1194 | Loss: 318.898 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 720/1194 | Loss: 284.313 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 730/1194 | Loss: 296.453 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 740/1194 | Loss: 285.885 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 750/1194 | Loss: 279.629 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 760/1194 | Loss: 312.376 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 770/1194 | Loss: 303.589 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 780/1194 | Loss: 294.289 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 790/1194 | Loss: 305.650 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 800/1194 | Loss: 294.977 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 810/1194 | Loss: 315.877 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 820/1194 | Loss: 300.043 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 830/1194 | Loss: 293.243 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 840/1194 | Loss: 303.401 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 850/1194 | Loss: 308.310 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 860/1194 | Loss: 289.223 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 870/1194 | Loss: 311.057 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 880/1194 | Loss: 322.453 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 890/1194 | Loss: 313.359 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 900/1194 | Loss: 274.639 | Accuracy: 0.500\n",
      "[Epoch: 11/200] - Step: 910/1194 | Loss: 285.721 | Accuracy: 0.300\n",
      "[Epoch: 11/200] - Step: 920/1194 | Loss: 302.450 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 930/1194 | Loss: 308.450 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 940/1194 | Loss: 304.247 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 950/1194 | Loss: 298.684 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 960/1194 | Loss: 297.334 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 970/1194 | Loss: 292.708 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 980/1194 | Loss: 309.804 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 990/1194 | Loss: 294.139 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1000/1194 | Loss: 269.525 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 1010/1194 | Loss: 295.917 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1020/1194 | Loss: 335.738 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1030/1194 | Loss: 291.620 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1040/1194 | Loss: 268.667 | Accuracy: 0.400\n",
      "[Epoch: 11/200] - Step: 1050/1194 | Loss: 308.268 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1060/1194 | Loss: 298.740 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1070/1194 | Loss: 310.120 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1080/1194 | Loss: 328.728 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1090/1194 | Loss: 292.387 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1100/1194 | Loss: 309.159 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1110/1194 | Loss: 326.682 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1120/1194 | Loss: 305.281 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1130/1194 | Loss: 300.112 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1140/1194 | Loss: 287.163 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1150/1194 | Loss: 305.011 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1160/1194 | Loss: 285.099 | Accuracy: 0.200\n",
      "[Epoch: 11/200] - Step: 1170/1194 | Loss: 308.660 | Accuracy: 0.000\n",
      "[Epoch: 11/200] - Step: 1180/1194 | Loss: 298.141 | Accuracy: 0.100\n",
      "[Epoch: 11/200] - Step: 1190/1194 | Loss: 292.677 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 12/200] - Step: 10/1194 | Loss: 302.003 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 20/1194 | Loss: 303.513 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 30/1194 | Loss: 298.843 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 40/1194 | Loss: 297.707 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 50/1194 | Loss: 300.408 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 60/1194 | Loss: 291.854 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 70/1194 | Loss: 296.203 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 80/1194 | Loss: 299.272 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 90/1194 | Loss: 319.912 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 100/1194 | Loss: 305.161 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 110/1194 | Loss: 297.128 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 120/1194 | Loss: 282.955 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 130/1194 | Loss: 298.984 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 140/1194 | Loss: 301.006 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 150/1194 | Loss: 324.694 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 160/1194 | Loss: 305.615 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 170/1194 | Loss: 296.732 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 180/1194 | Loss: 297.181 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 190/1194 | Loss: 322.675 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 200/1194 | Loss: 293.831 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 210/1194 | Loss: 303.784 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 220/1194 | Loss: 316.257 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 230/1194 | Loss: 303.146 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 240/1194 | Loss: 296.555 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 250/1194 | Loss: 284.013 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 260/1194 | Loss: 311.839 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 270/1194 | Loss: 301.414 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 280/1194 | Loss: 302.510 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 290/1194 | Loss: 297.310 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 300/1194 | Loss: 292.338 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 310/1194 | Loss: 289.954 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 320/1194 | Loss: 307.316 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 330/1194 | Loss: 303.545 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 340/1194 | Loss: 276.544 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 350/1194 | Loss: 281.715 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 360/1194 | Loss: 296.079 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 370/1194 | Loss: 283.656 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 380/1194 | Loss: 296.099 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 390/1194 | Loss: 310.521 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 400/1194 | Loss: 277.466 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 410/1194 | Loss: 286.035 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 420/1194 | Loss: 307.522 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 430/1194 | Loss: 292.898 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 440/1194 | Loss: 303.526 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 450/1194 | Loss: 315.574 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 460/1194 | Loss: 296.616 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 470/1194 | Loss: 300.380 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 480/1194 | Loss: 298.533 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 490/1194 | Loss: 297.783 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 500/1194 | Loss: 281.726 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 510/1194 | Loss: 295.209 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 520/1194 | Loss: 310.735 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 530/1194 | Loss: 294.950 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 540/1194 | Loss: 274.785 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 550/1194 | Loss: 322.366 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 560/1194 | Loss: 284.325 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 570/1194 | Loss: 310.940 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 580/1194 | Loss: 299.530 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 590/1194 | Loss: 300.557 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 600/1194 | Loss: 290.217 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 610/1194 | Loss: 302.054 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 620/1194 | Loss: 295.395 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 630/1194 | Loss: 291.229 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 640/1194 | Loss: 295.225 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 650/1194 | Loss: 287.080 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 660/1194 | Loss: 303.267 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 670/1194 | Loss: 317.728 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 680/1194 | Loss: 298.242 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 690/1194 | Loss: 281.450 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 700/1194 | Loss: 288.698 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 710/1194 | Loss: 283.647 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 720/1194 | Loss: 279.405 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 730/1194 | Loss: 284.708 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 740/1194 | Loss: 302.550 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 750/1194 | Loss: 303.775 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 760/1194 | Loss: 295.305 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 770/1194 | Loss: 303.010 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 780/1194 | Loss: 316.217 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 790/1194 | Loss: 293.871 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 800/1194 | Loss: 292.220 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 810/1194 | Loss: 305.273 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 820/1194 | Loss: 284.600 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 830/1194 | Loss: 296.160 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 840/1194 | Loss: 296.376 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 850/1194 | Loss: 319.710 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 860/1194 | Loss: 287.423 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 870/1194 | Loss: 302.162 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 880/1194 | Loss: 311.574 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 890/1194 | Loss: 288.361 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 900/1194 | Loss: 310.490 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 910/1194 | Loss: 308.512 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 920/1194 | Loss: 315.693 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 930/1194 | Loss: 275.942 | Accuracy: 0.400\n",
      "[Epoch: 12/200] - Step: 940/1194 | Loss: 285.120 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 950/1194 | Loss: 309.653 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 960/1194 | Loss: 288.926 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 970/1194 | Loss: 290.224 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 980/1194 | Loss: 304.381 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 990/1194 | Loss: 298.054 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1000/1194 | Loss: 304.727 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1010/1194 | Loss: 293.255 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1020/1194 | Loss: 300.634 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1030/1194 | Loss: 292.412 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1040/1194 | Loss: 299.686 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1050/1194 | Loss: 296.326 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1060/1194 | Loss: 336.120 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1070/1194 | Loss: 292.570 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1080/1194 | Loss: 290.814 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1090/1194 | Loss: 301.248 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1100/1194 | Loss: 308.411 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1110/1194 | Loss: 291.202 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1120/1194 | Loss: 289.758 | Accuracy: 0.200\n",
      "[Epoch: 12/200] - Step: 1130/1194 | Loss: 303.082 | Accuracy: 0.000\n",
      "[Epoch: 12/200] - Step: 1140/1194 | Loss: 302.816 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1150/1194 | Loss: 318.915 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1160/1194 | Loss: 274.818 | Accuracy: 0.300\n",
      "[Epoch: 12/200] - Step: 1170/1194 | Loss: 301.322 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1180/1194 | Loss: 296.936 | Accuracy: 0.100\n",
      "[Epoch: 12/200] - Step: 1190/1194 | Loss: 282.435 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 13/200] - Step: 10/1194 | Loss: 268.780 | Accuracy: 0.400\n",
      "[Epoch: 13/200] - Step: 20/1194 | Loss: 280.777 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 30/1194 | Loss: 312.525 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 40/1194 | Loss: 285.390 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 50/1194 | Loss: 309.526 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 60/1194 | Loss: 290.253 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 70/1194 | Loss: 294.802 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 80/1194 | Loss: 301.098 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 90/1194 | Loss: 295.645 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 100/1194 | Loss: 277.725 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 110/1194 | Loss: 303.323 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 120/1194 | Loss: 280.440 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 130/1194 | Loss: 316.471 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 140/1194 | Loss: 303.638 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 150/1194 | Loss: 283.393 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 160/1194 | Loss: 310.714 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 170/1194 | Loss: 296.203 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 180/1194 | Loss: 273.901 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 190/1194 | Loss: 286.881 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 200/1194 | Loss: 283.463 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 210/1194 | Loss: 282.642 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 220/1194 | Loss: 303.594 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 230/1194 | Loss: 320.433 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 240/1194 | Loss: 280.570 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 250/1194 | Loss: 305.464 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 260/1194 | Loss: 305.899 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 270/1194 | Loss: 315.573 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 280/1194 | Loss: 302.575 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 290/1194 | Loss: 312.217 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 300/1194 | Loss: 301.153 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 310/1194 | Loss: 285.481 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 320/1194 | Loss: 294.874 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 330/1194 | Loss: 323.484 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 340/1194 | Loss: 301.978 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 350/1194 | Loss: 299.566 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 360/1194 | Loss: 301.243 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 370/1194 | Loss: 305.433 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 380/1194 | Loss: 301.704 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 390/1194 | Loss: 296.889 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 400/1194 | Loss: 304.917 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 410/1194 | Loss: 315.238 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 420/1194 | Loss: 282.550 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 430/1194 | Loss: 306.512 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 440/1194 | Loss: 291.189 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 450/1194 | Loss: 308.103 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 460/1194 | Loss: 304.086 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 470/1194 | Loss: 307.426 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 480/1194 | Loss: 302.674 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 490/1194 | Loss: 289.527 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 500/1194 | Loss: 299.491 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 510/1194 | Loss: 291.591 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 520/1194 | Loss: 279.769 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 530/1194 | Loss: 292.963 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 540/1194 | Loss: 281.229 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 550/1194 | Loss: 302.045 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 560/1194 | Loss: 308.084 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 570/1194 | Loss: 297.674 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 580/1194 | Loss: 292.031 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 590/1194 | Loss: 299.215 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 600/1194 | Loss: 284.526 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 610/1194 | Loss: 286.473 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 620/1194 | Loss: 314.098 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 630/1194 | Loss: 291.490 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 640/1194 | Loss: 286.729 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 650/1194 | Loss: 296.402 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 660/1194 | Loss: 301.067 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 670/1194 | Loss: 285.603 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 680/1194 | Loss: 331.615 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 690/1194 | Loss: 294.885 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 700/1194 | Loss: 301.495 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 710/1194 | Loss: 291.150 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 720/1194 | Loss: 306.555 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 730/1194 | Loss: 287.728 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 740/1194 | Loss: 302.417 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 750/1194 | Loss: 300.452 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 760/1194 | Loss: 289.476 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 770/1194 | Loss: 289.773 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 780/1194 | Loss: 300.603 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 790/1194 | Loss: 297.691 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 800/1194 | Loss: 300.412 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 810/1194 | Loss: 301.645 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 820/1194 | Loss: 303.315 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 830/1194 | Loss: 288.844 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 840/1194 | Loss: 300.119 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 850/1194 | Loss: 307.106 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 860/1194 | Loss: 295.397 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 870/1194 | Loss: 300.631 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 880/1194 | Loss: 304.282 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 890/1194 | Loss: 291.201 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 900/1194 | Loss: 300.951 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 910/1194 | Loss: 305.392 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 920/1194 | Loss: 284.464 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 930/1194 | Loss: 297.655 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 940/1194 | Loss: 316.391 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 950/1194 | Loss: 288.331 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 960/1194 | Loss: 300.997 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 970/1194 | Loss: 341.073 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 980/1194 | Loss: 294.681 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 990/1194 | Loss: 293.624 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1000/1194 | Loss: 286.495 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1010/1194 | Loss: 304.705 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1020/1194 | Loss: 293.105 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1030/1194 | Loss: 302.480 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1040/1194 | Loss: 285.249 | Accuracy: 0.200\n",
      "[Epoch: 13/200] - Step: 1050/1194 | Loss: 312.264 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1060/1194 | Loss: 303.589 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1070/1194 | Loss: 290.126 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1080/1194 | Loss: 313.182 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1090/1194 | Loss: 298.080 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1100/1194 | Loss: 296.011 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1110/1194 | Loss: 304.472 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1120/1194 | Loss: 309.258 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1130/1194 | Loss: 304.738 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1140/1194 | Loss: 286.178 | Accuracy: 0.300\n",
      "[Epoch: 13/200] - Step: 1150/1194 | Loss: 291.167 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1160/1194 | Loss: 263.339 | Accuracy: 0.500\n",
      "[Epoch: 13/200] - Step: 1170/1194 | Loss: 309.981 | Accuracy: 0.100\n",
      "[Epoch: 13/200] - Step: 1180/1194 | Loss: 313.401 | Accuracy: 0.000\n",
      "[Epoch: 13/200] - Step: 1190/1194 | Loss: 283.715 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 14/200] - Step: 10/1194 | Loss: 294.977 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 20/1194 | Loss: 307.758 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 30/1194 | Loss: 296.170 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 40/1194 | Loss: 297.351 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 50/1194 | Loss: 295.822 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 60/1194 | Loss: 287.994 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 70/1194 | Loss: 300.168 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 80/1194 | Loss: 301.382 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 90/1194 | Loss: 285.831 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 100/1194 | Loss: 311.370 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 110/1194 | Loss: 290.346 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 120/1194 | Loss: 301.658 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 130/1194 | Loss: 285.121 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 140/1194 | Loss: 285.775 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 150/1194 | Loss: 305.795 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 160/1194 | Loss: 297.452 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 170/1194 | Loss: 290.204 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 180/1194 | Loss: 286.926 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 190/1194 | Loss: 297.209 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 200/1194 | Loss: 305.279 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 210/1194 | Loss: 295.420 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 220/1194 | Loss: 302.313 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 230/1194 | Loss: 307.422 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 240/1194 | Loss: 296.700 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 250/1194 | Loss: 303.305 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 260/1194 | Loss: 294.191 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 270/1194 | Loss: 271.975 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 280/1194 | Loss: 291.689 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 290/1194 | Loss: 290.121 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 300/1194 | Loss: 300.823 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 310/1194 | Loss: 296.423 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 320/1194 | Loss: 270.993 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 330/1194 | Loss: 292.115 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 340/1194 | Loss: 306.825 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 350/1194 | Loss: 277.774 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 360/1194 | Loss: 323.158 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 370/1194 | Loss: 301.850 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 380/1194 | Loss: 281.757 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 390/1194 | Loss: 301.047 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 400/1194 | Loss: 296.251 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 410/1194 | Loss: 296.359 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 420/1194 | Loss: 309.120 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 430/1194 | Loss: 289.515 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 440/1194 | Loss: 290.890 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 450/1194 | Loss: 297.980 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 460/1194 | Loss: 298.901 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 470/1194 | Loss: 305.572 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 480/1194 | Loss: 291.143 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 490/1194 | Loss: 309.985 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 500/1194 | Loss: 297.265 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 510/1194 | Loss: 284.802 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 520/1194 | Loss: 299.029 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 530/1194 | Loss: 306.482 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 540/1194 | Loss: 294.494 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 550/1194 | Loss: 284.889 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 560/1194 | Loss: 303.060 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 570/1194 | Loss: 310.538 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 580/1194 | Loss: 289.162 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 590/1194 | Loss: 301.426 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 600/1194 | Loss: 289.043 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 610/1194 | Loss: 292.727 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 620/1194 | Loss: 292.260 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 630/1194 | Loss: 290.634 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 640/1194 | Loss: 303.893 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 650/1194 | Loss: 330.975 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 660/1194 | Loss: 323.358 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 670/1194 | Loss: 289.204 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 680/1194 | Loss: 299.249 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 690/1194 | Loss: 299.294 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 700/1194 | Loss: 290.995 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 710/1194 | Loss: 283.747 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 720/1194 | Loss: 290.254 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 730/1194 | Loss: 301.493 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 740/1194 | Loss: 298.816 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 750/1194 | Loss: 286.101 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 760/1194 | Loss: 305.857 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 770/1194 | Loss: 310.023 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 780/1194 | Loss: 291.671 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 790/1194 | Loss: 303.146 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 800/1194 | Loss: 315.194 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 810/1194 | Loss: 313.552 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 820/1194 | Loss: 294.683 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 830/1194 | Loss: 308.519 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 840/1194 | Loss: 289.105 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 850/1194 | Loss: 297.353 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 860/1194 | Loss: 275.106 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 870/1194 | Loss: 326.653 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 880/1194 | Loss: 276.199 | Accuracy: 0.400\n",
      "[Epoch: 14/200] - Step: 890/1194 | Loss: 299.790 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 900/1194 | Loss: 284.982 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 910/1194 | Loss: 287.085 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 920/1194 | Loss: 290.900 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 930/1194 | Loss: 315.828 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 940/1194 | Loss: 306.012 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 950/1194 | Loss: 293.201 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 960/1194 | Loss: 301.971 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 970/1194 | Loss: 320.393 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 980/1194 | Loss: 287.489 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 990/1194 | Loss: 305.777 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1000/1194 | Loss: 289.869 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1010/1194 | Loss: 308.321 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1020/1194 | Loss: 299.617 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1030/1194 | Loss: 311.545 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1040/1194 | Loss: 300.667 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1050/1194 | Loss: 300.782 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1060/1194 | Loss: 306.769 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1070/1194 | Loss: 299.336 | Accuracy: 0.200\n",
      "[Epoch: 14/200] - Step: 1080/1194 | Loss: 296.569 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1090/1194 | Loss: 284.518 | Accuracy: 0.300\n",
      "[Epoch: 14/200] - Step: 1100/1194 | Loss: 307.939 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1110/1194 | Loss: 297.916 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1120/1194 | Loss: 292.361 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1130/1194 | Loss: 291.180 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1140/1194 | Loss: 312.106 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1150/1194 | Loss: 327.699 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1160/1194 | Loss: 319.462 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1170/1194 | Loss: 295.399 | Accuracy: 0.000\n",
      "[Epoch: 14/200] - Step: 1180/1194 | Loss: 298.516 | Accuracy: 0.100\n",
      "[Epoch: 14/200] - Step: 1190/1194 | Loss: 296.188 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 15/200] - Step: 10/1194 | Loss: 295.412 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 20/1194 | Loss: 305.000 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 30/1194 | Loss: 292.577 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 40/1194 | Loss: 306.544 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 50/1194 | Loss: 289.060 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 60/1194 | Loss: 289.271 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 70/1194 | Loss: 300.157 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 80/1194 | Loss: 302.855 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 90/1194 | Loss: 302.875 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 100/1194 | Loss: 303.715 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 110/1194 | Loss: 317.012 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 120/1194 | Loss: 304.705 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 130/1194 | Loss: 278.133 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 140/1194 | Loss: 292.524 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 150/1194 | Loss: 293.789 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 160/1194 | Loss: 303.299 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 170/1194 | Loss: 308.746 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 180/1194 | Loss: 294.110 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 190/1194 | Loss: 297.893 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 200/1194 | Loss: 287.828 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 210/1194 | Loss: 292.690 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 220/1194 | Loss: 293.034 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 230/1194 | Loss: 309.004 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 240/1194 | Loss: 304.532 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 250/1194 | Loss: 304.109 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 260/1194 | Loss: 308.699 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 270/1194 | Loss: 296.566 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 280/1194 | Loss: 290.628 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 290/1194 | Loss: 288.097 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 300/1194 | Loss: 305.482 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 310/1194 | Loss: 284.770 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 320/1194 | Loss: 292.831 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 330/1194 | Loss: 286.696 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 340/1194 | Loss: 311.150 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 350/1194 | Loss: 287.940 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 360/1194 | Loss: 300.373 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 370/1194 | Loss: 279.420 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 380/1194 | Loss: 293.978 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 390/1194 | Loss: 298.340 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 400/1194 | Loss: 302.490 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 410/1194 | Loss: 289.360 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 420/1194 | Loss: 306.003 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 430/1194 | Loss: 303.553 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 440/1194 | Loss: 295.076 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 450/1194 | Loss: 294.567 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 460/1194 | Loss: 299.259 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 470/1194 | Loss: 300.902 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 480/1194 | Loss: 283.750 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 490/1194 | Loss: 275.491 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 500/1194 | Loss: 318.654 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 510/1194 | Loss: 316.932 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 520/1194 | Loss: 286.620 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 530/1194 | Loss: 352.436 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 540/1194 | Loss: 303.169 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 550/1194 | Loss: 292.919 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 560/1194 | Loss: 303.604 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 570/1194 | Loss: 323.160 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 580/1194 | Loss: 289.933 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 590/1194 | Loss: 291.631 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 600/1194 | Loss: 302.518 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 610/1194 | Loss: 305.782 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 620/1194 | Loss: 307.259 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 630/1194 | Loss: 290.480 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 640/1194 | Loss: 298.277 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 650/1194 | Loss: 286.834 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 660/1194 | Loss: 297.784 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 670/1194 | Loss: 287.436 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 680/1194 | Loss: 290.762 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 690/1194 | Loss: 318.146 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 700/1194 | Loss: 302.568 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 710/1194 | Loss: 317.881 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 720/1194 | Loss: 290.346 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 730/1194 | Loss: 302.479 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 740/1194 | Loss: 299.725 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 750/1194 | Loss: 297.438 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 760/1194 | Loss: 306.665 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 770/1194 | Loss: 295.672 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 780/1194 | Loss: 295.017 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 790/1194 | Loss: 300.130 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 800/1194 | Loss: 282.481 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 810/1194 | Loss: 289.718 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 820/1194 | Loss: 281.091 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 830/1194 | Loss: 295.195 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 840/1194 | Loss: 293.881 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 850/1194 | Loss: 285.741 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 860/1194 | Loss: 291.859 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 870/1194 | Loss: 334.570 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 880/1194 | Loss: 264.750 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 890/1194 | Loss: 296.314 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 900/1194 | Loss: 296.940 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 910/1194 | Loss: 293.331 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 920/1194 | Loss: 301.013 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 930/1194 | Loss: 283.334 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 940/1194 | Loss: 298.685 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 950/1194 | Loss: 315.246 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 960/1194 | Loss: 309.600 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 970/1194 | Loss: 289.753 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 980/1194 | Loss: 295.281 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 990/1194 | Loss: 297.868 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1000/1194 | Loss: 307.697 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1010/1194 | Loss: 291.537 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1020/1194 | Loss: 313.379 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1030/1194 | Loss: 290.951 | Accuracy: 0.300\n",
      "[Epoch: 15/200] - Step: 1040/1194 | Loss: 307.259 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1050/1194 | Loss: 290.832 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1060/1194 | Loss: 272.410 | Accuracy: 0.400\n",
      "[Epoch: 15/200] - Step: 1070/1194 | Loss: 292.937 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1080/1194 | Loss: 301.374 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1090/1194 | Loss: 297.991 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1100/1194 | Loss: 308.749 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1110/1194 | Loss: 296.249 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1120/1194 | Loss: 298.067 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1130/1194 | Loss: 331.352 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1140/1194 | Loss: 289.499 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1150/1194 | Loss: 308.036 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1160/1194 | Loss: 291.846 | Accuracy: 0.100\n",
      "[Epoch: 15/200] - Step: 1170/1194 | Loss: 311.964 | Accuracy: 0.000\n",
      "[Epoch: 15/200] - Step: 1180/1194 | Loss: 294.182 | Accuracy: 0.200\n",
      "[Epoch: 15/200] - Step: 1190/1194 | Loss: 282.447 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 16/200] - Step: 10/1194 | Loss: 285.991 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 20/1194 | Loss: 308.808 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 30/1194 | Loss: 318.223 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 40/1194 | Loss: 296.899 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 50/1194 | Loss: 283.839 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 60/1194 | Loss: 288.743 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 70/1194 | Loss: 300.397 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 80/1194 | Loss: 290.155 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 90/1194 | Loss: 306.833 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 100/1194 | Loss: 292.506 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 110/1194 | Loss: 290.922 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 120/1194 | Loss: 297.739 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 130/1194 | Loss: 287.318 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 140/1194 | Loss: 299.298 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 150/1194 | Loss: 307.450 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 160/1194 | Loss: 300.274 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 170/1194 | Loss: 257.437 | Accuracy: 0.400\n",
      "[Epoch: 16/200] - Step: 180/1194 | Loss: 275.844 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 190/1194 | Loss: 294.063 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 200/1194 | Loss: 335.194 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 210/1194 | Loss: 296.702 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 220/1194 | Loss: 258.169 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 230/1194 | Loss: 296.827 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 240/1194 | Loss: 289.862 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 250/1194 | Loss: 307.475 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 260/1194 | Loss: 303.923 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 270/1194 | Loss: 297.358 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 280/1194 | Loss: 314.905 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 290/1194 | Loss: 300.200 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 300/1194 | Loss: 295.054 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 310/1194 | Loss: 314.647 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 320/1194 | Loss: 300.742 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 330/1194 | Loss: 296.542 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 340/1194 | Loss: 292.066 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 350/1194 | Loss: 290.617 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 360/1194 | Loss: 297.688 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 370/1194 | Loss: 298.302 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 380/1194 | Loss: 306.728 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 390/1194 | Loss: 293.515 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 400/1194 | Loss: 301.947 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 410/1194 | Loss: 314.014 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 420/1194 | Loss: 300.596 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 430/1194 | Loss: 290.202 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 440/1194 | Loss: 304.288 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 450/1194 | Loss: 308.828 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 460/1194 | Loss: 301.181 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 470/1194 | Loss: 302.092 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 480/1194 | Loss: 298.828 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 490/1194 | Loss: 291.814 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 500/1194 | Loss: 302.584 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 510/1194 | Loss: 305.526 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 520/1194 | Loss: 302.843 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 530/1194 | Loss: 296.736 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 540/1194 | Loss: 276.448 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 550/1194 | Loss: 301.485 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 560/1194 | Loss: 297.114 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 570/1194 | Loss: 300.758 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 580/1194 | Loss: 287.310 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 590/1194 | Loss: 282.422 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 600/1194 | Loss: 311.403 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 610/1194 | Loss: 315.720 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 620/1194 | Loss: 299.213 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 630/1194 | Loss: 294.439 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 640/1194 | Loss: 315.963 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 650/1194 | Loss: 313.089 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 660/1194 | Loss: 302.562 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 670/1194 | Loss: 299.165 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 680/1194 | Loss: 311.798 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 690/1194 | Loss: 313.230 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 700/1194 | Loss: 292.101 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 710/1194 | Loss: 306.967 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 720/1194 | Loss: 301.256 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 730/1194 | Loss: 294.067 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 740/1194 | Loss: 291.085 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 750/1194 | Loss: 299.603 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 760/1194 | Loss: 296.775 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 770/1194 | Loss: 293.777 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 780/1194 | Loss: 312.553 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 790/1194 | Loss: 301.629 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 800/1194 | Loss: 285.340 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 810/1194 | Loss: 297.410 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 820/1194 | Loss: 288.999 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 830/1194 | Loss: 273.825 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 840/1194 | Loss: 306.579 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 850/1194 | Loss: 333.075 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 860/1194 | Loss: 322.886 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 870/1194 | Loss: 283.661 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 880/1194 | Loss: 294.649 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 890/1194 | Loss: 302.906 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 900/1194 | Loss: 300.076 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 910/1194 | Loss: 300.249 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 920/1194 | Loss: 292.180 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 930/1194 | Loss: 286.659 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 940/1194 | Loss: 286.336 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 950/1194 | Loss: 300.644 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 960/1194 | Loss: 312.462 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 970/1194 | Loss: 290.920 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 980/1194 | Loss: 297.758 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 990/1194 | Loss: 288.260 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1000/1194 | Loss: 282.922 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1010/1194 | Loss: 300.615 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1020/1194 | Loss: 278.067 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1030/1194 | Loss: 276.636 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1040/1194 | Loss: 295.659 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1050/1194 | Loss: 286.379 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1060/1194 | Loss: 302.265 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1070/1194 | Loss: 295.485 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1080/1194 | Loss: 303.873 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1090/1194 | Loss: 300.119 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1100/1194 | Loss: 272.694 | Accuracy: 0.200\n",
      "[Epoch: 16/200] - Step: 1110/1194 | Loss: 316.009 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1120/1194 | Loss: 303.971 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1130/1194 | Loss: 311.297 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1140/1194 | Loss: 293.152 | Accuracy: 0.100\n",
      "[Epoch: 16/200] - Step: 1150/1194 | Loss: 315.236 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1160/1194 | Loss: 286.288 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1170/1194 | Loss: 277.747 | Accuracy: 0.300\n",
      "[Epoch: 16/200] - Step: 1180/1194 | Loss: 304.100 | Accuracy: 0.000\n",
      "[Epoch: 16/200] - Step: 1190/1194 | Loss: 296.951 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 17/200] - Step: 10/1194 | Loss: 298.304 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 20/1194 | Loss: 306.171 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 30/1194 | Loss: 274.607 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 40/1194 | Loss: 298.486 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 50/1194 | Loss: 282.802 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 60/1194 | Loss: 314.362 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 70/1194 | Loss: 292.401 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 80/1194 | Loss: 300.713 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 90/1194 | Loss: 308.636 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 100/1194 | Loss: 304.346 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 110/1194 | Loss: 304.326 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 120/1194 | Loss: 285.066 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 130/1194 | Loss: 306.683 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 140/1194 | Loss: 287.242 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 150/1194 | Loss: 313.782 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 160/1194 | Loss: 295.041 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 170/1194 | Loss: 300.281 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 180/1194 | Loss: 326.301 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 190/1194 | Loss: 288.502 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 200/1194 | Loss: 298.326 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 210/1194 | Loss: 303.167 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 220/1194 | Loss: 318.258 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 230/1194 | Loss: 287.700 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 240/1194 | Loss: 307.511 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 250/1194 | Loss: 299.371 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 260/1194 | Loss: 303.414 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 270/1194 | Loss: 290.456 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 280/1194 | Loss: 288.690 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 290/1194 | Loss: 297.444 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 300/1194 | Loss: 299.839 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 310/1194 | Loss: 293.613 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 320/1194 | Loss: 301.057 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 330/1194 | Loss: 299.070 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 340/1194 | Loss: 305.702 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 350/1194 | Loss: 286.923 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 360/1194 | Loss: 291.275 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 370/1194 | Loss: 290.692 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 380/1194 | Loss: 282.357 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 390/1194 | Loss: 304.161 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 400/1194 | Loss: 279.886 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 410/1194 | Loss: 297.301 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 420/1194 | Loss: 296.524 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 430/1194 | Loss: 316.483 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 440/1194 | Loss: 300.090 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 450/1194 | Loss: 314.611 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 460/1194 | Loss: 303.257 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 470/1194 | Loss: 306.537 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 480/1194 | Loss: 287.559 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 490/1194 | Loss: 299.666 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 500/1194 | Loss: 292.103 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 510/1194 | Loss: 298.050 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 520/1194 | Loss: 298.522 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 530/1194 | Loss: 300.919 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 540/1194 | Loss: 303.638 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 550/1194 | Loss: 306.377 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 560/1194 | Loss: 284.088 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 570/1194 | Loss: 305.866 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 580/1194 | Loss: 311.943 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 590/1194 | Loss: 291.616 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 600/1194 | Loss: 305.190 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 610/1194 | Loss: 305.783 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 620/1194 | Loss: 292.734 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 630/1194 | Loss: 294.583 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 640/1194 | Loss: 282.588 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 650/1194 | Loss: 302.117 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 660/1194 | Loss: 276.859 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 670/1194 | Loss: 278.958 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 680/1194 | Loss: 306.310 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 690/1194 | Loss: 317.952 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 700/1194 | Loss: 297.064 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 710/1194 | Loss: 306.155 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 720/1194 | Loss: 309.399 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 730/1194 | Loss: 313.359 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 740/1194 | Loss: 291.155 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 750/1194 | Loss: 300.742 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 760/1194 | Loss: 299.989 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 770/1194 | Loss: 314.399 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 780/1194 | Loss: 300.442 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 790/1194 | Loss: 289.436 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 800/1194 | Loss: 290.225 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 810/1194 | Loss: 290.136 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 820/1194 | Loss: 288.224 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 830/1194 | Loss: 290.625 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 840/1194 | Loss: 312.534 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 850/1194 | Loss: 283.868 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 860/1194 | Loss: 296.962 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 870/1194 | Loss: 309.076 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 880/1194 | Loss: 296.989 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 890/1194 | Loss: 272.847 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 900/1194 | Loss: 271.332 | Accuracy: 0.400\n",
      "[Epoch: 17/200] - Step: 910/1194 | Loss: 296.440 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 920/1194 | Loss: 290.962 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 930/1194 | Loss: 292.637 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 940/1194 | Loss: 292.806 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 950/1194 | Loss: 291.929 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 960/1194 | Loss: 290.780 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 970/1194 | Loss: 288.558 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 980/1194 | Loss: 305.004 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 990/1194 | Loss: 314.140 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1000/1194 | Loss: 298.746 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1010/1194 | Loss: 284.685 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1020/1194 | Loss: 311.133 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1030/1194 | Loss: 297.808 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1040/1194 | Loss: 303.353 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1050/1194 | Loss: 298.334 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1060/1194 | Loss: 303.219 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1070/1194 | Loss: 311.898 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1080/1194 | Loss: 279.252 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1090/1194 | Loss: 303.672 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1100/1194 | Loss: 299.678 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1110/1194 | Loss: 322.395 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1120/1194 | Loss: 309.259 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1130/1194 | Loss: 289.475 | Accuracy: 0.200\n",
      "[Epoch: 17/200] - Step: 1140/1194 | Loss: 292.904 | Accuracy: 0.100\n",
      "[Epoch: 17/200] - Step: 1150/1194 | Loss: 317.009 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1160/1194 | Loss: 291.579 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1170/1194 | Loss: 303.837 | Accuracy: 0.000\n",
      "[Epoch: 17/200] - Step: 1180/1194 | Loss: 279.229 | Accuracy: 0.300\n",
      "[Epoch: 17/200] - Step: 1190/1194 | Loss: 304.585 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 18/200] - Step: 10/1194 | Loss: 311.450 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 20/1194 | Loss: 299.446 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 30/1194 | Loss: 294.200 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 40/1194 | Loss: 311.054 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 50/1194 | Loss: 303.097 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 60/1194 | Loss: 299.936 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 70/1194 | Loss: 303.262 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 80/1194 | Loss: 293.743 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 90/1194 | Loss: 292.133 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 100/1194 | Loss: 292.664 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 110/1194 | Loss: 282.924 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 120/1194 | Loss: 325.060 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 130/1194 | Loss: 297.244 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 140/1194 | Loss: 293.367 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 150/1194 | Loss: 315.217 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 160/1194 | Loss: 300.903 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 170/1194 | Loss: 300.291 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 180/1194 | Loss: 300.341 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 190/1194 | Loss: 299.372 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 200/1194 | Loss: 290.435 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 210/1194 | Loss: 294.584 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 220/1194 | Loss: 316.278 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 230/1194 | Loss: 307.349 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 240/1194 | Loss: 307.975 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 250/1194 | Loss: 302.149 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 260/1194 | Loss: 299.265 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 270/1194 | Loss: 294.217 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 280/1194 | Loss: 300.502 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 290/1194 | Loss: 306.045 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 300/1194 | Loss: 301.721 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 310/1194 | Loss: 314.332 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 320/1194 | Loss: 294.631 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 330/1194 | Loss: 318.132 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 340/1194 | Loss: 283.430 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 350/1194 | Loss: 285.814 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 360/1194 | Loss: 278.492 | Accuracy: 0.400\n",
      "[Epoch: 18/200] - Step: 370/1194 | Loss: 303.805 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 380/1194 | Loss: 282.213 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 390/1194 | Loss: 291.301 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 400/1194 | Loss: 288.630 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 410/1194 | Loss: 311.106 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 420/1194 | Loss: 302.092 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 430/1194 | Loss: 289.679 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 440/1194 | Loss: 309.470 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 450/1194 | Loss: 317.849 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 460/1194 | Loss: 301.975 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 470/1194 | Loss: 288.770 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 480/1194 | Loss: 285.112 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 490/1194 | Loss: 287.894 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 500/1194 | Loss: 295.421 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 510/1194 | Loss: 304.621 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 520/1194 | Loss: 287.248 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 530/1194 | Loss: 313.096 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 540/1194 | Loss: 285.527 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 550/1194 | Loss: 303.062 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 560/1194 | Loss: 283.724 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 570/1194 | Loss: 284.035 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 580/1194 | Loss: 296.060 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 590/1194 | Loss: 313.361 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 600/1194 | Loss: 295.530 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 610/1194 | Loss: 301.563 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 620/1194 | Loss: 298.030 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 630/1194 | Loss: 287.292 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 640/1194 | Loss: 297.869 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 650/1194 | Loss: 301.988 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 660/1194 | Loss: 298.844 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 670/1194 | Loss: 282.581 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 680/1194 | Loss: 298.609 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 690/1194 | Loss: 297.814 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 700/1194 | Loss: 310.076 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 710/1194 | Loss: 290.397 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 720/1194 | Loss: 290.965 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 730/1194 | Loss: 321.662 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 740/1194 | Loss: 287.752 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 750/1194 | Loss: 303.480 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 760/1194 | Loss: 280.096 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 770/1194 | Loss: 317.288 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 780/1194 | Loss: 276.574 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 790/1194 | Loss: 304.180 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 800/1194 | Loss: 299.478 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 810/1194 | Loss: 307.988 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 820/1194 | Loss: 296.565 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 830/1194 | Loss: 299.479 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 840/1194 | Loss: 290.052 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 850/1194 | Loss: 305.804 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 860/1194 | Loss: 281.230 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 870/1194 | Loss: 308.203 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 880/1194 | Loss: 307.770 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 890/1194 | Loss: 291.867 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 900/1194 | Loss: 291.477 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 910/1194 | Loss: 287.167 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 920/1194 | Loss: 303.796 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 930/1194 | Loss: 292.315 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 940/1194 | Loss: 312.165 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 950/1194 | Loss: 293.682 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 960/1194 | Loss: 303.080 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 970/1194 | Loss: 289.463 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 980/1194 | Loss: 295.135 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 990/1194 | Loss: 288.517 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1000/1194 | Loss: 295.591 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1010/1194 | Loss: 289.596 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1020/1194 | Loss: 306.505 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1030/1194 | Loss: 291.826 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1040/1194 | Loss: 302.477 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1050/1194 | Loss: 319.447 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1060/1194 | Loss: 317.432 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1070/1194 | Loss: 289.012 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1080/1194 | Loss: 277.973 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1090/1194 | Loss: 300.459 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1100/1194 | Loss: 287.909 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1110/1194 | Loss: 298.435 | Accuracy: 0.100\n",
      "[Epoch: 18/200] - Step: 1120/1194 | Loss: 288.045 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1130/1194 | Loss: 285.671 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1140/1194 | Loss: 289.208 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1150/1194 | Loss: 281.190 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1160/1194 | Loss: 274.257 | Accuracy: 0.300\n",
      "[Epoch: 18/200] - Step: 1170/1194 | Loss: 283.443 | Accuracy: 0.200\n",
      "[Epoch: 18/200] - Step: 1180/1194 | Loss: 301.118 | Accuracy: 0.000\n",
      "[Epoch: 18/200] - Step: 1190/1194 | Loss: 311.267 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 19/200] - Step: 10/1194 | Loss: 302.148 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 20/1194 | Loss: 305.962 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 30/1194 | Loss: 295.255 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 40/1194 | Loss: 286.452 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 50/1194 | Loss: 300.654 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 60/1194 | Loss: 305.850 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 70/1194 | Loss: 302.006 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 80/1194 | Loss: 298.416 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 90/1194 | Loss: 292.598 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 100/1194 | Loss: 305.439 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 110/1194 | Loss: 294.413 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 120/1194 | Loss: 305.009 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 130/1194 | Loss: 301.414 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 140/1194 | Loss: 274.680 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 150/1194 | Loss: 307.594 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 160/1194 | Loss: 305.267 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 170/1194 | Loss: 307.268 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 180/1194 | Loss: 292.524 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 190/1194 | Loss: 298.983 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 200/1194 | Loss: 288.166 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 210/1194 | Loss: 267.418 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 220/1194 | Loss: 285.112 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 230/1194 | Loss: 292.622 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 240/1194 | Loss: 280.888 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 250/1194 | Loss: 276.490 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 260/1194 | Loss: 299.953 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 270/1194 | Loss: 283.916 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 280/1194 | Loss: 312.792 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 290/1194 | Loss: 291.272 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 300/1194 | Loss: 297.863 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 310/1194 | Loss: 330.378 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 320/1194 | Loss: 282.125 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 330/1194 | Loss: 302.993 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 340/1194 | Loss: 298.469 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 350/1194 | Loss: 301.661 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 360/1194 | Loss: 301.447 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 370/1194 | Loss: 303.593 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 380/1194 | Loss: 265.425 | Accuracy: 0.400\n",
      "[Epoch: 19/200] - Step: 390/1194 | Loss: 300.410 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 400/1194 | Loss: 283.515 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 410/1194 | Loss: 304.313 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 420/1194 | Loss: 309.215 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 430/1194 | Loss: 302.737 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 440/1194 | Loss: 318.257 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 450/1194 | Loss: 295.230 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 460/1194 | Loss: 296.348 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 470/1194 | Loss: 308.673 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 480/1194 | Loss: 302.770 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 490/1194 | Loss: 293.143 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 500/1194 | Loss: 293.787 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 510/1194 | Loss: 288.803 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 520/1194 | Loss: 294.679 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 530/1194 | Loss: 296.562 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 540/1194 | Loss: 297.444 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 550/1194 | Loss: 302.829 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 560/1194 | Loss: 346.186 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 570/1194 | Loss: 296.215 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 580/1194 | Loss: 306.128 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 590/1194 | Loss: 277.287 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 600/1194 | Loss: 303.002 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 610/1194 | Loss: 310.607 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 620/1194 | Loss: 299.782 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 630/1194 | Loss: 299.820 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 640/1194 | Loss: 302.590 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 650/1194 | Loss: 299.437 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 660/1194 | Loss: 290.030 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 670/1194 | Loss: 290.637 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 680/1194 | Loss: 290.749 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 690/1194 | Loss: 293.496 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 700/1194 | Loss: 293.793 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 710/1194 | Loss: 283.213 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 720/1194 | Loss: 313.979 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 730/1194 | Loss: 294.877 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 740/1194 | Loss: 302.983 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 750/1194 | Loss: 284.083 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 760/1194 | Loss: 312.409 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 770/1194 | Loss: 301.009 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 780/1194 | Loss: 289.481 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 790/1194 | Loss: 294.306 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 800/1194 | Loss: 316.732 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 810/1194 | Loss: 301.585 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 820/1194 | Loss: 295.705 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 830/1194 | Loss: 285.933 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 840/1194 | Loss: 301.075 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 850/1194 | Loss: 299.238 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 860/1194 | Loss: 301.359 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 870/1194 | Loss: 304.498 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 880/1194 | Loss: 297.120 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 890/1194 | Loss: 304.049 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 900/1194 | Loss: 283.280 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 910/1194 | Loss: 296.055 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 920/1194 | Loss: 292.718 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 930/1194 | Loss: 299.032 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 940/1194 | Loss: 300.895 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 950/1194 | Loss: 304.327 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 960/1194 | Loss: 299.647 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 970/1194 | Loss: 342.832 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 980/1194 | Loss: 305.225 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 990/1194 | Loss: 288.050 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1000/1194 | Loss: 306.406 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1010/1194 | Loss: 296.443 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1020/1194 | Loss: 298.021 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1030/1194 | Loss: 301.190 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1040/1194 | Loss: 307.942 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1050/1194 | Loss: 288.471 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1060/1194 | Loss: 271.139 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1070/1194 | Loss: 311.239 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1080/1194 | Loss: 288.361 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1090/1194 | Loss: 298.060 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1100/1194 | Loss: 307.141 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1110/1194 | Loss: 288.876 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1120/1194 | Loss: 294.805 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1130/1194 | Loss: 277.420 | Accuracy: 0.300\n",
      "[Epoch: 19/200] - Step: 1140/1194 | Loss: 288.493 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1150/1194 | Loss: 294.099 | Accuracy: 0.100\n",
      "[Epoch: 19/200] - Step: 1160/1194 | Loss: 318.100 | Accuracy: 0.200\n",
      "[Epoch: 19/200] - Step: 1170/1194 | Loss: 292.026 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1180/1194 | Loss: 314.177 | Accuracy: 0.000\n",
      "[Epoch: 19/200] - Step: 1190/1194 | Loss: 298.585 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 20/200] - Step: 10/1194 | Loss: 303.553 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 20/1194 | Loss: 302.555 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 30/1194 | Loss: 282.758 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 40/1194 | Loss: 268.103 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 50/1194 | Loss: 302.668 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 60/1194 | Loss: 297.403 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 70/1194 | Loss: 289.928 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 80/1194 | Loss: 289.359 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 90/1194 | Loss: 309.282 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 100/1194 | Loss: 284.477 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 110/1194 | Loss: 313.916 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 120/1194 | Loss: 304.642 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 130/1194 | Loss: 291.923 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 140/1194 | Loss: 308.985 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 150/1194 | Loss: 291.758 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 160/1194 | Loss: 282.950 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 170/1194 | Loss: 300.672 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 180/1194 | Loss: 298.331 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 190/1194 | Loss: 290.030 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 200/1194 | Loss: 302.936 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 210/1194 | Loss: 326.150 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 220/1194 | Loss: 300.142 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 230/1194 | Loss: 299.554 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 240/1194 | Loss: 292.060 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 250/1194 | Loss: 289.116 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 260/1194 | Loss: 306.788 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 270/1194 | Loss: 303.304 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 280/1194 | Loss: 323.638 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 290/1194 | Loss: 299.212 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 300/1194 | Loss: 326.892 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 310/1194 | Loss: 296.020 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 320/1194 | Loss: 300.662 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 330/1194 | Loss: 308.856 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 340/1194 | Loss: 308.429 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 350/1194 | Loss: 301.737 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 360/1194 | Loss: 318.414 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 370/1194 | Loss: 277.395 | Accuracy: 0.500\n",
      "[Epoch: 20/200] - Step: 380/1194 | Loss: 292.547 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 390/1194 | Loss: 277.753 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 400/1194 | Loss: 308.825 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 410/1194 | Loss: 311.228 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 420/1194 | Loss: 297.909 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 430/1194 | Loss: 293.371 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 440/1194 | Loss: 301.259 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 450/1194 | Loss: 299.687 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 460/1194 | Loss: 299.495 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 470/1194 | Loss: 301.446 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 480/1194 | Loss: 309.663 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 490/1194 | Loss: 304.857 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 500/1194 | Loss: 289.471 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 510/1194 | Loss: 305.018 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 520/1194 | Loss: 289.911 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 530/1194 | Loss: 293.873 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 540/1194 | Loss: 286.444 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 550/1194 | Loss: 292.446 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 560/1194 | Loss: 286.762 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 570/1194 | Loss: 332.060 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 580/1194 | Loss: 295.426 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 590/1194 | Loss: 306.182 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 600/1194 | Loss: 285.641 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 610/1194 | Loss: 293.172 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 620/1194 | Loss: 295.945 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 630/1194 | Loss: 274.680 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 640/1194 | Loss: 305.514 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 650/1194 | Loss: 311.136 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 660/1194 | Loss: 306.647 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 670/1194 | Loss: 294.676 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 680/1194 | Loss: 291.828 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 690/1194 | Loss: 288.159 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 700/1194 | Loss: 288.524 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 710/1194 | Loss: 288.908 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 720/1194 | Loss: 288.856 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 730/1194 | Loss: 296.618 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 740/1194 | Loss: 283.956 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 750/1194 | Loss: 311.863 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 760/1194 | Loss: 279.340 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 770/1194 | Loss: 268.575 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 780/1194 | Loss: 279.252 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 790/1194 | Loss: 271.460 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 800/1194 | Loss: 304.247 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 810/1194 | Loss: 308.806 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 820/1194 | Loss: 320.252 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 830/1194 | Loss: 287.637 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 840/1194 | Loss: 292.027 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 850/1194 | Loss: 308.569 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 860/1194 | Loss: 292.887 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 870/1194 | Loss: 295.526 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 880/1194 | Loss: 300.939 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 890/1194 | Loss: 291.727 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 900/1194 | Loss: 291.670 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 910/1194 | Loss: 279.076 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 920/1194 | Loss: 302.292 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 930/1194 | Loss: 301.370 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 940/1194 | Loss: 297.191 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 950/1194 | Loss: 310.757 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 960/1194 | Loss: 289.614 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 970/1194 | Loss: 324.979 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 980/1194 | Loss: 315.205 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 990/1194 | Loss: 284.699 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1000/1194 | Loss: 306.660 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1010/1194 | Loss: 294.478 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1020/1194 | Loss: 301.959 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1030/1194 | Loss: 301.473 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1040/1194 | Loss: 279.117 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1050/1194 | Loss: 331.236 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1060/1194 | Loss: 301.618 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1070/1194 | Loss: 296.010 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1080/1194 | Loss: 315.712 | Accuracy: 0.000\n",
      "[Epoch: 20/200] - Step: 1090/1194 | Loss: 293.949 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1100/1194 | Loss: 324.014 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1110/1194 | Loss: 303.799 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1120/1194 | Loss: 289.410 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1130/1194 | Loss: 287.245 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1140/1194 | Loss: 298.203 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1150/1194 | Loss: 287.676 | Accuracy: 0.100\n",
      "[Epoch: 20/200] - Step: 1160/1194 | Loss: 286.653 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1170/1194 | Loss: 285.242 | Accuracy: 0.200\n",
      "[Epoch: 20/200] - Step: 1180/1194 | Loss: 277.134 | Accuracy: 0.300\n",
      "[Epoch: 20/200] - Step: 1190/1194 | Loss: 315.364 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 21/200] - Step: 10/1194 | Loss: 298.261 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 20/1194 | Loss: 308.596 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 30/1194 | Loss: 308.545 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 40/1194 | Loss: 299.160 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 50/1194 | Loss: 294.686 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 60/1194 | Loss: 300.436 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 70/1194 | Loss: 293.940 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 80/1194 | Loss: 301.866 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 90/1194 | Loss: 320.568 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 100/1194 | Loss: 296.853 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 110/1194 | Loss: 305.047 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 120/1194 | Loss: 292.084 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 130/1194 | Loss: 297.156 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 140/1194 | Loss: 300.214 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 150/1194 | Loss: 307.651 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 160/1194 | Loss: 290.149 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 170/1194 | Loss: 307.235 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 180/1194 | Loss: 290.715 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 190/1194 | Loss: 294.800 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 200/1194 | Loss: 352.582 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 210/1194 | Loss: 293.764 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 220/1194 | Loss: 291.694 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 230/1194 | Loss: 298.600 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 240/1194 | Loss: 291.695 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 250/1194 | Loss: 296.078 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 260/1194 | Loss: 288.075 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 270/1194 | Loss: 303.003 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 280/1194 | Loss: 313.398 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 290/1194 | Loss: 285.329 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 300/1194 | Loss: 298.069 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 310/1194 | Loss: 304.510 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 320/1194 | Loss: 269.200 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 330/1194 | Loss: 321.281 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 340/1194 | Loss: 304.914 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 350/1194 | Loss: 288.392 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 360/1194 | Loss: 291.696 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 370/1194 | Loss: 301.461 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 380/1194 | Loss: 325.802 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 390/1194 | Loss: 294.080 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 400/1194 | Loss: 295.577 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 410/1194 | Loss: 294.168 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 420/1194 | Loss: 319.619 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 430/1194 | Loss: 293.712 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 440/1194 | Loss: 290.055 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 450/1194 | Loss: 287.695 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 460/1194 | Loss: 297.818 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 470/1194 | Loss: 287.166 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 480/1194 | Loss: 332.707 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 490/1194 | Loss: 302.202 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 500/1194 | Loss: 310.504 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 510/1194 | Loss: 283.597 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 520/1194 | Loss: 310.986 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 530/1194 | Loss: 311.170 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 540/1194 | Loss: 301.645 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 550/1194 | Loss: 296.325 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 560/1194 | Loss: 301.972 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 570/1194 | Loss: 303.631 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 580/1194 | Loss: 309.511 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 590/1194 | Loss: 307.616 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 600/1194 | Loss: 299.802 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 610/1194 | Loss: 292.741 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 620/1194 | Loss: 295.740 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 630/1194 | Loss: 281.213 | Accuracy: 0.400\n",
      "[Epoch: 21/200] - Step: 640/1194 | Loss: 302.163 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 650/1194 | Loss: 303.317 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 660/1194 | Loss: 302.794 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 670/1194 | Loss: 284.117 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 680/1194 | Loss: 310.581 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 690/1194 | Loss: 302.083 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 700/1194 | Loss: 278.199 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 710/1194 | Loss: 276.776 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 720/1194 | Loss: 277.215 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 730/1194 | Loss: 273.273 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 740/1194 | Loss: 307.142 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 750/1194 | Loss: 285.856 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 760/1194 | Loss: 266.286 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 770/1194 | Loss: 296.635 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 780/1194 | Loss: 306.073 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 790/1194 | Loss: 303.485 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 800/1194 | Loss: 299.437 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 810/1194 | Loss: 295.060 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 820/1194 | Loss: 310.133 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 830/1194 | Loss: 290.773 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 840/1194 | Loss: 296.782 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 850/1194 | Loss: 310.659 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 860/1194 | Loss: 293.604 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 870/1194 | Loss: 286.721 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 880/1194 | Loss: 291.950 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 890/1194 | Loss: 274.697 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 900/1194 | Loss: 313.776 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 910/1194 | Loss: 308.010 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 920/1194 | Loss: 302.466 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 930/1194 | Loss: 307.298 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 940/1194 | Loss: 284.359 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 950/1194 | Loss: 285.274 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 960/1194 | Loss: 289.115 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 970/1194 | Loss: 312.396 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 980/1194 | Loss: 292.561 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 990/1194 | Loss: 287.656 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1000/1194 | Loss: 296.467 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1010/1194 | Loss: 302.332 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1020/1194 | Loss: 292.413 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1030/1194 | Loss: 293.740 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1040/1194 | Loss: 294.833 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1050/1194 | Loss: 284.299 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1060/1194 | Loss: 287.082 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1070/1194 | Loss: 303.143 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1080/1194 | Loss: 258.091 | Accuracy: 0.500\n",
      "[Epoch: 21/200] - Step: 1090/1194 | Loss: 304.693 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1100/1194 | Loss: 314.981 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1110/1194 | Loss: 289.393 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1120/1194 | Loss: 300.473 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1130/1194 | Loss: 310.414 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1140/1194 | Loss: 295.045 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1150/1194 | Loss: 318.938 | Accuracy: 0.000\n",
      "[Epoch: 21/200] - Step: 1160/1194 | Loss: 278.148 | Accuracy: 0.300\n",
      "[Epoch: 21/200] - Step: 1170/1194 | Loss: 300.878 | Accuracy: 0.100\n",
      "[Epoch: 21/200] - Step: 1180/1194 | Loss: 278.317 | Accuracy: 0.200\n",
      "[Epoch: 21/200] - Step: 1190/1194 | Loss: 304.897 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 22/200] - Step: 10/1194 | Loss: 304.179 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 20/1194 | Loss: 290.861 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 30/1194 | Loss: 307.417 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 40/1194 | Loss: 291.062 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 50/1194 | Loss: 311.699 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 60/1194 | Loss: 303.155 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 70/1194 | Loss: 283.559 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 80/1194 | Loss: 290.331 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 90/1194 | Loss: 268.609 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 100/1194 | Loss: 311.132 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 110/1194 | Loss: 302.097 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 120/1194 | Loss: 280.693 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 130/1194 | Loss: 314.730 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 140/1194 | Loss: 306.861 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 150/1194 | Loss: 286.815 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 160/1194 | Loss: 304.764 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 170/1194 | Loss: 318.719 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 180/1194 | Loss: 288.940 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 190/1194 | Loss: 333.280 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 200/1194 | Loss: 301.514 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 210/1194 | Loss: 310.028 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 220/1194 | Loss: 291.536 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 230/1194 | Loss: 301.505 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 240/1194 | Loss: 279.555 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 250/1194 | Loss: 292.426 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 260/1194 | Loss: 283.244 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 270/1194 | Loss: 296.505 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 280/1194 | Loss: 280.322 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 290/1194 | Loss: 281.418 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 300/1194 | Loss: 284.252 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 310/1194 | Loss: 308.249 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 320/1194 | Loss: 317.873 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 330/1194 | Loss: 301.833 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 340/1194 | Loss: 294.950 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 350/1194 | Loss: 293.254 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 360/1194 | Loss: 267.298 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 370/1194 | Loss: 301.868 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 380/1194 | Loss: 315.486 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 390/1194 | Loss: 298.738 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 400/1194 | Loss: 300.499 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 410/1194 | Loss: 288.232 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 420/1194 | Loss: 284.251 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 430/1194 | Loss: 284.082 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 440/1194 | Loss: 299.959 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 450/1194 | Loss: 297.251 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 460/1194 | Loss: 309.247 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 470/1194 | Loss: 301.415 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 480/1194 | Loss: 301.631 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 490/1194 | Loss: 295.773 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 500/1194 | Loss: 310.640 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 510/1194 | Loss: 300.141 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 520/1194 | Loss: 305.678 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 530/1194 | Loss: 298.167 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 540/1194 | Loss: 291.921 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 550/1194 | Loss: 303.253 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 560/1194 | Loss: 289.440 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 570/1194 | Loss: 282.506 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 580/1194 | Loss: 280.353 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 590/1194 | Loss: 301.986 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 600/1194 | Loss: 301.405 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 610/1194 | Loss: 303.994 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 620/1194 | Loss: 283.335 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 630/1194 | Loss: 314.160 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 640/1194 | Loss: 312.690 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 650/1194 | Loss: 302.974 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 660/1194 | Loss: 303.226 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 670/1194 | Loss: 323.002 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 680/1194 | Loss: 286.895 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 690/1194 | Loss: 282.130 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 700/1194 | Loss: 287.923 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 710/1194 | Loss: 291.101 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 720/1194 | Loss: 303.834 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 730/1194 | Loss: 300.104 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 740/1194 | Loss: 300.702 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 750/1194 | Loss: 302.352 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 760/1194 | Loss: 281.683 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 770/1194 | Loss: 311.290 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 780/1194 | Loss: 306.529 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 790/1194 | Loss: 306.123 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 800/1194 | Loss: 286.123 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 810/1194 | Loss: 310.572 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 820/1194 | Loss: 291.303 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 830/1194 | Loss: 295.233 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 840/1194 | Loss: 306.955 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 850/1194 | Loss: 302.210 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 860/1194 | Loss: 272.027 | Accuracy: 0.400\n",
      "[Epoch: 22/200] - Step: 870/1194 | Loss: 301.924 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 880/1194 | Loss: 303.082 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 890/1194 | Loss: 289.273 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 900/1194 | Loss: 289.330 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 910/1194 | Loss: 303.378 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 920/1194 | Loss: 302.758 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 930/1194 | Loss: 309.141 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 940/1194 | Loss: 295.120 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 950/1194 | Loss: 281.257 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 960/1194 | Loss: 305.862 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 970/1194 | Loss: 295.638 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 980/1194 | Loss: 282.310 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 990/1194 | Loss: 299.707 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1000/1194 | Loss: 279.182 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1010/1194 | Loss: 302.934 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1020/1194 | Loss: 310.388 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1030/1194 | Loss: 303.115 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1040/1194 | Loss: 313.003 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1050/1194 | Loss: 306.439 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1060/1194 | Loss: 292.551 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1070/1194 | Loss: 295.985 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1080/1194 | Loss: 302.950 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1090/1194 | Loss: 322.427 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1100/1194 | Loss: 296.353 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1110/1194 | Loss: 282.291 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1120/1194 | Loss: 313.274 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1130/1194 | Loss: 296.581 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1140/1194 | Loss: 290.420 | Accuracy: 0.200\n",
      "[Epoch: 22/200] - Step: 1150/1194 | Loss: 299.599 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1160/1194 | Loss: 309.800 | Accuracy: 0.000\n",
      "[Epoch: 22/200] - Step: 1170/1194 | Loss: 278.478 | Accuracy: 0.300\n",
      "[Epoch: 22/200] - Step: 1180/1194 | Loss: 298.329 | Accuracy: 0.100\n",
      "[Epoch: 22/200] - Step: 1190/1194 | Loss: 303.786 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 23/200] - Step: 10/1194 | Loss: 293.712 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 20/1194 | Loss: 309.414 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 30/1194 | Loss: 298.428 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 40/1194 | Loss: 289.496 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 50/1194 | Loss: 298.128 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 60/1194 | Loss: 330.639 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 70/1194 | Loss: 318.289 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 80/1194 | Loss: 299.640 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 90/1194 | Loss: 304.807 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 100/1194 | Loss: 306.055 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 110/1194 | Loss: 303.658 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 120/1194 | Loss: 289.625 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 130/1194 | Loss: 296.983 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 140/1194 | Loss: 296.956 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 150/1194 | Loss: 297.019 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 160/1194 | Loss: 264.461 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 170/1194 | Loss: 282.176 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 180/1194 | Loss: 282.859 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 190/1194 | Loss: 300.885 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 200/1194 | Loss: 285.796 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 210/1194 | Loss: 303.972 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 220/1194 | Loss: 289.971 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 230/1194 | Loss: 304.304 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 240/1194 | Loss: 298.399 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 250/1194 | Loss: 303.257 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 260/1194 | Loss: 304.373 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 270/1194 | Loss: 294.065 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 280/1194 | Loss: 303.722 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 290/1194 | Loss: 292.955 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 300/1194 | Loss: 310.313 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 310/1194 | Loss: 299.750 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 320/1194 | Loss: 328.079 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 330/1194 | Loss: 310.078 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 340/1194 | Loss: 298.170 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 350/1194 | Loss: 300.327 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 360/1194 | Loss: 292.068 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 370/1194 | Loss: 293.070 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 380/1194 | Loss: 297.292 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 390/1194 | Loss: 302.704 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 400/1194 | Loss: 296.441 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 410/1194 | Loss: 297.124 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 420/1194 | Loss: 283.444 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 430/1194 | Loss: 300.967 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 440/1194 | Loss: 275.062 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 450/1194 | Loss: 321.360 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 460/1194 | Loss: 303.607 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 470/1194 | Loss: 281.932 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 480/1194 | Loss: 316.174 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 490/1194 | Loss: 277.627 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 500/1194 | Loss: 298.575 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 510/1194 | Loss: 291.476 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 520/1194 | Loss: 310.573 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 530/1194 | Loss: 278.488 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 540/1194 | Loss: 332.933 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 550/1194 | Loss: 295.012 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 560/1194 | Loss: 287.518 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 570/1194 | Loss: 340.340 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 580/1194 | Loss: 297.009 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 590/1194 | Loss: 303.521 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 600/1194 | Loss: 296.848 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 610/1194 | Loss: 292.515 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 620/1194 | Loss: 296.496 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 630/1194 | Loss: 293.152 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 640/1194 | Loss: 285.945 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 650/1194 | Loss: 293.081 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 660/1194 | Loss: 285.988 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 670/1194 | Loss: 295.068 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 680/1194 | Loss: 312.809 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 690/1194 | Loss: 309.419 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 700/1194 | Loss: 307.062 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 710/1194 | Loss: 278.603 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 720/1194 | Loss: 292.657 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 730/1194 | Loss: 308.913 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 740/1194 | Loss: 301.586 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 750/1194 | Loss: 300.209 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 760/1194 | Loss: 290.045 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 770/1194 | Loss: 333.414 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 780/1194 | Loss: 304.777 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 790/1194 | Loss: 312.031 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 800/1194 | Loss: 301.317 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 810/1194 | Loss: 277.451 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 820/1194 | Loss: 306.046 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 830/1194 | Loss: 299.590 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 840/1194 | Loss: 286.048 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 850/1194 | Loss: 320.296 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 860/1194 | Loss: 296.022 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 870/1194 | Loss: 299.158 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 880/1194 | Loss: 296.732 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 890/1194 | Loss: 271.131 | Accuracy: 0.400\n",
      "[Epoch: 23/200] - Step: 900/1194 | Loss: 307.830 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 910/1194 | Loss: 303.476 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 920/1194 | Loss: 289.226 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 930/1194 | Loss: 307.332 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 940/1194 | Loss: 285.501 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 950/1194 | Loss: 317.381 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 960/1194 | Loss: 290.448 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 970/1194 | Loss: 287.038 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 980/1194 | Loss: 266.690 | Accuracy: 0.500\n",
      "[Epoch: 23/200] - Step: 990/1194 | Loss: 306.306 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1000/1194 | Loss: 306.723 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1010/1194 | Loss: 286.147 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1020/1194 | Loss: 305.905 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1030/1194 | Loss: 281.828 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1040/1194 | Loss: 298.252 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1050/1194 | Loss: 291.249 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1060/1194 | Loss: 294.105 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1070/1194 | Loss: 313.289 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1080/1194 | Loss: 297.513 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1090/1194 | Loss: 301.880 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1100/1194 | Loss: 296.510 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1110/1194 | Loss: 295.897 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1120/1194 | Loss: 290.050 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1130/1194 | Loss: 286.531 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1140/1194 | Loss: 275.529 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1150/1194 | Loss: 291.490 | Accuracy: 0.200\n",
      "[Epoch: 23/200] - Step: 1160/1194 | Loss: 288.574 | Accuracy: 0.100\n",
      "[Epoch: 23/200] - Step: 1170/1194 | Loss: 307.256 | Accuracy: 0.000\n",
      "[Epoch: 23/200] - Step: 1180/1194 | Loss: 277.523 | Accuracy: 0.300\n",
      "[Epoch: 23/200] - Step: 1190/1194 | Loss: 304.974 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 24/200] - Step: 10/1194 | Loss: 296.534 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 20/1194 | Loss: 288.297 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 30/1194 | Loss: 305.148 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 40/1194 | Loss: 282.290 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 50/1194 | Loss: 288.295 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 60/1194 | Loss: 305.602 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 70/1194 | Loss: 312.946 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 80/1194 | Loss: 303.766 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 90/1194 | Loss: 288.370 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 100/1194 | Loss: 297.096 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 110/1194 | Loss: 284.049 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 120/1194 | Loss: 261.968 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 130/1194 | Loss: 302.795 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 140/1194 | Loss: 272.832 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 150/1194 | Loss: 300.697 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 160/1194 | Loss: 293.833 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 170/1194 | Loss: 301.854 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 180/1194 | Loss: 335.538 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 190/1194 | Loss: 289.370 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 200/1194 | Loss: 294.256 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 210/1194 | Loss: 279.852 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 220/1194 | Loss: 303.991 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 230/1194 | Loss: 267.166 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 240/1194 | Loss: 280.073 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 250/1194 | Loss: 269.244 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 260/1194 | Loss: 310.870 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 270/1194 | Loss: 334.394 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 280/1194 | Loss: 306.547 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 290/1194 | Loss: 287.494 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 300/1194 | Loss: 299.884 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 310/1194 | Loss: 292.509 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 320/1194 | Loss: 320.414 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 330/1194 | Loss: 335.128 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 340/1194 | Loss: 306.569 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 350/1194 | Loss: 306.701 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 360/1194 | Loss: 297.406 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 370/1194 | Loss: 307.878 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 380/1194 | Loss: 307.655 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 390/1194 | Loss: 301.150 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 400/1194 | Loss: 290.566 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 410/1194 | Loss: 281.209 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 420/1194 | Loss: 299.507 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 430/1194 | Loss: 307.091 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 440/1194 | Loss: 301.228 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 450/1194 | Loss: 285.041 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 460/1194 | Loss: 290.771 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 470/1194 | Loss: 287.601 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 480/1194 | Loss: 315.316 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 490/1194 | Loss: 285.626 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 500/1194 | Loss: 287.799 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 510/1194 | Loss: 303.162 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 520/1194 | Loss: 291.686 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 530/1194 | Loss: 282.454 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 540/1194 | Loss: 283.130 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 550/1194 | Loss: 304.211 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 560/1194 | Loss: 314.345 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 570/1194 | Loss: 292.725 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 580/1194 | Loss: 295.473 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 590/1194 | Loss: 312.612 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 600/1194 | Loss: 294.758 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 610/1194 | Loss: 292.981 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 620/1194 | Loss: 295.019 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 630/1194 | Loss: 314.599 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 640/1194 | Loss: 288.533 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 650/1194 | Loss: 291.273 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 660/1194 | Loss: 311.750 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 670/1194 | Loss: 285.047 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 680/1194 | Loss: 276.221 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 690/1194 | Loss: 285.563 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 700/1194 | Loss: 309.830 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 710/1194 | Loss: 307.561 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 720/1194 | Loss: 275.958 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 730/1194 | Loss: 298.948 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 740/1194 | Loss: 305.314 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 750/1194 | Loss: 277.824 | Accuracy: 0.400\n",
      "[Epoch: 24/200] - Step: 760/1194 | Loss: 284.228 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 770/1194 | Loss: 292.579 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 780/1194 | Loss: 298.300 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 790/1194 | Loss: 298.112 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 800/1194 | Loss: 291.781 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 810/1194 | Loss: 303.106 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 820/1194 | Loss: 300.173 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 830/1194 | Loss: 302.446 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 840/1194 | Loss: 302.025 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 850/1194 | Loss: 293.255 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 860/1194 | Loss: 307.131 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 870/1194 | Loss: 298.997 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 880/1194 | Loss: 296.733 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 890/1194 | Loss: 296.564 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 900/1194 | Loss: 297.365 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 910/1194 | Loss: 323.707 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 920/1194 | Loss: 302.848 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 930/1194 | Loss: 309.294 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 940/1194 | Loss: 301.969 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 950/1194 | Loss: 293.593 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 960/1194 | Loss: 301.910 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 970/1194 | Loss: 311.124 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 980/1194 | Loss: 297.264 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 990/1194 | Loss: 285.682 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1000/1194 | Loss: 291.413 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1010/1194 | Loss: 305.728 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1020/1194 | Loss: 317.073 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1030/1194 | Loss: 312.626 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1040/1194 | Loss: 295.094 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1050/1194 | Loss: 301.822 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1060/1194 | Loss: 333.529 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1070/1194 | Loss: 302.359 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1080/1194 | Loss: 298.067 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1090/1194 | Loss: 285.019 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1100/1194 | Loss: 291.557 | Accuracy: 0.300\n",
      "[Epoch: 24/200] - Step: 1110/1194 | Loss: 290.378 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1120/1194 | Loss: 290.090 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1130/1194 | Loss: 307.553 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1140/1194 | Loss: 293.658 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1150/1194 | Loss: 302.022 | Accuracy: 0.000\n",
      "[Epoch: 24/200] - Step: 1160/1194 | Loss: 285.084 | Accuracy: 0.200\n",
      "[Epoch: 24/200] - Step: 1170/1194 | Loss: 327.669 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1180/1194 | Loss: 291.976 | Accuracy: 0.100\n",
      "[Epoch: 24/200] - Step: 1190/1194 | Loss: 284.863 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 25/200] - Step: 10/1194 | Loss: 311.819 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 20/1194 | Loss: 283.496 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 30/1194 | Loss: 292.185 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 40/1194 | Loss: 279.899 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 50/1194 | Loss: 301.579 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 60/1194 | Loss: 290.144 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 70/1194 | Loss: 260.636 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 80/1194 | Loss: 339.369 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 90/1194 | Loss: 315.743 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 100/1194 | Loss: 289.302 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 110/1194 | Loss: 285.032 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 120/1194 | Loss: 284.603 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 130/1194 | Loss: 304.554 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 140/1194 | Loss: 314.707 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 150/1194 | Loss: 294.101 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 160/1194 | Loss: 298.560 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 170/1194 | Loss: 305.221 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 180/1194 | Loss: 297.177 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 190/1194 | Loss: 296.668 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 200/1194 | Loss: 298.978 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 210/1194 | Loss: 302.560 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 220/1194 | Loss: 297.605 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 230/1194 | Loss: 304.227 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 240/1194 | Loss: 307.754 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 250/1194 | Loss: 298.720 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 260/1194 | Loss: 302.624 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 270/1194 | Loss: 310.886 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 280/1194 | Loss: 304.414 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 290/1194 | Loss: 314.159 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 300/1194 | Loss: 297.083 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 310/1194 | Loss: 312.690 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 320/1194 | Loss: 304.239 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 330/1194 | Loss: 305.681 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 340/1194 | Loss: 306.406 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 350/1194 | Loss: 295.239 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 360/1194 | Loss: 296.940 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 370/1194 | Loss: 282.945 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 380/1194 | Loss: 301.490 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 390/1194 | Loss: 299.036 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 400/1194 | Loss: 303.773 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 410/1194 | Loss: 295.724 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 420/1194 | Loss: 280.072 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 430/1194 | Loss: 296.766 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 440/1194 | Loss: 303.016 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 450/1194 | Loss: 293.946 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 460/1194 | Loss: 284.512 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 470/1194 | Loss: 292.621 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 480/1194 | Loss: 283.255 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 490/1194 | Loss: 295.402 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 500/1194 | Loss: 285.196 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 510/1194 | Loss: 296.071 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 520/1194 | Loss: 284.295 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 530/1194 | Loss: 286.734 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 540/1194 | Loss: 277.586 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 550/1194 | Loss: 292.608 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 560/1194 | Loss: 309.688 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 570/1194 | Loss: 304.888 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 580/1194 | Loss: 280.975 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 590/1194 | Loss: 273.449 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 600/1194 | Loss: 279.697 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 610/1194 | Loss: 275.057 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 620/1194 | Loss: 293.623 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 630/1194 | Loss: 310.405 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 640/1194 | Loss: 286.316 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 650/1194 | Loss: 281.169 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 660/1194 | Loss: 317.736 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 670/1194 | Loss: 300.641 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 680/1194 | Loss: 304.710 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 690/1194 | Loss: 292.635 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 700/1194 | Loss: 300.300 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 710/1194 | Loss: 293.955 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 720/1194 | Loss: 308.341 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 730/1194 | Loss: 295.155 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 740/1194 | Loss: 295.499 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 750/1194 | Loss: 286.447 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 760/1194 | Loss: 298.276 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 770/1194 | Loss: 293.703 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 780/1194 | Loss: 292.861 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 790/1194 | Loss: 286.758 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 800/1194 | Loss: 298.347 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 810/1194 | Loss: 318.782 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 820/1194 | Loss: 305.962 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 830/1194 | Loss: 292.126 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 840/1194 | Loss: 292.875 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 850/1194 | Loss: 283.454 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 860/1194 | Loss: 296.752 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 870/1194 | Loss: 309.235 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 880/1194 | Loss: 285.197 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 890/1194 | Loss: 297.790 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 900/1194 | Loss: 286.337 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 910/1194 | Loss: 305.686 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 920/1194 | Loss: 301.356 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 930/1194 | Loss: 301.179 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 940/1194 | Loss: 305.003 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 950/1194 | Loss: 283.352 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 960/1194 | Loss: 273.445 | Accuracy: 0.400\n",
      "[Epoch: 25/200] - Step: 970/1194 | Loss: 282.215 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 980/1194 | Loss: 300.620 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 990/1194 | Loss: 302.451 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1000/1194 | Loss: 290.607 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1010/1194 | Loss: 322.038 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1020/1194 | Loss: 296.764 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1030/1194 | Loss: 300.448 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1040/1194 | Loss: 300.413 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1050/1194 | Loss: 310.005 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1060/1194 | Loss: 291.581 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1070/1194 | Loss: 307.948 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1080/1194 | Loss: 301.689 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1090/1194 | Loss: 314.465 | Accuracy: 0.300\n",
      "[Epoch: 25/200] - Step: 1100/1194 | Loss: 291.017 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1110/1194 | Loss: 320.600 | Accuracy: 0.200\n",
      "[Epoch: 25/200] - Step: 1120/1194 | Loss: 294.170 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1130/1194 | Loss: 299.491 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1140/1194 | Loss: 294.658 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1150/1194 | Loss: 306.674 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1160/1194 | Loss: 324.989 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1170/1194 | Loss: 294.675 | Accuracy: 0.100\n",
      "[Epoch: 25/200] - Step: 1180/1194 | Loss: 303.733 | Accuracy: 0.000\n",
      "[Epoch: 25/200] - Step: 1190/1194 | Loss: 302.688 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 26/200] - Step: 10/1194 | Loss: 309.259 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 20/1194 | Loss: 292.269 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 30/1194 | Loss: 304.791 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 40/1194 | Loss: 289.291 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 50/1194 | Loss: 286.848 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 60/1194 | Loss: 299.798 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 70/1194 | Loss: 293.570 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 80/1194 | Loss: 315.725 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 90/1194 | Loss: 288.044 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 100/1194 | Loss: 272.444 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 110/1194 | Loss: 301.387 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 120/1194 | Loss: 282.214 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 130/1194 | Loss: 295.201 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 140/1194 | Loss: 284.035 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 150/1194 | Loss: 304.456 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 160/1194 | Loss: 299.991 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 170/1194 | Loss: 293.701 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 180/1194 | Loss: 302.552 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 190/1194 | Loss: 366.088 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 200/1194 | Loss: 300.528 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 210/1194 | Loss: 293.310 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 220/1194 | Loss: 287.758 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 230/1194 | Loss: 296.411 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 240/1194 | Loss: 303.306 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 250/1194 | Loss: 301.055 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 260/1194 | Loss: 306.061 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 270/1194 | Loss: 300.399 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 280/1194 | Loss: 303.774 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 290/1194 | Loss: 320.457 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 300/1194 | Loss: 291.405 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 310/1194 | Loss: 291.460 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 320/1194 | Loss: 294.887 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 330/1194 | Loss: 292.725 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 340/1194 | Loss: 308.435 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 350/1194 | Loss: 310.362 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 360/1194 | Loss: 300.390 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 370/1194 | Loss: 295.091 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 380/1194 | Loss: 283.058 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 390/1194 | Loss: 316.031 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 400/1194 | Loss: 295.013 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 410/1194 | Loss: 289.625 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 420/1194 | Loss: 299.845 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 430/1194 | Loss: 290.877 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 440/1194 | Loss: 303.564 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 450/1194 | Loss: 288.262 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 460/1194 | Loss: 310.086 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 470/1194 | Loss: 306.518 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 480/1194 | Loss: 307.348 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 490/1194 | Loss: 294.055 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 500/1194 | Loss: 301.584 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 510/1194 | Loss: 303.172 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 520/1194 | Loss: 304.956 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 530/1194 | Loss: 303.783 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 540/1194 | Loss: 302.051 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 550/1194 | Loss: 288.471 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 560/1194 | Loss: 307.910 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 570/1194 | Loss: 305.059 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 580/1194 | Loss: 292.628 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 590/1194 | Loss: 293.174 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 600/1194 | Loss: 294.526 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 610/1194 | Loss: 307.127 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 620/1194 | Loss: 284.823 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 630/1194 | Loss: 279.505 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 640/1194 | Loss: 286.788 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 650/1194 | Loss: 288.157 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 660/1194 | Loss: 275.818 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 670/1194 | Loss: 297.342 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 680/1194 | Loss: 295.868 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 690/1194 | Loss: 278.319 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 700/1194 | Loss: 293.164 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 710/1194 | Loss: 302.906 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 720/1194 | Loss: 286.750 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 730/1194 | Loss: 290.140 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 740/1194 | Loss: 293.364 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 750/1194 | Loss: 307.098 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 760/1194 | Loss: 285.038 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 770/1194 | Loss: 286.197 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 780/1194 | Loss: 320.977 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 790/1194 | Loss: 281.682 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 800/1194 | Loss: 297.412 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 810/1194 | Loss: 288.770 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 820/1194 | Loss: 297.085 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 830/1194 | Loss: 294.054 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 840/1194 | Loss: 297.238 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 850/1194 | Loss: 296.615 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 860/1194 | Loss: 286.771 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 870/1194 | Loss: 284.663 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 880/1194 | Loss: 292.019 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 890/1194 | Loss: 292.123 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 900/1194 | Loss: 331.784 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 910/1194 | Loss: 298.436 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 920/1194 | Loss: 292.488 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 930/1194 | Loss: 299.688 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 940/1194 | Loss: 299.190 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 950/1194 | Loss: 309.501 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 960/1194 | Loss: 270.266 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 970/1194 | Loss: 293.497 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 980/1194 | Loss: 297.063 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 990/1194 | Loss: 312.567 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1000/1194 | Loss: 341.144 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1010/1194 | Loss: 304.185 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1020/1194 | Loss: 304.062 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1030/1194 | Loss: 305.715 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1040/1194 | Loss: 296.853 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1050/1194 | Loss: 285.516 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1060/1194 | Loss: 284.634 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1070/1194 | Loss: 298.709 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1080/1194 | Loss: 272.548 | Accuracy: 0.400\n",
      "[Epoch: 26/200] - Step: 1090/1194 | Loss: 320.051 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1100/1194 | Loss: 281.102 | Accuracy: 0.300\n",
      "[Epoch: 26/200] - Step: 1110/1194 | Loss: 337.663 | Accuracy: 0.000\n",
      "[Epoch: 26/200] - Step: 1120/1194 | Loss: 284.945 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1130/1194 | Loss: 300.356 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1140/1194 | Loss: 295.307 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1150/1194 | Loss: 290.571 | Accuracy: 0.200\n",
      "[Epoch: 26/200] - Step: 1160/1194 | Loss: 307.094 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1170/1194 | Loss: 297.369 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1180/1194 | Loss: 303.566 | Accuracy: 0.100\n",
      "[Epoch: 26/200] - Step: 1190/1194 | Loss: 306.517 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 27/200] - Step: 10/1194 | Loss: 295.520 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 20/1194 | Loss: 321.364 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 30/1194 | Loss: 300.279 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 40/1194 | Loss: 309.134 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 50/1194 | Loss: 295.147 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 60/1194 | Loss: 297.919 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 70/1194 | Loss: 285.239 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 80/1194 | Loss: 297.902 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 90/1194 | Loss: 300.950 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 100/1194 | Loss: 301.330 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 110/1194 | Loss: 287.039 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 120/1194 | Loss: 293.870 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 130/1194 | Loss: 294.046 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 140/1194 | Loss: 298.781 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 150/1194 | Loss: 265.032 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 160/1194 | Loss: 313.261 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 170/1194 | Loss: 310.622 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 180/1194 | Loss: 296.513 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 190/1194 | Loss: 304.664 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 200/1194 | Loss: 301.134 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 210/1194 | Loss: 285.225 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 220/1194 | Loss: 294.123 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 230/1194 | Loss: 293.337 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 240/1194 | Loss: 295.794 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 250/1194 | Loss: 303.828 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 260/1194 | Loss: 295.025 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 270/1194 | Loss: 301.119 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 280/1194 | Loss: 289.831 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 290/1194 | Loss: 285.338 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 300/1194 | Loss: 311.304 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 310/1194 | Loss: 304.786 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 320/1194 | Loss: 292.879 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 330/1194 | Loss: 311.885 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 340/1194 | Loss: 307.732 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 350/1194 | Loss: 288.919 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 360/1194 | Loss: 332.668 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 370/1194 | Loss: 292.917 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 380/1194 | Loss: 306.489 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 390/1194 | Loss: 303.654 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 400/1194 | Loss: 300.900 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 410/1194 | Loss: 296.492 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 420/1194 | Loss: 324.466 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 430/1194 | Loss: 313.958 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 440/1194 | Loss: 299.492 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 450/1194 | Loss: 306.778 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 460/1194 | Loss: 300.961 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 470/1194 | Loss: 289.965 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 480/1194 | Loss: 301.521 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 490/1194 | Loss: 297.211 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 500/1194 | Loss: 313.838 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 510/1194 | Loss: 293.935 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 520/1194 | Loss: 275.052 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 530/1194 | Loss: 300.088 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 540/1194 | Loss: 298.093 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 550/1194 | Loss: 319.217 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 560/1194 | Loss: 310.118 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 570/1194 | Loss: 286.740 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 580/1194 | Loss: 312.353 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 590/1194 | Loss: 303.033 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 600/1194 | Loss: 299.711 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 610/1194 | Loss: 289.717 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 620/1194 | Loss: 311.830 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 630/1194 | Loss: 302.329 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 640/1194 | Loss: 294.107 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 650/1194 | Loss: 279.718 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 660/1194 | Loss: 310.243 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 670/1194 | Loss: 270.605 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 680/1194 | Loss: 302.107 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 690/1194 | Loss: 304.353 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 700/1194 | Loss: 276.050 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 710/1194 | Loss: 295.877 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 720/1194 | Loss: 280.248 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 730/1194 | Loss: 289.081 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 740/1194 | Loss: 290.777 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 750/1194 | Loss: 307.245 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 760/1194 | Loss: 291.892 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 770/1194 | Loss: 302.079 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 780/1194 | Loss: 274.032 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 790/1194 | Loss: 299.181 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 800/1194 | Loss: 281.509 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 810/1194 | Loss: 292.936 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 820/1194 | Loss: 277.781 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 830/1194 | Loss: 317.657 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 840/1194 | Loss: 287.813 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 850/1194 | Loss: 306.520 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 860/1194 | Loss: 293.464 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 870/1194 | Loss: 271.925 | Accuracy: 0.400\n",
      "[Epoch: 27/200] - Step: 880/1194 | Loss: 293.029 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 890/1194 | Loss: 282.163 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 900/1194 | Loss: 302.220 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 910/1194 | Loss: 284.370 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 920/1194 | Loss: 300.493 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 930/1194 | Loss: 297.688 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 940/1194 | Loss: 302.478 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 950/1194 | Loss: 296.568 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 960/1194 | Loss: 313.019 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 970/1194 | Loss: 301.271 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 980/1194 | Loss: 311.534 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 990/1194 | Loss: 285.725 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1000/1194 | Loss: 304.741 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1010/1194 | Loss: 291.733 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1020/1194 | Loss: 315.651 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1030/1194 | Loss: 303.274 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1040/1194 | Loss: 304.438 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1050/1194 | Loss: 273.471 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1060/1194 | Loss: 291.278 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1070/1194 | Loss: 304.620 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1080/1194 | Loss: 295.083 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1090/1194 | Loss: 282.482 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1100/1194 | Loss: 298.131 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1110/1194 | Loss: 284.293 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1120/1194 | Loss: 301.347 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1130/1194 | Loss: 291.852 | Accuracy: 0.200\n",
      "[Epoch: 27/200] - Step: 1140/1194 | Loss: 290.053 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1150/1194 | Loss: 268.453 | Accuracy: 0.300\n",
      "[Epoch: 27/200] - Step: 1160/1194 | Loss: 293.678 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1170/1194 | Loss: 289.003 | Accuracy: 0.100\n",
      "[Epoch: 27/200] - Step: 1180/1194 | Loss: 317.550 | Accuracy: 0.000\n",
      "[Epoch: 27/200] - Step: 1190/1194 | Loss: 301.905 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 28/200] - Step: 10/1194 | Loss: 319.605 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 20/1194 | Loss: 288.496 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 30/1194 | Loss: 284.485 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 40/1194 | Loss: 252.528 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 50/1194 | Loss: 282.747 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 60/1194 | Loss: 284.887 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 70/1194 | Loss: 312.754 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 80/1194 | Loss: 297.051 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 90/1194 | Loss: 284.206 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 100/1194 | Loss: 301.091 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 110/1194 | Loss: 294.343 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 120/1194 | Loss: 312.190 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 130/1194 | Loss: 296.984 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 140/1194 | Loss: 297.088 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 150/1194 | Loss: 333.667 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 160/1194 | Loss: 297.481 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 170/1194 | Loss: 278.542 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 180/1194 | Loss: 296.672 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 190/1194 | Loss: 292.637 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 200/1194 | Loss: 302.625 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 210/1194 | Loss: 323.025 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 220/1194 | Loss: 306.224 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 230/1194 | Loss: 302.623 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 240/1194 | Loss: 295.129 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 250/1194 | Loss: 290.697 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 260/1194 | Loss: 303.363 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 270/1194 | Loss: 304.033 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 280/1194 | Loss: 299.716 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 290/1194 | Loss: 288.614 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 300/1194 | Loss: 304.907 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 310/1194 | Loss: 288.389 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 320/1194 | Loss: 307.373 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 330/1194 | Loss: 291.145 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 340/1194 | Loss: 291.956 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 350/1194 | Loss: 285.968 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 360/1194 | Loss: 287.851 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 370/1194 | Loss: 312.603 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 380/1194 | Loss: 308.819 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 390/1194 | Loss: 302.767 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 400/1194 | Loss: 287.584 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 410/1194 | Loss: 311.346 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 420/1194 | Loss: 287.476 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 430/1194 | Loss: 282.397 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 440/1194 | Loss: 329.930 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 450/1194 | Loss: 297.328 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 460/1194 | Loss: 305.784 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 470/1194 | Loss: 284.568 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 480/1194 | Loss: 306.409 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 490/1194 | Loss: 296.497 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 500/1194 | Loss: 284.185 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 510/1194 | Loss: 306.129 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 520/1194 | Loss: 307.127 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 530/1194 | Loss: 283.494 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 540/1194 | Loss: 296.269 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 550/1194 | Loss: 300.825 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 560/1194 | Loss: 291.716 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 570/1194 | Loss: 306.991 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 580/1194 | Loss: 323.612 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 590/1194 | Loss: 311.454 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 600/1194 | Loss: 298.026 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 610/1194 | Loss: 298.473 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 620/1194 | Loss: 283.011 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 630/1194 | Loss: 329.319 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 640/1194 | Loss: 297.409 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 650/1194 | Loss: 310.631 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 660/1194 | Loss: 299.817 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 670/1194 | Loss: 300.266 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 680/1194 | Loss: 304.004 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 690/1194 | Loss: 296.688 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 700/1194 | Loss: 301.412 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 710/1194 | Loss: 282.128 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 720/1194 | Loss: 317.179 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 730/1194 | Loss: 299.621 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 740/1194 | Loss: 290.767 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 750/1194 | Loss: 306.336 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 760/1194 | Loss: 293.650 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 770/1194 | Loss: 297.913 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 780/1194 | Loss: 309.768 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 790/1194 | Loss: 297.326 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 800/1194 | Loss: 299.447 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 810/1194 | Loss: 284.942 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 820/1194 | Loss: 284.645 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 830/1194 | Loss: 278.334 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 840/1194 | Loss: 301.236 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 850/1194 | Loss: 274.954 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 860/1194 | Loss: 297.236 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 870/1194 | Loss: 299.210 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 880/1194 | Loss: 306.818 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 890/1194 | Loss: 314.715 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 900/1194 | Loss: 288.955 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 910/1194 | Loss: 323.519 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 920/1194 | Loss: 300.570 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 930/1194 | Loss: 301.699 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 940/1194 | Loss: 299.616 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 950/1194 | Loss: 298.329 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 960/1194 | Loss: 286.057 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 970/1194 | Loss: 293.823 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 980/1194 | Loss: 298.763 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 990/1194 | Loss: 300.083 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1000/1194 | Loss: 300.824 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1010/1194 | Loss: 290.419 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1020/1194 | Loss: 298.752 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1030/1194 | Loss: 306.967 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1040/1194 | Loss: 303.303 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1050/1194 | Loss: 282.696 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1060/1194 | Loss: 284.659 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1070/1194 | Loss: 298.646 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1080/1194 | Loss: 295.424 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1090/1194 | Loss: 298.207 | Accuracy: 0.100\n",
      "[Epoch: 28/200] - Step: 1100/1194 | Loss: 300.354 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1110/1194 | Loss: 296.819 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1120/1194 | Loss: 307.714 | Accuracy: 0.000\n",
      "[Epoch: 28/200] - Step: 1130/1194 | Loss: 257.984 | Accuracy: 0.500\n",
      "[Epoch: 28/200] - Step: 1140/1194 | Loss: 288.818 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1150/1194 | Loss: 304.770 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1160/1194 | Loss: 292.909 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1170/1194 | Loss: 283.761 | Accuracy: 0.200\n",
      "[Epoch: 28/200] - Step: 1180/1194 | Loss: 276.825 | Accuracy: 0.300\n",
      "[Epoch: 28/200] - Step: 1190/1194 | Loss: 314.793 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 29/200] - Step: 10/1194 | Loss: 317.532 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 20/1194 | Loss: 304.542 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 30/1194 | Loss: 311.116 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 40/1194 | Loss: 290.257 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 50/1194 | Loss: 301.102 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 60/1194 | Loss: 293.176 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 70/1194 | Loss: 290.646 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 80/1194 | Loss: 330.455 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 90/1194 | Loss: 305.373 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 100/1194 | Loss: 295.095 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 110/1194 | Loss: 286.038 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 120/1194 | Loss: 295.609 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 130/1194 | Loss: 302.068 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 140/1194 | Loss: 295.775 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 150/1194 | Loss: 299.553 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 160/1194 | Loss: 296.261 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 170/1194 | Loss: 308.206 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 180/1194 | Loss: 299.369 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 190/1194 | Loss: 290.875 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 200/1194 | Loss: 301.177 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 210/1194 | Loss: 310.238 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 220/1194 | Loss: 292.519 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 230/1194 | Loss: 290.825 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 240/1194 | Loss: 296.443 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 250/1194 | Loss: 301.687 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 260/1194 | Loss: 294.672 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 270/1194 | Loss: 298.485 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 280/1194 | Loss: 295.338 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 290/1194 | Loss: 298.973 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 300/1194 | Loss: 287.539 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 310/1194 | Loss: 286.777 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 320/1194 | Loss: 306.530 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 330/1194 | Loss: 313.859 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 340/1194 | Loss: 286.081 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 350/1194 | Loss: 304.921 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 360/1194 | Loss: 291.610 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 370/1194 | Loss: 299.059 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 380/1194 | Loss: 286.666 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 390/1194 | Loss: 301.289 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 400/1194 | Loss: 298.193 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 410/1194 | Loss: 292.426 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 420/1194 | Loss: 291.261 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 430/1194 | Loss: 296.952 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 440/1194 | Loss: 302.051 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 450/1194 | Loss: 287.816 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 460/1194 | Loss: 290.313 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 470/1194 | Loss: 298.821 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 480/1194 | Loss: 308.171 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 490/1194 | Loss: 287.718 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 500/1194 | Loss: 286.102 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 510/1194 | Loss: 299.831 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 520/1194 | Loss: 278.939 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 530/1194 | Loss: 295.010 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 540/1194 | Loss: 306.885 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 550/1194 | Loss: 289.554 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 560/1194 | Loss: 294.972 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 570/1194 | Loss: 318.210 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 580/1194 | Loss: 294.392 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 590/1194 | Loss: 295.809 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 600/1194 | Loss: 293.948 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 610/1194 | Loss: 309.650 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 620/1194 | Loss: 290.036 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 630/1194 | Loss: 323.539 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 640/1194 | Loss: 295.370 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 650/1194 | Loss: 293.376 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 660/1194 | Loss: 299.658 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 670/1194 | Loss: 301.772 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 680/1194 | Loss: 277.611 | Accuracy: 0.400\n",
      "[Epoch: 29/200] - Step: 690/1194 | Loss: 295.316 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 700/1194 | Loss: 303.407 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 710/1194 | Loss: 292.235 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 720/1194 | Loss: 297.979 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 730/1194 | Loss: 297.404 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 740/1194 | Loss: 294.181 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 750/1194 | Loss: 283.116 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 760/1194 | Loss: 305.992 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 770/1194 | Loss: 299.576 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 780/1194 | Loss: 329.379 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 790/1194 | Loss: 286.090 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 800/1194 | Loss: 300.175 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 810/1194 | Loss: 322.900 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 820/1194 | Loss: 295.427 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 830/1194 | Loss: 296.636 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 840/1194 | Loss: 282.531 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 850/1194 | Loss: 285.437 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 860/1194 | Loss: 295.502 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 870/1194 | Loss: 279.468 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 880/1194 | Loss: 302.827 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 890/1194 | Loss: 317.958 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 900/1194 | Loss: 315.670 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 910/1194 | Loss: 278.710 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 920/1194 | Loss: 312.133 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 930/1194 | Loss: 293.336 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 940/1194 | Loss: 296.825 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 950/1194 | Loss: 295.691 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 960/1194 | Loss: 297.506 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 970/1194 | Loss: 297.631 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 980/1194 | Loss: 296.218 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 990/1194 | Loss: 299.493 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1000/1194 | Loss: 293.657 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1010/1194 | Loss: 288.549 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1020/1194 | Loss: 298.880 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1030/1194 | Loss: 294.698 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1040/1194 | Loss: 296.684 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1050/1194 | Loss: 309.755 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1060/1194 | Loss: 319.903 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1070/1194 | Loss: 293.348 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1080/1194 | Loss: 289.745 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1090/1194 | Loss: 298.276 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1100/1194 | Loss: 300.766 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1110/1194 | Loss: 317.141 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1120/1194 | Loss: 293.928 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1130/1194 | Loss: 284.643 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1140/1194 | Loss: 276.824 | Accuracy: 0.300\n",
      "[Epoch: 29/200] - Step: 1150/1194 | Loss: 296.373 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1160/1194 | Loss: 288.933 | Accuracy: 0.100\n",
      "[Epoch: 29/200] - Step: 1170/1194 | Loss: 316.522 | Accuracy: 0.000\n",
      "[Epoch: 29/200] - Step: 1180/1194 | Loss: 290.070 | Accuracy: 0.200\n",
      "[Epoch: 29/200] - Step: 1190/1194 | Loss: 261.663 | Accuracy: 0.500\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 30/200] - Step: 10/1194 | Loss: 305.962 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 20/1194 | Loss: 284.022 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 30/1194 | Loss: 296.626 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 40/1194 | Loss: 309.367 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 50/1194 | Loss: 342.517 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 60/1194 | Loss: 296.140 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 70/1194 | Loss: 291.618 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 80/1194 | Loss: 284.531 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 90/1194 | Loss: 306.822 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 100/1194 | Loss: 296.125 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 110/1194 | Loss: 254.809 | Accuracy: 0.500\n",
      "[Epoch: 30/200] - Step: 120/1194 | Loss: 294.027 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 130/1194 | Loss: 309.819 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 140/1194 | Loss: 287.994 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 150/1194 | Loss: 289.198 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 160/1194 | Loss: 307.076 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 170/1194 | Loss: 298.674 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 180/1194 | Loss: 291.522 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 190/1194 | Loss: 297.542 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 200/1194 | Loss: 304.988 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 210/1194 | Loss: 315.866 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 220/1194 | Loss: 278.008 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 230/1194 | Loss: 302.310 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 240/1194 | Loss: 288.340 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 250/1194 | Loss: 301.896 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 260/1194 | Loss: 324.263 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 270/1194 | Loss: 294.313 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 280/1194 | Loss: 297.129 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 290/1194 | Loss: 307.939 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 300/1194 | Loss: 290.144 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 310/1194 | Loss: 304.516 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 320/1194 | Loss: 302.666 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 330/1194 | Loss: 294.228 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 340/1194 | Loss: 310.547 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 350/1194 | Loss: 297.521 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 360/1194 | Loss: 297.288 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 370/1194 | Loss: 294.278 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 380/1194 | Loss: 301.814 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 390/1194 | Loss: 299.723 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 400/1194 | Loss: 278.126 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 410/1194 | Loss: 309.882 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 420/1194 | Loss: 284.748 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 430/1194 | Loss: 297.929 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 440/1194 | Loss: 306.458 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 450/1194 | Loss: 272.621 | Accuracy: 0.400\n",
      "[Epoch: 30/200] - Step: 460/1194 | Loss: 306.772 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 470/1194 | Loss: 293.601 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 480/1194 | Loss: 285.485 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 490/1194 | Loss: 300.579 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 500/1194 | Loss: 309.880 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 510/1194 | Loss: 281.158 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 520/1194 | Loss: 280.362 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 530/1194 | Loss: 288.655 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 540/1194 | Loss: 305.362 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 550/1194 | Loss: 288.619 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 560/1194 | Loss: 301.893 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 570/1194 | Loss: 293.820 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 580/1194 | Loss: 287.597 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 590/1194 | Loss: 301.784 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 600/1194 | Loss: 280.436 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 610/1194 | Loss: 298.470 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 620/1194 | Loss: 284.224 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 630/1194 | Loss: 301.046 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 640/1194 | Loss: 315.778 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 650/1194 | Loss: 310.603 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 660/1194 | Loss: 280.142 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 670/1194 | Loss: 296.263 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 680/1194 | Loss: 307.904 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 690/1194 | Loss: 306.424 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 700/1194 | Loss: 301.887 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 710/1194 | Loss: 298.897 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 720/1194 | Loss: 319.573 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 730/1194 | Loss: 299.653 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 740/1194 | Loss: 303.136 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 750/1194 | Loss: 294.522 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 760/1194 | Loss: 314.786 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 770/1194 | Loss: 304.041 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 780/1194 | Loss: 298.087 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 790/1194 | Loss: 290.945 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 800/1194 | Loss: 309.569 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 810/1194 | Loss: 294.129 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 820/1194 | Loss: 308.813 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 830/1194 | Loss: 301.591 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 840/1194 | Loss: 281.164 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 850/1194 | Loss: 298.652 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 860/1194 | Loss: 299.612 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 870/1194 | Loss: 307.571 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 880/1194 | Loss: 302.738 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 890/1194 | Loss: 291.997 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 900/1194 | Loss: 294.974 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 910/1194 | Loss: 302.870 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 920/1194 | Loss: 287.572 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 930/1194 | Loss: 300.607 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 940/1194 | Loss: 281.602 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 950/1194 | Loss: 285.593 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 960/1194 | Loss: 301.946 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 970/1194 | Loss: 293.680 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 980/1194 | Loss: 301.044 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 990/1194 | Loss: 274.762 | Accuracy: 0.300\n",
      "[Epoch: 30/200] - Step: 1000/1194 | Loss: 305.115 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1010/1194 | Loss: 311.565 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1020/1194 | Loss: 284.212 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1030/1194 | Loss: 296.650 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1040/1194 | Loss: 297.036 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1050/1194 | Loss: 300.781 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1060/1194 | Loss: 299.856 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1070/1194 | Loss: 316.068 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1080/1194 | Loss: 304.141 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1090/1194 | Loss: 291.280 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1100/1194 | Loss: 299.393 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1110/1194 | Loss: 288.970 | Accuracy: 0.000\n",
      "[Epoch: 30/200] - Step: 1120/1194 | Loss: 298.636 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1130/1194 | Loss: 298.045 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1140/1194 | Loss: 299.178 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1150/1194 | Loss: 290.213 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1160/1194 | Loss: 293.930 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1170/1194 | Loss: 302.423 | Accuracy: 0.100\n",
      "[Epoch: 30/200] - Step: 1180/1194 | Loss: 276.624 | Accuracy: 0.200\n",
      "[Epoch: 30/200] - Step: 1190/1194 | Loss: 300.282 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 31/200] - Step: 10/1194 | Loss: 317.605 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 20/1194 | Loss: 302.879 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 30/1194 | Loss: 293.141 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 40/1194 | Loss: 295.474 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 50/1194 | Loss: 300.980 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 60/1194 | Loss: 305.060 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 70/1194 | Loss: 305.264 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 80/1194 | Loss: 293.024 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 90/1194 | Loss: 293.907 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 100/1194 | Loss: 285.178 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 110/1194 | Loss: 299.509 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 120/1194 | Loss: 299.371 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 130/1194 | Loss: 298.481 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 140/1194 | Loss: 277.492 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 150/1194 | Loss: 286.175 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 160/1194 | Loss: 291.915 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 170/1194 | Loss: 286.539 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 180/1194 | Loss: 313.233 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 190/1194 | Loss: 304.494 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 200/1194 | Loss: 294.163 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 210/1194 | Loss: 291.246 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 220/1194 | Loss: 337.057 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 230/1194 | Loss: 334.147 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 240/1194 | Loss: 288.911 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 250/1194 | Loss: 291.198 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 260/1194 | Loss: 273.700 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 270/1194 | Loss: 313.187 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 280/1194 | Loss: 299.195 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 290/1194 | Loss: 284.171 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 300/1194 | Loss: 291.669 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 310/1194 | Loss: 313.853 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 320/1194 | Loss: 275.293 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 330/1194 | Loss: 309.931 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 340/1194 | Loss: 298.260 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 350/1194 | Loss: 301.199 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 360/1194 | Loss: 296.072 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 370/1194 | Loss: 295.087 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 380/1194 | Loss: 297.535 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 390/1194 | Loss: 271.599 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 400/1194 | Loss: 298.419 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 410/1194 | Loss: 289.645 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 420/1194 | Loss: 298.466 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 430/1194 | Loss: 288.810 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 440/1194 | Loss: 286.945 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 450/1194 | Loss: 304.491 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 460/1194 | Loss: 291.215 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 470/1194 | Loss: 303.783 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 480/1194 | Loss: 306.954 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 490/1194 | Loss: 298.639 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 500/1194 | Loss: 292.158 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 510/1194 | Loss: 266.323 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 520/1194 | Loss: 267.237 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 530/1194 | Loss: 293.661 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 540/1194 | Loss: 295.115 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 550/1194 | Loss: 292.235 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 560/1194 | Loss: 295.210 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 570/1194 | Loss: 282.402 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 580/1194 | Loss: 277.646 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 590/1194 | Loss: 305.439 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 600/1194 | Loss: 281.457 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 610/1194 | Loss: 304.359 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 620/1194 | Loss: 313.717 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 630/1194 | Loss: 289.824 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 640/1194 | Loss: 314.720 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 650/1194 | Loss: 316.442 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 660/1194 | Loss: 315.254 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 670/1194 | Loss: 287.547 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 680/1194 | Loss: 276.391 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 690/1194 | Loss: 296.926 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 700/1194 | Loss: 311.220 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 710/1194 | Loss: 295.615 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 720/1194 | Loss: 286.034 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 730/1194 | Loss: 297.671 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 740/1194 | Loss: 292.788 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 750/1194 | Loss: 296.219 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 760/1194 | Loss: 281.094 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 770/1194 | Loss: 304.270 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 780/1194 | Loss: 292.516 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 790/1194 | Loss: 306.918 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 800/1194 | Loss: 302.612 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 810/1194 | Loss: 297.994 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 820/1194 | Loss: 312.017 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 830/1194 | Loss: 294.660 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 840/1194 | Loss: 298.060 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 850/1194 | Loss: 292.728 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 860/1194 | Loss: 304.865 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 870/1194 | Loss: 299.925 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 880/1194 | Loss: 291.201 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 890/1194 | Loss: 307.576 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 900/1194 | Loss: 297.999 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 910/1194 | Loss: 300.790 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 920/1194 | Loss: 301.900 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 930/1194 | Loss: 288.307 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 940/1194 | Loss: 283.400 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 950/1194 | Loss: 299.736 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 960/1194 | Loss: 288.393 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 970/1194 | Loss: 308.197 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 980/1194 | Loss: 293.190 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 990/1194 | Loss: 329.356 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1000/1194 | Loss: 302.700 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1010/1194 | Loss: 305.233 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1020/1194 | Loss: 303.483 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1030/1194 | Loss: 311.522 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1040/1194 | Loss: 319.577 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1050/1194 | Loss: 296.215 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1060/1194 | Loss: 297.625 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1070/1194 | Loss: 305.298 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1080/1194 | Loss: 284.061 | Accuracy: 0.300\n",
      "[Epoch: 31/200] - Step: 1090/1194 | Loss: 304.271 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1100/1194 | Loss: 295.838 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1110/1194 | Loss: 318.784 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1120/1194 | Loss: 300.562 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1130/1194 | Loss: 311.458 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1140/1194 | Loss: 294.904 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1150/1194 | Loss: 284.938 | Accuracy: 0.400\n",
      "[Epoch: 31/200] - Step: 1160/1194 | Loss: 298.066 | Accuracy: 0.100\n",
      "[Epoch: 31/200] - Step: 1170/1194 | Loss: 301.930 | Accuracy: 0.000\n",
      "[Epoch: 31/200] - Step: 1180/1194 | Loss: 276.634 | Accuracy: 0.200\n",
      "[Epoch: 31/200] - Step: 1190/1194 | Loss: 296.297 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 32/200] - Step: 10/1194 | Loss: 299.206 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 20/1194 | Loss: 296.701 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 30/1194 | Loss: 287.454 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 40/1194 | Loss: 287.082 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 50/1194 | Loss: 272.903 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 60/1194 | Loss: 305.158 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 70/1194 | Loss: 293.644 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 80/1194 | Loss: 303.439 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 90/1194 | Loss: 305.759 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 100/1194 | Loss: 299.693 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 110/1194 | Loss: 315.362 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 120/1194 | Loss: 323.325 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 130/1194 | Loss: 299.729 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 140/1194 | Loss: 294.235 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 150/1194 | Loss: 301.689 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 160/1194 | Loss: 304.368 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 170/1194 | Loss: 308.350 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 180/1194 | Loss: 290.863 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 190/1194 | Loss: 297.606 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 200/1194 | Loss: 281.628 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 210/1194 | Loss: 286.401 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 220/1194 | Loss: 283.658 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 230/1194 | Loss: 315.305 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 240/1194 | Loss: 307.090 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 250/1194 | Loss: 302.645 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 260/1194 | Loss: 296.755 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 270/1194 | Loss: 290.268 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 280/1194 | Loss: 304.098 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 290/1194 | Loss: 308.821 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 300/1194 | Loss: 297.124 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 310/1194 | Loss: 288.591 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 320/1194 | Loss: 282.834 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 330/1194 | Loss: 270.498 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 340/1194 | Loss: 306.244 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 350/1194 | Loss: 288.727 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 360/1194 | Loss: 302.668 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 370/1194 | Loss: 285.168 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 380/1194 | Loss: 294.309 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 390/1194 | Loss: 287.942 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 400/1194 | Loss: 289.517 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 410/1194 | Loss: 277.755 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 420/1194 | Loss: 301.045 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 430/1194 | Loss: 257.569 | Accuracy: 0.400\n",
      "[Epoch: 32/200] - Step: 440/1194 | Loss: 326.523 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 450/1194 | Loss: 297.777 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 460/1194 | Loss: 302.598 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 470/1194 | Loss: 300.611 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 480/1194 | Loss: 294.497 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 490/1194 | Loss: 286.527 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 500/1194 | Loss: 354.819 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 510/1194 | Loss: 314.901 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 520/1194 | Loss: 296.311 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 530/1194 | Loss: 282.732 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 540/1194 | Loss: 303.162 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 550/1194 | Loss: 313.366 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 560/1194 | Loss: 272.632 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 570/1194 | Loss: 292.738 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 580/1194 | Loss: 304.727 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 590/1194 | Loss: 308.902 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 600/1194 | Loss: 295.759 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 610/1194 | Loss: 295.169 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 620/1194 | Loss: 285.785 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 630/1194 | Loss: 298.828 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 640/1194 | Loss: 304.755 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 650/1194 | Loss: 300.174 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 660/1194 | Loss: 301.625 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 670/1194 | Loss: 299.747 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 680/1194 | Loss: 297.098 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 690/1194 | Loss: 295.426 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 700/1194 | Loss: 306.741 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 710/1194 | Loss: 299.047 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 720/1194 | Loss: 290.497 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 730/1194 | Loss: 302.885 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 740/1194 | Loss: 287.339 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 750/1194 | Loss: 336.828 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 760/1194 | Loss: 307.413 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 770/1194 | Loss: 307.784 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 780/1194 | Loss: 328.504 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 790/1194 | Loss: 304.552 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 800/1194 | Loss: 280.774 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 810/1194 | Loss: 294.454 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 820/1194 | Loss: 295.499 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 830/1194 | Loss: 293.827 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 840/1194 | Loss: 304.524 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 850/1194 | Loss: 279.660 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 860/1194 | Loss: 286.301 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 870/1194 | Loss: 290.262 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 880/1194 | Loss: 302.362 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 890/1194 | Loss: 298.093 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 900/1194 | Loss: 289.876 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 910/1194 | Loss: 301.961 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 920/1194 | Loss: 305.739 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 930/1194 | Loss: 305.985 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 940/1194 | Loss: 286.293 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 950/1194 | Loss: 298.038 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 960/1194 | Loss: 292.983 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 970/1194 | Loss: 299.264 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 980/1194 | Loss: 284.732 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 990/1194 | Loss: 289.013 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1000/1194 | Loss: 290.647 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1010/1194 | Loss: 322.979 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1020/1194 | Loss: 295.624 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1030/1194 | Loss: 305.525 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1040/1194 | Loss: 305.348 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1050/1194 | Loss: 290.892 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1060/1194 | Loss: 298.534 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1070/1194 | Loss: 297.981 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1080/1194 | Loss: 278.506 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1090/1194 | Loss: 315.953 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1100/1194 | Loss: 303.731 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1110/1194 | Loss: 288.162 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1120/1194 | Loss: 281.718 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1130/1194 | Loss: 293.182 | Accuracy: 0.300\n",
      "[Epoch: 32/200] - Step: 1140/1194 | Loss: 293.734 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1150/1194 | Loss: 306.168 | Accuracy: 0.000\n",
      "[Epoch: 32/200] - Step: 1160/1194 | Loss: 281.093 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1170/1194 | Loss: 293.957 | Accuracy: 0.100\n",
      "[Epoch: 32/200] - Step: 1180/1194 | Loss: 284.728 | Accuracy: 0.200\n",
      "[Epoch: 32/200] - Step: 1190/1194 | Loss: 329.657 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 33/200] - Step: 10/1194 | Loss: 298.812 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 20/1194 | Loss: 313.476 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 30/1194 | Loss: 292.661 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 40/1194 | Loss: 296.032 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 50/1194 | Loss: 284.212 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 60/1194 | Loss: 296.091 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 70/1194 | Loss: 293.508 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 80/1194 | Loss: 282.366 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 90/1194 | Loss: 303.724 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 100/1194 | Loss: 295.841 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 110/1194 | Loss: 312.393 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 120/1194 | Loss: 280.693 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 130/1194 | Loss: 317.477 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 140/1194 | Loss: 297.481 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 150/1194 | Loss: 303.387 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 160/1194 | Loss: 304.840 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 170/1194 | Loss: 288.434 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 180/1194 | Loss: 278.955 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 190/1194 | Loss: 302.786 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 200/1194 | Loss: 292.037 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 210/1194 | Loss: 291.712 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 220/1194 | Loss: 318.446 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 230/1194 | Loss: 281.157 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 240/1194 | Loss: 324.837 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 250/1194 | Loss: 294.546 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 260/1194 | Loss: 294.451 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 270/1194 | Loss: 285.351 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 280/1194 | Loss: 319.190 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 290/1194 | Loss: 284.995 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 300/1194 | Loss: 284.618 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 310/1194 | Loss: 280.014 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 320/1194 | Loss: 306.432 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 330/1194 | Loss: 296.852 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 340/1194 | Loss: 322.978 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 350/1194 | Loss: 292.460 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 360/1194 | Loss: 284.436 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 370/1194 | Loss: 294.388 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 380/1194 | Loss: 293.335 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 390/1194 | Loss: 294.939 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 400/1194 | Loss: 305.349 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 410/1194 | Loss: 301.252 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 420/1194 | Loss: 290.510 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 430/1194 | Loss: 295.764 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 440/1194 | Loss: 288.526 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 450/1194 | Loss: 314.772 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 460/1194 | Loss: 303.969 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 470/1194 | Loss: 299.147 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 480/1194 | Loss: 288.124 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 490/1194 | Loss: 293.718 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 500/1194 | Loss: 293.619 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 510/1194 | Loss: 296.783 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 520/1194 | Loss: 306.247 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 530/1194 | Loss: 307.659 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 540/1194 | Loss: 299.347 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 550/1194 | Loss: 295.625 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 560/1194 | Loss: 289.722 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 570/1194 | Loss: 293.314 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 580/1194 | Loss: 308.529 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 590/1194 | Loss: 304.020 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 600/1194 | Loss: 303.090 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 610/1194 | Loss: 312.218 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 620/1194 | Loss: 297.328 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 630/1194 | Loss: 308.918 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 640/1194 | Loss: 297.336 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 650/1194 | Loss: 285.589 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 660/1194 | Loss: 305.597 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 670/1194 | Loss: 287.444 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 680/1194 | Loss: 306.437 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 690/1194 | Loss: 291.593 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 700/1194 | Loss: 294.555 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 710/1194 | Loss: 290.526 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 720/1194 | Loss: 294.646 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 730/1194 | Loss: 295.587 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 740/1194 | Loss: 277.412 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 750/1194 | Loss: 342.476 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 760/1194 | Loss: 303.670 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 770/1194 | Loss: 293.952 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 780/1194 | Loss: 292.509 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 790/1194 | Loss: 301.892 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 800/1194 | Loss: 294.077 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 810/1194 | Loss: 305.292 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 820/1194 | Loss: 299.119 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 830/1194 | Loss: 291.144 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 840/1194 | Loss: 285.465 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 850/1194 | Loss: 291.673 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 860/1194 | Loss: 310.698 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 870/1194 | Loss: 299.574 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 880/1194 | Loss: 272.024 | Accuracy: 0.400\n",
      "[Epoch: 33/200] - Step: 890/1194 | Loss: 289.115 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 900/1194 | Loss: 308.394 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 910/1194 | Loss: 327.893 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 920/1194 | Loss: 294.091 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 930/1194 | Loss: 289.190 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 940/1194 | Loss: 297.852 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 950/1194 | Loss: 292.860 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 960/1194 | Loss: 274.164 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 970/1194 | Loss: 301.529 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 980/1194 | Loss: 322.196 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 990/1194 | Loss: 286.381 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1000/1194 | Loss: 302.704 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1010/1194 | Loss: 291.849 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1020/1194 | Loss: 297.030 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1030/1194 | Loss: 290.643 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1040/1194 | Loss: 285.296 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1050/1194 | Loss: 283.051 | Accuracy: 0.200\n",
      "[Epoch: 33/200] - Step: 1060/1194 | Loss: 287.809 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1070/1194 | Loss: 275.717 | Accuracy: 0.300\n",
      "[Epoch: 33/200] - Step: 1080/1194 | Loss: 327.031 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 1090/1194 | Loss: 306.923 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 1100/1194 | Loss: 310.544 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 1110/1194 | Loss: 313.924 | Accuracy: 0.000\n",
      "[Epoch: 33/200] - Step: 1120/1194 | Loss: 287.968 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1130/1194 | Loss: 290.807 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1140/1194 | Loss: 295.514 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1150/1194 | Loss: 294.123 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1160/1194 | Loss: 299.583 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1170/1194 | Loss: 297.960 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1180/1194 | Loss: 296.125 | Accuracy: 0.100\n",
      "[Epoch: 33/200] - Step: 1190/1194 | Loss: 314.097 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 34/200] - Step: 10/1194 | Loss: 303.819 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 20/1194 | Loss: 301.826 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 30/1194 | Loss: 279.524 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 40/1194 | Loss: 305.768 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 50/1194 | Loss: 271.025 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 60/1194 | Loss: 290.321 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 70/1194 | Loss: 294.413 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 80/1194 | Loss: 280.292 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 90/1194 | Loss: 252.433 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 100/1194 | Loss: 300.281 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 110/1194 | Loss: 312.316 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 120/1194 | Loss: 301.068 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 130/1194 | Loss: 305.866 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 140/1194 | Loss: 306.658 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 150/1194 | Loss: 310.070 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 160/1194 | Loss: 306.649 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 170/1194 | Loss: 293.110 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 180/1194 | Loss: 297.608 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 190/1194 | Loss: 304.863 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 200/1194 | Loss: 290.547 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 210/1194 | Loss: 301.088 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 220/1194 | Loss: 282.505 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 230/1194 | Loss: 265.973 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 240/1194 | Loss: 282.036 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 250/1194 | Loss: 303.895 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 260/1194 | Loss: 296.781 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 270/1194 | Loss: 319.598 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 280/1194 | Loss: 294.545 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 290/1194 | Loss: 285.834 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 300/1194 | Loss: 301.074 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 310/1194 | Loss: 304.399 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 320/1194 | Loss: 302.066 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 330/1194 | Loss: 291.080 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 340/1194 | Loss: 285.822 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 350/1194 | Loss: 291.599 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 360/1194 | Loss: 293.036 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 370/1194 | Loss: 277.082 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 380/1194 | Loss: 299.773 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 390/1194 | Loss: 306.331 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 400/1194 | Loss: 318.968 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 410/1194 | Loss: 304.056 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 420/1194 | Loss: 305.704 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 430/1194 | Loss: 289.506 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 440/1194 | Loss: 298.866 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 450/1194 | Loss: 295.055 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 460/1194 | Loss: 307.043 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 470/1194 | Loss: 306.207 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 480/1194 | Loss: 303.408 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 490/1194 | Loss: 299.971 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 500/1194 | Loss: 293.157 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 510/1194 | Loss: 298.072 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 520/1194 | Loss: 307.428 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 530/1194 | Loss: 300.390 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 540/1194 | Loss: 307.412 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 550/1194 | Loss: 300.846 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 560/1194 | Loss: 294.379 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 570/1194 | Loss: 305.327 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 580/1194 | Loss: 284.882 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 590/1194 | Loss: 278.994 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 600/1194 | Loss: 288.917 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 610/1194 | Loss: 316.339 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 620/1194 | Loss: 278.284 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 630/1194 | Loss: 319.932 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 640/1194 | Loss: 289.090 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 650/1194 | Loss: 287.052 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 660/1194 | Loss: 272.328 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 670/1194 | Loss: 302.531 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 680/1194 | Loss: 299.611 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 690/1194 | Loss: 333.490 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 700/1194 | Loss: 291.238 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 710/1194 | Loss: 285.109 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 720/1194 | Loss: 293.283 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 730/1194 | Loss: 287.913 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 740/1194 | Loss: 327.526 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 750/1194 | Loss: 287.049 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 760/1194 | Loss: 295.104 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 770/1194 | Loss: 300.427 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 780/1194 | Loss: 291.867 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 790/1194 | Loss: 298.014 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 800/1194 | Loss: 284.084 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 810/1194 | Loss: 288.450 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 820/1194 | Loss: 282.606 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 830/1194 | Loss: 310.291 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 840/1194 | Loss: 296.904 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 850/1194 | Loss: 307.365 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 860/1194 | Loss: 309.011 | Accuracy: 0.300\n",
      "[Epoch: 34/200] - Step: 870/1194 | Loss: 302.715 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 880/1194 | Loss: 301.785 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 890/1194 | Loss: 304.003 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 900/1194 | Loss: 296.112 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 910/1194 | Loss: 297.480 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 920/1194 | Loss: 299.316 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 930/1194 | Loss: 306.430 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 940/1194 | Loss: 305.492 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 950/1194 | Loss: 290.537 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 960/1194 | Loss: 305.537 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 970/1194 | Loss: 298.499 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 980/1194 | Loss: 294.038 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 990/1194 | Loss: 270.256 | Accuracy: 0.400\n",
      "[Epoch: 34/200] - Step: 1000/1194 | Loss: 289.656 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1010/1194 | Loss: 310.088 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1020/1194 | Loss: 316.752 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1030/1194 | Loss: 293.217 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1040/1194 | Loss: 300.066 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1050/1194 | Loss: 319.961 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1060/1194 | Loss: 296.312 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1070/1194 | Loss: 293.024 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1080/1194 | Loss: 317.451 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1090/1194 | Loss: 298.045 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1100/1194 | Loss: 298.702 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1110/1194 | Loss: 289.844 | Accuracy: 0.200\n",
      "[Epoch: 34/200] - Step: 1120/1194 | Loss: 297.243 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1130/1194 | Loss: 285.395 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1140/1194 | Loss: 297.893 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1150/1194 | Loss: 307.119 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1160/1194 | Loss: 303.043 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1170/1194 | Loss: 296.623 | Accuracy: 0.100\n",
      "[Epoch: 34/200] - Step: 1180/1194 | Loss: 307.973 | Accuracy: 0.000\n",
      "[Epoch: 34/200] - Step: 1190/1194 | Loss: 292.795 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 35/200] - Step: 10/1194 | Loss: 302.028 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 20/1194 | Loss: 297.706 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 30/1194 | Loss: 288.132 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 40/1194 | Loss: 288.598 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 50/1194 | Loss: 286.404 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 60/1194 | Loss: 291.973 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 70/1194 | Loss: 286.385 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 80/1194 | Loss: 289.028 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 90/1194 | Loss: 294.548 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 100/1194 | Loss: 308.734 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 110/1194 | Loss: 302.270 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 120/1194 | Loss: 293.335 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 130/1194 | Loss: 301.294 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 140/1194 | Loss: 277.908 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 150/1194 | Loss: 295.354 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 160/1194 | Loss: 285.814 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 170/1194 | Loss: 292.996 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 180/1194 | Loss: 298.097 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 190/1194 | Loss: 304.316 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 200/1194 | Loss: 302.875 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 210/1194 | Loss: 298.044 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 220/1194 | Loss: 297.957 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 230/1194 | Loss: 306.954 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 240/1194 | Loss: 288.199 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 250/1194 | Loss: 275.834 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 260/1194 | Loss: 312.219 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 270/1194 | Loss: 300.618 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 280/1194 | Loss: 291.223 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 290/1194 | Loss: 305.419 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 300/1194 | Loss: 298.354 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 310/1194 | Loss: 305.476 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 320/1194 | Loss: 291.979 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 330/1194 | Loss: 307.431 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 340/1194 | Loss: 308.808 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 350/1194 | Loss: 293.928 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 360/1194 | Loss: 297.839 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 370/1194 | Loss: 281.002 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 380/1194 | Loss: 290.473 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 390/1194 | Loss: 306.265 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 400/1194 | Loss: 290.280 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 410/1194 | Loss: 276.709 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 420/1194 | Loss: 310.040 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 430/1194 | Loss: 273.025 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 440/1194 | Loss: 308.585 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 450/1194 | Loss: 300.145 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 460/1194 | Loss: 297.011 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 470/1194 | Loss: 295.283 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 480/1194 | Loss: 297.046 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 490/1194 | Loss: 292.409 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 500/1194 | Loss: 292.568 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 510/1194 | Loss: 288.668 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 520/1194 | Loss: 281.129 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 530/1194 | Loss: 294.219 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 540/1194 | Loss: 291.002 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 550/1194 | Loss: 295.042 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 560/1194 | Loss: 278.069 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 570/1194 | Loss: 310.086 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 580/1194 | Loss: 307.302 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 590/1194 | Loss: 287.065 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 600/1194 | Loss: 296.167 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 610/1194 | Loss: 288.911 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 620/1194 | Loss: 295.689 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 630/1194 | Loss: 299.640 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 640/1194 | Loss: 308.209 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 650/1194 | Loss: 295.685 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 660/1194 | Loss: 300.759 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 670/1194 | Loss: 300.600 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 680/1194 | Loss: 302.913 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 690/1194 | Loss: 303.106 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 700/1194 | Loss: 284.228 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 710/1194 | Loss: 293.818 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 720/1194 | Loss: 286.273 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 730/1194 | Loss: 298.833 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 740/1194 | Loss: 303.983 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 750/1194 | Loss: 295.056 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 760/1194 | Loss: 321.738 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 770/1194 | Loss: 300.752 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 780/1194 | Loss: 297.343 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 790/1194 | Loss: 310.280 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 800/1194 | Loss: 303.949 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 810/1194 | Loss: 353.021 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 820/1194 | Loss: 294.467 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 830/1194 | Loss: 297.006 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 840/1194 | Loss: 310.953 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 850/1194 | Loss: 300.810 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 860/1194 | Loss: 306.004 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 870/1194 | Loss: 295.056 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 880/1194 | Loss: 296.613 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 890/1194 | Loss: 294.402 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 900/1194 | Loss: 305.159 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 910/1194 | Loss: 297.907 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 920/1194 | Loss: 294.851 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 930/1194 | Loss: 300.655 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 940/1194 | Loss: 301.640 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 950/1194 | Loss: 292.589 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 960/1194 | Loss: 286.823 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 970/1194 | Loss: 299.810 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 980/1194 | Loss: 287.554 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 990/1194 | Loss: 292.799 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1000/1194 | Loss: 293.900 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1010/1194 | Loss: 298.047 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1020/1194 | Loss: 293.102 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1030/1194 | Loss: 298.127 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1040/1194 | Loss: 291.507 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1050/1194 | Loss: 284.303 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1060/1194 | Loss: 301.783 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1070/1194 | Loss: 321.777 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1080/1194 | Loss: 299.559 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1090/1194 | Loss: 294.750 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1100/1194 | Loss: 330.136 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1110/1194 | Loss: 270.418 | Accuracy: 0.300\n",
      "[Epoch: 35/200] - Step: 1120/1194 | Loss: 290.805 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1130/1194 | Loss: 333.854 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1140/1194 | Loss: 300.459 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1150/1194 | Loss: 290.708 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1160/1194 | Loss: 293.757 | Accuracy: 0.200\n",
      "[Epoch: 35/200] - Step: 1170/1194 | Loss: 293.892 | Accuracy: 0.100\n",
      "[Epoch: 35/200] - Step: 1180/1194 | Loss: 319.012 | Accuracy: 0.000\n",
      "[Epoch: 35/200] - Step: 1190/1194 | Loss: 306.564 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 36/200] - Step: 10/1194 | Loss: 293.983 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 20/1194 | Loss: 289.243 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 30/1194 | Loss: 295.877 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 40/1194 | Loss: 307.615 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 50/1194 | Loss: 278.486 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 60/1194 | Loss: 296.959 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 70/1194 | Loss: 312.881 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 80/1194 | Loss: 299.691 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 90/1194 | Loss: 298.400 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 100/1194 | Loss: 285.575 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 110/1194 | Loss: 303.908 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 120/1194 | Loss: 297.362 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 130/1194 | Loss: 307.808 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 140/1194 | Loss: 291.846 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 150/1194 | Loss: 274.938 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 160/1194 | Loss: 286.887 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 170/1194 | Loss: 289.335 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 180/1194 | Loss: 304.868 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 190/1194 | Loss: 278.430 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 200/1194 | Loss: 300.917 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 210/1194 | Loss: 285.686 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 220/1194 | Loss: 300.823 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 230/1194 | Loss: 282.189 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 240/1194 | Loss: 304.432 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 250/1194 | Loss: 288.486 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 260/1194 | Loss: 307.910 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 270/1194 | Loss: 295.259 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 280/1194 | Loss: 308.189 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 290/1194 | Loss: 285.349 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 300/1194 | Loss: 275.467 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 310/1194 | Loss: 307.589 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 320/1194 | Loss: 279.151 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 330/1194 | Loss: 286.995 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 340/1194 | Loss: 301.455 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 350/1194 | Loss: 295.399 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 360/1194 | Loss: 299.201 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 370/1194 | Loss: 275.471 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 380/1194 | Loss: 306.056 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 390/1194 | Loss: 290.594 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 400/1194 | Loss: 297.251 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 410/1194 | Loss: 280.310 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 420/1194 | Loss: 280.513 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 430/1194 | Loss: 299.644 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 440/1194 | Loss: 299.700 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 450/1194 | Loss: 304.791 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 460/1194 | Loss: 303.330 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 470/1194 | Loss: 313.686 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 480/1194 | Loss: 280.048 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 490/1194 | Loss: 306.971 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 500/1194 | Loss: 293.632 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 510/1194 | Loss: 297.428 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 520/1194 | Loss: 301.565 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 530/1194 | Loss: 303.328 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 540/1194 | Loss: 304.670 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 550/1194 | Loss: 292.671 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 560/1194 | Loss: 314.142 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 570/1194 | Loss: 289.515 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 580/1194 | Loss: 315.217 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 590/1194 | Loss: 293.742 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 600/1194 | Loss: 301.159 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 610/1194 | Loss: 295.926 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 620/1194 | Loss: 298.631 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 630/1194 | Loss: 307.049 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 640/1194 | Loss: 275.276 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 650/1194 | Loss: 305.893 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 660/1194 | Loss: 298.939 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 670/1194 | Loss: 294.354 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 680/1194 | Loss: 307.056 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 690/1194 | Loss: 298.256 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 700/1194 | Loss: 303.801 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 710/1194 | Loss: 292.780 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 720/1194 | Loss: 288.025 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 730/1194 | Loss: 293.829 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 740/1194 | Loss: 298.156 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 750/1194 | Loss: 281.507 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 760/1194 | Loss: 283.456 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 770/1194 | Loss: 297.129 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 780/1194 | Loss: 290.429 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 790/1194 | Loss: 287.917 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 800/1194 | Loss: 290.012 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 810/1194 | Loss: 316.811 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 820/1194 | Loss: 290.716 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 830/1194 | Loss: 310.916 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 840/1194 | Loss: 308.399 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 850/1194 | Loss: 289.822 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 860/1194 | Loss: 300.466 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 870/1194 | Loss: 313.663 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 880/1194 | Loss: 310.386 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 890/1194 | Loss: 293.324 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 900/1194 | Loss: 285.363 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 910/1194 | Loss: 300.066 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 920/1194 | Loss: 303.543 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 930/1194 | Loss: 309.762 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 940/1194 | Loss: 284.716 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 950/1194 | Loss: 292.559 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 960/1194 | Loss: 290.418 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 970/1194 | Loss: 319.622 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 980/1194 | Loss: 302.976 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 990/1194 | Loss: 293.820 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1000/1194 | Loss: 300.108 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 1010/1194 | Loss: 297.613 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 1020/1194 | Loss: 284.656 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1030/1194 | Loss: 291.162 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1040/1194 | Loss: 289.146 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1050/1194 | Loss: 300.419 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1060/1194 | Loss: 300.227 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 1070/1194 | Loss: 276.112 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1080/1194 | Loss: 301.892 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1090/1194 | Loss: 274.658 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1100/1194 | Loss: 299.214 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1110/1194 | Loss: 307.403 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1120/1194 | Loss: 307.818 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1130/1194 | Loss: 303.504 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1140/1194 | Loss: 292.769 | Accuracy: 0.300\n",
      "[Epoch: 36/200] - Step: 1150/1194 | Loss: 314.609 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1160/1194 | Loss: 313.410 | Accuracy: 0.000\n",
      "[Epoch: 36/200] - Step: 1170/1194 | Loss: 315.952 | Accuracy: 0.200\n",
      "[Epoch: 36/200] - Step: 1180/1194 | Loss: 324.067 | Accuracy: 0.100\n",
      "[Epoch: 36/200] - Step: 1190/1194 | Loss: 314.031 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 37/200] - Step: 10/1194 | Loss: 302.275 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 20/1194 | Loss: 285.885 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 30/1194 | Loss: 302.414 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 40/1194 | Loss: 279.170 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 50/1194 | Loss: 311.995 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 60/1194 | Loss: 317.675 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 70/1194 | Loss: 294.038 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 80/1194 | Loss: 291.935 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 90/1194 | Loss: 284.151 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 100/1194 | Loss: 289.848 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 110/1194 | Loss: 305.971 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 120/1194 | Loss: 289.556 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 130/1194 | Loss: 291.454 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 140/1194 | Loss: 292.984 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 150/1194 | Loss: 279.631 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 160/1194 | Loss: 308.446 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 170/1194 | Loss: 307.062 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 180/1194 | Loss: 302.211 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 190/1194 | Loss: 292.139 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 200/1194 | Loss: 302.849 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 210/1194 | Loss: 315.784 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 220/1194 | Loss: 296.205 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 230/1194 | Loss: 298.571 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 240/1194 | Loss: 300.915 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 250/1194 | Loss: 285.284 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 260/1194 | Loss: 298.575 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 270/1194 | Loss: 291.468 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 280/1194 | Loss: 302.098 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 290/1194 | Loss: 274.585 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 300/1194 | Loss: 282.162 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 310/1194 | Loss: 295.628 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 320/1194 | Loss: 275.618 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 330/1194 | Loss: 305.084 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 340/1194 | Loss: 279.432 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 350/1194 | Loss: 310.683 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 360/1194 | Loss: 287.825 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 370/1194 | Loss: 277.922 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 380/1194 | Loss: 278.039 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 390/1194 | Loss: 285.826 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 400/1194 | Loss: 303.919 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 410/1194 | Loss: 292.966 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 420/1194 | Loss: 290.067 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 430/1194 | Loss: 264.504 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 440/1194 | Loss: 280.509 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 450/1194 | Loss: 301.693 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 460/1194 | Loss: 305.014 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 470/1194 | Loss: 290.291 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 480/1194 | Loss: 266.866 | Accuracy: 0.400\n",
      "[Epoch: 37/200] - Step: 490/1194 | Loss: 297.176 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 500/1194 | Loss: 317.586 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 510/1194 | Loss: 305.480 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 520/1194 | Loss: 290.417 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 530/1194 | Loss: 303.065 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 540/1194 | Loss: 299.000 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 550/1194 | Loss: 312.556 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 560/1194 | Loss: 300.560 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 570/1194 | Loss: 312.311 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 580/1194 | Loss: 298.667 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 590/1194 | Loss: 298.295 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 600/1194 | Loss: 305.895 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 610/1194 | Loss: 316.579 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 620/1194 | Loss: 298.911 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 630/1194 | Loss: 284.547 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 640/1194 | Loss: 299.671 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 650/1194 | Loss: 284.408 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 660/1194 | Loss: 286.350 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 670/1194 | Loss: 311.468 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 680/1194 | Loss: 280.068 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 690/1194 | Loss: 327.030 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 700/1194 | Loss: 311.865 | Accuracy: 0.300\n",
      "[Epoch: 37/200] - Step: 710/1194 | Loss: 286.007 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 720/1194 | Loss: 310.618 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 730/1194 | Loss: 303.911 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 740/1194 | Loss: 293.324 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 750/1194 | Loss: 303.147 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 760/1194 | Loss: 305.652 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 770/1194 | Loss: 303.634 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 780/1194 | Loss: 291.064 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 790/1194 | Loss: 297.961 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 800/1194 | Loss: 295.366 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 810/1194 | Loss: 289.636 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 820/1194 | Loss: 290.516 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 830/1194 | Loss: 298.726 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 840/1194 | Loss: 300.024 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 850/1194 | Loss: 302.208 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 860/1194 | Loss: 300.835 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 870/1194 | Loss: 296.546 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 880/1194 | Loss: 289.980 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 890/1194 | Loss: 287.701 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 900/1194 | Loss: 299.976 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 910/1194 | Loss: 292.104 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 920/1194 | Loss: 315.391 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 930/1194 | Loss: 288.457 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 940/1194 | Loss: 299.586 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 950/1194 | Loss: 265.994 | Accuracy: 0.500\n",
      "[Epoch: 37/200] - Step: 960/1194 | Loss: 290.236 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 970/1194 | Loss: 332.617 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 980/1194 | Loss: 285.097 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 990/1194 | Loss: 294.201 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1000/1194 | Loss: 313.583 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1010/1194 | Loss: 311.732 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1020/1194 | Loss: 295.345 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1030/1194 | Loss: 296.788 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1040/1194 | Loss: 302.327 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1050/1194 | Loss: 303.019 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1060/1194 | Loss: 295.781 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1070/1194 | Loss: 296.160 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1080/1194 | Loss: 294.216 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1090/1194 | Loss: 309.660 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1100/1194 | Loss: 315.487 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1110/1194 | Loss: 292.695 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1120/1194 | Loss: 301.420 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1130/1194 | Loss: 284.753 | Accuracy: 0.200\n",
      "[Epoch: 37/200] - Step: 1140/1194 | Loss: 304.417 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1150/1194 | Loss: 293.986 | Accuracy: 0.100\n",
      "[Epoch: 37/200] - Step: 1160/1194 | Loss: 314.729 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1170/1194 | Loss: 311.967 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1180/1194 | Loss: 312.197 | Accuracy: 0.000\n",
      "[Epoch: 37/200] - Step: 1190/1194 | Loss: 326.651 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 38/200] - Step: 10/1194 | Loss: 313.032 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 20/1194 | Loss: 301.878 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 30/1194 | Loss: 307.923 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 40/1194 | Loss: 300.448 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 50/1194 | Loss: 302.319 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 60/1194 | Loss: 306.047 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 70/1194 | Loss: 294.819 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 80/1194 | Loss: 301.438 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 90/1194 | Loss: 295.927 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 100/1194 | Loss: 296.264 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 110/1194 | Loss: 300.878 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 120/1194 | Loss: 309.264 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 130/1194 | Loss: 305.149 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 140/1194 | Loss: 281.886 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 150/1194 | Loss: 305.028 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 160/1194 | Loss: 293.580 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 170/1194 | Loss: 295.619 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 180/1194 | Loss: 287.761 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 190/1194 | Loss: 297.789 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 200/1194 | Loss: 310.233 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 210/1194 | Loss: 297.634 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 220/1194 | Loss: 301.714 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 230/1194 | Loss: 319.154 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 240/1194 | Loss: 292.802 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 250/1194 | Loss: 282.456 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 260/1194 | Loss: 288.543 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 270/1194 | Loss: 306.567 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 280/1194 | Loss: 295.239 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 290/1194 | Loss: 302.682 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 300/1194 | Loss: 276.021 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 310/1194 | Loss: 298.944 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 320/1194 | Loss: 293.439 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 330/1194 | Loss: 285.097 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 340/1194 | Loss: 289.498 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 350/1194 | Loss: 278.332 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 360/1194 | Loss: 291.421 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 370/1194 | Loss: 289.789 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 380/1194 | Loss: 295.271 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 390/1194 | Loss: 286.760 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 400/1194 | Loss: 317.611 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 410/1194 | Loss: 313.898 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 420/1194 | Loss: 304.198 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 430/1194 | Loss: 277.151 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 440/1194 | Loss: 299.101 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 450/1194 | Loss: 276.720 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 460/1194 | Loss: 298.462 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 470/1194 | Loss: 308.782 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 480/1194 | Loss: 327.668 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 490/1194 | Loss: 302.937 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 500/1194 | Loss: 309.387 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 510/1194 | Loss: 301.785 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 520/1194 | Loss: 284.715 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 530/1194 | Loss: 312.868 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 540/1194 | Loss: 280.169 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 550/1194 | Loss: 291.739 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 560/1194 | Loss: 306.239 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 570/1194 | Loss: 294.634 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 580/1194 | Loss: 303.728 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 590/1194 | Loss: 286.272 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 600/1194 | Loss: 285.829 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 610/1194 | Loss: 307.398 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 620/1194 | Loss: 291.268 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 630/1194 | Loss: 295.827 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 640/1194 | Loss: 298.159 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 650/1194 | Loss: 292.545 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 660/1194 | Loss: 298.026 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 670/1194 | Loss: 300.516 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 680/1194 | Loss: 293.725 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 690/1194 | Loss: 297.307 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 700/1194 | Loss: 290.585 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 710/1194 | Loss: 293.659 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 720/1194 | Loss: 294.780 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 730/1194 | Loss: 307.672 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 740/1194 | Loss: 294.886 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 750/1194 | Loss: 295.170 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 760/1194 | Loss: 306.573 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 770/1194 | Loss: 303.331 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 780/1194 | Loss: 293.598 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 790/1194 | Loss: 303.878 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 800/1194 | Loss: 294.229 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 810/1194 | Loss: 290.961 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 820/1194 | Loss: 269.790 | Accuracy: 0.400\n",
      "[Epoch: 38/200] - Step: 830/1194 | Loss: 295.752 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 840/1194 | Loss: 283.095 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 850/1194 | Loss: 279.338 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 860/1194 | Loss: 291.114 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 870/1194 | Loss: 283.289 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 880/1194 | Loss: 260.562 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 890/1194 | Loss: 359.413 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 900/1194 | Loss: 280.621 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 910/1194 | Loss: 315.561 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 920/1194 | Loss: 308.440 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 930/1194 | Loss: 308.098 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 940/1194 | Loss: 316.075 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 950/1194 | Loss: 301.707 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 960/1194 | Loss: 291.703 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 970/1194 | Loss: 306.114 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 980/1194 | Loss: 295.125 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 990/1194 | Loss: 285.118 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1000/1194 | Loss: 289.097 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1010/1194 | Loss: 297.157 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1020/1194 | Loss: 304.098 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1030/1194 | Loss: 288.648 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1040/1194 | Loss: 339.523 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1050/1194 | Loss: 299.689 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1060/1194 | Loss: 293.597 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1070/1194 | Loss: 297.340 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1080/1194 | Loss: 303.241 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1090/1194 | Loss: 300.777 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1100/1194 | Loss: 297.801 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1110/1194 | Loss: 298.504 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1120/1194 | Loss: 279.480 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1130/1194 | Loss: 293.638 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1140/1194 | Loss: 299.135 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1150/1194 | Loss: 292.841 | Accuracy: 0.200\n",
      "[Epoch: 38/200] - Step: 1160/1194 | Loss: 282.110 | Accuracy: 0.300\n",
      "[Epoch: 38/200] - Step: 1170/1194 | Loss: 300.140 | Accuracy: 0.100\n",
      "[Epoch: 38/200] - Step: 1180/1194 | Loss: 315.114 | Accuracy: 0.000\n",
      "[Epoch: 38/200] - Step: 1190/1194 | Loss: 304.900 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 39/200] - Step: 10/1194 | Loss: 304.302 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 20/1194 | Loss: 309.360 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 30/1194 | Loss: 281.809 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 40/1194 | Loss: 285.769 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 50/1194 | Loss: 300.255 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 60/1194 | Loss: 297.822 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 70/1194 | Loss: 314.051 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 80/1194 | Loss: 295.925 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 90/1194 | Loss: 277.573 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 100/1194 | Loss: 310.992 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 110/1194 | Loss: 280.017 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 120/1194 | Loss: 291.538 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 130/1194 | Loss: 310.725 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 140/1194 | Loss: 314.062 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 150/1194 | Loss: 284.749 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 160/1194 | Loss: 278.052 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 170/1194 | Loss: 298.045 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 180/1194 | Loss: 291.270 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 190/1194 | Loss: 280.158 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 200/1194 | Loss: 281.029 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 210/1194 | Loss: 284.384 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 220/1194 | Loss: 296.416 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 230/1194 | Loss: 286.218 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 240/1194 | Loss: 342.124 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 250/1194 | Loss: 307.301 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 260/1194 | Loss: 288.071 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 270/1194 | Loss: 327.498 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 280/1194 | Loss: 278.823 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 290/1194 | Loss: 303.150 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 300/1194 | Loss: 300.555 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 310/1194 | Loss: 293.388 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 320/1194 | Loss: 293.036 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 330/1194 | Loss: 301.445 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 340/1194 | Loss: 318.179 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 350/1194 | Loss: 295.859 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 360/1194 | Loss: 305.738 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 370/1194 | Loss: 301.821 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 380/1194 | Loss: 317.056 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 390/1194 | Loss: 302.440 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 400/1194 | Loss: 304.176 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 410/1194 | Loss: 298.441 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 420/1194 | Loss: 294.220 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 430/1194 | Loss: 289.344 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 440/1194 | Loss: 291.778 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 450/1194 | Loss: 282.490 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 460/1194 | Loss: 316.055 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 470/1194 | Loss: 291.805 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 480/1194 | Loss: 283.284 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 490/1194 | Loss: 299.622 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 500/1194 | Loss: 304.003 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 510/1194 | Loss: 303.108 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 520/1194 | Loss: 306.048 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 530/1194 | Loss: 330.858 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 540/1194 | Loss: 280.976 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 550/1194 | Loss: 295.492 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 560/1194 | Loss: 289.055 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 570/1194 | Loss: 290.713 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 580/1194 | Loss: 278.281 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 590/1194 | Loss: 286.962 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 600/1194 | Loss: 307.972 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 610/1194 | Loss: 289.539 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 620/1194 | Loss: 295.847 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 630/1194 | Loss: 300.938 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 640/1194 | Loss: 315.983 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 650/1194 | Loss: 297.560 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 660/1194 | Loss: 266.306 | Accuracy: 0.400\n",
      "[Epoch: 39/200] - Step: 670/1194 | Loss: 299.505 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 680/1194 | Loss: 292.123 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 690/1194 | Loss: 299.691 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 700/1194 | Loss: 297.605 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 710/1194 | Loss: 295.867 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 720/1194 | Loss: 303.595 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 730/1194 | Loss: 291.796 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 740/1194 | Loss: 292.925 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 750/1194 | Loss: 298.232 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 760/1194 | Loss: 328.046 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 770/1194 | Loss: 291.445 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 780/1194 | Loss: 297.842 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 790/1194 | Loss: 308.441 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 800/1194 | Loss: 290.134 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 810/1194 | Loss: 307.244 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 820/1194 | Loss: 287.671 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 830/1194 | Loss: 294.579 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 840/1194 | Loss: 298.374 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 850/1194 | Loss: 301.772 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 860/1194 | Loss: 312.521 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 870/1194 | Loss: 282.118 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 880/1194 | Loss: 285.332 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 890/1194 | Loss: 296.790 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 900/1194 | Loss: 299.854 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 910/1194 | Loss: 311.063 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 920/1194 | Loss: 301.760 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 930/1194 | Loss: 298.294 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 940/1194 | Loss: 282.885 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 950/1194 | Loss: 289.177 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 960/1194 | Loss: 278.851 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 970/1194 | Loss: 313.353 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 980/1194 | Loss: 291.643 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 990/1194 | Loss: 271.275 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1000/1194 | Loss: 303.989 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1010/1194 | Loss: 276.410 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1020/1194 | Loss: 297.528 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1030/1194 | Loss: 312.738 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1040/1194 | Loss: 286.313 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1050/1194 | Loss: 285.329 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1060/1194 | Loss: 323.646 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1070/1194 | Loss: 311.161 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1080/1194 | Loss: 312.445 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1090/1194 | Loss: 298.965 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1100/1194 | Loss: 295.382 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1110/1194 | Loss: 290.247 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1120/1194 | Loss: 286.420 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1130/1194 | Loss: 290.612 | Accuracy: 0.200\n",
      "[Epoch: 39/200] - Step: 1140/1194 | Loss: 299.603 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1150/1194 | Loss: 299.078 | Accuracy: 0.100\n",
      "[Epoch: 39/200] - Step: 1160/1194 | Loss: 318.124 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1170/1194 | Loss: 309.763 | Accuracy: 0.000\n",
      "[Epoch: 39/200] - Step: 1180/1194 | Loss: 274.592 | Accuracy: 0.300\n",
      "[Epoch: 39/200] - Step: 1190/1194 | Loss: 307.958 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 40/200] - Step: 10/1194 | Loss: 300.547 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 20/1194 | Loss: 296.096 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 30/1194 | Loss: 293.872 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 40/1194 | Loss: 296.133 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 50/1194 | Loss: 303.597 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 60/1194 | Loss: 275.459 | Accuracy: 0.400\n",
      "[Epoch: 40/200] - Step: 70/1194 | Loss: 289.284 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 80/1194 | Loss: 313.504 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 90/1194 | Loss: 294.452 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 100/1194 | Loss: 323.518 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 110/1194 | Loss: 284.675 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 120/1194 | Loss: 291.901 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 130/1194 | Loss: 285.977 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 140/1194 | Loss: 301.026 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 150/1194 | Loss: 300.154 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 160/1194 | Loss: 314.106 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 170/1194 | Loss: 309.157 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 180/1194 | Loss: 297.744 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 190/1194 | Loss: 300.279 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 200/1194 | Loss: 291.683 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 210/1194 | Loss: 311.513 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 220/1194 | Loss: 305.240 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 230/1194 | Loss: 287.186 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 240/1194 | Loss: 306.265 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 250/1194 | Loss: 290.241 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 260/1194 | Loss: 305.231 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 270/1194 | Loss: 322.758 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 280/1194 | Loss: 297.726 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 290/1194 | Loss: 307.172 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 300/1194 | Loss: 305.519 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 310/1194 | Loss: 293.154 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 320/1194 | Loss: 310.144 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 330/1194 | Loss: 299.582 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 340/1194 | Loss: 294.923 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 350/1194 | Loss: 299.032 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 360/1194 | Loss: 303.207 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 370/1194 | Loss: 288.095 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 380/1194 | Loss: 301.338 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 390/1194 | Loss: 292.110 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 400/1194 | Loss: 302.453 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 410/1194 | Loss: 288.595 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 420/1194 | Loss: 319.660 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 430/1194 | Loss: 292.404 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 440/1194 | Loss: 294.268 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 450/1194 | Loss: 310.520 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 460/1194 | Loss: 281.267 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 470/1194 | Loss: 299.960 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 480/1194 | Loss: 276.120 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 490/1194 | Loss: 280.707 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 500/1194 | Loss: 310.481 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 510/1194 | Loss: 284.995 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 520/1194 | Loss: 292.996 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 530/1194 | Loss: 292.665 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 540/1194 | Loss: 290.596 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 550/1194 | Loss: 313.541 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 560/1194 | Loss: 324.554 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 570/1194 | Loss: 284.559 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 580/1194 | Loss: 285.722 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 590/1194 | Loss: 293.201 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 600/1194 | Loss: 292.149 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 610/1194 | Loss: 297.738 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 620/1194 | Loss: 290.492 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 630/1194 | Loss: 293.196 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 640/1194 | Loss: 309.278 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 650/1194 | Loss: 296.477 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 660/1194 | Loss: 294.357 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 670/1194 | Loss: 294.695 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 680/1194 | Loss: 300.518 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 690/1194 | Loss: 301.940 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 700/1194 | Loss: 309.079 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 710/1194 | Loss: 295.864 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 720/1194 | Loss: 301.279 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 730/1194 | Loss: 294.974 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 740/1194 | Loss: 308.617 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 750/1194 | Loss: 293.039 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 760/1194 | Loss: 281.453 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 770/1194 | Loss: 294.710 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 780/1194 | Loss: 297.628 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 790/1194 | Loss: 284.504 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 800/1194 | Loss: 304.843 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 810/1194 | Loss: 280.688 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 820/1194 | Loss: 297.239 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 830/1194 | Loss: 298.240 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 840/1194 | Loss: 289.876 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 850/1194 | Loss: 299.372 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 860/1194 | Loss: 305.159 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 870/1194 | Loss: 307.712 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 880/1194 | Loss: 298.120 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 890/1194 | Loss: 294.512 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 900/1194 | Loss: 285.724 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 910/1194 | Loss: 285.844 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 920/1194 | Loss: 304.597 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 930/1194 | Loss: 294.323 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 940/1194 | Loss: 314.251 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 950/1194 | Loss: 302.447 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 960/1194 | Loss: 296.449 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 970/1194 | Loss: 272.635 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 980/1194 | Loss: 289.956 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 990/1194 | Loss: 304.836 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1000/1194 | Loss: 282.102 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1010/1194 | Loss: 294.681 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1020/1194 | Loss: 321.578 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1030/1194 | Loss: 305.116 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1040/1194 | Loss: 311.881 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1050/1194 | Loss: 286.615 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1060/1194 | Loss: 279.613 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1070/1194 | Loss: 302.725 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1080/1194 | Loss: 290.643 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1090/1194 | Loss: 300.509 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1100/1194 | Loss: 295.212 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1110/1194 | Loss: 303.938 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1120/1194 | Loss: 298.341 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1130/1194 | Loss: 306.771 | Accuracy: 0.000\n",
      "[Epoch: 40/200] - Step: 1140/1194 | Loss: 289.363 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1150/1194 | Loss: 288.018 | Accuracy: 0.300\n",
      "[Epoch: 40/200] - Step: 1160/1194 | Loss: 297.092 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1170/1194 | Loss: 296.559 | Accuracy: 0.100\n",
      "[Epoch: 40/200] - Step: 1180/1194 | Loss: 288.022 | Accuracy: 0.200\n",
      "[Epoch: 40/200] - Step: 1190/1194 | Loss: 284.149 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 41/200] - Step: 10/1194 | Loss: 302.056 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 20/1194 | Loss: 278.155 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 30/1194 | Loss: 291.649 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 40/1194 | Loss: 297.990 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 50/1194 | Loss: 266.282 | Accuracy: 0.400\n",
      "[Epoch: 41/200] - Step: 60/1194 | Loss: 284.102 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 70/1194 | Loss: 273.845 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 80/1194 | Loss: 308.088 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 90/1194 | Loss: 330.873 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 100/1194 | Loss: 299.377 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 110/1194 | Loss: 288.575 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 120/1194 | Loss: 285.963 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 130/1194 | Loss: 294.677 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 140/1194 | Loss: 291.141 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 150/1194 | Loss: 294.876 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 160/1194 | Loss: 301.413 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 170/1194 | Loss: 328.586 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 180/1194 | Loss: 289.550 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 190/1194 | Loss: 320.818 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 200/1194 | Loss: 292.309 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 210/1194 | Loss: 303.684 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 220/1194 | Loss: 280.721 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 230/1194 | Loss: 279.651 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 240/1194 | Loss: 295.575 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 250/1194 | Loss: 296.920 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 260/1194 | Loss: 298.721 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 270/1194 | Loss: 297.786 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 280/1194 | Loss: 286.924 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 290/1194 | Loss: 275.545 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 300/1194 | Loss: 296.961 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 310/1194 | Loss: 310.725 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 320/1194 | Loss: 294.620 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 330/1194 | Loss: 304.394 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 340/1194 | Loss: 308.455 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 350/1194 | Loss: 315.184 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 360/1194 | Loss: 298.264 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 370/1194 | Loss: 291.846 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 380/1194 | Loss: 307.234 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 390/1194 | Loss: 299.674 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 400/1194 | Loss: 295.614 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 410/1194 | Loss: 298.762 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 420/1194 | Loss: 284.468 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 430/1194 | Loss: 282.165 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 440/1194 | Loss: 292.463 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 450/1194 | Loss: 282.513 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 460/1194 | Loss: 289.585 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 470/1194 | Loss: 297.470 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 480/1194 | Loss: 294.124 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 490/1194 | Loss: 295.978 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 500/1194 | Loss: 286.720 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 510/1194 | Loss: 311.215 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 520/1194 | Loss: 299.426 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 530/1194 | Loss: 293.399 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 540/1194 | Loss: 296.365 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 550/1194 | Loss: 283.176 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 560/1194 | Loss: 315.007 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 570/1194 | Loss: 309.470 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 580/1194 | Loss: 283.277 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 590/1194 | Loss: 292.234 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 600/1194 | Loss: 308.998 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 610/1194 | Loss: 296.059 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 620/1194 | Loss: 304.088 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 630/1194 | Loss: 300.470 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 640/1194 | Loss: 309.053 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 650/1194 | Loss: 294.709 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 660/1194 | Loss: 296.800 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 670/1194 | Loss: 298.513 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 680/1194 | Loss: 303.150 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 690/1194 | Loss: 306.081 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 700/1194 | Loss: 316.648 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 710/1194 | Loss: 312.855 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 720/1194 | Loss: 292.202 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 730/1194 | Loss: 301.523 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 740/1194 | Loss: 291.942 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 750/1194 | Loss: 287.856 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 760/1194 | Loss: 295.522 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 770/1194 | Loss: 328.871 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 780/1194 | Loss: 308.764 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 790/1194 | Loss: 299.934 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 800/1194 | Loss: 288.569 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 810/1194 | Loss: 309.041 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 820/1194 | Loss: 302.336 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 830/1194 | Loss: 303.135 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 840/1194 | Loss: 282.332 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 850/1194 | Loss: 307.306 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 860/1194 | Loss: 294.469 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 870/1194 | Loss: 286.197 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 880/1194 | Loss: 301.780 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 890/1194 | Loss: 301.967 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 900/1194 | Loss: 299.137 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 910/1194 | Loss: 299.869 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 920/1194 | Loss: 308.521 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 930/1194 | Loss: 277.626 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 940/1194 | Loss: 303.289 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 950/1194 | Loss: 296.113 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 960/1194 | Loss: 298.276 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 970/1194 | Loss: 304.729 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 980/1194 | Loss: 287.741 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 990/1194 | Loss: 301.110 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1000/1194 | Loss: 295.602 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 1010/1194 | Loss: 319.486 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1020/1194 | Loss: 311.556 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1030/1194 | Loss: 305.320 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 1040/1194 | Loss: 286.612 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1050/1194 | Loss: 308.735 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 1060/1194 | Loss: 283.238 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1070/1194 | Loss: 306.999 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1080/1194 | Loss: 303.099 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1090/1194 | Loss: 292.579 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1100/1194 | Loss: 289.237 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1110/1194 | Loss: 300.264 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1120/1194 | Loss: 289.521 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1130/1194 | Loss: 293.068 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1140/1194 | Loss: 309.021 | Accuracy: 0.000\n",
      "[Epoch: 41/200] - Step: 1150/1194 | Loss: 297.849 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1160/1194 | Loss: 284.077 | Accuracy: 0.300\n",
      "[Epoch: 41/200] - Step: 1170/1194 | Loss: 286.163 | Accuracy: 0.200\n",
      "[Epoch: 41/200] - Step: 1180/1194 | Loss: 307.575 | Accuracy: 0.100\n",
      "[Epoch: 41/200] - Step: 1190/1194 | Loss: 265.488 | Accuracy: 0.400\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 42/200] - Step: 10/1194 | Loss: 313.385 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 20/1194 | Loss: 308.619 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 30/1194 | Loss: 288.633 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 40/1194 | Loss: 299.880 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 50/1194 | Loss: 293.124 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 60/1194 | Loss: 298.925 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 70/1194 | Loss: 293.592 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 80/1194 | Loss: 298.977 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 90/1194 | Loss: 289.128 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 100/1194 | Loss: 303.592 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 110/1194 | Loss: 280.861 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 120/1194 | Loss: 281.405 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 130/1194 | Loss: 340.160 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 140/1194 | Loss: 283.795 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 150/1194 | Loss: 313.111 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 160/1194 | Loss: 306.953 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 170/1194 | Loss: 301.084 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 180/1194 | Loss: 294.925 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 190/1194 | Loss: 294.824 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 200/1194 | Loss: 309.402 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 210/1194 | Loss: 297.894 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 220/1194 | Loss: 293.862 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 230/1194 | Loss: 310.739 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 240/1194 | Loss: 295.403 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 250/1194 | Loss: 285.632 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 260/1194 | Loss: 294.079 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 270/1194 | Loss: 289.670 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 280/1194 | Loss: 306.948 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 290/1194 | Loss: 307.804 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 300/1194 | Loss: 284.510 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 310/1194 | Loss: 288.320 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 320/1194 | Loss: 298.598 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 330/1194 | Loss: 280.227 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 340/1194 | Loss: 297.952 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 350/1194 | Loss: 294.239 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 360/1194 | Loss: 300.345 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 370/1194 | Loss: 291.601 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 380/1194 | Loss: 306.461 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 390/1194 | Loss: 297.520 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 400/1194 | Loss: 273.696 | Accuracy: 0.400\n",
      "[Epoch: 42/200] - Step: 410/1194 | Loss: 293.899 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 420/1194 | Loss: 313.623 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 430/1194 | Loss: 280.321 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 440/1194 | Loss: 282.480 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 450/1194 | Loss: 278.361 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 460/1194 | Loss: 299.182 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 470/1194 | Loss: 305.124 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 480/1194 | Loss: 313.301 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 490/1194 | Loss: 336.183 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 500/1194 | Loss: 315.853 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 510/1194 | Loss: 300.686 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 520/1194 | Loss: 298.840 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 530/1194 | Loss: 298.274 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 540/1194 | Loss: 299.687 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 550/1194 | Loss: 299.228 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 560/1194 | Loss: 293.157 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 570/1194 | Loss: 300.608 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 580/1194 | Loss: 297.696 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 590/1194 | Loss: 294.486 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 600/1194 | Loss: 295.251 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 610/1194 | Loss: 296.523 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 620/1194 | Loss: 303.816 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 630/1194 | Loss: 291.202 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 640/1194 | Loss: 293.265 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 650/1194 | Loss: 303.290 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 660/1194 | Loss: 282.391 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 670/1194 | Loss: 305.504 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 680/1194 | Loss: 302.288 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 690/1194 | Loss: 288.924 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 700/1194 | Loss: 284.674 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 710/1194 | Loss: 344.876 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 720/1194 | Loss: 290.959 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 730/1194 | Loss: 290.240 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 740/1194 | Loss: 292.508 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 750/1194 | Loss: 299.534 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 760/1194 | Loss: 300.807 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 770/1194 | Loss: 294.205 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 780/1194 | Loss: 288.558 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 790/1194 | Loss: 288.078 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 800/1194 | Loss: 303.817 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 810/1194 | Loss: 289.325 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 820/1194 | Loss: 307.765 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 830/1194 | Loss: 291.066 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 840/1194 | Loss: 300.973 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 850/1194 | Loss: 293.169 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 860/1194 | Loss: 299.928 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 870/1194 | Loss: 283.102 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 880/1194 | Loss: 305.982 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 890/1194 | Loss: 291.546 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 900/1194 | Loss: 301.693 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 910/1194 | Loss: 309.700 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 920/1194 | Loss: 302.952 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 930/1194 | Loss: 321.531 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 940/1194 | Loss: 304.051 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 950/1194 | Loss: 312.730 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 960/1194 | Loss: 306.523 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 970/1194 | Loss: 298.965 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 980/1194 | Loss: 285.147 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 990/1194 | Loss: 291.436 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1000/1194 | Loss: 302.209 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1010/1194 | Loss: 292.669 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1020/1194 | Loss: 277.292 | Accuracy: 0.300\n",
      "[Epoch: 42/200] - Step: 1030/1194 | Loss: 291.355 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1040/1194 | Loss: 289.587 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1050/1194 | Loss: 281.866 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1060/1194 | Loss: 324.791 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1070/1194 | Loss: 298.522 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1080/1194 | Loss: 290.223 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1090/1194 | Loss: 306.523 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1100/1194 | Loss: 280.072 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1110/1194 | Loss: 292.474 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1120/1194 | Loss: 274.626 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1130/1194 | Loss: 300.228 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 1140/1194 | Loss: 289.944 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1150/1194 | Loss: 292.652 | Accuracy: 0.200\n",
      "[Epoch: 42/200] - Step: 1160/1194 | Loss: 292.927 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1170/1194 | Loss: 305.296 | Accuracy: 0.100\n",
      "[Epoch: 42/200] - Step: 1180/1194 | Loss: 303.726 | Accuracy: 0.000\n",
      "[Epoch: 42/200] - Step: 1190/1194 | Loss: 277.942 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 43/200] - Step: 10/1194 | Loss: 293.176 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 20/1194 | Loss: 293.390 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 30/1194 | Loss: 304.915 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 40/1194 | Loss: 302.709 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 50/1194 | Loss: 298.714 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 60/1194 | Loss: 286.971 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 70/1194 | Loss: 286.156 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 80/1194 | Loss: 284.382 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 90/1194 | Loss: 317.130 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 100/1194 | Loss: 285.990 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 110/1194 | Loss: 287.375 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 120/1194 | Loss: 303.198 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 130/1194 | Loss: 302.126 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 140/1194 | Loss: 278.269 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 150/1194 | Loss: 299.320 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 160/1194 | Loss: 289.500 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 170/1194 | Loss: 329.345 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 180/1194 | Loss: 287.634 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 190/1194 | Loss: 298.422 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 200/1194 | Loss: 304.184 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 210/1194 | Loss: 273.152 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 220/1194 | Loss: 294.781 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 230/1194 | Loss: 299.998 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 240/1194 | Loss: 293.592 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 250/1194 | Loss: 292.079 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 260/1194 | Loss: 306.989 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 270/1194 | Loss: 294.206 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 280/1194 | Loss: 296.784 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 290/1194 | Loss: 292.009 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 300/1194 | Loss: 289.651 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 310/1194 | Loss: 253.376 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 320/1194 | Loss: 301.641 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 330/1194 | Loss: 310.351 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 340/1194 | Loss: 276.532 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 350/1194 | Loss: 310.240 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 360/1194 | Loss: 302.333 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 370/1194 | Loss: 292.395 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 380/1194 | Loss: 305.146 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 390/1194 | Loss: 311.280 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 400/1194 | Loss: 324.381 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 410/1194 | Loss: 296.401 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 420/1194 | Loss: 292.676 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 430/1194 | Loss: 291.591 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 440/1194 | Loss: 274.080 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 450/1194 | Loss: 285.964 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 460/1194 | Loss: 274.037 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 470/1194 | Loss: 300.871 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 480/1194 | Loss: 298.102 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 490/1194 | Loss: 326.890 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 500/1194 | Loss: 293.772 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 510/1194 | Loss: 296.069 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 520/1194 | Loss: 295.501 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 530/1194 | Loss: 299.624 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 540/1194 | Loss: 283.236 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 550/1194 | Loss: 281.598 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 560/1194 | Loss: 288.181 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 570/1194 | Loss: 302.039 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 580/1194 | Loss: 292.320 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 590/1194 | Loss: 299.075 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 600/1194 | Loss: 305.833 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 610/1194 | Loss: 308.027 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 620/1194 | Loss: 284.381 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 630/1194 | Loss: 275.592 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 640/1194 | Loss: 288.888 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 650/1194 | Loss: 311.897 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 660/1194 | Loss: 333.506 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 670/1194 | Loss: 300.929 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 680/1194 | Loss: 277.923 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 690/1194 | Loss: 298.222 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 700/1194 | Loss: 298.400 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 710/1194 | Loss: 306.592 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 720/1194 | Loss: 293.981 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 730/1194 | Loss: 298.847 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 740/1194 | Loss: 306.570 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 750/1194 | Loss: 287.412 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 760/1194 | Loss: 299.898 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 770/1194 | Loss: 292.600 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 780/1194 | Loss: 290.058 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 790/1194 | Loss: 321.434 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 800/1194 | Loss: 314.393 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 810/1194 | Loss: 305.861 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 820/1194 | Loss: 302.098 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 830/1194 | Loss: 316.228 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 840/1194 | Loss: 292.904 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 850/1194 | Loss: 301.971 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 860/1194 | Loss: 305.132 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 870/1194 | Loss: 311.327 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 880/1194 | Loss: 299.057 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 890/1194 | Loss: 298.955 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 900/1194 | Loss: 295.936 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 910/1194 | Loss: 299.620 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 920/1194 | Loss: 310.056 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 930/1194 | Loss: 299.275 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 940/1194 | Loss: 295.663 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 950/1194 | Loss: 294.875 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 960/1194 | Loss: 287.110 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 970/1194 | Loss: 300.667 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 980/1194 | Loss: 294.294 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 990/1194 | Loss: 303.651 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1000/1194 | Loss: 309.723 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 1010/1194 | Loss: 306.236 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 1020/1194 | Loss: 302.666 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1030/1194 | Loss: 306.179 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 1040/1194 | Loss: 302.006 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 1050/1194 | Loss: 286.161 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1060/1194 | Loss: 278.196 | Accuracy: 0.400\n",
      "[Epoch: 43/200] - Step: 1070/1194 | Loss: 301.473 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1080/1194 | Loss: 288.024 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1090/1194 | Loss: 311.519 | Accuracy: 0.000\n",
      "[Epoch: 43/200] - Step: 1100/1194 | Loss: 278.037 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1110/1194 | Loss: 303.929 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1120/1194 | Loss: 291.915 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1130/1194 | Loss: 294.931 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1140/1194 | Loss: 296.114 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1150/1194 | Loss: 306.945 | Accuracy: 0.300\n",
      "[Epoch: 43/200] - Step: 1160/1194 | Loss: 302.326 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1170/1194 | Loss: 291.473 | Accuracy: 0.100\n",
      "[Epoch: 43/200] - Step: 1180/1194 | Loss: 283.687 | Accuracy: 0.200\n",
      "[Epoch: 43/200] - Step: 1190/1194 | Loss: 304.882 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 44/200] - Step: 10/1194 | Loss: 291.811 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 20/1194 | Loss: 298.826 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 30/1194 | Loss: 301.372 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 40/1194 | Loss: 309.245 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 50/1194 | Loss: 321.318 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 60/1194 | Loss: 302.801 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 70/1194 | Loss: 319.633 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 80/1194 | Loss: 303.146 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 90/1194 | Loss: 301.157 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 100/1194 | Loss: 294.554 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 110/1194 | Loss: 298.036 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 120/1194 | Loss: 301.455 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 130/1194 | Loss: 287.960 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 140/1194 | Loss: 297.637 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 150/1194 | Loss: 298.721 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 160/1194 | Loss: 301.178 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 170/1194 | Loss: 304.541 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 180/1194 | Loss: 286.537 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 190/1194 | Loss: 285.457 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 200/1194 | Loss: 307.284 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 210/1194 | Loss: 346.825 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 220/1194 | Loss: 307.322 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 230/1194 | Loss: 299.629 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 240/1194 | Loss: 302.152 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 250/1194 | Loss: 302.870 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 260/1194 | Loss: 290.427 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 270/1194 | Loss: 294.750 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 280/1194 | Loss: 294.285 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 290/1194 | Loss: 287.419 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 300/1194 | Loss: 296.738 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 310/1194 | Loss: 290.807 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 320/1194 | Loss: 296.147 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 330/1194 | Loss: 297.169 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 340/1194 | Loss: 293.183 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 350/1194 | Loss: 307.635 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 360/1194 | Loss: 294.834 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 370/1194 | Loss: 294.343 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 380/1194 | Loss: 302.061 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 390/1194 | Loss: 290.830 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 400/1194 | Loss: 283.941 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 410/1194 | Loss: 285.025 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 420/1194 | Loss: 316.266 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 430/1194 | Loss: 304.715 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 440/1194 | Loss: 282.904 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 450/1194 | Loss: 285.913 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 460/1194 | Loss: 290.226 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 470/1194 | Loss: 285.364 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 480/1194 | Loss: 267.012 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 490/1194 | Loss: 285.740 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 500/1194 | Loss: 301.024 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 510/1194 | Loss: 305.582 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 520/1194 | Loss: 287.577 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 530/1194 | Loss: 285.938 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 540/1194 | Loss: 296.154 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 550/1194 | Loss: 339.575 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 560/1194 | Loss: 302.672 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 570/1194 | Loss: 293.329 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 580/1194 | Loss: 278.626 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 590/1194 | Loss: 290.691 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 600/1194 | Loss: 298.001 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 610/1194 | Loss: 277.170 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 620/1194 | Loss: 302.055 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 630/1194 | Loss: 286.230 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 640/1194 | Loss: 268.852 | Accuracy: 0.300\n",
      "[Epoch: 44/200] - Step: 650/1194 | Loss: 308.622 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 660/1194 | Loss: 313.576 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 670/1194 | Loss: 290.445 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 680/1194 | Loss: 297.879 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 690/1194 | Loss: 322.843 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 700/1194 | Loss: 309.855 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 710/1194 | Loss: 300.326 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 720/1194 | Loss: 300.707 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 730/1194 | Loss: 292.320 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 740/1194 | Loss: 289.474 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 750/1194 | Loss: 291.185 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 760/1194 | Loss: 303.854 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 770/1194 | Loss: 327.223 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 780/1194 | Loss: 289.111 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 790/1194 | Loss: 300.451 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 800/1194 | Loss: 296.363 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 810/1194 | Loss: 283.155 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 820/1194 | Loss: 290.918 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 830/1194 | Loss: 301.145 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 840/1194 | Loss: 305.914 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 850/1194 | Loss: 320.028 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 860/1194 | Loss: 286.442 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 870/1194 | Loss: 300.486 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 880/1194 | Loss: 287.592 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 890/1194 | Loss: 303.358 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 900/1194 | Loss: 285.485 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 910/1194 | Loss: 301.279 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 920/1194 | Loss: 301.538 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 930/1194 | Loss: 307.143 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 940/1194 | Loss: 295.050 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 950/1194 | Loss: 291.961 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 960/1194 | Loss: 303.480 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 970/1194 | Loss: 307.713 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 980/1194 | Loss: 303.244 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 990/1194 | Loss: 276.725 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1000/1194 | Loss: 335.936 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1010/1194 | Loss: 278.614 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1020/1194 | Loss: 289.456 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1030/1194 | Loss: 289.667 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1040/1194 | Loss: 300.485 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1050/1194 | Loss: 288.868 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1060/1194 | Loss: 307.627 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1070/1194 | Loss: 291.214 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 1080/1194 | Loss: 292.937 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1090/1194 | Loss: 272.736 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1100/1194 | Loss: 314.892 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1110/1194 | Loss: 308.413 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1120/1194 | Loss: 297.151 | Accuracy: 0.000\n",
      "[Epoch: 44/200] - Step: 1130/1194 | Loss: 290.672 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1140/1194 | Loss: 270.779 | Accuracy: 0.400\n",
      "[Epoch: 44/200] - Step: 1150/1194 | Loss: 301.565 | Accuracy: 0.100\n",
      "[Epoch: 44/200] - Step: 1160/1194 | Loss: 297.320 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1170/1194 | Loss: 250.719 | Accuracy: 0.500\n",
      "[Epoch: 44/200] - Step: 1180/1194 | Loss: 280.258 | Accuracy: 0.200\n",
      "[Epoch: 44/200] - Step: 1190/1194 | Loss: 327.166 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 45/200] - Step: 10/1194 | Loss: 301.239 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 20/1194 | Loss: 306.380 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 30/1194 | Loss: 308.405 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 40/1194 | Loss: 307.909 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 50/1194 | Loss: 291.003 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 60/1194 | Loss: 302.130 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 70/1194 | Loss: 306.153 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 80/1194 | Loss: 293.005 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 90/1194 | Loss: 291.779 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 100/1194 | Loss: 284.403 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 110/1194 | Loss: 282.505 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 120/1194 | Loss: 315.082 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 130/1194 | Loss: 310.323 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 140/1194 | Loss: 306.259 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 150/1194 | Loss: 304.861 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 160/1194 | Loss: 293.296 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 170/1194 | Loss: 282.176 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 180/1194 | Loss: 308.919 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 190/1194 | Loss: 299.890 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 200/1194 | Loss: 308.139 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 210/1194 | Loss: 306.146 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 220/1194 | Loss: 293.983 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 230/1194 | Loss: 302.307 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 240/1194 | Loss: 304.511 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 250/1194 | Loss: 285.852 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 260/1194 | Loss: 295.870 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 270/1194 | Loss: 290.618 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 280/1194 | Loss: 295.088 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 290/1194 | Loss: 290.244 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 300/1194 | Loss: 289.666 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 310/1194 | Loss: 281.606 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 320/1194 | Loss: 290.035 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 330/1194 | Loss: 278.076 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 340/1194 | Loss: 297.484 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 350/1194 | Loss: 296.572 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 360/1194 | Loss: 305.962 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 370/1194 | Loss: 293.661 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 380/1194 | Loss: 267.408 | Accuracy: 0.400\n",
      "[Epoch: 45/200] - Step: 390/1194 | Loss: 299.110 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 400/1194 | Loss: 332.649 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 410/1194 | Loss: 303.908 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 420/1194 | Loss: 285.251 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 430/1194 | Loss: 300.572 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 440/1194 | Loss: 287.702 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 450/1194 | Loss: 302.470 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 460/1194 | Loss: 283.851 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 470/1194 | Loss: 304.900 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 480/1194 | Loss: 298.890 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 490/1194 | Loss: 300.762 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 500/1194 | Loss: 318.775 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 510/1194 | Loss: 308.705 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 520/1194 | Loss: 295.793 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 530/1194 | Loss: 305.802 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 540/1194 | Loss: 289.343 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 550/1194 | Loss: 295.115 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 560/1194 | Loss: 282.253 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 570/1194 | Loss: 290.541 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 580/1194 | Loss: 298.444 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 590/1194 | Loss: 300.896 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 600/1194 | Loss: 283.527 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 610/1194 | Loss: 295.825 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 620/1194 | Loss: 315.874 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 630/1194 | Loss: 317.833 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 640/1194 | Loss: 293.771 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 650/1194 | Loss: 301.443 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 660/1194 | Loss: 288.410 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 670/1194 | Loss: 292.321 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 680/1194 | Loss: 294.955 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 690/1194 | Loss: 286.906 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 700/1194 | Loss: 293.031 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 710/1194 | Loss: 289.133 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 720/1194 | Loss: 313.365 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 730/1194 | Loss: 307.608 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 740/1194 | Loss: 301.962 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 750/1194 | Loss: 296.004 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 760/1194 | Loss: 288.603 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 770/1194 | Loss: 305.858 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 780/1194 | Loss: 275.453 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 790/1194 | Loss: 289.847 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 800/1194 | Loss: 290.097 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 810/1194 | Loss: 303.907 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 820/1194 | Loss: 293.694 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 830/1194 | Loss: 295.065 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 840/1194 | Loss: 303.056 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 850/1194 | Loss: 305.234 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 860/1194 | Loss: 292.447 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 870/1194 | Loss: 322.446 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 880/1194 | Loss: 318.751 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 890/1194 | Loss: 297.056 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 900/1194 | Loss: 284.938 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 910/1194 | Loss: 295.402 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 920/1194 | Loss: 277.033 | Accuracy: 0.300\n",
      "[Epoch: 45/200] - Step: 930/1194 | Loss: 309.785 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 940/1194 | Loss: 301.107 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 950/1194 | Loss: 302.471 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 960/1194 | Loss: 307.100 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 970/1194 | Loss: 288.334 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 980/1194 | Loss: 300.495 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 990/1194 | Loss: 321.087 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1000/1194 | Loss: 288.789 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1010/1194 | Loss: 293.743 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1020/1194 | Loss: 303.959 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 1030/1194 | Loss: 293.456 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1040/1194 | Loss: 304.466 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1050/1194 | Loss: 285.941 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1060/1194 | Loss: 310.435 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1070/1194 | Loss: 288.954 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1080/1194 | Loss: 316.887 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 1090/1194 | Loss: 288.416 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1100/1194 | Loss: 285.641 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1110/1194 | Loss: 298.755 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1120/1194 | Loss: 284.186 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1130/1194 | Loss: 290.778 | Accuracy: 0.500\n",
      "[Epoch: 45/200] - Step: 1140/1194 | Loss: 289.952 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 1150/1194 | Loss: 279.324 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1160/1194 | Loss: 274.317 | Accuracy: 0.200\n",
      "[Epoch: 45/200] - Step: 1170/1194 | Loss: 298.584 | Accuracy: 0.000\n",
      "[Epoch: 45/200] - Step: 1180/1194 | Loss: 301.711 | Accuracy: 0.100\n",
      "[Epoch: 45/200] - Step: 1190/1194 | Loss: 293.848 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 46/200] - Step: 10/1194 | Loss: 299.043 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 20/1194 | Loss: 303.026 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 30/1194 | Loss: 268.981 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 40/1194 | Loss: 309.737 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 50/1194 | Loss: 285.759 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 60/1194 | Loss: 299.283 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 70/1194 | Loss: 299.121 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 80/1194 | Loss: 292.205 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 90/1194 | Loss: 292.893 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 100/1194 | Loss: 291.761 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 110/1194 | Loss: 283.051 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 120/1194 | Loss: 299.306 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 130/1194 | Loss: 310.210 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 140/1194 | Loss: 307.161 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 150/1194 | Loss: 279.262 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 160/1194 | Loss: 299.681 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 170/1194 | Loss: 292.373 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 180/1194 | Loss: 298.698 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 190/1194 | Loss: 298.895 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 200/1194 | Loss: 301.510 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 210/1194 | Loss: 305.677 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 220/1194 | Loss: 283.759 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 230/1194 | Loss: 296.262 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 240/1194 | Loss: 285.937 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 250/1194 | Loss: 273.286 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 260/1194 | Loss: 303.310 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 270/1194 | Loss: 294.910 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 280/1194 | Loss: 289.330 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 290/1194 | Loss: 278.767 | Accuracy: 0.400\n",
      "[Epoch: 46/200] - Step: 300/1194 | Loss: 291.082 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 310/1194 | Loss: 305.240 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 320/1194 | Loss: 305.381 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 330/1194 | Loss: 294.207 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 340/1194 | Loss: 305.162 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 350/1194 | Loss: 340.504 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 360/1194 | Loss: 310.456 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 370/1194 | Loss: 289.562 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 380/1194 | Loss: 296.821 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 390/1194 | Loss: 277.543 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 400/1194 | Loss: 305.112 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 410/1194 | Loss: 306.260 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 420/1194 | Loss: 284.992 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 430/1194 | Loss: 291.520 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 440/1194 | Loss: 312.134 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 450/1194 | Loss: 309.057 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 460/1194 | Loss: 313.780 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 470/1194 | Loss: 294.633 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 480/1194 | Loss: 294.854 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 490/1194 | Loss: 301.446 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 500/1194 | Loss: 305.919 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 510/1194 | Loss: 291.471 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 520/1194 | Loss: 288.720 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 530/1194 | Loss: 314.569 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 540/1194 | Loss: 288.051 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 550/1194 | Loss: 299.145 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 560/1194 | Loss: 301.564 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 570/1194 | Loss: 280.487 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 580/1194 | Loss: 290.569 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 590/1194 | Loss: 282.987 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 600/1194 | Loss: 290.959 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 610/1194 | Loss: 293.346 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 620/1194 | Loss: 298.727 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 630/1194 | Loss: 304.579 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 640/1194 | Loss: 301.256 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 650/1194 | Loss: 297.949 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 660/1194 | Loss: 299.905 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 670/1194 | Loss: 284.354 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 680/1194 | Loss: 305.987 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 690/1194 | Loss: 303.321 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 700/1194 | Loss: 299.130 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 710/1194 | Loss: 302.748 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 720/1194 | Loss: 291.742 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 730/1194 | Loss: 305.001 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 740/1194 | Loss: 311.398 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 750/1194 | Loss: 290.746 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 760/1194 | Loss: 301.379 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 770/1194 | Loss: 280.757 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 780/1194 | Loss: 289.843 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 790/1194 | Loss: 277.710 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 800/1194 | Loss: 315.687 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 810/1194 | Loss: 288.100 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 820/1194 | Loss: 314.092 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 830/1194 | Loss: 294.206 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 840/1194 | Loss: 295.899 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 850/1194 | Loss: 298.936 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 860/1194 | Loss: 305.240 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 870/1194 | Loss: 268.958 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 880/1194 | Loss: 305.541 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 890/1194 | Loss: 289.997 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 900/1194 | Loss: 296.333 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 910/1194 | Loss: 277.824 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 920/1194 | Loss: 311.973 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 930/1194 | Loss: 306.037 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 940/1194 | Loss: 322.210 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 950/1194 | Loss: 308.547 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 960/1194 | Loss: 301.644 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 970/1194 | Loss: 291.569 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 980/1194 | Loss: 290.719 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 990/1194 | Loss: 298.902 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 1000/1194 | Loss: 295.615 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1010/1194 | Loss: 305.303 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1020/1194 | Loss: 304.680 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 1030/1194 | Loss: 309.971 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1040/1194 | Loss: 294.949 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1050/1194 | Loss: 288.410 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1060/1194 | Loss: 280.424 | Accuracy: 0.300\n",
      "[Epoch: 46/200] - Step: 1070/1194 | Loss: 284.251 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1080/1194 | Loss: 304.541 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1090/1194 | Loss: 297.646 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1100/1194 | Loss: 284.823 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1110/1194 | Loss: 301.324 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1120/1194 | Loss: 298.141 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1130/1194 | Loss: 282.520 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1140/1194 | Loss: 287.919 | Accuracy: 0.200\n",
      "[Epoch: 46/200] - Step: 1150/1194 | Loss: 331.105 | Accuracy: 0.000\n",
      "[Epoch: 46/200] - Step: 1160/1194 | Loss: 301.614 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1170/1194 | Loss: 326.772 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1180/1194 | Loss: 296.059 | Accuracy: 0.100\n",
      "[Epoch: 46/200] - Step: 1190/1194 | Loss: 296.001 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 47/200] - Step: 10/1194 | Loss: 310.126 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 20/1194 | Loss: 311.616 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 30/1194 | Loss: 273.476 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 40/1194 | Loss: 301.078 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 50/1194 | Loss: 286.870 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 60/1194 | Loss: 273.905 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 70/1194 | Loss: 290.070 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 80/1194 | Loss: 292.455 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 90/1194 | Loss: 313.481 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 100/1194 | Loss: 286.620 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 110/1194 | Loss: 312.796 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 120/1194 | Loss: 307.247 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 130/1194 | Loss: 285.242 | Accuracy: 0.500\n",
      "[Epoch: 47/200] - Step: 140/1194 | Loss: 293.371 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 150/1194 | Loss: 297.255 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 160/1194 | Loss: 315.624 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 170/1194 | Loss: 290.680 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 180/1194 | Loss: 278.245 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 190/1194 | Loss: 302.985 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 200/1194 | Loss: 282.226 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 210/1194 | Loss: 293.817 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 220/1194 | Loss: 300.341 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 230/1194 | Loss: 296.685 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 240/1194 | Loss: 304.948 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 250/1194 | Loss: 306.699 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 260/1194 | Loss: 326.415 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 270/1194 | Loss: 283.509 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 280/1194 | Loss: 289.587 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 290/1194 | Loss: 283.541 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 300/1194 | Loss: 291.475 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 310/1194 | Loss: 335.387 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 320/1194 | Loss: 303.152 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 330/1194 | Loss: 280.831 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 340/1194 | Loss: 301.135 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 350/1194 | Loss: 293.501 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 360/1194 | Loss: 294.004 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 370/1194 | Loss: 299.308 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 380/1194 | Loss: 292.974 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 390/1194 | Loss: 284.588 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 400/1194 | Loss: 308.936 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 410/1194 | Loss: 299.251 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 420/1194 | Loss: 284.574 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 430/1194 | Loss: 279.781 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 440/1194 | Loss: 289.166 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 450/1194 | Loss: 307.657 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 460/1194 | Loss: 338.592 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 470/1194 | Loss: 288.829 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 480/1194 | Loss: 294.046 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 490/1194 | Loss: 294.567 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 500/1194 | Loss: 302.694 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 510/1194 | Loss: 300.181 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 520/1194 | Loss: 290.532 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 530/1194 | Loss: 299.978 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 540/1194 | Loss: 309.674 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 550/1194 | Loss: 298.352 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 560/1194 | Loss: 310.425 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 570/1194 | Loss: 307.459 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 580/1194 | Loss: 304.392 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 590/1194 | Loss: 286.088 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 600/1194 | Loss: 298.162 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 610/1194 | Loss: 299.330 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 620/1194 | Loss: 298.922 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 630/1194 | Loss: 290.041 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 640/1194 | Loss: 289.897 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 650/1194 | Loss: 298.349 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 660/1194 | Loss: 293.615 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 670/1194 | Loss: 306.693 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 680/1194 | Loss: 302.378 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 690/1194 | Loss: 314.628 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 700/1194 | Loss: 292.759 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 710/1194 | Loss: 294.593 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 720/1194 | Loss: 281.934 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 730/1194 | Loss: 274.533 | Accuracy: 0.300\n",
      "[Epoch: 47/200] - Step: 740/1194 | Loss: 296.890 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 750/1194 | Loss: 290.705 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 760/1194 | Loss: 297.719 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 770/1194 | Loss: 291.908 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 780/1194 | Loss: 295.050 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 790/1194 | Loss: 307.271 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 800/1194 | Loss: 289.817 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 810/1194 | Loss: 290.183 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 820/1194 | Loss: 300.862 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 830/1194 | Loss: 305.024 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 840/1194 | Loss: 292.327 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 850/1194 | Loss: 324.515 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 860/1194 | Loss: 305.526 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 870/1194 | Loss: 310.466 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 880/1194 | Loss: 307.918 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 890/1194 | Loss: 313.722 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 900/1194 | Loss: 296.141 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 910/1194 | Loss: 285.398 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 920/1194 | Loss: 307.629 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 930/1194 | Loss: 315.550 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 940/1194 | Loss: 302.014 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 950/1194 | Loss: 311.480 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 960/1194 | Loss: 291.861 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 970/1194 | Loss: 295.026 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 980/1194 | Loss: 300.531 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 990/1194 | Loss: 295.203 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1000/1194 | Loss: 280.454 | Accuracy: 0.400\n",
      "[Epoch: 47/200] - Step: 1010/1194 | Loss: 290.981 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1020/1194 | Loss: 296.255 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1030/1194 | Loss: 288.880 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1040/1194 | Loss: 283.623 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1050/1194 | Loss: 286.425 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1060/1194 | Loss: 275.390 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1070/1194 | Loss: 290.878 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1080/1194 | Loss: 299.516 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1090/1194 | Loss: 300.776 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 1100/1194 | Loss: 309.066 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 1110/1194 | Loss: 293.876 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1120/1194 | Loss: 294.447 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1130/1194 | Loss: 289.733 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1140/1194 | Loss: 315.528 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 1150/1194 | Loss: 303.899 | Accuracy: 0.000\n",
      "[Epoch: 47/200] - Step: 1160/1194 | Loss: 290.229 | Accuracy: 0.100\n",
      "[Epoch: 47/200] - Step: 1170/1194 | Loss: 284.861 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1180/1194 | Loss: 295.610 | Accuracy: 0.200\n",
      "[Epoch: 47/200] - Step: 1190/1194 | Loss: 296.265 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 48/200] - Step: 10/1194 | Loss: 281.932 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 20/1194 | Loss: 287.976 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 30/1194 | Loss: 287.263 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 40/1194 | Loss: 293.818 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 50/1194 | Loss: 289.400 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 60/1194 | Loss: 284.267 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 70/1194 | Loss: 300.495 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 80/1194 | Loss: 293.526 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 90/1194 | Loss: 277.033 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 100/1194 | Loss: 296.704 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 110/1194 | Loss: 310.008 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 120/1194 | Loss: 285.365 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 130/1194 | Loss: 310.679 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 140/1194 | Loss: 331.225 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 150/1194 | Loss: 284.085 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 160/1194 | Loss: 298.017 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 170/1194 | Loss: 315.685 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 180/1194 | Loss: 299.946 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 190/1194 | Loss: 310.192 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 200/1194 | Loss: 296.502 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 210/1194 | Loss: 308.914 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 220/1194 | Loss: 281.564 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 230/1194 | Loss: 301.189 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 240/1194 | Loss: 302.738 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 250/1194 | Loss: 308.410 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 260/1194 | Loss: 299.812 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 270/1194 | Loss: 294.633 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 280/1194 | Loss: 290.729 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 290/1194 | Loss: 290.035 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 300/1194 | Loss: 305.257 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 310/1194 | Loss: 290.276 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 320/1194 | Loss: 290.284 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 330/1194 | Loss: 296.069 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 340/1194 | Loss: 284.699 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 350/1194 | Loss: 282.950 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 360/1194 | Loss: 300.362 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 370/1194 | Loss: 277.747 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 380/1194 | Loss: 280.259 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 390/1194 | Loss: 325.206 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 400/1194 | Loss: 293.180 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 410/1194 | Loss: 298.760 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 420/1194 | Loss: 286.376 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 430/1194 | Loss: 296.845 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 440/1194 | Loss: 306.422 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 450/1194 | Loss: 297.777 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 460/1194 | Loss: 291.020 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 470/1194 | Loss: 302.341 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 480/1194 | Loss: 287.096 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 490/1194 | Loss: 282.375 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 500/1194 | Loss: 297.910 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 510/1194 | Loss: 279.156 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 520/1194 | Loss: 295.140 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 530/1194 | Loss: 302.266 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 540/1194 | Loss: 321.854 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 550/1194 | Loss: 294.237 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 560/1194 | Loss: 284.203 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 570/1194 | Loss: 301.281 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 580/1194 | Loss: 303.313 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 590/1194 | Loss: 294.557 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 600/1194 | Loss: 293.916 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 610/1194 | Loss: 293.284 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 620/1194 | Loss: 305.985 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 630/1194 | Loss: 303.039 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 640/1194 | Loss: 300.016 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 650/1194 | Loss: 291.164 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 660/1194 | Loss: 307.748 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 670/1194 | Loss: 277.972 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 680/1194 | Loss: 297.878 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 690/1194 | Loss: 309.231 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 700/1194 | Loss: 291.680 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 710/1194 | Loss: 318.615 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 720/1194 | Loss: 298.013 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 730/1194 | Loss: 304.462 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 740/1194 | Loss: 297.013 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 750/1194 | Loss: 308.213 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 760/1194 | Loss: 306.870 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 770/1194 | Loss: 302.177 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 780/1194 | Loss: 293.595 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 790/1194 | Loss: 301.581 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 800/1194 | Loss: 297.475 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 810/1194 | Loss: 297.442 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 820/1194 | Loss: 307.644 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 830/1194 | Loss: 296.530 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 840/1194 | Loss: 305.340 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 850/1194 | Loss: 290.668 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 860/1194 | Loss: 303.060 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 870/1194 | Loss: 284.512 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 880/1194 | Loss: 283.457 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 890/1194 | Loss: 301.341 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 900/1194 | Loss: 292.615 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 910/1194 | Loss: 306.327 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 920/1194 | Loss: 302.527 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 930/1194 | Loss: 280.178 | Accuracy: 0.400\n",
      "[Epoch: 48/200] - Step: 940/1194 | Loss: 305.018 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 950/1194 | Loss: 313.602 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 960/1194 | Loss: 293.651 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 970/1194 | Loss: 321.722 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 980/1194 | Loss: 281.955 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 990/1194 | Loss: 298.534 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1000/1194 | Loss: 296.755 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1010/1194 | Loss: 301.551 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1020/1194 | Loss: 299.551 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1030/1194 | Loss: 294.529 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1040/1194 | Loss: 305.456 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1050/1194 | Loss: 294.683 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1060/1194 | Loss: 279.082 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1070/1194 | Loss: 307.451 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1080/1194 | Loss: 308.492 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1090/1194 | Loss: 305.313 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1100/1194 | Loss: 286.876 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1110/1194 | Loss: 279.345 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1120/1194 | Loss: 304.914 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1130/1194 | Loss: 292.843 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1140/1194 | Loss: 280.434 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1150/1194 | Loss: 342.141 | Accuracy: 0.000\n",
      "[Epoch: 48/200] - Step: 1160/1194 | Loss: 293.150 | Accuracy: 0.200\n",
      "[Epoch: 48/200] - Step: 1170/1194 | Loss: 285.782 | Accuracy: 0.300\n",
      "[Epoch: 48/200] - Step: 1180/1194 | Loss: 297.797 | Accuracy: 0.100\n",
      "[Epoch: 48/200] - Step: 1190/1194 | Loss: 299.889 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 49/200] - Step: 10/1194 | Loss: 285.494 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 20/1194 | Loss: 292.537 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 30/1194 | Loss: 291.864 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 40/1194 | Loss: 273.520 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 50/1194 | Loss: 326.585 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 60/1194 | Loss: 297.528 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 70/1194 | Loss: 306.713 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 80/1194 | Loss: 313.252 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 90/1194 | Loss: 291.120 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 100/1194 | Loss: 299.747 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 110/1194 | Loss: 301.719 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 120/1194 | Loss: 297.231 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 130/1194 | Loss: 296.423 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 140/1194 | Loss: 290.438 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 150/1194 | Loss: 306.323 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 160/1194 | Loss: 304.624 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 170/1194 | Loss: 300.613 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 180/1194 | Loss: 296.922 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 190/1194 | Loss: 295.585 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 200/1194 | Loss: 296.132 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 210/1194 | Loss: 282.770 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 220/1194 | Loss: 305.488 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 230/1194 | Loss: 303.222 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 240/1194 | Loss: 297.067 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 250/1194 | Loss: 306.293 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 260/1194 | Loss: 352.354 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 270/1194 | Loss: 326.309 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 280/1194 | Loss: 295.775 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 290/1194 | Loss: 294.462 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 300/1194 | Loss: 301.253 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 310/1194 | Loss: 299.909 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 320/1194 | Loss: 295.515 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 330/1194 | Loss: 302.097 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 340/1194 | Loss: 293.164 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 350/1194 | Loss: 302.382 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 360/1194 | Loss: 286.737 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 370/1194 | Loss: 295.091 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 380/1194 | Loss: 303.379 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 390/1194 | Loss: 282.667 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 400/1194 | Loss: 291.764 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 410/1194 | Loss: 292.991 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 420/1194 | Loss: 288.282 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 430/1194 | Loss: 296.579 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 440/1194 | Loss: 284.077 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 450/1194 | Loss: 310.693 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 460/1194 | Loss: 306.531 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 470/1194 | Loss: 295.597 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 480/1194 | Loss: 281.712 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 490/1194 | Loss: 302.694 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 500/1194 | Loss: 294.976 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 510/1194 | Loss: 284.444 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 520/1194 | Loss: 317.595 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 530/1194 | Loss: 291.676 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 540/1194 | Loss: 292.950 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 550/1194 | Loss: 291.202 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 560/1194 | Loss: 286.006 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 570/1194 | Loss: 312.282 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 580/1194 | Loss: 309.123 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 590/1194 | Loss: 284.670 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 600/1194 | Loss: 274.551 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 610/1194 | Loss: 288.667 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 620/1194 | Loss: 300.092 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 630/1194 | Loss: 310.120 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 640/1194 | Loss: 296.036 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 650/1194 | Loss: 297.463 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 660/1194 | Loss: 308.267 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 670/1194 | Loss: 302.721 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 680/1194 | Loss: 289.809 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 690/1194 | Loss: 294.141 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 700/1194 | Loss: 291.507 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 710/1194 | Loss: 293.639 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 720/1194 | Loss: 283.128 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 730/1194 | Loss: 324.666 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 740/1194 | Loss: 289.639 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 750/1194 | Loss: 290.007 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 760/1194 | Loss: 303.931 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 770/1194 | Loss: 285.318 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 780/1194 | Loss: 289.481 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 790/1194 | Loss: 326.455 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 800/1194 | Loss: 303.342 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 810/1194 | Loss: 295.392 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 820/1194 | Loss: 306.587 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 830/1194 | Loss: 323.193 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 840/1194 | Loss: 284.793 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 850/1194 | Loss: 304.179 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 860/1194 | Loss: 300.626 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 870/1194 | Loss: 272.715 | Accuracy: 0.400\n",
      "[Epoch: 49/200] - Step: 880/1194 | Loss: 293.045 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 890/1194 | Loss: 303.851 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 900/1194 | Loss: 299.883 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 910/1194 | Loss: 294.941 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 920/1194 | Loss: 300.854 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 930/1194 | Loss: 280.415 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 940/1194 | Loss: 299.905 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 950/1194 | Loss: 301.816 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 960/1194 | Loss: 288.010 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 970/1194 | Loss: 287.325 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 980/1194 | Loss: 275.136 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 990/1194 | Loss: 276.413 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1000/1194 | Loss: 309.909 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1010/1194 | Loss: 291.607 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1020/1194 | Loss: 296.160 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1030/1194 | Loss: 317.965 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1040/1194 | Loss: 289.112 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1050/1194 | Loss: 295.593 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1060/1194 | Loss: 303.440 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1070/1194 | Loss: 302.822 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1080/1194 | Loss: 309.307 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1090/1194 | Loss: 293.969 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1100/1194 | Loss: 295.944 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1110/1194 | Loss: 296.599 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1120/1194 | Loss: 296.124 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1130/1194 | Loss: 320.219 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1140/1194 | Loss: 299.816 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1150/1194 | Loss: 280.373 | Accuracy: 0.300\n",
      "[Epoch: 49/200] - Step: 1160/1194 | Loss: 303.188 | Accuracy: 0.100\n",
      "[Epoch: 49/200] - Step: 1170/1194 | Loss: 283.537 | Accuracy: 0.200\n",
      "[Epoch: 49/200] - Step: 1180/1194 | Loss: 310.120 | Accuracy: 0.000\n",
      "[Epoch: 49/200] - Step: 1190/1194 | Loss: 293.473 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 50/200] - Step: 10/1194 | Loss: 300.265 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 20/1194 | Loss: 313.392 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 30/1194 | Loss: 305.815 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 40/1194 | Loss: 300.059 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 50/1194 | Loss: 332.871 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 60/1194 | Loss: 285.665 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 70/1194 | Loss: 292.361 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 80/1194 | Loss: 294.418 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 90/1194 | Loss: 303.778 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 100/1194 | Loss: 304.508 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 110/1194 | Loss: 304.663 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 120/1194 | Loss: 290.705 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 130/1194 | Loss: 304.642 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 140/1194 | Loss: 304.656 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 150/1194 | Loss: 292.500 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 160/1194 | Loss: 295.219 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 170/1194 | Loss: 307.101 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 180/1194 | Loss: 298.639 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 190/1194 | Loss: 297.488 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 200/1194 | Loss: 289.524 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 210/1194 | Loss: 284.204 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 220/1194 | Loss: 306.756 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 230/1194 | Loss: 305.502 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 240/1194 | Loss: 300.388 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 250/1194 | Loss: 311.201 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 260/1194 | Loss: 286.911 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 270/1194 | Loss: 307.679 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 280/1194 | Loss: 288.686 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 290/1194 | Loss: 284.548 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 300/1194 | Loss: 299.474 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 310/1194 | Loss: 302.460 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 320/1194 | Loss: 301.150 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 330/1194 | Loss: 288.689 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 340/1194 | Loss: 296.360 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 350/1194 | Loss: 283.209 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 360/1194 | Loss: 257.770 | Accuracy: 0.500\n",
      "[Epoch: 50/200] - Step: 370/1194 | Loss: 293.723 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 380/1194 | Loss: 305.951 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 390/1194 | Loss: 304.673 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 400/1194 | Loss: 285.387 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 410/1194 | Loss: 286.155 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 420/1194 | Loss: 308.209 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 430/1194 | Loss: 304.480 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 440/1194 | Loss: 304.826 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 450/1194 | Loss: 296.242 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 460/1194 | Loss: 280.037 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 470/1194 | Loss: 300.672 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 480/1194 | Loss: 290.447 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 490/1194 | Loss: 298.381 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 500/1194 | Loss: 307.965 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 510/1194 | Loss: 296.770 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 520/1194 | Loss: 297.556 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 530/1194 | Loss: 299.952 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 540/1194 | Loss: 276.730 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 550/1194 | Loss: 301.845 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 560/1194 | Loss: 302.416 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 570/1194 | Loss: 271.977 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 580/1194 | Loss: 297.453 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 590/1194 | Loss: 336.945 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 600/1194 | Loss: 310.386 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 610/1194 | Loss: 278.536 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 620/1194 | Loss: 290.728 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 630/1194 | Loss: 282.073 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 640/1194 | Loss: 280.555 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 650/1194 | Loss: 295.630 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 660/1194 | Loss: 306.543 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 670/1194 | Loss: 322.016 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 680/1194 | Loss: 283.681 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 690/1194 | Loss: 286.812 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 700/1194 | Loss: 287.071 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 710/1194 | Loss: 285.767 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 720/1194 | Loss: 270.441 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 730/1194 | Loss: 305.744 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 740/1194 | Loss: 305.732 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 750/1194 | Loss: 307.971 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 760/1194 | Loss: 309.078 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 770/1194 | Loss: 295.514 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 780/1194 | Loss: 313.327 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 790/1194 | Loss: 271.737 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 800/1194 | Loss: 302.214 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 810/1194 | Loss: 292.478 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 820/1194 | Loss: 297.602 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 830/1194 | Loss: 310.704 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 840/1194 | Loss: 307.968 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 850/1194 | Loss: 316.249 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 860/1194 | Loss: 292.572 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 870/1194 | Loss: 293.421 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 880/1194 | Loss: 314.911 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 890/1194 | Loss: 297.377 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 900/1194 | Loss: 286.390 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 910/1194 | Loss: 276.669 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 920/1194 | Loss: 293.948 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 930/1194 | Loss: 304.781 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 940/1194 | Loss: 309.908 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 950/1194 | Loss: 281.620 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 960/1194 | Loss: 276.604 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 970/1194 | Loss: 312.313 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 980/1194 | Loss: 270.564 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 990/1194 | Loss: 300.220 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1000/1194 | Loss: 297.998 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1010/1194 | Loss: 316.940 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1020/1194 | Loss: 304.214 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1030/1194 | Loss: 301.180 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1040/1194 | Loss: 287.181 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1050/1194 | Loss: 275.150 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1060/1194 | Loss: 282.064 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1070/1194 | Loss: 289.947 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1080/1194 | Loss: 317.246 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1090/1194 | Loss: 275.874 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1100/1194 | Loss: 279.642 | Accuracy: 0.300\n",
      "[Epoch: 50/200] - Step: 1110/1194 | Loss: 314.510 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1120/1194 | Loss: 300.207 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1130/1194 | Loss: 295.267 | Accuracy: 0.200\n",
      "[Epoch: 50/200] - Step: 1140/1194 | Loss: 297.448 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1150/1194 | Loss: 308.449 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1160/1194 | Loss: 323.692 | Accuracy: 0.100\n",
      "[Epoch: 50/200] - Step: 1170/1194 | Loss: 309.717 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1180/1194 | Loss: 307.224 | Accuracy: 0.000\n",
      "[Epoch: 50/200] - Step: 1190/1194 | Loss: 292.133 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 51/200] - Step: 10/1194 | Loss: 304.968 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 20/1194 | Loss: 305.460 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 30/1194 | Loss: 291.967 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 40/1194 | Loss: 286.723 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 50/1194 | Loss: 310.146 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 60/1194 | Loss: 282.780 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 70/1194 | Loss: 298.284 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 80/1194 | Loss: 304.123 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 90/1194 | Loss: 297.196 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 100/1194 | Loss: 308.849 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 110/1194 | Loss: 289.802 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 120/1194 | Loss: 298.238 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 130/1194 | Loss: 305.958 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 140/1194 | Loss: 294.536 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 150/1194 | Loss: 288.066 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 160/1194 | Loss: 302.253 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 170/1194 | Loss: 306.720 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 180/1194 | Loss: 298.492 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 190/1194 | Loss: 306.028 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 200/1194 | Loss: 296.279 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 210/1194 | Loss: 304.767 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 220/1194 | Loss: 307.091 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 230/1194 | Loss: 309.819 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 240/1194 | Loss: 298.361 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 250/1194 | Loss: 297.219 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 260/1194 | Loss: 295.744 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 270/1194 | Loss: 293.859 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 280/1194 | Loss: 300.051 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 290/1194 | Loss: 292.443 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 300/1194 | Loss: 294.602 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 310/1194 | Loss: 303.927 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 320/1194 | Loss: 289.729 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 330/1194 | Loss: 302.071 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 340/1194 | Loss: 304.964 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 350/1194 | Loss: 306.595 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 360/1194 | Loss: 312.359 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 370/1194 | Loss: 290.684 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 380/1194 | Loss: 307.033 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 390/1194 | Loss: 307.793 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 400/1194 | Loss: 281.090 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 410/1194 | Loss: 291.910 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 420/1194 | Loss: 291.929 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 430/1194 | Loss: 290.274 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 440/1194 | Loss: 288.049 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 450/1194 | Loss: 287.330 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 460/1194 | Loss: 329.333 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 470/1194 | Loss: 301.963 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 480/1194 | Loss: 279.845 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 490/1194 | Loss: 292.634 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 500/1194 | Loss: 301.082 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 510/1194 | Loss: 293.978 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 520/1194 | Loss: 290.674 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 530/1194 | Loss: 300.738 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 540/1194 | Loss: 288.996 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 550/1194 | Loss: 291.149 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 560/1194 | Loss: 299.352 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 570/1194 | Loss: 314.371 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 580/1194 | Loss: 297.388 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 590/1194 | Loss: 284.338 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 600/1194 | Loss: 306.623 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 610/1194 | Loss: 305.068 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 620/1194 | Loss: 311.728 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 630/1194 | Loss: 300.273 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 640/1194 | Loss: 299.876 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 650/1194 | Loss: 278.502 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 660/1194 | Loss: 288.425 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 670/1194 | Loss: 297.313 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 680/1194 | Loss: 293.140 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 690/1194 | Loss: 298.123 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 700/1194 | Loss: 324.331 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 710/1194 | Loss: 306.342 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 720/1194 | Loss: 305.708 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 730/1194 | Loss: 321.453 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 740/1194 | Loss: 307.559 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 750/1194 | Loss: 283.487 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 760/1194 | Loss: 311.434 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 770/1194 | Loss: 293.236 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 780/1194 | Loss: 302.017 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 790/1194 | Loss: 279.470 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 800/1194 | Loss: 294.047 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 810/1194 | Loss: 279.265 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 820/1194 | Loss: 306.053 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 830/1194 | Loss: 319.304 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 840/1194 | Loss: 288.100 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 850/1194 | Loss: 291.849 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 860/1194 | Loss: 295.796 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 870/1194 | Loss: 298.102 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 880/1194 | Loss: 287.265 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 890/1194 | Loss: 301.270 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 900/1194 | Loss: 289.484 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 910/1194 | Loss: 281.559 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 920/1194 | Loss: 299.905 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 930/1194 | Loss: 279.267 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 940/1194 | Loss: 282.957 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 950/1194 | Loss: 297.521 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 960/1194 | Loss: 281.737 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 970/1194 | Loss: 282.308 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 980/1194 | Loss: 298.569 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 990/1194 | Loss: 273.446 | Accuracy: 0.300\n",
      "[Epoch: 51/200] - Step: 1000/1194 | Loss: 291.434 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1010/1194 | Loss: 293.473 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1020/1194 | Loss: 272.111 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1030/1194 | Loss: 297.485 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1040/1194 | Loss: 318.690 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 1050/1194 | Loss: 311.579 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 1060/1194 | Loss: 284.776 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1070/1194 | Loss: 304.739 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1080/1194 | Loss: 282.585 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1090/1194 | Loss: 297.847 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1100/1194 | Loss: 306.702 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1110/1194 | Loss: 299.662 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1120/1194 | Loss: 293.462 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1130/1194 | Loss: 304.341 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 1140/1194 | Loss: 308.256 | Accuracy: 0.000\n",
      "[Epoch: 51/200] - Step: 1150/1194 | Loss: 286.846 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1160/1194 | Loss: 332.102 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1170/1194 | Loss: 275.907 | Accuracy: 0.200\n",
      "[Epoch: 51/200] - Step: 1180/1194 | Loss: 298.510 | Accuracy: 0.100\n",
      "[Epoch: 51/200] - Step: 1190/1194 | Loss: 294.137 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 52/200] - Step: 10/1194 | Loss: 310.126 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 20/1194 | Loss: 303.272 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 30/1194 | Loss: 275.136 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 40/1194 | Loss: 288.827 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 50/1194 | Loss: 295.773 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 60/1194 | Loss: 298.823 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 70/1194 | Loss: 285.680 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 80/1194 | Loss: 272.183 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 90/1194 | Loss: 301.359 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 100/1194 | Loss: 265.122 | Accuracy: 0.400\n",
      "[Epoch: 52/200] - Step: 110/1194 | Loss: 307.300 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 120/1194 | Loss: 281.086 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 130/1194 | Loss: 312.232 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 140/1194 | Loss: 288.169 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 150/1194 | Loss: 307.096 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 160/1194 | Loss: 283.429 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 170/1194 | Loss: 289.594 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 180/1194 | Loss: 285.937 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 190/1194 | Loss: 292.067 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 200/1194 | Loss: 303.327 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 210/1194 | Loss: 294.614 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 220/1194 | Loss: 294.121 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 230/1194 | Loss: 309.089 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 240/1194 | Loss: 283.876 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 250/1194 | Loss: 290.964 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 260/1194 | Loss: 307.667 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 270/1194 | Loss: 291.303 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 280/1194 | Loss: 291.436 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 290/1194 | Loss: 333.040 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 300/1194 | Loss: 287.741 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 310/1194 | Loss: 285.594 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 320/1194 | Loss: 301.391 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 330/1194 | Loss: 311.173 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 340/1194 | Loss: 299.190 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 350/1194 | Loss: 292.010 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 360/1194 | Loss: 287.751 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 370/1194 | Loss: 295.953 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 380/1194 | Loss: 339.293 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 390/1194 | Loss: 298.924 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 400/1194 | Loss: 283.519 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 410/1194 | Loss: 342.519 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 420/1194 | Loss: 284.497 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 430/1194 | Loss: 296.690 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 440/1194 | Loss: 290.131 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 450/1194 | Loss: 283.370 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 460/1194 | Loss: 288.361 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 470/1194 | Loss: 305.793 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 480/1194 | Loss: 310.468 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 490/1194 | Loss: 297.244 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 500/1194 | Loss: 297.651 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 510/1194 | Loss: 291.803 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 520/1194 | Loss: 277.913 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 530/1194 | Loss: 289.356 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 540/1194 | Loss: 284.013 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 550/1194 | Loss: 290.359 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 560/1194 | Loss: 303.657 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 570/1194 | Loss: 299.322 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 580/1194 | Loss: 297.365 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 590/1194 | Loss: 306.320 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 600/1194 | Loss: 306.878 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 610/1194 | Loss: 294.353 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 620/1194 | Loss: 300.239 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 630/1194 | Loss: 291.926 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 640/1194 | Loss: 311.235 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 650/1194 | Loss: 285.647 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 660/1194 | Loss: 307.099 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 670/1194 | Loss: 285.577 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 680/1194 | Loss: 299.553 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 690/1194 | Loss: 293.034 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 700/1194 | Loss: 291.252 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 710/1194 | Loss: 304.554 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 720/1194 | Loss: 302.740 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 730/1194 | Loss: 300.174 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 740/1194 | Loss: 293.600 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 750/1194 | Loss: 301.512 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 760/1194 | Loss: 292.426 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 770/1194 | Loss: 291.272 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 780/1194 | Loss: 311.471 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 790/1194 | Loss: 289.931 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 800/1194 | Loss: 304.326 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 810/1194 | Loss: 296.629 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 820/1194 | Loss: 300.720 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 830/1194 | Loss: 305.726 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 840/1194 | Loss: 299.392 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 850/1194 | Loss: 287.401 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 860/1194 | Loss: 306.672 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 870/1194 | Loss: 285.455 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 880/1194 | Loss: 294.028 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 890/1194 | Loss: 288.303 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 900/1194 | Loss: 289.663 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 910/1194 | Loss: 280.810 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 920/1194 | Loss: 295.637 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 930/1194 | Loss: 305.579 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 940/1194 | Loss: 302.352 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 950/1194 | Loss: 289.885 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 960/1194 | Loss: 299.361 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 970/1194 | Loss: 298.007 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 980/1194 | Loss: 324.623 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 990/1194 | Loss: 282.611 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1000/1194 | Loss: 304.003 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1010/1194 | Loss: 302.264 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1020/1194 | Loss: 311.023 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1030/1194 | Loss: 296.943 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1040/1194 | Loss: 297.802 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1050/1194 | Loss: 287.016 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1060/1194 | Loss: 280.116 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1070/1194 | Loss: 305.172 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1080/1194 | Loss: 298.743 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1090/1194 | Loss: 341.955 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1100/1194 | Loss: 286.445 | Accuracy: 0.200\n",
      "[Epoch: 52/200] - Step: 1110/1194 | Loss: 300.222 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1120/1194 | Loss: 307.742 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1130/1194 | Loss: 317.057 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1140/1194 | Loss: 299.634 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1150/1194 | Loss: 286.489 | Accuracy: 0.300\n",
      "[Epoch: 52/200] - Step: 1160/1194 | Loss: 300.972 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1170/1194 | Loss: 302.106 | Accuracy: 0.000\n",
      "[Epoch: 52/200] - Step: 1180/1194 | Loss: 291.542 | Accuracy: 0.100\n",
      "[Epoch: 52/200] - Step: 1190/1194 | Loss: 307.329 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 53/200] - Step: 10/1194 | Loss: 291.013 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 20/1194 | Loss: 287.394 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 30/1194 | Loss: 298.072 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 40/1194 | Loss: 293.942 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 50/1194 | Loss: 295.212 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 60/1194 | Loss: 297.308 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 70/1194 | Loss: 305.256 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 80/1194 | Loss: 298.948 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 90/1194 | Loss: 309.887 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 100/1194 | Loss: 304.281 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 110/1194 | Loss: 305.755 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 120/1194 | Loss: 302.538 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 130/1194 | Loss: 297.187 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 140/1194 | Loss: 297.355 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 150/1194 | Loss: 300.520 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 160/1194 | Loss: 307.306 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 170/1194 | Loss: 290.025 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 180/1194 | Loss: 285.300 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 190/1194 | Loss: 303.679 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 200/1194 | Loss: 299.192 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 210/1194 | Loss: 299.347 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 220/1194 | Loss: 300.616 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 230/1194 | Loss: 294.063 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 240/1194 | Loss: 322.197 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 250/1194 | Loss: 304.746 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 260/1194 | Loss: 287.609 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 270/1194 | Loss: 283.049 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 280/1194 | Loss: 293.979 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 290/1194 | Loss: 298.104 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 300/1194 | Loss: 294.566 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 310/1194 | Loss: 293.795 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 320/1194 | Loss: 299.161 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 330/1194 | Loss: 280.729 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 340/1194 | Loss: 305.035 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 350/1194 | Loss: 289.150 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 360/1194 | Loss: 317.151 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 370/1194 | Loss: 315.049 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 380/1194 | Loss: 289.766 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 390/1194 | Loss: 284.524 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 400/1194 | Loss: 301.545 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 410/1194 | Loss: 292.996 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 420/1194 | Loss: 296.375 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 430/1194 | Loss: 295.370 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 440/1194 | Loss: 296.982 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 450/1194 | Loss: 298.346 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 460/1194 | Loss: 298.897 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 470/1194 | Loss: 295.403 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 480/1194 | Loss: 303.790 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 490/1194 | Loss: 292.430 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 500/1194 | Loss: 293.571 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 510/1194 | Loss: 295.634 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 520/1194 | Loss: 308.452 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 530/1194 | Loss: 276.633 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 540/1194 | Loss: 297.542 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 550/1194 | Loss: 312.294 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 560/1194 | Loss: 279.998 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 570/1194 | Loss: 291.455 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 580/1194 | Loss: 306.576 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 590/1194 | Loss: 280.909 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 600/1194 | Loss: 287.919 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 610/1194 | Loss: 289.043 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 620/1194 | Loss: 278.223 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 630/1194 | Loss: 311.667 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 640/1194 | Loss: 305.902 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 650/1194 | Loss: 286.930 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 660/1194 | Loss: 297.396 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 670/1194 | Loss: 276.491 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 680/1194 | Loss: 302.659 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 690/1194 | Loss: 298.035 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 700/1194 | Loss: 276.360 | Accuracy: 0.400\n",
      "[Epoch: 53/200] - Step: 710/1194 | Loss: 295.473 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 720/1194 | Loss: 273.267 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 730/1194 | Loss: 286.327 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 740/1194 | Loss: 295.761 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 750/1194 | Loss: 277.154 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 760/1194 | Loss: 316.824 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 770/1194 | Loss: 312.599 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 780/1194 | Loss: 284.416 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 790/1194 | Loss: 293.755 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 800/1194 | Loss: 321.149 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 810/1194 | Loss: 299.764 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 820/1194 | Loss: 280.106 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 830/1194 | Loss: 297.809 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 840/1194 | Loss: 289.068 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 850/1194 | Loss: 278.567 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 860/1194 | Loss: 331.030 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 870/1194 | Loss: 299.409 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 880/1194 | Loss: 290.191 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 890/1194 | Loss: 307.923 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 900/1194 | Loss: 295.604 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 910/1194 | Loss: 289.642 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 920/1194 | Loss: 301.591 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 930/1194 | Loss: 314.729 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 940/1194 | Loss: 281.251 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 950/1194 | Loss: 290.482 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 960/1194 | Loss: 305.192 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 970/1194 | Loss: 297.048 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 980/1194 | Loss: 295.408 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 990/1194 | Loss: 303.377 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 1000/1194 | Loss: 323.748 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1010/1194 | Loss: 282.431 | Accuracy: 0.200\n",
      "[Epoch: 53/200] - Step: 1020/1194 | Loss: 298.642 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1030/1194 | Loss: 288.805 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1040/1194 | Loss: 308.090 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 1050/1194 | Loss: 293.835 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1060/1194 | Loss: 299.137 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1070/1194 | Loss: 289.233 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1080/1194 | Loss: 300.947 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 1090/1194 | Loss: 295.552 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1100/1194 | Loss: 322.901 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1110/1194 | Loss: 321.800 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 1120/1194 | Loss: 285.422 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1130/1194 | Loss: 301.988 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1140/1194 | Loss: 288.813 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1150/1194 | Loss: 300.782 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1160/1194 | Loss: 305.241 | Accuracy: 0.100\n",
      "[Epoch: 53/200] - Step: 1170/1194 | Loss: 282.253 | Accuracy: 0.300\n",
      "[Epoch: 53/200] - Step: 1180/1194 | Loss: 308.301 | Accuracy: 0.000\n",
      "[Epoch: 53/200] - Step: 1190/1194 | Loss: 301.017 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 54/200] - Step: 10/1194 | Loss: 300.545 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 20/1194 | Loss: 291.262 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 30/1194 | Loss: 295.366 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 40/1194 | Loss: 294.812 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 50/1194 | Loss: 306.944 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 60/1194 | Loss: 306.669 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 70/1194 | Loss: 280.050 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 80/1194 | Loss: 288.004 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 90/1194 | Loss: 310.348 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 100/1194 | Loss: 302.645 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 110/1194 | Loss: 307.442 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 120/1194 | Loss: 314.837 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 130/1194 | Loss: 300.268 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 140/1194 | Loss: 300.056 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 150/1194 | Loss: 296.126 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 160/1194 | Loss: 305.504 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 170/1194 | Loss: 300.154 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 180/1194 | Loss: 306.755 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 190/1194 | Loss: 284.804 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 200/1194 | Loss: 287.167 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 210/1194 | Loss: 310.059 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 220/1194 | Loss: 275.966 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 230/1194 | Loss: 308.835 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 240/1194 | Loss: 275.913 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 250/1194 | Loss: 325.391 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 260/1194 | Loss: 275.908 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 270/1194 | Loss: 306.949 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 280/1194 | Loss: 295.620 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 290/1194 | Loss: 296.552 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 300/1194 | Loss: 294.742 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 310/1194 | Loss: 290.825 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 320/1194 | Loss: 327.360 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 330/1194 | Loss: 290.365 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 340/1194 | Loss: 302.963 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 350/1194 | Loss: 306.427 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 360/1194 | Loss: 286.784 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 370/1194 | Loss: 301.616 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 380/1194 | Loss: 292.013 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 390/1194 | Loss: 286.286 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 400/1194 | Loss: 304.175 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 410/1194 | Loss: 302.122 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 420/1194 | Loss: 294.521 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 430/1194 | Loss: 294.751 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 440/1194 | Loss: 305.752 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 450/1194 | Loss: 310.809 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 460/1194 | Loss: 289.453 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 470/1194 | Loss: 308.813 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 480/1194 | Loss: 280.748 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 490/1194 | Loss: 299.093 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 500/1194 | Loss: 285.128 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 510/1194 | Loss: 300.626 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 520/1194 | Loss: 305.497 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 530/1194 | Loss: 304.846 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 540/1194 | Loss: 305.183 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 550/1194 | Loss: 293.093 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 560/1194 | Loss: 293.719 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 570/1194 | Loss: 263.424 | Accuracy: 0.500\n",
      "[Epoch: 54/200] - Step: 580/1194 | Loss: 297.845 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 590/1194 | Loss: 296.663 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 600/1194 | Loss: 292.858 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 610/1194 | Loss: 293.429 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 620/1194 | Loss: 279.725 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 630/1194 | Loss: 293.415 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 640/1194 | Loss: 313.332 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 650/1194 | Loss: 286.427 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 660/1194 | Loss: 297.813 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 670/1194 | Loss: 303.884 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 680/1194 | Loss: 286.004 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 690/1194 | Loss: 288.745 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 700/1194 | Loss: 295.746 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 710/1194 | Loss: 294.160 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 720/1194 | Loss: 292.960 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 730/1194 | Loss: 286.927 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 740/1194 | Loss: 279.708 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 750/1194 | Loss: 323.493 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 760/1194 | Loss: 313.288 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 770/1194 | Loss: 303.877 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 780/1194 | Loss: 315.250 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 790/1194 | Loss: 292.141 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 800/1194 | Loss: 305.698 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 810/1194 | Loss: 272.378 | Accuracy: 0.400\n",
      "[Epoch: 54/200] - Step: 820/1194 | Loss: 292.544 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 830/1194 | Loss: 289.149 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 840/1194 | Loss: 310.313 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 850/1194 | Loss: 311.721 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 860/1194 | Loss: 286.464 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 870/1194 | Loss: 311.662 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 880/1194 | Loss: 296.574 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 890/1194 | Loss: 279.992 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 900/1194 | Loss: 274.156 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 910/1194 | Loss: 275.579 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 920/1194 | Loss: 293.827 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 930/1194 | Loss: 310.639 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 940/1194 | Loss: 288.933 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 950/1194 | Loss: 272.356 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 960/1194 | Loss: 293.982 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 970/1194 | Loss: 304.225 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 980/1194 | Loss: 325.150 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 990/1194 | Loss: 321.177 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1000/1194 | Loss: 300.349 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1010/1194 | Loss: 300.129 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1020/1194 | Loss: 303.109 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1030/1194 | Loss: 282.140 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1040/1194 | Loss: 277.878 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1050/1194 | Loss: 313.018 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1060/1194 | Loss: 289.375 | Accuracy: 0.300\n",
      "[Epoch: 54/200] - Step: 1070/1194 | Loss: 288.155 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1080/1194 | Loss: 281.628 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1090/1194 | Loss: 303.344 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1100/1194 | Loss: 292.095 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1110/1194 | Loss: 284.288 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1120/1194 | Loss: 306.839 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1130/1194 | Loss: 329.150 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1140/1194 | Loss: 292.130 | Accuracy: 0.200\n",
      "[Epoch: 54/200] - Step: 1150/1194 | Loss: 298.103 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1160/1194 | Loss: 333.128 | Accuracy: 0.000\n",
      "[Epoch: 54/200] - Step: 1170/1194 | Loss: 292.380 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1180/1194 | Loss: 301.273 | Accuracy: 0.100\n",
      "[Epoch: 54/200] - Step: 1190/1194 | Loss: 286.867 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 55/200] - Step: 10/1194 | Loss: 287.144 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 20/1194 | Loss: 290.702 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 30/1194 | Loss: 305.493 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 40/1194 | Loss: 296.796 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 50/1194 | Loss: 302.845 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 60/1194 | Loss: 310.333 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 70/1194 | Loss: 294.453 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 80/1194 | Loss: 310.523 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 90/1194 | Loss: 286.197 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 100/1194 | Loss: 299.323 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 110/1194 | Loss: 290.977 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 120/1194 | Loss: 317.924 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 130/1194 | Loss: 295.608 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 140/1194 | Loss: 288.223 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 150/1194 | Loss: 286.897 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 160/1194 | Loss: 309.742 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 170/1194 | Loss: 293.201 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 180/1194 | Loss: 283.123 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 190/1194 | Loss: 288.545 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 200/1194 | Loss: 287.984 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 210/1194 | Loss: 305.256 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 220/1194 | Loss: 297.558 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 230/1194 | Loss: 309.044 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 240/1194 | Loss: 298.221 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 250/1194 | Loss: 285.172 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 260/1194 | Loss: 312.372 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 270/1194 | Loss: 312.206 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 280/1194 | Loss: 305.487 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 290/1194 | Loss: 300.288 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 300/1194 | Loss: 298.364 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 310/1194 | Loss: 313.028 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 320/1194 | Loss: 292.066 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 330/1194 | Loss: 278.084 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 340/1194 | Loss: 287.074 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 350/1194 | Loss: 283.389 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 360/1194 | Loss: 292.300 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 370/1194 | Loss: 314.139 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 380/1194 | Loss: 290.132 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 390/1194 | Loss: 302.251 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 400/1194 | Loss: 284.458 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 410/1194 | Loss: 275.880 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 420/1194 | Loss: 292.694 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 430/1194 | Loss: 300.986 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 440/1194 | Loss: 282.469 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 450/1194 | Loss: 260.287 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 460/1194 | Loss: 268.026 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 470/1194 | Loss: 286.599 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 480/1194 | Loss: 327.604 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 490/1194 | Loss: 293.576 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 500/1194 | Loss: 291.893 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 510/1194 | Loss: 295.145 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 520/1194 | Loss: 303.349 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 530/1194 | Loss: 293.135 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 540/1194 | Loss: 300.008 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 550/1194 | Loss: 289.404 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 560/1194 | Loss: 297.683 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 570/1194 | Loss: 280.398 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 580/1194 | Loss: 301.790 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 590/1194 | Loss: 304.052 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 600/1194 | Loss: 305.898 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 610/1194 | Loss: 303.043 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 620/1194 | Loss: 313.391 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 630/1194 | Loss: 295.084 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 640/1194 | Loss: 273.884 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 650/1194 | Loss: 299.729 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 660/1194 | Loss: 277.692 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 670/1194 | Loss: 260.258 | Accuracy: 0.400\n",
      "[Epoch: 55/200] - Step: 680/1194 | Loss: 293.709 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 690/1194 | Loss: 289.487 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 700/1194 | Loss: 312.253 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 710/1194 | Loss: 306.042 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 720/1194 | Loss: 309.197 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 730/1194 | Loss: 294.473 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 740/1194 | Loss: 304.061 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 750/1194 | Loss: 292.133 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 760/1194 | Loss: 291.500 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 770/1194 | Loss: 283.380 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 780/1194 | Loss: 288.327 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 790/1194 | Loss: 320.821 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 800/1194 | Loss: 324.697 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 810/1194 | Loss: 314.015 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 820/1194 | Loss: 322.800 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 830/1194 | Loss: 291.822 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 840/1194 | Loss: 309.904 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 850/1194 | Loss: 281.188 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 860/1194 | Loss: 298.716 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 870/1194 | Loss: 342.468 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 880/1194 | Loss: 280.863 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 890/1194 | Loss: 301.118 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 900/1194 | Loss: 281.174 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 910/1194 | Loss: 306.892 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 920/1194 | Loss: 306.886 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 930/1194 | Loss: 317.599 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 940/1194 | Loss: 309.777 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 950/1194 | Loss: 279.529 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 960/1194 | Loss: 284.514 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 970/1194 | Loss: 293.479 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 980/1194 | Loss: 296.259 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 990/1194 | Loss: 302.251 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1000/1194 | Loss: 290.471 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 1010/1194 | Loss: 300.505 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1020/1194 | Loss: 282.830 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 1030/1194 | Loss: 274.235 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1040/1194 | Loss: 314.652 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1050/1194 | Loss: 341.521 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1060/1194 | Loss: 299.394 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1070/1194 | Loss: 301.280 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1080/1194 | Loss: 312.261 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1090/1194 | Loss: 306.127 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1100/1194 | Loss: 295.555 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1110/1194 | Loss: 294.309 | Accuracy: 0.200\n",
      "[Epoch: 55/200] - Step: 1120/1194 | Loss: 302.832 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1130/1194 | Loss: 301.859 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1140/1194 | Loss: 305.604 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1150/1194 | Loss: 294.973 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1160/1194 | Loss: 284.129 | Accuracy: 0.300\n",
      "[Epoch: 55/200] - Step: 1170/1194 | Loss: 319.693 | Accuracy: 0.100\n",
      "[Epoch: 55/200] - Step: 1180/1194 | Loss: 298.563 | Accuracy: 0.000\n",
      "[Epoch: 55/200] - Step: 1190/1194 | Loss: 294.026 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 56/200] - Step: 10/1194 | Loss: 306.603 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 20/1194 | Loss: 304.303 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 30/1194 | Loss: 299.651 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 40/1194 | Loss: 301.060 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 50/1194 | Loss: 320.253 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 60/1194 | Loss: 289.210 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 70/1194 | Loss: 292.925 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 80/1194 | Loss: 290.163 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 90/1194 | Loss: 301.807 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 100/1194 | Loss: 285.681 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 110/1194 | Loss: 297.634 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 120/1194 | Loss: 295.398 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 130/1194 | Loss: 309.263 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 140/1194 | Loss: 316.329 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 150/1194 | Loss: 315.347 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 160/1194 | Loss: 300.572 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 170/1194 | Loss: 297.864 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 180/1194 | Loss: 265.659 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 190/1194 | Loss: 283.553 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 200/1194 | Loss: 286.520 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 210/1194 | Loss: 290.725 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 220/1194 | Loss: 303.240 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 230/1194 | Loss: 299.626 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 240/1194 | Loss: 278.852 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 250/1194 | Loss: 278.695 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 260/1194 | Loss: 297.241 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 270/1194 | Loss: 320.482 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 280/1194 | Loss: 299.556 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 290/1194 | Loss: 289.397 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 300/1194 | Loss: 308.856 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 310/1194 | Loss: 313.635 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 320/1194 | Loss: 325.613 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 330/1194 | Loss: 305.107 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 340/1194 | Loss: 300.920 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 350/1194 | Loss: 290.291 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 360/1194 | Loss: 276.565 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 370/1194 | Loss: 293.382 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 380/1194 | Loss: 314.086 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 390/1194 | Loss: 296.654 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 400/1194 | Loss: 291.439 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 410/1194 | Loss: 287.186 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 420/1194 | Loss: 311.222 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 430/1194 | Loss: 287.402 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 440/1194 | Loss: 304.543 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 450/1194 | Loss: 283.215 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 460/1194 | Loss: 305.114 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 470/1194 | Loss: 305.783 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 480/1194 | Loss: 293.976 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 490/1194 | Loss: 298.352 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 500/1194 | Loss: 292.194 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 510/1194 | Loss: 292.995 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 520/1194 | Loss: 303.596 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 530/1194 | Loss: 297.364 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 540/1194 | Loss: 309.937 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 550/1194 | Loss: 304.758 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 560/1194 | Loss: 280.176 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 570/1194 | Loss: 274.923 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 580/1194 | Loss: 297.495 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 590/1194 | Loss: 304.831 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 600/1194 | Loss: 294.028 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 610/1194 | Loss: 283.222 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 620/1194 | Loss: 300.544 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 630/1194 | Loss: 310.101 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 640/1194 | Loss: 294.183 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 650/1194 | Loss: 292.936 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 660/1194 | Loss: 315.436 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 670/1194 | Loss: 296.524 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 680/1194 | Loss: 306.343 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 690/1194 | Loss: 294.365 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 700/1194 | Loss: 288.790 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 710/1194 | Loss: 282.402 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 720/1194 | Loss: 293.958 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 730/1194 | Loss: 289.286 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 740/1194 | Loss: 307.229 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 750/1194 | Loss: 300.153 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 760/1194 | Loss: 307.093 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 770/1194 | Loss: 281.921 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 780/1194 | Loss: 291.680 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 790/1194 | Loss: 287.817 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 800/1194 | Loss: 307.862 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 810/1194 | Loss: 284.071 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 820/1194 | Loss: 293.921 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 830/1194 | Loss: 262.048 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 840/1194 | Loss: 289.597 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 850/1194 | Loss: 284.199 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 860/1194 | Loss: 265.763 | Accuracy: 0.400\n",
      "[Epoch: 56/200] - Step: 870/1194 | Loss: 304.563 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 880/1194 | Loss: 313.067 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 890/1194 | Loss: 303.922 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 900/1194 | Loss: 289.175 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 910/1194 | Loss: 290.819 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 920/1194 | Loss: 312.971 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 930/1194 | Loss: 299.201 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 940/1194 | Loss: 308.170 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 950/1194 | Loss: 288.589 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 960/1194 | Loss: 313.550 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 970/1194 | Loss: 288.082 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 980/1194 | Loss: 296.473 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 990/1194 | Loss: 278.602 | Accuracy: 0.300\n",
      "[Epoch: 56/200] - Step: 1000/1194 | Loss: 311.064 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1010/1194 | Loss: 290.016 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1020/1194 | Loss: 307.548 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1030/1194 | Loss: 305.498 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1040/1194 | Loss: 302.983 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1050/1194 | Loss: 296.410 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1060/1194 | Loss: 315.589 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1070/1194 | Loss: 303.461 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1080/1194 | Loss: 267.535 | Accuracy: 0.500\n",
      "[Epoch: 56/200] - Step: 1090/1194 | Loss: 296.070 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1100/1194 | Loss: 289.296 | Accuracy: 0.200\n",
      "[Epoch: 56/200] - Step: 1110/1194 | Loss: 302.914 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1120/1194 | Loss: 287.698 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1130/1194 | Loss: 299.590 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1140/1194 | Loss: 305.872 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1150/1194 | Loss: 304.470 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1160/1194 | Loss: 309.773 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1170/1194 | Loss: 315.760 | Accuracy: 0.000\n",
      "[Epoch: 56/200] - Step: 1180/1194 | Loss: 294.077 | Accuracy: 0.100\n",
      "[Epoch: 56/200] - Step: 1190/1194 | Loss: 309.810 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 57/200] - Step: 10/1194 | Loss: 301.459 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 20/1194 | Loss: 296.285 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 30/1194 | Loss: 305.113 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 40/1194 | Loss: 302.508 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 50/1194 | Loss: 298.084 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 60/1194 | Loss: 282.676 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 70/1194 | Loss: 292.184 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 80/1194 | Loss: 260.936 | Accuracy: 0.500\n",
      "[Epoch: 57/200] - Step: 90/1194 | Loss: 292.528 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 100/1194 | Loss: 283.892 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 110/1194 | Loss: 273.833 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 120/1194 | Loss: 309.251 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 130/1194 | Loss: 300.269 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 140/1194 | Loss: 297.455 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 150/1194 | Loss: 297.438 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 160/1194 | Loss: 283.209 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 170/1194 | Loss: 311.557 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 180/1194 | Loss: 290.077 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 190/1194 | Loss: 292.239 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 200/1194 | Loss: 298.427 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 210/1194 | Loss: 299.933 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 220/1194 | Loss: 291.267 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 230/1194 | Loss: 310.744 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 240/1194 | Loss: 297.781 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 250/1194 | Loss: 305.251 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 260/1194 | Loss: 305.300 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 270/1194 | Loss: 291.194 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 280/1194 | Loss: 308.597 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 290/1194 | Loss: 306.097 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 300/1194 | Loss: 293.995 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 310/1194 | Loss: 298.309 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 320/1194 | Loss: 290.967 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 330/1194 | Loss: 298.257 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 340/1194 | Loss: 304.605 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 350/1194 | Loss: 285.782 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 360/1194 | Loss: 309.395 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 370/1194 | Loss: 287.261 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 380/1194 | Loss: 269.270 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 390/1194 | Loss: 302.516 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 400/1194 | Loss: 307.902 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 410/1194 | Loss: 293.420 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 420/1194 | Loss: 283.296 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 430/1194 | Loss: 304.855 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 440/1194 | Loss: 295.916 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 450/1194 | Loss: 304.824 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 460/1194 | Loss: 326.786 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 470/1194 | Loss: 285.700 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 480/1194 | Loss: 291.236 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 490/1194 | Loss: 306.944 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 500/1194 | Loss: 295.646 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 510/1194 | Loss: 312.446 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 520/1194 | Loss: 315.352 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 530/1194 | Loss: 295.741 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 540/1194 | Loss: 291.959 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 550/1194 | Loss: 272.853 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 560/1194 | Loss: 297.378 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 570/1194 | Loss: 289.570 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 580/1194 | Loss: 300.747 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 590/1194 | Loss: 303.847 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 600/1194 | Loss: 297.558 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 610/1194 | Loss: 308.643 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 620/1194 | Loss: 289.560 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 630/1194 | Loss: 305.677 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 640/1194 | Loss: 299.075 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 650/1194 | Loss: 273.255 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 660/1194 | Loss: 307.388 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 670/1194 | Loss: 300.000 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 680/1194 | Loss: 303.226 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 690/1194 | Loss: 284.971 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 700/1194 | Loss: 325.836 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 710/1194 | Loss: 311.050 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 720/1194 | Loss: 291.401 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 730/1194 | Loss: 293.884 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 740/1194 | Loss: 304.549 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 750/1194 | Loss: 323.109 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 760/1194 | Loss: 299.944 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 770/1194 | Loss: 297.866 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 780/1194 | Loss: 306.912 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 790/1194 | Loss: 273.797 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 800/1194 | Loss: 289.259 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 810/1194 | Loss: 295.133 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 820/1194 | Loss: 299.777 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 830/1194 | Loss: 300.213 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 840/1194 | Loss: 304.419 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 850/1194 | Loss: 290.848 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 860/1194 | Loss: 274.541 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 870/1194 | Loss: 279.793 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 880/1194 | Loss: 296.039 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 890/1194 | Loss: 287.049 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 900/1194 | Loss: 308.425 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 910/1194 | Loss: 300.026 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 920/1194 | Loss: 305.353 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 930/1194 | Loss: 315.073 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 940/1194 | Loss: 292.596 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 950/1194 | Loss: 287.413 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 960/1194 | Loss: 298.595 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 970/1194 | Loss: 310.052 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 980/1194 | Loss: 279.981 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 990/1194 | Loss: 311.846 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 1000/1194 | Loss: 300.444 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 1010/1194 | Loss: 296.272 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 1020/1194 | Loss: 296.477 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1030/1194 | Loss: 298.021 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1040/1194 | Loss: 300.246 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 1050/1194 | Loss: 327.331 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 1060/1194 | Loss: 274.268 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1070/1194 | Loss: 292.669 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1080/1194 | Loss: 289.453 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 1090/1194 | Loss: 289.944 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1100/1194 | Loss: 305.927 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1110/1194 | Loss: 285.319 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 1120/1194 | Loss: 296.549 | Accuracy: 0.200\n",
      "[Epoch: 57/200] - Step: 1130/1194 | Loss: 330.201 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1140/1194 | Loss: 297.738 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1150/1194 | Loss: 294.743 | Accuracy: 0.100\n",
      "[Epoch: 57/200] - Step: 1160/1194 | Loss: 273.246 | Accuracy: 0.300\n",
      "[Epoch: 57/200] - Step: 1170/1194 | Loss: 261.498 | Accuracy: 0.400\n",
      "[Epoch: 57/200] - Step: 1180/1194 | Loss: 326.373 | Accuracy: 0.000\n",
      "[Epoch: 57/200] - Step: 1190/1194 | Loss: 307.888 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 58/200] - Step: 10/1194 | Loss: 296.896 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 20/1194 | Loss: 309.678 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 30/1194 | Loss: 296.949 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 40/1194 | Loss: 311.690 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 50/1194 | Loss: 303.974 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 60/1194 | Loss: 288.548 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 70/1194 | Loss: 306.239 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 80/1194 | Loss: 284.895 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 90/1194 | Loss: 269.653 | Accuracy: 0.400\n",
      "[Epoch: 58/200] - Step: 100/1194 | Loss: 315.217 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 110/1194 | Loss: 335.624 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 120/1194 | Loss: 288.737 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 130/1194 | Loss: 297.550 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 140/1194 | Loss: 296.901 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 150/1194 | Loss: 300.518 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 160/1194 | Loss: 297.962 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 170/1194 | Loss: 280.956 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 180/1194 | Loss: 298.780 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 190/1194 | Loss: 291.991 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 200/1194 | Loss: 284.790 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 210/1194 | Loss: 307.530 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 220/1194 | Loss: 284.321 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 230/1194 | Loss: 285.762 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 240/1194 | Loss: 292.671 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 250/1194 | Loss: 301.157 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 260/1194 | Loss: 271.540 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 270/1194 | Loss: 289.928 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 280/1194 | Loss: 283.453 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 290/1194 | Loss: 303.839 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 300/1194 | Loss: 305.584 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 310/1194 | Loss: 304.972 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 320/1194 | Loss: 279.523 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 330/1194 | Loss: 312.291 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 340/1194 | Loss: 313.401 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 350/1194 | Loss: 287.203 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 360/1194 | Loss: 281.399 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 370/1194 | Loss: 318.429 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 380/1194 | Loss: 308.127 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 390/1194 | Loss: 287.355 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 400/1194 | Loss: 288.823 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 410/1194 | Loss: 285.996 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 420/1194 | Loss: 300.935 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 430/1194 | Loss: 273.780 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 440/1194 | Loss: 284.828 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 450/1194 | Loss: 313.380 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 460/1194 | Loss: 308.201 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 470/1194 | Loss: 296.348 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 480/1194 | Loss: 279.900 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 490/1194 | Loss: 302.247 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 500/1194 | Loss: 310.100 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 510/1194 | Loss: 302.822 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 520/1194 | Loss: 301.776 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 530/1194 | Loss: 303.345 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 540/1194 | Loss: 298.099 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 550/1194 | Loss: 297.301 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 560/1194 | Loss: 289.374 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 570/1194 | Loss: 291.634 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 580/1194 | Loss: 305.037 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 590/1194 | Loss: 287.930 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 600/1194 | Loss: 294.317 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 610/1194 | Loss: 289.924 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 620/1194 | Loss: 298.451 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 630/1194 | Loss: 305.110 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 640/1194 | Loss: 285.562 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 650/1194 | Loss: 297.849 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 660/1194 | Loss: 289.515 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 670/1194 | Loss: 307.418 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 680/1194 | Loss: 301.605 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 690/1194 | Loss: 288.128 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 700/1194 | Loss: 306.230 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 710/1194 | Loss: 301.976 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 720/1194 | Loss: 296.320 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 730/1194 | Loss: 292.360 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 740/1194 | Loss: 304.264 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 750/1194 | Loss: 300.670 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 760/1194 | Loss: 274.520 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 770/1194 | Loss: 299.295 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 780/1194 | Loss: 283.968 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 790/1194 | Loss: 304.876 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 800/1194 | Loss: 286.201 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 810/1194 | Loss: 290.173 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 820/1194 | Loss: 306.598 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 830/1194 | Loss: 303.403 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 840/1194 | Loss: 294.257 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 850/1194 | Loss: 273.251 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 860/1194 | Loss: 329.640 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 870/1194 | Loss: 292.558 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 880/1194 | Loss: 304.236 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 890/1194 | Loss: 285.276 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 900/1194 | Loss: 311.786 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 910/1194 | Loss: 304.210 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 920/1194 | Loss: 305.449 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 930/1194 | Loss: 287.993 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 940/1194 | Loss: 287.044 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 950/1194 | Loss: 309.363 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 960/1194 | Loss: 297.700 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 970/1194 | Loss: 316.491 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 980/1194 | Loss: 301.978 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 990/1194 | Loss: 294.727 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1000/1194 | Loss: 294.061 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 1010/1194 | Loss: 289.106 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1020/1194 | Loss: 268.673 | Accuracy: 0.300\n",
      "[Epoch: 58/200] - Step: 1030/1194 | Loss: 316.994 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 1040/1194 | Loss: 304.650 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1050/1194 | Loss: 293.339 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1060/1194 | Loss: 289.512 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1070/1194 | Loss: 286.084 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1080/1194 | Loss: 302.444 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1090/1194 | Loss: 293.003 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1100/1194 | Loss: 299.200 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1110/1194 | Loss: 292.919 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1120/1194 | Loss: 300.310 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1130/1194 | Loss: 291.052 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 1140/1194 | Loss: 322.713 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1150/1194 | Loss: 302.415 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1160/1194 | Loss: 306.057 | Accuracy: 0.100\n",
      "[Epoch: 58/200] - Step: 1170/1194 | Loss: 312.848 | Accuracy: 0.000\n",
      "[Epoch: 58/200] - Step: 1180/1194 | Loss: 290.000 | Accuracy: 0.200\n",
      "[Epoch: 58/200] - Step: 1190/1194 | Loss: 305.163 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 59/200] - Step: 10/1194 | Loss: 283.799 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 20/1194 | Loss: 303.818 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 30/1194 | Loss: 301.748 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 40/1194 | Loss: 307.159 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 50/1194 | Loss: 291.532 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 60/1194 | Loss: 286.760 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 70/1194 | Loss: 297.871 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 80/1194 | Loss: 287.813 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 90/1194 | Loss: 311.570 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 100/1194 | Loss: 275.586 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 110/1194 | Loss: 291.125 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 120/1194 | Loss: 292.586 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 130/1194 | Loss: 315.702 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 140/1194 | Loss: 279.997 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 150/1194 | Loss: 290.058 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 160/1194 | Loss: 315.666 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 170/1194 | Loss: 279.374 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 180/1194 | Loss: 295.253 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 190/1194 | Loss: 297.818 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 200/1194 | Loss: 281.716 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 210/1194 | Loss: 288.408 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 220/1194 | Loss: 306.458 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 230/1194 | Loss: 314.539 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 240/1194 | Loss: 293.040 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 250/1194 | Loss: 279.077 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 260/1194 | Loss: 322.082 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 270/1194 | Loss: 304.655 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 280/1194 | Loss: 292.235 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 290/1194 | Loss: 301.796 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 300/1194 | Loss: 295.038 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 310/1194 | Loss: 310.095 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 320/1194 | Loss: 287.171 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 330/1194 | Loss: 289.135 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 340/1194 | Loss: 294.103 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 350/1194 | Loss: 293.889 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 360/1194 | Loss: 297.641 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 370/1194 | Loss: 288.061 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 380/1194 | Loss: 300.238 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 390/1194 | Loss: 300.507 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 400/1194 | Loss: 304.852 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 410/1194 | Loss: 286.525 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 420/1194 | Loss: 296.692 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 430/1194 | Loss: 304.615 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 440/1194 | Loss: 293.791 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 450/1194 | Loss: 269.928 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 460/1194 | Loss: 287.180 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 470/1194 | Loss: 308.104 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 480/1194 | Loss: 287.190 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 490/1194 | Loss: 308.081 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 500/1194 | Loss: 304.342 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 510/1194 | Loss: 303.143 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 520/1194 | Loss: 304.752 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 530/1194 | Loss: 302.424 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 540/1194 | Loss: 297.488 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 550/1194 | Loss: 285.834 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 560/1194 | Loss: 300.222 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 570/1194 | Loss: 293.306 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 580/1194 | Loss: 296.803 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 590/1194 | Loss: 294.977 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 600/1194 | Loss: 312.279 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 610/1194 | Loss: 293.655 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 620/1194 | Loss: 303.801 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 630/1194 | Loss: 289.172 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 640/1194 | Loss: 293.153 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 650/1194 | Loss: 301.283 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 660/1194 | Loss: 278.719 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 670/1194 | Loss: 277.397 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 680/1194 | Loss: 302.430 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 690/1194 | Loss: 304.131 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 700/1194 | Loss: 310.801 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 710/1194 | Loss: 305.940 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 720/1194 | Loss: 288.553 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 730/1194 | Loss: 285.805 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 740/1194 | Loss: 294.923 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 750/1194 | Loss: 314.239 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 760/1194 | Loss: 294.873 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 770/1194 | Loss: 284.431 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 780/1194 | Loss: 300.809 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 790/1194 | Loss: 301.409 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 800/1194 | Loss: 300.460 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 810/1194 | Loss: 319.624 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 820/1194 | Loss: 275.562 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 830/1194 | Loss: 302.812 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 840/1194 | Loss: 286.715 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 850/1194 | Loss: 315.525 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 860/1194 | Loss: 319.744 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 870/1194 | Loss: 290.413 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 880/1194 | Loss: 299.780 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 890/1194 | Loss: 308.438 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 900/1194 | Loss: 299.873 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 910/1194 | Loss: 301.145 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 920/1194 | Loss: 296.487 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 930/1194 | Loss: 298.380 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 940/1194 | Loss: 281.200 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 950/1194 | Loss: 305.248 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 960/1194 | Loss: 306.370 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 970/1194 | Loss: 308.749 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 980/1194 | Loss: 304.466 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 990/1194 | Loss: 326.011 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1000/1194 | Loss: 278.535 | Accuracy: 0.400\n",
      "[Epoch: 59/200] - Step: 1010/1194 | Loss: 319.923 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1020/1194 | Loss: 304.500 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1030/1194 | Loss: 295.478 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 1040/1194 | Loss: 292.961 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 1050/1194 | Loss: 300.996 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 1060/1194 | Loss: 296.313 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1070/1194 | Loss: 279.224 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1080/1194 | Loss: 303.651 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1090/1194 | Loss: 324.026 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 1100/1194 | Loss: 284.073 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1110/1194 | Loss: 297.984 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1120/1194 | Loss: 291.748 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1130/1194 | Loss: 300.615 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1140/1194 | Loss: 306.006 | Accuracy: 0.000\n",
      "[Epoch: 59/200] - Step: 1150/1194 | Loss: 286.520 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 1160/1194 | Loss: 277.744 | Accuracy: 0.300\n",
      "[Epoch: 59/200] - Step: 1170/1194 | Loss: 278.404 | Accuracy: 0.200\n",
      "[Epoch: 59/200] - Step: 1180/1194 | Loss: 304.922 | Accuracy: 0.100\n",
      "[Epoch: 59/200] - Step: 1190/1194 | Loss: 288.679 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 60/200] - Step: 10/1194 | Loss: 312.016 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 20/1194 | Loss: 296.579 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 30/1194 | Loss: 299.585 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 40/1194 | Loss: 297.572 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 50/1194 | Loss: 303.384 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 60/1194 | Loss: 306.705 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 70/1194 | Loss: 265.802 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 80/1194 | Loss: 285.443 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 90/1194 | Loss: 300.130 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 100/1194 | Loss: 296.329 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 110/1194 | Loss: 305.410 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 120/1194 | Loss: 300.319 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 130/1194 | Loss: 307.230 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 140/1194 | Loss: 296.262 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 150/1194 | Loss: 311.147 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 160/1194 | Loss: 297.780 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 170/1194 | Loss: 282.227 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 180/1194 | Loss: 315.282 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 190/1194 | Loss: 297.094 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 200/1194 | Loss: 304.530 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 210/1194 | Loss: 300.252 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 220/1194 | Loss: 302.527 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 230/1194 | Loss: 298.756 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 240/1194 | Loss: 302.144 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 250/1194 | Loss: 295.473 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 260/1194 | Loss: 298.172 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 270/1194 | Loss: 291.535 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 280/1194 | Loss: 320.790 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 290/1194 | Loss: 273.672 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 300/1194 | Loss: 289.479 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 310/1194 | Loss: 338.855 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 320/1194 | Loss: 296.893 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 330/1194 | Loss: 293.012 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 340/1194 | Loss: 284.242 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 350/1194 | Loss: 302.647 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 360/1194 | Loss: 284.961 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 370/1194 | Loss: 284.025 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 380/1194 | Loss: 301.086 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 390/1194 | Loss: 325.095 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 400/1194 | Loss: 309.240 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 410/1194 | Loss: 298.988 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 420/1194 | Loss: 297.663 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 430/1194 | Loss: 301.480 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 440/1194 | Loss: 296.318 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 450/1194 | Loss: 301.333 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 460/1194 | Loss: 294.425 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 470/1194 | Loss: 298.931 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 480/1194 | Loss: 302.779 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 490/1194 | Loss: 308.760 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 500/1194 | Loss: 294.638 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 510/1194 | Loss: 298.747 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 520/1194 | Loss: 298.772 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 530/1194 | Loss: 302.468 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 540/1194 | Loss: 283.421 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 550/1194 | Loss: 298.698 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 560/1194 | Loss: 306.118 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 570/1194 | Loss: 300.927 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 580/1194 | Loss: 314.167 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 590/1194 | Loss: 297.218 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 600/1194 | Loss: 293.114 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 610/1194 | Loss: 280.107 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 620/1194 | Loss: 296.959 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 630/1194 | Loss: 274.608 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 640/1194 | Loss: 304.114 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 650/1194 | Loss: 287.800 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 660/1194 | Loss: 288.943 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 670/1194 | Loss: 280.734 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 680/1194 | Loss: 300.932 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 690/1194 | Loss: 300.496 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 700/1194 | Loss: 285.991 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 710/1194 | Loss: 298.516 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 720/1194 | Loss: 297.279 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 730/1194 | Loss: 283.961 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 740/1194 | Loss: 289.403 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 750/1194 | Loss: 286.118 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 760/1194 | Loss: 293.214 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 770/1194 | Loss: 292.613 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 780/1194 | Loss: 307.062 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 790/1194 | Loss: 302.556 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 800/1194 | Loss: 272.643 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 810/1194 | Loss: 280.656 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 820/1194 | Loss: 307.182 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 830/1194 | Loss: 286.321 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 840/1194 | Loss: 292.521 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 850/1194 | Loss: 291.444 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 860/1194 | Loss: 316.682 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 870/1194 | Loss: 287.109 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 880/1194 | Loss: 306.127 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 890/1194 | Loss: 321.051 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 900/1194 | Loss: 305.610 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 910/1194 | Loss: 294.213 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 920/1194 | Loss: 307.600 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 930/1194 | Loss: 289.642 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 940/1194 | Loss: 298.056 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 950/1194 | Loss: 288.437 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 960/1194 | Loss: 276.434 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 970/1194 | Loss: 302.015 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 980/1194 | Loss: 301.799 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 990/1194 | Loss: 303.091 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 1000/1194 | Loss: 309.977 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 1010/1194 | Loss: 300.746 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1020/1194 | Loss: 270.046 | Accuracy: 0.300\n",
      "[Epoch: 60/200] - Step: 1030/1194 | Loss: 311.502 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 1040/1194 | Loss: 291.527 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1050/1194 | Loss: 298.376 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 1060/1194 | Loss: 306.011 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 1070/1194 | Loss: 310.531 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 1080/1194 | Loss: 289.623 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1090/1194 | Loss: 304.070 | Accuracy: 0.000\n",
      "[Epoch: 60/200] - Step: 1100/1194 | Loss: 301.101 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 1110/1194 | Loss: 283.923 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1120/1194 | Loss: 281.384 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1130/1194 | Loss: 271.822 | Accuracy: 0.400\n",
      "[Epoch: 60/200] - Step: 1140/1194 | Loss: 299.785 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 1150/1194 | Loss: 320.521 | Accuracy: 0.100\n",
      "[Epoch: 60/200] - Step: 1160/1194 | Loss: 291.071 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1170/1194 | Loss: 299.266 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1180/1194 | Loss: 275.382 | Accuracy: 0.200\n",
      "[Epoch: 60/200] - Step: 1190/1194 | Loss: 315.331 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 61/200] - Step: 10/1194 | Loss: 292.012 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 20/1194 | Loss: 319.296 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 30/1194 | Loss: 303.029 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 40/1194 | Loss: 281.446 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 50/1194 | Loss: 289.223 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 60/1194 | Loss: 314.767 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 70/1194 | Loss: 298.021 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 80/1194 | Loss: 277.973 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 90/1194 | Loss: 284.707 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 100/1194 | Loss: 262.801 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 110/1194 | Loss: 279.424 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 120/1194 | Loss: 300.587 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 130/1194 | Loss: 293.358 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 140/1194 | Loss: 297.172 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 150/1194 | Loss: 281.473 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 160/1194 | Loss: 294.259 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 170/1194 | Loss: 287.139 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 180/1194 | Loss: 300.895 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 190/1194 | Loss: 299.494 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 200/1194 | Loss: 284.844 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 210/1194 | Loss: 284.425 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 220/1194 | Loss: 300.638 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 230/1194 | Loss: 348.399 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 240/1194 | Loss: 285.986 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 250/1194 | Loss: 292.646 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 260/1194 | Loss: 285.686 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 270/1194 | Loss: 301.942 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 280/1194 | Loss: 307.294 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 290/1194 | Loss: 269.825 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 300/1194 | Loss: 280.286 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 310/1194 | Loss: 288.610 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 320/1194 | Loss: 322.716 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 330/1194 | Loss: 303.970 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 340/1194 | Loss: 296.843 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 350/1194 | Loss: 306.402 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 360/1194 | Loss: 274.128 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 370/1194 | Loss: 288.253 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 380/1194 | Loss: 306.613 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 390/1194 | Loss: 301.769 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 400/1194 | Loss: 283.829 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 410/1194 | Loss: 301.795 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 420/1194 | Loss: 297.768 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 430/1194 | Loss: 295.514 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 440/1194 | Loss: 301.936 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 450/1194 | Loss: 299.002 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 460/1194 | Loss: 297.983 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 470/1194 | Loss: 283.901 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 480/1194 | Loss: 287.592 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 490/1194 | Loss: 296.945 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 500/1194 | Loss: 301.361 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 510/1194 | Loss: 278.810 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 520/1194 | Loss: 298.307 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 530/1194 | Loss: 297.774 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 540/1194 | Loss: 304.790 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 550/1194 | Loss: 311.764 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 560/1194 | Loss: 303.730 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 570/1194 | Loss: 318.237 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 580/1194 | Loss: 298.273 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 590/1194 | Loss: 285.770 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 600/1194 | Loss: 312.262 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 610/1194 | Loss: 307.790 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 620/1194 | Loss: 314.263 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 630/1194 | Loss: 302.104 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 640/1194 | Loss: 303.836 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 650/1194 | Loss: 290.174 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 660/1194 | Loss: 308.176 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 670/1194 | Loss: 297.759 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 680/1194 | Loss: 299.654 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 690/1194 | Loss: 296.514 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 700/1194 | Loss: 288.546 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 710/1194 | Loss: 303.690 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 720/1194 | Loss: 294.993 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 730/1194 | Loss: 301.006 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 740/1194 | Loss: 299.708 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 750/1194 | Loss: 301.215 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 760/1194 | Loss: 282.926 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 770/1194 | Loss: 289.980 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 780/1194 | Loss: 299.235 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 790/1194 | Loss: 289.623 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 800/1194 | Loss: 304.276 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 810/1194 | Loss: 302.527 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 820/1194 | Loss: 303.177 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 830/1194 | Loss: 274.813 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 840/1194 | Loss: 304.426 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 850/1194 | Loss: 309.715 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 860/1194 | Loss: 271.220 | Accuracy: 0.400\n",
      "[Epoch: 61/200] - Step: 870/1194 | Loss: 295.279 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 880/1194 | Loss: 292.102 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 890/1194 | Loss: 298.486 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 900/1194 | Loss: 308.409 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 910/1194 | Loss: 321.731 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 920/1194 | Loss: 309.061 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 930/1194 | Loss: 304.396 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 940/1194 | Loss: 303.634 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 950/1194 | Loss: 290.327 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 960/1194 | Loss: 293.275 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 970/1194 | Loss: 295.014 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 980/1194 | Loss: 289.269 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 990/1194 | Loss: 283.570 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 1000/1194 | Loss: 295.929 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 1010/1194 | Loss: 283.412 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1020/1194 | Loss: 290.984 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1030/1194 | Loss: 287.579 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 1040/1194 | Loss: 272.744 | Accuracy: 0.300\n",
      "[Epoch: 61/200] - Step: 1050/1194 | Loss: 296.836 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 1060/1194 | Loss: 313.407 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1070/1194 | Loss: 307.881 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1080/1194 | Loss: 300.411 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1090/1194 | Loss: 315.579 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 1100/1194 | Loss: 286.726 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1110/1194 | Loss: 324.896 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1120/1194 | Loss: 310.604 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1130/1194 | Loss: 305.883 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1140/1194 | Loss: 294.555 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1150/1194 | Loss: 300.758 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1160/1194 | Loss: 299.706 | Accuracy: 0.100\n",
      "[Epoch: 61/200] - Step: 1170/1194 | Loss: 302.881 | Accuracy: 0.000\n",
      "[Epoch: 61/200] - Step: 1180/1194 | Loss: 287.893 | Accuracy: 0.200\n",
      "[Epoch: 61/200] - Step: 1190/1194 | Loss: 307.281 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 62/200] - Step: 10/1194 | Loss: 292.243 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 20/1194 | Loss: 292.705 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 30/1194 | Loss: 313.287 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 40/1194 | Loss: 297.866 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 50/1194 | Loss: 328.014 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 60/1194 | Loss: 290.005 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 70/1194 | Loss: 308.127 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 80/1194 | Loss: 303.454 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 90/1194 | Loss: 279.380 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 100/1194 | Loss: 304.717 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 110/1194 | Loss: 293.280 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 120/1194 | Loss: 290.898 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 130/1194 | Loss: 294.254 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 140/1194 | Loss: 290.537 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 150/1194 | Loss: 286.841 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 160/1194 | Loss: 307.704 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 170/1194 | Loss: 301.440 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 180/1194 | Loss: 288.022 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 190/1194 | Loss: 301.991 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 200/1194 | Loss: 290.826 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 210/1194 | Loss: 304.276 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 220/1194 | Loss: 277.344 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 230/1194 | Loss: 287.647 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 240/1194 | Loss: 302.749 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 250/1194 | Loss: 292.390 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 260/1194 | Loss: 306.577 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 270/1194 | Loss: 286.558 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 280/1194 | Loss: 309.412 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 290/1194 | Loss: 303.141 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 300/1194 | Loss: 305.569 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 310/1194 | Loss: 285.273 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 320/1194 | Loss: 297.166 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 330/1194 | Loss: 289.526 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 340/1194 | Loss: 302.805 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 350/1194 | Loss: 285.811 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 360/1194 | Loss: 300.521 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 370/1194 | Loss: 310.253 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 380/1194 | Loss: 288.213 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 390/1194 | Loss: 286.706 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 400/1194 | Loss: 306.028 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 410/1194 | Loss: 300.990 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 420/1194 | Loss: 296.121 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 430/1194 | Loss: 314.435 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 440/1194 | Loss: 309.142 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 450/1194 | Loss: 305.360 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 460/1194 | Loss: 298.377 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 470/1194 | Loss: 281.326 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 480/1194 | Loss: 294.655 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 490/1194 | Loss: 306.706 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 500/1194 | Loss: 273.595 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 510/1194 | Loss: 286.491 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 520/1194 | Loss: 301.897 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 530/1194 | Loss: 288.870 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 540/1194 | Loss: 313.908 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 550/1194 | Loss: 282.439 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 560/1194 | Loss: 307.898 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 570/1194 | Loss: 285.737 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 580/1194 | Loss: 299.834 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 590/1194 | Loss: 289.847 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 600/1194 | Loss: 290.649 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 610/1194 | Loss: 290.886 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 620/1194 | Loss: 334.609 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 630/1194 | Loss: 295.591 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 640/1194 | Loss: 324.189 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 650/1194 | Loss: 311.902 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 660/1194 | Loss: 295.079 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 670/1194 | Loss: 300.222 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 680/1194 | Loss: 295.837 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 690/1194 | Loss: 306.437 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 700/1194 | Loss: 289.291 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 710/1194 | Loss: 286.977 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 720/1194 | Loss: 290.572 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 730/1194 | Loss: 274.142 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 740/1194 | Loss: 310.993 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 750/1194 | Loss: 287.587 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 760/1194 | Loss: 307.503 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 770/1194 | Loss: 294.721 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 780/1194 | Loss: 299.640 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 790/1194 | Loss: 310.084 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 800/1194 | Loss: 294.833 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 810/1194 | Loss: 302.439 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 820/1194 | Loss: 292.172 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 830/1194 | Loss: 280.751 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 840/1194 | Loss: 310.085 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 850/1194 | Loss: 341.676 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 860/1194 | Loss: 278.573 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 870/1194 | Loss: 315.013 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 880/1194 | Loss: 294.521 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 890/1194 | Loss: 303.470 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 900/1194 | Loss: 305.923 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 910/1194 | Loss: 309.775 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 920/1194 | Loss: 290.268 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 930/1194 | Loss: 297.411 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 940/1194 | Loss: 306.158 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 950/1194 | Loss: 291.851 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 960/1194 | Loss: 277.130 | Accuracy: 0.400\n",
      "[Epoch: 62/200] - Step: 970/1194 | Loss: 298.525 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 980/1194 | Loss: 300.703 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 990/1194 | Loss: 275.328 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 1000/1194 | Loss: 274.942 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 1010/1194 | Loss: 277.855 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 1020/1194 | Loss: 279.560 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1030/1194 | Loss: 296.498 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 1040/1194 | Loss: 286.135 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1050/1194 | Loss: 281.647 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1060/1194 | Loss: 272.448 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1070/1194 | Loss: 293.046 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 1080/1194 | Loss: 321.519 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1090/1194 | Loss: 314.336 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1100/1194 | Loss: 454.610 | Accuracy: 0.200\n",
      "[Epoch: 62/200] - Step: 1110/1194 | Loss: 307.276 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1120/1194 | Loss: 269.722 | Accuracy: 0.300\n",
      "[Epoch: 62/200] - Step: 1130/1194 | Loss: 316.704 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1140/1194 | Loss: 300.905 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 1150/1194 | Loss: 297.719 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1160/1194 | Loss: 299.148 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 1170/1194 | Loss: 304.295 | Accuracy: 0.000\n",
      "[Epoch: 62/200] - Step: 1180/1194 | Loss: 285.008 | Accuracy: 0.100\n",
      "[Epoch: 62/200] - Step: 1190/1194 | Loss: 289.873 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 63/200] - Step: 10/1194 | Loss: 297.848 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 20/1194 | Loss: 292.204 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 30/1194 | Loss: 278.809 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 40/1194 | Loss: 291.829 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 50/1194 | Loss: 302.615 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 60/1194 | Loss: 303.883 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 70/1194 | Loss: 302.482 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 80/1194 | Loss: 287.592 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 90/1194 | Loss: 309.705 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 100/1194 | Loss: 288.186 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 110/1194 | Loss: 306.590 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 120/1194 | Loss: 287.780 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 130/1194 | Loss: 306.847 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 140/1194 | Loss: 308.838 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 150/1194 | Loss: 297.891 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 160/1194 | Loss: 289.426 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 170/1194 | Loss: 293.770 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 180/1194 | Loss: 286.141 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 190/1194 | Loss: 273.401 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 200/1194 | Loss: 298.150 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 210/1194 | Loss: 301.475 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 220/1194 | Loss: 300.498 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 230/1194 | Loss: 286.019 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 240/1194 | Loss: 300.365 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 250/1194 | Loss: 313.042 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 260/1194 | Loss: 297.208 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 270/1194 | Loss: 293.547 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 280/1194 | Loss: 311.246 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 290/1194 | Loss: 265.922 | Accuracy: 0.400\n",
      "[Epoch: 63/200] - Step: 300/1194 | Loss: 292.946 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 310/1194 | Loss: 289.685 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 320/1194 | Loss: 286.161 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 330/1194 | Loss: 322.060 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 340/1194 | Loss: 306.224 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 350/1194 | Loss: 303.945 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 360/1194 | Loss: 301.242 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 370/1194 | Loss: 293.262 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 380/1194 | Loss: 305.202 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 390/1194 | Loss: 301.860 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 400/1194 | Loss: 296.098 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 410/1194 | Loss: 295.507 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 420/1194 | Loss: 275.176 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 430/1194 | Loss: 297.558 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 440/1194 | Loss: 295.131 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 450/1194 | Loss: 284.034 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 460/1194 | Loss: 297.002 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 470/1194 | Loss: 279.517 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 480/1194 | Loss: 283.893 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 490/1194 | Loss: 288.173 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 500/1194 | Loss: 295.192 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 510/1194 | Loss: 306.036 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 520/1194 | Loss: 306.927 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 530/1194 | Loss: 290.235 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 540/1194 | Loss: 285.485 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 550/1194 | Loss: 305.559 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 560/1194 | Loss: 305.140 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 570/1194 | Loss: 295.850 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 580/1194 | Loss: 298.934 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 590/1194 | Loss: 293.262 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 600/1194 | Loss: 259.632 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 610/1194 | Loss: 337.005 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 620/1194 | Loss: 308.467 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 630/1194 | Loss: 289.510 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 640/1194 | Loss: 274.289 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 650/1194 | Loss: 337.911 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 660/1194 | Loss: 302.691 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 670/1194 | Loss: 334.097 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 680/1194 | Loss: 291.511 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 690/1194 | Loss: 307.903 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 700/1194 | Loss: 296.466 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 710/1194 | Loss: 305.820 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 720/1194 | Loss: 278.432 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 730/1194 | Loss: 301.885 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 740/1194 | Loss: 294.251 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 750/1194 | Loss: 295.564 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 760/1194 | Loss: 296.532 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 770/1194 | Loss: 294.509 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 780/1194 | Loss: 295.018 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 790/1194 | Loss: 309.563 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 800/1194 | Loss: 293.472 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 810/1194 | Loss: 304.576 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 820/1194 | Loss: 297.493 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 830/1194 | Loss: 293.242 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 840/1194 | Loss: 302.785 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 850/1194 | Loss: 287.777 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 860/1194 | Loss: 299.328 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 870/1194 | Loss: 327.038 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 880/1194 | Loss: 301.351 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 890/1194 | Loss: 290.644 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 900/1194 | Loss: 290.423 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 910/1194 | Loss: 288.080 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 920/1194 | Loss: 301.096 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 930/1194 | Loss: 294.866 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 940/1194 | Loss: 307.210 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 950/1194 | Loss: 325.916 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 960/1194 | Loss: 293.938 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 970/1194 | Loss: 278.695 | Accuracy: 0.300\n",
      "[Epoch: 63/200] - Step: 980/1194 | Loss: 308.575 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 990/1194 | Loss: 308.540 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1000/1194 | Loss: 266.955 | Accuracy: 0.500\n",
      "[Epoch: 63/200] - Step: 1010/1194 | Loss: 295.784 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1020/1194 | Loss: 282.750 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1030/1194 | Loss: 285.738 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1040/1194 | Loss: 330.957 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1050/1194 | Loss: 307.885 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1060/1194 | Loss: 306.638 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1070/1194 | Loss: 302.483 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1080/1194 | Loss: 302.322 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1090/1194 | Loss: 278.217 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 1100/1194 | Loss: 293.072 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 1110/1194 | Loss: 297.514 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1120/1194 | Loss: 304.811 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1130/1194 | Loss: 295.985 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1140/1194 | Loss: 295.594 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1150/1194 | Loss: 302.496 | Accuracy: 0.000\n",
      "[Epoch: 63/200] - Step: 1160/1194 | Loss: 293.201 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 1170/1194 | Loss: 291.959 | Accuracy: 0.100\n",
      "[Epoch: 63/200] - Step: 1180/1194 | Loss: 287.781 | Accuracy: 0.200\n",
      "[Epoch: 63/200] - Step: 1190/1194 | Loss: 294.211 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 64/200] - Step: 10/1194 | Loss: 282.677 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 20/1194 | Loss: 299.467 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 30/1194 | Loss: 294.756 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 40/1194 | Loss: 279.534 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 50/1194 | Loss: 298.025 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 60/1194 | Loss: 307.916 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 70/1194 | Loss: 286.267 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 80/1194 | Loss: 296.299 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 90/1194 | Loss: 296.958 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 100/1194 | Loss: 303.915 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 110/1194 | Loss: 302.893 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 120/1194 | Loss: 289.673 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 130/1194 | Loss: 279.113 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 140/1194 | Loss: 272.254 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 150/1194 | Loss: 296.995 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 160/1194 | Loss: 281.474 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 170/1194 | Loss: 270.324 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 180/1194 | Loss: 293.655 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 190/1194 | Loss: 307.345 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 200/1194 | Loss: 293.251 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 210/1194 | Loss: 286.054 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 220/1194 | Loss: 306.934 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 230/1194 | Loss: 267.753 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 240/1194 | Loss: 293.202 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 250/1194 | Loss: 311.441 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 260/1194 | Loss: 306.329 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 270/1194 | Loss: 305.548 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 280/1194 | Loss: 301.517 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 290/1194 | Loss: 304.229 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 300/1194 | Loss: 276.345 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 310/1194 | Loss: 307.640 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 320/1194 | Loss: 296.904 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 330/1194 | Loss: 294.325 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 340/1194 | Loss: 296.464 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 350/1194 | Loss: 293.564 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 360/1194 | Loss: 281.960 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 370/1194 | Loss: 272.192 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 380/1194 | Loss: 318.664 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 390/1194 | Loss: 299.879 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 400/1194 | Loss: 293.875 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 410/1194 | Loss: 300.910 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 420/1194 | Loss: 299.333 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 430/1194 | Loss: 286.236 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 440/1194 | Loss: 311.477 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 450/1194 | Loss: 316.489 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 460/1194 | Loss: 340.096 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 470/1194 | Loss: 291.704 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 480/1194 | Loss: 300.099 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 490/1194 | Loss: 297.327 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 500/1194 | Loss: 294.569 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 510/1194 | Loss: 312.285 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 520/1194 | Loss: 292.948 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 530/1194 | Loss: 294.444 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 540/1194 | Loss: 309.633 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 550/1194 | Loss: 290.531 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 560/1194 | Loss: 316.731 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 570/1194 | Loss: 296.454 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 580/1194 | Loss: 302.961 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 590/1194 | Loss: 289.843 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 600/1194 | Loss: 291.475 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 610/1194 | Loss: 270.092 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 620/1194 | Loss: 288.423 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 630/1194 | Loss: 272.152 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 640/1194 | Loss: 296.063 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 650/1194 | Loss: 307.399 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 660/1194 | Loss: 302.821 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 670/1194 | Loss: 314.213 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 680/1194 | Loss: 293.357 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 690/1194 | Loss: 304.467 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 700/1194 | Loss: 310.194 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 710/1194 | Loss: 301.224 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 720/1194 | Loss: 288.750 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 730/1194 | Loss: 300.275 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 740/1194 | Loss: 296.324 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 750/1194 | Loss: 304.720 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 760/1194 | Loss: 289.565 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 770/1194 | Loss: 293.167 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 780/1194 | Loss: 292.448 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 790/1194 | Loss: 299.210 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 800/1194 | Loss: 289.523 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 810/1194 | Loss: 298.115 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 820/1194 | Loss: 287.572 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 830/1194 | Loss: 294.387 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 840/1194 | Loss: 301.014 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 850/1194 | Loss: 293.886 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 860/1194 | Loss: 292.679 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 870/1194 | Loss: 297.568 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 880/1194 | Loss: 270.190 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 890/1194 | Loss: 287.798 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 900/1194 | Loss: 336.358 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 910/1194 | Loss: 304.358 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 920/1194 | Loss: 296.308 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 930/1194 | Loss: 296.480 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 940/1194 | Loss: 261.655 | Accuracy: 0.400\n",
      "[Epoch: 64/200] - Step: 950/1194 | Loss: 301.906 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 960/1194 | Loss: 306.853 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 970/1194 | Loss: 303.726 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 980/1194 | Loss: 300.953 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 990/1194 | Loss: 305.794 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1000/1194 | Loss: 300.091 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1010/1194 | Loss: 295.000 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1020/1194 | Loss: 304.528 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1030/1194 | Loss: 279.384 | Accuracy: 0.300\n",
      "[Epoch: 64/200] - Step: 1040/1194 | Loss: 302.700 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1050/1194 | Loss: 301.909 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1060/1194 | Loss: 302.129 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1070/1194 | Loss: 291.902 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1080/1194 | Loss: 294.885 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1090/1194 | Loss: 329.285 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1100/1194 | Loss: 306.773 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1110/1194 | Loss: 292.703 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 1120/1194 | Loss: 295.082 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1130/1194 | Loss: 300.295 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1140/1194 | Loss: 303.826 | Accuracy: 0.100\n",
      "[Epoch: 64/200] - Step: 1150/1194 | Loss: 290.712 | Accuracy: 0.200\n",
      "[Epoch: 64/200] - Step: 1160/1194 | Loss: 301.602 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1170/1194 | Loss: 299.332 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1180/1194 | Loss: 310.504 | Accuracy: 0.000\n",
      "[Epoch: 64/200] - Step: 1190/1194 | Loss: 295.720 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 65/200] - Step: 10/1194 | Loss: 298.619 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 20/1194 | Loss: 316.711 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 30/1194 | Loss: 282.790 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 40/1194 | Loss: 293.012 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 50/1194 | Loss: 300.489 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 60/1194 | Loss: 301.123 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 70/1194 | Loss: 299.194 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 80/1194 | Loss: 292.600 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 90/1194 | Loss: 301.148 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 100/1194 | Loss: 303.029 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 110/1194 | Loss: 280.128 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 120/1194 | Loss: 298.548 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 130/1194 | Loss: 293.854 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 140/1194 | Loss: 284.734 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 150/1194 | Loss: 304.214 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 160/1194 | Loss: 292.919 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 170/1194 | Loss: 293.307 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 180/1194 | Loss: 289.202 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 190/1194 | Loss: 313.895 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 200/1194 | Loss: 303.012 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 210/1194 | Loss: 291.843 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 220/1194 | Loss: 307.581 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 230/1194 | Loss: 314.282 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 240/1194 | Loss: 295.378 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 250/1194 | Loss: 301.983 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 260/1194 | Loss: 286.736 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 270/1194 | Loss: 304.413 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 280/1194 | Loss: 304.921 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 290/1194 | Loss: 291.196 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 300/1194 | Loss: 284.356 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 310/1194 | Loss: 309.330 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 320/1194 | Loss: 306.307 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 330/1194 | Loss: 296.810 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 340/1194 | Loss: 287.657 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 350/1194 | Loss: 270.559 | Accuracy: 0.400\n",
      "[Epoch: 65/200] - Step: 360/1194 | Loss: 287.895 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 370/1194 | Loss: 306.122 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 380/1194 | Loss: 301.312 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 390/1194 | Loss: 295.655 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 400/1194 | Loss: 290.366 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 410/1194 | Loss: 280.676 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 420/1194 | Loss: 281.838 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 430/1194 | Loss: 298.948 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 440/1194 | Loss: 335.793 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 450/1194 | Loss: 296.529 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 460/1194 | Loss: 294.827 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 470/1194 | Loss: 288.103 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 480/1194 | Loss: 285.780 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 490/1194 | Loss: 302.167 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 500/1194 | Loss: 286.507 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 510/1194 | Loss: 291.018 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 520/1194 | Loss: 329.813 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 530/1194 | Loss: 314.030 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 540/1194 | Loss: 299.997 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 550/1194 | Loss: 284.667 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 560/1194 | Loss: 285.610 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 570/1194 | Loss: 301.029 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 580/1194 | Loss: 285.781 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 590/1194 | Loss: 301.987 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 600/1194 | Loss: 296.059 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 610/1194 | Loss: 289.150 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 620/1194 | Loss: 301.008 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 630/1194 | Loss: 302.840 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 640/1194 | Loss: 313.282 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 650/1194 | Loss: 312.072 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 660/1194 | Loss: 286.028 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 670/1194 | Loss: 287.431 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 680/1194 | Loss: 289.770 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 690/1194 | Loss: 292.382 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 700/1194 | Loss: 308.894 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 710/1194 | Loss: 311.576 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 720/1194 | Loss: 299.403 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 730/1194 | Loss: 292.622 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 740/1194 | Loss: 276.910 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 750/1194 | Loss: 316.364 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 760/1194 | Loss: 301.147 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 770/1194 | Loss: 293.191 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 780/1194 | Loss: 294.461 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 790/1194 | Loss: 292.856 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 800/1194 | Loss: 291.212 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 810/1194 | Loss: 287.925 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 820/1194 | Loss: 296.723 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 830/1194 | Loss: 281.305 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 840/1194 | Loss: 285.619 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 850/1194 | Loss: 304.172 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 860/1194 | Loss: 291.690 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 870/1194 | Loss: 308.300 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 880/1194 | Loss: 312.839 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 890/1194 | Loss: 323.673 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 900/1194 | Loss: 306.326 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 910/1194 | Loss: 327.993 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 920/1194 | Loss: 295.717 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 930/1194 | Loss: 288.003 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 940/1194 | Loss: 293.160 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 950/1194 | Loss: 302.315 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 960/1194 | Loss: 278.655 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 970/1194 | Loss: 296.428 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 980/1194 | Loss: 277.016 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 990/1194 | Loss: 309.853 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1000/1194 | Loss: 282.631 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 1010/1194 | Loss: 282.959 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 1020/1194 | Loss: 298.357 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1030/1194 | Loss: 282.296 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1040/1194 | Loss: 299.561 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1050/1194 | Loss: 292.427 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1060/1194 | Loss: 306.514 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 1070/1194 | Loss: 300.536 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 1080/1194 | Loss: 306.837 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 1090/1194 | Loss: 288.491 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 1100/1194 | Loss: 306.843 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 1110/1194 | Loss: 301.335 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1120/1194 | Loss: 304.705 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1130/1194 | Loss: 288.260 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1140/1194 | Loss: 305.455 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1150/1194 | Loss: 290.279 | Accuracy: 0.200\n",
      "[Epoch: 65/200] - Step: 1160/1194 | Loss: 322.734 | Accuracy: 0.000\n",
      "[Epoch: 65/200] - Step: 1170/1194 | Loss: 279.250 | Accuracy: 0.300\n",
      "[Epoch: 65/200] - Step: 1180/1194 | Loss: 294.585 | Accuracy: 0.100\n",
      "[Epoch: 65/200] - Step: 1190/1194 | Loss: 288.075 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 66/200] - Step: 10/1194 | Loss: 299.837 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 20/1194 | Loss: 311.176 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 30/1194 | Loss: 303.318 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 40/1194 | Loss: 292.071 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 50/1194 | Loss: 301.758 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 60/1194 | Loss: 295.503 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 70/1194 | Loss: 314.399 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 80/1194 | Loss: 292.588 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 90/1194 | Loss: 309.213 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 100/1194 | Loss: 307.541 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 110/1194 | Loss: 306.203 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 120/1194 | Loss: 294.613 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 130/1194 | Loss: 291.881 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 140/1194 | Loss: 290.582 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 150/1194 | Loss: 286.412 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 160/1194 | Loss: 309.431 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 170/1194 | Loss: 281.557 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 180/1194 | Loss: 299.342 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 190/1194 | Loss: 282.448 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 200/1194 | Loss: 280.261 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 210/1194 | Loss: 306.440 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 220/1194 | Loss: 286.578 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 230/1194 | Loss: 279.692 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 240/1194 | Loss: 279.023 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 250/1194 | Loss: 291.787 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 260/1194 | Loss: 304.168 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 270/1194 | Loss: 295.877 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 280/1194 | Loss: 292.002 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 290/1194 | Loss: 300.822 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 300/1194 | Loss: 276.760 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 310/1194 | Loss: 271.097 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 320/1194 | Loss: 293.076 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 330/1194 | Loss: 313.935 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 340/1194 | Loss: 289.643 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 350/1194 | Loss: 319.079 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 360/1194 | Loss: 338.354 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 370/1194 | Loss: 293.053 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 380/1194 | Loss: 303.164 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 390/1194 | Loss: 271.588 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 400/1194 | Loss: 273.963 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 410/1194 | Loss: 309.690 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 420/1194 | Loss: 257.639 | Accuracy: 0.400\n",
      "[Epoch: 66/200] - Step: 430/1194 | Loss: 307.021 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 440/1194 | Loss: 307.088 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 450/1194 | Loss: 281.970 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 460/1194 | Loss: 310.713 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 470/1194 | Loss: 335.508 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 480/1194 | Loss: 328.913 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 490/1194 | Loss: 298.217 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 500/1194 | Loss: 302.784 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 510/1194 | Loss: 295.665 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 520/1194 | Loss: 296.930 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 530/1194 | Loss: 293.693 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 540/1194 | Loss: 307.188 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 550/1194 | Loss: 288.030 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 560/1194 | Loss: 302.428 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 570/1194 | Loss: 301.531 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 580/1194 | Loss: 298.806 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 590/1194 | Loss: 296.276 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 600/1194 | Loss: 326.764 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 610/1194 | Loss: 301.548 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 620/1194 | Loss: 292.946 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 630/1194 | Loss: 298.379 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 640/1194 | Loss: 290.055 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 650/1194 | Loss: 292.190 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 660/1194 | Loss: 301.315 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 670/1194 | Loss: 284.963 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 680/1194 | Loss: 304.966 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 690/1194 | Loss: 302.648 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 700/1194 | Loss: 281.426 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 710/1194 | Loss: 303.761 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 720/1194 | Loss: 296.586 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 730/1194 | Loss: 292.383 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 740/1194 | Loss: 288.283 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 750/1194 | Loss: 295.955 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 760/1194 | Loss: 281.546 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 770/1194 | Loss: 293.468 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 780/1194 | Loss: 290.923 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 790/1194 | Loss: 286.863 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 800/1194 | Loss: 296.977 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 810/1194 | Loss: 306.201 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 820/1194 | Loss: 283.193 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 830/1194 | Loss: 272.465 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 840/1194 | Loss: 295.798 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 850/1194 | Loss: 285.484 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 860/1194 | Loss: 273.790 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 870/1194 | Loss: 304.733 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 880/1194 | Loss: 286.980 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 890/1194 | Loss: 321.702 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 900/1194 | Loss: 336.607 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 910/1194 | Loss: 301.829 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 920/1194 | Loss: 310.567 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 930/1194 | Loss: 286.000 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 940/1194 | Loss: 294.020 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 950/1194 | Loss: 305.739 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 960/1194 | Loss: 295.104 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 970/1194 | Loss: 308.361 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 980/1194 | Loss: 297.280 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 990/1194 | Loss: 306.157 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 1000/1194 | Loss: 304.874 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1010/1194 | Loss: 290.975 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1020/1194 | Loss: 302.036 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 1030/1194 | Loss: 295.355 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1040/1194 | Loss: 292.657 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1050/1194 | Loss: 305.701 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1060/1194 | Loss: 300.193 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1070/1194 | Loss: 296.682 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1080/1194 | Loss: 287.297 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 1090/1194 | Loss: 295.450 | Accuracy: 0.200\n",
      "[Epoch: 66/200] - Step: 1100/1194 | Loss: 302.769 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1110/1194 | Loss: 295.516 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1120/1194 | Loss: 296.507 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1130/1194 | Loss: 305.952 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1140/1194 | Loss: 312.121 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 1150/1194 | Loss: 302.389 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 1160/1194 | Loss: 288.570 | Accuracy: 0.300\n",
      "[Epoch: 66/200] - Step: 1170/1194 | Loss: 292.339 | Accuracy: 0.100\n",
      "[Epoch: 66/200] - Step: 1180/1194 | Loss: 302.702 | Accuracy: 0.000\n",
      "[Epoch: 66/200] - Step: 1190/1194 | Loss: 269.335 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 67/200] - Step: 10/1194 | Loss: 281.990 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 20/1194 | Loss: 277.641 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 30/1194 | Loss: 286.615 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 40/1194 | Loss: 280.887 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 50/1194 | Loss: 306.193 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 60/1194 | Loss: 311.015 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 70/1194 | Loss: 299.991 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 80/1194 | Loss: 295.280 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 90/1194 | Loss: 298.676 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 100/1194 | Loss: 292.870 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 110/1194 | Loss: 300.102 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 120/1194 | Loss: 300.385 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 130/1194 | Loss: 278.346 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 140/1194 | Loss: 288.805 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 150/1194 | Loss: 307.389 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 160/1194 | Loss: 316.138 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 170/1194 | Loss: 294.967 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 180/1194 | Loss: 303.681 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 190/1194 | Loss: 289.814 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 200/1194 | Loss: 296.110 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 210/1194 | Loss: 293.102 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 220/1194 | Loss: 285.559 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 230/1194 | Loss: 296.629 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 240/1194 | Loss: 304.916 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 250/1194 | Loss: 320.757 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 260/1194 | Loss: 295.520 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 270/1194 | Loss: 311.665 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 280/1194 | Loss: 324.703 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 290/1194 | Loss: 286.936 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 300/1194 | Loss: 299.683 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 310/1194 | Loss: 287.303 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 320/1194 | Loss: 292.676 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 330/1194 | Loss: 308.937 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 340/1194 | Loss: 286.068 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 350/1194 | Loss: 314.795 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 360/1194 | Loss: 287.975 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 370/1194 | Loss: 299.250 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 380/1194 | Loss: 295.976 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 390/1194 | Loss: 307.978 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 400/1194 | Loss: 328.010 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 410/1194 | Loss: 305.340 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 420/1194 | Loss: 292.872 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 430/1194 | Loss: 302.225 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 440/1194 | Loss: 297.662 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 450/1194 | Loss: 271.346 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 460/1194 | Loss: 291.262 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 470/1194 | Loss: 292.761 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 480/1194 | Loss: 262.177 | Accuracy: 0.600\n",
      "[Epoch: 67/200] - Step: 490/1194 | Loss: 290.480 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 500/1194 | Loss: 302.895 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 510/1194 | Loss: 287.220 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 520/1194 | Loss: 299.010 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 530/1194 | Loss: 316.434 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 540/1194 | Loss: 282.558 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 550/1194 | Loss: 291.455 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 560/1194 | Loss: 282.594 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 570/1194 | Loss: 292.857 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 580/1194 | Loss: 294.698 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 590/1194 | Loss: 289.928 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 600/1194 | Loss: 336.027 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 610/1194 | Loss: 304.804 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 620/1194 | Loss: 305.911 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 630/1194 | Loss: 292.601 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 640/1194 | Loss: 275.452 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 650/1194 | Loss: 300.042 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 660/1194 | Loss: 300.286 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 670/1194 | Loss: 306.191 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 680/1194 | Loss: 301.684 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 690/1194 | Loss: 293.251 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 700/1194 | Loss: 304.480 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 710/1194 | Loss: 308.205 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 720/1194 | Loss: 299.958 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 730/1194 | Loss: 297.464 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 740/1194 | Loss: 271.310 | Accuracy: 0.400\n",
      "[Epoch: 67/200] - Step: 750/1194 | Loss: 283.246 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 760/1194 | Loss: 286.745 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 770/1194 | Loss: 290.517 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 780/1194 | Loss: 282.059 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 790/1194 | Loss: 282.023 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 800/1194 | Loss: 293.915 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 810/1194 | Loss: 308.410 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 820/1194 | Loss: 339.266 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 830/1194 | Loss: 300.017 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 840/1194 | Loss: 302.324 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 850/1194 | Loss: 277.889 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 860/1194 | Loss: 305.153 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 870/1194 | Loss: 295.036 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 880/1194 | Loss: 305.961 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 890/1194 | Loss: 299.010 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 900/1194 | Loss: 286.014 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 910/1194 | Loss: 301.426 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 920/1194 | Loss: 305.470 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 930/1194 | Loss: 312.699 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 940/1194 | Loss: 295.477 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 950/1194 | Loss: 299.913 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 960/1194 | Loss: 302.253 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 970/1194 | Loss: 288.854 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 980/1194 | Loss: 293.953 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 990/1194 | Loss: 332.378 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1000/1194 | Loss: 315.885 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1010/1194 | Loss: 296.987 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 1020/1194 | Loss: 293.043 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1030/1194 | Loss: 291.883 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1040/1194 | Loss: 288.785 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 1050/1194 | Loss: 287.031 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 1060/1194 | Loss: 309.381 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1070/1194 | Loss: 292.465 | Accuracy: 0.500\n",
      "[Epoch: 67/200] - Step: 1080/1194 | Loss: 298.371 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1090/1194 | Loss: 300.268 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1100/1194 | Loss: 295.253 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1110/1194 | Loss: 291.421 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 1120/1194 | Loss: 302.112 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1130/1194 | Loss: 298.697 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 1140/1194 | Loss: 303.600 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1150/1194 | Loss: 280.719 | Accuracy: 0.300\n",
      "[Epoch: 67/200] - Step: 1160/1194 | Loss: 301.134 | Accuracy: 0.000\n",
      "[Epoch: 67/200] - Step: 1170/1194 | Loss: 281.361 | Accuracy: 0.200\n",
      "[Epoch: 67/200] - Step: 1180/1194 | Loss: 286.882 | Accuracy: 0.100\n",
      "[Epoch: 67/200] - Step: 1190/1194 | Loss: 307.392 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 68/200] - Step: 10/1194 | Loss: 293.557 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 20/1194 | Loss: 291.815 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 30/1194 | Loss: 289.942 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 40/1194 | Loss: 305.741 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 50/1194 | Loss: 301.608 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 60/1194 | Loss: 294.786 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 70/1194 | Loss: 310.734 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 80/1194 | Loss: 285.666 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 90/1194 | Loss: 291.680 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 100/1194 | Loss: 296.893 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 110/1194 | Loss: 304.432 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 120/1194 | Loss: 296.395 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 130/1194 | Loss: 305.411 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 140/1194 | Loss: 266.436 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 150/1194 | Loss: 301.721 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 160/1194 | Loss: 295.635 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 170/1194 | Loss: 292.153 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 180/1194 | Loss: 331.096 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 190/1194 | Loss: 333.885 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 200/1194 | Loss: 305.673 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 210/1194 | Loss: 293.615 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 220/1194 | Loss: 287.740 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 230/1194 | Loss: 291.583 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 240/1194 | Loss: 301.151 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 250/1194 | Loss: 315.452 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 260/1194 | Loss: 322.140 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 270/1194 | Loss: 302.539 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 280/1194 | Loss: 292.568 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 290/1194 | Loss: 305.325 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 300/1194 | Loss: 299.730 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 310/1194 | Loss: 285.856 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 320/1194 | Loss: 306.695 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 330/1194 | Loss: 290.161 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 340/1194 | Loss: 290.795 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 350/1194 | Loss: 293.065 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 360/1194 | Loss: 308.994 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 370/1194 | Loss: 278.710 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 380/1194 | Loss: 309.876 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 390/1194 | Loss: 304.026 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 400/1194 | Loss: 301.061 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 410/1194 | Loss: 277.236 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 420/1194 | Loss: 299.572 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 430/1194 | Loss: 280.863 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 440/1194 | Loss: 297.631 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 450/1194 | Loss: 293.610 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 460/1194 | Loss: 307.881 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 470/1194 | Loss: 300.808 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 480/1194 | Loss: 289.678 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 490/1194 | Loss: 281.010 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 500/1194 | Loss: 306.376 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 510/1194 | Loss: 302.678 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 520/1194 | Loss: 303.544 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 530/1194 | Loss: 285.007 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 540/1194 | Loss: 279.298 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 550/1194 | Loss: 332.608 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 560/1194 | Loss: 292.257 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 570/1194 | Loss: 290.238 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 580/1194 | Loss: 288.923 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 590/1194 | Loss: 287.543 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 600/1194 | Loss: 301.991 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 610/1194 | Loss: 305.681 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 620/1194 | Loss: 309.910 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 630/1194 | Loss: 294.354 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 640/1194 | Loss: 321.271 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 650/1194 | Loss: 289.115 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 660/1194 | Loss: 287.918 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 670/1194 | Loss: 285.439 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 680/1194 | Loss: 301.516 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 690/1194 | Loss: 278.702 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 700/1194 | Loss: 306.513 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 710/1194 | Loss: 301.526 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 720/1194 | Loss: 309.082 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 730/1194 | Loss: 292.637 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 740/1194 | Loss: 306.984 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 750/1194 | Loss: 307.353 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 760/1194 | Loss: 298.092 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 770/1194 | Loss: 289.100 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 780/1194 | Loss: 307.608 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 790/1194 | Loss: 302.549 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 800/1194 | Loss: 294.361 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 810/1194 | Loss: 267.201 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 820/1194 | Loss: 310.440 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 830/1194 | Loss: 295.695 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 840/1194 | Loss: 304.167 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 850/1194 | Loss: 297.451 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 860/1194 | Loss: 292.130 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 870/1194 | Loss: 292.998 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 880/1194 | Loss: 309.721 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 890/1194 | Loss: 281.960 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 900/1194 | Loss: 304.977 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 910/1194 | Loss: 299.821 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 920/1194 | Loss: 277.677 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 930/1194 | Loss: 289.576 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 940/1194 | Loss: 309.303 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 950/1194 | Loss: 300.140 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 960/1194 | Loss: 332.977 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 970/1194 | Loss: 269.028 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 980/1194 | Loss: 302.945 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 990/1194 | Loss: 300.777 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1000/1194 | Loss: 286.966 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 1010/1194 | Loss: 293.693 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1020/1194 | Loss: 290.665 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 1030/1194 | Loss: 315.887 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1040/1194 | Loss: 297.014 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1050/1194 | Loss: 287.740 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 1060/1194 | Loss: 290.897 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 1070/1194 | Loss: 302.727 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 1080/1194 | Loss: 273.718 | Accuracy: 0.300\n",
      "[Epoch: 68/200] - Step: 1090/1194 | Loss: 310.608 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1100/1194 | Loss: 291.343 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 1110/1194 | Loss: 296.387 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1120/1194 | Loss: 286.627 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 1130/1194 | Loss: 269.104 | Accuracy: 0.500\n",
      "[Epoch: 68/200] - Step: 1140/1194 | Loss: 258.597 | Accuracy: 0.400\n",
      "[Epoch: 68/200] - Step: 1150/1194 | Loss: 302.186 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1160/1194 | Loss: 310.559 | Accuracy: 0.100\n",
      "[Epoch: 68/200] - Step: 1170/1194 | Loss: 279.141 | Accuracy: 0.200\n",
      "[Epoch: 68/200] - Step: 1180/1194 | Loss: 293.786 | Accuracy: 0.000\n",
      "[Epoch: 68/200] - Step: 1190/1194 | Loss: 314.216 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 69/200] - Step: 10/1194 | Loss: 290.970 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 20/1194 | Loss: 297.759 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 30/1194 | Loss: 295.423 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 40/1194 | Loss: 302.235 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 50/1194 | Loss: 303.895 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 60/1194 | Loss: 285.419 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 70/1194 | Loss: 310.497 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 80/1194 | Loss: 284.307 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 90/1194 | Loss: 297.681 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 100/1194 | Loss: 290.100 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 110/1194 | Loss: 302.789 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 120/1194 | Loss: 284.516 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 130/1194 | Loss: 303.908 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 140/1194 | Loss: 290.860 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 150/1194 | Loss: 282.214 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 160/1194 | Loss: 283.441 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 170/1194 | Loss: 293.818 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 180/1194 | Loss: 303.369 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 190/1194 | Loss: 298.212 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 200/1194 | Loss: 296.592 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 210/1194 | Loss: 299.498 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 220/1194 | Loss: 287.202 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 230/1194 | Loss: 287.851 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 240/1194 | Loss: 289.853 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 250/1194 | Loss: 308.095 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 260/1194 | Loss: 285.859 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 270/1194 | Loss: 299.709 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 280/1194 | Loss: 298.870 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 290/1194 | Loss: 277.396 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 300/1194 | Loss: 305.643 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 310/1194 | Loss: 301.357 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 320/1194 | Loss: 278.317 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 330/1194 | Loss: 276.474 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 340/1194 | Loss: 283.259 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 350/1194 | Loss: 295.458 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 360/1194 | Loss: 314.281 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 370/1194 | Loss: 286.559 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 380/1194 | Loss: 308.531 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 390/1194 | Loss: 305.341 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 400/1194 | Loss: 283.322 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 410/1194 | Loss: 304.706 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 420/1194 | Loss: 286.419 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 430/1194 | Loss: 300.058 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 440/1194 | Loss: 304.424 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 450/1194 | Loss: 296.205 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 460/1194 | Loss: 296.841 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 470/1194 | Loss: 284.476 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 480/1194 | Loss: 284.544 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 490/1194 | Loss: 299.193 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 500/1194 | Loss: 316.734 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 510/1194 | Loss: 325.359 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 520/1194 | Loss: 302.974 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 530/1194 | Loss: 282.560 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 540/1194 | Loss: 295.343 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 550/1194 | Loss: 286.439 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 560/1194 | Loss: 297.111 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 570/1194 | Loss: 284.356 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 580/1194 | Loss: 309.071 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 590/1194 | Loss: 309.120 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 600/1194 | Loss: 301.574 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 610/1194 | Loss: 297.393 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 620/1194 | Loss: 289.950 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 630/1194 | Loss: 306.939 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 640/1194 | Loss: 289.627 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 650/1194 | Loss: 318.724 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 660/1194 | Loss: 304.034 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 670/1194 | Loss: 296.590 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 680/1194 | Loss: 303.051 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 690/1194 | Loss: 303.688 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 700/1194 | Loss: 291.061 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 710/1194 | Loss: 302.958 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 720/1194 | Loss: 284.420 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 730/1194 | Loss: 309.983 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 740/1194 | Loss: 301.873 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 750/1194 | Loss: 283.418 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 760/1194 | Loss: 275.961 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 770/1194 | Loss: 317.699 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 780/1194 | Loss: 287.276 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 790/1194 | Loss: 298.059 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 800/1194 | Loss: 294.428 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 810/1194 | Loss: 291.732 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 820/1194 | Loss: 300.611 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 830/1194 | Loss: 293.759 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 840/1194 | Loss: 296.770 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 850/1194 | Loss: 290.907 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 860/1194 | Loss: 297.348 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 870/1194 | Loss: 274.470 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 880/1194 | Loss: 296.013 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 890/1194 | Loss: 290.098 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 900/1194 | Loss: 254.752 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 910/1194 | Loss: 297.117 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 920/1194 | Loss: 299.075 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 930/1194 | Loss: 342.771 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 940/1194 | Loss: 295.748 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 950/1194 | Loss: 309.174 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 960/1194 | Loss: 287.158 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 970/1194 | Loss: 333.691 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 980/1194 | Loss: 286.049 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 990/1194 | Loss: 308.247 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1000/1194 | Loss: 310.735 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1010/1194 | Loss: 299.469 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1020/1194 | Loss: 303.522 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1030/1194 | Loss: 302.189 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1040/1194 | Loss: 305.218 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1050/1194 | Loss: 326.356 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1060/1194 | Loss: 283.087 | Accuracy: 0.300\n",
      "[Epoch: 69/200] - Step: 1070/1194 | Loss: 308.124 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1080/1194 | Loss: 300.208 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1090/1194 | Loss: 304.065 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1100/1194 | Loss: 282.218 | Accuracy: 0.400\n",
      "[Epoch: 69/200] - Step: 1110/1194 | Loss: 316.259 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1120/1194 | Loss: 299.835 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1130/1194 | Loss: 295.369 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 1140/1194 | Loss: 298.808 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 1150/1194 | Loss: 301.004 | Accuracy: 0.000\n",
      "[Epoch: 69/200] - Step: 1160/1194 | Loss: 294.743 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 1170/1194 | Loss: 295.640 | Accuracy: 0.100\n",
      "[Epoch: 69/200] - Step: 1180/1194 | Loss: 286.034 | Accuracy: 0.200\n",
      "[Epoch: 69/200] - Step: 1190/1194 | Loss: 301.376 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 70/200] - Step: 10/1194 | Loss: 282.490 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 20/1194 | Loss: 305.645 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 30/1194 | Loss: 297.012 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 40/1194 | Loss: 301.577 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 50/1194 | Loss: 294.937 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 60/1194 | Loss: 289.613 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 70/1194 | Loss: 289.589 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 80/1194 | Loss: 300.240 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 90/1194 | Loss: 298.264 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 100/1194 | Loss: 316.050 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 110/1194 | Loss: 301.050 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 120/1194 | Loss: 306.490 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 130/1194 | Loss: 283.286 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 140/1194 | Loss: 296.734 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 150/1194 | Loss: 312.862 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 160/1194 | Loss: 288.683 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 170/1194 | Loss: 280.459 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 180/1194 | Loss: 291.429 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 190/1194 | Loss: 314.176 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 200/1194 | Loss: 294.671 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 210/1194 | Loss: 297.562 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 220/1194 | Loss: 302.009 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 230/1194 | Loss: 305.534 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 240/1194 | Loss: 288.239 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 250/1194 | Loss: 301.959 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 260/1194 | Loss: 291.509 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 270/1194 | Loss: 308.997 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 280/1194 | Loss: 304.949 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 290/1194 | Loss: 289.973 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 300/1194 | Loss: 315.428 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 310/1194 | Loss: 296.571 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 320/1194 | Loss: 293.561 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 330/1194 | Loss: 289.166 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 340/1194 | Loss: 307.352 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 350/1194 | Loss: 286.478 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 360/1194 | Loss: 294.436 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 370/1194 | Loss: 302.277 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 380/1194 | Loss: 296.872 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 390/1194 | Loss: 301.282 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 400/1194 | Loss: 291.630 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 410/1194 | Loss: 295.712 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 420/1194 | Loss: 310.403 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 430/1194 | Loss: 295.420 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 440/1194 | Loss: 294.451 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 450/1194 | Loss: 296.071 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 460/1194 | Loss: 292.077 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 470/1194 | Loss: 308.874 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 480/1194 | Loss: 291.653 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 490/1194 | Loss: 291.920 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 500/1194 | Loss: 283.140 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 510/1194 | Loss: 306.771 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 520/1194 | Loss: 284.970 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 530/1194 | Loss: 306.394 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 540/1194 | Loss: 286.227 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 550/1194 | Loss: 293.583 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 560/1194 | Loss: 300.198 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 570/1194 | Loss: 310.404 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 580/1194 | Loss: 324.209 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 590/1194 | Loss: 293.320 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 600/1194 | Loss: 296.926 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 610/1194 | Loss: 306.568 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 620/1194 | Loss: 304.121 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 630/1194 | Loss: 299.103 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 640/1194 | Loss: 287.235 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 650/1194 | Loss: 301.990 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 660/1194 | Loss: 298.814 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 670/1194 | Loss: 294.776 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 680/1194 | Loss: 301.073 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 690/1194 | Loss: 299.944 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 700/1194 | Loss: 289.073 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 710/1194 | Loss: 296.893 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 720/1194 | Loss: 301.684 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 730/1194 | Loss: 302.199 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 740/1194 | Loss: 301.433 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 750/1194 | Loss: 298.481 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 760/1194 | Loss: 280.922 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 770/1194 | Loss: 291.845 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 780/1194 | Loss: 289.886 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 790/1194 | Loss: 306.734 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 800/1194 | Loss: 296.925 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 810/1194 | Loss: 284.284 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 820/1194 | Loss: 280.358 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 830/1194 | Loss: 291.361 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 840/1194 | Loss: 298.833 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 850/1194 | Loss: 303.391 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 860/1194 | Loss: 295.093 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 870/1194 | Loss: 334.342 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 880/1194 | Loss: 300.795 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 890/1194 | Loss: 298.642 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 900/1194 | Loss: 317.163 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 910/1194 | Loss: 305.678 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 920/1194 | Loss: 304.006 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 930/1194 | Loss: 289.491 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 940/1194 | Loss: 279.741 | Accuracy: 0.400\n",
      "[Epoch: 70/200] - Step: 950/1194 | Loss: 290.999 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 960/1194 | Loss: 298.768 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 970/1194 | Loss: 285.748 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 980/1194 | Loss: 294.994 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 990/1194 | Loss: 302.818 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 1000/1194 | Loss: 275.904 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 1010/1194 | Loss: 281.515 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1020/1194 | Loss: 303.300 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 1030/1194 | Loss: 286.620 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 1040/1194 | Loss: 310.586 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 1050/1194 | Loss: 291.743 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1060/1194 | Loss: 308.865 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 1070/1194 | Loss: 292.688 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 1080/1194 | Loss: 299.787 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 1090/1194 | Loss: 284.886 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1100/1194 | Loss: 305.922 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 1110/1194 | Loss: 289.227 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1120/1194 | Loss: 330.740 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 1130/1194 | Loss: 295.647 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1140/1194 | Loss: 274.511 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1150/1194 | Loss: 265.613 | Accuracy: 0.300\n",
      "[Epoch: 70/200] - Step: 1160/1194 | Loss: 289.949 | Accuracy: 0.200\n",
      "[Epoch: 70/200] - Step: 1170/1194 | Loss: 290.828 | Accuracy: 0.100\n",
      "[Epoch: 70/200] - Step: 1180/1194 | Loss: 323.480 | Accuracy: 0.000\n",
      "[Epoch: 70/200] - Step: 1190/1194 | Loss: 304.048 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 71/200] - Step: 10/1194 | Loss: 285.629 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 20/1194 | Loss: 304.411 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 30/1194 | Loss: 284.196 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 40/1194 | Loss: 303.641 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 50/1194 | Loss: 302.242 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 60/1194 | Loss: 293.761 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 70/1194 | Loss: 309.114 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 80/1194 | Loss: 286.996 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 90/1194 | Loss: 307.747 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 100/1194 | Loss: 312.372 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 110/1194 | Loss: 292.249 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 120/1194 | Loss: 292.701 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 130/1194 | Loss: 280.838 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 140/1194 | Loss: 307.161 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 150/1194 | Loss: 302.464 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 160/1194 | Loss: 345.850 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 170/1194 | Loss: 286.926 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 180/1194 | Loss: 290.105 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 190/1194 | Loss: 301.360 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 200/1194 | Loss: 292.338 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 210/1194 | Loss: 302.391 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 220/1194 | Loss: 314.057 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 230/1194 | Loss: 304.422 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 240/1194 | Loss: 293.397 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 250/1194 | Loss: 295.912 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 260/1194 | Loss: 288.118 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 270/1194 | Loss: 288.618 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 280/1194 | Loss: 285.160 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 290/1194 | Loss: 293.411 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 300/1194 | Loss: 278.428 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 310/1194 | Loss: 297.529 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 320/1194 | Loss: 284.016 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 330/1194 | Loss: 300.576 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 340/1194 | Loss: 275.106 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 350/1194 | Loss: 296.506 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 360/1194 | Loss: 290.430 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 370/1194 | Loss: 290.768 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 380/1194 | Loss: 291.855 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 390/1194 | Loss: 265.105 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 400/1194 | Loss: 306.814 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 410/1194 | Loss: 307.574 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 420/1194 | Loss: 291.690 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 430/1194 | Loss: 297.812 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 440/1194 | Loss: 342.075 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 450/1194 | Loss: 287.139 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 460/1194 | Loss: 298.370 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 470/1194 | Loss: 279.952 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 480/1194 | Loss: 288.970 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 490/1194 | Loss: 301.839 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 500/1194 | Loss: 336.077 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 510/1194 | Loss: 295.104 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 520/1194 | Loss: 292.030 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 530/1194 | Loss: 332.506 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 540/1194 | Loss: 293.078 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 550/1194 | Loss: 304.644 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 560/1194 | Loss: 296.218 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 570/1194 | Loss: 286.822 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 580/1194 | Loss: 290.510 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 590/1194 | Loss: 270.674 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 600/1194 | Loss: 302.131 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 610/1194 | Loss: 294.127 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 620/1194 | Loss: 302.638 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 630/1194 | Loss: 299.731 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 640/1194 | Loss: 307.305 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 650/1194 | Loss: 306.470 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 660/1194 | Loss: 297.028 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 670/1194 | Loss: 292.449 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 680/1194 | Loss: 303.499 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 690/1194 | Loss: 306.203 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 700/1194 | Loss: 299.590 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 710/1194 | Loss: 299.623 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 720/1194 | Loss: 290.984 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 730/1194 | Loss: 298.438 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 740/1194 | Loss: 299.013 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 750/1194 | Loss: 300.517 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 760/1194 | Loss: 285.562 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 770/1194 | Loss: 299.354 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 780/1194 | Loss: 292.325 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 790/1194 | Loss: 292.405 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 800/1194 | Loss: 279.585 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 810/1194 | Loss: 274.861 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 820/1194 | Loss: 289.690 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 830/1194 | Loss: 310.820 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 840/1194 | Loss: 303.092 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 850/1194 | Loss: 302.932 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 860/1194 | Loss: 294.504 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 870/1194 | Loss: 289.161 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 880/1194 | Loss: 300.155 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 890/1194 | Loss: 313.744 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 900/1194 | Loss: 279.081 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 910/1194 | Loss: 296.625 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 920/1194 | Loss: 300.495 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 930/1194 | Loss: 294.304 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 940/1194 | Loss: 306.372 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 950/1194 | Loss: 282.107 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 960/1194 | Loss: 278.503 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 970/1194 | Loss: 298.544 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 980/1194 | Loss: 307.050 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 990/1194 | Loss: 304.504 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 1000/1194 | Loss: 293.857 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 1010/1194 | Loss: 309.524 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1020/1194 | Loss: 294.163 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1030/1194 | Loss: 275.398 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 1040/1194 | Loss: 288.406 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 1050/1194 | Loss: 314.710 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 1060/1194 | Loss: 294.656 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1070/1194 | Loss: 284.922 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 1080/1194 | Loss: 300.308 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1090/1194 | Loss: 280.628 | Accuracy: 0.300\n",
      "[Epoch: 71/200] - Step: 1100/1194 | Loss: 314.913 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 1110/1194 | Loss: 309.705 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 1120/1194 | Loss: 294.292 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1130/1194 | Loss: 288.005 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1140/1194 | Loss: 292.814 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1150/1194 | Loss: 297.224 | Accuracy: 0.100\n",
      "[Epoch: 71/200] - Step: 1160/1194 | Loss: 337.281 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 1170/1194 | Loss: 289.411 | Accuracy: 0.200\n",
      "[Epoch: 71/200] - Step: 1180/1194 | Loss: 300.272 | Accuracy: 0.000\n",
      "[Epoch: 71/200] - Step: 1190/1194 | Loss: 301.699 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 72/200] - Step: 10/1194 | Loss: 297.261 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 20/1194 | Loss: 289.286 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 30/1194 | Loss: 304.410 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 40/1194 | Loss: 293.522 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 50/1194 | Loss: 301.248 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 60/1194 | Loss: 331.928 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 70/1194 | Loss: 289.244 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 80/1194 | Loss: 309.078 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 90/1194 | Loss: 302.039 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 100/1194 | Loss: 305.187 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 110/1194 | Loss: 300.078 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 120/1194 | Loss: 315.624 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 130/1194 | Loss: 298.149 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 140/1194 | Loss: 298.283 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 150/1194 | Loss: 306.665 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 160/1194 | Loss: 304.756 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 170/1194 | Loss: 287.151 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 180/1194 | Loss: 300.410 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 190/1194 | Loss: 299.769 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 200/1194 | Loss: 283.700 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 210/1194 | Loss: 305.333 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 220/1194 | Loss: 295.665 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 230/1194 | Loss: 299.471 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 240/1194 | Loss: 303.243 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 250/1194 | Loss: 291.664 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 260/1194 | Loss: 284.010 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 270/1194 | Loss: 283.272 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 280/1194 | Loss: 289.102 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 290/1194 | Loss: 277.662 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 300/1194 | Loss: 274.489 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 310/1194 | Loss: 299.978 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 320/1194 | Loss: 294.911 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 330/1194 | Loss: 291.324 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 340/1194 | Loss: 275.045 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 350/1194 | Loss: 274.115 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 360/1194 | Loss: 304.807 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 370/1194 | Loss: 292.969 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 380/1194 | Loss: 282.911 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 390/1194 | Loss: 280.804 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 400/1194 | Loss: 305.600 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 410/1194 | Loss: 319.112 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 420/1194 | Loss: 271.882 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 430/1194 | Loss: 300.523 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 440/1194 | Loss: 291.710 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 450/1194 | Loss: 293.673 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 460/1194 | Loss: 315.477 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 470/1194 | Loss: 303.528 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 480/1194 | Loss: 296.984 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 490/1194 | Loss: 314.702 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 500/1194 | Loss: 288.676 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 510/1194 | Loss: 299.185 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 520/1194 | Loss: 329.874 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 530/1194 | Loss: 297.712 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 540/1194 | Loss: 287.521 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 550/1194 | Loss: 305.924 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 560/1194 | Loss: 295.613 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 570/1194 | Loss: 286.824 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 580/1194 | Loss: 286.931 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 590/1194 | Loss: 298.035 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 600/1194 | Loss: 293.093 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 610/1194 | Loss: 281.853 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 620/1194 | Loss: 298.953 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 630/1194 | Loss: 292.743 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 640/1194 | Loss: 305.525 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 650/1194 | Loss: 279.429 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 660/1194 | Loss: 286.456 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 670/1194 | Loss: 304.521 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 680/1194 | Loss: 310.553 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 690/1194 | Loss: 312.886 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 700/1194 | Loss: 301.128 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 710/1194 | Loss: 307.548 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 720/1194 | Loss: 295.168 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 730/1194 | Loss: 300.422 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 740/1194 | Loss: 295.363 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 750/1194 | Loss: 304.694 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 760/1194 | Loss: 301.822 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 770/1194 | Loss: 300.894 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 780/1194 | Loss: 291.383 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 790/1194 | Loss: 286.232 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 800/1194 | Loss: 299.135 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 810/1194 | Loss: 305.301 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 820/1194 | Loss: 283.758 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 830/1194 | Loss: 308.844 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 840/1194 | Loss: 297.020 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 850/1194 | Loss: 340.045 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 860/1194 | Loss: 303.610 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 870/1194 | Loss: 280.540 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 880/1194 | Loss: 302.070 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 890/1194 | Loss: 292.888 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 900/1194 | Loss: 295.607 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 910/1194 | Loss: 299.976 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 920/1194 | Loss: 288.429 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 930/1194 | Loss: 279.969 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 940/1194 | Loss: 306.112 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 950/1194 | Loss: 301.798 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 960/1194 | Loss: 300.764 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 970/1194 | Loss: 305.937 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 980/1194 | Loss: 295.507 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 990/1194 | Loss: 290.203 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1000/1194 | Loss: 290.142 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 1010/1194 | Loss: 300.337 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 1020/1194 | Loss: 293.873 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1030/1194 | Loss: 294.789 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1040/1194 | Loss: 304.223 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1050/1194 | Loss: 283.646 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 1060/1194 | Loss: 305.663 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 1070/1194 | Loss: 301.970 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1080/1194 | Loss: 291.749 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 1090/1194 | Loss: 302.719 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1100/1194 | Loss: 281.403 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 1110/1194 | Loss: 305.922 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 1120/1194 | Loss: 305.371 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 1130/1194 | Loss: 291.044 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1140/1194 | Loss: 291.510 | Accuracy: 0.200\n",
      "[Epoch: 72/200] - Step: 1150/1194 | Loss: 283.902 | Accuracy: 0.300\n",
      "[Epoch: 72/200] - Step: 1160/1194 | Loss: 294.035 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1170/1194 | Loss: 306.738 | Accuracy: 0.000\n",
      "[Epoch: 72/200] - Step: 1180/1194 | Loss: 296.791 | Accuracy: 0.100\n",
      "[Epoch: 72/200] - Step: 1190/1194 | Loss: 289.142 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 73/200] - Step: 10/1194 | Loss: 288.219 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 20/1194 | Loss: 284.465 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 30/1194 | Loss: 305.510 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 40/1194 | Loss: 287.872 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 50/1194 | Loss: 298.093 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 60/1194 | Loss: 303.298 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 70/1194 | Loss: 275.723 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 80/1194 | Loss: 295.903 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 90/1194 | Loss: 285.003 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 100/1194 | Loss: 274.109 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 110/1194 | Loss: 331.093 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 120/1194 | Loss: 300.960 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 130/1194 | Loss: 290.161 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 140/1194 | Loss: 318.752 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 150/1194 | Loss: 299.796 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 160/1194 | Loss: 289.198 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 170/1194 | Loss: 303.614 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 180/1194 | Loss: 296.497 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 190/1194 | Loss: 303.579 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 200/1194 | Loss: 294.748 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 210/1194 | Loss: 298.873 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 220/1194 | Loss: 295.902 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 230/1194 | Loss: 288.336 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 240/1194 | Loss: 288.665 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 250/1194 | Loss: 304.452 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 260/1194 | Loss: 278.072 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 270/1194 | Loss: 338.300 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 280/1194 | Loss: 293.651 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 290/1194 | Loss: 302.260 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 300/1194 | Loss: 284.425 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 310/1194 | Loss: 297.908 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 320/1194 | Loss: 298.013 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 330/1194 | Loss: 268.057 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 340/1194 | Loss: 285.182 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 350/1194 | Loss: 313.367 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 360/1194 | Loss: 312.685 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 370/1194 | Loss: 305.089 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 380/1194 | Loss: 313.342 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 390/1194 | Loss: 282.553 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 400/1194 | Loss: 281.013 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 410/1194 | Loss: 300.001 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 420/1194 | Loss: 278.867 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 430/1194 | Loss: 286.520 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 440/1194 | Loss: 315.353 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 450/1194 | Loss: 313.183 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 460/1194 | Loss: 302.329 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 470/1194 | Loss: 283.292 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 480/1194 | Loss: 302.665 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 490/1194 | Loss: 309.502 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 500/1194 | Loss: 272.955 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 510/1194 | Loss: 307.691 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 520/1194 | Loss: 291.492 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 530/1194 | Loss: 278.247 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 540/1194 | Loss: 294.711 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 550/1194 | Loss: 321.633 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 560/1194 | Loss: 300.419 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 570/1194 | Loss: 286.859 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 580/1194 | Loss: 310.772 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 590/1194 | Loss: 298.161 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 600/1194 | Loss: 296.253 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 610/1194 | Loss: 294.253 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 620/1194 | Loss: 300.907 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 630/1194 | Loss: 295.252 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 640/1194 | Loss: 302.225 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 650/1194 | Loss: 295.035 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 660/1194 | Loss: 291.791 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 670/1194 | Loss: 297.213 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 680/1194 | Loss: 267.420 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 690/1194 | Loss: 266.071 | Accuracy: 0.400\n",
      "[Epoch: 73/200] - Step: 700/1194 | Loss: 280.277 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 710/1194 | Loss: 290.146 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 720/1194 | Loss: 305.918 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 730/1194 | Loss: 315.144 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 740/1194 | Loss: 294.762 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 750/1194 | Loss: 288.217 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 760/1194 | Loss: 296.434 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 770/1194 | Loss: 300.037 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 780/1194 | Loss: 293.264 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 790/1194 | Loss: 298.884 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 800/1194 | Loss: 290.459 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 810/1194 | Loss: 300.312 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 820/1194 | Loss: 294.778 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 830/1194 | Loss: 288.929 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 840/1194 | Loss: 291.684 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 850/1194 | Loss: 295.812 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 860/1194 | Loss: 294.754 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 870/1194 | Loss: 300.478 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 880/1194 | Loss: 330.381 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 890/1194 | Loss: 313.325 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 900/1194 | Loss: 300.530 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 910/1194 | Loss: 315.205 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 920/1194 | Loss: 281.683 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 930/1194 | Loss: 304.801 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 940/1194 | Loss: 294.484 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 950/1194 | Loss: 304.796 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 960/1194 | Loss: 285.077 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 970/1194 | Loss: 286.681 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 980/1194 | Loss: 307.451 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 990/1194 | Loss: 293.832 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1000/1194 | Loss: 295.599 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1010/1194 | Loss: 294.947 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1020/1194 | Loss: 305.626 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1030/1194 | Loss: 297.553 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1040/1194 | Loss: 305.875 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1050/1194 | Loss: 290.293 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1060/1194 | Loss: 315.743 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1070/1194 | Loss: 301.554 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1080/1194 | Loss: 291.918 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1090/1194 | Loss: 285.360 | Accuracy: 0.300\n",
      "[Epoch: 73/200] - Step: 1100/1194 | Loss: 307.911 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1110/1194 | Loss: 303.422 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1120/1194 | Loss: 290.133 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1130/1194 | Loss: 309.004 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1140/1194 | Loss: 307.548 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1150/1194 | Loss: 330.000 | Accuracy: 0.000\n",
      "[Epoch: 73/200] - Step: 1160/1194 | Loss: 291.576 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1170/1194 | Loss: 293.782 | Accuracy: 0.100\n",
      "[Epoch: 73/200] - Step: 1180/1194 | Loss: 286.965 | Accuracy: 0.200\n",
      "[Epoch: 73/200] - Step: 1190/1194 | Loss: 299.550 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 74/200] - Step: 10/1194 | Loss: 301.401 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 20/1194 | Loss: 308.051 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 30/1194 | Loss: 291.509 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 40/1194 | Loss: 290.691 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 50/1194 | Loss: 279.857 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 60/1194 | Loss: 298.382 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 70/1194 | Loss: 289.367 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 80/1194 | Loss: 294.457 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 90/1194 | Loss: 286.786 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 100/1194 | Loss: 283.517 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 110/1194 | Loss: 277.597 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 120/1194 | Loss: 292.027 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 130/1194 | Loss: 299.559 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 140/1194 | Loss: 306.792 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 150/1194 | Loss: 305.274 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 160/1194 | Loss: 328.558 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 170/1194 | Loss: 288.448 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 180/1194 | Loss: 293.937 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 190/1194 | Loss: 292.743 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 200/1194 | Loss: 289.080 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 210/1194 | Loss: 255.165 | Accuracy: 0.500\n",
      "[Epoch: 74/200] - Step: 220/1194 | Loss: 305.335 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 230/1194 | Loss: 290.443 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 240/1194 | Loss: 303.278 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 250/1194 | Loss: 281.790 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 260/1194 | Loss: 297.603 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 270/1194 | Loss: 305.899 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 280/1194 | Loss: 291.558 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 290/1194 | Loss: 331.871 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 300/1194 | Loss: 309.814 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 310/1194 | Loss: 313.334 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 320/1194 | Loss: 280.808 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 330/1194 | Loss: 286.531 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 340/1194 | Loss: 331.048 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 350/1194 | Loss: 310.130 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 360/1194 | Loss: 307.348 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 370/1194 | Loss: 284.807 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 380/1194 | Loss: 299.104 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 390/1194 | Loss: 308.287 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 400/1194 | Loss: 295.523 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 410/1194 | Loss: 294.316 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 420/1194 | Loss: 305.885 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 430/1194 | Loss: 287.060 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 440/1194 | Loss: 291.770 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 450/1194 | Loss: 301.139 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 460/1194 | Loss: 304.123 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 470/1194 | Loss: 282.991 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 480/1194 | Loss: 289.294 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 490/1194 | Loss: 291.803 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 500/1194 | Loss: 281.252 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 510/1194 | Loss: 284.130 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 520/1194 | Loss: 271.432 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 530/1194 | Loss: 303.525 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 540/1194 | Loss: 334.422 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 550/1194 | Loss: 291.482 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 560/1194 | Loss: 296.785 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 570/1194 | Loss: 310.775 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 580/1194 | Loss: 292.969 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 590/1194 | Loss: 276.691 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 600/1194 | Loss: 311.580 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 610/1194 | Loss: 303.585 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 620/1194 | Loss: 297.902 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 630/1194 | Loss: 283.332 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 640/1194 | Loss: 294.515 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 650/1194 | Loss: 270.091 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 660/1194 | Loss: 306.443 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 670/1194 | Loss: 310.459 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 680/1194 | Loss: 303.787 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 690/1194 | Loss: 292.258 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 700/1194 | Loss: 304.274 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 710/1194 | Loss: 292.849 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 720/1194 | Loss: 282.152 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 730/1194 | Loss: 299.743 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 740/1194 | Loss: 297.569 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 750/1194 | Loss: 299.652 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 760/1194 | Loss: 294.397 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 770/1194 | Loss: 275.770 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 780/1194 | Loss: 300.465 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 790/1194 | Loss: 301.096 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 800/1194 | Loss: 302.008 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 810/1194 | Loss: 276.168 | Accuracy: 0.400\n",
      "[Epoch: 74/200] - Step: 820/1194 | Loss: 298.330 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 830/1194 | Loss: 305.960 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 840/1194 | Loss: 310.896 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 850/1194 | Loss: 300.179 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 860/1194 | Loss: 292.602 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 870/1194 | Loss: 288.351 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 880/1194 | Loss: 313.632 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 890/1194 | Loss: 304.848 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 900/1194 | Loss: 296.863 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 910/1194 | Loss: 295.294 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 920/1194 | Loss: 298.286 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 930/1194 | Loss: 280.916 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 940/1194 | Loss: 299.556 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 950/1194 | Loss: 269.235 | Accuracy: 0.300\n",
      "[Epoch: 74/200] - Step: 960/1194 | Loss: 308.163 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 970/1194 | Loss: 315.296 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 980/1194 | Loss: 299.728 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 990/1194 | Loss: 296.511 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1000/1194 | Loss: 303.256 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 1010/1194 | Loss: 309.201 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1020/1194 | Loss: 288.109 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1030/1194 | Loss: 297.460 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1040/1194 | Loss: 309.485 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1050/1194 | Loss: 299.583 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1060/1194 | Loss: 295.722 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 1070/1194 | Loss: 288.809 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 1080/1194 | Loss: 306.420 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 1090/1194 | Loss: 305.384 | Accuracy: 0.000\n",
      "[Epoch: 74/200] - Step: 1100/1194 | Loss: 307.304 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1110/1194 | Loss: 284.893 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 1120/1194 | Loss: 292.085 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1130/1194 | Loss: 320.007 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 1140/1194 | Loss: 298.891 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1150/1194 | Loss: 289.866 | Accuracy: 0.200\n",
      "[Epoch: 74/200] - Step: 1160/1194 | Loss: 299.884 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1170/1194 | Loss: 329.026 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1180/1194 | Loss: 293.165 | Accuracy: 0.100\n",
      "[Epoch: 74/200] - Step: 1190/1194 | Loss: 287.223 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 75/200] - Step: 10/1194 | Loss: 302.064 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 20/1194 | Loss: 294.020 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 30/1194 | Loss: 279.756 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 40/1194 | Loss: 272.128 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 50/1194 | Loss: 273.101 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 60/1194 | Loss: 315.816 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 70/1194 | Loss: 285.765 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 80/1194 | Loss: 288.119 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 90/1194 | Loss: 279.677 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 100/1194 | Loss: 321.004 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 110/1194 | Loss: 282.218 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 120/1194 | Loss: 299.372 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 130/1194 | Loss: 280.371 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 140/1194 | Loss: 302.049 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 150/1194 | Loss: 293.767 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 160/1194 | Loss: 295.954 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 170/1194 | Loss: 280.224 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 180/1194 | Loss: 292.928 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 190/1194 | Loss: 297.199 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 200/1194 | Loss: 297.527 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 210/1194 | Loss: 317.739 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 220/1194 | Loss: 292.848 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 230/1194 | Loss: 288.414 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 240/1194 | Loss: 318.706 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 250/1194 | Loss: 303.204 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 260/1194 | Loss: 289.061 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 270/1194 | Loss: 330.255 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 280/1194 | Loss: 307.689 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 290/1194 | Loss: 302.770 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 300/1194 | Loss: 301.634 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 310/1194 | Loss: 307.532 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 320/1194 | Loss: 308.335 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 330/1194 | Loss: 288.107 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 340/1194 | Loss: 295.370 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 350/1194 | Loss: 303.978 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 360/1194 | Loss: 283.527 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 370/1194 | Loss: 293.499 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 380/1194 | Loss: 329.928 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 390/1194 | Loss: 301.087 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 400/1194 | Loss: 301.758 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 410/1194 | Loss: 310.633 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 420/1194 | Loss: 289.571 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 430/1194 | Loss: 288.262 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 440/1194 | Loss: 291.418 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 450/1194 | Loss: 297.355 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 460/1194 | Loss: 293.717 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 470/1194 | Loss: 299.255 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 480/1194 | Loss: 289.405 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 490/1194 | Loss: 275.709 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 500/1194 | Loss: 276.298 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 510/1194 | Loss: 296.826 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 520/1194 | Loss: 310.861 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 530/1194 | Loss: 292.516 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 540/1194 | Loss: 284.894 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 550/1194 | Loss: 305.117 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 560/1194 | Loss: 304.287 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 570/1194 | Loss: 295.216 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 580/1194 | Loss: 307.310 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 590/1194 | Loss: 298.185 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 600/1194 | Loss: 303.505 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 610/1194 | Loss: 294.442 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 620/1194 | Loss: 297.446 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 630/1194 | Loss: 291.353 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 640/1194 | Loss: 297.932 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 650/1194 | Loss: 307.204 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 660/1194 | Loss: 307.596 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 670/1194 | Loss: 305.447 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 680/1194 | Loss: 288.319 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 690/1194 | Loss: 313.877 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 700/1194 | Loss: 291.124 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 710/1194 | Loss: 291.835 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 720/1194 | Loss: 323.875 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 730/1194 | Loss: 287.859 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 740/1194 | Loss: 305.259 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 750/1194 | Loss: 298.828 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 760/1194 | Loss: 311.917 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 770/1194 | Loss: 295.787 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 780/1194 | Loss: 274.781 | Accuracy: 0.500\n",
      "[Epoch: 75/200] - Step: 790/1194 | Loss: 302.866 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 800/1194 | Loss: 293.723 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 810/1194 | Loss: 288.317 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 820/1194 | Loss: 289.462 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 830/1194 | Loss: 331.889 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 840/1194 | Loss: 297.388 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 850/1194 | Loss: 293.728 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 860/1194 | Loss: 285.772 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 870/1194 | Loss: 295.309 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 880/1194 | Loss: 296.302 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 890/1194 | Loss: 304.486 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 900/1194 | Loss: 281.031 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 910/1194 | Loss: 294.014 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 920/1194 | Loss: 298.705 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 930/1194 | Loss: 295.445 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 940/1194 | Loss: 296.480 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 950/1194 | Loss: 287.435 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 960/1194 | Loss: 298.154 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 970/1194 | Loss: 283.587 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 980/1194 | Loss: 302.420 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 990/1194 | Loss: 313.517 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1000/1194 | Loss: 342.027 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1010/1194 | Loss: 286.075 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 1020/1194 | Loss: 277.784 | Accuracy: 0.200\n",
      "[Epoch: 75/200] - Step: 1030/1194 | Loss: 290.612 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1040/1194 | Loss: 301.648 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1050/1194 | Loss: 296.753 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1060/1194 | Loss: 301.354 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1070/1194 | Loss: 268.912 | Accuracy: 0.400\n",
      "[Epoch: 75/200] - Step: 1080/1194 | Loss: 287.769 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1090/1194 | Loss: 307.819 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1100/1194 | Loss: 300.992 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1110/1194 | Loss: 287.902 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1120/1194 | Loss: 287.258 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1130/1194 | Loss: 299.403 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1140/1194 | Loss: 294.782 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1150/1194 | Loss: 282.129 | Accuracy: 0.300\n",
      "[Epoch: 75/200] - Step: 1160/1194 | Loss: 334.980 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1170/1194 | Loss: 292.765 | Accuracy: 0.100\n",
      "[Epoch: 75/200] - Step: 1180/1194 | Loss: 302.681 | Accuracy: 0.000\n",
      "[Epoch: 75/200] - Step: 1190/1194 | Loss: 298.442 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 76/200] - Step: 10/1194 | Loss: 295.229 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 20/1194 | Loss: 294.846 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 30/1194 | Loss: 310.124 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 40/1194 | Loss: 279.051 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 50/1194 | Loss: 309.946 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 60/1194 | Loss: 275.509 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 70/1194 | Loss: 295.951 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 80/1194 | Loss: 285.687 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 90/1194 | Loss: 296.134 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 100/1194 | Loss: 287.824 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 110/1194 | Loss: 298.602 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 120/1194 | Loss: 307.578 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 130/1194 | Loss: 295.795 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 140/1194 | Loss: 307.264 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 150/1194 | Loss: 294.869 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 160/1194 | Loss: 309.458 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 170/1194 | Loss: 268.963 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 180/1194 | Loss: 307.735 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 190/1194 | Loss: 292.256 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 200/1194 | Loss: 309.793 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 210/1194 | Loss: 301.700 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 220/1194 | Loss: 289.444 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 230/1194 | Loss: 315.304 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 240/1194 | Loss: 314.792 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 250/1194 | Loss: 308.974 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 260/1194 | Loss: 299.561 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 270/1194 | Loss: 298.150 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 280/1194 | Loss: 314.729 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 290/1194 | Loss: 289.103 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 300/1194 | Loss: 300.439 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 310/1194 | Loss: 287.912 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 320/1194 | Loss: 298.032 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 330/1194 | Loss: 291.763 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 340/1194 | Loss: 307.479 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 350/1194 | Loss: 289.195 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 360/1194 | Loss: 292.784 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 370/1194 | Loss: 318.870 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 380/1194 | Loss: 267.109 | Accuracy: 0.400\n",
      "[Epoch: 76/200] - Step: 390/1194 | Loss: 277.747 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 400/1194 | Loss: 297.563 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 410/1194 | Loss: 304.176 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 420/1194 | Loss: 292.249 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 430/1194 | Loss: 281.198 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 440/1194 | Loss: 296.762 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 450/1194 | Loss: 289.870 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 460/1194 | Loss: 287.561 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 470/1194 | Loss: 334.165 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 480/1194 | Loss: 294.672 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 490/1194 | Loss: 293.066 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 500/1194 | Loss: 290.815 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 510/1194 | Loss: 298.852 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 520/1194 | Loss: 287.835 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 530/1194 | Loss: 303.805 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 540/1194 | Loss: 296.568 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 550/1194 | Loss: 299.109 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 560/1194 | Loss: 309.047 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 570/1194 | Loss: 297.919 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 580/1194 | Loss: 282.986 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 590/1194 | Loss: 307.293 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 600/1194 | Loss: 289.230 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 610/1194 | Loss: 293.143 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 620/1194 | Loss: 286.202 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 630/1194 | Loss: 337.429 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 640/1194 | Loss: 295.045 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 650/1194 | Loss: 276.922 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 660/1194 | Loss: 302.559 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 670/1194 | Loss: 286.622 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 680/1194 | Loss: 305.931 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 690/1194 | Loss: 308.392 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 700/1194 | Loss: 294.767 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 710/1194 | Loss: 287.699 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 720/1194 | Loss: 300.210 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 730/1194 | Loss: 307.749 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 740/1194 | Loss: 300.134 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 750/1194 | Loss: 300.167 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 760/1194 | Loss: 299.266 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 770/1194 | Loss: 306.010 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 780/1194 | Loss: 288.838 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 790/1194 | Loss: 307.250 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 800/1194 | Loss: 298.125 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 810/1194 | Loss: 288.776 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 820/1194 | Loss: 291.026 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 830/1194 | Loss: 305.835 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 840/1194 | Loss: 297.678 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 850/1194 | Loss: 303.827 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 860/1194 | Loss: 293.954 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 870/1194 | Loss: 281.096 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 880/1194 | Loss: 290.219 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 890/1194 | Loss: 297.675 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 900/1194 | Loss: 285.318 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 910/1194 | Loss: 293.611 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 920/1194 | Loss: 299.184 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 930/1194 | Loss: 282.813 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 940/1194 | Loss: 281.639 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 950/1194 | Loss: 302.439 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 960/1194 | Loss: 289.767 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 970/1194 | Loss: 286.083 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 980/1194 | Loss: 304.620 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 990/1194 | Loss: 289.546 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1000/1194 | Loss: 301.535 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1010/1194 | Loss: 302.470 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 1020/1194 | Loss: 345.009 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1030/1194 | Loss: 309.541 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1040/1194 | Loss: 276.211 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 1050/1194 | Loss: 303.838 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1060/1194 | Loss: 333.855 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1070/1194 | Loss: 297.326 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 1080/1194 | Loss: 282.960 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 1090/1194 | Loss: 298.148 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 1100/1194 | Loss: 304.123 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1110/1194 | Loss: 295.239 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 1120/1194 | Loss: 281.127 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 1130/1194 | Loss: 288.514 | Accuracy: 0.200\n",
      "[Epoch: 76/200] - Step: 1140/1194 | Loss: 310.311 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1150/1194 | Loss: 275.731 | Accuracy: 0.300\n",
      "[Epoch: 76/200] - Step: 1160/1194 | Loss: 292.815 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 1170/1194 | Loss: 289.141 | Accuracy: 0.100\n",
      "[Epoch: 76/200] - Step: 1180/1194 | Loss: 305.656 | Accuracy: 0.000\n",
      "[Epoch: 76/200] - Step: 1190/1194 | Loss: 297.501 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 77/200] - Step: 10/1194 | Loss: 295.704 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 20/1194 | Loss: 310.532 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 30/1194 | Loss: 289.696 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 40/1194 | Loss: 296.992 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 50/1194 | Loss: 290.989 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 60/1194 | Loss: 301.053 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 70/1194 | Loss: 305.164 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 80/1194 | Loss: 301.968 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 90/1194 | Loss: 302.519 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 100/1194 | Loss: 277.250 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 110/1194 | Loss: 293.085 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 120/1194 | Loss: 294.002 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 130/1194 | Loss: 305.163 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 140/1194 | Loss: 290.028 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 150/1194 | Loss: 295.560 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 160/1194 | Loss: 330.973 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 170/1194 | Loss: 297.795 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 180/1194 | Loss: 294.503 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 190/1194 | Loss: 306.074 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 200/1194 | Loss: 295.312 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 210/1194 | Loss: 288.028 | Accuracy: 0.300\n",
      "[Epoch: 77/200] - Step: 220/1194 | Loss: 296.211 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 230/1194 | Loss: 285.692 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 240/1194 | Loss: 295.631 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 250/1194 | Loss: 293.753 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 260/1194 | Loss: 294.593 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 270/1194 | Loss: 287.424 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 280/1194 | Loss: 314.711 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 290/1194 | Loss: 301.596 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 300/1194 | Loss: 278.033 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 310/1194 | Loss: 283.425 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 320/1194 | Loss: 301.897 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 330/1194 | Loss: 289.493 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 340/1194 | Loss: 293.724 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 350/1194 | Loss: 286.533 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 360/1194 | Loss: 257.322 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 370/1194 | Loss: 300.330 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 380/1194 | Loss: 294.690 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 390/1194 | Loss: 286.512 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 400/1194 | Loss: 299.678 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 410/1194 | Loss: 314.120 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 420/1194 | Loss: 313.288 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 430/1194 | Loss: 332.257 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 440/1194 | Loss: 292.213 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 450/1194 | Loss: 294.238 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 460/1194 | Loss: 293.167 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 470/1194 | Loss: 308.869 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 480/1194 | Loss: 295.778 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 490/1194 | Loss: 294.279 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 500/1194 | Loss: 309.175 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 510/1194 | Loss: 289.834 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 520/1194 | Loss: 315.287 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 530/1194 | Loss: 294.764 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 540/1194 | Loss: 294.175 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 550/1194 | Loss: 300.963 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 560/1194 | Loss: 300.449 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 570/1194 | Loss: 280.311 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 580/1194 | Loss: 294.791 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 590/1194 | Loss: 293.397 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 600/1194 | Loss: 294.188 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 610/1194 | Loss: 316.195 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 620/1194 | Loss: 297.486 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 630/1194 | Loss: 312.618 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 640/1194 | Loss: 304.583 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 650/1194 | Loss: 286.425 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 660/1194 | Loss: 286.507 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 670/1194 | Loss: 293.022 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 680/1194 | Loss: 301.302 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 690/1194 | Loss: 301.002 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 700/1194 | Loss: 328.171 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 710/1194 | Loss: 302.543 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 720/1194 | Loss: 280.924 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 730/1194 | Loss: 294.455 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 740/1194 | Loss: 297.341 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 750/1194 | Loss: 291.719 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 760/1194 | Loss: 328.443 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 770/1194 | Loss: 302.910 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 780/1194 | Loss: 277.877 | Accuracy: 0.400\n",
      "[Epoch: 77/200] - Step: 790/1194 | Loss: 314.319 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 800/1194 | Loss: 305.109 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 810/1194 | Loss: 295.774 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 820/1194 | Loss: 289.921 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 830/1194 | Loss: 301.989 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 840/1194 | Loss: 294.577 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 850/1194 | Loss: 294.995 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 860/1194 | Loss: 296.823 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 870/1194 | Loss: 293.880 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 880/1194 | Loss: 285.045 | Accuracy: 0.300\n",
      "[Epoch: 77/200] - Step: 890/1194 | Loss: 300.778 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 900/1194 | Loss: 280.663 | Accuracy: 0.300\n",
      "[Epoch: 77/200] - Step: 910/1194 | Loss: 280.333 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 920/1194 | Loss: 323.605 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 930/1194 | Loss: 296.910 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 940/1194 | Loss: 299.074 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 950/1194 | Loss: 302.488 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 960/1194 | Loss: 297.059 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 970/1194 | Loss: 309.829 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 980/1194 | Loss: 296.500 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 990/1194 | Loss: 284.099 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1000/1194 | Loss: 283.724 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1010/1194 | Loss: 289.456 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1020/1194 | Loss: 299.551 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 1030/1194 | Loss: 273.822 | Accuracy: 0.300\n",
      "[Epoch: 77/200] - Step: 1040/1194 | Loss: 304.337 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 1050/1194 | Loss: 295.133 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1060/1194 | Loss: 296.707 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1070/1194 | Loss: 292.731 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1080/1194 | Loss: 280.641 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1090/1194 | Loss: 319.485 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 1100/1194 | Loss: 286.248 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1110/1194 | Loss: 295.481 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1120/1194 | Loss: 279.716 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1130/1194 | Loss: 292.118 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1140/1194 | Loss: 275.212 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1150/1194 | Loss: 288.843 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1160/1194 | Loss: 317.539 | Accuracy: 0.100\n",
      "[Epoch: 77/200] - Step: 1170/1194 | Loss: 290.433 | Accuracy: 0.200\n",
      "[Epoch: 77/200] - Step: 1180/1194 | Loss: 313.385 | Accuracy: 0.000\n",
      "[Epoch: 77/200] - Step: 1190/1194 | Loss: 316.601 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 78/200] - Step: 10/1194 | Loss: 259.719 | Accuracy: 0.500\n",
      "[Epoch: 78/200] - Step: 20/1194 | Loss: 304.587 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 30/1194 | Loss: 301.848 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 40/1194 | Loss: 276.632 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 50/1194 | Loss: 290.837 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 60/1194 | Loss: 301.709 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 70/1194 | Loss: 312.164 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 80/1194 | Loss: 289.538 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 90/1194 | Loss: 302.900 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 100/1194 | Loss: 296.203 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 110/1194 | Loss: 290.864 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 120/1194 | Loss: 301.529 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 130/1194 | Loss: 294.561 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 140/1194 | Loss: 299.159 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 150/1194 | Loss: 306.972 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 160/1194 | Loss: 284.026 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 170/1194 | Loss: 296.605 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 180/1194 | Loss: 308.476 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 190/1194 | Loss: 302.011 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 200/1194 | Loss: 289.811 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 210/1194 | Loss: 289.099 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 220/1194 | Loss: 282.965 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 230/1194 | Loss: 285.771 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 240/1194 | Loss: 283.828 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 250/1194 | Loss: 280.159 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 260/1194 | Loss: 286.066 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 270/1194 | Loss: 292.312 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 280/1194 | Loss: 308.223 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 290/1194 | Loss: 307.399 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 300/1194 | Loss: 288.128 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 310/1194 | Loss: 273.903 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 320/1194 | Loss: 317.852 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 330/1194 | Loss: 307.783 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 340/1194 | Loss: 297.721 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 350/1194 | Loss: 301.016 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 360/1194 | Loss: 307.620 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 370/1194 | Loss: 279.934 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 380/1194 | Loss: 298.062 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 390/1194 | Loss: 267.962 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 400/1194 | Loss: 277.023 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 410/1194 | Loss: 299.841 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 420/1194 | Loss: 295.954 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 430/1194 | Loss: 290.423 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 440/1194 | Loss: 294.331 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 450/1194 | Loss: 272.591 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 460/1194 | Loss: 286.188 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 470/1194 | Loss: 290.769 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 480/1194 | Loss: 266.173 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 490/1194 | Loss: 310.050 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 500/1194 | Loss: 312.529 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 510/1194 | Loss: 290.592 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 520/1194 | Loss: 311.166 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 530/1194 | Loss: 300.922 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 540/1194 | Loss: 299.345 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 550/1194 | Loss: 284.337 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 560/1194 | Loss: 284.957 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 570/1194 | Loss: 301.590 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 580/1194 | Loss: 338.237 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 590/1194 | Loss: 277.040 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 600/1194 | Loss: 297.251 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 610/1194 | Loss: 290.867 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 620/1194 | Loss: 292.356 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 630/1194 | Loss: 320.272 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 640/1194 | Loss: 339.227 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 650/1194 | Loss: 294.505 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 660/1194 | Loss: 300.797 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 670/1194 | Loss: 275.853 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 680/1194 | Loss: 280.047 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 690/1194 | Loss: 336.236 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 700/1194 | Loss: 302.904 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 710/1194 | Loss: 296.161 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 720/1194 | Loss: 300.387 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 730/1194 | Loss: 284.854 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 740/1194 | Loss: 319.496 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 750/1194 | Loss: 299.318 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 760/1194 | Loss: 279.299 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 770/1194 | Loss: 314.269 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 780/1194 | Loss: 300.602 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 790/1194 | Loss: 300.124 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 800/1194 | Loss: 256.690 | Accuracy: 0.600\n",
      "[Epoch: 78/200] - Step: 810/1194 | Loss: 294.276 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 820/1194 | Loss: 305.352 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 830/1194 | Loss: 323.618 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 840/1194 | Loss: 313.048 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 850/1194 | Loss: 281.577 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 860/1194 | Loss: 293.877 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 870/1194 | Loss: 305.615 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 880/1194 | Loss: 305.430 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 890/1194 | Loss: 293.427 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 900/1194 | Loss: 292.674 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 910/1194 | Loss: 282.718 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 920/1194 | Loss: 302.002 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 930/1194 | Loss: 294.168 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 940/1194 | Loss: 286.473 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 950/1194 | Loss: 300.595 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 960/1194 | Loss: 305.642 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 970/1194 | Loss: 290.713 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 980/1194 | Loss: 282.614 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 990/1194 | Loss: 340.049 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1000/1194 | Loss: 291.045 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1010/1194 | Loss: 300.781 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1020/1194 | Loss: 316.284 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1030/1194 | Loss: 296.724 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1040/1194 | Loss: 298.941 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1050/1194 | Loss: 292.198 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1060/1194 | Loss: 308.570 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1070/1194 | Loss: 286.247 | Accuracy: 0.300\n",
      "[Epoch: 78/200] - Step: 1080/1194 | Loss: 299.624 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1090/1194 | Loss: 301.381 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1100/1194 | Loss: 316.829 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1110/1194 | Loss: 305.010 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1120/1194 | Loss: 300.438 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1130/1194 | Loss: 290.608 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1140/1194 | Loss: 306.494 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1150/1194 | Loss: 297.530 | Accuracy: 0.100\n",
      "[Epoch: 78/200] - Step: 1160/1194 | Loss: 311.732 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1170/1194 | Loss: 295.400 | Accuracy: 0.200\n",
      "[Epoch: 78/200] - Step: 1180/1194 | Loss: 306.602 | Accuracy: 0.000\n",
      "[Epoch: 78/200] - Step: 1190/1194 | Loss: 300.138 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 79/200] - Step: 10/1194 | Loss: 300.770 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 20/1194 | Loss: 283.987 | Accuracy: 0.300\n",
      "[Epoch: 79/200] - Step: 30/1194 | Loss: 290.179 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 40/1194 | Loss: 290.183 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 50/1194 | Loss: 279.215 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 60/1194 | Loss: 289.129 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 70/1194 | Loss: 290.432 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 80/1194 | Loss: 294.888 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 90/1194 | Loss: 304.684 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 100/1194 | Loss: 302.758 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 110/1194 | Loss: 298.578 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 120/1194 | Loss: 321.452 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 130/1194 | Loss: 282.008 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 140/1194 | Loss: 300.692 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 150/1194 | Loss: 306.970 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 160/1194 | Loss: 314.382 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 170/1194 | Loss: 305.477 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 180/1194 | Loss: 280.462 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 190/1194 | Loss: 263.689 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 200/1194 | Loss: 288.726 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 210/1194 | Loss: 303.064 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 220/1194 | Loss: 298.846 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 230/1194 | Loss: 311.191 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 240/1194 | Loss: 306.924 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 250/1194 | Loss: 335.585 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 260/1194 | Loss: 298.778 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 270/1194 | Loss: 303.270 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 280/1194 | Loss: 297.538 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 290/1194 | Loss: 278.592 | Accuracy: 0.300\n",
      "[Epoch: 79/200] - Step: 300/1194 | Loss: 300.889 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 310/1194 | Loss: 286.103 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 320/1194 | Loss: 304.343 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 330/1194 | Loss: 309.571 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 340/1194 | Loss: 302.990 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 350/1194 | Loss: 299.337 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 360/1194 | Loss: 294.579 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 370/1194 | Loss: 298.951 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 380/1194 | Loss: 294.581 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 390/1194 | Loss: 296.863 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 400/1194 | Loss: 299.223 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 410/1194 | Loss: 308.790 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 420/1194 | Loss: 280.744 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 430/1194 | Loss: 296.059 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 440/1194 | Loss: 299.335 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 450/1194 | Loss: 272.634 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 460/1194 | Loss: 314.675 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 470/1194 | Loss: 289.115 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 480/1194 | Loss: 288.969 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 490/1194 | Loss: 278.610 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 500/1194 | Loss: 300.227 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 510/1194 | Loss: 300.177 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 520/1194 | Loss: 267.834 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 530/1194 | Loss: 294.532 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 540/1194 | Loss: 327.381 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 550/1194 | Loss: 289.302 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 560/1194 | Loss: 311.454 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 570/1194 | Loss: 301.072 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 580/1194 | Loss: 290.569 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 590/1194 | Loss: 292.704 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 600/1194 | Loss: 274.976 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 610/1194 | Loss: 309.473 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 620/1194 | Loss: 291.355 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 630/1194 | Loss: 302.129 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 640/1194 | Loss: 306.667 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 650/1194 | Loss: 334.681 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 660/1194 | Loss: 311.546 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 670/1194 | Loss: 303.449 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 680/1194 | Loss: 300.486 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 690/1194 | Loss: 317.932 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 700/1194 | Loss: 284.836 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 710/1194 | Loss: 308.209 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 720/1194 | Loss: 303.738 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 730/1194 | Loss: 306.529 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 740/1194 | Loss: 305.498 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 750/1194 | Loss: 273.901 | Accuracy: 0.300\n",
      "[Epoch: 79/200] - Step: 760/1194 | Loss: 293.949 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 770/1194 | Loss: 304.622 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 780/1194 | Loss: 295.052 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 790/1194 | Loss: 292.432 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 800/1194 | Loss: 286.085 | Accuracy: 0.300\n",
      "[Epoch: 79/200] - Step: 810/1194 | Loss: 279.804 | Accuracy: 0.400\n",
      "[Epoch: 79/200] - Step: 820/1194 | Loss: 295.512 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 830/1194 | Loss: 288.530 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 840/1194 | Loss: 292.146 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 850/1194 | Loss: 309.899 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 860/1194 | Loss: 327.151 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 870/1194 | Loss: 300.539 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 880/1194 | Loss: 302.390 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 890/1194 | Loss: 298.217 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 900/1194 | Loss: 290.910 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 910/1194 | Loss: 296.309 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 920/1194 | Loss: 276.227 | Accuracy: 0.300\n",
      "[Epoch: 79/200] - Step: 930/1194 | Loss: 306.261 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 940/1194 | Loss: 296.034 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 950/1194 | Loss: 297.638 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 960/1194 | Loss: 297.413 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 970/1194 | Loss: 264.847 | Accuracy: 0.500\n",
      "[Epoch: 79/200] - Step: 980/1194 | Loss: 282.354 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 990/1194 | Loss: 286.761 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 1000/1194 | Loss: 291.672 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 1010/1194 | Loss: 297.983 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 1020/1194 | Loss: 307.080 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1030/1194 | Loss: 293.445 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1040/1194 | Loss: 292.839 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1050/1194 | Loss: 312.814 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1060/1194 | Loss: 309.154 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1070/1194 | Loss: 312.520 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1080/1194 | Loss: 313.799 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1090/1194 | Loss: 298.238 | Accuracy: 0.000\n",
      "[Epoch: 79/200] - Step: 1100/1194 | Loss: 297.191 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1110/1194 | Loss: 305.190 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1120/1194 | Loss: 290.123 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1130/1194 | Loss: 298.283 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1140/1194 | Loss: 282.283 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 1150/1194 | Loss: 282.335 | Accuracy: 0.200\n",
      "[Epoch: 79/200] - Step: 1160/1194 | Loss: 297.658 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1170/1194 | Loss: 294.521 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1180/1194 | Loss: 291.676 | Accuracy: 0.100\n",
      "[Epoch: 79/200] - Step: 1190/1194 | Loss: 282.740 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 80/200] - Step: 10/1194 | Loss: 288.414 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 20/1194 | Loss: 307.391 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 30/1194 | Loss: 300.370 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 40/1194 | Loss: 293.861 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 50/1194 | Loss: 287.735 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 60/1194 | Loss: 303.367 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 70/1194 | Loss: 297.720 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 80/1194 | Loss: 310.717 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 90/1194 | Loss: 300.424 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 100/1194 | Loss: 305.279 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 110/1194 | Loss: 280.918 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 120/1194 | Loss: 312.710 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 130/1194 | Loss: 296.451 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 140/1194 | Loss: 295.709 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 150/1194 | Loss: 294.961 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 160/1194 | Loss: 294.247 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 170/1194 | Loss: 326.646 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 180/1194 | Loss: 305.394 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 190/1194 | Loss: 304.546 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 200/1194 | Loss: 283.562 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 210/1194 | Loss: 282.905 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 220/1194 | Loss: 299.054 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 230/1194 | Loss: 295.603 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 240/1194 | Loss: 286.461 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 250/1194 | Loss: 295.218 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 260/1194 | Loss: 305.819 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 270/1194 | Loss: 286.549 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 280/1194 | Loss: 291.579 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 290/1194 | Loss: 311.643 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 300/1194 | Loss: 305.973 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 310/1194 | Loss: 299.957 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 320/1194 | Loss: 300.770 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 330/1194 | Loss: 289.364 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 340/1194 | Loss: 310.939 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 350/1194 | Loss: 329.951 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 360/1194 | Loss: 308.832 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 370/1194 | Loss: 302.672 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 380/1194 | Loss: 309.720 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 390/1194 | Loss: 281.039 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 400/1194 | Loss: 305.972 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 410/1194 | Loss: 294.739 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 420/1194 | Loss: 285.670 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 430/1194 | Loss: 300.169 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 440/1194 | Loss: 291.994 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 450/1194 | Loss: 305.355 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 460/1194 | Loss: 296.053 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 470/1194 | Loss: 294.445 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 480/1194 | Loss: 299.134 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 490/1194 | Loss: 295.457 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 500/1194 | Loss: 284.489 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 510/1194 | Loss: 292.256 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 520/1194 | Loss: 291.658 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 530/1194 | Loss: 288.132 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 540/1194 | Loss: 286.912 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 550/1194 | Loss: 301.522 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 560/1194 | Loss: 286.743 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 570/1194 | Loss: 282.768 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 580/1194 | Loss: 290.950 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 590/1194 | Loss: 284.175 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 600/1194 | Loss: 295.047 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 610/1194 | Loss: 302.291 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 620/1194 | Loss: 275.965 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 630/1194 | Loss: 288.712 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 640/1194 | Loss: 302.396 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 650/1194 | Loss: 300.727 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 660/1194 | Loss: 291.322 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 670/1194 | Loss: 309.934 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 680/1194 | Loss: 262.139 | Accuracy: 0.500\n",
      "[Epoch: 80/200] - Step: 690/1194 | Loss: 347.040 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 700/1194 | Loss: 304.621 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 710/1194 | Loss: 294.695 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 720/1194 | Loss: 295.578 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 730/1194 | Loss: 304.818 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 740/1194 | Loss: 293.152 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 750/1194 | Loss: 292.743 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 760/1194 | Loss: 283.536 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 770/1194 | Loss: 277.414 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 780/1194 | Loss: 277.420 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 790/1194 | Loss: 273.711 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 800/1194 | Loss: 299.210 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 810/1194 | Loss: 316.838 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 820/1194 | Loss: 283.500 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 830/1194 | Loss: 278.358 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 840/1194 | Loss: 326.484 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 850/1194 | Loss: 310.375 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 860/1194 | Loss: 290.155 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 870/1194 | Loss: 278.421 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 880/1194 | Loss: 305.178 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 890/1194 | Loss: 300.229 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 900/1194 | Loss: 291.655 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 910/1194 | Loss: 308.961 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 920/1194 | Loss: 298.848 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 930/1194 | Loss: 301.652 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 940/1194 | Loss: 314.268 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 950/1194 | Loss: 307.845 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 960/1194 | Loss: 292.194 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 970/1194 | Loss: 296.586 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 980/1194 | Loss: 306.365 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 990/1194 | Loss: 308.712 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1000/1194 | Loss: 293.711 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1010/1194 | Loss: 292.517 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 1020/1194 | Loss: 303.587 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1030/1194 | Loss: 304.202 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1040/1194 | Loss: 292.118 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 1050/1194 | Loss: 306.828 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1060/1194 | Loss: 293.012 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 1070/1194 | Loss: 294.196 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1080/1194 | Loss: 297.444 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1090/1194 | Loss: 302.601 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1100/1194 | Loss: 300.620 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1110/1194 | Loss: 288.603 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 1120/1194 | Loss: 284.353 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 1130/1194 | Loss: 299.866 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1140/1194 | Loss: 310.225 | Accuracy: 0.300\n",
      "[Epoch: 80/200] - Step: 1150/1194 | Loss: 286.543 | Accuracy: 0.200\n",
      "[Epoch: 80/200] - Step: 1160/1194 | Loss: 300.960 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1170/1194 | Loss: 290.458 | Accuracy: 0.100\n",
      "[Epoch: 80/200] - Step: 1180/1194 | Loss: 295.457 | Accuracy: 0.000\n",
      "[Epoch: 80/200] - Step: 1190/1194 | Loss: 289.340 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 81/200] - Step: 10/1194 | Loss: 308.045 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 20/1194 | Loss: 285.646 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 30/1194 | Loss: 286.115 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 40/1194 | Loss: 294.039 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 50/1194 | Loss: 305.199 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 60/1194 | Loss: 323.919 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 70/1194 | Loss: 305.061 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 80/1194 | Loss: 294.156 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 90/1194 | Loss: 298.248 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 100/1194 | Loss: 283.259 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 110/1194 | Loss: 293.540 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 120/1194 | Loss: 302.873 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 130/1194 | Loss: 302.257 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 140/1194 | Loss: 302.654 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 150/1194 | Loss: 279.131 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 160/1194 | Loss: 285.649 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 170/1194 | Loss: 265.168 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 180/1194 | Loss: 261.372 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 190/1194 | Loss: 286.804 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 200/1194 | Loss: 312.112 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 210/1194 | Loss: 266.873 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 220/1194 | Loss: 289.189 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 230/1194 | Loss: 294.159 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 240/1194 | Loss: 277.605 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 250/1194 | Loss: 269.319 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 260/1194 | Loss: 316.368 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 270/1194 | Loss: 294.809 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 280/1194 | Loss: 312.734 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 290/1194 | Loss: 319.644 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 300/1194 | Loss: 302.168 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 310/1194 | Loss: 287.483 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 320/1194 | Loss: 272.818 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 330/1194 | Loss: 315.243 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 340/1194 | Loss: 293.982 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 350/1194 | Loss: 303.491 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 360/1194 | Loss: 296.078 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 370/1194 | Loss: 307.868 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 380/1194 | Loss: 284.289 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 390/1194 | Loss: 281.371 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 400/1194 | Loss: 292.051 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 410/1194 | Loss: 300.958 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 420/1194 | Loss: 277.852 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 430/1194 | Loss: 271.234 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 440/1194 | Loss: 299.451 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 450/1194 | Loss: 308.966 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 460/1194 | Loss: 296.446 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 470/1194 | Loss: 330.307 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 480/1194 | Loss: 272.343 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 490/1194 | Loss: 302.706 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 500/1194 | Loss: 300.117 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 510/1194 | Loss: 307.930 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 520/1194 | Loss: 291.463 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 530/1194 | Loss: 293.789 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 540/1194 | Loss: 322.187 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 550/1194 | Loss: 288.830 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 560/1194 | Loss: 286.735 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 570/1194 | Loss: 307.413 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 580/1194 | Loss: 314.125 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 590/1194 | Loss: 290.566 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 600/1194 | Loss: 288.651 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 610/1194 | Loss: 327.116 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 620/1194 | Loss: 289.168 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 630/1194 | Loss: 290.572 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 640/1194 | Loss: 282.156 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 650/1194 | Loss: 305.497 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 660/1194 | Loss: 305.687 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 670/1194 | Loss: 272.696 | Accuracy: 0.400\n",
      "[Epoch: 81/200] - Step: 680/1194 | Loss: 289.921 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 690/1194 | Loss: 307.599 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 700/1194 | Loss: 340.784 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 710/1194 | Loss: 291.055 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 720/1194 | Loss: 303.863 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 730/1194 | Loss: 301.482 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 740/1194 | Loss: 306.798 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 750/1194 | Loss: 317.304 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 760/1194 | Loss: 301.636 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 770/1194 | Loss: 312.767 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 780/1194 | Loss: 308.158 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 790/1194 | Loss: 289.656 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 800/1194 | Loss: 305.124 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 810/1194 | Loss: 283.158 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 820/1194 | Loss: 298.895 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 830/1194 | Loss: 290.617 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 840/1194 | Loss: 300.861 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 850/1194 | Loss: 300.706 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 860/1194 | Loss: 299.555 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 870/1194 | Loss: 294.732 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 880/1194 | Loss: 297.928 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 890/1194 | Loss: 290.703 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 900/1194 | Loss: 303.676 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 910/1194 | Loss: 313.193 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 920/1194 | Loss: 290.738 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 930/1194 | Loss: 295.448 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 940/1194 | Loss: 290.401 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 950/1194 | Loss: 306.778 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 960/1194 | Loss: 277.248 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 970/1194 | Loss: 307.490 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 980/1194 | Loss: 303.348 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 990/1194 | Loss: 315.135 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 1000/1194 | Loss: 308.058 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 1010/1194 | Loss: 287.914 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 1020/1194 | Loss: 284.304 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 1030/1194 | Loss: 324.944 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1040/1194 | Loss: 289.915 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1050/1194 | Loss: 292.451 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1060/1194 | Loss: 295.719 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1070/1194 | Loss: 293.284 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1080/1194 | Loss: 281.149 | Accuracy: 0.300\n",
      "[Epoch: 81/200] - Step: 1090/1194 | Loss: 299.842 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1100/1194 | Loss: 293.695 | Accuracy: 0.000\n",
      "[Epoch: 81/200] - Step: 1110/1194 | Loss: 295.665 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1120/1194 | Loss: 292.638 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1130/1194 | Loss: 292.991 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1140/1194 | Loss: 306.037 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1150/1194 | Loss: 295.742 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 1160/1194 | Loss: 305.027 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1170/1194 | Loss: 287.311 | Accuracy: 0.200\n",
      "[Epoch: 81/200] - Step: 1180/1194 | Loss: 300.399 | Accuracy: 0.100\n",
      "[Epoch: 81/200] - Step: 1190/1194 | Loss: 303.114 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 82/200] - Step: 10/1194 | Loss: 298.352 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 20/1194 | Loss: 304.514 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 30/1194 | Loss: 291.667 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 40/1194 | Loss: 295.527 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 50/1194 | Loss: 305.388 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 60/1194 | Loss: 303.379 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 70/1194 | Loss: 294.999 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 80/1194 | Loss: 288.703 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 90/1194 | Loss: 291.521 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 100/1194 | Loss: 305.460 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 110/1194 | Loss: 287.658 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 120/1194 | Loss: 297.787 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 130/1194 | Loss: 303.044 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 140/1194 | Loss: 302.500 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 150/1194 | Loss: 298.575 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 160/1194 | Loss: 289.349 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 170/1194 | Loss: 311.293 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 180/1194 | Loss: 327.329 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 190/1194 | Loss: 289.872 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 200/1194 | Loss: 302.968 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 210/1194 | Loss: 269.159 | Accuracy: 0.400\n",
      "[Epoch: 82/200] - Step: 220/1194 | Loss: 272.865 | Accuracy: 0.400\n",
      "[Epoch: 82/200] - Step: 230/1194 | Loss: 295.721 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 240/1194 | Loss: 292.258 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 250/1194 | Loss: 299.055 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 260/1194 | Loss: 293.219 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 270/1194 | Loss: 296.066 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 280/1194 | Loss: 283.326 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 290/1194 | Loss: 305.772 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 300/1194 | Loss: 292.373 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 310/1194 | Loss: 293.621 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 320/1194 | Loss: 293.687 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 330/1194 | Loss: 293.088 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 340/1194 | Loss: 330.678 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 350/1194 | Loss: 297.079 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 360/1194 | Loss: 282.170 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 370/1194 | Loss: 298.271 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 380/1194 | Loss: 288.704 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 390/1194 | Loss: 273.119 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 400/1194 | Loss: 290.812 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 410/1194 | Loss: 306.382 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 420/1194 | Loss: 290.358 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 430/1194 | Loss: 311.880 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 440/1194 | Loss: 292.335 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 450/1194 | Loss: 289.231 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 460/1194 | Loss: 291.853 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 470/1194 | Loss: 286.296 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 480/1194 | Loss: 306.611 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 490/1194 | Loss: 278.291 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 500/1194 | Loss: 306.466 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 510/1194 | Loss: 297.078 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 520/1194 | Loss: 293.331 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 530/1194 | Loss: 289.684 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 540/1194 | Loss: 287.707 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 550/1194 | Loss: 307.861 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 560/1194 | Loss: 336.810 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 570/1194 | Loss: 279.795 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 580/1194 | Loss: 312.841 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 590/1194 | Loss: 280.248 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 600/1194 | Loss: 300.113 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 610/1194 | Loss: 286.159 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 620/1194 | Loss: 292.095 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 630/1194 | Loss: 314.356 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 640/1194 | Loss: 334.026 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 650/1194 | Loss: 302.876 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 660/1194 | Loss: 307.184 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 670/1194 | Loss: 290.808 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 680/1194 | Loss: 309.383 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 690/1194 | Loss: 302.066 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 700/1194 | Loss: 312.109 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 710/1194 | Loss: 282.918 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 720/1194 | Loss: 325.482 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 730/1194 | Loss: 284.320 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 740/1194 | Loss: 295.587 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 750/1194 | Loss: 297.660 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 760/1194 | Loss: 309.078 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 770/1194 | Loss: 306.263 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 780/1194 | Loss: 281.258 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 790/1194 | Loss: 291.886 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 800/1194 | Loss: 295.483 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 810/1194 | Loss: 319.050 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 820/1194 | Loss: 288.297 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 830/1194 | Loss: 278.000 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 840/1194 | Loss: 296.527 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 850/1194 | Loss: 302.997 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 860/1194 | Loss: 301.024 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 870/1194 | Loss: 290.928 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 880/1194 | Loss: 304.815 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 890/1194 | Loss: 299.910 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 900/1194 | Loss: 292.853 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 910/1194 | Loss: 306.232 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 920/1194 | Loss: 281.659 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 930/1194 | Loss: 289.451 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 940/1194 | Loss: 303.655 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 950/1194 | Loss: 287.337 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 960/1194 | Loss: 295.202 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 970/1194 | Loss: 292.591 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 980/1194 | Loss: 302.231 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 990/1194 | Loss: 303.171 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1000/1194 | Loss: 302.196 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1010/1194 | Loss: 287.382 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1020/1194 | Loss: 288.115 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1030/1194 | Loss: 292.631 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1040/1194 | Loss: 296.323 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1050/1194 | Loss: 294.844 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1060/1194 | Loss: 295.886 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1070/1194 | Loss: 308.029 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1080/1194 | Loss: 289.490 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1090/1194 | Loss: 311.546 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1100/1194 | Loss: 295.186 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1110/1194 | Loss: 315.096 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1120/1194 | Loss: 287.293 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1130/1194 | Loss: 284.441 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1140/1194 | Loss: 302.733 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1150/1194 | Loss: 275.910 | Accuracy: 0.300\n",
      "[Epoch: 82/200] - Step: 1160/1194 | Loss: 304.358 | Accuracy: 0.000\n",
      "[Epoch: 82/200] - Step: 1170/1194 | Loss: 283.928 | Accuracy: 0.200\n",
      "[Epoch: 82/200] - Step: 1180/1194 | Loss: 305.262 | Accuracy: 0.100\n",
      "[Epoch: 82/200] - Step: 1190/1194 | Loss: 295.066 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 83/200] - Step: 10/1194 | Loss: 284.267 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 20/1194 | Loss: 280.287 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 30/1194 | Loss: 284.355 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 40/1194 | Loss: 301.431 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 50/1194 | Loss: 334.658 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 60/1194 | Loss: 306.507 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 70/1194 | Loss: 285.785 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 80/1194 | Loss: 296.345 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 90/1194 | Loss: 306.484 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 100/1194 | Loss: 305.868 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 110/1194 | Loss: 285.617 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 120/1194 | Loss: 275.719 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 130/1194 | Loss: 287.323 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 140/1194 | Loss: 311.022 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 150/1194 | Loss: 304.089 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 160/1194 | Loss: 296.996 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 170/1194 | Loss: 300.492 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 180/1194 | Loss: 279.788 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 190/1194 | Loss: 293.739 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 200/1194 | Loss: 312.198 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 210/1194 | Loss: 295.213 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 220/1194 | Loss: 300.194 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 230/1194 | Loss: 302.347 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 240/1194 | Loss: 289.872 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 250/1194 | Loss: 293.166 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 260/1194 | Loss: 285.344 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 270/1194 | Loss: 293.770 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 280/1194 | Loss: 300.575 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 290/1194 | Loss: 293.688 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 300/1194 | Loss: 324.316 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 310/1194 | Loss: 294.285 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 320/1194 | Loss: 303.690 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 330/1194 | Loss: 313.285 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 340/1194 | Loss: 284.598 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 350/1194 | Loss: 307.634 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 360/1194 | Loss: 293.066 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 370/1194 | Loss: 294.515 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 380/1194 | Loss: 294.268 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 390/1194 | Loss: 303.300 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 400/1194 | Loss: 272.684 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 410/1194 | Loss: 295.118 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 420/1194 | Loss: 299.314 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 430/1194 | Loss: 323.543 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 440/1194 | Loss: 290.584 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 450/1194 | Loss: 293.282 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 460/1194 | Loss: 301.825 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 470/1194 | Loss: 293.249 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 480/1194 | Loss: 276.822 | Accuracy: 0.400\n",
      "[Epoch: 83/200] - Step: 490/1194 | Loss: 286.688 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 500/1194 | Loss: 318.015 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 510/1194 | Loss: 287.626 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 520/1194 | Loss: 286.021 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 530/1194 | Loss: 295.992 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 540/1194 | Loss: 303.419 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 550/1194 | Loss: 301.994 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 560/1194 | Loss: 312.242 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 570/1194 | Loss: 289.330 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 580/1194 | Loss: 308.332 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 590/1194 | Loss: 304.680 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 600/1194 | Loss: 298.419 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 610/1194 | Loss: 307.955 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 620/1194 | Loss: 315.907 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 630/1194 | Loss: 297.139 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 640/1194 | Loss: 291.171 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 650/1194 | Loss: 306.925 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 660/1194 | Loss: 297.345 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 670/1194 | Loss: 283.776 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 680/1194 | Loss: 302.691 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 690/1194 | Loss: 288.565 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 700/1194 | Loss: 310.957 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 710/1194 | Loss: 283.704 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 720/1194 | Loss: 316.314 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 730/1194 | Loss: 289.879 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 740/1194 | Loss: 305.923 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 750/1194 | Loss: 284.243 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 760/1194 | Loss: 312.898 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 770/1194 | Loss: 293.950 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 780/1194 | Loss: 293.063 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 790/1194 | Loss: 310.973 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 800/1194 | Loss: 283.122 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 810/1194 | Loss: 318.262 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 820/1194 | Loss: 294.400 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 830/1194 | Loss: 303.709 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 840/1194 | Loss: 287.949 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 850/1194 | Loss: 304.509 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 860/1194 | Loss: 298.537 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 870/1194 | Loss: 313.884 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 880/1194 | Loss: 310.642 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 890/1194 | Loss: 304.939 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 900/1194 | Loss: 299.675 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 910/1194 | Loss: 300.560 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 920/1194 | Loss: 278.068 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 930/1194 | Loss: 307.349 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 940/1194 | Loss: 298.251 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 950/1194 | Loss: 292.172 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 960/1194 | Loss: 284.174 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 970/1194 | Loss: 288.279 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 980/1194 | Loss: 286.986 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 990/1194 | Loss: 277.258 | Accuracy: 0.400\n",
      "[Epoch: 83/200] - Step: 1000/1194 | Loss: 299.136 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 1010/1194 | Loss: 272.006 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 1020/1194 | Loss: 304.954 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1030/1194 | Loss: 299.183 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1040/1194 | Loss: 291.409 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 1050/1194 | Loss: 321.323 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1060/1194 | Loss: 298.964 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 1070/1194 | Loss: 290.112 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 1080/1194 | Loss: 304.226 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 1090/1194 | Loss: 291.185 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 1100/1194 | Loss: 304.006 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1110/1194 | Loss: 289.876 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1120/1194 | Loss: 285.742 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 1130/1194 | Loss: 294.318 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 1140/1194 | Loss: 270.403 | Accuracy: 0.300\n",
      "[Epoch: 83/200] - Step: 1150/1194 | Loss: 299.963 | Accuracy: 0.100\n",
      "[Epoch: 83/200] - Step: 1160/1194 | Loss: 288.020 | Accuracy: 0.200\n",
      "[Epoch: 83/200] - Step: 1170/1194 | Loss: 262.501 | Accuracy: 0.400\n",
      "[Epoch: 83/200] - Step: 1180/1194 | Loss: 314.365 | Accuracy: 0.000\n",
      "[Epoch: 83/200] - Step: 1190/1194 | Loss: 306.491 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 84/200] - Step: 10/1194 | Loss: 288.250 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 20/1194 | Loss: 312.318 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 30/1194 | Loss: 296.419 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 40/1194 | Loss: 292.935 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 50/1194 | Loss: 307.249 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 60/1194 | Loss: 295.898 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 70/1194 | Loss: 307.042 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 80/1194 | Loss: 286.740 | Accuracy: 0.300\n",
      "[Epoch: 84/200] - Step: 90/1194 | Loss: 299.934 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 100/1194 | Loss: 295.661 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 110/1194 | Loss: 283.922 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 120/1194 | Loss: 309.317 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 130/1194 | Loss: 300.646 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 140/1194 | Loss: 332.478 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 150/1194 | Loss: 284.606 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 160/1194 | Loss: 302.194 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 170/1194 | Loss: 273.961 | Accuracy: 0.400\n",
      "[Epoch: 84/200] - Step: 180/1194 | Loss: 284.559 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 190/1194 | Loss: 301.574 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 200/1194 | Loss: 303.334 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 210/1194 | Loss: 306.097 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 220/1194 | Loss: 281.494 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 230/1194 | Loss: 287.870 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 240/1194 | Loss: 304.820 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 250/1194 | Loss: 297.421 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 260/1194 | Loss: 296.586 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 270/1194 | Loss: 290.887 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 280/1194 | Loss: 293.758 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 290/1194 | Loss: 292.650 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 300/1194 | Loss: 285.733 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 310/1194 | Loss: 315.418 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 320/1194 | Loss: 300.727 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 330/1194 | Loss: 295.119 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 340/1194 | Loss: 295.746 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 350/1194 | Loss: 276.997 | Accuracy: 0.300\n",
      "[Epoch: 84/200] - Step: 360/1194 | Loss: 290.039 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 370/1194 | Loss: 320.878 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 380/1194 | Loss: 296.627 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 390/1194 | Loss: 291.497 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 400/1194 | Loss: 289.479 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 410/1194 | Loss: 280.946 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 420/1194 | Loss: 302.523 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 430/1194 | Loss: 295.377 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 440/1194 | Loss: 294.719 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 450/1194 | Loss: 308.820 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 460/1194 | Loss: 295.113 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 470/1194 | Loss: 289.893 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 480/1194 | Loss: 280.788 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 490/1194 | Loss: 310.759 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 500/1194 | Loss: 309.363 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 510/1194 | Loss: 288.691 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 520/1194 | Loss: 324.425 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 530/1194 | Loss: 293.684 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 540/1194 | Loss: 283.798 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 550/1194 | Loss: 289.702 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 560/1194 | Loss: 296.633 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 570/1194 | Loss: 298.549 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 580/1194 | Loss: 300.119 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 590/1194 | Loss: 298.001 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 600/1194 | Loss: 284.275 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 610/1194 | Loss: 303.327 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 620/1194 | Loss: 303.206 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 630/1194 | Loss: 305.506 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 640/1194 | Loss: 357.072 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 650/1194 | Loss: 305.766 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 660/1194 | Loss: 278.460 | Accuracy: 0.300\n",
      "[Epoch: 84/200] - Step: 670/1194 | Loss: 313.533 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 680/1194 | Loss: 326.911 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 690/1194 | Loss: 301.122 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 700/1194 | Loss: 290.210 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 710/1194 | Loss: 302.467 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 720/1194 | Loss: 298.606 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 730/1194 | Loss: 289.732 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 740/1194 | Loss: 279.334 | Accuracy: 0.400\n",
      "[Epoch: 84/200] - Step: 750/1194 | Loss: 298.925 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 760/1194 | Loss: 295.295 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 770/1194 | Loss: 306.254 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 780/1194 | Loss: 285.131 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 790/1194 | Loss: 294.574 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 800/1194 | Loss: 302.576 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 810/1194 | Loss: 300.389 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 820/1194 | Loss: 305.882 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 830/1194 | Loss: 290.048 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 840/1194 | Loss: 300.619 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 850/1194 | Loss: 280.722 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 860/1194 | Loss: 296.116 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 870/1194 | Loss: 312.379 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 880/1194 | Loss: 299.731 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 890/1194 | Loss: 295.156 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 900/1194 | Loss: 307.624 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 910/1194 | Loss: 288.717 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 920/1194 | Loss: 297.006 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 930/1194 | Loss: 287.133 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 940/1194 | Loss: 292.928 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 950/1194 | Loss: 292.988 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 960/1194 | Loss: 298.782 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 970/1194 | Loss: 294.643 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 980/1194 | Loss: 308.255 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 990/1194 | Loss: 282.064 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1000/1194 | Loss: 294.251 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1010/1194 | Loss: 291.400 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 1020/1194 | Loss: 294.133 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1030/1194 | Loss: 298.237 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 1040/1194 | Loss: 306.282 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 1050/1194 | Loss: 288.269 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1060/1194 | Loss: 285.457 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1070/1194 | Loss: 267.713 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1080/1194 | Loss: 305.778 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 1090/1194 | Loss: 303.184 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 1100/1194 | Loss: 290.789 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1110/1194 | Loss: 287.668 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1120/1194 | Loss: 313.419 | Accuracy: 0.100\n",
      "[Epoch: 84/200] - Step: 1130/1194 | Loss: 300.556 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 1140/1194 | Loss: 272.887 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1150/1194 | Loss: 278.006 | Accuracy: 0.300\n",
      "[Epoch: 84/200] - Step: 1160/1194 | Loss: 314.888 | Accuracy: 0.000\n",
      "[Epoch: 84/200] - Step: 1170/1194 | Loss: 285.014 | Accuracy: 0.200\n",
      "[Epoch: 84/200] - Step: 1180/1194 | Loss: 288.530 | Accuracy: 0.300\n",
      "[Epoch: 84/200] - Step: 1190/1194 | Loss: 307.119 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 85/200] - Step: 10/1194 | Loss: 291.970 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 20/1194 | Loss: 301.103 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 30/1194 | Loss: 279.137 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 40/1194 | Loss: 290.740 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 50/1194 | Loss: 333.234 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 60/1194 | Loss: 291.211 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 70/1194 | Loss: 282.575 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 80/1194 | Loss: 301.820 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 90/1194 | Loss: 275.852 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 100/1194 | Loss: 317.073 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 110/1194 | Loss: 300.348 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 120/1194 | Loss: 278.994 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 130/1194 | Loss: 299.903 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 140/1194 | Loss: 295.751 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 150/1194 | Loss: 288.711 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 160/1194 | Loss: 296.350 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 170/1194 | Loss: 315.859 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 180/1194 | Loss: 288.792 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 190/1194 | Loss: 305.105 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 200/1194 | Loss: 293.180 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 210/1194 | Loss: 307.965 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 220/1194 | Loss: 300.266 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 230/1194 | Loss: 274.658 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 240/1194 | Loss: 292.054 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 250/1194 | Loss: 302.219 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 260/1194 | Loss: 293.822 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 270/1194 | Loss: 294.919 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 280/1194 | Loss: 305.127 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 290/1194 | Loss: 302.855 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 300/1194 | Loss: 291.740 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 310/1194 | Loss: 282.737 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 320/1194 | Loss: 304.794 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 330/1194 | Loss: 302.467 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 340/1194 | Loss: 293.910 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 350/1194 | Loss: 287.152 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 360/1194 | Loss: 301.903 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 370/1194 | Loss: 282.131 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 380/1194 | Loss: 296.412 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 390/1194 | Loss: 285.182 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 400/1194 | Loss: 304.813 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 410/1194 | Loss: 291.103 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 420/1194 | Loss: 313.036 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 430/1194 | Loss: 302.978 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 440/1194 | Loss: 302.903 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 450/1194 | Loss: 334.143 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 460/1194 | Loss: 276.384 | Accuracy: 0.400\n",
      "[Epoch: 85/200] - Step: 470/1194 | Loss: 296.572 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 480/1194 | Loss: 299.296 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 490/1194 | Loss: 271.288 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 500/1194 | Loss: 300.431 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 510/1194 | Loss: 278.158 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 520/1194 | Loss: 308.900 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 530/1194 | Loss: 277.125 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 540/1194 | Loss: 304.180 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 550/1194 | Loss: 291.634 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 560/1194 | Loss: 283.674 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 570/1194 | Loss: 291.843 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 580/1194 | Loss: 301.138 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 590/1194 | Loss: 286.047 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 600/1194 | Loss: 296.225 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 610/1194 | Loss: 297.054 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 620/1194 | Loss: 300.552 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 630/1194 | Loss: 307.327 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 640/1194 | Loss: 298.465 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 650/1194 | Loss: 286.743 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 660/1194 | Loss: 309.460 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 670/1194 | Loss: 300.390 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 680/1194 | Loss: 289.073 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 690/1194 | Loss: 304.425 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 700/1194 | Loss: 319.267 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 710/1194 | Loss: 292.218 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 720/1194 | Loss: 301.207 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 730/1194 | Loss: 301.460 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 740/1194 | Loss: 287.524 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 750/1194 | Loss: 305.703 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 760/1194 | Loss: 303.911 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 770/1194 | Loss: 301.003 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 780/1194 | Loss: 288.127 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 790/1194 | Loss: 301.876 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 800/1194 | Loss: 310.555 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 810/1194 | Loss: 297.153 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 820/1194 | Loss: 307.284 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 830/1194 | Loss: 301.644 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 840/1194 | Loss: 280.551 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 850/1194 | Loss: 293.187 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 860/1194 | Loss: 284.713 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 870/1194 | Loss: 304.679 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 880/1194 | Loss: 288.216 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 890/1194 | Loss: 285.314 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 900/1194 | Loss: 288.186 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 910/1194 | Loss: 294.197 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 920/1194 | Loss: 285.629 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 930/1194 | Loss: 299.304 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 940/1194 | Loss: 296.773 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 950/1194 | Loss: 288.849 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 960/1194 | Loss: 299.189 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 970/1194 | Loss: 305.760 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 980/1194 | Loss: 299.644 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 990/1194 | Loss: 308.714 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1000/1194 | Loss: 273.340 | Accuracy: 0.400\n",
      "[Epoch: 85/200] - Step: 1010/1194 | Loss: 305.306 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1020/1194 | Loss: 285.540 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 1030/1194 | Loss: 315.256 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 1040/1194 | Loss: 279.677 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 1050/1194 | Loss: 291.589 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1060/1194 | Loss: 283.292 | Accuracy: 0.300\n",
      "[Epoch: 85/200] - Step: 1070/1194 | Loss: 303.313 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1080/1194 | Loss: 312.490 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1090/1194 | Loss: 339.262 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1100/1194 | Loss: 300.647 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1110/1194 | Loss: 303.142 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1120/1194 | Loss: 283.732 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 1130/1194 | Loss: 292.306 | Accuracy: 0.200\n",
      "[Epoch: 85/200] - Step: 1140/1194 | Loss: 298.944 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1150/1194 | Loss: 297.653 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1160/1194 | Loss: 325.911 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1170/1194 | Loss: 295.158 | Accuracy: 0.100\n",
      "[Epoch: 85/200] - Step: 1180/1194 | Loss: 305.362 | Accuracy: 0.000\n",
      "[Epoch: 85/200] - Step: 1190/1194 | Loss: 306.184 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 86/200] - Step: 10/1194 | Loss: 294.568 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 20/1194 | Loss: 293.603 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 30/1194 | Loss: 295.835 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 40/1194 | Loss: 293.122 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 50/1194 | Loss: 292.849 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 60/1194 | Loss: 298.808 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 70/1194 | Loss: 300.606 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 80/1194 | Loss: 303.251 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 90/1194 | Loss: 282.517 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 100/1194 | Loss: 324.508 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 110/1194 | Loss: 331.857 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 120/1194 | Loss: 282.757 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 130/1194 | Loss: 294.603 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 140/1194 | Loss: 286.132 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 150/1194 | Loss: 299.953 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 160/1194 | Loss: 291.157 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 170/1194 | Loss: 302.845 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 180/1194 | Loss: 282.075 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 190/1194 | Loss: 304.622 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 200/1194 | Loss: 294.449 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 210/1194 | Loss: 281.053 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 220/1194 | Loss: 300.633 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 230/1194 | Loss: 287.244 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 240/1194 | Loss: 293.751 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 250/1194 | Loss: 304.082 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 260/1194 | Loss: 299.791 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 270/1194 | Loss: 305.716 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 280/1194 | Loss: 298.219 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 290/1194 | Loss: 282.408 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 300/1194 | Loss: 269.441 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 310/1194 | Loss: 311.109 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 320/1194 | Loss: 313.301 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 330/1194 | Loss: 304.559 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 340/1194 | Loss: 284.077 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 350/1194 | Loss: 276.608 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 360/1194 | Loss: 289.741 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 370/1194 | Loss: 292.239 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 380/1194 | Loss: 316.400 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 390/1194 | Loss: 276.977 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 400/1194 | Loss: 296.492 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 410/1194 | Loss: 302.321 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 420/1194 | Loss: 294.909 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 430/1194 | Loss: 314.327 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 440/1194 | Loss: 294.242 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 450/1194 | Loss: 311.772 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 460/1194 | Loss: 286.913 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 470/1194 | Loss: 304.915 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 480/1194 | Loss: 299.252 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 490/1194 | Loss: 295.708 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 500/1194 | Loss: 295.586 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 510/1194 | Loss: 293.955 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 520/1194 | Loss: 296.922 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 530/1194 | Loss: 264.515 | Accuracy: 0.400\n",
      "[Epoch: 86/200] - Step: 540/1194 | Loss: 301.626 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 550/1194 | Loss: 305.758 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 560/1194 | Loss: 297.055 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 570/1194 | Loss: 289.234 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 580/1194 | Loss: 291.671 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 590/1194 | Loss: 304.667 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 600/1194 | Loss: 298.228 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 610/1194 | Loss: 333.145 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 620/1194 | Loss: 300.070 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 630/1194 | Loss: 303.413 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 640/1194 | Loss: 290.915 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 650/1194 | Loss: 293.492 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 660/1194 | Loss: 297.701 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 670/1194 | Loss: 300.538 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 680/1194 | Loss: 308.945 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 690/1194 | Loss: 295.460 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 700/1194 | Loss: 285.760 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 710/1194 | Loss: 311.389 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 720/1194 | Loss: 312.098 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 730/1194 | Loss: 287.548 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 740/1194 | Loss: 300.004 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 750/1194 | Loss: 301.002 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 760/1194 | Loss: 307.055 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 770/1194 | Loss: 309.640 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 780/1194 | Loss: 302.802 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 790/1194 | Loss: 283.181 | Accuracy: 0.300\n",
      "[Epoch: 86/200] - Step: 800/1194 | Loss: 302.524 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 810/1194 | Loss: 291.251 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 820/1194 | Loss: 292.708 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 830/1194 | Loss: 295.752 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 840/1194 | Loss: 295.064 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 850/1194 | Loss: 315.291 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 860/1194 | Loss: 285.531 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 870/1194 | Loss: 286.511 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 880/1194 | Loss: 295.540 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 890/1194 | Loss: 288.204 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 900/1194 | Loss: 296.216 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 910/1194 | Loss: 288.587 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 920/1194 | Loss: 334.540 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 930/1194 | Loss: 300.815 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 940/1194 | Loss: 303.107 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 950/1194 | Loss: 305.703 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 960/1194 | Loss: 296.285 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 970/1194 | Loss: 291.149 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 980/1194 | Loss: 298.044 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 990/1194 | Loss: 284.230 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1000/1194 | Loss: 297.570 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1010/1194 | Loss: 292.072 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1020/1194 | Loss: 307.092 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 1030/1194 | Loss: 307.911 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 1040/1194 | Loss: 303.359 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 1050/1194 | Loss: 293.153 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1060/1194 | Loss: 295.749 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1070/1194 | Loss: 291.046 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 1080/1194 | Loss: 297.250 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1090/1194 | Loss: 296.853 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1100/1194 | Loss: 291.953 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1110/1194 | Loss: 279.372 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 1120/1194 | Loss: 306.890 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 1130/1194 | Loss: 297.386 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 1140/1194 | Loss: 300.318 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1150/1194 | Loss: 289.672 | Accuracy: 0.200\n",
      "[Epoch: 86/200] - Step: 1160/1194 | Loss: 323.038 | Accuracy: 0.000\n",
      "[Epoch: 86/200] - Step: 1170/1194 | Loss: 293.475 | Accuracy: 0.100\n",
      "[Epoch: 86/200] - Step: 1180/1194 | Loss: 274.826 | Accuracy: 0.400\n",
      "[Epoch: 86/200] - Step: 1190/1194 | Loss: 289.814 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 87/200] - Step: 10/1194 | Loss: 295.588 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 20/1194 | Loss: 296.363 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 30/1194 | Loss: 279.641 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 40/1194 | Loss: 299.746 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 50/1194 | Loss: 311.386 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 60/1194 | Loss: 252.411 | Accuracy: 0.500\n",
      "[Epoch: 87/200] - Step: 70/1194 | Loss: 306.284 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 80/1194 | Loss: 324.692 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 90/1194 | Loss: 309.285 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 100/1194 | Loss: 306.532 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 110/1194 | Loss: 315.380 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 120/1194 | Loss: 290.044 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 130/1194 | Loss: 301.058 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 140/1194 | Loss: 294.058 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 150/1194 | Loss: 329.392 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 160/1194 | Loss: 295.136 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 170/1194 | Loss: 302.098 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 180/1194 | Loss: 292.354 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 190/1194 | Loss: 290.736 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 200/1194 | Loss: 301.477 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 210/1194 | Loss: 299.295 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 220/1194 | Loss: 283.441 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 230/1194 | Loss: 298.682 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 240/1194 | Loss: 302.934 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 250/1194 | Loss: 297.037 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 260/1194 | Loss: 296.086 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 270/1194 | Loss: 298.850 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 280/1194 | Loss: 299.340 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 290/1194 | Loss: 302.816 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 300/1194 | Loss: 307.652 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 310/1194 | Loss: 294.613 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 320/1194 | Loss: 270.952 | Accuracy: 0.400\n",
      "[Epoch: 87/200] - Step: 330/1194 | Loss: 310.135 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 340/1194 | Loss: 298.485 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 350/1194 | Loss: 290.772 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 360/1194 | Loss: 291.143 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 370/1194 | Loss: 301.907 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 380/1194 | Loss: 287.266 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 390/1194 | Loss: 314.791 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 400/1194 | Loss: 284.804 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 410/1194 | Loss: 291.494 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 420/1194 | Loss: 305.784 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 430/1194 | Loss: 291.319 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 440/1194 | Loss: 300.380 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 450/1194 | Loss: 287.353 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 460/1194 | Loss: 293.718 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 470/1194 | Loss: 304.790 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 480/1194 | Loss: 299.125 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 490/1194 | Loss: 303.531 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 500/1194 | Loss: 296.467 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 510/1194 | Loss: 310.615 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 520/1194 | Loss: 303.806 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 530/1194 | Loss: 297.264 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 540/1194 | Loss: 305.047 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 550/1194 | Loss: 279.589 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 560/1194 | Loss: 289.817 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 570/1194 | Loss: 293.100 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 580/1194 | Loss: 307.719 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 590/1194 | Loss: 296.734 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 600/1194 | Loss: 307.780 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 610/1194 | Loss: 293.616 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 620/1194 | Loss: 288.998 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 630/1194 | Loss: 281.918 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 640/1194 | Loss: 295.599 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 650/1194 | Loss: 300.745 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 660/1194 | Loss: 295.533 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 670/1194 | Loss: 314.846 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 680/1194 | Loss: 298.142 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 690/1194 | Loss: 272.839 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 700/1194 | Loss: 298.545 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 710/1194 | Loss: 294.245 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 720/1194 | Loss: 289.040 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 730/1194 | Loss: 287.323 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 740/1194 | Loss: 287.801 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 750/1194 | Loss: 317.704 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 760/1194 | Loss: 297.518 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 770/1194 | Loss: 309.382 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 780/1194 | Loss: 302.703 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 790/1194 | Loss: 298.167 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 800/1194 | Loss: 304.545 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 810/1194 | Loss: 289.156 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 820/1194 | Loss: 271.941 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 830/1194 | Loss: 272.476 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 840/1194 | Loss: 300.463 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 850/1194 | Loss: 301.369 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 860/1194 | Loss: 283.395 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 870/1194 | Loss: 318.950 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 880/1194 | Loss: 299.287 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 890/1194 | Loss: 310.878 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 900/1194 | Loss: 298.709 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 910/1194 | Loss: 327.899 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 920/1194 | Loss: 296.951 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 930/1194 | Loss: 275.915 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 940/1194 | Loss: 304.018 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 950/1194 | Loss: 291.950 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 960/1194 | Loss: 287.601 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 970/1194 | Loss: 303.132 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 980/1194 | Loss: 290.839 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 990/1194 | Loss: 283.283 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 1000/1194 | Loss: 284.045 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1010/1194 | Loss: 265.000 | Accuracy: 0.400\n",
      "[Epoch: 87/200] - Step: 1020/1194 | Loss: 310.940 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 1030/1194 | Loss: 300.565 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 1040/1194 | Loss: 297.418 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 1050/1194 | Loss: 299.540 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 1060/1194 | Loss: 296.323 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1070/1194 | Loss: 310.197 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 1080/1194 | Loss: 277.943 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 1090/1194 | Loss: 265.259 | Accuracy: 0.300\n",
      "[Epoch: 87/200] - Step: 1100/1194 | Loss: 310.058 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1110/1194 | Loss: 290.967 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 1120/1194 | Loss: 307.040 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1130/1194 | Loss: 305.566 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1140/1194 | Loss: 294.756 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 1150/1194 | Loss: 287.316 | Accuracy: 0.200\n",
      "[Epoch: 87/200] - Step: 1160/1194 | Loss: 298.979 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1170/1194 | Loss: 299.786 | Accuracy: 0.100\n",
      "[Epoch: 87/200] - Step: 1180/1194 | Loss: 302.831 | Accuracy: 0.000\n",
      "[Epoch: 87/200] - Step: 1190/1194 | Loss: 317.696 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 88/200] - Step: 10/1194 | Loss: 295.535 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 20/1194 | Loss: 286.031 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 30/1194 | Loss: 276.888 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 40/1194 | Loss: 315.871 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 50/1194 | Loss: 299.928 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 60/1194 | Loss: 294.268 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 70/1194 | Loss: 285.687 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 80/1194 | Loss: 306.683 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 90/1194 | Loss: 272.253 | Accuracy: 0.400\n",
      "[Epoch: 88/200] - Step: 100/1194 | Loss: 296.875 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 110/1194 | Loss: 312.861 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 120/1194 | Loss: 298.975 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 130/1194 | Loss: 290.116 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 140/1194 | Loss: 310.622 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 150/1194 | Loss: 292.786 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 160/1194 | Loss: 298.486 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 170/1194 | Loss: 314.837 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 180/1194 | Loss: 304.059 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 190/1194 | Loss: 283.851 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 200/1194 | Loss: 303.721 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 210/1194 | Loss: 273.577 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 220/1194 | Loss: 280.776 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 230/1194 | Loss: 262.796 | Accuracy: 0.400\n",
      "[Epoch: 88/200] - Step: 240/1194 | Loss: 276.721 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 250/1194 | Loss: 301.082 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 260/1194 | Loss: 314.957 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 270/1194 | Loss: 285.612 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 280/1194 | Loss: 291.151 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 290/1194 | Loss: 305.616 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 300/1194 | Loss: 306.844 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 310/1194 | Loss: 294.482 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 320/1194 | Loss: 343.739 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 330/1194 | Loss: 303.423 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 340/1194 | Loss: 285.579 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 350/1194 | Loss: 317.004 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 360/1194 | Loss: 308.808 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 370/1194 | Loss: 287.080 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 380/1194 | Loss: 298.201 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 390/1194 | Loss: 290.617 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 400/1194 | Loss: 291.888 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 410/1194 | Loss: 298.172 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 420/1194 | Loss: 288.037 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 430/1194 | Loss: 295.632 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 440/1194 | Loss: 300.300 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 450/1194 | Loss: 309.338 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 460/1194 | Loss: 302.597 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 470/1194 | Loss: 296.173 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 480/1194 | Loss: 325.068 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 490/1194 | Loss: 307.257 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 500/1194 | Loss: 325.956 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 510/1194 | Loss: 295.309 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 520/1194 | Loss: 297.094 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 530/1194 | Loss: 296.192 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 540/1194 | Loss: 281.227 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 550/1194 | Loss: 326.054 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 560/1194 | Loss: 306.007 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 570/1194 | Loss: 288.609 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 580/1194 | Loss: 303.666 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 590/1194 | Loss: 300.982 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 600/1194 | Loss: 303.316 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 610/1194 | Loss: 308.513 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 620/1194 | Loss: 307.989 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 630/1194 | Loss: 299.121 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 640/1194 | Loss: 300.362 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 650/1194 | Loss: 306.333 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 660/1194 | Loss: 301.715 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 670/1194 | Loss: 297.282 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 680/1194 | Loss: 315.225 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 690/1194 | Loss: 299.150 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 700/1194 | Loss: 296.828 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 710/1194 | Loss: 294.801 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 720/1194 | Loss: 287.921 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 730/1194 | Loss: 292.184 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 740/1194 | Loss: 293.518 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 750/1194 | Loss: 300.804 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 760/1194 | Loss: 287.071 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 770/1194 | Loss: 299.845 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 780/1194 | Loss: 291.473 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 790/1194 | Loss: 303.715 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 800/1194 | Loss: 288.658 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 810/1194 | Loss: 281.295 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 820/1194 | Loss: 283.543 | Accuracy: 0.300\n",
      "[Epoch: 88/200] - Step: 830/1194 | Loss: 284.628 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 840/1194 | Loss: 300.377 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 850/1194 | Loss: 282.813 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 860/1194 | Loss: 279.216 | Accuracy: 0.400\n",
      "[Epoch: 88/200] - Step: 870/1194 | Loss: 289.819 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 880/1194 | Loss: 309.680 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 890/1194 | Loss: 305.899 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 900/1194 | Loss: 289.793 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 910/1194 | Loss: 287.974 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 920/1194 | Loss: 295.451 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 930/1194 | Loss: 316.924 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 940/1194 | Loss: 287.115 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 950/1194 | Loss: 303.467 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 960/1194 | Loss: 304.575 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 970/1194 | Loss: 299.425 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 980/1194 | Loss: 293.785 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 990/1194 | Loss: 306.253 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 1000/1194 | Loss: 281.744 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1010/1194 | Loss: 289.264 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1020/1194 | Loss: 295.087 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1030/1194 | Loss: 313.358 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1040/1194 | Loss: 292.912 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1050/1194 | Loss: 318.275 | Accuracy: 0.000\n",
      "[Epoch: 88/200] - Step: 1060/1194 | Loss: 283.819 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1070/1194 | Loss: 298.550 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1080/1194 | Loss: 293.913 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1090/1194 | Loss: 298.304 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1100/1194 | Loss: 298.978 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1110/1194 | Loss: 283.747 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1120/1194 | Loss: 292.062 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1130/1194 | Loss: 304.415 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1140/1194 | Loss: 281.149 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1150/1194 | Loss: 279.442 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1160/1194 | Loss: 290.471 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1170/1194 | Loss: 279.865 | Accuracy: 0.200\n",
      "[Epoch: 88/200] - Step: 1180/1194 | Loss: 297.742 | Accuracy: 0.100\n",
      "[Epoch: 88/200] - Step: 1190/1194 | Loss: 291.791 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 89/200] - Step: 10/1194 | Loss: 295.237 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 20/1194 | Loss: 302.329 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 30/1194 | Loss: 313.387 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 40/1194 | Loss: 290.377 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 50/1194 | Loss: 291.027 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 60/1194 | Loss: 290.269 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 70/1194 | Loss: 305.807 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 80/1194 | Loss: 291.765 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 90/1194 | Loss: 289.583 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 100/1194 | Loss: 282.007 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 110/1194 | Loss: 300.003 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 120/1194 | Loss: 280.978 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 130/1194 | Loss: 285.841 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 140/1194 | Loss: 312.132 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 150/1194 | Loss: 296.535 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 160/1194 | Loss: 294.807 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 170/1194 | Loss: 299.174 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 180/1194 | Loss: 302.221 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 190/1194 | Loss: 289.884 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 200/1194 | Loss: 302.231 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 210/1194 | Loss: 290.823 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 220/1194 | Loss: 293.672 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 230/1194 | Loss: 296.138 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 240/1194 | Loss: 340.065 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 250/1194 | Loss: 307.617 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 260/1194 | Loss: 295.722 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 270/1194 | Loss: 295.872 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 280/1194 | Loss: 292.842 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 290/1194 | Loss: 297.638 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 300/1194 | Loss: 289.862 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 310/1194 | Loss: 299.094 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 320/1194 | Loss: 269.422 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 330/1194 | Loss: 287.188 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 340/1194 | Loss: 293.688 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 350/1194 | Loss: 288.263 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 360/1194 | Loss: 292.415 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 370/1194 | Loss: 301.459 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 380/1194 | Loss: 295.243 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 390/1194 | Loss: 290.057 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 400/1194 | Loss: 300.165 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 410/1194 | Loss: 304.258 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 420/1194 | Loss: 282.548 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 430/1194 | Loss: 289.992 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 440/1194 | Loss: 335.747 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 450/1194 | Loss: 296.899 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 460/1194 | Loss: 307.530 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 470/1194 | Loss: 275.652 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 480/1194 | Loss: 275.414 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 490/1194 | Loss: 297.126 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 500/1194 | Loss: 304.207 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 510/1194 | Loss: 312.300 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 520/1194 | Loss: 302.594 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 530/1194 | Loss: 300.666 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 540/1194 | Loss: 287.403 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 550/1194 | Loss: 310.520 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 560/1194 | Loss: 276.703 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 570/1194 | Loss: 300.988 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 580/1194 | Loss: 262.227 | Accuracy: 0.400\n",
      "[Epoch: 89/200] - Step: 590/1194 | Loss: 281.420 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 600/1194 | Loss: 303.505 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 610/1194 | Loss: 310.711 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 620/1194 | Loss: 272.792 | Accuracy: 0.400\n",
      "[Epoch: 89/200] - Step: 630/1194 | Loss: 310.057 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 640/1194 | Loss: 295.047 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 650/1194 | Loss: 300.198 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 660/1194 | Loss: 301.551 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 670/1194 | Loss: 306.336 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 680/1194 | Loss: 304.628 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 690/1194 | Loss: 284.658 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 700/1194 | Loss: 275.962 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 710/1194 | Loss: 282.921 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 720/1194 | Loss: 318.540 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 730/1194 | Loss: 290.197 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 740/1194 | Loss: 290.735 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 750/1194 | Loss: 309.099 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 760/1194 | Loss: 291.452 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 770/1194 | Loss: 298.345 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 780/1194 | Loss: 296.454 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 790/1194 | Loss: 293.349 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 800/1194 | Loss: 306.519 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 810/1194 | Loss: 287.414 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 820/1194 | Loss: 314.442 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 830/1194 | Loss: 298.091 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 840/1194 | Loss: 300.254 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 850/1194 | Loss: 302.027 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 860/1194 | Loss: 312.291 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 870/1194 | Loss: 298.757 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 880/1194 | Loss: 279.234 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 890/1194 | Loss: 305.486 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 900/1194 | Loss: 296.180 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 910/1194 | Loss: 290.966 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 920/1194 | Loss: 309.107 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 930/1194 | Loss: 272.849 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 940/1194 | Loss: 292.964 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 950/1194 | Loss: 298.178 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 960/1194 | Loss: 309.816 | Accuracy: 0.400\n",
      "[Epoch: 89/200] - Step: 970/1194 | Loss: 301.751 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 980/1194 | Loss: 302.056 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 990/1194 | Loss: 296.860 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 1000/1194 | Loss: 304.721 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 1010/1194 | Loss: 332.662 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1020/1194 | Loss: 299.638 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 1030/1194 | Loss: 298.067 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 1040/1194 | Loss: 294.818 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 1050/1194 | Loss: 310.107 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 1060/1194 | Loss: 310.143 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1070/1194 | Loss: 283.887 | Accuracy: 0.300\n",
      "[Epoch: 89/200] - Step: 1080/1194 | Loss: 298.035 | Accuracy: 0.100\n",
      "[Epoch: 89/200] - Step: 1090/1194 | Loss: 295.598 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1100/1194 | Loss: 293.860 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 1110/1194 | Loss: 277.763 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 1120/1194 | Loss: 265.986 | Accuracy: 0.400\n",
      "[Epoch: 89/200] - Step: 1130/1194 | Loss: 298.751 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 1140/1194 | Loss: 310.201 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1150/1194 | Loss: 305.866 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1160/1194 | Loss: 313.993 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1170/1194 | Loss: 315.956 | Accuracy: 0.000\n",
      "[Epoch: 89/200] - Step: 1180/1194 | Loss: 293.039 | Accuracy: 0.200\n",
      "[Epoch: 89/200] - Step: 1190/1194 | Loss: 299.461 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 90/200] - Step: 10/1194 | Loss: 297.018 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 20/1194 | Loss: 311.706 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 30/1194 | Loss: 297.351 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 40/1194 | Loss: 297.755 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 50/1194 | Loss: 284.128 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 60/1194 | Loss: 275.119 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 70/1194 | Loss: 308.169 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 80/1194 | Loss: 286.704 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 90/1194 | Loss: 298.676 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 100/1194 | Loss: 275.712 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 110/1194 | Loss: 319.456 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 120/1194 | Loss: 297.145 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 130/1194 | Loss: 307.643 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 140/1194 | Loss: 303.679 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 150/1194 | Loss: 307.697 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 160/1194 | Loss: 300.392 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 170/1194 | Loss: 286.014 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 180/1194 | Loss: 288.347 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 190/1194 | Loss: 293.167 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 200/1194 | Loss: 325.575 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 210/1194 | Loss: 290.158 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 220/1194 | Loss: 288.657 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 230/1194 | Loss: 316.965 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 240/1194 | Loss: 288.618 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 250/1194 | Loss: 291.989 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 260/1194 | Loss: 307.150 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 270/1194 | Loss: 302.473 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 280/1194 | Loss: 283.548 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 290/1194 | Loss: 311.321 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 300/1194 | Loss: 299.310 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 310/1194 | Loss: 306.889 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 320/1194 | Loss: 327.936 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 330/1194 | Loss: 290.603 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 340/1194 | Loss: 290.002 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 350/1194 | Loss: 297.510 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 360/1194 | Loss: 304.604 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 370/1194 | Loss: 303.845 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 380/1194 | Loss: 297.539 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 390/1194 | Loss: 294.201 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 400/1194 | Loss: 292.851 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 410/1194 | Loss: 292.114 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 420/1194 | Loss: 288.798 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 430/1194 | Loss: 295.766 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 440/1194 | Loss: 302.353 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 450/1194 | Loss: 305.317 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 460/1194 | Loss: 309.664 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 470/1194 | Loss: 297.972 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 480/1194 | Loss: 305.516 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 490/1194 | Loss: 307.668 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 500/1194 | Loss: 296.998 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 510/1194 | Loss: 281.758 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 520/1194 | Loss: 299.068 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 530/1194 | Loss: 281.218 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 540/1194 | Loss: 315.726 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 550/1194 | Loss: 296.367 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 560/1194 | Loss: 299.269 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 570/1194 | Loss: 300.970 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 580/1194 | Loss: 304.316 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 590/1194 | Loss: 289.535 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 600/1194 | Loss: 293.756 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 610/1194 | Loss: 293.637 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 620/1194 | Loss: 271.779 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 630/1194 | Loss: 286.094 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 640/1194 | Loss: 301.083 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 650/1194 | Loss: 297.571 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 660/1194 | Loss: 296.418 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 670/1194 | Loss: 292.786 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 680/1194 | Loss: 289.496 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 690/1194 | Loss: 280.367 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 700/1194 | Loss: 298.664 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 710/1194 | Loss: 297.330 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 720/1194 | Loss: 294.176 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 730/1194 | Loss: 287.846 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 740/1194 | Loss: 302.633 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 750/1194 | Loss: 293.833 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 760/1194 | Loss: 289.381 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 770/1194 | Loss: 303.071 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 780/1194 | Loss: 301.408 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 790/1194 | Loss: 297.575 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 800/1194 | Loss: 286.424 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 810/1194 | Loss: 272.536 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 820/1194 | Loss: 291.985 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 830/1194 | Loss: 287.854 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 840/1194 | Loss: 306.134 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 850/1194 | Loss: 293.983 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 860/1194 | Loss: 321.504 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 870/1194 | Loss: 290.569 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 880/1194 | Loss: 299.906 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 890/1194 | Loss: 291.614 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 900/1194 | Loss: 308.445 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 910/1194 | Loss: 307.813 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 920/1194 | Loss: 289.925 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 930/1194 | Loss: 309.424 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 940/1194 | Loss: 297.949 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 950/1194 | Loss: 285.948 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 960/1194 | Loss: 302.635 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 970/1194 | Loss: 300.465 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 980/1194 | Loss: 301.776 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 990/1194 | Loss: 300.079 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1000/1194 | Loss: 278.405 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1010/1194 | Loss: 310.641 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1020/1194 | Loss: 300.358 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1030/1194 | Loss: 308.577 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1040/1194 | Loss: 298.905 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 1050/1194 | Loss: 289.572 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1060/1194 | Loss: 285.805 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1070/1194 | Loss: 305.146 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 1080/1194 | Loss: 311.616 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1090/1194 | Loss: 293.937 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 1100/1194 | Loss: 281.854 | Accuracy: 0.300\n",
      "[Epoch: 90/200] - Step: 1110/1194 | Loss: 288.430 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1120/1194 | Loss: 304.850 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 1130/1194 | Loss: 293.513 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1140/1194 | Loss: 306.322 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1150/1194 | Loss: 313.334 | Accuracy: 0.000\n",
      "[Epoch: 90/200] - Step: 1160/1194 | Loss: 286.098 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1170/1194 | Loss: 284.060 | Accuracy: 0.200\n",
      "[Epoch: 90/200] - Step: 1180/1194 | Loss: 290.881 | Accuracy: 0.100\n",
      "[Epoch: 90/200] - Step: 1190/1194 | Loss: 281.858 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 91/200] - Step: 10/1194 | Loss: 295.741 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 20/1194 | Loss: 308.326 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 30/1194 | Loss: 297.248 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 40/1194 | Loss: 285.956 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 50/1194 | Loss: 296.330 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 60/1194 | Loss: 301.460 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 70/1194 | Loss: 320.924 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 80/1194 | Loss: 291.875 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 90/1194 | Loss: 283.272 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 100/1194 | Loss: 288.823 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 110/1194 | Loss: 307.916 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 120/1194 | Loss: 303.837 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 130/1194 | Loss: 288.053 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 140/1194 | Loss: 310.477 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 150/1194 | Loss: 294.641 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 160/1194 | Loss: 307.412 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 170/1194 | Loss: 308.010 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 180/1194 | Loss: 299.809 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 190/1194 | Loss: 289.239 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 200/1194 | Loss: 294.787 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 210/1194 | Loss: 289.898 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 220/1194 | Loss: 301.116 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 230/1194 | Loss: 283.879 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 240/1194 | Loss: 286.473 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 250/1194 | Loss: 289.409 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 260/1194 | Loss: 285.674 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 270/1194 | Loss: 302.547 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 280/1194 | Loss: 282.537 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 290/1194 | Loss: 309.736 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 300/1194 | Loss: 295.411 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 310/1194 | Loss: 289.948 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 320/1194 | Loss: 297.479 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 330/1194 | Loss: 292.708 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 340/1194 | Loss: 276.869 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 350/1194 | Loss: 302.788 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 360/1194 | Loss: 315.825 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 370/1194 | Loss: 296.827 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 380/1194 | Loss: 292.159 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 390/1194 | Loss: 296.218 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 400/1194 | Loss: 302.167 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 410/1194 | Loss: 285.339 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 420/1194 | Loss: 309.348 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 430/1194 | Loss: 287.380 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 440/1194 | Loss: 300.188 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 450/1194 | Loss: 275.382 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 460/1194 | Loss: 301.118 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 470/1194 | Loss: 316.213 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 480/1194 | Loss: 289.515 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 490/1194 | Loss: 303.571 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 500/1194 | Loss: 311.962 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 510/1194 | Loss: 296.190 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 520/1194 | Loss: 290.661 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 530/1194 | Loss: 290.299 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 540/1194 | Loss: 297.523 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 550/1194 | Loss: 299.892 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 560/1194 | Loss: 273.529 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 570/1194 | Loss: 325.156 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 580/1194 | Loss: 296.807 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 590/1194 | Loss: 294.338 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 600/1194 | Loss: 291.089 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 610/1194 | Loss: 294.972 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 620/1194 | Loss: 295.221 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 630/1194 | Loss: 260.719 | Accuracy: 0.400\n",
      "[Epoch: 91/200] - Step: 640/1194 | Loss: 286.806 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 650/1194 | Loss: 273.570 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 660/1194 | Loss: 326.956 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 670/1194 | Loss: 298.388 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 680/1194 | Loss: 293.680 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 690/1194 | Loss: 295.428 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 700/1194 | Loss: 314.793 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 710/1194 | Loss: 297.687 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 720/1194 | Loss: 307.817 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 730/1194 | Loss: 265.476 | Accuracy: 0.400\n",
      "[Epoch: 91/200] - Step: 740/1194 | Loss: 299.788 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 750/1194 | Loss: 302.982 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 760/1194 | Loss: 297.675 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 770/1194 | Loss: 306.753 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 780/1194 | Loss: 291.821 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 790/1194 | Loss: 283.380 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 800/1194 | Loss: 301.169 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 810/1194 | Loss: 299.935 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 820/1194 | Loss: 286.458 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 830/1194 | Loss: 322.829 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 840/1194 | Loss: 284.312 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 850/1194 | Loss: 288.284 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 860/1194 | Loss: 284.486 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 870/1194 | Loss: 307.658 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 880/1194 | Loss: 303.365 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 890/1194 | Loss: 287.972 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 900/1194 | Loss: 288.199 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 910/1194 | Loss: 286.339 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 920/1194 | Loss: 300.398 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 930/1194 | Loss: 303.669 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 940/1194 | Loss: 294.090 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 950/1194 | Loss: 293.483 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 960/1194 | Loss: 312.424 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 970/1194 | Loss: 301.056 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 980/1194 | Loss: 296.233 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 990/1194 | Loss: 325.461 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1000/1194 | Loss: 280.851 | Accuracy: 0.300\n",
      "[Epoch: 91/200] - Step: 1010/1194 | Loss: 305.615 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1020/1194 | Loss: 296.933 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1030/1194 | Loss: 271.678 | Accuracy: 0.400\n",
      "[Epoch: 91/200] - Step: 1040/1194 | Loss: 292.011 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 1050/1194 | Loss: 301.411 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1060/1194 | Loss: 278.580 | Accuracy: 0.200\n",
      "[Epoch: 91/200] - Step: 1070/1194 | Loss: 317.886 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1080/1194 | Loss: 307.799 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1090/1194 | Loss: 299.530 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1100/1194 | Loss: 306.881 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1110/1194 | Loss: 307.009 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1120/1194 | Loss: 315.613 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1130/1194 | Loss: 308.456 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1140/1194 | Loss: 296.665 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1150/1194 | Loss: 298.305 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1160/1194 | Loss: 293.912 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1170/1194 | Loss: 308.855 | Accuracy: 0.000\n",
      "[Epoch: 91/200] - Step: 1180/1194 | Loss: 294.451 | Accuracy: 0.100\n",
      "[Epoch: 91/200] - Step: 1190/1194 | Loss: 295.218 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 92/200] - Step: 10/1194 | Loss: 300.494 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 20/1194 | Loss: 307.463 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 30/1194 | Loss: 295.690 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 40/1194 | Loss: 284.619 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 50/1194 | Loss: 282.563 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 60/1194 | Loss: 291.916 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 70/1194 | Loss: 276.221 | Accuracy: 0.400\n",
      "[Epoch: 92/200] - Step: 80/1194 | Loss: 288.211 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 90/1194 | Loss: 291.112 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 100/1194 | Loss: 293.580 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 110/1194 | Loss: 282.649 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 120/1194 | Loss: 285.371 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 130/1194 | Loss: 285.762 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 140/1194 | Loss: 297.088 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 150/1194 | Loss: 313.761 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 160/1194 | Loss: 285.530 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 170/1194 | Loss: 282.399 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 180/1194 | Loss: 306.402 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 190/1194 | Loss: 302.327 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 200/1194 | Loss: 295.182 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 210/1194 | Loss: 301.898 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 220/1194 | Loss: 283.973 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 230/1194 | Loss: 308.984 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 240/1194 | Loss: 297.012 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 250/1194 | Loss: 291.254 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 260/1194 | Loss: 295.433 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 270/1194 | Loss: 290.070 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 280/1194 | Loss: 307.585 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 290/1194 | Loss: 294.545 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 300/1194 | Loss: 288.775 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 310/1194 | Loss: 302.438 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 320/1194 | Loss: 306.579 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 330/1194 | Loss: 298.825 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 340/1194 | Loss: 284.312 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 350/1194 | Loss: 292.112 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 360/1194 | Loss: 279.688 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 370/1194 | Loss: 296.390 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 380/1194 | Loss: 300.282 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 390/1194 | Loss: 306.204 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 400/1194 | Loss: 295.727 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 410/1194 | Loss: 298.709 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 420/1194 | Loss: 301.512 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 430/1194 | Loss: 310.079 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 440/1194 | Loss: 307.116 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 450/1194 | Loss: 297.550 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 460/1194 | Loss: 310.237 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 470/1194 | Loss: 290.951 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 480/1194 | Loss: 283.247 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 490/1194 | Loss: 291.536 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 500/1194 | Loss: 309.006 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 510/1194 | Loss: 291.519 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 520/1194 | Loss: 306.862 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 530/1194 | Loss: 282.784 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 540/1194 | Loss: 289.878 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 550/1194 | Loss: 277.177 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 560/1194 | Loss: 306.646 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 570/1194 | Loss: 300.888 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 580/1194 | Loss: 312.309 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 590/1194 | Loss: 287.297 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 600/1194 | Loss: 298.587 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 610/1194 | Loss: 306.899 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 620/1194 | Loss: 291.129 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 630/1194 | Loss: 306.440 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 640/1194 | Loss: 301.267 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 650/1194 | Loss: 277.378 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 660/1194 | Loss: 307.016 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 670/1194 | Loss: 303.750 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 680/1194 | Loss: 296.655 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 690/1194 | Loss: 305.897 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 700/1194 | Loss: 277.221 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 710/1194 | Loss: 289.205 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 720/1194 | Loss: 286.443 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 730/1194 | Loss: 287.225 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 740/1194 | Loss: 297.284 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 750/1194 | Loss: 298.479 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 760/1194 | Loss: 284.425 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 770/1194 | Loss: 295.319 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 780/1194 | Loss: 280.043 | Accuracy: 0.300\n",
      "[Epoch: 92/200] - Step: 790/1194 | Loss: 313.974 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 800/1194 | Loss: 297.559 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 810/1194 | Loss: 295.409 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 820/1194 | Loss: 297.130 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 830/1194 | Loss: 281.804 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 840/1194 | Loss: 280.290 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 850/1194 | Loss: 302.813 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 860/1194 | Loss: 301.802 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 870/1194 | Loss: 300.156 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 880/1194 | Loss: 302.150 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 890/1194 | Loss: 310.104 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 900/1194 | Loss: 290.057 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 910/1194 | Loss: 280.315 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 920/1194 | Loss: 301.296 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 930/1194 | Loss: 305.950 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 940/1194 | Loss: 298.735 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 950/1194 | Loss: 309.354 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 960/1194 | Loss: 313.150 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 970/1194 | Loss: 341.004 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 980/1194 | Loss: 296.152 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 990/1194 | Loss: 300.229 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1000/1194 | Loss: 306.481 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1010/1194 | Loss: 316.269 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1020/1194 | Loss: 286.019 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1030/1194 | Loss: 302.027 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1040/1194 | Loss: 286.298 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1050/1194 | Loss: 316.867 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1060/1194 | Loss: 292.619 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1070/1194 | Loss: 324.351 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1080/1194 | Loss: 332.171 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1090/1194 | Loss: 298.131 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1100/1194 | Loss: 287.308 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1110/1194 | Loss: 289.404 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1120/1194 | Loss: 303.319 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1130/1194 | Loss: 302.517 | Accuracy: 0.000\n",
      "[Epoch: 92/200] - Step: 1140/1194 | Loss: 292.212 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1150/1194 | Loss: 303.572 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1160/1194 | Loss: 292.595 | Accuracy: 0.200\n",
      "[Epoch: 92/200] - Step: 1170/1194 | Loss: 287.269 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1180/1194 | Loss: 302.009 | Accuracy: 0.100\n",
      "[Epoch: 92/200] - Step: 1190/1194 | Loss: 297.954 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 93/200] - Step: 10/1194 | Loss: 291.025 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 20/1194 | Loss: 300.277 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 30/1194 | Loss: 305.061 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 40/1194 | Loss: 316.199 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 50/1194 | Loss: 305.874 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 60/1194 | Loss: 288.659 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 70/1194 | Loss: 299.901 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 80/1194 | Loss: 274.877 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 90/1194 | Loss: 293.423 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 100/1194 | Loss: 297.327 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 110/1194 | Loss: 295.622 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 120/1194 | Loss: 296.604 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 130/1194 | Loss: 295.878 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 140/1194 | Loss: 308.084 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 150/1194 | Loss: 310.466 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 160/1194 | Loss: 289.529 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 170/1194 | Loss: 288.254 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 180/1194 | Loss: 296.190 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 190/1194 | Loss: 308.540 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 200/1194 | Loss: 284.573 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 210/1194 | Loss: 300.905 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 220/1194 | Loss: 289.837 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 230/1194 | Loss: 290.448 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 240/1194 | Loss: 299.337 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 250/1194 | Loss: 282.262 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 260/1194 | Loss: 293.997 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 270/1194 | Loss: 290.450 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 280/1194 | Loss: 289.694 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 290/1194 | Loss: 294.290 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 300/1194 | Loss: 297.963 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 310/1194 | Loss: 324.064 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 320/1194 | Loss: 279.074 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 330/1194 | Loss: 294.757 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 340/1194 | Loss: 290.923 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 350/1194 | Loss: 278.562 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 360/1194 | Loss: 291.901 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 370/1194 | Loss: 307.284 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 380/1194 | Loss: 289.759 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 390/1194 | Loss: 307.737 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 400/1194 | Loss: 302.465 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 410/1194 | Loss: 291.863 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 420/1194 | Loss: 308.678 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 430/1194 | Loss: 290.910 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 440/1194 | Loss: 290.039 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 450/1194 | Loss: 320.116 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 460/1194 | Loss: 309.288 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 470/1194 | Loss: 293.285 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 480/1194 | Loss: 294.258 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 490/1194 | Loss: 306.924 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 500/1194 | Loss: 288.154 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 510/1194 | Loss: 308.244 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 520/1194 | Loss: 297.083 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 530/1194 | Loss: 321.204 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 540/1194 | Loss: 285.971 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 550/1194 | Loss: 284.651 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 560/1194 | Loss: 288.564 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 570/1194 | Loss: 282.832 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 580/1194 | Loss: 299.282 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 590/1194 | Loss: 311.306 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 600/1194 | Loss: 304.930 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 610/1194 | Loss: 299.261 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 620/1194 | Loss: 299.813 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 630/1194 | Loss: 298.666 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 640/1194 | Loss: 258.165 | Accuracy: 0.500\n",
      "[Epoch: 93/200] - Step: 650/1194 | Loss: 298.747 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 660/1194 | Loss: 333.275 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 670/1194 | Loss: 302.803 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 680/1194 | Loss: 297.211 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 690/1194 | Loss: 297.847 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 700/1194 | Loss: 288.513 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 710/1194 | Loss: 305.881 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 720/1194 | Loss: 291.746 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 730/1194 | Loss: 277.826 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 740/1194 | Loss: 307.427 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 750/1194 | Loss: 298.891 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 760/1194 | Loss: 276.127 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 770/1194 | Loss: 289.237 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 780/1194 | Loss: 312.059 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 790/1194 | Loss: 288.156 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 800/1194 | Loss: 297.484 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 810/1194 | Loss: 281.787 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 820/1194 | Loss: 297.495 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 830/1194 | Loss: 272.454 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 840/1194 | Loss: 316.547 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 850/1194 | Loss: 307.220 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 860/1194 | Loss: 306.691 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 870/1194 | Loss: 305.469 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 880/1194 | Loss: 295.018 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 890/1194 | Loss: 286.695 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 900/1194 | Loss: 294.688 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 910/1194 | Loss: 311.098 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 920/1194 | Loss: 290.854 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 930/1194 | Loss: 308.123 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 940/1194 | Loss: 305.859 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 950/1194 | Loss: 274.796 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 960/1194 | Loss: 300.674 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 970/1194 | Loss: 300.106 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 980/1194 | Loss: 291.633 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 990/1194 | Loss: 297.043 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 1000/1194 | Loss: 282.798 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 1010/1194 | Loss: 318.807 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1020/1194 | Loss: 298.304 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1030/1194 | Loss: 278.962 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 1040/1194 | Loss: 276.302 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 1050/1194 | Loss: 294.212 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 1060/1194 | Loss: 291.991 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 1070/1194 | Loss: 287.774 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 1080/1194 | Loss: 300.618 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 1090/1194 | Loss: 313.841 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1100/1194 | Loss: 309.609 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1110/1194 | Loss: 300.985 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1120/1194 | Loss: 304.115 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 1130/1194 | Loss: 327.093 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1140/1194 | Loss: 285.326 | Accuracy: 0.300\n",
      "[Epoch: 93/200] - Step: 1150/1194 | Loss: 297.725 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1160/1194 | Loss: 292.076 | Accuracy: 0.200\n",
      "[Epoch: 93/200] - Step: 1170/1194 | Loss: 289.327 | Accuracy: 0.100\n",
      "[Epoch: 93/200] - Step: 1180/1194 | Loss: 316.529 | Accuracy: 0.000\n",
      "[Epoch: 93/200] - Step: 1190/1194 | Loss: 305.556 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 94/200] - Step: 10/1194 | Loss: 293.039 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 20/1194 | Loss: 311.628 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 30/1194 | Loss: 291.377 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 40/1194 | Loss: 294.314 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 50/1194 | Loss: 300.402 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 60/1194 | Loss: 295.214 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 70/1194 | Loss: 295.819 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 80/1194 | Loss: 310.118 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 90/1194 | Loss: 297.860 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 100/1194 | Loss: 293.507 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 110/1194 | Loss: 302.057 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 120/1194 | Loss: 291.247 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 130/1194 | Loss: 295.396 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 140/1194 | Loss: 296.023 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 150/1194 | Loss: 293.502 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 160/1194 | Loss: 298.747 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 170/1194 | Loss: 325.064 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 180/1194 | Loss: 292.336 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 190/1194 | Loss: 305.216 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 200/1194 | Loss: 295.133 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 210/1194 | Loss: 301.344 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 220/1194 | Loss: 293.807 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 230/1194 | Loss: 287.579 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 240/1194 | Loss: 302.286 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 250/1194 | Loss: 276.497 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 260/1194 | Loss: 292.184 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 270/1194 | Loss: 299.920 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 280/1194 | Loss: 286.175 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 290/1194 | Loss: 303.196 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 300/1194 | Loss: 308.965 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 310/1194 | Loss: 306.761 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 320/1194 | Loss: 306.980 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 330/1194 | Loss: 288.986 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 340/1194 | Loss: 286.475 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 350/1194 | Loss: 298.458 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 360/1194 | Loss: 293.652 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 370/1194 | Loss: 275.996 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 380/1194 | Loss: 296.014 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 390/1194 | Loss: 310.515 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 400/1194 | Loss: 300.473 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 410/1194 | Loss: 293.172 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 420/1194 | Loss: 278.082 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 430/1194 | Loss: 295.206 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 440/1194 | Loss: 281.214 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 450/1194 | Loss: 300.757 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 460/1194 | Loss: 335.211 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 470/1194 | Loss: 274.510 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 480/1194 | Loss: 299.323 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 490/1194 | Loss: 317.511 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 500/1194 | Loss: 283.123 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 510/1194 | Loss: 309.019 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 520/1194 | Loss: 289.755 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 530/1194 | Loss: 295.583 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 540/1194 | Loss: 291.597 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 550/1194 | Loss: 322.533 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 560/1194 | Loss: 290.770 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 570/1194 | Loss: 299.732 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 580/1194 | Loss: 298.612 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 590/1194 | Loss: 296.839 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 600/1194 | Loss: 290.260 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 610/1194 | Loss: 284.699 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 620/1194 | Loss: 275.985 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 630/1194 | Loss: 286.796 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 640/1194 | Loss: 281.614 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 650/1194 | Loss: 286.132 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 660/1194 | Loss: 300.340 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 670/1194 | Loss: 289.082 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 680/1194 | Loss: 293.062 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 690/1194 | Loss: 301.066 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 700/1194 | Loss: 319.758 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 710/1194 | Loss: 301.337 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 720/1194 | Loss: 299.789 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 730/1194 | Loss: 298.513 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 740/1194 | Loss: 301.389 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 750/1194 | Loss: 294.064 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 760/1194 | Loss: 284.308 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 770/1194 | Loss: 274.725 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 780/1194 | Loss: 320.488 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 790/1194 | Loss: 294.502 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 800/1194 | Loss: 292.845 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 810/1194 | Loss: 321.182 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 820/1194 | Loss: 308.266 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 830/1194 | Loss: 293.560 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 840/1194 | Loss: 289.769 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 850/1194 | Loss: 301.147 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 860/1194 | Loss: 292.806 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 870/1194 | Loss: 302.401 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 880/1194 | Loss: 304.535 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 890/1194 | Loss: 287.454 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 900/1194 | Loss: 286.992 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 910/1194 | Loss: 288.756 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 920/1194 | Loss: 302.731 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 930/1194 | Loss: 274.747 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 940/1194 | Loss: 298.133 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 950/1194 | Loss: 289.828 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 960/1194 | Loss: 318.849 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 970/1194 | Loss: 294.465 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 980/1194 | Loss: 292.014 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 990/1194 | Loss: 315.520 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1000/1194 | Loss: 300.109 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1010/1194 | Loss: 293.282 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1020/1194 | Loss: 284.192 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1030/1194 | Loss: 312.395 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1040/1194 | Loss: 300.123 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1050/1194 | Loss: 312.448 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1060/1194 | Loss: 304.826 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1070/1194 | Loss: 309.752 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1080/1194 | Loss: 296.342 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1090/1194 | Loss: 280.046 | Accuracy: 0.300\n",
      "[Epoch: 94/200] - Step: 1100/1194 | Loss: 288.350 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1110/1194 | Loss: 293.006 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1120/1194 | Loss: 293.038 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1130/1194 | Loss: 295.462 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1140/1194 | Loss: 310.718 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1150/1194 | Loss: 297.753 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1160/1194 | Loss: 304.914 | Accuracy: 0.000\n",
      "[Epoch: 94/200] - Step: 1170/1194 | Loss: 296.053 | Accuracy: 0.100\n",
      "[Epoch: 94/200] - Step: 1180/1194 | Loss: 289.772 | Accuracy: 0.200\n",
      "[Epoch: 94/200] - Step: 1190/1194 | Loss: 300.580 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 95/200] - Step: 10/1194 | Loss: 301.453 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 20/1194 | Loss: 285.716 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 30/1194 | Loss: 295.036 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 40/1194 | Loss: 281.152 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 50/1194 | Loss: 289.349 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 60/1194 | Loss: 305.426 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 70/1194 | Loss: 299.938 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 80/1194 | Loss: 294.881 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 90/1194 | Loss: 278.141 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 100/1194 | Loss: 314.547 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 110/1194 | Loss: 285.583 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 120/1194 | Loss: 276.873 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 130/1194 | Loss: 271.668 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 140/1194 | Loss: 260.527 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 150/1194 | Loss: 315.985 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 160/1194 | Loss: 304.072 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 170/1194 | Loss: 276.778 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 180/1194 | Loss: 307.132 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 190/1194 | Loss: 317.357 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 200/1194 | Loss: 284.180 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 210/1194 | Loss: 275.031 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 220/1194 | Loss: 285.238 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 230/1194 | Loss: 315.232 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 240/1194 | Loss: 308.053 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 250/1194 | Loss: 303.125 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 260/1194 | Loss: 307.257 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 270/1194 | Loss: 280.868 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 280/1194 | Loss: 303.220 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 290/1194 | Loss: 296.407 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 300/1194 | Loss: 291.756 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 310/1194 | Loss: 293.775 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 320/1194 | Loss: 308.747 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 330/1194 | Loss: 291.215 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 340/1194 | Loss: 305.878 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 350/1194 | Loss: 295.775 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 360/1194 | Loss: 293.100 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 370/1194 | Loss: 299.968 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 380/1194 | Loss: 307.670 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 390/1194 | Loss: 302.976 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 400/1194 | Loss: 313.652 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 410/1194 | Loss: 295.344 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 420/1194 | Loss: 304.884 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 430/1194 | Loss: 302.796 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 440/1194 | Loss: 285.682 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 450/1194 | Loss: 307.038 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 460/1194 | Loss: 295.837 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 470/1194 | Loss: 307.876 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 480/1194 | Loss: 293.396 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 490/1194 | Loss: 304.750 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 500/1194 | Loss: 294.465 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 510/1194 | Loss: 293.415 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 520/1194 | Loss: 304.676 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 530/1194 | Loss: 285.035 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 540/1194 | Loss: 284.606 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 550/1194 | Loss: 291.659 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 560/1194 | Loss: 299.190 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 570/1194 | Loss: 291.262 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 580/1194 | Loss: 294.550 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 590/1194 | Loss: 279.988 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 600/1194 | Loss: 302.277 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 610/1194 | Loss: 293.469 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 620/1194 | Loss: 337.464 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 630/1194 | Loss: 293.205 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 640/1194 | Loss: 304.358 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 650/1194 | Loss: 301.281 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 660/1194 | Loss: 291.216 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 670/1194 | Loss: 307.129 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 680/1194 | Loss: 308.562 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 690/1194 | Loss: 295.912 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 700/1194 | Loss: 295.476 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 710/1194 | Loss: 296.395 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 720/1194 | Loss: 294.042 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 730/1194 | Loss: 288.315 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 740/1194 | Loss: 300.102 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 750/1194 | Loss: 277.951 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 760/1194 | Loss: 303.591 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 770/1194 | Loss: 312.188 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 780/1194 | Loss: 286.446 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 790/1194 | Loss: 307.972 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 800/1194 | Loss: 292.621 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 810/1194 | Loss: 295.655 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 820/1194 | Loss: 295.604 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 830/1194 | Loss: 308.991 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 840/1194 | Loss: 277.051 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 850/1194 | Loss: 286.776 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 860/1194 | Loss: 309.359 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 870/1194 | Loss: 362.509 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 880/1194 | Loss: 294.774 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 890/1194 | Loss: 280.354 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 900/1194 | Loss: 297.429 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 910/1194 | Loss: 291.965 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 920/1194 | Loss: 306.983 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 930/1194 | Loss: 302.298 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 940/1194 | Loss: 286.426 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 950/1194 | Loss: 304.014 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 960/1194 | Loss: 290.574 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 970/1194 | Loss: 288.454 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 980/1194 | Loss: 312.872 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 990/1194 | Loss: 298.353 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1000/1194 | Loss: 304.441 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 1010/1194 | Loss: 314.499 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1020/1194 | Loss: 283.738 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1030/1194 | Loss: 301.948 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1040/1194 | Loss: 301.518 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 1050/1194 | Loss: 294.961 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1060/1194 | Loss: 305.874 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1070/1194 | Loss: 308.640 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1080/1194 | Loss: 292.034 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1090/1194 | Loss: 304.684 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1100/1194 | Loss: 288.922 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1110/1194 | Loss: 311.283 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1120/1194 | Loss: 282.024 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1130/1194 | Loss: 292.425 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1140/1194 | Loss: 296.720 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 1150/1194 | Loss: 291.406 | Accuracy: 0.100\n",
      "[Epoch: 95/200] - Step: 1160/1194 | Loss: 285.737 | Accuracy: 0.200\n",
      "[Epoch: 95/200] - Step: 1170/1194 | Loss: 272.939 | Accuracy: 0.300\n",
      "[Epoch: 95/200] - Step: 1180/1194 | Loss: 291.009 | Accuracy: 0.000\n",
      "[Epoch: 95/200] - Step: 1190/1194 | Loss: 290.071 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 96/200] - Step: 10/1194 | Loss: 289.862 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 20/1194 | Loss: 299.488 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 30/1194 | Loss: 301.707 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 40/1194 | Loss: 295.761 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 50/1194 | Loss: 285.531 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 60/1194 | Loss: 289.777 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 70/1194 | Loss: 290.932 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 80/1194 | Loss: 282.273 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 90/1194 | Loss: 297.736 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 100/1194 | Loss: 304.213 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 110/1194 | Loss: 276.256 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 120/1194 | Loss: 295.864 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 130/1194 | Loss: 298.620 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 140/1194 | Loss: 299.426 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 150/1194 | Loss: 278.194 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 160/1194 | Loss: 294.364 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 170/1194 | Loss: 290.037 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 180/1194 | Loss: 307.802 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 190/1194 | Loss: 294.344 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 200/1194 | Loss: 285.024 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 210/1194 | Loss: 287.461 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 220/1194 | Loss: 294.740 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 230/1194 | Loss: 297.078 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 240/1194 | Loss: 277.188 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 250/1194 | Loss: 272.361 | Accuracy: 0.300\n",
      "[Epoch: 96/200] - Step: 260/1194 | Loss: 300.587 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 270/1194 | Loss: 282.514 | Accuracy: 0.300\n",
      "[Epoch: 96/200] - Step: 280/1194 | Loss: 269.122 | Accuracy: 0.300\n",
      "[Epoch: 96/200] - Step: 290/1194 | Loss: 292.243 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 300/1194 | Loss: 297.695 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 310/1194 | Loss: 299.810 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 320/1194 | Loss: 305.016 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 330/1194 | Loss: 284.622 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 340/1194 | Loss: 304.193 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 350/1194 | Loss: 282.752 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 360/1194 | Loss: 329.511 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 370/1194 | Loss: 302.541 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 380/1194 | Loss: 284.785 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 390/1194 | Loss: 286.465 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 400/1194 | Loss: 306.563 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 410/1194 | Loss: 297.326 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 420/1194 | Loss: 286.618 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 430/1194 | Loss: 282.994 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 440/1194 | Loss: 306.290 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 450/1194 | Loss: 288.411 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 460/1194 | Loss: 308.055 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 470/1194 | Loss: 291.334 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 480/1194 | Loss: 327.557 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 490/1194 | Loss: 307.783 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 500/1194 | Loss: 291.526 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 510/1194 | Loss: 299.655 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 520/1194 | Loss: 287.965 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 530/1194 | Loss: 291.488 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 540/1194 | Loss: 285.551 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 550/1194 | Loss: 309.938 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 560/1194 | Loss: 300.057 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 570/1194 | Loss: 312.263 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 580/1194 | Loss: 306.966 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 590/1194 | Loss: 327.267 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 600/1194 | Loss: 295.589 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 610/1194 | Loss: 295.577 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 620/1194 | Loss: 301.645 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 630/1194 | Loss: 290.224 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 640/1194 | Loss: 296.635 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 650/1194 | Loss: 308.081 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 660/1194 | Loss: 291.691 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 670/1194 | Loss: 312.282 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 680/1194 | Loss: 308.858 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 690/1194 | Loss: 282.075 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 700/1194 | Loss: 307.930 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 710/1194 | Loss: 302.876 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 720/1194 | Loss: 298.700 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 730/1194 | Loss: 305.147 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 740/1194 | Loss: 301.486 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 750/1194 | Loss: 283.504 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 760/1194 | Loss: 307.597 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 770/1194 | Loss: 302.923 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 780/1194 | Loss: 283.679 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 790/1194 | Loss: 301.839 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 800/1194 | Loss: 307.739 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 810/1194 | Loss: 285.102 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 820/1194 | Loss: 297.899 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 830/1194 | Loss: 302.092 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 840/1194 | Loss: 288.589 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 850/1194 | Loss: 304.491 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 860/1194 | Loss: 299.027 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 870/1194 | Loss: 285.982 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 880/1194 | Loss: 317.321 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 890/1194 | Loss: 298.270 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 900/1194 | Loss: 310.371 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 910/1194 | Loss: 290.082 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 920/1194 | Loss: 296.124 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 930/1194 | Loss: 320.575 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 940/1194 | Loss: 304.793 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 950/1194 | Loss: 290.016 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 960/1194 | Loss: 286.318 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 970/1194 | Loss: 303.675 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 980/1194 | Loss: 302.921 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 990/1194 | Loss: 298.580 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1000/1194 | Loss: 289.885 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 1010/1194 | Loss: 293.757 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1020/1194 | Loss: 305.910 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 1030/1194 | Loss: 288.867 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 1040/1194 | Loss: 294.216 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1050/1194 | Loss: 294.564 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1060/1194 | Loss: 301.447 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1070/1194 | Loss: 298.712 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1080/1194 | Loss: 302.171 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1090/1194 | Loss: 297.644 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1100/1194 | Loss: 308.253 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 1110/1194 | Loss: 290.070 | Accuracy: 0.200\n",
      "[Epoch: 96/200] - Step: 1120/1194 | Loss: 297.358 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1130/1194 | Loss: 282.982 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1140/1194 | Loss: 303.483 | Accuracy: 0.100\n",
      "[Epoch: 96/200] - Step: 1150/1194 | Loss: 312.982 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 1160/1194 | Loss: 302.888 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 1170/1194 | Loss: 304.648 | Accuracy: 0.000\n",
      "[Epoch: 96/200] - Step: 1180/1194 | Loss: 277.780 | Accuracy: 0.400\n",
      "[Epoch: 96/200] - Step: 1190/1194 | Loss: 283.367 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 97/200] - Step: 10/1194 | Loss: 263.453 | Accuracy: 0.400\n",
      "[Epoch: 97/200] - Step: 20/1194 | Loss: 318.697 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 30/1194 | Loss: 302.942 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 40/1194 | Loss: 292.370 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 50/1194 | Loss: 298.337 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 60/1194 | Loss: 289.903 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 70/1194 | Loss: 300.447 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 80/1194 | Loss: 292.541 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 90/1194 | Loss: 291.755 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 100/1194 | Loss: 307.527 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 110/1194 | Loss: 307.202 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 120/1194 | Loss: 286.838 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 130/1194 | Loss: 283.774 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 140/1194 | Loss: 290.230 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 150/1194 | Loss: 297.038 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 160/1194 | Loss: 275.102 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 170/1194 | Loss: 280.641 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 180/1194 | Loss: 307.747 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 190/1194 | Loss: 313.398 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 200/1194 | Loss: 280.180 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 210/1194 | Loss: 294.019 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 220/1194 | Loss: 288.530 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 230/1194 | Loss: 296.859 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 240/1194 | Loss: 293.273 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 250/1194 | Loss: 302.442 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 260/1194 | Loss: 283.436 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 270/1194 | Loss: 285.668 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 280/1194 | Loss: 275.710 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 290/1194 | Loss: 305.616 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 300/1194 | Loss: 300.532 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 310/1194 | Loss: 278.692 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 320/1194 | Loss: 296.203 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 330/1194 | Loss: 316.204 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 340/1194 | Loss: 314.288 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 350/1194 | Loss: 290.539 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 360/1194 | Loss: 307.389 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 370/1194 | Loss: 299.256 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 380/1194 | Loss: 296.615 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 390/1194 | Loss: 321.231 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 400/1194 | Loss: 299.382 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 410/1194 | Loss: 305.510 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 420/1194 | Loss: 275.123 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 430/1194 | Loss: 286.776 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 440/1194 | Loss: 286.922 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 450/1194 | Loss: 304.510 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 460/1194 | Loss: 300.979 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 470/1194 | Loss: 309.883 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 480/1194 | Loss: 300.305 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 490/1194 | Loss: 297.210 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 500/1194 | Loss: 289.642 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 510/1194 | Loss: 307.777 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 520/1194 | Loss: 298.312 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 530/1194 | Loss: 305.953 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 540/1194 | Loss: 300.166 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 550/1194 | Loss: 300.714 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 560/1194 | Loss: 299.952 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 570/1194 | Loss: 298.238 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 580/1194 | Loss: 294.616 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 590/1194 | Loss: 301.433 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 600/1194 | Loss: 296.867 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 610/1194 | Loss: 279.864 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 620/1194 | Loss: 294.568 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 630/1194 | Loss: 301.514 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 640/1194 | Loss: 319.423 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 650/1194 | Loss: 290.703 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 660/1194 | Loss: 294.436 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 670/1194 | Loss: 290.683 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 680/1194 | Loss: 320.379 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 690/1194 | Loss: 295.630 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 700/1194 | Loss: 297.709 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 710/1194 | Loss: 286.947 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 720/1194 | Loss: 298.617 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 730/1194 | Loss: 290.303 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 740/1194 | Loss: 281.171 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 750/1194 | Loss: 305.896 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 760/1194 | Loss: 295.960 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 770/1194 | Loss: 276.147 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 780/1194 | Loss: 272.542 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 790/1194 | Loss: 282.564 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 800/1194 | Loss: 306.222 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 810/1194 | Loss: 309.222 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 820/1194 | Loss: 311.559 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 830/1194 | Loss: 295.768 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 840/1194 | Loss: 314.358 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 850/1194 | Loss: 336.624 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 860/1194 | Loss: 294.016 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 870/1194 | Loss: 313.339 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 880/1194 | Loss: 315.035 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 890/1194 | Loss: 306.481 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 900/1194 | Loss: 309.175 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 910/1194 | Loss: 296.730 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 920/1194 | Loss: 301.744 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 930/1194 | Loss: 289.999 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 940/1194 | Loss: 293.453 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 950/1194 | Loss: 300.808 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 960/1194 | Loss: 307.263 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 970/1194 | Loss: 286.695 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 980/1194 | Loss: 293.170 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 990/1194 | Loss: 304.331 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 1000/1194 | Loss: 283.959 | Accuracy: 0.300\n",
      "[Epoch: 97/200] - Step: 1010/1194 | Loss: 297.573 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1020/1194 | Loss: 287.368 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1030/1194 | Loss: 309.617 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 1040/1194 | Loss: 297.751 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1050/1194 | Loss: 303.930 | Accuracy: 0.000\n",
      "[Epoch: 97/200] - Step: 1060/1194 | Loss: 285.219 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 1070/1194 | Loss: 289.429 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1080/1194 | Loss: 295.751 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1090/1194 | Loss: 306.096 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1100/1194 | Loss: 303.990 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1110/1194 | Loss: 283.830 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1120/1194 | Loss: 298.249 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1130/1194 | Loss: 287.219 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1140/1194 | Loss: 297.789 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 1150/1194 | Loss: 285.017 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 1160/1194 | Loss: 305.071 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1170/1194 | Loss: 306.488 | Accuracy: 0.100\n",
      "[Epoch: 97/200] - Step: 1180/1194 | Loss: 289.200 | Accuracy: 0.200\n",
      "[Epoch: 97/200] - Step: 1190/1194 | Loss: 292.406 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 98/200] - Step: 10/1194 | Loss: 285.151 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 20/1194 | Loss: 303.048 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 30/1194 | Loss: 298.012 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 40/1194 | Loss: 307.085 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 50/1194 | Loss: 288.139 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 60/1194 | Loss: 290.121 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 70/1194 | Loss: 327.453 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 80/1194 | Loss: 283.459 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 90/1194 | Loss: 294.314 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 100/1194 | Loss: 297.688 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 110/1194 | Loss: 297.153 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 120/1194 | Loss: 295.022 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 130/1194 | Loss: 292.263 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 140/1194 | Loss: 299.061 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 150/1194 | Loss: 293.874 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 160/1194 | Loss: 291.946 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 170/1194 | Loss: 300.488 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 180/1194 | Loss: 300.201 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 190/1194 | Loss: 283.878 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 200/1194 | Loss: 306.775 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 210/1194 | Loss: 303.752 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 220/1194 | Loss: 272.401 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 230/1194 | Loss: 302.150 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 240/1194 | Loss: 292.542 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 250/1194 | Loss: 301.986 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 260/1194 | Loss: 305.484 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 270/1194 | Loss: 298.850 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 280/1194 | Loss: 270.212 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 290/1194 | Loss: 275.404 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 300/1194 | Loss: 295.129 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 310/1194 | Loss: 287.814 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 320/1194 | Loss: 305.297 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 330/1194 | Loss: 297.308 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 340/1194 | Loss: 305.210 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 350/1194 | Loss: 326.575 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 360/1194 | Loss: 322.994 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 370/1194 | Loss: 299.224 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 380/1194 | Loss: 291.700 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 390/1194 | Loss: 285.559 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 400/1194 | Loss: 295.865 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 410/1194 | Loss: 282.528 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 420/1194 | Loss: 278.051 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 430/1194 | Loss: 309.589 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 440/1194 | Loss: 268.289 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 450/1194 | Loss: 282.843 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 460/1194 | Loss: 281.361 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 470/1194 | Loss: 308.290 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 480/1194 | Loss: 305.994 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 490/1194 | Loss: 273.363 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 500/1194 | Loss: 295.182 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 510/1194 | Loss: 309.326 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 520/1194 | Loss: 293.222 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 530/1194 | Loss: 302.655 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 540/1194 | Loss: 309.406 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 550/1194 | Loss: 290.753 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 560/1194 | Loss: 275.782 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 570/1194 | Loss: 296.884 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 580/1194 | Loss: 270.953 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 590/1194 | Loss: 311.124 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 600/1194 | Loss: 296.004 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 610/1194 | Loss: 306.743 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 620/1194 | Loss: 305.279 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 630/1194 | Loss: 302.302 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 640/1194 | Loss: 294.635 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 650/1194 | Loss: 279.594 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 660/1194 | Loss: 291.832 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 670/1194 | Loss: 311.464 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 680/1194 | Loss: 286.524 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 690/1194 | Loss: 292.624 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 700/1194 | Loss: 319.746 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 710/1194 | Loss: 311.600 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 720/1194 | Loss: 299.482 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 730/1194 | Loss: 311.495 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 740/1194 | Loss: 313.159 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 750/1194 | Loss: 272.551 | Accuracy: 0.400\n",
      "[Epoch: 98/200] - Step: 760/1194 | Loss: 309.571 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 770/1194 | Loss: 295.114 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 780/1194 | Loss: 301.303 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 790/1194 | Loss: 321.399 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 800/1194 | Loss: 298.525 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 810/1194 | Loss: 300.614 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 820/1194 | Loss: 299.449 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 830/1194 | Loss: 290.068 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 840/1194 | Loss: 294.863 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 850/1194 | Loss: 286.341 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 860/1194 | Loss: 323.004 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 870/1194 | Loss: 302.700 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 880/1194 | Loss: 306.855 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 890/1194 | Loss: 303.447 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 900/1194 | Loss: 299.873 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 910/1194 | Loss: 304.894 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 920/1194 | Loss: 302.548 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 930/1194 | Loss: 286.781 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 940/1194 | Loss: 303.315 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 950/1194 | Loss: 301.668 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 960/1194 | Loss: 288.372 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 970/1194 | Loss: 287.982 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 980/1194 | Loss: 316.545 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 990/1194 | Loss: 310.787 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1000/1194 | Loss: 305.503 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1010/1194 | Loss: 305.575 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1020/1194 | Loss: 304.463 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1030/1194 | Loss: 275.004 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 1040/1194 | Loss: 288.397 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 1050/1194 | Loss: 300.816 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1060/1194 | Loss: 304.678 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1070/1194 | Loss: 299.851 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1080/1194 | Loss: 293.851 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1090/1194 | Loss: 296.971 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1100/1194 | Loss: 287.810 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1110/1194 | Loss: 277.371 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 1120/1194 | Loss: 300.048 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 1130/1194 | Loss: 282.936 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1140/1194 | Loss: 298.050 | Accuracy: 0.100\n",
      "[Epoch: 98/200] - Step: 1150/1194 | Loss: 286.410 | Accuracy: 0.200\n",
      "[Epoch: 98/200] - Step: 1160/1194 | Loss: 285.906 | Accuracy: 0.300\n",
      "[Epoch: 98/200] - Step: 1170/1194 | Loss: 315.836 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1180/1194 | Loss: 302.764 | Accuracy: 0.000\n",
      "[Epoch: 98/200] - Step: 1190/1194 | Loss: 290.097 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 99/200] - Step: 10/1194 | Loss: 313.499 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 20/1194 | Loss: 291.625 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 30/1194 | Loss: 290.738 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 40/1194 | Loss: 305.119 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 50/1194 | Loss: 291.147 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 60/1194 | Loss: 312.338 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 70/1194 | Loss: 307.570 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 80/1194 | Loss: 292.274 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 90/1194 | Loss: 300.436 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 100/1194 | Loss: 285.362 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 110/1194 | Loss: 275.639 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 120/1194 | Loss: 294.552 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 130/1194 | Loss: 270.083 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 140/1194 | Loss: 295.210 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 150/1194 | Loss: 291.897 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 160/1194 | Loss: 286.907 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 170/1194 | Loss: 289.527 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 180/1194 | Loss: 328.473 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 190/1194 | Loss: 281.486 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 200/1194 | Loss: 301.872 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 210/1194 | Loss: 296.509 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 220/1194 | Loss: 315.122 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 230/1194 | Loss: 278.666 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 240/1194 | Loss: 298.990 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 250/1194 | Loss: 333.685 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 260/1194 | Loss: 298.306 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 270/1194 | Loss: 288.310 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 280/1194 | Loss: 298.093 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 290/1194 | Loss: 286.439 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 300/1194 | Loss: 287.621 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 310/1194 | Loss: 286.357 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 320/1194 | Loss: 306.093 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 330/1194 | Loss: 276.927 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 340/1194 | Loss: 306.680 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 350/1194 | Loss: 292.868 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 360/1194 | Loss: 291.760 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 370/1194 | Loss: 278.418 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 380/1194 | Loss: 285.877 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 390/1194 | Loss: 298.506 | Accuracy: 0.400\n",
      "[Epoch: 99/200] - Step: 400/1194 | Loss: 302.064 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 410/1194 | Loss: 301.750 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 420/1194 | Loss: 293.250 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 430/1194 | Loss: 293.236 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 440/1194 | Loss: 284.905 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 450/1194 | Loss: 282.188 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 460/1194 | Loss: 313.060 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 470/1194 | Loss: 287.820 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 480/1194 | Loss: 295.049 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 490/1194 | Loss: 270.246 | Accuracy: 0.400\n",
      "[Epoch: 99/200] - Step: 500/1194 | Loss: 308.855 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 510/1194 | Loss: 306.359 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 520/1194 | Loss: 289.291 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 530/1194 | Loss: 292.325 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 540/1194 | Loss: 278.658 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 550/1194 | Loss: 310.881 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 560/1194 | Loss: 308.590 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 570/1194 | Loss: 302.030 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 580/1194 | Loss: 287.114 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 590/1194 | Loss: 294.195 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 600/1194 | Loss: 291.252 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 610/1194 | Loss: 292.141 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 620/1194 | Loss: 323.654 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 630/1194 | Loss: 293.706 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 640/1194 | Loss: 283.789 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 650/1194 | Loss: 311.339 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 660/1194 | Loss: 288.951 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 670/1194 | Loss: 282.551 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 680/1194 | Loss: 275.134 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 690/1194 | Loss: 309.629 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 700/1194 | Loss: 284.348 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 710/1194 | Loss: 289.142 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 720/1194 | Loss: 298.133 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 730/1194 | Loss: 310.081 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 740/1194 | Loss: 277.209 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 750/1194 | Loss: 318.301 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 760/1194 | Loss: 305.719 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 770/1194 | Loss: 299.845 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 780/1194 | Loss: 299.247 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 790/1194 | Loss: 301.911 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 800/1194 | Loss: 288.524 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 810/1194 | Loss: 280.746 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 820/1194 | Loss: 294.355 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 830/1194 | Loss: 294.333 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 840/1194 | Loss: 314.311 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 850/1194 | Loss: 294.613 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 860/1194 | Loss: 311.972 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 870/1194 | Loss: 314.275 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 880/1194 | Loss: 282.709 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 890/1194 | Loss: 312.802 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 900/1194 | Loss: 308.812 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 910/1194 | Loss: 281.476 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 920/1194 | Loss: 306.997 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 930/1194 | Loss: 310.812 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 940/1194 | Loss: 293.217 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 950/1194 | Loss: 302.640 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 960/1194 | Loss: 299.842 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 970/1194 | Loss: 307.591 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 980/1194 | Loss: 300.242 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 990/1194 | Loss: 307.467 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1000/1194 | Loss: 288.273 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 1010/1194 | Loss: 293.253 | Accuracy: 0.200\n",
      "[Epoch: 99/200] - Step: 1020/1194 | Loss: 302.787 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1030/1194 | Loss: 297.517 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1040/1194 | Loss: 306.011 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1050/1194 | Loss: 299.190 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1060/1194 | Loss: 294.945 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1070/1194 | Loss: 302.764 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1080/1194 | Loss: 299.869 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1090/1194 | Loss: 299.489 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1100/1194 | Loss: 303.469 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1110/1194 | Loss: 298.310 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1120/1194 | Loss: 300.833 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1130/1194 | Loss: 314.890 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1140/1194 | Loss: 277.456 | Accuracy: 0.300\n",
      "[Epoch: 99/200] - Step: 1150/1194 | Loss: 300.609 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1160/1194 | Loss: 303.522 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1170/1194 | Loss: 301.348 | Accuracy: 0.100\n",
      "[Epoch: 99/200] - Step: 1180/1194 | Loss: 296.993 | Accuracy: 0.000\n",
      "[Epoch: 99/200] - Step: 1190/1194 | Loss: 299.429 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 100/200] - Step: 10/1194 | Loss: 289.583 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 20/1194 | Loss: 290.468 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 30/1194 | Loss: 295.708 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 40/1194 | Loss: 302.157 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 50/1194 | Loss: 310.199 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 60/1194 | Loss: 286.936 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 70/1194 | Loss: 291.160 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 80/1194 | Loss: 297.785 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 90/1194 | Loss: 274.531 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 100/1194 | Loss: 284.699 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 110/1194 | Loss: 305.443 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 120/1194 | Loss: 299.170 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 130/1194 | Loss: 302.987 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 140/1194 | Loss: 295.218 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 150/1194 | Loss: 297.688 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 160/1194 | Loss: 292.084 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 170/1194 | Loss: 298.427 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 180/1194 | Loss: 309.932 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 190/1194 | Loss: 302.965 | Accuracy: 0.400\n",
      "[Epoch: 100/200] - Step: 200/1194 | Loss: 282.350 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 210/1194 | Loss: 298.630 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 220/1194 | Loss: 294.798 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 230/1194 | Loss: 303.847 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 240/1194 | Loss: 299.166 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 250/1194 | Loss: 330.406 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 260/1194 | Loss: 286.314 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 270/1194 | Loss: 307.834 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 280/1194 | Loss: 283.379 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 290/1194 | Loss: 293.006 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 300/1194 | Loss: 276.907 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 310/1194 | Loss: 293.858 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 320/1194 | Loss: 296.313 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 330/1194 | Loss: 295.788 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 340/1194 | Loss: 285.325 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 350/1194 | Loss: 307.140 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 360/1194 | Loss: 286.183 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 370/1194 | Loss: 304.130 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 380/1194 | Loss: 300.770 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 390/1194 | Loss: 333.999 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 400/1194 | Loss: 303.213 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 410/1194 | Loss: 289.376 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 420/1194 | Loss: 301.621 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 430/1194 | Loss: 315.473 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 440/1194 | Loss: 306.181 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 450/1194 | Loss: 304.807 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 460/1194 | Loss: 314.157 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 470/1194 | Loss: 303.641 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 480/1194 | Loss: 291.966 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 490/1194 | Loss: 291.198 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 500/1194 | Loss: 305.031 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 510/1194 | Loss: 289.968 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 520/1194 | Loss: 295.482 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 530/1194 | Loss: 283.299 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 540/1194 | Loss: 295.180 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 550/1194 | Loss: 303.053 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 560/1194 | Loss: 307.993 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 570/1194 | Loss: 288.454 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 580/1194 | Loss: 303.659 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 590/1194 | Loss: 293.146 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 600/1194 | Loss: 286.039 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 610/1194 | Loss: 297.442 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 620/1194 | Loss: 298.630 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 630/1194 | Loss: 278.637 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 640/1194 | Loss: 306.894 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 650/1194 | Loss: 302.739 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 660/1194 | Loss: 286.902 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 670/1194 | Loss: 274.336 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 680/1194 | Loss: 300.973 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 690/1194 | Loss: 294.760 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 700/1194 | Loss: 292.994 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 710/1194 | Loss: 279.140 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 720/1194 | Loss: 295.951 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 730/1194 | Loss: 308.373 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 740/1194 | Loss: 287.270 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 750/1194 | Loss: 296.198 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 760/1194 | Loss: 284.751 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 770/1194 | Loss: 311.018 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 780/1194 | Loss: 340.846 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 790/1194 | Loss: 301.118 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 800/1194 | Loss: 297.600 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 810/1194 | Loss: 297.806 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 820/1194 | Loss: 320.884 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 830/1194 | Loss: 298.886 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 840/1194 | Loss: 280.909 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 850/1194 | Loss: 304.187 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 860/1194 | Loss: 304.419 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 870/1194 | Loss: 295.694 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 880/1194 | Loss: 278.578 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 890/1194 | Loss: 300.661 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 900/1194 | Loss: 296.613 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 910/1194 | Loss: 298.406 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 920/1194 | Loss: 270.442 | Accuracy: 0.300\n",
      "[Epoch: 100/200] - Step: 930/1194 | Loss: 313.245 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 940/1194 | Loss: 287.635 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 950/1194 | Loss: 288.716 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 960/1194 | Loss: 281.500 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 970/1194 | Loss: 279.104 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 980/1194 | Loss: 304.202 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 990/1194 | Loss: 305.768 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1000/1194 | Loss: 302.107 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1010/1194 | Loss: 296.430 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 1020/1194 | Loss: 296.148 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1030/1194 | Loss: 289.890 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1040/1194 | Loss: 294.323 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1050/1194 | Loss: 290.212 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1060/1194 | Loss: 296.869 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1070/1194 | Loss: 307.097 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 1080/1194 | Loss: 290.145 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1090/1194 | Loss: 303.925 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 1100/1194 | Loss: 294.161 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1110/1194 | Loss: 294.045 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1120/1194 | Loss: 284.126 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1130/1194 | Loss: 305.631 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1140/1194 | Loss: 320.346 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1150/1194 | Loss: 287.272 | Accuracy: 0.200\n",
      "[Epoch: 100/200] - Step: 1160/1194 | Loss: 295.406 | Accuracy: 0.100\n",
      "[Epoch: 100/200] - Step: 1170/1194 | Loss: 304.108 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 1180/1194 | Loss: 306.609 | Accuracy: 0.000\n",
      "[Epoch: 100/200] - Step: 1190/1194 | Loss: 288.312 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 101/200] - Step: 10/1194 | Loss: 287.547 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 20/1194 | Loss: 293.260 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 30/1194 | Loss: 300.882 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 40/1194 | Loss: 285.881 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 50/1194 | Loss: 286.127 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 60/1194 | Loss: 309.670 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 70/1194 | Loss: 302.285 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 80/1194 | Loss: 312.459 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 90/1194 | Loss: 293.247 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 100/1194 | Loss: 292.388 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 110/1194 | Loss: 290.438 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 120/1194 | Loss: 279.693 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 130/1194 | Loss: 310.882 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 140/1194 | Loss: 295.770 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 150/1194 | Loss: 286.272 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 160/1194 | Loss: 270.789 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 170/1194 | Loss: 301.463 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 180/1194 | Loss: 300.372 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 190/1194 | Loss: 292.275 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 200/1194 | Loss: 309.898 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 210/1194 | Loss: 287.939 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 220/1194 | Loss: 286.034 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 230/1194 | Loss: 287.484 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 240/1194 | Loss: 305.872 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 250/1194 | Loss: 302.263 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 260/1194 | Loss: 290.693 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 270/1194 | Loss: 312.442 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 280/1194 | Loss: 316.877 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 290/1194 | Loss: 302.560 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 300/1194 | Loss: 281.165 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 310/1194 | Loss: 313.667 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 320/1194 | Loss: 336.957 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 330/1194 | Loss: 297.469 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 340/1194 | Loss: 309.467 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 350/1194 | Loss: 289.345 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 360/1194 | Loss: 309.095 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 370/1194 | Loss: 295.703 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 380/1194 | Loss: 312.585 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 390/1194 | Loss: 298.458 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 400/1194 | Loss: 292.467 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 410/1194 | Loss: 288.615 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 420/1194 | Loss: 283.409 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 430/1194 | Loss: 290.563 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 440/1194 | Loss: 299.818 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 450/1194 | Loss: 279.401 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 460/1194 | Loss: 302.934 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 470/1194 | Loss: 300.455 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 480/1194 | Loss: 299.641 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 490/1194 | Loss: 327.573 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 500/1194 | Loss: 275.085 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 510/1194 | Loss: 293.267 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 520/1194 | Loss: 285.078 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 530/1194 | Loss: 279.465 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 540/1194 | Loss: 302.488 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 550/1194 | Loss: 298.153 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 560/1194 | Loss: 296.422 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 570/1194 | Loss: 298.382 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 580/1194 | Loss: 291.876 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 590/1194 | Loss: 292.438 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 600/1194 | Loss: 299.562 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 610/1194 | Loss: 303.316 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 620/1194 | Loss: 308.369 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 630/1194 | Loss: 282.920 | Accuracy: 0.400\n",
      "[Epoch: 101/200] - Step: 640/1194 | Loss: 294.699 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 650/1194 | Loss: 300.265 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 660/1194 | Loss: 304.146 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 670/1194 | Loss: 303.179 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 680/1194 | Loss: 286.784 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 690/1194 | Loss: 362.720 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 700/1194 | Loss: 293.921 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 710/1194 | Loss: 310.339 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 720/1194 | Loss: 294.541 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 730/1194 | Loss: 294.657 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 740/1194 | Loss: 295.206 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 750/1194 | Loss: 295.860 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 760/1194 | Loss: 310.221 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 770/1194 | Loss: 306.967 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 780/1194 | Loss: 286.122 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 790/1194 | Loss: 279.168 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 800/1194 | Loss: 285.048 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 810/1194 | Loss: 280.833 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 820/1194 | Loss: 305.217 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 830/1194 | Loss: 295.483 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 840/1194 | Loss: 285.327 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 850/1194 | Loss: 315.645 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 860/1194 | Loss: 284.658 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 870/1194 | Loss: 286.207 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 880/1194 | Loss: 293.434 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 890/1194 | Loss: 269.639 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 900/1194 | Loss: 309.879 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 910/1194 | Loss: 290.082 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 920/1194 | Loss: 305.114 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 930/1194 | Loss: 299.152 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 940/1194 | Loss: 311.114 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 950/1194 | Loss: 301.036 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 960/1194 | Loss: 313.596 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 970/1194 | Loss: 297.456 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 980/1194 | Loss: 273.319 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 990/1194 | Loss: 321.818 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 1000/1194 | Loss: 309.934 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 1010/1194 | Loss: 298.340 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1020/1194 | Loss: 297.486 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1030/1194 | Loss: 282.406 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 1040/1194 | Loss: 296.508 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 1050/1194 | Loss: 297.154 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1060/1194 | Loss: 288.542 | Accuracy: 0.300\n",
      "[Epoch: 101/200] - Step: 1070/1194 | Loss: 300.753 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1080/1194 | Loss: 286.650 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 1090/1194 | Loss: 286.019 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1100/1194 | Loss: 288.856 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 1110/1194 | Loss: 312.797 | Accuracy: 0.000\n",
      "[Epoch: 101/200] - Step: 1120/1194 | Loss: 287.891 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 1130/1194 | Loss: 270.948 | Accuracy: 0.400\n",
      "[Epoch: 101/200] - Step: 1140/1194 | Loss: 302.882 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1150/1194 | Loss: 296.940 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1160/1194 | Loss: 281.591 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1170/1194 | Loss: 336.207 | Accuracy: 0.100\n",
      "[Epoch: 101/200] - Step: 1180/1194 | Loss: 285.945 | Accuracy: 0.200\n",
      "[Epoch: 101/200] - Step: 1190/1194 | Loss: 286.149 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 102/200] - Step: 10/1194 | Loss: 283.474 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 20/1194 | Loss: 297.804 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 30/1194 | Loss: 301.708 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 40/1194 | Loss: 304.559 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 50/1194 | Loss: 285.251 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 60/1194 | Loss: 285.612 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 70/1194 | Loss: 297.702 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 80/1194 | Loss: 271.925 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 90/1194 | Loss: 330.636 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 100/1194 | Loss: 290.887 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 110/1194 | Loss: 288.993 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 120/1194 | Loss: 281.532 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 130/1194 | Loss: 288.571 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 140/1194 | Loss: 293.904 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 150/1194 | Loss: 303.845 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 160/1194 | Loss: 304.389 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 170/1194 | Loss: 290.996 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 180/1194 | Loss: 309.421 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 190/1194 | Loss: 305.696 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 200/1194 | Loss: 308.630 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 210/1194 | Loss: 294.295 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 220/1194 | Loss: 304.869 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 230/1194 | Loss: 285.780 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 240/1194 | Loss: 309.405 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 250/1194 | Loss: 308.530 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 260/1194 | Loss: 303.334 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 270/1194 | Loss: 294.059 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 280/1194 | Loss: 283.394 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 290/1194 | Loss: 285.733 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 300/1194 | Loss: 295.363 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 310/1194 | Loss: 315.540 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 320/1194 | Loss: 295.048 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 330/1194 | Loss: 289.124 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 340/1194 | Loss: 285.924 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 350/1194 | Loss: 298.866 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 360/1194 | Loss: 304.921 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 370/1194 | Loss: 296.943 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 380/1194 | Loss: 305.136 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 390/1194 | Loss: 289.267 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 400/1194 | Loss: 278.514 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 410/1194 | Loss: 283.416 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 420/1194 | Loss: 297.462 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 430/1194 | Loss: 306.532 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 440/1194 | Loss: 273.055 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 450/1194 | Loss: 283.733 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 460/1194 | Loss: 287.943 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 470/1194 | Loss: 301.518 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 480/1194 | Loss: 307.924 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 490/1194 | Loss: 296.646 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 500/1194 | Loss: 295.775 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 510/1194 | Loss: 282.321 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 520/1194 | Loss: 290.877 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 530/1194 | Loss: 305.259 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 540/1194 | Loss: 296.983 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 550/1194 | Loss: 301.565 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 560/1194 | Loss: 305.708 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 570/1194 | Loss: 304.042 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 580/1194 | Loss: 287.679 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 590/1194 | Loss: 299.288 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 600/1194 | Loss: 297.381 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 610/1194 | Loss: 296.244 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 620/1194 | Loss: 288.155 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 630/1194 | Loss: 283.044 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 640/1194 | Loss: 302.175 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 650/1194 | Loss: 294.491 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 660/1194 | Loss: 321.502 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 670/1194 | Loss: 302.136 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 680/1194 | Loss: 305.858 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 690/1194 | Loss: 334.812 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 700/1194 | Loss: 314.034 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 710/1194 | Loss: 313.284 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 720/1194 | Loss: 302.303 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 730/1194 | Loss: 290.072 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 740/1194 | Loss: 271.739 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 750/1194 | Loss: 298.007 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 760/1194 | Loss: 318.995 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 770/1194 | Loss: 311.643 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 780/1194 | Loss: 293.497 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 790/1194 | Loss: 306.115 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 800/1194 | Loss: 307.906 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 810/1194 | Loss: 316.687 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 820/1194 | Loss: 273.681 | Accuracy: 0.400\n",
      "[Epoch: 102/200] - Step: 830/1194 | Loss: 285.123 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 840/1194 | Loss: 299.479 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 850/1194 | Loss: 296.463 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 860/1194 | Loss: 332.565 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 870/1194 | Loss: 280.667 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 880/1194 | Loss: 327.052 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 890/1194 | Loss: 291.736 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 900/1194 | Loss: 297.555 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 910/1194 | Loss: 301.213 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 920/1194 | Loss: 300.631 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 930/1194 | Loss: 283.295 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 940/1194 | Loss: 270.656 | Accuracy: 0.400\n",
      "[Epoch: 102/200] - Step: 950/1194 | Loss: 302.760 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 960/1194 | Loss: 294.502 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 970/1194 | Loss: 305.766 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 980/1194 | Loss: 306.998 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 990/1194 | Loss: 290.620 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 1000/1194 | Loss: 300.983 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1010/1194 | Loss: 304.617 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1020/1194 | Loss: 301.817 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1030/1194 | Loss: 299.328 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1040/1194 | Loss: 296.031 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1050/1194 | Loss: 290.929 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 1060/1194 | Loss: 274.744 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 1070/1194 | Loss: 288.669 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 1080/1194 | Loss: 290.446 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1090/1194 | Loss: 295.874 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 1100/1194 | Loss: 288.528 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1110/1194 | Loss: 310.577 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1120/1194 | Loss: 293.125 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1130/1194 | Loss: 287.884 | Accuracy: 0.200\n",
      "[Epoch: 102/200] - Step: 1140/1194 | Loss: 301.168 | Accuracy: 0.000\n",
      "[Epoch: 102/200] - Step: 1150/1194 | Loss: 278.828 | Accuracy: 0.300\n",
      "[Epoch: 102/200] - Step: 1160/1194 | Loss: 295.580 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1170/1194 | Loss: 296.913 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1180/1194 | Loss: 291.877 | Accuracy: 0.100\n",
      "[Epoch: 102/200] - Step: 1190/1194 | Loss: 293.155 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 103/200] - Step: 10/1194 | Loss: 289.075 | Accuracy: 0.500\n",
      "[Epoch: 103/200] - Step: 20/1194 | Loss: 290.854 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 30/1194 | Loss: 288.673 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 40/1194 | Loss: 300.161 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 50/1194 | Loss: 308.461 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 60/1194 | Loss: 296.737 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 70/1194 | Loss: 293.471 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 80/1194 | Loss: 302.235 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 90/1194 | Loss: 307.169 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 100/1194 | Loss: 296.246 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 110/1194 | Loss: 284.913 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 120/1194 | Loss: 295.218 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 130/1194 | Loss: 281.428 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 140/1194 | Loss: 286.226 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 150/1194 | Loss: 306.328 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 160/1194 | Loss: 303.056 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 170/1194 | Loss: 305.442 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 180/1194 | Loss: 281.027 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 190/1194 | Loss: 320.986 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 200/1194 | Loss: 274.188 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 210/1194 | Loss: 299.256 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 220/1194 | Loss: 311.375 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 230/1194 | Loss: 296.295 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 240/1194 | Loss: 303.342 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 250/1194 | Loss: 284.281 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 260/1194 | Loss: 286.373 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 270/1194 | Loss: 309.728 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 280/1194 | Loss: 298.565 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 290/1194 | Loss: 300.066 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 300/1194 | Loss: 292.921 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 310/1194 | Loss: 320.664 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 320/1194 | Loss: 295.511 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 330/1194 | Loss: 300.740 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 340/1194 | Loss: 302.525 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 350/1194 | Loss: 300.115 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 360/1194 | Loss: 300.956 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 370/1194 | Loss: 302.209 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 380/1194 | Loss: 297.859 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 390/1194 | Loss: 286.277 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 400/1194 | Loss: 302.270 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 410/1194 | Loss: 305.009 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 420/1194 | Loss: 281.168 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 430/1194 | Loss: 292.876 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 440/1194 | Loss: 302.290 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 450/1194 | Loss: 309.028 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 460/1194 | Loss: 299.216 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 470/1194 | Loss: 288.129 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 480/1194 | Loss: 296.920 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 490/1194 | Loss: 293.210 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 500/1194 | Loss: 297.929 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 510/1194 | Loss: 292.606 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 520/1194 | Loss: 307.141 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 530/1194 | Loss: 295.622 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 540/1194 | Loss: 301.859 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 550/1194 | Loss: 303.067 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 560/1194 | Loss: 302.185 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 570/1194 | Loss: 300.237 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 580/1194 | Loss: 292.402 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 590/1194 | Loss: 288.443 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 600/1194 | Loss: 288.269 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 610/1194 | Loss: 302.705 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 620/1194 | Loss: 292.379 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 630/1194 | Loss: 305.711 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 640/1194 | Loss: 282.470 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 650/1194 | Loss: 343.058 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 660/1194 | Loss: 301.317 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 670/1194 | Loss: 281.677 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 680/1194 | Loss: 270.080 | Accuracy: 0.400\n",
      "[Epoch: 103/200] - Step: 690/1194 | Loss: 291.499 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 700/1194 | Loss: 292.615 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 710/1194 | Loss: 284.499 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 720/1194 | Loss: 312.605 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 730/1194 | Loss: 299.547 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 740/1194 | Loss: 290.724 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 750/1194 | Loss: 292.319 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 760/1194 | Loss: 310.667 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 770/1194 | Loss: 288.435 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 780/1194 | Loss: 290.967 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 790/1194 | Loss: 286.817 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 800/1194 | Loss: 293.078 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 810/1194 | Loss: 288.212 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 820/1194 | Loss: 279.020 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 830/1194 | Loss: 285.374 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 840/1194 | Loss: 298.496 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 850/1194 | Loss: 279.679 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 860/1194 | Loss: 296.737 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 870/1194 | Loss: 305.865 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 880/1194 | Loss: 295.513 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 890/1194 | Loss: 340.693 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 900/1194 | Loss: 326.622 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 910/1194 | Loss: 285.106 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 920/1194 | Loss: 314.405 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 930/1194 | Loss: 294.149 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 940/1194 | Loss: 285.174 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 950/1194 | Loss: 267.081 | Accuracy: 0.400\n",
      "[Epoch: 103/200] - Step: 960/1194 | Loss: 298.962 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 970/1194 | Loss: 303.126 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 980/1194 | Loss: 287.827 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 990/1194 | Loss: 256.046 | Accuracy: 0.500\n",
      "[Epoch: 103/200] - Step: 1000/1194 | Loss: 303.399 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1010/1194 | Loss: 280.338 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 1020/1194 | Loss: 292.774 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1030/1194 | Loss: 284.560 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1040/1194 | Loss: 286.954 | Accuracy: 0.300\n",
      "[Epoch: 103/200] - Step: 1050/1194 | Loss: 305.974 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1060/1194 | Loss: 339.336 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1070/1194 | Loss: 304.565 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1080/1194 | Loss: 297.221 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1090/1194 | Loss: 313.530 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1100/1194 | Loss: 291.100 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 1110/1194 | Loss: 294.586 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 1120/1194 | Loss: 298.212 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1130/1194 | Loss: 294.911 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1140/1194 | Loss: 314.077 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1150/1194 | Loss: 312.066 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1160/1194 | Loss: 301.525 | Accuracy: 0.000\n",
      "[Epoch: 103/200] - Step: 1170/1194 | Loss: 294.029 | Accuracy: 0.100\n",
      "[Epoch: 103/200] - Step: 1180/1194 | Loss: 291.750 | Accuracy: 0.200\n",
      "[Epoch: 103/200] - Step: 1190/1194 | Loss: 304.213 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 104/200] - Step: 10/1194 | Loss: 295.897 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 20/1194 | Loss: 326.804 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 30/1194 | Loss: 306.109 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 40/1194 | Loss: 326.998 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 50/1194 | Loss: 286.599 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 60/1194 | Loss: 290.380 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 70/1194 | Loss: 307.800 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 80/1194 | Loss: 296.135 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 90/1194 | Loss: 319.429 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 100/1194 | Loss: 291.464 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 110/1194 | Loss: 296.109 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 120/1194 | Loss: 290.832 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 130/1194 | Loss: 285.997 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 140/1194 | Loss: 285.610 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 150/1194 | Loss: 301.579 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 160/1194 | Loss: 288.542 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 170/1194 | Loss: 299.348 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 180/1194 | Loss: 291.064 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 190/1194 | Loss: 277.218 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 200/1194 | Loss: 305.391 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 210/1194 | Loss: 304.804 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 220/1194 | Loss: 291.295 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 230/1194 | Loss: 299.112 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 240/1194 | Loss: 292.241 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 250/1194 | Loss: 295.337 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 260/1194 | Loss: 284.695 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 270/1194 | Loss: 288.841 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 280/1194 | Loss: 304.000 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 290/1194 | Loss: 292.065 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 300/1194 | Loss: 310.891 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 310/1194 | Loss: 283.801 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 320/1194 | Loss: 311.466 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 330/1194 | Loss: 289.938 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 340/1194 | Loss: 288.213 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 350/1194 | Loss: 322.588 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 360/1194 | Loss: 309.049 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 370/1194 | Loss: 279.984 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 380/1194 | Loss: 279.013 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 390/1194 | Loss: 290.500 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 400/1194 | Loss: 298.537 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 410/1194 | Loss: 295.427 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 420/1194 | Loss: 292.175 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 430/1194 | Loss: 284.257 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 440/1194 | Loss: 299.954 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 450/1194 | Loss: 298.697 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 460/1194 | Loss: 285.958 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 470/1194 | Loss: 290.260 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 480/1194 | Loss: 292.205 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 490/1194 | Loss: 297.566 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 500/1194 | Loss: 292.870 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 510/1194 | Loss: 305.176 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 520/1194 | Loss: 287.037 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 530/1194 | Loss: 283.108 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 540/1194 | Loss: 279.159 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 550/1194 | Loss: 296.181 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 560/1194 | Loss: 298.971 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 570/1194 | Loss: 301.651 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 580/1194 | Loss: 273.327 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 590/1194 | Loss: 293.936 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 600/1194 | Loss: 300.299 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 610/1194 | Loss: 282.114 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 620/1194 | Loss: 287.982 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 630/1194 | Loss: 303.448 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 640/1194 | Loss: 307.554 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 650/1194 | Loss: 300.533 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 660/1194 | Loss: 299.224 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 670/1194 | Loss: 291.422 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 680/1194 | Loss: 310.766 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 690/1194 | Loss: 295.846 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 700/1194 | Loss: 311.364 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 710/1194 | Loss: 290.576 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 720/1194 | Loss: 289.408 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 730/1194 | Loss: 317.500 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 740/1194 | Loss: 298.277 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 750/1194 | Loss: 289.496 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 760/1194 | Loss: 296.843 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 770/1194 | Loss: 318.996 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 780/1194 | Loss: 282.103 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 790/1194 | Loss: 303.091 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 800/1194 | Loss: 315.428 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 810/1194 | Loss: 315.934 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 820/1194 | Loss: 290.841 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 830/1194 | Loss: 301.124 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 840/1194 | Loss: 279.205 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 850/1194 | Loss: 300.678 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 860/1194 | Loss: 307.514 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 870/1194 | Loss: 290.399 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 880/1194 | Loss: 308.159 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 890/1194 | Loss: 307.023 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 900/1194 | Loss: 285.829 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 910/1194 | Loss: 293.344 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 920/1194 | Loss: 303.644 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 930/1194 | Loss: 297.228 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 940/1194 | Loss: 311.378 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 950/1194 | Loss: 305.801 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 960/1194 | Loss: 284.780 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 970/1194 | Loss: 283.081 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 980/1194 | Loss: 287.203 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 990/1194 | Loss: 310.021 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 1000/1194 | Loss: 311.995 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 1010/1194 | Loss: 294.313 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1020/1194 | Loss: 296.820 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1030/1194 | Loss: 311.974 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 1040/1194 | Loss: 296.928 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 1050/1194 | Loss: 298.038 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1060/1194 | Loss: 297.587 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1070/1194 | Loss: 299.281 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1080/1194 | Loss: 285.696 | Accuracy: 0.300\n",
      "[Epoch: 104/200] - Step: 1090/1194 | Loss: 294.441 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1100/1194 | Loss: 284.616 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1110/1194 | Loss: 302.686 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 1120/1194 | Loss: 282.892 | Accuracy: 0.200\n",
      "[Epoch: 104/200] - Step: 1130/1194 | Loss: 328.633 | Accuracy: 0.000\n",
      "[Epoch: 104/200] - Step: 1140/1194 | Loss: 298.809 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1150/1194 | Loss: 294.876 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1160/1194 | Loss: 289.316 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1170/1194 | Loss: 293.769 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1180/1194 | Loss: 302.755 | Accuracy: 0.100\n",
      "[Epoch: 104/200] - Step: 1190/1194 | Loss: 298.269 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 105/200] - Step: 10/1194 | Loss: 271.727 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 20/1194 | Loss: 297.909 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 30/1194 | Loss: 278.377 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 40/1194 | Loss: 317.248 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 50/1194 | Loss: 319.206 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 60/1194 | Loss: 287.104 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 70/1194 | Loss: 329.175 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 80/1194 | Loss: 302.470 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 90/1194 | Loss: 296.734 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 100/1194 | Loss: 304.686 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 110/1194 | Loss: 293.208 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 120/1194 | Loss: 273.305 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 130/1194 | Loss: 274.084 | Accuracy: 0.400\n",
      "[Epoch: 105/200] - Step: 140/1194 | Loss: 293.818 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 150/1194 | Loss: 309.406 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 160/1194 | Loss: 292.784 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 170/1194 | Loss: 287.769 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 180/1194 | Loss: 282.495 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 190/1194 | Loss: 303.028 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 200/1194 | Loss: 295.935 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 210/1194 | Loss: 306.409 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 220/1194 | Loss: 300.586 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 230/1194 | Loss: 303.714 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 240/1194 | Loss: 303.154 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 250/1194 | Loss: 294.023 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 260/1194 | Loss: 298.451 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 270/1194 | Loss: 311.841 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 280/1194 | Loss: 303.209 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 290/1194 | Loss: 297.620 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 300/1194 | Loss: 307.070 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 310/1194 | Loss: 294.809 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 320/1194 | Loss: 305.356 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 330/1194 | Loss: 319.402 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 340/1194 | Loss: 302.623 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 350/1194 | Loss: 285.530 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 360/1194 | Loss: 310.819 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 370/1194 | Loss: 270.238 | Accuracy: 0.400\n",
      "[Epoch: 105/200] - Step: 380/1194 | Loss: 295.176 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 390/1194 | Loss: 292.112 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 400/1194 | Loss: 284.990 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 410/1194 | Loss: 296.739 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 420/1194 | Loss: 309.001 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 430/1194 | Loss: 291.609 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 440/1194 | Loss: 334.582 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 450/1194 | Loss: 291.274 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 460/1194 | Loss: 282.706 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 470/1194 | Loss: 279.723 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 480/1194 | Loss: 295.053 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 490/1194 | Loss: 286.874 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 500/1194 | Loss: 283.847 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 510/1194 | Loss: 305.946 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 520/1194 | Loss: 311.028 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 530/1194 | Loss: 302.136 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 540/1194 | Loss: 306.084 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 550/1194 | Loss: 298.911 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 560/1194 | Loss: 277.841 | Accuracy: 0.400\n",
      "[Epoch: 105/200] - Step: 570/1194 | Loss: 294.966 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 580/1194 | Loss: 315.116 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 590/1194 | Loss: 295.306 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 600/1194 | Loss: 292.812 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 610/1194 | Loss: 295.385 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 620/1194 | Loss: 302.960 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 630/1194 | Loss: 296.672 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 640/1194 | Loss: 301.639 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 650/1194 | Loss: 298.610 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 660/1194 | Loss: 299.367 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 670/1194 | Loss: 297.206 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 680/1194 | Loss: 299.482 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 690/1194 | Loss: 297.624 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 700/1194 | Loss: 325.324 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 710/1194 | Loss: 294.668 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 720/1194 | Loss: 290.629 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 730/1194 | Loss: 286.990 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 740/1194 | Loss: 285.894 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 750/1194 | Loss: 284.278 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 760/1194 | Loss: 302.916 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 770/1194 | Loss: 308.571 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 780/1194 | Loss: 276.091 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 790/1194 | Loss: 327.768 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 800/1194 | Loss: 286.835 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 810/1194 | Loss: 295.526 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 820/1194 | Loss: 319.712 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 830/1194 | Loss: 295.079 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 840/1194 | Loss: 292.458 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 850/1194 | Loss: 307.855 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 860/1194 | Loss: 300.103 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 870/1194 | Loss: 296.269 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 880/1194 | Loss: 289.803 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 890/1194 | Loss: 293.990 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 900/1194 | Loss: 287.523 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 910/1194 | Loss: 306.574 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 920/1194 | Loss: 294.680 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 930/1194 | Loss: 308.484 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 940/1194 | Loss: 297.148 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 950/1194 | Loss: 304.640 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 960/1194 | Loss: 302.740 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 970/1194 | Loss: 301.420 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 980/1194 | Loss: 286.477 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 990/1194 | Loss: 296.266 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1000/1194 | Loss: 280.816 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1010/1194 | Loss: 300.712 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1020/1194 | Loss: 301.791 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 1030/1194 | Loss: 309.649 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1040/1194 | Loss: 291.988 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1050/1194 | Loss: 300.144 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1060/1194 | Loss: 299.150 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1070/1194 | Loss: 284.981 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1080/1194 | Loss: 294.130 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1090/1194 | Loss: 285.259 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1100/1194 | Loss: 276.450 | Accuracy: 0.300\n",
      "[Epoch: 105/200] - Step: 1110/1194 | Loss: 294.013 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1120/1194 | Loss: 292.819 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1130/1194 | Loss: 293.804 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1140/1194 | Loss: 290.388 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1150/1194 | Loss: 304.499 | Accuracy: 0.100\n",
      "[Epoch: 105/200] - Step: 1160/1194 | Loss: 273.713 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1170/1194 | Loss: 304.886 | Accuracy: 0.000\n",
      "[Epoch: 105/200] - Step: 1180/1194 | Loss: 289.046 | Accuracy: 0.200\n",
      "[Epoch: 105/200] - Step: 1190/1194 | Loss: 303.055 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 106/200] - Step: 10/1194 | Loss: 302.597 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 20/1194 | Loss: 271.189 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 30/1194 | Loss: 304.796 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 40/1194 | Loss: 315.187 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 50/1194 | Loss: 346.406 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 60/1194 | Loss: 306.176 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 70/1194 | Loss: 286.799 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 80/1194 | Loss: 309.597 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 90/1194 | Loss: 292.165 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 100/1194 | Loss: 293.639 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 110/1194 | Loss: 274.119 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 120/1194 | Loss: 313.132 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 130/1194 | Loss: 292.447 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 140/1194 | Loss: 275.419 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 150/1194 | Loss: 284.667 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 160/1194 | Loss: 308.483 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 170/1194 | Loss: 299.535 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 180/1194 | Loss: 302.368 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 190/1194 | Loss: 290.958 | Accuracy: 0.400\n",
      "[Epoch: 106/200] - Step: 200/1194 | Loss: 297.606 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 210/1194 | Loss: 298.293 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 220/1194 | Loss: 305.172 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 230/1194 | Loss: 280.922 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 240/1194 | Loss: 283.929 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 250/1194 | Loss: 283.908 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 260/1194 | Loss: 279.065 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 270/1194 | Loss: 273.971 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 280/1194 | Loss: 280.030 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 290/1194 | Loss: 300.808 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 300/1194 | Loss: 305.746 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 310/1194 | Loss: 298.862 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 320/1194 | Loss: 299.066 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 330/1194 | Loss: 325.314 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 340/1194 | Loss: 320.849 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 350/1194 | Loss: 298.041 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 360/1194 | Loss: 293.237 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 370/1194 | Loss: 289.560 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 380/1194 | Loss: 295.680 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 390/1194 | Loss: 297.508 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 400/1194 | Loss: 292.639 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 410/1194 | Loss: 284.146 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 420/1194 | Loss: 299.140 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 430/1194 | Loss: 285.122 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 440/1194 | Loss: 302.529 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 450/1194 | Loss: 287.012 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 460/1194 | Loss: 273.814 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 470/1194 | Loss: 296.013 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 480/1194 | Loss: 298.107 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 490/1194 | Loss: 289.705 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 500/1194 | Loss: 282.023 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 510/1194 | Loss: 309.158 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 520/1194 | Loss: 303.628 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 530/1194 | Loss: 295.657 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 540/1194 | Loss: 306.699 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 550/1194 | Loss: 309.625 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 560/1194 | Loss: 309.566 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 570/1194 | Loss: 311.665 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 580/1194 | Loss: 293.583 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 590/1194 | Loss: 302.298 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 600/1194 | Loss: 301.771 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 610/1194 | Loss: 293.455 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 620/1194 | Loss: 290.665 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 630/1194 | Loss: 316.627 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 640/1194 | Loss: 297.754 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 650/1194 | Loss: 298.269 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 660/1194 | Loss: 306.126 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 670/1194 | Loss: 310.535 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 680/1194 | Loss: 291.335 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 690/1194 | Loss: 303.475 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 700/1194 | Loss: 284.624 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 710/1194 | Loss: 311.107 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 720/1194 | Loss: 276.822 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 730/1194 | Loss: 276.363 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 740/1194 | Loss: 303.747 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 750/1194 | Loss: 303.201 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 760/1194 | Loss: 309.299 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 770/1194 | Loss: 321.989 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 780/1194 | Loss: 310.273 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 790/1194 | Loss: 316.383 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 800/1194 | Loss: 295.112 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 810/1194 | Loss: 286.096 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 820/1194 | Loss: 284.370 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 830/1194 | Loss: 307.457 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 840/1194 | Loss: 286.554 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 850/1194 | Loss: 290.467 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 860/1194 | Loss: 292.866 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 870/1194 | Loss: 311.010 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 880/1194 | Loss: 299.737 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 890/1194 | Loss: 289.842 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 900/1194 | Loss: 280.713 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 910/1194 | Loss: 302.110 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 920/1194 | Loss: 301.000 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 930/1194 | Loss: 297.483 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 940/1194 | Loss: 285.140 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 950/1194 | Loss: 300.973 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 960/1194 | Loss: 302.689 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 970/1194 | Loss: 287.987 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 980/1194 | Loss: 301.749 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 990/1194 | Loss: 310.265 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1000/1194 | Loss: 299.232 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1010/1194 | Loss: 307.924 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1020/1194 | Loss: 297.986 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1030/1194 | Loss: 291.479 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 1040/1194 | Loss: 311.112 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1050/1194 | Loss: 309.250 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1060/1194 | Loss: 285.044 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 1070/1194 | Loss: 327.139 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1080/1194 | Loss: 283.529 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 1090/1194 | Loss: 292.191 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1100/1194 | Loss: 290.002 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 1110/1194 | Loss: 288.955 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 1120/1194 | Loss: 277.789 | Accuracy: 0.300\n",
      "[Epoch: 106/200] - Step: 1130/1194 | Loss: 305.893 | Accuracy: 0.000\n",
      "[Epoch: 106/200] - Step: 1140/1194 | Loss: 303.081 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1150/1194 | Loss: 299.296 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 1160/1194 | Loss: 292.719 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1170/1194 | Loss: 281.154 | Accuracy: 0.200\n",
      "[Epoch: 106/200] - Step: 1180/1194 | Loss: 294.741 | Accuracy: 0.100\n",
      "[Epoch: 106/200] - Step: 1190/1194 | Loss: 271.431 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 107/200] - Step: 10/1194 | Loss: 311.933 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 20/1194 | Loss: 293.740 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 30/1194 | Loss: 293.251 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 40/1194 | Loss: 293.137 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 50/1194 | Loss: 295.906 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 60/1194 | Loss: 288.838 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 70/1194 | Loss: 295.631 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 80/1194 | Loss: 303.779 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 90/1194 | Loss: 299.793 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 100/1194 | Loss: 271.499 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 110/1194 | Loss: 301.089 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 120/1194 | Loss: 293.137 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 130/1194 | Loss: 286.182 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 140/1194 | Loss: 299.411 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 150/1194 | Loss: 290.472 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 160/1194 | Loss: 291.401 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 170/1194 | Loss: 293.386 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 180/1194 | Loss: 288.675 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 190/1194 | Loss: 290.196 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 200/1194 | Loss: 305.305 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 210/1194 | Loss: 291.210 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 220/1194 | Loss: 292.385 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 230/1194 | Loss: 297.157 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 240/1194 | Loss: 310.196 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 250/1194 | Loss: 299.546 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 260/1194 | Loss: 312.426 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 270/1194 | Loss: 340.479 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 280/1194 | Loss: 288.139 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 290/1194 | Loss: 279.051 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 300/1194 | Loss: 296.887 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 310/1194 | Loss: 284.270 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 320/1194 | Loss: 305.569 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 330/1194 | Loss: 263.730 | Accuracy: 0.400\n",
      "[Epoch: 107/200] - Step: 340/1194 | Loss: 282.625 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 350/1194 | Loss: 281.532 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 360/1194 | Loss: 301.900 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 370/1194 | Loss: 270.940 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 380/1194 | Loss: 311.070 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 390/1194 | Loss: 310.346 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 400/1194 | Loss: 303.268 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 410/1194 | Loss: 307.048 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 420/1194 | Loss: 262.497 | Accuracy: 0.400\n",
      "[Epoch: 107/200] - Step: 430/1194 | Loss: 290.448 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 440/1194 | Loss: 310.025 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 450/1194 | Loss: 308.152 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 460/1194 | Loss: 340.607 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 470/1194 | Loss: 291.372 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 480/1194 | Loss: 311.098 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 490/1194 | Loss: 294.058 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 500/1194 | Loss: 301.303 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 510/1194 | Loss: 317.300 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 520/1194 | Loss: 287.516 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 530/1194 | Loss: 311.278 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 540/1194 | Loss: 295.715 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 550/1194 | Loss: 297.760 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 560/1194 | Loss: 298.663 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 570/1194 | Loss: 296.308 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 580/1194 | Loss: 293.750 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 590/1194 | Loss: 289.432 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 600/1194 | Loss: 298.133 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 610/1194 | Loss: 291.627 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 620/1194 | Loss: 295.427 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 630/1194 | Loss: 301.034 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 640/1194 | Loss: 309.860 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 650/1194 | Loss: 280.509 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 660/1194 | Loss: 281.945 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 670/1194 | Loss: 297.209 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 680/1194 | Loss: 283.953 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 690/1194 | Loss: 283.753 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 700/1194 | Loss: 298.716 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 710/1194 | Loss: 310.264 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 720/1194 | Loss: 298.440 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 730/1194 | Loss: 306.221 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 740/1194 | Loss: 281.560 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 750/1194 | Loss: 276.056 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 760/1194 | Loss: 295.927 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 770/1194 | Loss: 297.736 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 780/1194 | Loss: 293.523 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 790/1194 | Loss: 294.052 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 800/1194 | Loss: 289.319 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 810/1194 | Loss: 287.806 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 820/1194 | Loss: 341.106 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 830/1194 | Loss: 283.890 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 840/1194 | Loss: 300.526 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 850/1194 | Loss: 299.406 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 860/1194 | Loss: 293.166 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 870/1194 | Loss: 322.151 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 880/1194 | Loss: 317.480 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 890/1194 | Loss: 286.415 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 900/1194 | Loss: 307.456 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 910/1194 | Loss: 294.357 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 920/1194 | Loss: 291.095 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 930/1194 | Loss: 309.529 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 940/1194 | Loss: 287.852 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 950/1194 | Loss: 306.423 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 960/1194 | Loss: 287.306 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 970/1194 | Loss: 309.659 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 980/1194 | Loss: 296.374 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 990/1194 | Loss: 295.191 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 1000/1194 | Loss: 309.285 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 1010/1194 | Loss: 286.816 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 1020/1194 | Loss: 287.604 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 1030/1194 | Loss: 320.771 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 1040/1194 | Loss: 305.374 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1050/1194 | Loss: 288.258 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 1060/1194 | Loss: 297.017 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1070/1194 | Loss: 264.649 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 1080/1194 | Loss: 308.385 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1090/1194 | Loss: 301.407 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 1100/1194 | Loss: 306.843 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1110/1194 | Loss: 284.453 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 1120/1194 | Loss: 312.428 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1130/1194 | Loss: 274.772 | Accuracy: 0.300\n",
      "[Epoch: 107/200] - Step: 1140/1194 | Loss: 296.490 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 1150/1194 | Loss: 304.427 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1160/1194 | Loss: 307.084 | Accuracy: 0.100\n",
      "[Epoch: 107/200] - Step: 1170/1194 | Loss: 312.186 | Accuracy: 0.000\n",
      "[Epoch: 107/200] - Step: 1180/1194 | Loss: 292.589 | Accuracy: 0.200\n",
      "[Epoch: 107/200] - Step: 1190/1194 | Loss: 295.151 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 108/200] - Step: 10/1194 | Loss: 293.755 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 20/1194 | Loss: 304.725 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 30/1194 | Loss: 294.417 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 40/1194 | Loss: 313.617 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 50/1194 | Loss: 303.178 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 60/1194 | Loss: 271.151 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 70/1194 | Loss: 298.908 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 80/1194 | Loss: 284.394 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 90/1194 | Loss: 313.569 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 100/1194 | Loss: 293.819 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 110/1194 | Loss: 286.686 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 120/1194 | Loss: 284.277 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 130/1194 | Loss: 305.621 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 140/1194 | Loss: 286.263 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 150/1194 | Loss: 269.991 | Accuracy: 0.400\n",
      "[Epoch: 108/200] - Step: 160/1194 | Loss: 286.583 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 170/1194 | Loss: 290.880 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 180/1194 | Loss: 272.624 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 190/1194 | Loss: 318.808 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 200/1194 | Loss: 285.562 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 210/1194 | Loss: 310.553 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 220/1194 | Loss: 292.496 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 230/1194 | Loss: 285.555 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 240/1194 | Loss: 309.249 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 250/1194 | Loss: 292.639 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 260/1194 | Loss: 280.280 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 270/1194 | Loss: 297.529 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 280/1194 | Loss: 314.574 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 290/1194 | Loss: 307.941 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 300/1194 | Loss: 288.928 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 310/1194 | Loss: 310.367 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 320/1194 | Loss: 297.616 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 330/1194 | Loss: 305.598 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 340/1194 | Loss: 294.652 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 350/1194 | Loss: 308.775 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 360/1194 | Loss: 298.491 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 370/1194 | Loss: 273.389 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 380/1194 | Loss: 297.960 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 390/1194 | Loss: 301.768 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 400/1194 | Loss: 307.437 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 410/1194 | Loss: 306.254 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 420/1194 | Loss: 301.111 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 430/1194 | Loss: 290.405 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 440/1194 | Loss: 293.737 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 450/1194 | Loss: 300.363 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 460/1194 | Loss: 326.596 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 470/1194 | Loss: 298.044 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 480/1194 | Loss: 296.946 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 490/1194 | Loss: 287.932 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 500/1194 | Loss: 328.293 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 510/1194 | Loss: 303.862 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 520/1194 | Loss: 296.725 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 530/1194 | Loss: 310.892 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 540/1194 | Loss: 288.456 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 550/1194 | Loss: 300.810 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 560/1194 | Loss: 283.579 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 570/1194 | Loss: 284.078 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 580/1194 | Loss: 302.682 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 590/1194 | Loss: 300.625 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 600/1194 | Loss: 293.564 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 610/1194 | Loss: 295.557 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 620/1194 | Loss: 298.266 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 630/1194 | Loss: 283.832 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 640/1194 | Loss: 302.531 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 650/1194 | Loss: 282.868 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 660/1194 | Loss: 294.120 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 670/1194 | Loss: 285.216 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 680/1194 | Loss: 318.456 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 690/1194 | Loss: 271.615 | Accuracy: 0.400\n",
      "[Epoch: 108/200] - Step: 700/1194 | Loss: 298.487 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 710/1194 | Loss: 323.201 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 720/1194 | Loss: 289.668 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 730/1194 | Loss: 285.990 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 740/1194 | Loss: 298.355 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 750/1194 | Loss: 302.379 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 760/1194 | Loss: 303.348 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 770/1194 | Loss: 291.133 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 780/1194 | Loss: 292.364 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 790/1194 | Loss: 311.543 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 800/1194 | Loss: 282.632 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 810/1194 | Loss: 288.104 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 820/1194 | Loss: 310.187 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 830/1194 | Loss: 300.282 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 840/1194 | Loss: 304.857 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 850/1194 | Loss: 297.206 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 860/1194 | Loss: 309.846 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 870/1194 | Loss: 300.891 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 880/1194 | Loss: 283.584 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 890/1194 | Loss: 302.378 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 900/1194 | Loss: 284.986 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 910/1194 | Loss: 299.900 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 920/1194 | Loss: 302.157 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 930/1194 | Loss: 271.090 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 940/1194 | Loss: 307.401 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 950/1194 | Loss: 283.041 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 960/1194 | Loss: 316.497 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 970/1194 | Loss: 306.595 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 980/1194 | Loss: 290.957 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 990/1194 | Loss: 314.328 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1000/1194 | Loss: 298.393 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 1010/1194 | Loss: 296.667 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1020/1194 | Loss: 304.767 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1030/1194 | Loss: 291.595 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 1040/1194 | Loss: 294.416 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1050/1194 | Loss: 274.166 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 1060/1194 | Loss: 312.724 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 1070/1194 | Loss: 283.643 | Accuracy: 0.300\n",
      "[Epoch: 108/200] - Step: 1080/1194 | Loss: 292.193 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1090/1194 | Loss: 286.279 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1100/1194 | Loss: 293.598 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1110/1194 | Loss: 289.007 | Accuracy: 0.200\n",
      "[Epoch: 108/200] - Step: 1120/1194 | Loss: 302.327 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1130/1194 | Loss: 305.303 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1140/1194 | Loss: 306.175 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1150/1194 | Loss: 296.316 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1160/1194 | Loss: 325.573 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1170/1194 | Loss: 291.236 | Accuracy: 0.000\n",
      "[Epoch: 108/200] - Step: 1180/1194 | Loss: 290.301 | Accuracy: 0.100\n",
      "[Epoch: 108/200] - Step: 1190/1194 | Loss: 295.916 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 109/200] - Step: 10/1194 | Loss: 271.857 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 20/1194 | Loss: 300.847 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 30/1194 | Loss: 312.631 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 40/1194 | Loss: 307.262 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 50/1194 | Loss: 262.883 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 60/1194 | Loss: 294.508 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 70/1194 | Loss: 316.521 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 80/1194 | Loss: 301.187 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 90/1194 | Loss: 296.267 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 100/1194 | Loss: 308.224 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 110/1194 | Loss: 293.611 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 120/1194 | Loss: 298.727 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 130/1194 | Loss: 296.573 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 140/1194 | Loss: 308.712 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 150/1194 | Loss: 305.311 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 160/1194 | Loss: 301.874 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 170/1194 | Loss: 286.937 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 180/1194 | Loss: 285.246 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 190/1194 | Loss: 277.183 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 200/1194 | Loss: 286.769 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 210/1194 | Loss: 293.290 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 220/1194 | Loss: 311.255 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 230/1194 | Loss: 298.122 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 240/1194 | Loss: 290.560 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 250/1194 | Loss: 297.992 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 260/1194 | Loss: 289.006 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 270/1194 | Loss: 330.143 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 280/1194 | Loss: 303.717 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 290/1194 | Loss: 279.205 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 300/1194 | Loss: 309.389 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 310/1194 | Loss: 331.944 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 320/1194 | Loss: 299.531 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 330/1194 | Loss: 302.460 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 340/1194 | Loss: 312.076 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 350/1194 | Loss: 299.063 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 360/1194 | Loss: 305.907 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 370/1194 | Loss: 276.961 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 380/1194 | Loss: 285.751 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 390/1194 | Loss: 331.189 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 400/1194 | Loss: 293.714 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 410/1194 | Loss: 284.018 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 420/1194 | Loss: 300.133 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 430/1194 | Loss: 316.671 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 440/1194 | Loss: 313.478 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 450/1194 | Loss: 305.698 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 460/1194 | Loss: 271.222 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 470/1194 | Loss: 270.057 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 480/1194 | Loss: 303.725 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 490/1194 | Loss: 295.358 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 500/1194 | Loss: 297.500 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 510/1194 | Loss: 292.540 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 520/1194 | Loss: 301.673 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 530/1194 | Loss: 307.209 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 540/1194 | Loss: 304.409 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 550/1194 | Loss: 300.136 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 560/1194 | Loss: 309.182 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 570/1194 | Loss: 305.680 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 580/1194 | Loss: 299.391 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 590/1194 | Loss: 304.515 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 600/1194 | Loss: 305.133 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 610/1194 | Loss: 305.695 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 620/1194 | Loss: 301.338 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 630/1194 | Loss: 304.036 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 640/1194 | Loss: 301.068 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 650/1194 | Loss: 304.753 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 660/1194 | Loss: 276.219 | Accuracy: 0.400\n",
      "[Epoch: 109/200] - Step: 670/1194 | Loss: 296.985 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 680/1194 | Loss: 283.328 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 690/1194 | Loss: 297.408 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 700/1194 | Loss: 299.980 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 710/1194 | Loss: 303.026 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 720/1194 | Loss: 291.422 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 730/1194 | Loss: 306.619 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 740/1194 | Loss: 293.531 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 750/1194 | Loss: 306.032 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 760/1194 | Loss: 288.178 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 770/1194 | Loss: 296.527 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 780/1194 | Loss: 280.967 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 790/1194 | Loss: 307.179 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 800/1194 | Loss: 292.098 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 810/1194 | Loss: 305.868 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 820/1194 | Loss: 297.226 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 830/1194 | Loss: 300.126 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 840/1194 | Loss: 289.855 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 850/1194 | Loss: 302.602 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 860/1194 | Loss: 262.050 | Accuracy: 0.500\n",
      "[Epoch: 109/200] - Step: 870/1194 | Loss: 290.423 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 880/1194 | Loss: 297.040 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 890/1194 | Loss: 300.450 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 900/1194 | Loss: 286.730 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 910/1194 | Loss: 313.584 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 920/1194 | Loss: 292.451 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 930/1194 | Loss: 306.622 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 940/1194 | Loss: 296.005 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 950/1194 | Loss: 340.076 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 960/1194 | Loss: 303.576 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 970/1194 | Loss: 291.305 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 980/1194 | Loss: 292.581 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 990/1194 | Loss: 295.111 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 1000/1194 | Loss: 280.035 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 1010/1194 | Loss: 296.962 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1020/1194 | Loss: 302.913 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 1030/1194 | Loss: 293.195 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 1040/1194 | Loss: 293.831 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 1050/1194 | Loss: 296.377 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1060/1194 | Loss: 309.323 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1070/1194 | Loss: 298.556 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1080/1194 | Loss: 279.237 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 1090/1194 | Loss: 274.391 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 1100/1194 | Loss: 293.221 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1110/1194 | Loss: 295.584 | Accuracy: 0.000\n",
      "[Epoch: 109/200] - Step: 1120/1194 | Loss: 291.283 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 1130/1194 | Loss: 265.066 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 1140/1194 | Loss: 280.714 | Accuracy: 0.300\n",
      "[Epoch: 109/200] - Step: 1150/1194 | Loss: 299.536 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1160/1194 | Loss: 297.384 | Accuracy: 0.200\n",
      "[Epoch: 109/200] - Step: 1170/1194 | Loss: 263.334 | Accuracy: 0.400\n",
      "[Epoch: 109/200] - Step: 1180/1194 | Loss: 301.917 | Accuracy: 0.100\n",
      "[Epoch: 109/200] - Step: 1190/1194 | Loss: 274.652 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 110/200] - Step: 10/1194 | Loss: 320.913 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 20/1194 | Loss: 284.500 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 30/1194 | Loss: 297.381 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 40/1194 | Loss: 304.605 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 50/1194 | Loss: 276.867 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 60/1194 | Loss: 284.593 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 70/1194 | Loss: 321.798 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 80/1194 | Loss: 295.713 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 90/1194 | Loss: 276.565 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 100/1194 | Loss: 271.363 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 110/1194 | Loss: 300.690 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 120/1194 | Loss: 303.428 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 130/1194 | Loss: 306.291 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 140/1194 | Loss: 294.094 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 150/1194 | Loss: 300.711 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 160/1194 | Loss: 304.379 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 170/1194 | Loss: 300.616 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 180/1194 | Loss: 289.964 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 190/1194 | Loss: 288.828 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 200/1194 | Loss: 294.818 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 210/1194 | Loss: 299.679 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 220/1194 | Loss: 308.425 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 230/1194 | Loss: 285.891 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 240/1194 | Loss: 285.673 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 250/1194 | Loss: 302.692 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 260/1194 | Loss: 306.743 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 270/1194 | Loss: 282.675 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 280/1194 | Loss: 261.116 | Accuracy: 0.400\n",
      "[Epoch: 110/200] - Step: 290/1194 | Loss: 276.545 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 300/1194 | Loss: 288.794 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 310/1194 | Loss: 354.944 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 320/1194 | Loss: 263.636 | Accuracy: 0.400\n",
      "[Epoch: 110/200] - Step: 330/1194 | Loss: 280.422 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 340/1194 | Loss: 290.237 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 350/1194 | Loss: 290.826 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 360/1194 | Loss: 294.510 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 370/1194 | Loss: 298.546 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 380/1194 | Loss: 295.180 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 390/1194 | Loss: 306.981 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 400/1194 | Loss: 288.886 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 410/1194 | Loss: 306.740 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 420/1194 | Loss: 318.714 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 430/1194 | Loss: 270.305 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 440/1194 | Loss: 295.808 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 450/1194 | Loss: 305.982 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 460/1194 | Loss: 301.134 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 470/1194 | Loss: 286.730 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 480/1194 | Loss: 321.224 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 490/1194 | Loss: 298.624 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 500/1194 | Loss: 300.486 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 510/1194 | Loss: 289.612 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 520/1194 | Loss: 302.150 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 530/1194 | Loss: 298.943 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 540/1194 | Loss: 281.308 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 550/1194 | Loss: 297.274 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 560/1194 | Loss: 315.709 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 570/1194 | Loss: 296.317 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 580/1194 | Loss: 285.103 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 590/1194 | Loss: 301.980 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 600/1194 | Loss: 293.343 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 610/1194 | Loss: 292.983 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 620/1194 | Loss: 303.247 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 630/1194 | Loss: 339.575 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 640/1194 | Loss: 298.268 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 650/1194 | Loss: 306.626 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 660/1194 | Loss: 301.073 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 670/1194 | Loss: 280.816 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 680/1194 | Loss: 314.828 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 690/1194 | Loss: 305.363 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 700/1194 | Loss: 298.641 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 710/1194 | Loss: 288.591 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 720/1194 | Loss: 306.806 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 730/1194 | Loss: 296.522 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 740/1194 | Loss: 307.004 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 750/1194 | Loss: 298.754 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 760/1194 | Loss: 294.222 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 770/1194 | Loss: 313.482 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 780/1194 | Loss: 289.096 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 790/1194 | Loss: 294.740 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 800/1194 | Loss: 302.688 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 810/1194 | Loss: 292.174 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 820/1194 | Loss: 290.366 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 830/1194 | Loss: 323.366 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 840/1194 | Loss: 309.241 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 850/1194 | Loss: 288.536 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 860/1194 | Loss: 298.304 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 870/1194 | Loss: 295.945 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 880/1194 | Loss: 299.023 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 890/1194 | Loss: 301.851 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 900/1194 | Loss: 302.717 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 910/1194 | Loss: 292.705 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 920/1194 | Loss: 299.073 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 930/1194 | Loss: 301.190 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 940/1194 | Loss: 310.580 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 950/1194 | Loss: 310.743 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 960/1194 | Loss: 295.685 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 970/1194 | Loss: 310.463 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 980/1194 | Loss: 283.740 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 990/1194 | Loss: 311.205 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 1000/1194 | Loss: 289.928 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 1010/1194 | Loss: 275.932 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 1020/1194 | Loss: 296.199 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 1030/1194 | Loss: 316.407 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 1040/1194 | Loss: 303.854 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1050/1194 | Loss: 290.355 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1060/1194 | Loss: 294.450 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 1070/1194 | Loss: 289.342 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 1080/1194 | Loss: 287.514 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 1090/1194 | Loss: 296.306 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1100/1194 | Loss: 298.553 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1110/1194 | Loss: 297.357 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1120/1194 | Loss: 283.566 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 1130/1194 | Loss: 300.926 | Accuracy: 0.000\n",
      "[Epoch: 110/200] - Step: 1140/1194 | Loss: 278.899 | Accuracy: 0.300\n",
      "[Epoch: 110/200] - Step: 1150/1194 | Loss: 309.987 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1160/1194 | Loss: 293.132 | Accuracy: 0.100\n",
      "[Epoch: 110/200] - Step: 1170/1194 | Loss: 283.675 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 1180/1194 | Loss: 284.430 | Accuracy: 0.200\n",
      "[Epoch: 110/200] - Step: 1190/1194 | Loss: 290.352 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 111/200] - Step: 10/1194 | Loss: 296.938 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 20/1194 | Loss: 296.806 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 30/1194 | Loss: 304.335 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 40/1194 | Loss: 295.154 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 50/1194 | Loss: 300.590 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 60/1194 | Loss: 285.227 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 70/1194 | Loss: 277.665 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 80/1194 | Loss: 299.497 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 90/1194 | Loss: 269.863 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 100/1194 | Loss: 293.845 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 110/1194 | Loss: 302.783 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 120/1194 | Loss: 298.997 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 130/1194 | Loss: 277.043 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 140/1194 | Loss: 308.336 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 150/1194 | Loss: 304.637 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 160/1194 | Loss: 326.168 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 170/1194 | Loss: 283.040 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 180/1194 | Loss: 275.498 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 190/1194 | Loss: 300.373 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 200/1194 | Loss: 297.934 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 210/1194 | Loss: 305.106 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 220/1194 | Loss: 316.532 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 230/1194 | Loss: 289.600 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 240/1194 | Loss: 330.262 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 250/1194 | Loss: 286.148 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 260/1194 | Loss: 284.074 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 270/1194 | Loss: 306.417 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 280/1194 | Loss: 307.967 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 290/1194 | Loss: 293.130 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 300/1194 | Loss: 293.337 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 310/1194 | Loss: 306.227 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 320/1194 | Loss: 290.185 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 330/1194 | Loss: 300.433 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 340/1194 | Loss: 329.947 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 350/1194 | Loss: 299.017 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 360/1194 | Loss: 293.967 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 370/1194 | Loss: 300.748 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 380/1194 | Loss: 298.523 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 390/1194 | Loss: 288.008 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 400/1194 | Loss: 296.433 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 410/1194 | Loss: 298.687 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 420/1194 | Loss: 273.913 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 430/1194 | Loss: 292.986 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 440/1194 | Loss: 274.495 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 450/1194 | Loss: 293.274 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 460/1194 | Loss: 302.764 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 470/1194 | Loss: 340.465 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 480/1194 | Loss: 302.671 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 490/1194 | Loss: 342.257 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 500/1194 | Loss: 304.782 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 510/1194 | Loss: 292.962 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 520/1194 | Loss: 280.988 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 530/1194 | Loss: 298.290 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 540/1194 | Loss: 305.122 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 550/1194 | Loss: 304.691 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 560/1194 | Loss: 296.051 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 570/1194 | Loss: 300.037 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 580/1194 | Loss: 294.375 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 590/1194 | Loss: 302.040 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 600/1194 | Loss: 308.032 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 610/1194 | Loss: 291.589 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 620/1194 | Loss: 290.379 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 630/1194 | Loss: 284.397 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 640/1194 | Loss: 306.025 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 650/1194 | Loss: 291.821 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 660/1194 | Loss: 303.636 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 670/1194 | Loss: 300.405 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 680/1194 | Loss: 306.334 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 690/1194 | Loss: 308.643 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 700/1194 | Loss: 303.964 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 710/1194 | Loss: 292.636 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 720/1194 | Loss: 286.444 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 730/1194 | Loss: 297.199 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 740/1194 | Loss: 303.320 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 750/1194 | Loss: 294.708 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 760/1194 | Loss: 284.582 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 770/1194 | Loss: 307.059 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 780/1194 | Loss: 272.779 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 790/1194 | Loss: 302.796 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 800/1194 | Loss: 293.949 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 810/1194 | Loss: 297.172 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 820/1194 | Loss: 295.468 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 830/1194 | Loss: 316.782 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 840/1194 | Loss: 303.450 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 850/1194 | Loss: 295.193 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 860/1194 | Loss: 281.722 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 870/1194 | Loss: 304.799 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 880/1194 | Loss: 309.384 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 890/1194 | Loss: 289.014 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 900/1194 | Loss: 299.520 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 910/1194 | Loss: 284.581 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 920/1194 | Loss: 280.689 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 930/1194 | Loss: 286.001 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 940/1194 | Loss: 298.259 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 950/1194 | Loss: 265.750 | Accuracy: 0.400\n",
      "[Epoch: 111/200] - Step: 960/1194 | Loss: 300.980 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 970/1194 | Loss: 300.233 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 980/1194 | Loss: 290.485 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 990/1194 | Loss: 307.820 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1000/1194 | Loss: 279.474 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 1010/1194 | Loss: 302.168 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1020/1194 | Loss: 280.368 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1030/1194 | Loss: 274.736 | Accuracy: 0.300\n",
      "[Epoch: 111/200] - Step: 1040/1194 | Loss: 296.747 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1050/1194 | Loss: 300.703 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1060/1194 | Loss: 291.437 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1070/1194 | Loss: 289.044 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 1080/1194 | Loss: 300.458 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1090/1194 | Loss: 286.305 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1100/1194 | Loss: 297.325 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1110/1194 | Loss: 298.058 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1120/1194 | Loss: 308.490 | Accuracy: 0.000\n",
      "[Epoch: 111/200] - Step: 1130/1194 | Loss: 307.559 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1140/1194 | Loss: 295.009 | Accuracy: 0.200\n",
      "[Epoch: 111/200] - Step: 1150/1194 | Loss: 294.100 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1160/1194 | Loss: 308.518 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1170/1194 | Loss: 296.048 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1180/1194 | Loss: 294.465 | Accuracy: 0.100\n",
      "[Epoch: 111/200] - Step: 1190/1194 | Loss: 294.893 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 112/200] - Step: 10/1194 | Loss: 313.069 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 20/1194 | Loss: 305.679 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 30/1194 | Loss: 289.040 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 40/1194 | Loss: 300.781 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 50/1194 | Loss: 292.430 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 60/1194 | Loss: 286.657 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 70/1194 | Loss: 289.682 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 80/1194 | Loss: 291.239 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 90/1194 | Loss: 295.688 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 100/1194 | Loss: 285.017 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 110/1194 | Loss: 331.575 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 120/1194 | Loss: 292.792 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 130/1194 | Loss: 302.373 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 140/1194 | Loss: 295.056 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 150/1194 | Loss: 284.839 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 160/1194 | Loss: 276.715 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 170/1194 | Loss: 314.527 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 180/1194 | Loss: 304.887 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 190/1194 | Loss: 286.851 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 200/1194 | Loss: 297.654 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 210/1194 | Loss: 284.442 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 220/1194 | Loss: 290.768 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 230/1194 | Loss: 298.484 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 240/1194 | Loss: 291.716 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 250/1194 | Loss: 292.623 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 260/1194 | Loss: 301.670 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 270/1194 | Loss: 300.699 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 280/1194 | Loss: 300.578 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 290/1194 | Loss: 304.337 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 300/1194 | Loss: 295.471 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 310/1194 | Loss: 289.687 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 320/1194 | Loss: 303.373 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 330/1194 | Loss: 294.726 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 340/1194 | Loss: 296.307 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 350/1194 | Loss: 281.252 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 360/1194 | Loss: 306.706 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 370/1194 | Loss: 303.634 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 380/1194 | Loss: 294.662 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 390/1194 | Loss: 316.177 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 400/1194 | Loss: 293.605 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 410/1194 | Loss: 289.917 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 420/1194 | Loss: 314.929 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 430/1194 | Loss: 286.216 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 440/1194 | Loss: 312.024 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 450/1194 | Loss: 311.088 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 460/1194 | Loss: 335.796 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 470/1194 | Loss: 282.448 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 480/1194 | Loss: 281.444 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 490/1194 | Loss: 292.774 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 500/1194 | Loss: 311.735 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 510/1194 | Loss: 326.277 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 520/1194 | Loss: 307.132 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 530/1194 | Loss: 311.555 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 540/1194 | Loss: 287.098 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 550/1194 | Loss: 277.125 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 560/1194 | Loss: 319.842 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 570/1194 | Loss: 295.061 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 580/1194 | Loss: 297.622 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 590/1194 | Loss: 293.592 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 600/1194 | Loss: 304.178 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 610/1194 | Loss: 275.906 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 620/1194 | Loss: 316.880 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 630/1194 | Loss: 330.236 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 640/1194 | Loss: 296.697 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 650/1194 | Loss: 302.375 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 660/1194 | Loss: 302.924 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 670/1194 | Loss: 291.786 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 680/1194 | Loss: 297.723 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 690/1194 | Loss: 291.899 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 700/1194 | Loss: 290.072 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 710/1194 | Loss: 295.607 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 720/1194 | Loss: 278.867 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 730/1194 | Loss: 309.590 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 740/1194 | Loss: 284.953 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 750/1194 | Loss: 282.147 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 760/1194 | Loss: 303.201 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 770/1194 | Loss: 301.320 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 780/1194 | Loss: 288.050 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 790/1194 | Loss: 280.300 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 800/1194 | Loss: 299.800 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 810/1194 | Loss: 280.031 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 820/1194 | Loss: 307.009 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 830/1194 | Loss: 296.757 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 840/1194 | Loss: 297.560 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 850/1194 | Loss: 293.882 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 860/1194 | Loss: 276.459 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 870/1194 | Loss: 300.660 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 880/1194 | Loss: 282.587 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 890/1194 | Loss: 295.245 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 900/1194 | Loss: 302.983 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 910/1194 | Loss: 293.178 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 920/1194 | Loss: 298.560 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 930/1194 | Loss: 283.805 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 940/1194 | Loss: 303.292 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 950/1194 | Loss: 309.069 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 960/1194 | Loss: 297.608 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 970/1194 | Loss: 303.471 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 980/1194 | Loss: 294.761 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 990/1194 | Loss: 286.740 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 1000/1194 | Loss: 279.932 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 1010/1194 | Loss: 300.668 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1020/1194 | Loss: 298.548 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1030/1194 | Loss: 296.060 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1040/1194 | Loss: 297.425 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1050/1194 | Loss: 280.724 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 1060/1194 | Loss: 314.692 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 1070/1194 | Loss: 309.218 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 1080/1194 | Loss: 286.053 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1090/1194 | Loss: 280.792 | Accuracy: 0.200\n",
      "[Epoch: 112/200] - Step: 1100/1194 | Loss: 302.158 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1110/1194 | Loss: 303.325 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1120/1194 | Loss: 299.359 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1130/1194 | Loss: 317.122 | Accuracy: 0.000\n",
      "[Epoch: 112/200] - Step: 1140/1194 | Loss: 274.816 | Accuracy: 0.400\n",
      "[Epoch: 112/200] - Step: 1150/1194 | Loss: 286.326 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1160/1194 | Loss: 270.284 | Accuracy: 0.300\n",
      "[Epoch: 112/200] - Step: 1170/1194 | Loss: 296.245 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1180/1194 | Loss: 324.833 | Accuracy: 0.100\n",
      "[Epoch: 112/200] - Step: 1190/1194 | Loss: 286.892 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 113/200] - Step: 10/1194 | Loss: 306.282 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 20/1194 | Loss: 290.219 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 30/1194 | Loss: 281.902 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 40/1194 | Loss: 315.187 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 50/1194 | Loss: 293.895 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 60/1194 | Loss: 295.660 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 70/1194 | Loss: 323.869 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 80/1194 | Loss: 276.419 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 90/1194 | Loss: 292.824 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 100/1194 | Loss: 283.536 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 110/1194 | Loss: 297.005 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 120/1194 | Loss: 317.752 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 130/1194 | Loss: 307.667 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 140/1194 | Loss: 282.588 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 150/1194 | Loss: 276.743 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 160/1194 | Loss: 312.149 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 170/1194 | Loss: 330.286 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 180/1194 | Loss: 284.356 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 190/1194 | Loss: 307.037 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 200/1194 | Loss: 331.433 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 210/1194 | Loss: 306.993 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 220/1194 | Loss: 286.306 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 230/1194 | Loss: 307.248 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 240/1194 | Loss: 290.235 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 250/1194 | Loss: 300.042 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 260/1194 | Loss: 282.519 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 270/1194 | Loss: 318.419 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 280/1194 | Loss: 298.387 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 290/1194 | Loss: 296.835 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 300/1194 | Loss: 283.862 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 310/1194 | Loss: 285.986 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 320/1194 | Loss: 287.641 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 330/1194 | Loss: 293.837 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 340/1194 | Loss: 302.730 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 350/1194 | Loss: 280.522 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 360/1194 | Loss: 294.984 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 370/1194 | Loss: 307.877 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 380/1194 | Loss: 282.409 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 390/1194 | Loss: 300.863 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 400/1194 | Loss: 282.455 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 410/1194 | Loss: 270.142 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 420/1194 | Loss: 303.106 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 430/1194 | Loss: 307.644 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 440/1194 | Loss: 295.049 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 450/1194 | Loss: 289.388 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 460/1194 | Loss: 298.905 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 470/1194 | Loss: 303.866 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 480/1194 | Loss: 306.831 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 490/1194 | Loss: 313.981 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 500/1194 | Loss: 289.416 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 510/1194 | Loss: 288.567 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 520/1194 | Loss: 312.587 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 530/1194 | Loss: 283.409 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 540/1194 | Loss: 307.522 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 550/1194 | Loss: 298.144 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 560/1194 | Loss: 287.359 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 570/1194 | Loss: 290.172 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 580/1194 | Loss: 309.800 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 590/1194 | Loss: 301.631 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 600/1194 | Loss: 300.036 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 610/1194 | Loss: 292.932 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 620/1194 | Loss: 294.232 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 630/1194 | Loss: 285.413 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 640/1194 | Loss: 307.041 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 650/1194 | Loss: 274.566 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 660/1194 | Loss: 300.814 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 670/1194 | Loss: 294.027 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 680/1194 | Loss: 289.966 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 690/1194 | Loss: 296.990 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 700/1194 | Loss: 305.774 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 710/1194 | Loss: 336.189 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 720/1194 | Loss: 301.534 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 730/1194 | Loss: 300.073 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 740/1194 | Loss: 306.475 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 750/1194 | Loss: 290.791 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 760/1194 | Loss: 302.172 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 770/1194 | Loss: 276.221 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 780/1194 | Loss: 295.289 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 790/1194 | Loss: 300.696 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 800/1194 | Loss: 299.431 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 810/1194 | Loss: 284.825 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 820/1194 | Loss: 285.851 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 830/1194 | Loss: 290.036 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 840/1194 | Loss: 288.010 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 850/1194 | Loss: 292.609 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 860/1194 | Loss: 309.977 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 870/1194 | Loss: 290.399 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 880/1194 | Loss: 315.585 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 890/1194 | Loss: 305.895 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 900/1194 | Loss: 288.631 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 910/1194 | Loss: 288.906 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 920/1194 | Loss: 300.710 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 930/1194 | Loss: 289.903 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 940/1194 | Loss: 303.146 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 950/1194 | Loss: 288.240 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 960/1194 | Loss: 291.322 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 970/1194 | Loss: 299.812 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 980/1194 | Loss: 305.288 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 990/1194 | Loss: 303.557 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1000/1194 | Loss: 308.564 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1010/1194 | Loss: 301.663 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1020/1194 | Loss: 299.550 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1030/1194 | Loss: 300.877 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1040/1194 | Loss: 301.328 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1050/1194 | Loss: 304.187 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1060/1194 | Loss: 295.702 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1070/1194 | Loss: 288.011 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 1080/1194 | Loss: 280.769 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 1090/1194 | Loss: 300.164 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1100/1194 | Loss: 290.215 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 1110/1194 | Loss: 281.482 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 1120/1194 | Loss: 280.490 | Accuracy: 0.200\n",
      "[Epoch: 113/200] - Step: 1130/1194 | Loss: 304.381 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1140/1194 | Loss: 300.770 | Accuracy: 0.000\n",
      "[Epoch: 113/200] - Step: 1150/1194 | Loss: 291.661 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1160/1194 | Loss: 301.637 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1170/1194 | Loss: 279.253 | Accuracy: 0.300\n",
      "[Epoch: 113/200] - Step: 1180/1194 | Loss: 295.115 | Accuracy: 0.100\n",
      "[Epoch: 113/200] - Step: 1190/1194 | Loss: 302.304 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 114/200] - Step: 10/1194 | Loss: 288.973 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 20/1194 | Loss: 305.622 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 30/1194 | Loss: 297.102 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 40/1194 | Loss: 332.663 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 50/1194 | Loss: 293.201 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 60/1194 | Loss: 297.105 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 70/1194 | Loss: 290.001 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 80/1194 | Loss: 290.237 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 90/1194 | Loss: 284.154 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 100/1194 | Loss: 310.356 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 110/1194 | Loss: 303.843 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 120/1194 | Loss: 293.046 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 130/1194 | Loss: 304.992 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 140/1194 | Loss: 282.770 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 150/1194 | Loss: 294.060 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 160/1194 | Loss: 300.862 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 170/1194 | Loss: 280.933 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 180/1194 | Loss: 292.729 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 190/1194 | Loss: 311.415 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 200/1194 | Loss: 292.475 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 210/1194 | Loss: 312.226 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 220/1194 | Loss: 305.676 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 230/1194 | Loss: 286.237 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 240/1194 | Loss: 267.810 | Accuracy: 0.400\n",
      "[Epoch: 114/200] - Step: 250/1194 | Loss: 283.558 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 260/1194 | Loss: 308.172 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 270/1194 | Loss: 301.679 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 280/1194 | Loss: 291.141 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 290/1194 | Loss: 313.482 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 300/1194 | Loss: 287.596 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 310/1194 | Loss: 274.616 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 320/1194 | Loss: 280.792 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 330/1194 | Loss: 289.801 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 340/1194 | Loss: 317.050 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 350/1194 | Loss: 282.418 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 360/1194 | Loss: 281.851 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 370/1194 | Loss: 302.926 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 380/1194 | Loss: 304.186 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 390/1194 | Loss: 287.898 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 400/1194 | Loss: 296.070 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 410/1194 | Loss: 312.471 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 420/1194 | Loss: 302.814 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 430/1194 | Loss: 288.574 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 440/1194 | Loss: 306.297 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 450/1194 | Loss: 303.690 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 460/1194 | Loss: 305.316 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 470/1194 | Loss: 291.575 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 480/1194 | Loss: 276.560 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 490/1194 | Loss: 294.233 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 500/1194 | Loss: 296.300 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 510/1194 | Loss: 300.234 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 520/1194 | Loss: 296.492 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 530/1194 | Loss: 304.968 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 540/1194 | Loss: 277.612 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 550/1194 | Loss: 304.113 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 560/1194 | Loss: 298.814 | Accuracy: 0.400\n",
      "[Epoch: 114/200] - Step: 570/1194 | Loss: 283.500 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 580/1194 | Loss: 287.649 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 590/1194 | Loss: 318.474 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 600/1194 | Loss: 304.393 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 610/1194 | Loss: 287.588 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 620/1194 | Loss: 274.321 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 630/1194 | Loss: 292.985 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 640/1194 | Loss: 314.552 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 650/1194 | Loss: 300.714 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 660/1194 | Loss: 284.348 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 670/1194 | Loss: 306.912 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 680/1194 | Loss: 300.011 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 690/1194 | Loss: 293.326 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 700/1194 | Loss: 307.559 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 710/1194 | Loss: 305.686 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 720/1194 | Loss: 301.195 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 730/1194 | Loss: 297.936 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 740/1194 | Loss: 284.895 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 750/1194 | Loss: 296.712 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 760/1194 | Loss: 302.405 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 770/1194 | Loss: 312.084 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 780/1194 | Loss: 295.611 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 790/1194 | Loss: 291.995 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 800/1194 | Loss: 310.907 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 810/1194 | Loss: 294.026 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 820/1194 | Loss: 286.243 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 830/1194 | Loss: 287.904 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 840/1194 | Loss: 288.612 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 850/1194 | Loss: 292.970 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 860/1194 | Loss: 338.000 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 870/1194 | Loss: 293.614 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 880/1194 | Loss: 301.502 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 890/1194 | Loss: 303.645 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 900/1194 | Loss: 306.595 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 910/1194 | Loss: 278.898 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 920/1194 | Loss: 290.421 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 930/1194 | Loss: 287.233 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 940/1194 | Loss: 296.222 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 950/1194 | Loss: 284.670 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 960/1194 | Loss: 308.727 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 970/1194 | Loss: 306.705 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 980/1194 | Loss: 284.936 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 990/1194 | Loss: 294.894 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1000/1194 | Loss: 297.048 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1010/1194 | Loss: 330.180 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1020/1194 | Loss: 299.237 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1030/1194 | Loss: 294.482 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 1040/1194 | Loss: 301.275 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1050/1194 | Loss: 278.882 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 1060/1194 | Loss: 291.257 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1070/1194 | Loss: 281.049 | Accuracy: 0.300\n",
      "[Epoch: 114/200] - Step: 1080/1194 | Loss: 288.194 | Accuracy: 0.200\n",
      "[Epoch: 114/200] - Step: 1090/1194 | Loss: 310.359 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 1100/1194 | Loss: 291.646 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1110/1194 | Loss: 328.122 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1120/1194 | Loss: 300.215 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 1130/1194 | Loss: 295.928 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1140/1194 | Loss: 300.603 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1150/1194 | Loss: 314.297 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 1160/1194 | Loss: 259.984 | Accuracy: 0.500\n",
      "[Epoch: 114/200] - Step: 1170/1194 | Loss: 303.275 | Accuracy: 0.000\n",
      "[Epoch: 114/200] - Step: 1180/1194 | Loss: 295.586 | Accuracy: 0.100\n",
      "[Epoch: 114/200] - Step: 1190/1194 | Loss: 310.795 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 115/200] - Step: 10/1194 | Loss: 285.281 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 20/1194 | Loss: 286.593 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 30/1194 | Loss: 268.540 | Accuracy: 0.400\n",
      "[Epoch: 115/200] - Step: 40/1194 | Loss: 291.580 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 50/1194 | Loss: 332.913 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 60/1194 | Loss: 290.288 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 70/1194 | Loss: 303.348 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 80/1194 | Loss: 288.482 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 90/1194 | Loss: 290.305 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 100/1194 | Loss: 292.329 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 110/1194 | Loss: 298.187 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 120/1194 | Loss: 347.079 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 130/1194 | Loss: 294.577 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 140/1194 | Loss: 280.010 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 150/1194 | Loss: 279.339 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 160/1194 | Loss: 327.819 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 170/1194 | Loss: 303.475 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 180/1194 | Loss: 279.939 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 190/1194 | Loss: 294.557 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 200/1194 | Loss: 293.983 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 210/1194 | Loss: 305.163 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 220/1194 | Loss: 300.968 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 230/1194 | Loss: 299.362 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 240/1194 | Loss: 292.888 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 250/1194 | Loss: 291.635 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 260/1194 | Loss: 282.834 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 270/1194 | Loss: 310.687 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 280/1194 | Loss: 316.145 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 290/1194 | Loss: 287.907 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 300/1194 | Loss: 302.630 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 310/1194 | Loss: 302.005 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 320/1194 | Loss: 301.591 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 330/1194 | Loss: 306.842 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 340/1194 | Loss: 309.046 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 350/1194 | Loss: 296.180 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 360/1194 | Loss: 307.023 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 370/1194 | Loss: 302.803 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 380/1194 | Loss: 300.619 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 390/1194 | Loss: 300.246 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 400/1194 | Loss: 286.853 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 410/1194 | Loss: 284.868 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 420/1194 | Loss: 288.455 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 430/1194 | Loss: 304.213 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 440/1194 | Loss: 302.687 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 450/1194 | Loss: 293.180 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 460/1194 | Loss: 318.722 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 470/1194 | Loss: 286.519 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 480/1194 | Loss: 284.806 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 490/1194 | Loss: 304.478 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 500/1194 | Loss: 293.884 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 510/1194 | Loss: 294.495 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 520/1194 | Loss: 292.250 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 530/1194 | Loss: 291.272 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 540/1194 | Loss: 282.239 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 550/1194 | Loss: 310.373 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 560/1194 | Loss: 277.064 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 570/1194 | Loss: 289.271 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 580/1194 | Loss: 309.561 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 590/1194 | Loss: 304.087 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 600/1194 | Loss: 300.735 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 610/1194 | Loss: 304.790 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 620/1194 | Loss: 289.231 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 630/1194 | Loss: 275.125 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 640/1194 | Loss: 313.139 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 650/1194 | Loss: 274.745 | Accuracy: 0.400\n",
      "[Epoch: 115/200] - Step: 660/1194 | Loss: 311.063 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 670/1194 | Loss: 297.718 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 680/1194 | Loss: 306.222 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 690/1194 | Loss: 286.927 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 700/1194 | Loss: 297.447 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 710/1194 | Loss: 290.098 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 720/1194 | Loss: 277.097 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 730/1194 | Loss: 297.023 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 740/1194 | Loss: 296.399 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 750/1194 | Loss: 314.900 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 760/1194 | Loss: 296.053 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 770/1194 | Loss: 283.267 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 780/1194 | Loss: 284.508 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 790/1194 | Loss: 292.340 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 800/1194 | Loss: 315.739 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 810/1194 | Loss: 299.779 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 820/1194 | Loss: 295.364 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 830/1194 | Loss: 302.461 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 840/1194 | Loss: 296.844 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 850/1194 | Loss: 282.170 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 860/1194 | Loss: 307.740 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 870/1194 | Loss: 291.418 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 880/1194 | Loss: 302.744 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 890/1194 | Loss: 298.553 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 900/1194 | Loss: 293.432 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 910/1194 | Loss: 297.813 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 920/1194 | Loss: 327.004 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 930/1194 | Loss: 312.231 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 940/1194 | Loss: 299.634 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 950/1194 | Loss: 354.322 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 960/1194 | Loss: 300.817 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 970/1194 | Loss: 278.898 | Accuracy: 0.500\n",
      "[Epoch: 115/200] - Step: 980/1194 | Loss: 286.630 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 990/1194 | Loss: 293.328 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1000/1194 | Loss: 305.084 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 1010/1194 | Loss: 310.442 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 1020/1194 | Loss: 303.072 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1030/1194 | Loss: 298.374 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1040/1194 | Loss: 300.777 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1050/1194 | Loss: 281.763 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1060/1194 | Loss: 279.115 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1070/1194 | Loss: 312.179 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 1080/1194 | Loss: 284.569 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1090/1194 | Loss: 282.745 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1100/1194 | Loss: 289.577 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1110/1194 | Loss: 285.971 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1120/1194 | Loss: 298.906 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 1130/1194 | Loss: 295.402 | Accuracy: 0.200\n",
      "[Epoch: 115/200] - Step: 1140/1194 | Loss: 305.512 | Accuracy: 0.000\n",
      "[Epoch: 115/200] - Step: 1150/1194 | Loss: 288.722 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1160/1194 | Loss: 301.196 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1170/1194 | Loss: 281.340 | Accuracy: 0.300\n",
      "[Epoch: 115/200] - Step: 1180/1194 | Loss: 293.108 | Accuracy: 0.100\n",
      "[Epoch: 115/200] - Step: 1190/1194 | Loss: 273.218 | Accuracy: 0.400\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 116/200] - Step: 10/1194 | Loss: 287.276 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 20/1194 | Loss: 306.295 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 30/1194 | Loss: 311.612 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 40/1194 | Loss: 282.569 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 50/1194 | Loss: 300.985 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 60/1194 | Loss: 263.702 | Accuracy: 0.400\n",
      "[Epoch: 116/200] - Step: 70/1194 | Loss: 300.680 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 80/1194 | Loss: 289.279 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 90/1194 | Loss: 292.853 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 100/1194 | Loss: 309.695 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 110/1194 | Loss: 306.067 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 120/1194 | Loss: 292.430 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 130/1194 | Loss: 319.238 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 140/1194 | Loss: 284.527 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 150/1194 | Loss: 312.210 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 160/1194 | Loss: 284.291 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 170/1194 | Loss: 287.400 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 180/1194 | Loss: 289.366 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 190/1194 | Loss: 305.014 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 200/1194 | Loss: 305.938 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 210/1194 | Loss: 290.565 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 220/1194 | Loss: 309.645 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 230/1194 | Loss: 291.559 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 240/1194 | Loss: 276.772 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 250/1194 | Loss: 290.149 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 260/1194 | Loss: 303.473 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 270/1194 | Loss: 313.552 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 280/1194 | Loss: 312.422 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 290/1194 | Loss: 331.046 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 300/1194 | Loss: 292.531 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 310/1194 | Loss: 294.550 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 320/1194 | Loss: 282.334 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 330/1194 | Loss: 299.981 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 340/1194 | Loss: 296.103 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 350/1194 | Loss: 286.346 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 360/1194 | Loss: 314.066 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 370/1194 | Loss: 307.602 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 380/1194 | Loss: 296.060 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 390/1194 | Loss: 334.868 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 400/1194 | Loss: 284.404 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 410/1194 | Loss: 292.119 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 420/1194 | Loss: 292.230 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 430/1194 | Loss: 298.307 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 440/1194 | Loss: 279.938 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 450/1194 | Loss: 295.812 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 460/1194 | Loss: 291.868 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 470/1194 | Loss: 310.242 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 480/1194 | Loss: 300.764 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 490/1194 | Loss: 298.316 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 500/1194 | Loss: 301.275 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 510/1194 | Loss: 289.085 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 520/1194 | Loss: 305.723 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 530/1194 | Loss: 308.105 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 540/1194 | Loss: 293.085 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 550/1194 | Loss: 274.851 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 560/1194 | Loss: 281.876 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 570/1194 | Loss: 308.861 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 580/1194 | Loss: 276.847 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 590/1194 | Loss: 274.510 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 600/1194 | Loss: 285.783 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 610/1194 | Loss: 284.374 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 620/1194 | Loss: 304.166 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 630/1194 | Loss: 297.076 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 640/1194 | Loss: 300.264 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 650/1194 | Loss: 316.590 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 660/1194 | Loss: 296.623 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 670/1194 | Loss: 281.690 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 680/1194 | Loss: 293.725 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 690/1194 | Loss: 285.800 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 700/1194 | Loss: 301.824 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 710/1194 | Loss: 294.222 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 720/1194 | Loss: 281.326 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 730/1194 | Loss: 297.015 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 740/1194 | Loss: 306.131 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 750/1194 | Loss: 294.247 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 760/1194 | Loss: 299.473 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 770/1194 | Loss: 312.467 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 780/1194 | Loss: 321.667 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 790/1194 | Loss: 280.031 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 800/1194 | Loss: 296.154 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 810/1194 | Loss: 308.551 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 820/1194 | Loss: 285.678 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 830/1194 | Loss: 282.869 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 840/1194 | Loss: 297.197 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 850/1194 | Loss: 306.706 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 860/1194 | Loss: 282.810 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 870/1194 | Loss: 311.711 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 880/1194 | Loss: 304.626 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 890/1194 | Loss: 318.042 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 900/1194 | Loss: 291.889 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 910/1194 | Loss: 292.904 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 920/1194 | Loss: 297.789 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 930/1194 | Loss: 286.911 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 940/1194 | Loss: 283.382 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 950/1194 | Loss: 317.243 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 960/1194 | Loss: 285.567 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 970/1194 | Loss: 308.766 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 980/1194 | Loss: 289.939 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 990/1194 | Loss: 298.917 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1000/1194 | Loss: 291.881 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1010/1194 | Loss: 334.854 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 1020/1194 | Loss: 289.220 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1030/1194 | Loss: 280.486 | Accuracy: 0.300\n",
      "[Epoch: 116/200] - Step: 1040/1194 | Loss: 281.163 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1050/1194 | Loss: 296.751 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1060/1194 | Loss: 287.524 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1070/1194 | Loss: 287.616 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1080/1194 | Loss: 302.260 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1090/1194 | Loss: 295.507 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1100/1194 | Loss: 288.068 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1110/1194 | Loss: 306.071 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 1120/1194 | Loss: 303.954 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1130/1194 | Loss: 298.230 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1140/1194 | Loss: 288.640 | Accuracy: 0.200\n",
      "[Epoch: 116/200] - Step: 1150/1194 | Loss: 295.722 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1160/1194 | Loss: 310.531 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1170/1194 | Loss: 294.022 | Accuracy: 0.100\n",
      "[Epoch: 116/200] - Step: 1180/1194 | Loss: 305.727 | Accuracy: 0.000\n",
      "[Epoch: 116/200] - Step: 1190/1194 | Loss: 314.367 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 117/200] - Step: 10/1194 | Loss: 304.762 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 20/1194 | Loss: 290.953 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 30/1194 | Loss: 301.198 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 40/1194 | Loss: 295.332 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 50/1194 | Loss: 308.477 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 60/1194 | Loss: 289.884 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 70/1194 | Loss: 289.351 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 80/1194 | Loss: 296.596 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 90/1194 | Loss: 295.011 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 100/1194 | Loss: 293.886 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 110/1194 | Loss: 282.560 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 120/1194 | Loss: 302.478 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 130/1194 | Loss: 304.559 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 140/1194 | Loss: 298.323 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 150/1194 | Loss: 302.882 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 160/1194 | Loss: 292.342 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 170/1194 | Loss: 295.046 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 180/1194 | Loss: 303.444 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 190/1194 | Loss: 280.502 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 200/1194 | Loss: 291.262 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 210/1194 | Loss: 287.920 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 220/1194 | Loss: 323.290 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 230/1194 | Loss: 304.279 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 240/1194 | Loss: 295.935 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 250/1194 | Loss: 284.821 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 260/1194 | Loss: 287.633 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 270/1194 | Loss: 289.832 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 280/1194 | Loss: 301.440 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 290/1194 | Loss: 303.957 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 300/1194 | Loss: 280.432 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 310/1194 | Loss: 296.687 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 320/1194 | Loss: 296.183 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 330/1194 | Loss: 308.091 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 340/1194 | Loss: 269.959 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 350/1194 | Loss: 279.229 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 360/1194 | Loss: 293.826 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 370/1194 | Loss: 289.688 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 380/1194 | Loss: 283.029 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 390/1194 | Loss: 301.334 | Accuracy: 0.400\n",
      "[Epoch: 117/200] - Step: 400/1194 | Loss: 301.728 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 410/1194 | Loss: 298.951 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 420/1194 | Loss: 312.904 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 430/1194 | Loss: 291.915 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 440/1194 | Loss: 288.318 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 450/1194 | Loss: 291.458 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 460/1194 | Loss: 290.800 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 470/1194 | Loss: 294.911 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 480/1194 | Loss: 288.497 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 490/1194 | Loss: 279.336 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 500/1194 | Loss: 289.361 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 510/1194 | Loss: 315.470 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 520/1194 | Loss: 318.965 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 530/1194 | Loss: 295.527 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 540/1194 | Loss: 294.168 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 550/1194 | Loss: 310.925 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 560/1194 | Loss: 304.523 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 570/1194 | Loss: 301.475 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 580/1194 | Loss: 302.837 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 590/1194 | Loss: 286.903 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 600/1194 | Loss: 300.668 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 610/1194 | Loss: 276.437 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 620/1194 | Loss: 312.428 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 630/1194 | Loss: 326.852 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 640/1194 | Loss: 291.683 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 650/1194 | Loss: 302.900 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 660/1194 | Loss: 295.368 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 670/1194 | Loss: 281.181 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 680/1194 | Loss: 308.924 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 690/1194 | Loss: 326.117 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 700/1194 | Loss: 302.050 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 710/1194 | Loss: 297.882 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 720/1194 | Loss: 294.537 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 730/1194 | Loss: 287.361 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 740/1194 | Loss: 280.997 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 750/1194 | Loss: 294.194 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 760/1194 | Loss: 288.706 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 770/1194 | Loss: 315.011 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 780/1194 | Loss: 289.231 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 790/1194 | Loss: 296.322 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 800/1194 | Loss: 306.755 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 810/1194 | Loss: 295.369 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 820/1194 | Loss: 295.568 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 830/1194 | Loss: 291.187 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 840/1194 | Loss: 305.252 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 850/1194 | Loss: 304.844 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 860/1194 | Loss: 287.999 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 870/1194 | Loss: 288.790 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 880/1194 | Loss: 303.950 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 890/1194 | Loss: 310.896 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 900/1194 | Loss: 293.527 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 910/1194 | Loss: 302.023 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 920/1194 | Loss: 302.347 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 930/1194 | Loss: 309.621 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 940/1194 | Loss: 296.505 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 950/1194 | Loss: 308.813 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 960/1194 | Loss: 291.904 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 970/1194 | Loss: 290.498 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 980/1194 | Loss: 307.628 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 990/1194 | Loss: 319.296 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1000/1194 | Loss: 301.561 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1010/1194 | Loss: 289.151 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1020/1194 | Loss: 286.725 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1030/1194 | Loss: 281.009 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1040/1194 | Loss: 298.295 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1050/1194 | Loss: 285.609 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1060/1194 | Loss: 301.609 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1070/1194 | Loss: 308.969 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1080/1194 | Loss: 286.588 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1090/1194 | Loss: 299.514 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1100/1194 | Loss: 287.632 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1110/1194 | Loss: 309.508 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1120/1194 | Loss: 300.154 | Accuracy: 0.000\n",
      "[Epoch: 117/200] - Step: 1130/1194 | Loss: 296.823 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1140/1194 | Loss: 298.699 | Accuracy: 0.200\n",
      "[Epoch: 117/200] - Step: 1150/1194 | Loss: 291.317 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1160/1194 | Loss: 279.811 | Accuracy: 0.300\n",
      "[Epoch: 117/200] - Step: 1170/1194 | Loss: 297.693 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1180/1194 | Loss: 292.963 | Accuracy: 0.100\n",
      "[Epoch: 117/200] - Step: 1190/1194 | Loss: 313.186 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 118/200] - Step: 10/1194 | Loss: 299.716 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 20/1194 | Loss: 332.288 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 30/1194 | Loss: 305.586 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 40/1194 | Loss: 295.149 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 50/1194 | Loss: 296.344 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 60/1194 | Loss: 309.394 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 70/1194 | Loss: 296.664 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 80/1194 | Loss: 297.878 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 90/1194 | Loss: 290.008 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 100/1194 | Loss: 287.698 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 110/1194 | Loss: 285.205 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 120/1194 | Loss: 289.436 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 130/1194 | Loss: 296.698 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 140/1194 | Loss: 270.077 | Accuracy: 0.400\n",
      "[Epoch: 118/200] - Step: 150/1194 | Loss: 289.760 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 160/1194 | Loss: 301.790 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 170/1194 | Loss: 293.689 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 180/1194 | Loss: 308.928 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 190/1194 | Loss: 288.106 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 200/1194 | Loss: 291.168 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 210/1194 | Loss: 275.609 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 220/1194 | Loss: 285.815 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 230/1194 | Loss: 344.418 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 240/1194 | Loss: 289.063 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 250/1194 | Loss: 293.330 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 260/1194 | Loss: 296.626 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 270/1194 | Loss: 307.784 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 280/1194 | Loss: 292.068 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 290/1194 | Loss: 302.482 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 300/1194 | Loss: 296.631 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 310/1194 | Loss: 314.346 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 320/1194 | Loss: 329.502 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 330/1194 | Loss: 303.695 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 340/1194 | Loss: 302.012 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 350/1194 | Loss: 291.254 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 360/1194 | Loss: 310.136 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 370/1194 | Loss: 299.144 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 380/1194 | Loss: 272.010 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 390/1194 | Loss: 307.492 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 400/1194 | Loss: 303.633 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 410/1194 | Loss: 298.101 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 420/1194 | Loss: 310.959 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 430/1194 | Loss: 290.485 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 440/1194 | Loss: 288.680 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 450/1194 | Loss: 303.341 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 460/1194 | Loss: 276.052 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 470/1194 | Loss: 297.898 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 480/1194 | Loss: 292.168 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 490/1194 | Loss: 306.462 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 500/1194 | Loss: 276.816 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 510/1194 | Loss: 282.414 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 520/1194 | Loss: 294.815 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 530/1194 | Loss: 256.593 | Accuracy: 0.500\n",
      "[Epoch: 118/200] - Step: 540/1194 | Loss: 291.469 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 550/1194 | Loss: 295.790 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 560/1194 | Loss: 294.501 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 570/1194 | Loss: 309.004 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 580/1194 | Loss: 277.157 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 590/1194 | Loss: 289.062 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 600/1194 | Loss: 305.228 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 610/1194 | Loss: 287.708 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 620/1194 | Loss: 303.774 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 630/1194 | Loss: 292.864 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 640/1194 | Loss: 310.362 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 650/1194 | Loss: 282.727 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 660/1194 | Loss: 300.501 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 670/1194 | Loss: 335.598 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 680/1194 | Loss: 310.878 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 690/1194 | Loss: 313.181 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 700/1194 | Loss: 283.521 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 710/1194 | Loss: 298.379 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 720/1194 | Loss: 293.472 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 730/1194 | Loss: 281.121 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 740/1194 | Loss: 307.221 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 750/1194 | Loss: 298.603 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 760/1194 | Loss: 290.326 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 770/1194 | Loss: 286.350 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 780/1194 | Loss: 315.226 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 790/1194 | Loss: 292.695 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 800/1194 | Loss: 267.658 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 810/1194 | Loss: 310.231 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 820/1194 | Loss: 294.794 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 830/1194 | Loss: 312.593 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 840/1194 | Loss: 296.572 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 850/1194 | Loss: 333.308 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 860/1194 | Loss: 276.508 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 870/1194 | Loss: 304.334 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 880/1194 | Loss: 300.400 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 890/1194 | Loss: 287.584 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 900/1194 | Loss: 284.334 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 910/1194 | Loss: 290.825 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 920/1194 | Loss: 309.004 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 930/1194 | Loss: 305.014 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 940/1194 | Loss: 294.844 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 950/1194 | Loss: 285.760 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 960/1194 | Loss: 299.271 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 970/1194 | Loss: 295.301 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 980/1194 | Loss: 307.841 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 990/1194 | Loss: 298.430 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1000/1194 | Loss: 279.008 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 1010/1194 | Loss: 295.803 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1020/1194 | Loss: 333.222 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1030/1194 | Loss: 304.982 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1040/1194 | Loss: 310.165 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1050/1194 | Loss: 299.385 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1060/1194 | Loss: 279.290 | Accuracy: 0.300\n",
      "[Epoch: 118/200] - Step: 1070/1194 | Loss: 286.852 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 1080/1194 | Loss: 267.135 | Accuracy: 0.400\n",
      "[Epoch: 118/200] - Step: 1090/1194 | Loss: 298.311 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1100/1194 | Loss: 293.458 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1110/1194 | Loss: 288.427 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 1120/1194 | Loss: 295.976 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1130/1194 | Loss: 304.027 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1140/1194 | Loss: 298.574 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1150/1194 | Loss: 317.969 | Accuracy: 0.000\n",
      "[Epoch: 118/200] - Step: 1160/1194 | Loss: 284.949 | Accuracy: 0.200\n",
      "[Epoch: 118/200] - Step: 1170/1194 | Loss: 297.338 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1180/1194 | Loss: 298.119 | Accuracy: 0.100\n",
      "[Epoch: 118/200] - Step: 1190/1194 | Loss: 303.162 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 119/200] - Step: 10/1194 | Loss: 290.121 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 20/1194 | Loss: 290.525 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 30/1194 | Loss: 272.700 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 40/1194 | Loss: 306.218 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 50/1194 | Loss: 289.421 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 60/1194 | Loss: 300.922 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 70/1194 | Loss: 296.427 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 80/1194 | Loss: 308.943 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 90/1194 | Loss: 287.997 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 100/1194 | Loss: 291.846 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 110/1194 | Loss: 283.592 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 120/1194 | Loss: 296.405 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 130/1194 | Loss: 292.933 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 140/1194 | Loss: 300.185 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 150/1194 | Loss: 300.695 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 160/1194 | Loss: 291.257 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 170/1194 | Loss: 305.358 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 180/1194 | Loss: 295.595 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 190/1194 | Loss: 313.192 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 200/1194 | Loss: 295.843 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 210/1194 | Loss: 292.798 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 220/1194 | Loss: 292.917 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 230/1194 | Loss: 294.164 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 240/1194 | Loss: 300.274 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 250/1194 | Loss: 279.287 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 260/1194 | Loss: 304.401 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 270/1194 | Loss: 291.139 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 280/1194 | Loss: 295.866 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 290/1194 | Loss: 288.521 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 300/1194 | Loss: 307.448 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 310/1194 | Loss: 292.600 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 320/1194 | Loss: 293.682 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 330/1194 | Loss: 311.138 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 340/1194 | Loss: 309.881 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 350/1194 | Loss: 291.955 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 360/1194 | Loss: 289.957 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 370/1194 | Loss: 300.690 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 380/1194 | Loss: 274.113 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 390/1194 | Loss: 306.505 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 400/1194 | Loss: 312.816 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 410/1194 | Loss: 290.018 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 420/1194 | Loss: 289.208 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 430/1194 | Loss: 295.131 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 440/1194 | Loss: 316.239 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 450/1194 | Loss: 309.400 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 460/1194 | Loss: 293.274 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 470/1194 | Loss: 300.107 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 480/1194 | Loss: 301.579 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 490/1194 | Loss: 303.224 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 500/1194 | Loss: 307.914 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 510/1194 | Loss: 296.799 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 520/1194 | Loss: 300.196 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 530/1194 | Loss: 302.147 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 540/1194 | Loss: 293.865 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 550/1194 | Loss: 285.696 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 560/1194 | Loss: 301.946 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 570/1194 | Loss: 311.914 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 580/1194 | Loss: 298.241 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 590/1194 | Loss: 293.973 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 600/1194 | Loss: 295.283 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 610/1194 | Loss: 275.600 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 620/1194 | Loss: 277.612 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 630/1194 | Loss: 299.008 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 640/1194 | Loss: 292.990 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 650/1194 | Loss: 333.608 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 660/1194 | Loss: 291.571 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 670/1194 | Loss: 267.574 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 680/1194 | Loss: 316.411 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 690/1194 | Loss: 299.276 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 700/1194 | Loss: 284.797 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 710/1194 | Loss: 314.308 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 720/1194 | Loss: 279.931 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 730/1194 | Loss: 274.705 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 740/1194 | Loss: 298.316 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 750/1194 | Loss: 304.211 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 760/1194 | Loss: 329.009 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 770/1194 | Loss: 311.761 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 780/1194 | Loss: 296.222 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 790/1194 | Loss: 285.141 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 800/1194 | Loss: 295.827 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 810/1194 | Loss: 294.892 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 820/1194 | Loss: 308.659 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 830/1194 | Loss: 311.849 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 840/1194 | Loss: 294.379 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 850/1194 | Loss: 305.806 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 860/1194 | Loss: 293.290 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 870/1194 | Loss: 290.966 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 880/1194 | Loss: 302.958 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 890/1194 | Loss: 295.994 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 900/1194 | Loss: 297.481 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 910/1194 | Loss: 306.070 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 920/1194 | Loss: 296.855 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 930/1194 | Loss: 308.632 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 940/1194 | Loss: 321.471 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 950/1194 | Loss: 303.811 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 960/1194 | Loss: 285.194 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 970/1194 | Loss: 289.249 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 980/1194 | Loss: 301.837 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 990/1194 | Loss: 312.352 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 1000/1194 | Loss: 292.525 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1010/1194 | Loss: 293.068 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1020/1194 | Loss: 299.296 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1030/1194 | Loss: 296.084 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1040/1194 | Loss: 299.724 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 1050/1194 | Loss: 295.216 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1060/1194 | Loss: 301.668 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1070/1194 | Loss: 299.472 | Accuracy: 0.300\n",
      "[Epoch: 119/200] - Step: 1080/1194 | Loss: 287.296 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1090/1194 | Loss: 274.240 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1100/1194 | Loss: 291.724 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1110/1194 | Loss: 298.700 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1120/1194 | Loss: 300.331 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1130/1194 | Loss: 302.061 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1140/1194 | Loss: 274.691 | Accuracy: 0.400\n",
      "[Epoch: 119/200] - Step: 1150/1194 | Loss: 309.919 | Accuracy: 0.000\n",
      "[Epoch: 119/200] - Step: 1160/1194 | Loss: 288.521 | Accuracy: 0.100\n",
      "[Epoch: 119/200] - Step: 1170/1194 | Loss: 282.425 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1180/1194 | Loss: 291.971 | Accuracy: 0.200\n",
      "[Epoch: 119/200] - Step: 1190/1194 | Loss: 280.074 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 120/200] - Step: 10/1194 | Loss: 291.593 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 20/1194 | Loss: 301.105 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 30/1194 | Loss: 306.755 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 40/1194 | Loss: 278.143 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 50/1194 | Loss: 292.910 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 60/1194 | Loss: 300.912 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 70/1194 | Loss: 294.901 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 80/1194 | Loss: 295.782 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 90/1194 | Loss: 295.680 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 100/1194 | Loss: 303.457 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 110/1194 | Loss: 298.770 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 120/1194 | Loss: 278.431 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 130/1194 | Loss: 306.439 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 140/1194 | Loss: 289.179 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 150/1194 | Loss: 315.955 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 160/1194 | Loss: 325.237 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 170/1194 | Loss: 302.905 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 180/1194 | Loss: 294.371 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 190/1194 | Loss: 292.089 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 200/1194 | Loss: 290.327 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 210/1194 | Loss: 322.779 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 220/1194 | Loss: 307.503 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 230/1194 | Loss: 293.440 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 240/1194 | Loss: 304.829 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 250/1194 | Loss: 308.403 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 260/1194 | Loss: 292.637 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 270/1194 | Loss: 292.284 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 280/1194 | Loss: 297.795 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 290/1194 | Loss: 299.557 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 300/1194 | Loss: 301.382 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 310/1194 | Loss: 278.346 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 320/1194 | Loss: 297.802 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 330/1194 | Loss: 289.169 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 340/1194 | Loss: 295.258 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 350/1194 | Loss: 297.467 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 360/1194 | Loss: 302.662 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 370/1194 | Loss: 291.506 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 380/1194 | Loss: 285.772 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 390/1194 | Loss: 299.232 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 400/1194 | Loss: 303.776 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 410/1194 | Loss: 282.677 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 420/1194 | Loss: 304.297 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 430/1194 | Loss: 308.079 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 440/1194 | Loss: 274.166 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 450/1194 | Loss: 267.358 | Accuracy: 0.400\n",
      "[Epoch: 120/200] - Step: 460/1194 | Loss: 298.164 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 470/1194 | Loss: 294.343 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 480/1194 | Loss: 296.856 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 490/1194 | Loss: 309.806 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 500/1194 | Loss: 280.521 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 510/1194 | Loss: 299.946 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 520/1194 | Loss: 313.798 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 530/1194 | Loss: 290.405 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 540/1194 | Loss: 305.339 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 550/1194 | Loss: 300.037 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 560/1194 | Loss: 290.387 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 570/1194 | Loss: 289.229 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 580/1194 | Loss: 289.308 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 590/1194 | Loss: 287.781 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 600/1194 | Loss: 295.570 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 610/1194 | Loss: 309.827 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 620/1194 | Loss: 297.515 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 630/1194 | Loss: 298.586 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 640/1194 | Loss: 269.559 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 650/1194 | Loss: 293.526 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 660/1194 | Loss: 303.697 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 670/1194 | Loss: 300.340 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 680/1194 | Loss: 294.443 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 690/1194 | Loss: 283.123 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 700/1194 | Loss: 294.413 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 710/1194 | Loss: 292.625 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 720/1194 | Loss: 316.364 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 730/1194 | Loss: 284.054 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 740/1194 | Loss: 300.031 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 750/1194 | Loss: 285.162 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 760/1194 | Loss: 300.051 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 770/1194 | Loss: 287.002 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 780/1194 | Loss: 297.179 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 790/1194 | Loss: 293.323 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 800/1194 | Loss: 297.788 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 810/1194 | Loss: 288.608 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 820/1194 | Loss: 307.129 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 830/1194 | Loss: 286.552 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 840/1194 | Loss: 302.963 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 850/1194 | Loss: 282.115 | Accuracy: 0.300\n",
      "[Epoch: 120/200] - Step: 860/1194 | Loss: 302.990 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 870/1194 | Loss: 302.804 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 880/1194 | Loss: 302.901 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 890/1194 | Loss: 297.179 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 900/1194 | Loss: 282.287 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 910/1194 | Loss: 286.333 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 920/1194 | Loss: 304.360 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 930/1194 | Loss: 273.970 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 940/1194 | Loss: 312.218 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 950/1194 | Loss: 297.859 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 960/1194 | Loss: 291.433 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 970/1194 | Loss: 303.150 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 980/1194 | Loss: 289.157 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 990/1194 | Loss: 300.967 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1000/1194 | Loss: 322.840 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1010/1194 | Loss: 295.069 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1020/1194 | Loss: 303.333 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 1030/1194 | Loss: 308.314 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 1040/1194 | Loss: 302.298 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 1050/1194 | Loss: 311.572 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 1060/1194 | Loss: 302.952 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1070/1194 | Loss: 299.733 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1080/1194 | Loss: 329.796 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1090/1194 | Loss: 292.591 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1100/1194 | Loss: 295.465 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1110/1194 | Loss: 293.867 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1120/1194 | Loss: 287.649 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1130/1194 | Loss: 303.270 | Accuracy: 0.000\n",
      "[Epoch: 120/200] - Step: 1140/1194 | Loss: 294.058 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1150/1194 | Loss: 294.810 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1160/1194 | Loss: 300.910 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1170/1194 | Loss: 290.748 | Accuracy: 0.200\n",
      "[Epoch: 120/200] - Step: 1180/1194 | Loss: 293.203 | Accuracy: 0.100\n",
      "[Epoch: 120/200] - Step: 1190/1194 | Loss: 310.502 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 121/200] - Step: 10/1194 | Loss: 281.363 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 20/1194 | Loss: 305.102 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 30/1194 | Loss: 283.022 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 40/1194 | Loss: 301.160 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 50/1194 | Loss: 316.077 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 60/1194 | Loss: 295.639 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 70/1194 | Loss: 305.286 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 80/1194 | Loss: 300.022 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 90/1194 | Loss: 286.736 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 100/1194 | Loss: 307.396 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 110/1194 | Loss: 291.939 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 120/1194 | Loss: 298.190 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 130/1194 | Loss: 300.667 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 140/1194 | Loss: 304.749 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 150/1194 | Loss: 289.847 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 160/1194 | Loss: 317.318 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 170/1194 | Loss: 313.029 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 180/1194 | Loss: 278.855 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 190/1194 | Loss: 287.374 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 200/1194 | Loss: 294.817 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 210/1194 | Loss: 278.389 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 220/1194 | Loss: 275.378 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 230/1194 | Loss: 298.382 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 240/1194 | Loss: 287.886 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 250/1194 | Loss: 299.422 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 260/1194 | Loss: 287.500 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 270/1194 | Loss: 312.666 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 280/1194 | Loss: 282.579 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 290/1194 | Loss: 297.195 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 300/1194 | Loss: 296.202 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 310/1194 | Loss: 279.262 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 320/1194 | Loss: 329.322 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 330/1194 | Loss: 287.413 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 340/1194 | Loss: 308.195 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 350/1194 | Loss: 290.117 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 360/1194 | Loss: 303.644 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 370/1194 | Loss: 309.388 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 380/1194 | Loss: 286.034 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 390/1194 | Loss: 297.136 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 400/1194 | Loss: 287.131 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 410/1194 | Loss: 311.509 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 420/1194 | Loss: 291.728 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 430/1194 | Loss: 276.584 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 440/1194 | Loss: 298.141 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 450/1194 | Loss: 285.788 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 460/1194 | Loss: 292.169 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 470/1194 | Loss: 297.121 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 480/1194 | Loss: 285.816 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 490/1194 | Loss: 298.955 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 500/1194 | Loss: 297.181 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 510/1194 | Loss: 292.699 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 520/1194 | Loss: 295.663 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 530/1194 | Loss: 284.401 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 540/1194 | Loss: 293.666 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 550/1194 | Loss: 293.512 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 560/1194 | Loss: 303.430 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 570/1194 | Loss: 297.248 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 580/1194 | Loss: 299.375 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 590/1194 | Loss: 300.141 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 600/1194 | Loss: 294.327 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 610/1194 | Loss: 286.576 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 620/1194 | Loss: 305.502 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 630/1194 | Loss: 300.731 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 640/1194 | Loss: 290.467 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 650/1194 | Loss: 300.196 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 660/1194 | Loss: 303.475 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 670/1194 | Loss: 293.257 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 680/1194 | Loss: 297.570 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 690/1194 | Loss: 288.891 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 700/1194 | Loss: 314.090 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 710/1194 | Loss: 311.571 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 720/1194 | Loss: 307.792 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 730/1194 | Loss: 296.497 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 740/1194 | Loss: 293.375 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 750/1194 | Loss: 292.848 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 760/1194 | Loss: 311.084 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 770/1194 | Loss: 289.613 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 780/1194 | Loss: 308.824 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 790/1194 | Loss: 306.627 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 800/1194 | Loss: 288.934 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 810/1194 | Loss: 304.742 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 820/1194 | Loss: 293.841 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 830/1194 | Loss: 310.025 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 840/1194 | Loss: 296.079 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 850/1194 | Loss: 279.427 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 860/1194 | Loss: 287.579 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 870/1194 | Loss: 282.783 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 880/1194 | Loss: 311.183 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 890/1194 | Loss: 298.423 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 900/1194 | Loss: 305.319 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 910/1194 | Loss: 312.945 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 920/1194 | Loss: 299.741 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 930/1194 | Loss: 310.323 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 940/1194 | Loss: 294.684 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 950/1194 | Loss: 307.226 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 960/1194 | Loss: 298.171 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 970/1194 | Loss: 304.063 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 980/1194 | Loss: 277.699 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 990/1194 | Loss: 291.221 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1000/1194 | Loss: 293.332 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 1010/1194 | Loss: 385.609 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1020/1194 | Loss: 278.463 | Accuracy: 0.300\n",
      "[Epoch: 121/200] - Step: 1030/1194 | Loss: 311.733 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1040/1194 | Loss: 293.072 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1050/1194 | Loss: 287.362 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1060/1194 | Loss: 299.310 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 1070/1194 | Loss: 292.563 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1080/1194 | Loss: 289.968 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 1090/1194 | Loss: 297.415 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1100/1194 | Loss: 299.519 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 1110/1194 | Loss: 294.353 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1120/1194 | Loss: 284.994 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1130/1194 | Loss: 290.703 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1140/1194 | Loss: 295.389 | Accuracy: 0.100\n",
      "[Epoch: 121/200] - Step: 1150/1194 | Loss: 287.982 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1160/1194 | Loss: 295.988 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1170/1194 | Loss: 291.319 | Accuracy: 0.200\n",
      "[Epoch: 121/200] - Step: 1180/1194 | Loss: 317.406 | Accuracy: 0.000\n",
      "[Epoch: 121/200] - Step: 1190/1194 | Loss: 281.311 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 122/200] - Step: 10/1194 | Loss: 294.802 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 20/1194 | Loss: 308.957 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 30/1194 | Loss: 283.721 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 40/1194 | Loss: 300.538 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 50/1194 | Loss: 309.529 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 60/1194 | Loss: 289.233 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 70/1194 | Loss: 291.657 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 80/1194 | Loss: 296.550 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 90/1194 | Loss: 308.036 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 100/1194 | Loss: 284.225 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 110/1194 | Loss: 302.498 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 120/1194 | Loss: 306.845 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 130/1194 | Loss: 290.285 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 140/1194 | Loss: 291.996 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 150/1194 | Loss: 298.532 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 160/1194 | Loss: 298.349 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 170/1194 | Loss: 279.255 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 180/1194 | Loss: 313.139 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 190/1194 | Loss: 300.119 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 200/1194 | Loss: 282.130 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 210/1194 | Loss: 299.628 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 220/1194 | Loss: 296.982 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 230/1194 | Loss: 335.474 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 240/1194 | Loss: 310.817 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 250/1194 | Loss: 297.719 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 260/1194 | Loss: 298.136 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 270/1194 | Loss: 288.474 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 280/1194 | Loss: 307.839 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 290/1194 | Loss: 296.717 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 300/1194 | Loss: 291.480 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 310/1194 | Loss: 281.437 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 320/1194 | Loss: 293.622 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 330/1194 | Loss: 296.325 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 340/1194 | Loss: 307.064 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 350/1194 | Loss: 291.672 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 360/1194 | Loss: 314.892 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 370/1194 | Loss: 302.906 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 380/1194 | Loss: 293.638 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 390/1194 | Loss: 289.665 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 400/1194 | Loss: 333.834 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 410/1194 | Loss: 298.146 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 420/1194 | Loss: 285.656 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 430/1194 | Loss: 299.230 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 440/1194 | Loss: 299.705 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 450/1194 | Loss: 306.533 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 460/1194 | Loss: 300.730 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 470/1194 | Loss: 292.668 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 480/1194 | Loss: 275.337 | Accuracy: 0.400\n",
      "[Epoch: 122/200] - Step: 490/1194 | Loss: 297.061 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 500/1194 | Loss: 281.497 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 510/1194 | Loss: 295.831 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 520/1194 | Loss: 295.645 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 530/1194 | Loss: 301.237 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 540/1194 | Loss: 294.421 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 550/1194 | Loss: 280.820 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 560/1194 | Loss: 289.841 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 570/1194 | Loss: 294.858 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 580/1194 | Loss: 302.717 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 590/1194 | Loss: 295.461 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 600/1194 | Loss: 298.623 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 610/1194 | Loss: 287.652 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 620/1194 | Loss: 284.724 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 630/1194 | Loss: 314.144 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 640/1194 | Loss: 283.282 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 650/1194 | Loss: 294.637 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 660/1194 | Loss: 318.569 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 670/1194 | Loss: 306.712 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 680/1194 | Loss: 302.946 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 690/1194 | Loss: 285.566 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 700/1194 | Loss: 269.130 | Accuracy: 0.400\n",
      "[Epoch: 122/200] - Step: 710/1194 | Loss: 307.380 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 720/1194 | Loss: 326.969 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 730/1194 | Loss: 297.675 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 740/1194 | Loss: 297.554 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 750/1194 | Loss: 286.657 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 760/1194 | Loss: 301.405 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 770/1194 | Loss: 302.159 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 780/1194 | Loss: 308.504 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 790/1194 | Loss: 282.730 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 800/1194 | Loss: 300.967 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 810/1194 | Loss: 286.157 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 820/1194 | Loss: 278.677 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 830/1194 | Loss: 302.841 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 840/1194 | Loss: 310.439 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 850/1194 | Loss: 301.672 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 860/1194 | Loss: 288.220 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 870/1194 | Loss: 304.316 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 880/1194 | Loss: 281.880 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 890/1194 | Loss: 306.782 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 900/1194 | Loss: 284.484 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 910/1194 | Loss: 301.629 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 920/1194 | Loss: 304.623 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 930/1194 | Loss: 294.405 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 940/1194 | Loss: 307.275 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 950/1194 | Loss: 269.124 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 960/1194 | Loss: 309.643 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 970/1194 | Loss: 293.154 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 980/1194 | Loss: 289.316 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 990/1194 | Loss: 284.178 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 1000/1194 | Loss: 295.072 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1010/1194 | Loss: 307.552 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 1020/1194 | Loss: 296.331 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1030/1194 | Loss: 286.572 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 1040/1194 | Loss: 289.839 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1050/1194 | Loss: 294.568 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1060/1194 | Loss: 280.134 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1070/1194 | Loss: 301.356 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 1080/1194 | Loss: 300.869 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 1090/1194 | Loss: 300.863 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1100/1194 | Loss: 280.796 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 1110/1194 | Loss: 275.986 | Accuracy: 0.300\n",
      "[Epoch: 122/200] - Step: 1120/1194 | Loss: 308.469 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 1130/1194 | Loss: 324.112 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1140/1194 | Loss: 295.039 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1150/1194 | Loss: 297.071 | Accuracy: 0.000\n",
      "[Epoch: 122/200] - Step: 1160/1194 | Loss: 284.127 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 1170/1194 | Loss: 297.971 | Accuracy: 0.200\n",
      "[Epoch: 122/200] - Step: 1180/1194 | Loss: 330.687 | Accuracy: 0.100\n",
      "[Epoch: 122/200] - Step: 1190/1194 | Loss: 286.039 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 123/200] - Step: 10/1194 | Loss: 305.571 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 20/1194 | Loss: 281.628 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 30/1194 | Loss: 276.388 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 40/1194 | Loss: 310.420 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 50/1194 | Loss: 304.332 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 60/1194 | Loss: 303.615 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 70/1194 | Loss: 304.484 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 80/1194 | Loss: 310.222 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 90/1194 | Loss: 285.937 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 100/1194 | Loss: 306.527 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 110/1194 | Loss: 290.173 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 120/1194 | Loss: 296.142 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 130/1194 | Loss: 309.446 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 140/1194 | Loss: 285.855 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 150/1194 | Loss: 309.058 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 160/1194 | Loss: 302.543 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 170/1194 | Loss: 297.289 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 180/1194 | Loss: 298.261 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 190/1194 | Loss: 293.067 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 200/1194 | Loss: 289.381 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 210/1194 | Loss: 300.581 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 220/1194 | Loss: 300.581 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 230/1194 | Loss: 297.334 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 240/1194 | Loss: 310.201 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 250/1194 | Loss: 298.459 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 260/1194 | Loss: 295.115 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 270/1194 | Loss: 301.327 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 280/1194 | Loss: 307.845 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 290/1194 | Loss: 284.880 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 300/1194 | Loss: 296.376 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 310/1194 | Loss: 299.272 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 320/1194 | Loss: 276.073 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 330/1194 | Loss: 299.773 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 340/1194 | Loss: 296.084 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 350/1194 | Loss: 300.843 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 360/1194 | Loss: 295.995 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 370/1194 | Loss: 281.779 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 380/1194 | Loss: 300.560 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 390/1194 | Loss: 284.952 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 400/1194 | Loss: 306.698 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 410/1194 | Loss: 297.787 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 420/1194 | Loss: 302.242 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 430/1194 | Loss: 308.034 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 440/1194 | Loss: 284.035 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 450/1194 | Loss: 289.922 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 460/1194 | Loss: 306.025 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 470/1194 | Loss: 303.523 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 480/1194 | Loss: 285.311 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 490/1194 | Loss: 315.464 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 500/1194 | Loss: 286.399 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 510/1194 | Loss: 292.898 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 520/1194 | Loss: 279.369 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 530/1194 | Loss: 284.931 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 540/1194 | Loss: 302.313 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 550/1194 | Loss: 312.970 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 560/1194 | Loss: 295.581 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 570/1194 | Loss: 287.252 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 580/1194 | Loss: 292.556 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 590/1194 | Loss: 305.748 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 600/1194 | Loss: 285.805 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 610/1194 | Loss: 299.684 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 620/1194 | Loss: 285.398 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 630/1194 | Loss: 292.377 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 640/1194 | Loss: 304.771 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 650/1194 | Loss: 263.649 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 660/1194 | Loss: 295.907 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 670/1194 | Loss: 280.432 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 680/1194 | Loss: 280.998 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 690/1194 | Loss: 296.995 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 700/1194 | Loss: 265.756 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 710/1194 | Loss: 294.666 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 720/1194 | Loss: 324.395 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 730/1194 | Loss: 295.323 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 740/1194 | Loss: 296.468 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 750/1194 | Loss: 284.100 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 760/1194 | Loss: 302.694 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 770/1194 | Loss: 282.726 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 780/1194 | Loss: 307.387 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 790/1194 | Loss: 294.663 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 800/1194 | Loss: 312.547 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 810/1194 | Loss: 300.955 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 820/1194 | Loss: 303.316 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 830/1194 | Loss: 306.211 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 840/1194 | Loss: 307.690 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 850/1194 | Loss: 296.889 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 860/1194 | Loss: 291.575 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 870/1194 | Loss: 283.924 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 880/1194 | Loss: 341.776 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 890/1194 | Loss: 311.060 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 900/1194 | Loss: 306.361 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 910/1194 | Loss: 311.374 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 920/1194 | Loss: 288.441 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 930/1194 | Loss: 277.512 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 940/1194 | Loss: 292.468 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 950/1194 | Loss: 283.950 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 960/1194 | Loss: 308.166 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 970/1194 | Loss: 310.636 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 980/1194 | Loss: 289.274 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 990/1194 | Loss: 289.508 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1000/1194 | Loss: 294.334 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 1010/1194 | Loss: 323.737 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1020/1194 | Loss: 318.037 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 1030/1194 | Loss: 286.965 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1040/1194 | Loss: 293.053 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1050/1194 | Loss: 297.958 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1060/1194 | Loss: 300.279 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1070/1194 | Loss: 309.286 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 1080/1194 | Loss: 307.808 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1090/1194 | Loss: 281.794 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1100/1194 | Loss: 289.046 | Accuracy: 0.300\n",
      "[Epoch: 123/200] - Step: 1110/1194 | Loss: 310.370 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 1120/1194 | Loss: 301.007 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1130/1194 | Loss: 297.139 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1140/1194 | Loss: 292.295 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1150/1194 | Loss: 303.987 | Accuracy: 0.000\n",
      "[Epoch: 123/200] - Step: 1160/1194 | Loss: 294.740 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1170/1194 | Loss: 303.034 | Accuracy: 0.100\n",
      "[Epoch: 123/200] - Step: 1180/1194 | Loss: 283.576 | Accuracy: 0.200\n",
      "[Epoch: 123/200] - Step: 1190/1194 | Loss: 274.643 | Accuracy: 0.400\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 124/200] - Step: 10/1194 | Loss: 303.982 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 20/1194 | Loss: 280.051 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 30/1194 | Loss: 296.843 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 40/1194 | Loss: 306.460 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 50/1194 | Loss: 326.541 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 60/1194 | Loss: 291.463 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 70/1194 | Loss: 292.936 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 80/1194 | Loss: 275.196 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 90/1194 | Loss: 299.885 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 100/1194 | Loss: 306.267 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 110/1194 | Loss: 302.985 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 120/1194 | Loss: 291.099 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 130/1194 | Loss: 285.468 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 140/1194 | Loss: 290.573 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 150/1194 | Loss: 293.860 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 160/1194 | Loss: 293.317 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 170/1194 | Loss: 308.190 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 180/1194 | Loss: 290.276 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 190/1194 | Loss: 296.160 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 200/1194 | Loss: 291.708 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 210/1194 | Loss: 324.611 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 220/1194 | Loss: 292.599 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 230/1194 | Loss: 284.766 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 240/1194 | Loss: 302.253 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 250/1194 | Loss: 289.597 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 260/1194 | Loss: 291.941 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 270/1194 | Loss: 305.474 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 280/1194 | Loss: 302.992 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 290/1194 | Loss: 290.051 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 300/1194 | Loss: 280.413 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 310/1194 | Loss: 301.957 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 320/1194 | Loss: 302.523 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 330/1194 | Loss: 291.416 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 340/1194 | Loss: 319.757 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 350/1194 | Loss: 310.089 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 360/1194 | Loss: 296.056 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 370/1194 | Loss: 302.537 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 380/1194 | Loss: 294.732 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 390/1194 | Loss: 296.323 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 400/1194 | Loss: 296.187 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 410/1194 | Loss: 301.928 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 420/1194 | Loss: 296.885 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 430/1194 | Loss: 273.002 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 440/1194 | Loss: 326.980 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 450/1194 | Loss: 307.484 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 460/1194 | Loss: 284.895 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 470/1194 | Loss: 316.014 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 480/1194 | Loss: 311.978 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 490/1194 | Loss: 280.458 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 500/1194 | Loss: 293.050 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 510/1194 | Loss: 287.708 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 520/1194 | Loss: 299.274 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 530/1194 | Loss: 270.056 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 540/1194 | Loss: 277.538 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 550/1194 | Loss: 295.462 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 560/1194 | Loss: 308.569 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 570/1194 | Loss: 285.663 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 580/1194 | Loss: 335.202 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 590/1194 | Loss: 301.468 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 600/1194 | Loss: 300.124 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 610/1194 | Loss: 287.528 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 620/1194 | Loss: 292.844 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 630/1194 | Loss: 298.969 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 640/1194 | Loss: 296.424 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 650/1194 | Loss: 280.697 | Accuracy: 0.400\n",
      "[Epoch: 124/200] - Step: 660/1194 | Loss: 308.487 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 670/1194 | Loss: 289.369 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 680/1194 | Loss: 281.797 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 690/1194 | Loss: 287.585 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 700/1194 | Loss: 280.187 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 710/1194 | Loss: 309.891 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 720/1194 | Loss: 301.596 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 730/1194 | Loss: 294.512 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 740/1194 | Loss: 293.726 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 750/1194 | Loss: 307.671 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 760/1194 | Loss: 287.005 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 770/1194 | Loss: 303.272 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 780/1194 | Loss: 311.215 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 790/1194 | Loss: 287.933 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 800/1194 | Loss: 289.386 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 810/1194 | Loss: 292.282 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 820/1194 | Loss: 315.920 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 830/1194 | Loss: 313.397 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 840/1194 | Loss: 298.362 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 850/1194 | Loss: 299.531 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 860/1194 | Loss: 293.140 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 870/1194 | Loss: 299.092 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 880/1194 | Loss: 308.523 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 890/1194 | Loss: 290.223 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 900/1194 | Loss: 306.754 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 910/1194 | Loss: 305.769 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 920/1194 | Loss: 299.420 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 930/1194 | Loss: 279.751 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 940/1194 | Loss: 307.039 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 950/1194 | Loss: 293.677 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 960/1194 | Loss: 288.774 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 970/1194 | Loss: 287.949 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 980/1194 | Loss: 297.377 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 990/1194 | Loss: 302.141 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1000/1194 | Loss: 303.090 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1010/1194 | Loss: 301.135 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1020/1194 | Loss: 279.122 | Accuracy: 0.300\n",
      "[Epoch: 124/200] - Step: 1030/1194 | Loss: 290.399 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1040/1194 | Loss: 303.215 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1050/1194 | Loss: 303.412 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1060/1194 | Loss: 305.381 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1070/1194 | Loss: 302.330 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1080/1194 | Loss: 289.854 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1090/1194 | Loss: 298.787 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1100/1194 | Loss: 290.541 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1110/1194 | Loss: 292.759 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1120/1194 | Loss: 304.880 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1130/1194 | Loss: 290.981 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 1140/1194 | Loss: 295.762 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 1150/1194 | Loss: 291.366 | Accuracy: 0.000\n",
      "[Epoch: 124/200] - Step: 1160/1194 | Loss: 290.132 | Accuracy: 0.200\n",
      "[Epoch: 124/200] - Step: 1170/1194 | Loss: 298.838 | Accuracy: 0.100\n",
      "[Epoch: 124/200] - Step: 1180/1194 | Loss: 264.578 | Accuracy: 0.400\n",
      "[Epoch: 124/200] - Step: 1190/1194 | Loss: 308.447 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 125/200] - Step: 10/1194 | Loss: 285.260 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 20/1194 | Loss: 286.898 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 30/1194 | Loss: 295.869 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 40/1194 | Loss: 297.696 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 50/1194 | Loss: 330.222 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 60/1194 | Loss: 304.915 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 70/1194 | Loss: 299.880 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 80/1194 | Loss: 298.024 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 90/1194 | Loss: 283.676 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 100/1194 | Loss: 301.826 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 110/1194 | Loss: 301.470 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 120/1194 | Loss: 305.076 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 130/1194 | Loss: 307.697 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 140/1194 | Loss: 303.614 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 150/1194 | Loss: 299.977 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 160/1194 | Loss: 309.492 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 170/1194 | Loss: 273.840 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 180/1194 | Loss: 290.203 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 190/1194 | Loss: 291.028 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 200/1194 | Loss: 304.266 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 210/1194 | Loss: 306.504 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 220/1194 | Loss: 281.580 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 230/1194 | Loss: 300.300 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 240/1194 | Loss: 305.299 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 250/1194 | Loss: 283.204 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 260/1194 | Loss: 275.861 | Accuracy: 0.400\n",
      "[Epoch: 125/200] - Step: 270/1194 | Loss: 301.753 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 280/1194 | Loss: 301.228 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 290/1194 | Loss: 309.315 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 300/1194 | Loss: 290.215 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 310/1194 | Loss: 311.150 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 320/1194 | Loss: 293.758 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 330/1194 | Loss: 298.836 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 340/1194 | Loss: 279.921 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 350/1194 | Loss: 291.604 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 360/1194 | Loss: 314.352 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 370/1194 | Loss: 303.910 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 380/1194 | Loss: 283.787 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 390/1194 | Loss: 290.325 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 400/1194 | Loss: 291.504 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 410/1194 | Loss: 278.075 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 420/1194 | Loss: 281.559 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 430/1194 | Loss: 284.393 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 440/1194 | Loss: 284.831 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 450/1194 | Loss: 286.687 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 460/1194 | Loss: 287.810 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 470/1194 | Loss: 298.046 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 480/1194 | Loss: 277.730 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 490/1194 | Loss: 298.884 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 500/1194 | Loss: 262.466 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 510/1194 | Loss: 299.447 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 520/1194 | Loss: 306.863 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 530/1194 | Loss: 288.259 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 540/1194 | Loss: 293.213 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 550/1194 | Loss: 289.389 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 560/1194 | Loss: 315.475 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 570/1194 | Loss: 286.977 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 580/1194 | Loss: 299.423 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 590/1194 | Loss: 309.656 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 600/1194 | Loss: 293.886 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 610/1194 | Loss: 301.231 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 620/1194 | Loss: 304.085 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 630/1194 | Loss: 278.753 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 640/1194 | Loss: 284.382 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 650/1194 | Loss: 301.919 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 660/1194 | Loss: 315.530 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 670/1194 | Loss: 299.381 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 680/1194 | Loss: 275.933 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 690/1194 | Loss: 272.344 | Accuracy: 0.400\n",
      "[Epoch: 125/200] - Step: 700/1194 | Loss: 304.230 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 710/1194 | Loss: 304.582 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 720/1194 | Loss: 275.984 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 730/1194 | Loss: 304.829 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 740/1194 | Loss: 316.033 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 750/1194 | Loss: 287.959 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 760/1194 | Loss: 312.294 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 770/1194 | Loss: 291.362 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 780/1194 | Loss: 329.217 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 790/1194 | Loss: 311.600 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 800/1194 | Loss: 291.817 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 810/1194 | Loss: 299.533 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 820/1194 | Loss: 305.484 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 830/1194 | Loss: 278.221 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 840/1194 | Loss: 287.355 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 850/1194 | Loss: 292.816 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 860/1194 | Loss: 289.112 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 870/1194 | Loss: 310.580 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 880/1194 | Loss: 294.174 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 890/1194 | Loss: 300.208 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 900/1194 | Loss: 329.332 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 910/1194 | Loss: 293.526 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 920/1194 | Loss: 292.140 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 930/1194 | Loss: 286.212 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 940/1194 | Loss: 324.801 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 950/1194 | Loss: 301.102 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 960/1194 | Loss: 300.998 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 970/1194 | Loss: 294.613 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 980/1194 | Loss: 285.003 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 990/1194 | Loss: 295.009 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1000/1194 | Loss: 301.843 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1010/1194 | Loss: 314.179 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1020/1194 | Loss: 311.912 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1030/1194 | Loss: 264.071 | Accuracy: 0.400\n",
      "[Epoch: 125/200] - Step: 1040/1194 | Loss: 301.033 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1050/1194 | Loss: 284.555 | Accuracy: 0.200\n",
      "[Epoch: 125/200] - Step: 1060/1194 | Loss: 310.250 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1070/1194 | Loss: 293.787 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1080/1194 | Loss: 304.529 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1090/1194 | Loss: 303.426 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1100/1194 | Loss: 310.841 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1110/1194 | Loss: 303.342 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1120/1194 | Loss: 304.913 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1130/1194 | Loss: 284.907 | Accuracy: 0.300\n",
      "[Epoch: 125/200] - Step: 1140/1194 | Loss: 298.040 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1150/1194 | Loss: 307.269 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1160/1194 | Loss: 296.601 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1170/1194 | Loss: 310.112 | Accuracy: 0.000\n",
      "[Epoch: 125/200] - Step: 1180/1194 | Loss: 297.738 | Accuracy: 0.100\n",
      "[Epoch: 125/200] - Step: 1190/1194 | Loss: 303.081 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 126/200] - Step: 10/1194 | Loss: 307.686 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 20/1194 | Loss: 299.219 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 30/1194 | Loss: 293.042 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 40/1194 | Loss: 308.879 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 50/1194 | Loss: 294.616 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 60/1194 | Loss: 289.059 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 70/1194 | Loss: 299.932 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 80/1194 | Loss: 292.967 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 90/1194 | Loss: 305.725 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 100/1194 | Loss: 314.237 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 110/1194 | Loss: 295.346 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 120/1194 | Loss: 288.732 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 130/1194 | Loss: 308.349 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 140/1194 | Loss: 294.392 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 150/1194 | Loss: 300.040 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 160/1194 | Loss: 302.577 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 170/1194 | Loss: 301.545 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 180/1194 | Loss: 284.722 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 190/1194 | Loss: 293.085 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 200/1194 | Loss: 292.432 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 210/1194 | Loss: 287.231 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 220/1194 | Loss: 289.667 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 230/1194 | Loss: 319.726 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 240/1194 | Loss: 298.537 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 250/1194 | Loss: 284.028 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 260/1194 | Loss: 289.565 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 270/1194 | Loss: 284.510 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 280/1194 | Loss: 286.974 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 290/1194 | Loss: 296.057 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 300/1194 | Loss: 296.688 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 310/1194 | Loss: 302.518 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 320/1194 | Loss: 267.365 | Accuracy: 0.400\n",
      "[Epoch: 126/200] - Step: 330/1194 | Loss: 315.703 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 340/1194 | Loss: 289.865 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 350/1194 | Loss: 295.741 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 360/1194 | Loss: 289.212 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 370/1194 | Loss: 308.159 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 380/1194 | Loss: 291.425 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 390/1194 | Loss: 262.319 | Accuracy: 0.400\n",
      "[Epoch: 126/200] - Step: 400/1194 | Loss: 289.393 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 410/1194 | Loss: 286.137 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 420/1194 | Loss: 303.513 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 430/1194 | Loss: 301.227 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 440/1194 | Loss: 282.978 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 450/1194 | Loss: 297.735 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 460/1194 | Loss: 299.707 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 470/1194 | Loss: 298.090 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 480/1194 | Loss: 307.642 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 490/1194 | Loss: 293.749 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 500/1194 | Loss: 292.979 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 510/1194 | Loss: 306.089 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 520/1194 | Loss: 292.815 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 530/1194 | Loss: 302.433 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 540/1194 | Loss: 285.029 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 550/1194 | Loss: 308.530 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 560/1194 | Loss: 282.971 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 570/1194 | Loss: 312.535 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 580/1194 | Loss: 296.858 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 590/1194 | Loss: 308.453 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 600/1194 | Loss: 295.720 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 610/1194 | Loss: 294.402 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 620/1194 | Loss: 286.039 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 630/1194 | Loss: 300.191 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 640/1194 | Loss: 299.890 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 650/1194 | Loss: 306.337 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 660/1194 | Loss: 288.080 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 670/1194 | Loss: 306.514 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 680/1194 | Loss: 306.668 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 690/1194 | Loss: 309.402 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 700/1194 | Loss: 314.535 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 710/1194 | Loss: 305.537 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 720/1194 | Loss: 286.699 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 730/1194 | Loss: 287.020 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 740/1194 | Loss: 295.476 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 750/1194 | Loss: 305.147 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 760/1194 | Loss: 289.768 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 770/1194 | Loss: 281.187 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 780/1194 | Loss: 309.927 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 790/1194 | Loss: 286.376 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 800/1194 | Loss: 323.625 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 810/1194 | Loss: 296.508 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 820/1194 | Loss: 277.921 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 830/1194 | Loss: 299.760 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 840/1194 | Loss: 275.691 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 850/1194 | Loss: 299.370 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 860/1194 | Loss: 301.211 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 870/1194 | Loss: 302.870 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 880/1194 | Loss: 311.215 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 890/1194 | Loss: 292.852 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 900/1194 | Loss: 297.259 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 910/1194 | Loss: 298.330 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 920/1194 | Loss: 299.191 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 930/1194 | Loss: 292.569 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 940/1194 | Loss: 301.404 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 950/1194 | Loss: 301.676 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 960/1194 | Loss: 304.768 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 970/1194 | Loss: 300.105 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 980/1194 | Loss: 305.288 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 990/1194 | Loss: 285.802 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1000/1194 | Loss: 297.136 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1010/1194 | Loss: 288.790 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1020/1194 | Loss: 295.340 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1030/1194 | Loss: 296.077 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1040/1194 | Loss: 289.244 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 1050/1194 | Loss: 301.514 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 1060/1194 | Loss: 296.779 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1070/1194 | Loss: 300.842 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1080/1194 | Loss: 287.777 | Accuracy: 0.200\n",
      "[Epoch: 126/200] - Step: 1090/1194 | Loss: 289.169 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1100/1194 | Loss: 280.763 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 1110/1194 | Loss: 314.959 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1120/1194 | Loss: 284.925 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1130/1194 | Loss: 317.878 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1140/1194 | Loss: 333.405 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1150/1194 | Loss: 315.756 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 1160/1194 | Loss: 271.390 | Accuracy: 0.300\n",
      "[Epoch: 126/200] - Step: 1170/1194 | Loss: 298.400 | Accuracy: 0.000\n",
      "[Epoch: 126/200] - Step: 1180/1194 | Loss: 289.307 | Accuracy: 0.100\n",
      "[Epoch: 126/200] - Step: 1190/1194 | Loss: 301.236 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 127/200] - Step: 10/1194 | Loss: 295.242 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 20/1194 | Loss: 284.673 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 30/1194 | Loss: 306.272 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 40/1194 | Loss: 290.121 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 50/1194 | Loss: 310.495 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 60/1194 | Loss: 288.100 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 70/1194 | Loss: 292.005 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 80/1194 | Loss: 288.032 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 90/1194 | Loss: 305.300 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 100/1194 | Loss: 293.180 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 110/1194 | Loss: 299.202 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 120/1194 | Loss: 356.357 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 130/1194 | Loss: 305.921 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 140/1194 | Loss: 278.452 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 150/1194 | Loss: 285.168 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 160/1194 | Loss: 303.968 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 170/1194 | Loss: 264.903 | Accuracy: 0.400\n",
      "[Epoch: 127/200] - Step: 180/1194 | Loss: 293.775 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 190/1194 | Loss: 292.879 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 200/1194 | Loss: 337.304 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 210/1194 | Loss: 312.653 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 220/1194 | Loss: 298.518 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 230/1194 | Loss: 287.290 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 240/1194 | Loss: 294.208 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 250/1194 | Loss: 301.075 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 260/1194 | Loss: 290.023 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 270/1194 | Loss: 294.753 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 280/1194 | Loss: 291.086 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 290/1194 | Loss: 290.844 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 300/1194 | Loss: 277.939 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 310/1194 | Loss: 310.410 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 320/1194 | Loss: 296.685 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 330/1194 | Loss: 300.999 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 340/1194 | Loss: 299.655 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 350/1194 | Loss: 302.781 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 360/1194 | Loss: 277.076 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 370/1194 | Loss: 296.148 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 380/1194 | Loss: 303.311 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 390/1194 | Loss: 277.352 | Accuracy: 0.400\n",
      "[Epoch: 127/200] - Step: 400/1194 | Loss: 290.359 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 410/1194 | Loss: 332.845 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 420/1194 | Loss: 298.352 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 430/1194 | Loss: 289.807 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 440/1194 | Loss: 305.677 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 450/1194 | Loss: 301.294 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 460/1194 | Loss: 305.604 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 470/1194 | Loss: 303.240 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 480/1194 | Loss: 299.080 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 490/1194 | Loss: 310.922 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 500/1194 | Loss: 296.020 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 510/1194 | Loss: 301.118 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 520/1194 | Loss: 295.929 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 530/1194 | Loss: 298.750 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 540/1194 | Loss: 279.265 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 550/1194 | Loss: 312.909 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 560/1194 | Loss: 311.368 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 570/1194 | Loss: 304.107 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 580/1194 | Loss: 301.469 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 590/1194 | Loss: 294.379 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 600/1194 | Loss: 297.823 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 610/1194 | Loss: 294.520 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 620/1194 | Loss: 301.448 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 630/1194 | Loss: 299.586 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 640/1194 | Loss: 275.709 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 650/1194 | Loss: 300.995 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 660/1194 | Loss: 287.077 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 670/1194 | Loss: 298.132 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 680/1194 | Loss: 288.537 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 690/1194 | Loss: 285.751 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 700/1194 | Loss: 283.134 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 710/1194 | Loss: 286.440 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 720/1194 | Loss: 292.606 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 730/1194 | Loss: 303.354 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 740/1194 | Loss: 311.287 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 750/1194 | Loss: 315.587 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 760/1194 | Loss: 310.412 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 770/1194 | Loss: 299.401 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 780/1194 | Loss: 301.446 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 790/1194 | Loss: 303.462 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 800/1194 | Loss: 299.472 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 810/1194 | Loss: 295.711 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 820/1194 | Loss: 293.232 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 830/1194 | Loss: 310.625 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 840/1194 | Loss: 300.442 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 850/1194 | Loss: 283.174 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 860/1194 | Loss: 287.793 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 870/1194 | Loss: 297.286 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 880/1194 | Loss: 307.015 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 890/1194 | Loss: 276.272 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 900/1194 | Loss: 295.261 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 910/1194 | Loss: 311.986 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 920/1194 | Loss: 298.971 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 930/1194 | Loss: 299.185 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 940/1194 | Loss: 306.803 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 950/1194 | Loss: 291.905 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 960/1194 | Loss: 285.550 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 970/1194 | Loss: 308.776 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 980/1194 | Loss: 297.508 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 990/1194 | Loss: 302.375 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1000/1194 | Loss: 294.473 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 1010/1194 | Loss: 294.325 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 1020/1194 | Loss: 284.710 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 1030/1194 | Loss: 296.031 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1040/1194 | Loss: 306.640 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 1050/1194 | Loss: 296.383 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1060/1194 | Loss: 300.502 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1070/1194 | Loss: 287.906 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1080/1194 | Loss: 309.126 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 1090/1194 | Loss: 275.112 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 1100/1194 | Loss: 292.259 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1110/1194 | Loss: 281.846 | Accuracy: 0.200\n",
      "[Epoch: 127/200] - Step: 1120/1194 | Loss: 270.386 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 1130/1194 | Loss: 297.109 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 1140/1194 | Loss: 301.890 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 1150/1194 | Loss: 271.007 | Accuracy: 0.300\n",
      "[Epoch: 127/200] - Step: 1160/1194 | Loss: 296.743 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1170/1194 | Loss: 296.074 | Accuracy: 0.100\n",
      "[Epoch: 127/200] - Step: 1180/1194 | Loss: 296.002 | Accuracy: 0.000\n",
      "[Epoch: 127/200] - Step: 1190/1194 | Loss: 286.055 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 128/200] - Step: 10/1194 | Loss: 294.983 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 20/1194 | Loss: 306.605 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 30/1194 | Loss: 290.544 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 40/1194 | Loss: 306.315 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 50/1194 | Loss: 315.005 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 60/1194 | Loss: 294.837 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 70/1194 | Loss: 282.984 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 80/1194 | Loss: 295.982 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 90/1194 | Loss: 307.902 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 100/1194 | Loss: 284.588 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 110/1194 | Loss: 286.655 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 120/1194 | Loss: 309.940 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 130/1194 | Loss: 293.975 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 140/1194 | Loss: 322.636 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 150/1194 | Loss: 288.637 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 160/1194 | Loss: 299.783 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 170/1194 | Loss: 297.232 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 180/1194 | Loss: 312.331 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 190/1194 | Loss: 294.498 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 200/1194 | Loss: 297.985 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 210/1194 | Loss: 279.549 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 220/1194 | Loss: 297.030 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 230/1194 | Loss: 317.470 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 240/1194 | Loss: 291.336 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 250/1194 | Loss: 297.748 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 260/1194 | Loss: 307.913 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 270/1194 | Loss: 295.239 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 280/1194 | Loss: 296.203 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 290/1194 | Loss: 284.426 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 300/1194 | Loss: 290.427 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 310/1194 | Loss: 305.140 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 320/1194 | Loss: 299.644 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 330/1194 | Loss: 302.816 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 340/1194 | Loss: 273.775 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 350/1194 | Loss: 312.020 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 360/1194 | Loss: 276.869 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 370/1194 | Loss: 293.212 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 380/1194 | Loss: 286.374 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 390/1194 | Loss: 314.221 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 400/1194 | Loss: 292.922 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 410/1194 | Loss: 276.788 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 420/1194 | Loss: 297.817 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 430/1194 | Loss: 299.909 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 440/1194 | Loss: 306.569 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 450/1194 | Loss: 307.697 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 460/1194 | Loss: 292.981 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 470/1194 | Loss: 296.960 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 480/1194 | Loss: 287.495 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 490/1194 | Loss: 287.835 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 500/1194 | Loss: 303.479 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 510/1194 | Loss: 266.036 | Accuracy: 0.400\n",
      "[Epoch: 128/200] - Step: 520/1194 | Loss: 270.160 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 530/1194 | Loss: 284.762 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 540/1194 | Loss: 293.237 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 550/1194 | Loss: 294.201 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 560/1194 | Loss: 303.317 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 570/1194 | Loss: 307.661 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 580/1194 | Loss: 306.092 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 590/1194 | Loss: 299.602 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 600/1194 | Loss: 279.629 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 610/1194 | Loss: 289.224 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 620/1194 | Loss: 295.887 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 630/1194 | Loss: 273.967 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 640/1194 | Loss: 296.852 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 650/1194 | Loss: 291.620 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 660/1194 | Loss: 311.755 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 670/1194 | Loss: 308.399 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 680/1194 | Loss: 317.063 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 690/1194 | Loss: 298.890 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 700/1194 | Loss: 327.279 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 710/1194 | Loss: 290.130 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 720/1194 | Loss: 306.790 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 730/1194 | Loss: 302.532 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 740/1194 | Loss: 292.430 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 750/1194 | Loss: 283.137 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 760/1194 | Loss: 301.122 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 770/1194 | Loss: 291.705 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 780/1194 | Loss: 331.175 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 790/1194 | Loss: 291.290 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 800/1194 | Loss: 315.023 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 810/1194 | Loss: 318.192 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 820/1194 | Loss: 277.260 | Accuracy: 0.400\n",
      "[Epoch: 128/200] - Step: 830/1194 | Loss: 298.460 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 840/1194 | Loss: 312.155 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 850/1194 | Loss: 291.459 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 860/1194 | Loss: 301.314 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 870/1194 | Loss: 292.114 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 880/1194 | Loss: 298.246 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 890/1194 | Loss: 284.808 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 900/1194 | Loss: 298.936 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 910/1194 | Loss: 283.470 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 920/1194 | Loss: 297.041 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 930/1194 | Loss: 285.843 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 940/1194 | Loss: 274.265 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 950/1194 | Loss: 303.539 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 960/1194 | Loss: 309.591 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 970/1194 | Loss: 303.861 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 980/1194 | Loss: 308.969 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 990/1194 | Loss: 300.530 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1000/1194 | Loss: 282.095 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1010/1194 | Loss: 308.217 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1020/1194 | Loss: 295.006 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 1030/1194 | Loss: 316.692 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1040/1194 | Loss: 296.768 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1050/1194 | Loss: 281.893 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1060/1194 | Loss: 286.254 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1070/1194 | Loss: 319.029 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1080/1194 | Loss: 304.047 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1090/1194 | Loss: 277.104 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1100/1194 | Loss: 293.796 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1110/1194 | Loss: 277.588 | Accuracy: 0.300\n",
      "[Epoch: 128/200] - Step: 1120/1194 | Loss: 337.333 | Accuracy: 0.000\n",
      "[Epoch: 128/200] - Step: 1130/1194 | Loss: 291.084 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1140/1194 | Loss: 291.528 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 1150/1194 | Loss: 297.454 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 1160/1194 | Loss: 302.650 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 1170/1194 | Loss: 291.565 | Accuracy: 0.200\n",
      "[Epoch: 128/200] - Step: 1180/1194 | Loss: 287.441 | Accuracy: 0.100\n",
      "[Epoch: 128/200] - Step: 1190/1194 | Loss: 291.096 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 129/200] - Step: 10/1194 | Loss: 301.410 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 20/1194 | Loss: 285.753 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 30/1194 | Loss: 302.436 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 40/1194 | Loss: 294.974 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 50/1194 | Loss: 303.789 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 60/1194 | Loss: 315.831 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 70/1194 | Loss: 276.717 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 80/1194 | Loss: 262.650 | Accuracy: 0.500\n",
      "[Epoch: 129/200] - Step: 90/1194 | Loss: 302.381 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 100/1194 | Loss: 310.228 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 110/1194 | Loss: 304.437 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 120/1194 | Loss: 298.034 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 130/1194 | Loss: 297.570 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 140/1194 | Loss: 309.803 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 150/1194 | Loss: 299.621 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 160/1194 | Loss: 285.229 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 170/1194 | Loss: 314.817 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 180/1194 | Loss: 291.011 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 190/1194 | Loss: 292.847 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 200/1194 | Loss: 297.948 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 210/1194 | Loss: 308.940 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 220/1194 | Loss: 305.067 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 230/1194 | Loss: 304.871 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 240/1194 | Loss: 298.523 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 250/1194 | Loss: 336.554 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 260/1194 | Loss: 287.776 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 270/1194 | Loss: 312.481 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 280/1194 | Loss: 327.085 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 290/1194 | Loss: 275.656 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 300/1194 | Loss: 279.773 | Accuracy: 0.400\n",
      "[Epoch: 129/200] - Step: 310/1194 | Loss: 295.953 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 320/1194 | Loss: 282.177 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 330/1194 | Loss: 298.666 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 340/1194 | Loss: 314.828 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 350/1194 | Loss: 287.214 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 360/1194 | Loss: 278.103 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 370/1194 | Loss: 296.001 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 380/1194 | Loss: 299.884 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 390/1194 | Loss: 290.168 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 400/1194 | Loss: 288.083 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 410/1194 | Loss: 292.318 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 420/1194 | Loss: 281.334 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 430/1194 | Loss: 300.219 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 440/1194 | Loss: 313.045 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 450/1194 | Loss: 335.211 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 460/1194 | Loss: 293.609 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 470/1194 | Loss: 299.176 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 480/1194 | Loss: 303.798 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 490/1194 | Loss: 301.690 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 500/1194 | Loss: 289.380 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 510/1194 | Loss: 300.502 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 520/1194 | Loss: 286.670 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 530/1194 | Loss: 289.539 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 540/1194 | Loss: 295.802 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 550/1194 | Loss: 277.432 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 560/1194 | Loss: 277.592 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 570/1194 | Loss: 274.473 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 580/1194 | Loss: 302.405 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 590/1194 | Loss: 295.843 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 600/1194 | Loss: 304.144 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 610/1194 | Loss: 290.197 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 620/1194 | Loss: 298.601 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 630/1194 | Loss: 274.243 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 640/1194 | Loss: 309.225 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 650/1194 | Loss: 287.193 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 660/1194 | Loss: 313.291 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 670/1194 | Loss: 299.328 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 680/1194 | Loss: 292.209 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 690/1194 | Loss: 293.965 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 700/1194 | Loss: 286.562 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 710/1194 | Loss: 299.290 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 720/1194 | Loss: 299.699 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 730/1194 | Loss: 290.309 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 740/1194 | Loss: 299.735 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 750/1194 | Loss: 276.772 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 760/1194 | Loss: 293.649 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 770/1194 | Loss: 301.220 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 780/1194 | Loss: 303.161 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 790/1194 | Loss: 285.753 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 800/1194 | Loss: 307.433 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 810/1194 | Loss: 279.129 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 820/1194 | Loss: 285.036 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 830/1194 | Loss: 318.015 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 840/1194 | Loss: 290.372 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 850/1194 | Loss: 300.781 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 860/1194 | Loss: 302.235 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 870/1194 | Loss: 291.572 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 880/1194 | Loss: 298.729 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 890/1194 | Loss: 313.467 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 900/1194 | Loss: 287.406 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 910/1194 | Loss: 300.044 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 920/1194 | Loss: 299.404 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 930/1194 | Loss: 298.528 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 940/1194 | Loss: 291.578 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 950/1194 | Loss: 299.014 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 960/1194 | Loss: 290.756 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 970/1194 | Loss: 297.524 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 980/1194 | Loss: 298.099 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 990/1194 | Loss: 297.330 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1000/1194 | Loss: 304.053 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 1010/1194 | Loss: 285.667 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1020/1194 | Loss: 292.094 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1030/1194 | Loss: 317.405 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 1040/1194 | Loss: 298.605 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1050/1194 | Loss: 302.466 | Accuracy: 0.300\n",
      "[Epoch: 129/200] - Step: 1060/1194 | Loss: 312.001 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1070/1194 | Loss: 297.706 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1080/1194 | Loss: 301.930 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1090/1194 | Loss: 313.129 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 1100/1194 | Loss: 290.658 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1110/1194 | Loss: 294.636 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1120/1194 | Loss: 291.077 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1130/1194 | Loss: 305.967 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1140/1194 | Loss: 292.540 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1150/1194 | Loss: 296.413 | Accuracy: 0.000\n",
      "[Epoch: 129/200] - Step: 1160/1194 | Loss: 295.209 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1170/1194 | Loss: 288.743 | Accuracy: 0.100\n",
      "[Epoch: 129/200] - Step: 1180/1194 | Loss: 287.806 | Accuracy: 0.200\n",
      "[Epoch: 129/200] - Step: 1190/1194 | Loss: 293.740 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 130/200] - Step: 10/1194 | Loss: 271.901 | Accuracy: 0.400\n",
      "[Epoch: 130/200] - Step: 20/1194 | Loss: 281.292 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 30/1194 | Loss: 306.762 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 40/1194 | Loss: 294.005 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 50/1194 | Loss: 287.843 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 60/1194 | Loss: 281.022 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 70/1194 | Loss: 298.129 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 80/1194 | Loss: 289.391 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 90/1194 | Loss: 275.580 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 100/1194 | Loss: 298.035 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 110/1194 | Loss: 294.158 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 120/1194 | Loss: 293.803 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 130/1194 | Loss: 311.599 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 140/1194 | Loss: 295.021 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 150/1194 | Loss: 315.024 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 160/1194 | Loss: 291.564 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 170/1194 | Loss: 304.211 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 180/1194 | Loss: 288.821 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 190/1194 | Loss: 306.172 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 200/1194 | Loss: 303.895 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 210/1194 | Loss: 308.396 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 220/1194 | Loss: 287.270 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 230/1194 | Loss: 299.057 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 240/1194 | Loss: 279.517 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 250/1194 | Loss: 333.008 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 260/1194 | Loss: 282.989 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 270/1194 | Loss: 301.081 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 280/1194 | Loss: 295.397 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 290/1194 | Loss: 295.982 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 300/1194 | Loss: 299.193 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 310/1194 | Loss: 313.194 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 320/1194 | Loss: 316.130 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 330/1194 | Loss: 278.482 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 340/1194 | Loss: 279.664 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 350/1194 | Loss: 288.449 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 360/1194 | Loss: 273.549 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 370/1194 | Loss: 301.890 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 380/1194 | Loss: 292.933 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 390/1194 | Loss: 310.077 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 400/1194 | Loss: 307.966 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 410/1194 | Loss: 291.071 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 420/1194 | Loss: 298.173 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 430/1194 | Loss: 301.928 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 440/1194 | Loss: 293.437 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 450/1194 | Loss: 302.133 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 460/1194 | Loss: 307.921 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 470/1194 | Loss: 291.239 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 480/1194 | Loss: 295.491 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 490/1194 | Loss: 281.197 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 500/1194 | Loss: 302.266 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 510/1194 | Loss: 293.402 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 520/1194 | Loss: 282.000 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 530/1194 | Loss: 297.219 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 540/1194 | Loss: 292.167 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 550/1194 | Loss: 293.373 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 560/1194 | Loss: 317.037 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 570/1194 | Loss: 287.433 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 580/1194 | Loss: 298.708 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 590/1194 | Loss: 301.046 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 600/1194 | Loss: 291.049 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 610/1194 | Loss: 292.992 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 620/1194 | Loss: 305.668 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 630/1194 | Loss: 304.466 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 640/1194 | Loss: 289.085 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 650/1194 | Loss: 289.010 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 660/1194 | Loss: 285.707 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 670/1194 | Loss: 294.884 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 680/1194 | Loss: 292.977 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 690/1194 | Loss: 313.409 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 700/1194 | Loss: 278.353 | Accuracy: 0.400\n",
      "[Epoch: 130/200] - Step: 710/1194 | Loss: 284.082 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 720/1194 | Loss: 299.330 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 730/1194 | Loss: 324.484 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 740/1194 | Loss: 287.267 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 750/1194 | Loss: 288.308 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 760/1194 | Loss: 302.688 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 770/1194 | Loss: 296.367 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 780/1194 | Loss: 300.523 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 790/1194 | Loss: 310.930 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 800/1194 | Loss: 290.932 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 810/1194 | Loss: 282.711 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 820/1194 | Loss: 318.176 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 830/1194 | Loss: 306.263 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 840/1194 | Loss: 291.965 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 850/1194 | Loss: 307.920 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 860/1194 | Loss: 306.369 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 870/1194 | Loss: 290.716 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 880/1194 | Loss: 302.608 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 890/1194 | Loss: 296.576 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 900/1194 | Loss: 298.023 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 910/1194 | Loss: 295.931 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 920/1194 | Loss: 305.697 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 930/1194 | Loss: 291.954 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 940/1194 | Loss: 306.360 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 950/1194 | Loss: 274.554 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 960/1194 | Loss: 297.053 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 970/1194 | Loss: 289.639 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 980/1194 | Loss: 335.847 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 990/1194 | Loss: 313.719 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1000/1194 | Loss: 296.417 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1010/1194 | Loss: 281.714 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 1020/1194 | Loss: 293.619 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1030/1194 | Loss: 295.886 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1040/1194 | Loss: 298.271 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1050/1194 | Loss: 303.104 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1060/1194 | Loss: 292.303 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1070/1194 | Loss: 309.156 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1080/1194 | Loss: 300.847 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1090/1194 | Loss: 279.030 | Accuracy: 0.300\n",
      "[Epoch: 130/200] - Step: 1100/1194 | Loss: 281.552 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 1110/1194 | Loss: 282.228 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 1120/1194 | Loss: 326.581 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1130/1194 | Loss: 303.272 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1140/1194 | Loss: 279.899 | Accuracy: 0.200\n",
      "[Epoch: 130/200] - Step: 1150/1194 | Loss: 294.903 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1160/1194 | Loss: 296.613 | Accuracy: 0.100\n",
      "[Epoch: 130/200] - Step: 1170/1194 | Loss: 319.864 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1180/1194 | Loss: 309.322 | Accuracy: 0.000\n",
      "[Epoch: 130/200] - Step: 1190/1194 | Loss: 290.448 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 131/200] - Step: 10/1194 | Loss: 303.086 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 20/1194 | Loss: 286.708 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 30/1194 | Loss: 303.558 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 40/1194 | Loss: 280.125 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 50/1194 | Loss: 311.465 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 60/1194 | Loss: 303.893 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 70/1194 | Loss: 286.057 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 80/1194 | Loss: 284.788 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 90/1194 | Loss: 300.983 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 100/1194 | Loss: 291.261 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 110/1194 | Loss: 320.826 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 120/1194 | Loss: 298.543 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 130/1194 | Loss: 282.215 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 140/1194 | Loss: 280.413 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 150/1194 | Loss: 297.503 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 160/1194 | Loss: 288.225 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 170/1194 | Loss: 297.067 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 180/1194 | Loss: 287.002 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 190/1194 | Loss: 297.093 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 200/1194 | Loss: 285.481 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 210/1194 | Loss: 296.966 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 220/1194 | Loss: 319.307 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 230/1194 | Loss: 286.062 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 240/1194 | Loss: 296.565 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 250/1194 | Loss: 302.032 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 260/1194 | Loss: 286.744 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 270/1194 | Loss: 290.221 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 280/1194 | Loss: 301.651 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 290/1194 | Loss: 292.779 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 300/1194 | Loss: 303.900 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 310/1194 | Loss: 277.945 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 320/1194 | Loss: 279.274 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 330/1194 | Loss: 288.907 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 340/1194 | Loss: 304.774 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 350/1194 | Loss: 314.081 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 360/1194 | Loss: 292.043 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 370/1194 | Loss: 286.225 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 380/1194 | Loss: 290.952 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 390/1194 | Loss: 307.442 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 400/1194 | Loss: 290.241 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 410/1194 | Loss: 292.601 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 420/1194 | Loss: 291.806 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 430/1194 | Loss: 321.385 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 440/1194 | Loss: 279.297 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 450/1194 | Loss: 285.206 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 460/1194 | Loss: 332.679 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 470/1194 | Loss: 307.967 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 480/1194 | Loss: 290.875 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 490/1194 | Loss: 300.779 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 500/1194 | Loss: 299.884 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 510/1194 | Loss: 299.778 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 520/1194 | Loss: 297.488 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 530/1194 | Loss: 271.666 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 540/1194 | Loss: 294.093 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 550/1194 | Loss: 295.469 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 560/1194 | Loss: 295.947 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 570/1194 | Loss: 305.965 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 580/1194 | Loss: 296.497 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 590/1194 | Loss: 281.076 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 600/1194 | Loss: 293.495 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 610/1194 | Loss: 278.397 | Accuracy: 0.400\n",
      "[Epoch: 131/200] - Step: 620/1194 | Loss: 278.578 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 630/1194 | Loss: 304.933 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 640/1194 | Loss: 323.968 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 650/1194 | Loss: 297.085 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 660/1194 | Loss: 292.436 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 670/1194 | Loss: 311.147 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 680/1194 | Loss: 303.217 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 690/1194 | Loss: 289.119 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 700/1194 | Loss: 273.381 | Accuracy: 0.400\n",
      "[Epoch: 131/200] - Step: 710/1194 | Loss: 296.517 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 720/1194 | Loss: 314.171 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 730/1194 | Loss: 288.695 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 740/1194 | Loss: 274.278 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 750/1194 | Loss: 307.629 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 760/1194 | Loss: 291.707 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 770/1194 | Loss: 276.453 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 780/1194 | Loss: 300.367 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 790/1194 | Loss: 312.553 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 800/1194 | Loss: 307.437 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 810/1194 | Loss: 295.541 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 820/1194 | Loss: 295.774 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 830/1194 | Loss: 312.111 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 840/1194 | Loss: 283.818 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 850/1194 | Loss: 301.979 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 860/1194 | Loss: 300.158 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 870/1194 | Loss: 301.027 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 880/1194 | Loss: 334.185 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 890/1194 | Loss: 299.232 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 900/1194 | Loss: 279.661 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 910/1194 | Loss: 296.662 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 920/1194 | Loss: 290.708 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 930/1194 | Loss: 296.358 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 940/1194 | Loss: 293.958 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 950/1194 | Loss: 306.575 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 960/1194 | Loss: 303.568 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 970/1194 | Loss: 295.578 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 980/1194 | Loss: 299.041 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 990/1194 | Loss: 296.872 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1000/1194 | Loss: 303.865 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1010/1194 | Loss: 296.646 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 1020/1194 | Loss: 301.790 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1030/1194 | Loss: 318.276 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 1040/1194 | Loss: 292.059 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 1050/1194 | Loss: 327.365 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 1060/1194 | Loss: 282.094 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 1070/1194 | Loss: 322.810 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1080/1194 | Loss: 296.661 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1090/1194 | Loss: 307.339 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 1100/1194 | Loss: 275.072 | Accuracy: 0.300\n",
      "[Epoch: 131/200] - Step: 1110/1194 | Loss: 309.720 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 1120/1194 | Loss: 307.418 | Accuracy: 0.000\n",
      "[Epoch: 131/200] - Step: 1130/1194 | Loss: 293.248 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1140/1194 | Loss: 287.878 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1150/1194 | Loss: 291.147 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 1160/1194 | Loss: 287.148 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1170/1194 | Loss: 292.894 | Accuracy: 0.100\n",
      "[Epoch: 131/200] - Step: 1180/1194 | Loss: 292.085 | Accuracy: 0.200\n",
      "[Epoch: 131/200] - Step: 1190/1194 | Loss: 316.994 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 132/200] - Step: 10/1194 | Loss: 281.983 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 20/1194 | Loss: 276.780 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 30/1194 | Loss: 280.565 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 40/1194 | Loss: 294.547 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 50/1194 | Loss: 290.110 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 60/1194 | Loss: 304.510 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 70/1194 | Loss: 295.506 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 80/1194 | Loss: 315.866 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 90/1194 | Loss: 299.615 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 100/1194 | Loss: 293.695 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 110/1194 | Loss: 288.150 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 120/1194 | Loss: 285.646 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 130/1194 | Loss: 295.566 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 140/1194 | Loss: 315.283 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 150/1194 | Loss: 286.060 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 160/1194 | Loss: 280.170 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 170/1194 | Loss: 313.771 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 180/1194 | Loss: 291.990 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 190/1194 | Loss: 310.167 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 200/1194 | Loss: 295.836 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 210/1194 | Loss: 303.414 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 220/1194 | Loss: 285.939 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 230/1194 | Loss: 304.307 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 240/1194 | Loss: 310.275 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 250/1194 | Loss: 290.708 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 260/1194 | Loss: 298.958 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 270/1194 | Loss: 294.779 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 280/1194 | Loss: 300.834 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 290/1194 | Loss: 290.292 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 300/1194 | Loss: 277.918 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 310/1194 | Loss: 298.841 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 320/1194 | Loss: 294.745 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 330/1194 | Loss: 298.881 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 340/1194 | Loss: 291.529 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 350/1194 | Loss: 299.428 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 360/1194 | Loss: 280.484 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 370/1194 | Loss: 330.088 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 380/1194 | Loss: 295.862 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 390/1194 | Loss: 310.018 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 400/1194 | Loss: 293.721 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 410/1194 | Loss: 304.174 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 420/1194 | Loss: 302.548 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 430/1194 | Loss: 288.923 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 440/1194 | Loss: 308.302 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 450/1194 | Loss: 297.622 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 460/1194 | Loss: 306.936 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 470/1194 | Loss: 325.814 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 480/1194 | Loss: 291.903 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 490/1194 | Loss: 299.503 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 500/1194 | Loss: 294.319 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 510/1194 | Loss: 310.634 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 520/1194 | Loss: 286.747 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 530/1194 | Loss: 294.854 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 540/1194 | Loss: 307.663 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 550/1194 | Loss: 296.394 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 560/1194 | Loss: 306.230 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 570/1194 | Loss: 306.399 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 580/1194 | Loss: 287.516 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 590/1194 | Loss: 281.856 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 600/1194 | Loss: 274.044 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 610/1194 | Loss: 307.100 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 620/1194 | Loss: 274.231 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 630/1194 | Loss: 303.628 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 640/1194 | Loss: 304.587 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 650/1194 | Loss: 302.846 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 660/1194 | Loss: 294.801 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 670/1194 | Loss: 302.481 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 680/1194 | Loss: 295.006 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 690/1194 | Loss: 291.434 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 700/1194 | Loss: 301.627 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 710/1194 | Loss: 293.786 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 720/1194 | Loss: 291.620 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 730/1194 | Loss: 301.592 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 740/1194 | Loss: 290.268 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 750/1194 | Loss: 293.753 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 760/1194 | Loss: 304.953 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 770/1194 | Loss: 301.900 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 780/1194 | Loss: 308.199 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 790/1194 | Loss: 315.341 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 800/1194 | Loss: 307.895 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 810/1194 | Loss: 289.557 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 820/1194 | Loss: 270.616 | Accuracy: 0.400\n",
      "[Epoch: 132/200] - Step: 830/1194 | Loss: 299.588 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 840/1194 | Loss: 305.834 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 850/1194 | Loss: 273.793 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 860/1194 | Loss: 293.013 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 870/1194 | Loss: 276.419 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 880/1194 | Loss: 289.523 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 890/1194 | Loss: 282.069 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 900/1194 | Loss: 301.243 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 910/1194 | Loss: 296.844 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 920/1194 | Loss: 271.517 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 930/1194 | Loss: 299.650 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 940/1194 | Loss: 302.824 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 950/1194 | Loss: 286.279 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 960/1194 | Loss: 313.731 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 970/1194 | Loss: 333.810 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 980/1194 | Loss: 298.898 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 990/1194 | Loss: 276.939 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 1000/1194 | Loss: 300.612 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 1010/1194 | Loss: 311.490 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1020/1194 | Loss: 297.577 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 1030/1194 | Loss: 281.244 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 1040/1194 | Loss: 305.692 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1050/1194 | Loss: 299.758 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 1060/1194 | Loss: 307.285 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1070/1194 | Loss: 299.198 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1080/1194 | Loss: 290.474 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 1090/1194 | Loss: 271.015 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 1100/1194 | Loss: 284.553 | Accuracy: 0.100\n",
      "[Epoch: 132/200] - Step: 1110/1194 | Loss: 311.396 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1120/1194 | Loss: 298.274 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1130/1194 | Loss: 318.255 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1140/1194 | Loss: 290.654 | Accuracy: 0.200\n",
      "[Epoch: 132/200] - Step: 1150/1194 | Loss: 307.872 | Accuracy: 0.300\n",
      "[Epoch: 132/200] - Step: 1160/1194 | Loss: 295.315 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1170/1194 | Loss: 306.463 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1180/1194 | Loss: 293.671 | Accuracy: 0.000\n",
      "[Epoch: 132/200] - Step: 1190/1194 | Loss: 294.697 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 133/200] - Step: 10/1194 | Loss: 296.007 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 20/1194 | Loss: 286.495 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 30/1194 | Loss: 298.192 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 40/1194 | Loss: 291.875 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 50/1194 | Loss: 304.855 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 60/1194 | Loss: 299.012 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 70/1194 | Loss: 333.976 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 80/1194 | Loss: 305.539 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 90/1194 | Loss: 306.223 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 100/1194 | Loss: 302.693 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 110/1194 | Loss: 287.258 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 120/1194 | Loss: 303.051 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 130/1194 | Loss: 290.298 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 140/1194 | Loss: 302.901 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 150/1194 | Loss: 284.792 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 160/1194 | Loss: 321.937 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 170/1194 | Loss: 267.199 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 180/1194 | Loss: 285.895 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 190/1194 | Loss: 303.041 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 200/1194 | Loss: 310.499 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 210/1194 | Loss: 302.346 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 220/1194 | Loss: 316.668 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 230/1194 | Loss: 293.958 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 240/1194 | Loss: 269.674 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 250/1194 | Loss: 295.132 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 260/1194 | Loss: 291.535 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 270/1194 | Loss: 296.470 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 280/1194 | Loss: 312.635 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 290/1194 | Loss: 277.422 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 300/1194 | Loss: 297.583 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 310/1194 | Loss: 326.769 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 320/1194 | Loss: 288.531 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 330/1194 | Loss: 306.722 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 340/1194 | Loss: 302.997 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 350/1194 | Loss: 293.708 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 360/1194 | Loss: 285.617 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 370/1194 | Loss: 283.026 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 380/1194 | Loss: 312.873 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 390/1194 | Loss: 287.091 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 400/1194 | Loss: 288.646 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 410/1194 | Loss: 320.630 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 420/1194 | Loss: 305.269 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 430/1194 | Loss: 280.650 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 440/1194 | Loss: 287.823 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 450/1194 | Loss: 294.776 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 460/1194 | Loss: 301.414 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 470/1194 | Loss: 293.385 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 480/1194 | Loss: 292.099 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 490/1194 | Loss: 312.318 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 500/1194 | Loss: 301.912 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 510/1194 | Loss: 283.953 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 520/1194 | Loss: 265.523 | Accuracy: 0.400\n",
      "[Epoch: 133/200] - Step: 530/1194 | Loss: 302.874 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 540/1194 | Loss: 277.838 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 550/1194 | Loss: 304.237 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 560/1194 | Loss: 306.320 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 570/1194 | Loss: 292.901 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 580/1194 | Loss: 301.497 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 590/1194 | Loss: 310.027 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 600/1194 | Loss: 296.617 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 610/1194 | Loss: 300.483 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 620/1194 | Loss: 302.471 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 630/1194 | Loss: 296.347 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 640/1194 | Loss: 291.887 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 650/1194 | Loss: 292.728 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 660/1194 | Loss: 322.972 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 670/1194 | Loss: 288.977 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 680/1194 | Loss: 293.946 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 690/1194 | Loss: 290.403 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 700/1194 | Loss: 298.510 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 710/1194 | Loss: 304.857 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 720/1194 | Loss: 290.926 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 730/1194 | Loss: 294.208 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 740/1194 | Loss: 297.474 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 750/1194 | Loss: 267.005 | Accuracy: 0.400\n",
      "[Epoch: 133/200] - Step: 760/1194 | Loss: 304.911 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 770/1194 | Loss: 294.476 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 780/1194 | Loss: 307.117 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 790/1194 | Loss: 299.535 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 800/1194 | Loss: 312.768 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 810/1194 | Loss: 314.248 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 820/1194 | Loss: 301.259 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 830/1194 | Loss: 287.572 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 840/1194 | Loss: 297.836 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 850/1194 | Loss: 321.322 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 860/1194 | Loss: 292.016 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 870/1194 | Loss: 296.161 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 880/1194 | Loss: 300.434 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 890/1194 | Loss: 279.760 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 900/1194 | Loss: 288.178 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 910/1194 | Loss: 287.767 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 920/1194 | Loss: 307.907 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 930/1194 | Loss: 287.131 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 940/1194 | Loss: 330.644 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 950/1194 | Loss: 285.326 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 960/1194 | Loss: 295.217 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 970/1194 | Loss: 291.057 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 980/1194 | Loss: 284.404 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 990/1194 | Loss: 306.822 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1000/1194 | Loss: 284.963 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1010/1194 | Loss: 286.617 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1020/1194 | Loss: 317.274 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1030/1194 | Loss: 295.983 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1040/1194 | Loss: 279.800 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 1050/1194 | Loss: 302.688 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1060/1194 | Loss: 287.650 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 1070/1194 | Loss: 299.571 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1080/1194 | Loss: 282.837 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 1090/1194 | Loss: 307.478 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1100/1194 | Loss: 296.758 | Accuracy: 0.000\n",
      "[Epoch: 133/200] - Step: 1110/1194 | Loss: 296.333 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1120/1194 | Loss: 300.561 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1130/1194 | Loss: 280.750 | Accuracy: 0.200\n",
      "[Epoch: 133/200] - Step: 1140/1194 | Loss: 282.085 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 1150/1194 | Loss: 296.185 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1160/1194 | Loss: 305.175 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1170/1194 | Loss: 286.334 | Accuracy: 0.300\n",
      "[Epoch: 133/200] - Step: 1180/1194 | Loss: 298.740 | Accuracy: 0.100\n",
      "[Epoch: 133/200] - Step: 1190/1194 | Loss: 301.877 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 134/200] - Step: 10/1194 | Loss: 303.861 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 20/1194 | Loss: 328.370 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 30/1194 | Loss: 314.097 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 40/1194 | Loss: 279.682 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 50/1194 | Loss: 290.021 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 60/1194 | Loss: 305.607 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 70/1194 | Loss: 312.772 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 80/1194 | Loss: 298.862 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 90/1194 | Loss: 278.756 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 100/1194 | Loss: 285.090 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 110/1194 | Loss: 290.984 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 120/1194 | Loss: 300.523 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 130/1194 | Loss: 303.500 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 140/1194 | Loss: 275.198 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 150/1194 | Loss: 299.414 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 160/1194 | Loss: 282.914 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 170/1194 | Loss: 297.376 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 180/1194 | Loss: 292.327 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 190/1194 | Loss: 309.968 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 200/1194 | Loss: 303.079 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 210/1194 | Loss: 279.476 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 220/1194 | Loss: 309.489 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 230/1194 | Loss: 270.122 | Accuracy: 0.400\n",
      "[Epoch: 134/200] - Step: 240/1194 | Loss: 287.993 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 250/1194 | Loss: 343.444 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 260/1194 | Loss: 306.640 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 270/1194 | Loss: 270.998 | Accuracy: 0.400\n",
      "[Epoch: 134/200] - Step: 280/1194 | Loss: 272.873 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 290/1194 | Loss: 300.401 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 300/1194 | Loss: 307.578 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 310/1194 | Loss: 286.798 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 320/1194 | Loss: 308.311 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 330/1194 | Loss: 285.271 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 340/1194 | Loss: 338.173 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 350/1194 | Loss: 317.017 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 360/1194 | Loss: 295.561 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 370/1194 | Loss: 306.471 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 380/1194 | Loss: 293.397 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 390/1194 | Loss: 306.181 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 400/1194 | Loss: 304.953 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 410/1194 | Loss: 294.975 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 420/1194 | Loss: 301.250 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 430/1194 | Loss: 298.084 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 440/1194 | Loss: 333.643 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 450/1194 | Loss: 293.089 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 460/1194 | Loss: 290.106 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 470/1194 | Loss: 291.561 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 480/1194 | Loss: 298.769 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 490/1194 | Loss: 281.743 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 500/1194 | Loss: 308.262 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 510/1194 | Loss: 278.474 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 520/1194 | Loss: 306.502 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 530/1194 | Loss: 288.998 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 540/1194 | Loss: 297.912 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 550/1194 | Loss: 306.719 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 560/1194 | Loss: 313.377 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 570/1194 | Loss: 287.693 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 580/1194 | Loss: 290.369 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 590/1194 | Loss: 285.819 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 600/1194 | Loss: 289.093 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 610/1194 | Loss: 294.219 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 620/1194 | Loss: 311.200 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 630/1194 | Loss: 281.048 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 640/1194 | Loss: 297.321 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 650/1194 | Loss: 287.741 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 660/1194 | Loss: 271.553 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 670/1194 | Loss: 309.580 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 680/1194 | Loss: 276.560 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 690/1194 | Loss: 291.773 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 700/1194 | Loss: 274.935 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 710/1194 | Loss: 292.479 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 720/1194 | Loss: 301.731 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 730/1194 | Loss: 301.540 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 740/1194 | Loss: 346.118 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 750/1194 | Loss: 300.509 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 760/1194 | Loss: 290.910 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 770/1194 | Loss: 294.135 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 780/1194 | Loss: 306.577 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 790/1194 | Loss: 302.895 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 800/1194 | Loss: 293.496 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 810/1194 | Loss: 305.229 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 820/1194 | Loss: 287.362 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 830/1194 | Loss: 303.582 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 840/1194 | Loss: 288.489 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 850/1194 | Loss: 300.363 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 860/1194 | Loss: 294.689 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 870/1194 | Loss: 281.824 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 880/1194 | Loss: 287.263 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 890/1194 | Loss: 292.540 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 900/1194 | Loss: 288.428 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 910/1194 | Loss: 307.822 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 920/1194 | Loss: 306.490 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 930/1194 | Loss: 299.826 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 940/1194 | Loss: 303.409 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 950/1194 | Loss: 293.768 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 960/1194 | Loss: 291.853 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 970/1194 | Loss: 268.510 | Accuracy: 0.400\n",
      "[Epoch: 134/200] - Step: 980/1194 | Loss: 312.805 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 990/1194 | Loss: 311.215 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 1000/1194 | Loss: 295.063 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 1010/1194 | Loss: 308.961 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 1020/1194 | Loss: 320.356 | Accuracy: 0.000\n",
      "[Epoch: 134/200] - Step: 1030/1194 | Loss: 290.125 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1040/1194 | Loss: 286.338 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 1050/1194 | Loss: 283.934 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 1060/1194 | Loss: 304.523 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1070/1194 | Loss: 294.873 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1080/1194 | Loss: 302.249 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1090/1194 | Loss: 283.885 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 1100/1194 | Loss: 291.937 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1110/1194 | Loss: 290.356 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1120/1194 | Loss: 299.648 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1130/1194 | Loss: 290.442 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1140/1194 | Loss: 310.227 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1150/1194 | Loss: 294.086 | Accuracy: 0.100\n",
      "[Epoch: 134/200] - Step: 1160/1194 | Loss: 291.256 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 1170/1194 | Loss: 272.906 | Accuracy: 0.300\n",
      "[Epoch: 134/200] - Step: 1180/1194 | Loss: 285.968 | Accuracy: 0.200\n",
      "[Epoch: 134/200] - Step: 1190/1194 | Loss: 310.375 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 135/200] - Step: 10/1194 | Loss: 316.550 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 20/1194 | Loss: 274.105 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 30/1194 | Loss: 298.977 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 40/1194 | Loss: 292.233 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 50/1194 | Loss: 283.000 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 60/1194 | Loss: 268.957 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 70/1194 | Loss: 288.487 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 80/1194 | Loss: 299.894 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 90/1194 | Loss: 284.261 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 100/1194 | Loss: 298.413 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 110/1194 | Loss: 291.764 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 120/1194 | Loss: 300.685 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 130/1194 | Loss: 305.965 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 140/1194 | Loss: 297.603 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 150/1194 | Loss: 296.328 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 160/1194 | Loss: 284.906 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 170/1194 | Loss: 278.081 | Accuracy: 0.400\n",
      "[Epoch: 135/200] - Step: 180/1194 | Loss: 289.662 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 190/1194 | Loss: 296.747 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 200/1194 | Loss: 299.303 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 210/1194 | Loss: 275.772 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 220/1194 | Loss: 306.128 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 230/1194 | Loss: 298.324 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 240/1194 | Loss: 278.420 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 250/1194 | Loss: 280.595 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 260/1194 | Loss: 285.385 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 270/1194 | Loss: 287.451 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 280/1194 | Loss: 303.029 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 290/1194 | Loss: 282.015 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 300/1194 | Loss: 302.134 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 310/1194 | Loss: 303.509 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 320/1194 | Loss: 290.460 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 330/1194 | Loss: 314.439 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 340/1194 | Loss: 293.299 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 350/1194 | Loss: 314.813 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 360/1194 | Loss: 279.894 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 370/1194 | Loss: 296.383 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 380/1194 | Loss: 271.096 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 390/1194 | Loss: 285.542 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 400/1194 | Loss: 282.636 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 410/1194 | Loss: 299.031 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 420/1194 | Loss: 304.932 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 430/1194 | Loss: 291.312 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 440/1194 | Loss: 292.590 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 450/1194 | Loss: 315.858 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 460/1194 | Loss: 294.679 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 470/1194 | Loss: 295.801 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 480/1194 | Loss: 295.850 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 490/1194 | Loss: 338.552 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 500/1194 | Loss: 300.270 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 510/1194 | Loss: 301.015 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 520/1194 | Loss: 288.360 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 530/1194 | Loss: 286.900 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 540/1194 | Loss: 305.354 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 550/1194 | Loss: 289.653 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 560/1194 | Loss: 312.869 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 570/1194 | Loss: 303.719 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 580/1194 | Loss: 298.335 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 590/1194 | Loss: 306.519 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 600/1194 | Loss: 294.384 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 610/1194 | Loss: 333.250 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 620/1194 | Loss: 307.293 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 630/1194 | Loss: 301.706 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 640/1194 | Loss: 288.801 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 650/1194 | Loss: 278.676 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 660/1194 | Loss: 295.785 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 670/1194 | Loss: 285.475 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 680/1194 | Loss: 315.235 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 690/1194 | Loss: 305.680 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 700/1194 | Loss: 284.483 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 710/1194 | Loss: 294.402 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 720/1194 | Loss: 292.869 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 730/1194 | Loss: 294.144 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 740/1194 | Loss: 300.399 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 750/1194 | Loss: 301.344 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 760/1194 | Loss: 293.059 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 770/1194 | Loss: 296.843 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 780/1194 | Loss: 294.588 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 790/1194 | Loss: 290.127 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 800/1194 | Loss: 295.666 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 810/1194 | Loss: 284.410 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 820/1194 | Loss: 288.305 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 830/1194 | Loss: 317.805 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 840/1194 | Loss: 292.229 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 850/1194 | Loss: 298.337 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 860/1194 | Loss: 279.305 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 870/1194 | Loss: 332.175 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 880/1194 | Loss: 329.299 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 890/1194 | Loss: 289.061 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 900/1194 | Loss: 292.420 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 910/1194 | Loss: 314.080 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 920/1194 | Loss: 295.253 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 930/1194 | Loss: 305.734 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 940/1194 | Loss: 296.560 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 950/1194 | Loss: 302.900 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 960/1194 | Loss: 304.770 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 970/1194 | Loss: 301.643 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 980/1194 | Loss: 288.908 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 990/1194 | Loss: 295.572 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1000/1194 | Loss: 301.621 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 1010/1194 | Loss: 312.544 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1020/1194 | Loss: 311.469 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1030/1194 | Loss: 290.101 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 1040/1194 | Loss: 283.162 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 1050/1194 | Loss: 304.221 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1060/1194 | Loss: 314.935 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1070/1194 | Loss: 297.048 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 1080/1194 | Loss: 283.689 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 1090/1194 | Loss: 324.840 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 1100/1194 | Loss: 306.091 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1110/1194 | Loss: 296.611 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 1120/1194 | Loss: 294.737 | Accuracy: 0.100\n",
      "[Epoch: 135/200] - Step: 1130/1194 | Loss: 289.646 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 1140/1194 | Loss: 299.692 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1150/1194 | Loss: 272.076 | Accuracy: 0.300\n",
      "[Epoch: 135/200] - Step: 1160/1194 | Loss: 307.109 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1170/1194 | Loss: 291.003 | Accuracy: 0.200\n",
      "[Epoch: 135/200] - Step: 1180/1194 | Loss: 304.965 | Accuracy: 0.000\n",
      "[Epoch: 135/200] - Step: 1190/1194 | Loss: 283.379 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 136/200] - Step: 10/1194 | Loss: 291.228 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 20/1194 | Loss: 295.356 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 30/1194 | Loss: 317.264 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 40/1194 | Loss: 303.859 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 50/1194 | Loss: 294.782 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 60/1194 | Loss: 297.704 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 70/1194 | Loss: 306.206 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 80/1194 | Loss: 296.425 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 90/1194 | Loss: 312.383 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 100/1194 | Loss: 305.982 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 110/1194 | Loss: 296.017 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 120/1194 | Loss: 292.096 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 130/1194 | Loss: 302.977 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 140/1194 | Loss: 284.651 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 150/1194 | Loss: 284.611 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 160/1194 | Loss: 303.264 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 170/1194 | Loss: 290.860 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 180/1194 | Loss: 310.492 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 190/1194 | Loss: 293.488 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 200/1194 | Loss: 293.079 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 210/1194 | Loss: 306.060 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 220/1194 | Loss: 298.614 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 230/1194 | Loss: 308.467 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 240/1194 | Loss: 296.697 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 250/1194 | Loss: 277.223 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 260/1194 | Loss: 310.624 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 270/1194 | Loss: 291.883 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 280/1194 | Loss: 283.594 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 290/1194 | Loss: 314.447 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 300/1194 | Loss: 292.555 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 310/1194 | Loss: 328.819 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 320/1194 | Loss: 281.749 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 330/1194 | Loss: 284.262 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 340/1194 | Loss: 324.930 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 350/1194 | Loss: 305.260 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 360/1194 | Loss: 301.065 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 370/1194 | Loss: 286.542 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 380/1194 | Loss: 287.871 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 390/1194 | Loss: 294.428 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 400/1194 | Loss: 309.499 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 410/1194 | Loss: 293.859 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 420/1194 | Loss: 292.896 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 430/1194 | Loss: 280.784 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 440/1194 | Loss: 296.537 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 450/1194 | Loss: 303.490 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 460/1194 | Loss: 298.144 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 470/1194 | Loss: 300.303 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 480/1194 | Loss: 296.090 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 490/1194 | Loss: 298.180 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 500/1194 | Loss: 279.652 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 510/1194 | Loss: 289.857 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 520/1194 | Loss: 286.100 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 530/1194 | Loss: 298.233 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 540/1194 | Loss: 280.793 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 550/1194 | Loss: 276.332 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 560/1194 | Loss: 309.801 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 570/1194 | Loss: 298.710 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 580/1194 | Loss: 271.917 | Accuracy: 0.400\n",
      "[Epoch: 136/200] - Step: 590/1194 | Loss: 286.616 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 600/1194 | Loss: 297.576 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 610/1194 | Loss: 287.098 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 620/1194 | Loss: 294.347 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 630/1194 | Loss: 304.316 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 640/1194 | Loss: 261.615 | Accuracy: 0.400\n",
      "[Epoch: 136/200] - Step: 650/1194 | Loss: 294.399 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 660/1194 | Loss: 309.783 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 670/1194 | Loss: 321.483 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 680/1194 | Loss: 295.498 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 690/1194 | Loss: 282.472 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 700/1194 | Loss: 278.827 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 710/1194 | Loss: 334.240 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 720/1194 | Loss: 288.349 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 730/1194 | Loss: 294.784 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 740/1194 | Loss: 293.569 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 750/1194 | Loss: 284.134 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 760/1194 | Loss: 301.209 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 770/1194 | Loss: 298.728 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 780/1194 | Loss: 282.766 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 790/1194 | Loss: 297.472 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 800/1194 | Loss: 336.018 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 810/1194 | Loss: 294.769 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 820/1194 | Loss: 311.141 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 830/1194 | Loss: 303.260 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 840/1194 | Loss: 295.917 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 850/1194 | Loss: 288.872 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 860/1194 | Loss: 311.752 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 870/1194 | Loss: 296.288 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 880/1194 | Loss: 312.501 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 890/1194 | Loss: 284.053 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 900/1194 | Loss: 311.107 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 910/1194 | Loss: 293.107 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 920/1194 | Loss: 308.474 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 930/1194 | Loss: 294.776 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 940/1194 | Loss: 282.197 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 950/1194 | Loss: 302.749 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 960/1194 | Loss: 300.493 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 970/1194 | Loss: 289.505 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 980/1194 | Loss: 293.134 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 990/1194 | Loss: 276.927 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 1000/1194 | Loss: 297.528 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1010/1194 | Loss: 315.024 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1020/1194 | Loss: 304.882 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1030/1194 | Loss: 303.786 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1040/1194 | Loss: 279.499 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 1050/1194 | Loss: 308.237 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1060/1194 | Loss: 298.508 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1070/1194 | Loss: 298.948 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1080/1194 | Loss: 305.375 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1090/1194 | Loss: 278.789 | Accuracy: 0.300\n",
      "[Epoch: 136/200] - Step: 1100/1194 | Loss: 312.427 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1110/1194 | Loss: 294.070 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 1120/1194 | Loss: 291.601 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 1130/1194 | Loss: 284.092 | Accuracy: 0.200\n",
      "[Epoch: 136/200] - Step: 1140/1194 | Loss: 296.165 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1150/1194 | Loss: 298.275 | Accuracy: 0.100\n",
      "[Epoch: 136/200] - Step: 1160/1194 | Loss: 294.943 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1170/1194 | Loss: 287.687 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1180/1194 | Loss: 310.098 | Accuracy: 0.000\n",
      "[Epoch: 136/200] - Step: 1190/1194 | Loss: 286.458 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 137/200] - Step: 10/1194 | Loss: 293.341 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 20/1194 | Loss: 296.963 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 30/1194 | Loss: 293.869 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 40/1194 | Loss: 288.885 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 50/1194 | Loss: 287.730 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 60/1194 | Loss: 307.776 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 70/1194 | Loss: 316.057 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 80/1194 | Loss: 301.346 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 90/1194 | Loss: 287.960 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 100/1194 | Loss: 302.586 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 110/1194 | Loss: 299.390 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 120/1194 | Loss: 266.259 | Accuracy: 0.400\n",
      "[Epoch: 137/200] - Step: 130/1194 | Loss: 268.064 | Accuracy: 0.400\n",
      "[Epoch: 137/200] - Step: 140/1194 | Loss: 298.586 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 150/1194 | Loss: 285.341 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 160/1194 | Loss: 308.379 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 170/1194 | Loss: 280.074 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 180/1194 | Loss: 290.776 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 190/1194 | Loss: 297.628 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 200/1194 | Loss: 294.673 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 210/1194 | Loss: 294.860 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 220/1194 | Loss: 287.095 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 230/1194 | Loss: 312.709 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 240/1194 | Loss: 264.470 | Accuracy: 0.400\n",
      "[Epoch: 137/200] - Step: 250/1194 | Loss: 286.064 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 260/1194 | Loss: 318.592 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 270/1194 | Loss: 319.099 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 280/1194 | Loss: 291.386 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 290/1194 | Loss: 291.110 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 300/1194 | Loss: 276.709 | Accuracy: 0.300\n",
      "[Epoch: 137/200] - Step: 310/1194 | Loss: 283.502 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 320/1194 | Loss: 300.571 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 330/1194 | Loss: 290.467 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 340/1194 | Loss: 290.747 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 350/1194 | Loss: 317.104 | Accuracy: 0.300\n",
      "[Epoch: 137/200] - Step: 360/1194 | Loss: 301.945 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 370/1194 | Loss: 278.364 | Accuracy: 0.300\n",
      "[Epoch: 137/200] - Step: 380/1194 | Loss: 304.334 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 390/1194 | Loss: 298.185 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 400/1194 | Loss: 309.286 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 410/1194 | Loss: 307.030 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 420/1194 | Loss: 294.383 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 430/1194 | Loss: 308.791 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 440/1194 | Loss: 286.941 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 450/1194 | Loss: 336.456 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 460/1194 | Loss: 286.634 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 470/1194 | Loss: 281.400 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 480/1194 | Loss: 335.204 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 490/1194 | Loss: 304.631 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 500/1194 | Loss: 296.827 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 510/1194 | Loss: 302.325 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 520/1194 | Loss: 308.457 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 530/1194 | Loss: 307.322 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 540/1194 | Loss: 296.850 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 550/1194 | Loss: 303.963 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 560/1194 | Loss: 293.093 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 570/1194 | Loss: 300.475 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 580/1194 | Loss: 287.591 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 590/1194 | Loss: 293.384 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 600/1194 | Loss: 311.962 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 610/1194 | Loss: 310.760 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 620/1194 | Loss: 307.106 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 630/1194 | Loss: 300.464 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 640/1194 | Loss: 303.875 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 650/1194 | Loss: 297.091 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 660/1194 | Loss: 285.924 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 670/1194 | Loss: 303.399 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 680/1194 | Loss: 289.282 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 690/1194 | Loss: 302.692 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 700/1194 | Loss: 291.754 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 710/1194 | Loss: 300.101 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 720/1194 | Loss: 293.991 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 730/1194 | Loss: 284.174 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 740/1194 | Loss: 309.829 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 750/1194 | Loss: 287.191 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 760/1194 | Loss: 275.827 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 770/1194 | Loss: 298.958 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 780/1194 | Loss: 298.418 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 790/1194 | Loss: 307.029 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 800/1194 | Loss: 317.080 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 810/1194 | Loss: 299.048 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 820/1194 | Loss: 301.803 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 830/1194 | Loss: 301.050 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 840/1194 | Loss: 295.973 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 850/1194 | Loss: 301.110 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 860/1194 | Loss: 293.840 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 870/1194 | Loss: 292.356 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 880/1194 | Loss: 281.611 | Accuracy: 0.400\n",
      "[Epoch: 137/200] - Step: 890/1194 | Loss: 287.333 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 900/1194 | Loss: 284.783 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 910/1194 | Loss: 285.965 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 920/1194 | Loss: 306.255 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 930/1194 | Loss: 321.038 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 940/1194 | Loss: 287.086 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 950/1194 | Loss: 297.763 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 960/1194 | Loss: 310.237 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 970/1194 | Loss: 304.562 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 980/1194 | Loss: 305.663 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 990/1194 | Loss: 281.842 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 1000/1194 | Loss: 288.588 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 1010/1194 | Loss: 293.033 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 1020/1194 | Loss: 282.310 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 1030/1194 | Loss: 333.748 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1040/1194 | Loss: 290.803 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 1050/1194 | Loss: 308.797 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1060/1194 | Loss: 284.076 | Accuracy: 0.300\n",
      "[Epoch: 137/200] - Step: 1070/1194 | Loss: 297.419 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1080/1194 | Loss: 298.206 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1090/1194 | Loss: 303.214 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1100/1194 | Loss: 292.798 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 1110/1194 | Loss: 304.430 | Accuracy: 0.100\n",
      "[Epoch: 137/200] - Step: 1120/1194 | Loss: 288.746 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 1130/1194 | Loss: 294.436 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1140/1194 | Loss: 296.262 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1150/1194 | Loss: 296.618 | Accuracy: 0.000\n",
      "[Epoch: 137/200] - Step: 1160/1194 | Loss: 281.760 | Accuracy: 0.400\n",
      "[Epoch: 137/200] - Step: 1170/1194 | Loss: 295.048 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 1180/1194 | Loss: 284.413 | Accuracy: 0.200\n",
      "[Epoch: 137/200] - Step: 1190/1194 | Loss: 304.678 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 138/200] - Step: 10/1194 | Loss: 289.598 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 20/1194 | Loss: 296.760 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 30/1194 | Loss: 302.295 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 40/1194 | Loss: 304.511 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 50/1194 | Loss: 290.871 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 60/1194 | Loss: 286.271 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 70/1194 | Loss: 304.834 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 80/1194 | Loss: 294.363 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 90/1194 | Loss: 291.836 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 100/1194 | Loss: 287.085 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 110/1194 | Loss: 302.864 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 120/1194 | Loss: 299.962 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 130/1194 | Loss: 272.909 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 140/1194 | Loss: 293.460 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 150/1194 | Loss: 313.178 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 160/1194 | Loss: 284.368 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 170/1194 | Loss: 299.928 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 180/1194 | Loss: 301.432 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 190/1194 | Loss: 319.753 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 200/1194 | Loss: 295.726 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 210/1194 | Loss: 311.913 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 220/1194 | Loss: 289.993 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 230/1194 | Loss: 286.381 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 240/1194 | Loss: 303.277 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 250/1194 | Loss: 276.213 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 260/1194 | Loss: 292.619 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 270/1194 | Loss: 299.849 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 280/1194 | Loss: 308.416 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 290/1194 | Loss: 286.105 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 300/1194 | Loss: 301.909 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 310/1194 | Loss: 301.732 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 320/1194 | Loss: 303.111 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 330/1194 | Loss: 288.834 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 340/1194 | Loss: 288.821 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 350/1194 | Loss: 272.500 | Accuracy: 0.400\n",
      "[Epoch: 138/200] - Step: 360/1194 | Loss: 304.990 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 370/1194 | Loss: 284.151 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 380/1194 | Loss: 330.047 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 390/1194 | Loss: 298.988 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 400/1194 | Loss: 283.776 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 410/1194 | Loss: 285.960 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 420/1194 | Loss: 293.550 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 430/1194 | Loss: 303.730 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 440/1194 | Loss: 282.138 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 450/1194 | Loss: 293.218 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 460/1194 | Loss: 298.754 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 470/1194 | Loss: 302.528 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 480/1194 | Loss: 291.340 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 490/1194 | Loss: 296.252 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 500/1194 | Loss: 288.769 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 510/1194 | Loss: 272.763 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 520/1194 | Loss: 294.871 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 530/1194 | Loss: 314.703 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 540/1194 | Loss: 296.085 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 550/1194 | Loss: 295.065 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 560/1194 | Loss: 287.737 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 570/1194 | Loss: 271.792 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 580/1194 | Loss: 284.785 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 590/1194 | Loss: 297.724 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 600/1194 | Loss: 298.558 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 610/1194 | Loss: 290.352 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 620/1194 | Loss: 297.277 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 630/1194 | Loss: 314.251 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 640/1194 | Loss: 297.961 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 650/1194 | Loss: 331.415 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 660/1194 | Loss: 291.919 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 670/1194 | Loss: 272.740 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 680/1194 | Loss: 305.895 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 690/1194 | Loss: 288.113 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 700/1194 | Loss: 287.508 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 710/1194 | Loss: 299.352 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 720/1194 | Loss: 281.301 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 730/1194 | Loss: 293.722 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 740/1194 | Loss: 320.054 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 750/1194 | Loss: 306.848 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 760/1194 | Loss: 297.987 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 770/1194 | Loss: 293.739 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 780/1194 | Loss: 312.455 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 790/1194 | Loss: 313.277 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 800/1194 | Loss: 293.571 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 810/1194 | Loss: 290.214 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 820/1194 | Loss: 300.477 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 830/1194 | Loss: 290.872 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 840/1194 | Loss: 289.248 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 850/1194 | Loss: 298.584 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 860/1194 | Loss: 291.796 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 870/1194 | Loss: 264.012 | Accuracy: 0.500\n",
      "[Epoch: 138/200] - Step: 880/1194 | Loss: 341.138 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 890/1194 | Loss: 320.519 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 900/1194 | Loss: 303.834 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 910/1194 | Loss: 299.350 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 920/1194 | Loss: 285.989 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 930/1194 | Loss: 295.852 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 940/1194 | Loss: 315.891 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 950/1194 | Loss: 297.616 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 960/1194 | Loss: 266.998 | Accuracy: 0.500\n",
      "[Epoch: 138/200] - Step: 970/1194 | Loss: 305.340 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 980/1194 | Loss: 305.345 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 990/1194 | Loss: 298.039 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1000/1194 | Loss: 281.878 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 1010/1194 | Loss: 313.747 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1020/1194 | Loss: 305.740 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1030/1194 | Loss: 303.593 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1040/1194 | Loss: 309.533 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1050/1194 | Loss: 303.106 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1060/1194 | Loss: 281.648 | Accuracy: 0.300\n",
      "[Epoch: 138/200] - Step: 1070/1194 | Loss: 331.149 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1080/1194 | Loss: 297.199 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1090/1194 | Loss: 291.918 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1100/1194 | Loss: 296.603 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1110/1194 | Loss: 280.914 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 1120/1194 | Loss: 316.684 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 1130/1194 | Loss: 306.551 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1140/1194 | Loss: 303.885 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1150/1194 | Loss: 296.173 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1160/1194 | Loss: 286.613 | Accuracy: 0.200\n",
      "[Epoch: 138/200] - Step: 1170/1194 | Loss: 298.026 | Accuracy: 0.100\n",
      "[Epoch: 138/200] - Step: 1180/1194 | Loss: 307.224 | Accuracy: 0.000\n",
      "[Epoch: 138/200] - Step: 1190/1194 | Loss: 279.319 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 139/200] - Step: 10/1194 | Loss: 279.676 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 20/1194 | Loss: 294.915 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 30/1194 | Loss: 307.116 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 40/1194 | Loss: 300.451 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 50/1194 | Loss: 298.177 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 60/1194 | Loss: 284.745 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 70/1194 | Loss: 304.101 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 80/1194 | Loss: 285.545 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 90/1194 | Loss: 308.037 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 100/1194 | Loss: 276.957 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 110/1194 | Loss: 295.890 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 120/1194 | Loss: 297.766 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 130/1194 | Loss: 301.846 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 140/1194 | Loss: 292.707 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 150/1194 | Loss: 301.027 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 160/1194 | Loss: 295.066 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 170/1194 | Loss: 305.672 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 180/1194 | Loss: 299.071 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 190/1194 | Loss: 275.923 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 200/1194 | Loss: 306.490 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 210/1194 | Loss: 295.803 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 220/1194 | Loss: 297.644 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 230/1194 | Loss: 280.585 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 240/1194 | Loss: 302.565 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 250/1194 | Loss: 309.451 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 260/1194 | Loss: 305.116 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 270/1194 | Loss: 296.345 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 280/1194 | Loss: 299.432 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 290/1194 | Loss: 306.552 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 300/1194 | Loss: 292.070 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 310/1194 | Loss: 303.407 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 320/1194 | Loss: 299.145 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 330/1194 | Loss: 285.593 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 340/1194 | Loss: 274.969 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 350/1194 | Loss: 309.793 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 360/1194 | Loss: 309.575 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 370/1194 | Loss: 302.943 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 380/1194 | Loss: 297.278 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 390/1194 | Loss: 293.380 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 400/1194 | Loss: 291.112 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 410/1194 | Loss: 284.115 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 420/1194 | Loss: 278.983 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 430/1194 | Loss: 299.683 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 440/1194 | Loss: 282.495 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 450/1194 | Loss: 271.871 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 460/1194 | Loss: 269.953 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 470/1194 | Loss: 301.461 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 480/1194 | Loss: 292.646 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 490/1194 | Loss: 286.385 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 500/1194 | Loss: 300.263 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 510/1194 | Loss: 311.070 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 520/1194 | Loss: 289.992 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 530/1194 | Loss: 287.406 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 540/1194 | Loss: 302.521 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 550/1194 | Loss: 312.363 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 560/1194 | Loss: 287.992 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 570/1194 | Loss: 292.370 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 580/1194 | Loss: 270.862 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 590/1194 | Loss: 301.068 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 600/1194 | Loss: 319.930 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 610/1194 | Loss: 300.318 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 620/1194 | Loss: 313.086 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 630/1194 | Loss: 288.720 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 640/1194 | Loss: 279.358 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 650/1194 | Loss: 288.735 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 660/1194 | Loss: 309.061 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 670/1194 | Loss: 274.300 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 680/1194 | Loss: 364.401 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 690/1194 | Loss: 294.091 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 700/1194 | Loss: 299.623 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 710/1194 | Loss: 295.656 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 720/1194 | Loss: 291.874 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 730/1194 | Loss: 299.849 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 740/1194 | Loss: 309.443 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 750/1194 | Loss: 304.957 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 760/1194 | Loss: 305.535 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 770/1194 | Loss: 302.322 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 780/1194 | Loss: 312.202 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 790/1194 | Loss: 286.878 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 800/1194 | Loss: 293.855 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 810/1194 | Loss: 307.613 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 820/1194 | Loss: 295.908 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 830/1194 | Loss: 311.088 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 840/1194 | Loss: 324.776 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 850/1194 | Loss: 291.759 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 860/1194 | Loss: 287.720 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 870/1194 | Loss: 285.966 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 880/1194 | Loss: 277.581 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 890/1194 | Loss: 304.692 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 900/1194 | Loss: 282.058 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 910/1194 | Loss: 301.170 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 920/1194 | Loss: 294.543 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 930/1194 | Loss: 300.837 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 940/1194 | Loss: 306.773 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 950/1194 | Loss: 292.184 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 960/1194 | Loss: 297.807 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 970/1194 | Loss: 286.229 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 980/1194 | Loss: 313.581 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 990/1194 | Loss: 287.713 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1000/1194 | Loss: 283.631 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1010/1194 | Loss: 281.987 | Accuracy: 0.300\n",
      "[Epoch: 139/200] - Step: 1020/1194 | Loss: 291.225 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1030/1194 | Loss: 294.413 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1040/1194 | Loss: 284.420 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1050/1194 | Loss: 303.866 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1060/1194 | Loss: 273.149 | Accuracy: 0.400\n",
      "[Epoch: 139/200] - Step: 1070/1194 | Loss: 315.049 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1080/1194 | Loss: 305.042 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1090/1194 | Loss: 304.841 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1100/1194 | Loss: 278.581 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1110/1194 | Loss: 297.419 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1120/1194 | Loss: 278.499 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1130/1194 | Loss: 294.899 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1140/1194 | Loss: 284.199 | Accuracy: 0.200\n",
      "[Epoch: 139/200] - Step: 1150/1194 | Loss: 331.260 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1160/1194 | Loss: 355.302 | Accuracy: 0.000\n",
      "[Epoch: 139/200] - Step: 1170/1194 | Loss: 300.292 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1180/1194 | Loss: 300.873 | Accuracy: 0.100\n",
      "[Epoch: 139/200] - Step: 1190/1194 | Loss: 302.012 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 140/200] - Step: 10/1194 | Loss: 299.935 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 20/1194 | Loss: 292.183 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 30/1194 | Loss: 298.625 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 40/1194 | Loss: 263.265 | Accuracy: 0.600\n",
      "[Epoch: 140/200] - Step: 50/1194 | Loss: 303.496 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 60/1194 | Loss: 311.223 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 70/1194 | Loss: 296.174 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 80/1194 | Loss: 298.981 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 90/1194 | Loss: 305.748 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 100/1194 | Loss: 296.436 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 110/1194 | Loss: 304.069 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 120/1194 | Loss: 304.902 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 130/1194 | Loss: 278.360 | Accuracy: 0.300\n",
      "[Epoch: 140/200] - Step: 140/1194 | Loss: 302.707 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 150/1194 | Loss: 299.909 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 160/1194 | Loss: 303.207 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 170/1194 | Loss: 310.430 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 180/1194 | Loss: 301.884 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 190/1194 | Loss: 308.740 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 200/1194 | Loss: 332.208 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 210/1194 | Loss: 301.821 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 220/1194 | Loss: 270.075 | Accuracy: 0.400\n",
      "[Epoch: 140/200] - Step: 230/1194 | Loss: 297.479 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 240/1194 | Loss: 277.276 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 250/1194 | Loss: 299.354 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 260/1194 | Loss: 302.497 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 270/1194 | Loss: 295.071 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 280/1194 | Loss: 288.171 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 290/1194 | Loss: 280.274 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 300/1194 | Loss: 321.175 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 310/1194 | Loss: 288.883 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 320/1194 | Loss: 304.648 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 330/1194 | Loss: 289.022 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 340/1194 | Loss: 300.607 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 350/1194 | Loss: 283.947 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 360/1194 | Loss: 300.619 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 370/1194 | Loss: 298.822 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 380/1194 | Loss: 297.791 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 390/1194 | Loss: 300.479 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 400/1194 | Loss: 285.799 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 410/1194 | Loss: 329.519 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 420/1194 | Loss: 305.627 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 430/1194 | Loss: 293.199 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 440/1194 | Loss: 297.478 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 450/1194 | Loss: 293.047 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 460/1194 | Loss: 273.626 | Accuracy: 0.300\n",
      "[Epoch: 140/200] - Step: 470/1194 | Loss: 278.265 | Accuracy: 0.300\n",
      "[Epoch: 140/200] - Step: 480/1194 | Loss: 303.108 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 490/1194 | Loss: 299.335 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 500/1194 | Loss: 304.762 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 510/1194 | Loss: 286.647 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 520/1194 | Loss: 294.959 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 530/1194 | Loss: 297.635 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 540/1194 | Loss: 293.068 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 550/1194 | Loss: 288.144 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 560/1194 | Loss: 334.884 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 570/1194 | Loss: 288.888 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 580/1194 | Loss: 295.889 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 590/1194 | Loss: 292.190 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 600/1194 | Loss: 290.851 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 610/1194 | Loss: 285.063 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 620/1194 | Loss: 292.524 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 630/1194 | Loss: 321.668 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 640/1194 | Loss: 301.921 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 650/1194 | Loss: 292.946 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 660/1194 | Loss: 283.793 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 670/1194 | Loss: 316.886 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 680/1194 | Loss: 297.232 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 690/1194 | Loss: 275.578 | Accuracy: 0.400\n",
      "[Epoch: 140/200] - Step: 700/1194 | Loss: 300.522 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 710/1194 | Loss: 256.603 | Accuracy: 0.500\n",
      "[Epoch: 140/200] - Step: 720/1194 | Loss: 300.805 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 730/1194 | Loss: 298.085 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 740/1194 | Loss: 295.671 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 750/1194 | Loss: 307.555 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 760/1194 | Loss: 317.015 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 770/1194 | Loss: 316.154 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 780/1194 | Loss: 305.327 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 790/1194 | Loss: 297.028 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 800/1194 | Loss: 291.809 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 810/1194 | Loss: 306.791 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 820/1194 | Loss: 301.831 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 830/1194 | Loss: 312.772 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 840/1194 | Loss: 280.762 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 850/1194 | Loss: 307.563 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 860/1194 | Loss: 300.090 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 870/1194 | Loss: 295.257 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 880/1194 | Loss: 289.889 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 890/1194 | Loss: 292.057 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 900/1194 | Loss: 301.233 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 910/1194 | Loss: 285.768 | Accuracy: 0.300\n",
      "[Epoch: 140/200] - Step: 920/1194 | Loss: 281.805 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 930/1194 | Loss: 318.740 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 940/1194 | Loss: 308.915 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 950/1194 | Loss: 292.586 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 960/1194 | Loss: 306.209 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 970/1194 | Loss: 289.809 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 980/1194 | Loss: 288.193 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 990/1194 | Loss: 300.708 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1000/1194 | Loss: 291.228 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 1010/1194 | Loss: 291.653 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1020/1194 | Loss: 294.899 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1030/1194 | Loss: 309.947 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 1040/1194 | Loss: 299.815 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1050/1194 | Loss: 295.249 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1060/1194 | Loss: 290.822 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1070/1194 | Loss: 300.631 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1080/1194 | Loss: 306.637 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 1090/1194 | Loss: 280.597 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 1100/1194 | Loss: 271.134 | Accuracy: 0.400\n",
      "[Epoch: 140/200] - Step: 1110/1194 | Loss: 292.570 | Accuracy: 0.200\n",
      "[Epoch: 140/200] - Step: 1120/1194 | Loss: 308.109 | Accuracy: 0.000\n",
      "[Epoch: 140/200] - Step: 1130/1194 | Loss: 304.470 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1140/1194 | Loss: 279.952 | Accuracy: 0.300\n",
      "[Epoch: 140/200] - Step: 1150/1194 | Loss: 298.124 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1160/1194 | Loss: 297.949 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1170/1194 | Loss: 285.320 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1180/1194 | Loss: 302.178 | Accuracy: 0.100\n",
      "[Epoch: 140/200] - Step: 1190/1194 | Loss: 287.050 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 141/200] - Step: 10/1194 | Loss: 289.052 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 20/1194 | Loss: 320.596 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 30/1194 | Loss: 298.374 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 40/1194 | Loss: 307.059 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 50/1194 | Loss: 300.816 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 60/1194 | Loss: 304.320 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 70/1194 | Loss: 297.679 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 80/1194 | Loss: 293.386 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 90/1194 | Loss: 300.196 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 100/1194 | Loss: 303.490 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 110/1194 | Loss: 310.049 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 120/1194 | Loss: 301.890 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 130/1194 | Loss: 277.879 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 140/1194 | Loss: 275.383 | Accuracy: 0.400\n",
      "[Epoch: 141/200] - Step: 150/1194 | Loss: 306.555 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 160/1194 | Loss: 301.820 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 170/1194 | Loss: 287.847 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 180/1194 | Loss: 311.751 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 190/1194 | Loss: 289.197 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 200/1194 | Loss: 321.408 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 210/1194 | Loss: 306.981 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 220/1194 | Loss: 281.279 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 230/1194 | Loss: 293.251 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 240/1194 | Loss: 300.262 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 250/1194 | Loss: 293.794 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 260/1194 | Loss: 293.391 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 270/1194 | Loss: 282.367 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 280/1194 | Loss: 290.530 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 290/1194 | Loss: 292.126 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 300/1194 | Loss: 289.159 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 310/1194 | Loss: 268.248 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 320/1194 | Loss: 289.352 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 330/1194 | Loss: 287.894 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 340/1194 | Loss: 293.141 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 350/1194 | Loss: 307.475 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 360/1194 | Loss: 295.238 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 370/1194 | Loss: 295.445 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 380/1194 | Loss: 284.105 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 390/1194 | Loss: 291.727 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 400/1194 | Loss: 261.632 | Accuracy: 0.400\n",
      "[Epoch: 141/200] - Step: 410/1194 | Loss: 302.256 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 420/1194 | Loss: 284.664 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 430/1194 | Loss: 297.309 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 440/1194 | Loss: 291.812 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 450/1194 | Loss: 288.269 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 460/1194 | Loss: 299.581 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 470/1194 | Loss: 313.316 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 480/1194 | Loss: 291.484 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 490/1194 | Loss: 300.358 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 500/1194 | Loss: 288.272 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 510/1194 | Loss: 275.385 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 520/1194 | Loss: 306.194 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 530/1194 | Loss: 319.790 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 540/1194 | Loss: 305.268 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 550/1194 | Loss: 294.276 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 560/1194 | Loss: 305.684 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 570/1194 | Loss: 285.988 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 580/1194 | Loss: 295.715 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 590/1194 | Loss: 328.802 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 600/1194 | Loss: 301.303 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 610/1194 | Loss: 300.125 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 620/1194 | Loss: 287.282 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 630/1194 | Loss: 303.516 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 640/1194 | Loss: 290.408 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 650/1194 | Loss: 309.582 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 660/1194 | Loss: 294.252 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 670/1194 | Loss: 312.084 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 680/1194 | Loss: 267.370 | Accuracy: 0.400\n",
      "[Epoch: 141/200] - Step: 690/1194 | Loss: 274.536 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 700/1194 | Loss: 298.250 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 710/1194 | Loss: 301.108 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 720/1194 | Loss: 295.656 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 730/1194 | Loss: 297.498 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 740/1194 | Loss: 300.737 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 750/1194 | Loss: 304.732 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 760/1194 | Loss: 294.961 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 770/1194 | Loss: 294.702 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 780/1194 | Loss: 317.686 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 790/1194 | Loss: 301.713 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 800/1194 | Loss: 269.064 | Accuracy: 0.400\n",
      "[Epoch: 141/200] - Step: 810/1194 | Loss: 311.743 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 820/1194 | Loss: 283.659 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 830/1194 | Loss: 282.340 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 840/1194 | Loss: 308.164 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 850/1194 | Loss: 278.673 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 860/1194 | Loss: 296.216 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 870/1194 | Loss: 295.497 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 880/1194 | Loss: 290.970 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 890/1194 | Loss: 318.985 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 900/1194 | Loss: 309.120 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 910/1194 | Loss: 304.469 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 920/1194 | Loss: 292.578 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 930/1194 | Loss: 294.275 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 940/1194 | Loss: 275.008 | Accuracy: 0.300\n",
      "[Epoch: 141/200] - Step: 950/1194 | Loss: 295.001 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 960/1194 | Loss: 319.798 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 970/1194 | Loss: 292.781 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 980/1194 | Loss: 288.312 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 990/1194 | Loss: 296.968 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1000/1194 | Loss: 293.341 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1010/1194 | Loss: 312.464 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1020/1194 | Loss: 301.085 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1030/1194 | Loss: 298.413 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1040/1194 | Loss: 330.830 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1050/1194 | Loss: 288.014 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 1060/1194 | Loss: 288.128 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 1070/1194 | Loss: 282.341 | Accuracy: 0.200\n",
      "[Epoch: 141/200] - Step: 1080/1194 | Loss: 291.984 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1090/1194 | Loss: 293.580 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1100/1194 | Loss: 308.327 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1110/1194 | Loss: 301.173 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1120/1194 | Loss: 316.146 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1130/1194 | Loss: 298.135 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1140/1194 | Loss: 307.668 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1150/1194 | Loss: 307.185 | Accuracy: 0.000\n",
      "[Epoch: 141/200] - Step: 1160/1194 | Loss: 288.974 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1170/1194 | Loss: 291.045 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1180/1194 | Loss: 298.490 | Accuracy: 0.100\n",
      "[Epoch: 141/200] - Step: 1190/1194 | Loss: 291.589 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 142/200] - Step: 10/1194 | Loss: 283.894 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 20/1194 | Loss: 298.790 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 30/1194 | Loss: 301.596 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 40/1194 | Loss: 289.287 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 50/1194 | Loss: 285.930 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 60/1194 | Loss: 302.678 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 70/1194 | Loss: 278.989 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 80/1194 | Loss: 322.858 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 90/1194 | Loss: 281.002 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 100/1194 | Loss: 310.903 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 110/1194 | Loss: 301.671 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 120/1194 | Loss: 297.359 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 130/1194 | Loss: 277.399 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 140/1194 | Loss: 282.768 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 150/1194 | Loss: 288.926 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 160/1194 | Loss: 304.813 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 170/1194 | Loss: 296.120 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 180/1194 | Loss: 302.925 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 190/1194 | Loss: 303.122 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 200/1194 | Loss: 298.302 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 210/1194 | Loss: 309.218 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 220/1194 | Loss: 301.693 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 230/1194 | Loss: 293.437 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 240/1194 | Loss: 291.427 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 250/1194 | Loss: 292.383 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 260/1194 | Loss: 319.446 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 270/1194 | Loss: 301.142 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 280/1194 | Loss: 297.177 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 290/1194 | Loss: 311.714 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 300/1194 | Loss: 305.073 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 310/1194 | Loss: 304.156 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 320/1194 | Loss: 306.664 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 330/1194 | Loss: 280.981 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 340/1194 | Loss: 302.054 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 350/1194 | Loss: 306.258 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 360/1194 | Loss: 307.385 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 370/1194 | Loss: 306.341 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 380/1194 | Loss: 297.640 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 390/1194 | Loss: 297.694 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 400/1194 | Loss: 293.287 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 410/1194 | Loss: 313.923 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 420/1194 | Loss: 303.329 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 430/1194 | Loss: 286.998 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 440/1194 | Loss: 307.267 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 450/1194 | Loss: 287.457 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 460/1194 | Loss: 293.774 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 470/1194 | Loss: 303.549 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 480/1194 | Loss: 305.157 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 490/1194 | Loss: 297.853 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 500/1194 | Loss: 302.394 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 510/1194 | Loss: 273.447 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 520/1194 | Loss: 304.913 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 530/1194 | Loss: 312.782 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 540/1194 | Loss: 279.069 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 550/1194 | Loss: 292.527 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 560/1194 | Loss: 308.377 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 570/1194 | Loss: 302.896 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 580/1194 | Loss: 288.907 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 590/1194 | Loss: 298.977 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 600/1194 | Loss: 286.987 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 610/1194 | Loss: 298.752 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 620/1194 | Loss: 301.056 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 630/1194 | Loss: 317.869 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 640/1194 | Loss: 294.311 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 650/1194 | Loss: 303.631 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 660/1194 | Loss: 295.633 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 670/1194 | Loss: 300.571 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 680/1194 | Loss: 292.606 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 690/1194 | Loss: 303.331 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 700/1194 | Loss: 291.844 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 710/1194 | Loss: 306.430 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 720/1194 | Loss: 303.265 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 730/1194 | Loss: 312.840 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 740/1194 | Loss: 308.169 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 750/1194 | Loss: 302.016 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 760/1194 | Loss: 292.448 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 770/1194 | Loss: 277.794 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 780/1194 | Loss: 287.191 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 790/1194 | Loss: 304.849 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 800/1194 | Loss: 310.886 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 810/1194 | Loss: 286.538 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 820/1194 | Loss: 315.597 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 830/1194 | Loss: 279.444 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 840/1194 | Loss: 295.253 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 850/1194 | Loss: 289.219 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 860/1194 | Loss: 308.023 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 870/1194 | Loss: 288.523 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 880/1194 | Loss: 279.205 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 890/1194 | Loss: 314.167 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 900/1194 | Loss: 323.030 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 910/1194 | Loss: 292.959 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 920/1194 | Loss: 292.062 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 930/1194 | Loss: 322.899 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 940/1194 | Loss: 298.420 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 950/1194 | Loss: 296.444 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 960/1194 | Loss: 285.687 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 970/1194 | Loss: 268.673 | Accuracy: 0.400\n",
      "[Epoch: 142/200] - Step: 980/1194 | Loss: 283.290 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 990/1194 | Loss: 304.692 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1000/1194 | Loss: 321.888 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1010/1194 | Loss: 280.489 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 1020/1194 | Loss: 280.257 | Accuracy: 0.400\n",
      "[Epoch: 142/200] - Step: 1030/1194 | Loss: 296.946 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1040/1194 | Loss: 295.292 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1050/1194 | Loss: 275.107 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1060/1194 | Loss: 292.027 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1070/1194 | Loss: 290.412 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1080/1194 | Loss: 298.588 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1090/1194 | Loss: 288.555 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1100/1194 | Loss: 305.548 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 1110/1194 | Loss: 293.542 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1120/1194 | Loss: 287.402 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1130/1194 | Loss: 296.614 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1140/1194 | Loss: 284.087 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1150/1194 | Loss: 285.190 | Accuracy: 0.100\n",
      "[Epoch: 142/200] - Step: 1160/1194 | Loss: 265.787 | Accuracy: 0.300\n",
      "[Epoch: 142/200] - Step: 1170/1194 | Loss: 298.290 | Accuracy: 0.000\n",
      "[Epoch: 142/200] - Step: 1180/1194 | Loss: 282.245 | Accuracy: 0.200\n",
      "[Epoch: 142/200] - Step: 1190/1194 | Loss: 306.730 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 143/200] - Step: 10/1194 | Loss: 287.581 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 20/1194 | Loss: 281.657 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 30/1194 | Loss: 305.431 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 40/1194 | Loss: 299.556 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 50/1194 | Loss: 304.458 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 60/1194 | Loss: 298.291 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 70/1194 | Loss: 277.807 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 80/1194 | Loss: 281.620 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 90/1194 | Loss: 283.089 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 100/1194 | Loss: 323.453 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 110/1194 | Loss: 294.077 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 120/1194 | Loss: 300.510 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 130/1194 | Loss: 296.530 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 140/1194 | Loss: 290.237 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 150/1194 | Loss: 288.221 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 160/1194 | Loss: 308.949 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 170/1194 | Loss: 295.495 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 180/1194 | Loss: 290.732 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 190/1194 | Loss: 317.306 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 200/1194 | Loss: 308.276 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 210/1194 | Loss: 300.780 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 220/1194 | Loss: 291.366 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 230/1194 | Loss: 341.138 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 240/1194 | Loss: 276.609 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 250/1194 | Loss: 289.839 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 260/1194 | Loss: 268.908 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 270/1194 | Loss: 288.393 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 280/1194 | Loss: 295.811 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 290/1194 | Loss: 287.576 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 300/1194 | Loss: 301.940 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 310/1194 | Loss: 281.078 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 320/1194 | Loss: 303.408 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 330/1194 | Loss: 287.152 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 340/1194 | Loss: 293.577 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 350/1194 | Loss: 297.766 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 360/1194 | Loss: 302.569 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 370/1194 | Loss: 282.683 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 380/1194 | Loss: 301.968 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 390/1194 | Loss: 275.679 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 400/1194 | Loss: 289.775 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 410/1194 | Loss: 316.271 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 420/1194 | Loss: 275.301 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 430/1194 | Loss: 284.357 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 440/1194 | Loss: 273.816 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 450/1194 | Loss: 307.104 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 460/1194 | Loss: 297.082 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 470/1194 | Loss: 271.845 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 480/1194 | Loss: 314.871 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 490/1194 | Loss: 304.834 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 500/1194 | Loss: 294.937 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 510/1194 | Loss: 295.122 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 520/1194 | Loss: 309.218 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 530/1194 | Loss: 302.981 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 540/1194 | Loss: 291.311 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 550/1194 | Loss: 300.047 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 560/1194 | Loss: 310.508 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 570/1194 | Loss: 310.180 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 580/1194 | Loss: 288.439 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 590/1194 | Loss: 307.933 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 600/1194 | Loss: 307.135 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 610/1194 | Loss: 292.588 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 620/1194 | Loss: 284.344 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 630/1194 | Loss: 284.682 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 640/1194 | Loss: 299.332 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 650/1194 | Loss: 314.815 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 660/1194 | Loss: 300.170 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 670/1194 | Loss: 292.010 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 680/1194 | Loss: 296.765 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 690/1194 | Loss: 299.721 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 700/1194 | Loss: 292.500 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 710/1194 | Loss: 258.665 | Accuracy: 0.500\n",
      "[Epoch: 143/200] - Step: 720/1194 | Loss: 299.307 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 730/1194 | Loss: 297.101 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 740/1194 | Loss: 277.115 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 750/1194 | Loss: 299.897 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 760/1194 | Loss: 278.291 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 770/1194 | Loss: 284.373 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 780/1194 | Loss: 277.165 | Accuracy: 0.300\n",
      "[Epoch: 143/200] - Step: 790/1194 | Loss: 289.567 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 800/1194 | Loss: 303.649 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 810/1194 | Loss: 298.533 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 820/1194 | Loss: 305.209 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 830/1194 | Loss: 297.410 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 840/1194 | Loss: 300.065 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 850/1194 | Loss: 301.818 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 860/1194 | Loss: 302.926 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 870/1194 | Loss: 327.918 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 880/1194 | Loss: 294.392 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 890/1194 | Loss: 296.186 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 900/1194 | Loss: 278.800 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 910/1194 | Loss: 302.328 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 920/1194 | Loss: 303.339 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 930/1194 | Loss: 295.010 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 940/1194 | Loss: 312.478 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 950/1194 | Loss: 297.542 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 960/1194 | Loss: 308.064 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 970/1194 | Loss: 303.556 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 980/1194 | Loss: 293.833 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 990/1194 | Loss: 291.813 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1000/1194 | Loss: 305.808 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1010/1194 | Loss: 299.319 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1020/1194 | Loss: 295.466 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1030/1194 | Loss: 312.017 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1040/1194 | Loss: 333.358 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1050/1194 | Loss: 298.445 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1060/1194 | Loss: 322.315 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1070/1194 | Loss: 295.151 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 1080/1194 | Loss: 280.553 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 1090/1194 | Loss: 304.986 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1100/1194 | Loss: 301.299 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 1110/1194 | Loss: 330.279 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1120/1194 | Loss: 302.663 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1130/1194 | Loss: 281.121 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 1140/1194 | Loss: 298.614 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1150/1194 | Loss: 302.722 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1160/1194 | Loss: 297.421 | Accuracy: 0.000\n",
      "[Epoch: 143/200] - Step: 1170/1194 | Loss: 301.985 | Accuracy: 0.100\n",
      "[Epoch: 143/200] - Step: 1180/1194 | Loss: 288.913 | Accuracy: 0.200\n",
      "[Epoch: 143/200] - Step: 1190/1194 | Loss: 295.539 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 144/200] - Step: 10/1194 | Loss: 296.096 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 20/1194 | Loss: 304.386 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 30/1194 | Loss: 313.228 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 40/1194 | Loss: 297.982 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 50/1194 | Loss: 295.643 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 60/1194 | Loss: 298.167 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 70/1194 | Loss: 280.296 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 80/1194 | Loss: 301.563 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 90/1194 | Loss: 292.392 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 100/1194 | Loss: 283.016 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 110/1194 | Loss: 305.052 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 120/1194 | Loss: 296.586 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 130/1194 | Loss: 282.729 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 140/1194 | Loss: 298.004 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 150/1194 | Loss: 295.597 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 160/1194 | Loss: 293.754 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 170/1194 | Loss: 311.821 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 180/1194 | Loss: 283.975 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 190/1194 | Loss: 284.075 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 200/1194 | Loss: 307.474 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 210/1194 | Loss: 324.509 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 220/1194 | Loss: 312.800 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 230/1194 | Loss: 305.013 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 240/1194 | Loss: 285.745 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 250/1194 | Loss: 299.890 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 260/1194 | Loss: 289.230 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 270/1194 | Loss: 289.812 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 280/1194 | Loss: 281.845 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 290/1194 | Loss: 286.904 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 300/1194 | Loss: 285.362 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 310/1194 | Loss: 300.628 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 320/1194 | Loss: 295.188 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 330/1194 | Loss: 288.083 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 340/1194 | Loss: 305.590 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 350/1194 | Loss: 306.785 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 360/1194 | Loss: 284.086 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 370/1194 | Loss: 283.077 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 380/1194 | Loss: 278.166 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 390/1194 | Loss: 301.278 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 400/1194 | Loss: 294.699 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 410/1194 | Loss: 295.516 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 420/1194 | Loss: 297.198 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 430/1194 | Loss: 299.689 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 440/1194 | Loss: 271.556 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 450/1194 | Loss: 314.180 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 460/1194 | Loss: 295.476 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 470/1194 | Loss: 297.502 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 480/1194 | Loss: 300.209 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 490/1194 | Loss: 303.386 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 500/1194 | Loss: 295.645 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 510/1194 | Loss: 299.539 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 520/1194 | Loss: 284.506 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 530/1194 | Loss: 285.795 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 540/1194 | Loss: 292.899 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 550/1194 | Loss: 290.191 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 560/1194 | Loss: 309.686 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 570/1194 | Loss: 295.233 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 580/1194 | Loss: 295.174 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 590/1194 | Loss: 301.598 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 600/1194 | Loss: 293.392 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 610/1194 | Loss: 297.189 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 620/1194 | Loss: 313.476 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 630/1194 | Loss: 293.532 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 640/1194 | Loss: 294.783 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 650/1194 | Loss: 306.189 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 660/1194 | Loss: 270.289 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 670/1194 | Loss: 283.716 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 680/1194 | Loss: 302.594 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 690/1194 | Loss: 316.690 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 700/1194 | Loss: 301.821 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 710/1194 | Loss: 299.341 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 720/1194 | Loss: 297.913 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 730/1194 | Loss: 300.558 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 740/1194 | Loss: 304.610 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 750/1194 | Loss: 308.087 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 760/1194 | Loss: 300.555 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 770/1194 | Loss: 304.322 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 780/1194 | Loss: 290.426 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 790/1194 | Loss: 299.981 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 800/1194 | Loss: 291.719 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 810/1194 | Loss: 300.282 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 820/1194 | Loss: 286.810 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 830/1194 | Loss: 280.508 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 840/1194 | Loss: 303.905 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 850/1194 | Loss: 301.851 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 860/1194 | Loss: 297.836 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 870/1194 | Loss: 301.275 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 880/1194 | Loss: 309.507 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 890/1194 | Loss: 275.040 | Accuracy: 0.300\n",
      "[Epoch: 144/200] - Step: 900/1194 | Loss: 309.468 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 910/1194 | Loss: 308.974 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 920/1194 | Loss: 304.810 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 930/1194 | Loss: 296.749 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 940/1194 | Loss: 308.490 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 950/1194 | Loss: 298.298 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 960/1194 | Loss: 295.958 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 970/1194 | Loss: 328.476 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 980/1194 | Loss: 294.692 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 990/1194 | Loss: 308.980 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1000/1194 | Loss: 294.488 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1010/1194 | Loss: 302.044 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1020/1194 | Loss: 285.792 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 1030/1194 | Loss: 296.910 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 1040/1194 | Loss: 294.565 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 1050/1194 | Loss: 297.169 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1060/1194 | Loss: 302.168 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1070/1194 | Loss: 298.900 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1080/1194 | Loss: 291.770 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1090/1194 | Loss: 287.874 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1100/1194 | Loss: 286.943 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1110/1194 | Loss: 291.885 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 1120/1194 | Loss: 303.570 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1130/1194 | Loss: 291.220 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1140/1194 | Loss: 291.343 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1150/1194 | Loss: 268.754 | Accuracy: 0.500\n",
      "[Epoch: 144/200] - Step: 1160/1194 | Loss: 287.436 | Accuracy: 0.200\n",
      "[Epoch: 144/200] - Step: 1170/1194 | Loss: 304.372 | Accuracy: 0.000\n",
      "[Epoch: 144/200] - Step: 1180/1194 | Loss: 330.111 | Accuracy: 0.100\n",
      "[Epoch: 144/200] - Step: 1190/1194 | Loss: 293.523 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 145/200] - Step: 10/1194 | Loss: 313.423 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 20/1194 | Loss: 302.836 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 30/1194 | Loss: 313.062 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 40/1194 | Loss: 302.822 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 50/1194 | Loss: 293.299 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 60/1194 | Loss: 303.620 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 70/1194 | Loss: 294.437 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 80/1194 | Loss: 298.548 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 90/1194 | Loss: 280.050 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 100/1194 | Loss: 294.582 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 110/1194 | Loss: 300.751 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 120/1194 | Loss: 295.708 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 130/1194 | Loss: 283.028 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 140/1194 | Loss: 322.106 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 150/1194 | Loss: 328.202 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 160/1194 | Loss: 293.486 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 170/1194 | Loss: 304.611 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 180/1194 | Loss: 299.363 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 190/1194 | Loss: 318.923 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 200/1194 | Loss: 295.269 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 210/1194 | Loss: 292.975 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 220/1194 | Loss: 295.399 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 230/1194 | Loss: 289.989 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 240/1194 | Loss: 302.632 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 250/1194 | Loss: 298.541 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 260/1194 | Loss: 295.295 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 270/1194 | Loss: 295.747 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 280/1194 | Loss: 287.835 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 290/1194 | Loss: 304.420 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 300/1194 | Loss: 285.188 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 310/1194 | Loss: 278.882 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 320/1194 | Loss: 299.139 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 330/1194 | Loss: 311.591 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 340/1194 | Loss: 300.369 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 350/1194 | Loss: 291.816 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 360/1194 | Loss: 286.383 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 370/1194 | Loss: 301.590 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 380/1194 | Loss: 285.923 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 390/1194 | Loss: 298.077 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 400/1194 | Loss: 307.334 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 410/1194 | Loss: 291.353 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 420/1194 | Loss: 298.863 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 430/1194 | Loss: 293.983 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 440/1194 | Loss: 295.639 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 450/1194 | Loss: 265.306 | Accuracy: 0.400\n",
      "[Epoch: 145/200] - Step: 460/1194 | Loss: 294.308 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 470/1194 | Loss: 289.950 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 480/1194 | Loss: 280.304 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 490/1194 | Loss: 294.444 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 500/1194 | Loss: 303.590 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 510/1194 | Loss: 282.208 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 520/1194 | Loss: 295.689 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 530/1194 | Loss: 323.840 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 540/1194 | Loss: 314.026 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 550/1194 | Loss: 299.724 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 560/1194 | Loss: 283.554 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 570/1194 | Loss: 277.540 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 580/1194 | Loss: 291.162 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 590/1194 | Loss: 287.941 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 600/1194 | Loss: 267.020 | Accuracy: 0.400\n",
      "[Epoch: 145/200] - Step: 610/1194 | Loss: 294.972 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 620/1194 | Loss: 302.729 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 630/1194 | Loss: 296.209 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 640/1194 | Loss: 312.391 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 650/1194 | Loss: 297.930 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 660/1194 | Loss: 290.422 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 670/1194 | Loss: 299.017 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 680/1194 | Loss: 290.326 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 690/1194 | Loss: 296.610 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 700/1194 | Loss: 263.130 | Accuracy: 0.400\n",
      "[Epoch: 145/200] - Step: 710/1194 | Loss: 290.021 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 720/1194 | Loss: 303.333 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 730/1194 | Loss: 287.212 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 740/1194 | Loss: 300.180 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 750/1194 | Loss: 306.750 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 760/1194 | Loss: 300.407 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 770/1194 | Loss: 312.089 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 780/1194 | Loss: 288.024 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 790/1194 | Loss: 307.642 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 800/1194 | Loss: 299.808 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 810/1194 | Loss: 310.190 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 820/1194 | Loss: 293.299 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 830/1194 | Loss: 299.138 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 840/1194 | Loss: 307.503 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 850/1194 | Loss: 302.734 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 860/1194 | Loss: 286.798 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 870/1194 | Loss: 302.581 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 880/1194 | Loss: 306.927 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 890/1194 | Loss: 297.957 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 900/1194 | Loss: 305.537 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 910/1194 | Loss: 281.034 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 920/1194 | Loss: 291.634 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 930/1194 | Loss: 293.920 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 940/1194 | Loss: 282.663 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 950/1194 | Loss: 296.378 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 960/1194 | Loss: 294.247 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 970/1194 | Loss: 307.230 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 980/1194 | Loss: 306.631 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 990/1194 | Loss: 308.129 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1000/1194 | Loss: 280.488 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 1010/1194 | Loss: 275.417 | Accuracy: 0.300\n",
      "[Epoch: 145/200] - Step: 1020/1194 | Loss: 278.637 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 1030/1194 | Loss: 295.532 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1040/1194 | Loss: 289.773 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1050/1194 | Loss: 298.420 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1060/1194 | Loss: 346.055 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1070/1194 | Loss: 286.499 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1080/1194 | Loss: 306.868 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1090/1194 | Loss: 281.398 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 1100/1194 | Loss: 302.402 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1110/1194 | Loss: 288.382 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 1120/1194 | Loss: 304.418 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1130/1194 | Loss: 283.025 | Accuracy: 0.200\n",
      "[Epoch: 145/200] - Step: 1140/1194 | Loss: 327.775 | Accuracy: 0.000\n",
      "[Epoch: 145/200] - Step: 1150/1194 | Loss: 295.818 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1160/1194 | Loss: 289.007 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1170/1194 | Loss: 298.834 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1180/1194 | Loss: 298.022 | Accuracy: 0.100\n",
      "[Epoch: 145/200] - Step: 1190/1194 | Loss: 315.749 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 146/200] - Step: 10/1194 | Loss: 277.200 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 20/1194 | Loss: 285.900 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 30/1194 | Loss: 298.530 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 40/1194 | Loss: 286.501 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 50/1194 | Loss: 286.688 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 60/1194 | Loss: 296.732 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 70/1194 | Loss: 285.134 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 80/1194 | Loss: 309.988 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 90/1194 | Loss: 295.748 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 100/1194 | Loss: 298.369 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 110/1194 | Loss: 286.320 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 120/1194 | Loss: 290.217 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 130/1194 | Loss: 277.824 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 140/1194 | Loss: 311.755 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 150/1194 | Loss: 281.161 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 160/1194 | Loss: 270.035 | Accuracy: 0.400\n",
      "[Epoch: 146/200] - Step: 170/1194 | Loss: 290.304 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 180/1194 | Loss: 276.811 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 190/1194 | Loss: 307.925 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 200/1194 | Loss: 295.289 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 210/1194 | Loss: 278.885 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 220/1194 | Loss: 291.863 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 230/1194 | Loss: 301.088 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 240/1194 | Loss: 337.427 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 250/1194 | Loss: 273.181 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 260/1194 | Loss: 298.128 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 270/1194 | Loss: 311.370 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 280/1194 | Loss: 293.881 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 290/1194 | Loss: 282.785 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 300/1194 | Loss: 305.719 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 310/1194 | Loss: 297.508 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 320/1194 | Loss: 297.994 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 330/1194 | Loss: 290.161 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 340/1194 | Loss: 304.230 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 350/1194 | Loss: 311.454 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 360/1194 | Loss: 299.350 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 370/1194 | Loss: 301.788 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 380/1194 | Loss: 282.211 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 390/1194 | Loss: 308.792 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 400/1194 | Loss: 294.265 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 410/1194 | Loss: 295.750 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 420/1194 | Loss: 311.486 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 430/1194 | Loss: 271.090 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 440/1194 | Loss: 304.068 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 450/1194 | Loss: 284.721 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 460/1194 | Loss: 276.601 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 470/1194 | Loss: 300.912 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 480/1194 | Loss: 305.156 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 490/1194 | Loss: 286.497 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 500/1194 | Loss: 307.642 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 510/1194 | Loss: 279.345 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 520/1194 | Loss: 297.766 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 530/1194 | Loss: 335.820 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 540/1194 | Loss: 319.765 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 550/1194 | Loss: 301.963 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 560/1194 | Loss: 299.759 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 570/1194 | Loss: 298.311 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 580/1194 | Loss: 308.180 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 590/1194 | Loss: 305.205 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 600/1194 | Loss: 274.491 | Accuracy: 0.400\n",
      "[Epoch: 146/200] - Step: 610/1194 | Loss: 298.397 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 620/1194 | Loss: 332.159 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 630/1194 | Loss: 280.429 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 640/1194 | Loss: 305.571 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 650/1194 | Loss: 296.420 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 660/1194 | Loss: 298.781 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 670/1194 | Loss: 291.518 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 680/1194 | Loss: 308.200 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 690/1194 | Loss: 287.758 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 700/1194 | Loss: 287.388 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 710/1194 | Loss: 295.132 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 720/1194 | Loss: 285.581 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 730/1194 | Loss: 305.958 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 740/1194 | Loss: 305.805 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 750/1194 | Loss: 296.450 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 760/1194 | Loss: 303.632 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 770/1194 | Loss: 293.504 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 780/1194 | Loss: 287.904 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 790/1194 | Loss: 288.667 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 800/1194 | Loss: 283.662 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 810/1194 | Loss: 311.834 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 820/1194 | Loss: 300.789 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 830/1194 | Loss: 302.276 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 840/1194 | Loss: 306.567 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 850/1194 | Loss: 298.264 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 860/1194 | Loss: 294.358 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 870/1194 | Loss: 302.865 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 880/1194 | Loss: 296.827 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 890/1194 | Loss: 276.738 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 900/1194 | Loss: 313.545 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 910/1194 | Loss: 288.820 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 920/1194 | Loss: 312.804 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 930/1194 | Loss: 315.781 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 940/1194 | Loss: 316.174 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 950/1194 | Loss: 283.470 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 960/1194 | Loss: 309.445 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 970/1194 | Loss: 296.427 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 980/1194 | Loss: 287.714 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 990/1194 | Loss: 300.542 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1000/1194 | Loss: 301.403 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 1010/1194 | Loss: 314.624 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1020/1194 | Loss: 299.830 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 1030/1194 | Loss: 301.669 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1040/1194 | Loss: 312.399 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1050/1194 | Loss: 298.620 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1060/1194 | Loss: 294.960 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 1070/1194 | Loss: 298.924 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1080/1194 | Loss: 302.127 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1090/1194 | Loss: 298.370 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1100/1194 | Loss: 297.248 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 1110/1194 | Loss: 305.118 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 1120/1194 | Loss: 270.602 | Accuracy: 0.500\n",
      "[Epoch: 146/200] - Step: 1130/1194 | Loss: 308.569 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1140/1194 | Loss: 293.039 | Accuracy: 0.200\n",
      "[Epoch: 146/200] - Step: 1150/1194 | Loss: 287.719 | Accuracy: 0.100\n",
      "[Epoch: 146/200] - Step: 1160/1194 | Loss: 275.221 | Accuracy: 0.300\n",
      "[Epoch: 146/200] - Step: 1170/1194 | Loss: 296.964 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1180/1194 | Loss: 301.346 | Accuracy: 0.000\n",
      "[Epoch: 146/200] - Step: 1190/1194 | Loss: 291.554 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 147/200] - Step: 10/1194 | Loss: 305.824 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 20/1194 | Loss: 290.640 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 30/1194 | Loss: 295.828 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 40/1194 | Loss: 303.419 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 50/1194 | Loss: 297.447 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 60/1194 | Loss: 311.883 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 70/1194 | Loss: 291.639 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 80/1194 | Loss: 304.105 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 90/1194 | Loss: 302.012 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 100/1194 | Loss: 295.251 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 110/1194 | Loss: 327.810 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 120/1194 | Loss: 300.130 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 130/1194 | Loss: 298.240 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 140/1194 | Loss: 291.535 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 150/1194 | Loss: 298.475 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 160/1194 | Loss: 298.261 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 170/1194 | Loss: 303.911 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 180/1194 | Loss: 283.155 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 190/1194 | Loss: 298.932 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 200/1194 | Loss: 303.352 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 210/1194 | Loss: 270.381 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 220/1194 | Loss: 296.373 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 230/1194 | Loss: 297.383 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 240/1194 | Loss: 311.047 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 250/1194 | Loss: 306.864 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 260/1194 | Loss: 299.406 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 270/1194 | Loss: 274.650 | Accuracy: 0.400\n",
      "[Epoch: 147/200] - Step: 280/1194 | Loss: 291.474 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 290/1194 | Loss: 309.055 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 300/1194 | Loss: 297.899 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 310/1194 | Loss: 294.740 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 320/1194 | Loss: 294.211 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 330/1194 | Loss: 304.878 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 340/1194 | Loss: 311.736 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 350/1194 | Loss: 277.312 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 360/1194 | Loss: 299.414 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 370/1194 | Loss: 307.457 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 380/1194 | Loss: 287.501 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 390/1194 | Loss: 308.156 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 400/1194 | Loss: 290.346 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 410/1194 | Loss: 303.673 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 420/1194 | Loss: 300.592 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 430/1194 | Loss: 291.180 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 440/1194 | Loss: 288.244 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 450/1194 | Loss: 306.370 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 460/1194 | Loss: 285.855 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 470/1194 | Loss: 288.020 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 480/1194 | Loss: 300.743 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 490/1194 | Loss: 296.231 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 500/1194 | Loss: 287.002 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 510/1194 | Loss: 284.466 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 520/1194 | Loss: 293.793 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 530/1194 | Loss: 265.233 | Accuracy: 0.400\n",
      "[Epoch: 147/200] - Step: 540/1194 | Loss: 302.708 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 550/1194 | Loss: 301.521 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 560/1194 | Loss: 305.783 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 570/1194 | Loss: 306.947 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 580/1194 | Loss: 301.364 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 590/1194 | Loss: 294.025 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 600/1194 | Loss: 297.534 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 610/1194 | Loss: 307.989 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 620/1194 | Loss: 277.015 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 630/1194 | Loss: 307.556 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 640/1194 | Loss: 329.197 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 650/1194 | Loss: 303.278 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 660/1194 | Loss: 292.827 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 670/1194 | Loss: 299.143 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 680/1194 | Loss: 312.655 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 690/1194 | Loss: 277.659 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 700/1194 | Loss: 284.598 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 710/1194 | Loss: 296.319 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 720/1194 | Loss: 283.959 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 730/1194 | Loss: 289.531 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 740/1194 | Loss: 292.689 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 750/1194 | Loss: 296.028 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 760/1194 | Loss: 295.714 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 770/1194 | Loss: 300.380 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 780/1194 | Loss: 280.634 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 790/1194 | Loss: 277.147 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 800/1194 | Loss: 306.689 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 810/1194 | Loss: 317.429 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 820/1194 | Loss: 298.993 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 830/1194 | Loss: 274.368 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 840/1194 | Loss: 304.381 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 850/1194 | Loss: 305.167 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 860/1194 | Loss: 291.924 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 870/1194 | Loss: 301.186 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 880/1194 | Loss: 285.624 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 890/1194 | Loss: 291.978 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 900/1194 | Loss: 299.869 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 910/1194 | Loss: 293.872 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 920/1194 | Loss: 273.551 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 930/1194 | Loss: 293.223 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 940/1194 | Loss: 292.554 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 950/1194 | Loss: 312.279 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 960/1194 | Loss: 286.427 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 970/1194 | Loss: 284.851 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 980/1194 | Loss: 291.691 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 990/1194 | Loss: 294.346 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1000/1194 | Loss: 292.238 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1010/1194 | Loss: 294.624 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 1020/1194 | Loss: 338.590 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1030/1194 | Loss: 278.895 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 1040/1194 | Loss: 305.558 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 1050/1194 | Loss: 301.510 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1060/1194 | Loss: 305.925 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1070/1194 | Loss: 302.198 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1080/1194 | Loss: 279.209 | Accuracy: 0.300\n",
      "[Epoch: 147/200] - Step: 1090/1194 | Loss: 345.624 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1100/1194 | Loss: 301.812 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1110/1194 | Loss: 319.007 | Accuracy: 0.000\n",
      "[Epoch: 147/200] - Step: 1120/1194 | Loss: 310.563 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1130/1194 | Loss: 302.785 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1140/1194 | Loss: 290.118 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1150/1194 | Loss: 300.169 | Accuracy: 0.100\n",
      "[Epoch: 147/200] - Step: 1160/1194 | Loss: 290.320 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 1170/1194 | Loss: 270.233 | Accuracy: 0.400\n",
      "[Epoch: 147/200] - Step: 1180/1194 | Loss: 283.516 | Accuracy: 0.200\n",
      "[Epoch: 147/200] - Step: 1190/1194 | Loss: 287.189 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 148/200] - Step: 10/1194 | Loss: 297.119 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 20/1194 | Loss: 298.938 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 30/1194 | Loss: 283.253 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 40/1194 | Loss: 296.927 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 50/1194 | Loss: 265.307 | Accuracy: 0.400\n",
      "[Epoch: 148/200] - Step: 60/1194 | Loss: 295.294 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 70/1194 | Loss: 289.977 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 80/1194 | Loss: 273.241 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 90/1194 | Loss: 279.013 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 100/1194 | Loss: 297.885 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 110/1194 | Loss: 286.996 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 120/1194 | Loss: 305.536 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 130/1194 | Loss: 299.481 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 140/1194 | Loss: 306.289 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 150/1194 | Loss: 317.046 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 160/1194 | Loss: 277.784 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 170/1194 | Loss: 290.396 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 180/1194 | Loss: 274.157 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 190/1194 | Loss: 289.338 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 200/1194 | Loss: 294.230 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 210/1194 | Loss: 322.155 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 220/1194 | Loss: 284.721 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 230/1194 | Loss: 297.434 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 240/1194 | Loss: 287.042 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 250/1194 | Loss: 335.789 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 260/1194 | Loss: 297.014 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 270/1194 | Loss: 287.242 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 280/1194 | Loss: 296.361 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 290/1194 | Loss: 276.755 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 300/1194 | Loss: 302.873 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 310/1194 | Loss: 314.102 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 320/1194 | Loss: 279.400 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 330/1194 | Loss: 285.597 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 340/1194 | Loss: 293.857 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 350/1194 | Loss: 286.554 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 360/1194 | Loss: 296.552 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 370/1194 | Loss: 314.240 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 380/1194 | Loss: 319.206 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 390/1194 | Loss: 296.080 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 400/1194 | Loss: 285.150 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 410/1194 | Loss: 300.203 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 420/1194 | Loss: 297.879 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 430/1194 | Loss: 298.579 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 440/1194 | Loss: 302.454 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 450/1194 | Loss: 299.819 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 460/1194 | Loss: 306.803 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 470/1194 | Loss: 320.852 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 480/1194 | Loss: 306.931 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 490/1194 | Loss: 280.943 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 500/1194 | Loss: 276.305 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 510/1194 | Loss: 290.767 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 520/1194 | Loss: 309.036 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 530/1194 | Loss: 271.859 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 540/1194 | Loss: 309.457 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 550/1194 | Loss: 304.958 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 560/1194 | Loss: 305.093 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 570/1194 | Loss: 296.619 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 580/1194 | Loss: 284.455 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 590/1194 | Loss: 291.239 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 600/1194 | Loss: 290.830 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 610/1194 | Loss: 310.478 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 620/1194 | Loss: 296.053 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 630/1194 | Loss: 296.723 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 640/1194 | Loss: 288.046 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 650/1194 | Loss: 300.985 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 660/1194 | Loss: 293.961 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 670/1194 | Loss: 298.893 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 680/1194 | Loss: 273.039 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 690/1194 | Loss: 296.035 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 700/1194 | Loss: 304.199 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 710/1194 | Loss: 306.857 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 720/1194 | Loss: 294.624 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 730/1194 | Loss: 291.883 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 740/1194 | Loss: 324.823 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 750/1194 | Loss: 314.808 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 760/1194 | Loss: 313.369 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 770/1194 | Loss: 305.834 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 780/1194 | Loss: 293.279 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 790/1194 | Loss: 276.638 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 800/1194 | Loss: 300.490 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 810/1194 | Loss: 303.265 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 820/1194 | Loss: 301.343 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 830/1194 | Loss: 280.308 | Accuracy: 0.400\n",
      "[Epoch: 148/200] - Step: 840/1194 | Loss: 309.088 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 850/1194 | Loss: 289.302 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 860/1194 | Loss: 299.121 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 870/1194 | Loss: 298.377 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 880/1194 | Loss: 306.079 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 890/1194 | Loss: 306.962 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 900/1194 | Loss: 300.332 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 910/1194 | Loss: 289.077 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 920/1194 | Loss: 283.601 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 930/1194 | Loss: 305.486 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 940/1194 | Loss: 298.122 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 950/1194 | Loss: 341.712 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 960/1194 | Loss: 281.562 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 970/1194 | Loss: 291.014 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 980/1194 | Loss: 300.033 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 990/1194 | Loss: 301.672 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 1000/1194 | Loss: 317.943 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 1010/1194 | Loss: 306.305 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 1020/1194 | Loss: 304.218 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 1030/1194 | Loss: 292.778 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 1040/1194 | Loss: 283.549 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 1050/1194 | Loss: 291.042 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 1060/1194 | Loss: 293.282 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1070/1194 | Loss: 302.166 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 1080/1194 | Loss: 296.760 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1090/1194 | Loss: 295.609 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1100/1194 | Loss: 291.951 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1110/1194 | Loss: 293.360 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 1120/1194 | Loss: 302.421 | Accuracy: 0.000\n",
      "[Epoch: 148/200] - Step: 1130/1194 | Loss: 300.277 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1140/1194 | Loss: 294.260 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1150/1194 | Loss: 301.572 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1160/1194 | Loss: 296.509 | Accuracy: 0.100\n",
      "[Epoch: 148/200] - Step: 1170/1194 | Loss: 276.033 | Accuracy: 0.300\n",
      "[Epoch: 148/200] - Step: 1180/1194 | Loss: 298.289 | Accuracy: 0.200\n",
      "[Epoch: 148/200] - Step: 1190/1194 | Loss: 300.341 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 149/200] - Step: 10/1194 | Loss: 302.135 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 20/1194 | Loss: 286.203 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 30/1194 | Loss: 308.984 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 40/1194 | Loss: 302.604 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 50/1194 | Loss: 286.174 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 60/1194 | Loss: 302.060 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 70/1194 | Loss: 298.768 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 80/1194 | Loss: 280.186 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 90/1194 | Loss: 293.216 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 100/1194 | Loss: 301.293 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 110/1194 | Loss: 303.402 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 120/1194 | Loss: 302.290 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 130/1194 | Loss: 285.405 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 140/1194 | Loss: 275.868 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 150/1194 | Loss: 282.401 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 160/1194 | Loss: 267.144 | Accuracy: 0.400\n",
      "[Epoch: 149/200] - Step: 170/1194 | Loss: 308.898 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 180/1194 | Loss: 318.660 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 190/1194 | Loss: 294.386 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 200/1194 | Loss: 276.705 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 210/1194 | Loss: 303.943 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 220/1194 | Loss: 290.943 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 230/1194 | Loss: 313.198 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 240/1194 | Loss: 308.708 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 250/1194 | Loss: 289.172 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 260/1194 | Loss: 299.876 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 270/1194 | Loss: 294.154 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 280/1194 | Loss: 316.267 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 290/1194 | Loss: 297.481 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 300/1194 | Loss: 292.438 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 310/1194 | Loss: 309.397 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 320/1194 | Loss: 308.048 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 330/1194 | Loss: 307.910 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 340/1194 | Loss: 303.278 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 350/1194 | Loss: 295.117 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 360/1194 | Loss: 293.104 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 370/1194 | Loss: 297.660 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 380/1194 | Loss: 296.294 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 390/1194 | Loss: 293.829 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 400/1194 | Loss: 301.445 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 410/1194 | Loss: 300.541 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 420/1194 | Loss: 309.126 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 430/1194 | Loss: 292.434 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 440/1194 | Loss: 282.759 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 450/1194 | Loss: 282.694 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 460/1194 | Loss: 295.876 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 470/1194 | Loss: 309.598 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 480/1194 | Loss: 306.590 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 490/1194 | Loss: 275.259 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 500/1194 | Loss: 293.481 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 510/1194 | Loss: 305.402 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 520/1194 | Loss: 289.977 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 530/1194 | Loss: 295.777 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 540/1194 | Loss: 286.390 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 550/1194 | Loss: 306.050 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 560/1194 | Loss: 271.239 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 570/1194 | Loss: 303.464 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 580/1194 | Loss: 293.289 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 590/1194 | Loss: 294.554 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 600/1194 | Loss: 295.197 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 610/1194 | Loss: 294.692 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 620/1194 | Loss: 304.907 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 630/1194 | Loss: 303.384 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 640/1194 | Loss: 335.915 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 650/1194 | Loss: 301.123 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 660/1194 | Loss: 308.727 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 670/1194 | Loss: 299.409 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 680/1194 | Loss: 303.794 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 690/1194 | Loss: 300.178 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 700/1194 | Loss: 285.971 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 710/1194 | Loss: 287.950 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 720/1194 | Loss: 297.921 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 730/1194 | Loss: 296.200 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 740/1194 | Loss: 276.637 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 750/1194 | Loss: 286.913 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 760/1194 | Loss: 293.947 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 770/1194 | Loss: 270.251 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 780/1194 | Loss: 308.438 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 790/1194 | Loss: 331.453 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 800/1194 | Loss: 279.072 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 810/1194 | Loss: 300.479 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 820/1194 | Loss: 289.875 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 830/1194 | Loss: 321.658 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 840/1194 | Loss: 269.788 | Accuracy: 0.300\n",
      "[Epoch: 149/200] - Step: 850/1194 | Loss: 285.580 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 860/1194 | Loss: 285.574 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 870/1194 | Loss: 308.778 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 880/1194 | Loss: 268.633 | Accuracy: 0.400\n",
      "[Epoch: 149/200] - Step: 890/1194 | Loss: 295.362 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 900/1194 | Loss: 285.162 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 910/1194 | Loss: 302.551 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 920/1194 | Loss: 281.233 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 930/1194 | Loss: 302.609 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 940/1194 | Loss: 314.049 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 950/1194 | Loss: 300.199 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 960/1194 | Loss: 312.658 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 970/1194 | Loss: 294.587 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 980/1194 | Loss: 285.075 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 990/1194 | Loss: 272.435 | Accuracy: 0.400\n",
      "[Epoch: 149/200] - Step: 1000/1194 | Loss: 272.586 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 1010/1194 | Loss: 310.960 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1020/1194 | Loss: 293.002 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 1030/1194 | Loss: 325.347 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1040/1194 | Loss: 308.467 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1050/1194 | Loss: 292.929 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1060/1194 | Loss: 325.794 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1070/1194 | Loss: 298.644 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1080/1194 | Loss: 298.963 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1090/1194 | Loss: 307.800 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1100/1194 | Loss: 289.114 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 1110/1194 | Loss: 302.950 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1120/1194 | Loss: 297.121 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1130/1194 | Loss: 306.689 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1140/1194 | Loss: 301.083 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1150/1194 | Loss: 314.089 | Accuracy: 0.000\n",
      "[Epoch: 149/200] - Step: 1160/1194 | Loss: 288.623 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 1170/1194 | Loss: 293.949 | Accuracy: 0.200\n",
      "[Epoch: 149/200] - Step: 1180/1194 | Loss: 296.198 | Accuracy: 0.100\n",
      "[Epoch: 149/200] - Step: 1190/1194 | Loss: 279.326 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 150/200] - Step: 10/1194 | Loss: 311.412 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 20/1194 | Loss: 290.454 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 30/1194 | Loss: 288.351 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 40/1194 | Loss: 290.173 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 50/1194 | Loss: 296.119 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 60/1194 | Loss: 318.579 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 70/1194 | Loss: 287.740 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 80/1194 | Loss: 302.092 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 90/1194 | Loss: 332.395 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 100/1194 | Loss: 272.331 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 110/1194 | Loss: 304.348 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 120/1194 | Loss: 296.487 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 130/1194 | Loss: 298.728 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 140/1194 | Loss: 292.716 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 150/1194 | Loss: 290.102 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 160/1194 | Loss: 304.545 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 170/1194 | Loss: 303.390 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 180/1194 | Loss: 309.111 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 190/1194 | Loss: 326.974 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 200/1194 | Loss: 298.045 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 210/1194 | Loss: 297.601 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 220/1194 | Loss: 315.172 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 230/1194 | Loss: 287.300 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 240/1194 | Loss: 299.636 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 250/1194 | Loss: 300.846 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 260/1194 | Loss: 301.460 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 270/1194 | Loss: 298.903 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 280/1194 | Loss: 295.045 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 290/1194 | Loss: 320.863 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 300/1194 | Loss: 296.273 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 310/1194 | Loss: 287.888 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 320/1194 | Loss: 306.282 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 330/1194 | Loss: 301.206 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 340/1194 | Loss: 298.477 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 350/1194 | Loss: 307.120 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 360/1194 | Loss: 299.938 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 370/1194 | Loss: 306.604 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 380/1194 | Loss: 301.754 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 390/1194 | Loss: 297.601 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 400/1194 | Loss: 280.810 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 410/1194 | Loss: 296.890 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 420/1194 | Loss: 296.616 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 430/1194 | Loss: 300.286 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 440/1194 | Loss: 299.199 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 450/1194 | Loss: 301.698 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 460/1194 | Loss: 304.108 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 470/1194 | Loss: 298.045 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 480/1194 | Loss: 302.600 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 490/1194 | Loss: 299.621 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 500/1194 | Loss: 286.623 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 510/1194 | Loss: 286.552 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 520/1194 | Loss: 296.978 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 530/1194 | Loss: 279.036 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 540/1194 | Loss: 293.955 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 550/1194 | Loss: 272.206 | Accuracy: 0.400\n",
      "[Epoch: 150/200] - Step: 560/1194 | Loss: 283.852 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 570/1194 | Loss: 304.319 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 580/1194 | Loss: 320.417 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 590/1194 | Loss: 296.278 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 600/1194 | Loss: 277.048 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 610/1194 | Loss: 294.609 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 620/1194 | Loss: 303.756 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 630/1194 | Loss: 295.228 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 640/1194 | Loss: 304.099 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 650/1194 | Loss: 290.161 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 660/1194 | Loss: 300.324 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 670/1194 | Loss: 306.281 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 680/1194 | Loss: 287.580 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 690/1194 | Loss: 317.015 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 700/1194 | Loss: 286.351 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 710/1194 | Loss: 297.625 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 720/1194 | Loss: 288.929 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 730/1194 | Loss: 301.350 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 740/1194 | Loss: 309.083 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 750/1194 | Loss: 309.017 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 760/1194 | Loss: 297.037 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 770/1194 | Loss: 292.071 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 780/1194 | Loss: 305.173 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 790/1194 | Loss: 287.359 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 800/1194 | Loss: 285.746 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 810/1194 | Loss: 285.164 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 820/1194 | Loss: 295.209 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 830/1194 | Loss: 301.309 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 840/1194 | Loss: 305.135 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 850/1194 | Loss: 301.223 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 860/1194 | Loss: 283.288 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 870/1194 | Loss: 302.414 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 880/1194 | Loss: 285.120 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 890/1194 | Loss: 298.874 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 900/1194 | Loss: 296.847 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 910/1194 | Loss: 296.337 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 920/1194 | Loss: 294.394 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 930/1194 | Loss: 290.008 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 940/1194 | Loss: 268.667 | Accuracy: 0.400\n",
      "[Epoch: 150/200] - Step: 950/1194 | Loss: 289.566 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 960/1194 | Loss: 290.789 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 970/1194 | Loss: 298.312 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 980/1194 | Loss: 282.069 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 990/1194 | Loss: 309.416 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 1000/1194 | Loss: 303.943 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1010/1194 | Loss: 288.923 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1020/1194 | Loss: 283.520 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 1030/1194 | Loss: 301.106 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1040/1194 | Loss: 273.266 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 1050/1194 | Loss: 295.384 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 1060/1194 | Loss: 320.518 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 1070/1194 | Loss: 295.893 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1080/1194 | Loss: 311.648 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 1090/1194 | Loss: 276.765 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 1100/1194 | Loss: 285.013 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 1110/1194 | Loss: 291.722 | Accuracy: 0.000\n",
      "[Epoch: 150/200] - Step: 1120/1194 | Loss: 296.971 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1130/1194 | Loss: 298.200 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1140/1194 | Loss: 298.438 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1150/1194 | Loss: 285.942 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1160/1194 | Loss: 262.854 | Accuracy: 0.300\n",
      "[Epoch: 150/200] - Step: 1170/1194 | Loss: 306.726 | Accuracy: 0.100\n",
      "[Epoch: 150/200] - Step: 1180/1194 | Loss: 295.194 | Accuracy: 0.200\n",
      "[Epoch: 150/200] - Step: 1190/1194 | Loss: 306.904 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 151/200] - Step: 10/1194 | Loss: 297.047 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 20/1194 | Loss: 286.611 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 30/1194 | Loss: 277.371 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 40/1194 | Loss: 304.197 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 50/1194 | Loss: 286.604 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 60/1194 | Loss: 294.548 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 70/1194 | Loss: 288.691 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 80/1194 | Loss: 295.874 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 90/1194 | Loss: 288.862 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 100/1194 | Loss: 283.025 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 110/1194 | Loss: 290.183 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 120/1194 | Loss: 293.108 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 130/1194 | Loss: 302.241 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 140/1194 | Loss: 284.952 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 150/1194 | Loss: 289.407 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 160/1194 | Loss: 281.233 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 170/1194 | Loss: 301.053 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 180/1194 | Loss: 288.478 | Accuracy: 0.300\n",
      "[Epoch: 151/200] - Step: 190/1194 | Loss: 285.351 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 200/1194 | Loss: 300.577 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 210/1194 | Loss: 307.076 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 220/1194 | Loss: 304.507 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 230/1194 | Loss: 299.894 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 240/1194 | Loss: 294.936 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 250/1194 | Loss: 305.406 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 260/1194 | Loss: 302.190 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 270/1194 | Loss: 295.168 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 280/1194 | Loss: 288.347 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 290/1194 | Loss: 291.822 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 300/1194 | Loss: 291.479 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 310/1194 | Loss: 299.650 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 320/1194 | Loss: 287.151 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 330/1194 | Loss: 309.483 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 340/1194 | Loss: 301.314 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 350/1194 | Loss: 297.948 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 360/1194 | Loss: 311.483 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 370/1194 | Loss: 295.806 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 380/1194 | Loss: 299.184 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 390/1194 | Loss: 294.944 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 400/1194 | Loss: 304.719 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 410/1194 | Loss: 307.169 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 420/1194 | Loss: 286.178 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 430/1194 | Loss: 290.857 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 440/1194 | Loss: 300.597 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 450/1194 | Loss: 280.097 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 460/1194 | Loss: 310.497 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 470/1194 | Loss: 293.506 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 480/1194 | Loss: 298.686 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 490/1194 | Loss: 312.479 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 500/1194 | Loss: 289.282 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 510/1194 | Loss: 288.032 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 520/1194 | Loss: 289.957 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 530/1194 | Loss: 294.664 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 540/1194 | Loss: 278.486 | Accuracy: 0.300\n",
      "[Epoch: 151/200] - Step: 550/1194 | Loss: 305.245 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 560/1194 | Loss: 299.554 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 570/1194 | Loss: 291.612 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 580/1194 | Loss: 296.786 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 590/1194 | Loss: 303.326 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 600/1194 | Loss: 309.059 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 610/1194 | Loss: 268.026 | Accuracy: 0.300\n",
      "[Epoch: 151/200] - Step: 620/1194 | Loss: 296.719 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 630/1194 | Loss: 293.111 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 640/1194 | Loss: 299.837 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 650/1194 | Loss: 305.493 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 660/1194 | Loss: 286.521 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 670/1194 | Loss: 291.059 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 680/1194 | Loss: 289.730 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 690/1194 | Loss: 290.124 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 700/1194 | Loss: 285.134 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 710/1194 | Loss: 304.711 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 720/1194 | Loss: 282.454 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 730/1194 | Loss: 307.633 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 740/1194 | Loss: 311.592 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 750/1194 | Loss: 297.918 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 760/1194 | Loss: 305.122 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 770/1194 | Loss: 298.837 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 780/1194 | Loss: 318.796 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 790/1194 | Loss: 279.584 | Accuracy: 0.300\n",
      "[Epoch: 151/200] - Step: 800/1194 | Loss: 319.838 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 810/1194 | Loss: 313.800 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 820/1194 | Loss: 328.032 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 830/1194 | Loss: 296.213 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 840/1194 | Loss: 301.102 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 850/1194 | Loss: 285.582 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 860/1194 | Loss: 287.857 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 870/1194 | Loss: 305.114 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 880/1194 | Loss: 286.220 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 890/1194 | Loss: 270.147 | Accuracy: 0.500\n",
      "[Epoch: 151/200] - Step: 900/1194 | Loss: 293.992 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 910/1194 | Loss: 290.454 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 920/1194 | Loss: 291.390 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 930/1194 | Loss: 298.300 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 940/1194 | Loss: 309.546 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 950/1194 | Loss: 294.462 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 960/1194 | Loss: 286.607 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 970/1194 | Loss: 285.418 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 980/1194 | Loss: 299.276 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 990/1194 | Loss: 304.130 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1000/1194 | Loss: 301.278 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1010/1194 | Loss: 296.392 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1020/1194 | Loss: 284.332 | Accuracy: 0.300\n",
      "[Epoch: 151/200] - Step: 1030/1194 | Loss: 296.677 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1040/1194 | Loss: 292.062 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 1050/1194 | Loss: 304.245 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1060/1194 | Loss: 309.367 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1070/1194 | Loss: 289.181 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1080/1194 | Loss: 311.728 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 1090/1194 | Loss: 322.909 | Accuracy: 0.200\n",
      "[Epoch: 151/200] - Step: 1100/1194 | Loss: 300.551 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1110/1194 | Loss: 299.607 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1120/1194 | Loss: 297.036 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1130/1194 | Loss: 305.513 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1140/1194 | Loss: 328.600 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1150/1194 | Loss: 300.551 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1160/1194 | Loss: 298.238 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1170/1194 | Loss: 321.571 | Accuracy: 0.000\n",
      "[Epoch: 151/200] - Step: 1180/1194 | Loss: 290.002 | Accuracy: 0.100\n",
      "[Epoch: 151/200] - Step: 1190/1194 | Loss: 288.669 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 152/200] - Step: 10/1194 | Loss: 300.503 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 20/1194 | Loss: 299.921 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 30/1194 | Loss: 298.149 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 40/1194 | Loss: 302.945 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 50/1194 | Loss: 292.214 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 60/1194 | Loss: 277.466 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 70/1194 | Loss: 292.155 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 80/1194 | Loss: 288.171 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 90/1194 | Loss: 298.331 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 100/1194 | Loss: 300.435 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 110/1194 | Loss: 290.809 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 120/1194 | Loss: 291.737 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 130/1194 | Loss: 300.725 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 140/1194 | Loss: 295.211 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 150/1194 | Loss: 293.259 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 160/1194 | Loss: 307.337 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 170/1194 | Loss: 284.088 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 180/1194 | Loss: 304.773 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 190/1194 | Loss: 301.677 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 200/1194 | Loss: 293.328 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 210/1194 | Loss: 309.481 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 220/1194 | Loss: 296.405 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 230/1194 | Loss: 288.367 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 240/1194 | Loss: 306.598 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 250/1194 | Loss: 322.942 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 260/1194 | Loss: 308.900 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 270/1194 | Loss: 292.698 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 280/1194 | Loss: 302.551 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 290/1194 | Loss: 296.576 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 300/1194 | Loss: 290.553 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 310/1194 | Loss: 297.542 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 320/1194 | Loss: 296.486 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 330/1194 | Loss: 337.714 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 340/1194 | Loss: 285.148 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 350/1194 | Loss: 292.535 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 360/1194 | Loss: 306.368 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 370/1194 | Loss: 310.917 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 380/1194 | Loss: 293.962 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 390/1194 | Loss: 295.397 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 400/1194 | Loss: 285.980 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 410/1194 | Loss: 284.006 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 420/1194 | Loss: 309.239 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 430/1194 | Loss: 293.533 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 440/1194 | Loss: 304.862 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 450/1194 | Loss: 291.707 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 460/1194 | Loss: 301.484 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 470/1194 | Loss: 300.763 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 480/1194 | Loss: 290.159 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 490/1194 | Loss: 291.218 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 500/1194 | Loss: 294.308 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 510/1194 | Loss: 301.410 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 520/1194 | Loss: 298.108 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 530/1194 | Loss: 306.210 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 540/1194 | Loss: 292.419 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 550/1194 | Loss: 281.636 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 560/1194 | Loss: 298.387 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 570/1194 | Loss: 299.297 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 580/1194 | Loss: 294.012 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 590/1194 | Loss: 306.165 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 600/1194 | Loss: 316.141 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 610/1194 | Loss: 309.036 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 620/1194 | Loss: 326.169 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 630/1194 | Loss: 294.814 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 640/1194 | Loss: 301.176 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 650/1194 | Loss: 291.922 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 660/1194 | Loss: 281.876 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 670/1194 | Loss: 305.462 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 680/1194 | Loss: 298.786 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 690/1194 | Loss: 299.115 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 700/1194 | Loss: 294.816 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 710/1194 | Loss: 332.898 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 720/1194 | Loss: 287.445 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 730/1194 | Loss: 290.270 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 740/1194 | Loss: 300.478 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 750/1194 | Loss: 289.863 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 760/1194 | Loss: 296.645 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 770/1194 | Loss: 298.578 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 780/1194 | Loss: 302.573 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 790/1194 | Loss: 306.440 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 800/1194 | Loss: 286.190 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 810/1194 | Loss: 293.854 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 820/1194 | Loss: 278.816 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 830/1194 | Loss: 291.978 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 840/1194 | Loss: 289.813 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 850/1194 | Loss: 274.443 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 860/1194 | Loss: 300.070 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 870/1194 | Loss: 285.005 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 880/1194 | Loss: 279.017 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 890/1194 | Loss: 318.430 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 900/1194 | Loss: 299.382 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 910/1194 | Loss: 292.803 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 920/1194 | Loss: 289.696 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 930/1194 | Loss: 310.348 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 940/1194 | Loss: 281.183 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 950/1194 | Loss: 285.443 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 960/1194 | Loss: 295.343 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 970/1194 | Loss: 277.366 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 980/1194 | Loss: 296.239 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 990/1194 | Loss: 309.997 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1000/1194 | Loss: 280.944 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 1010/1194 | Loss: 294.442 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1020/1194 | Loss: 301.987 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1030/1194 | Loss: 299.551 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1040/1194 | Loss: 287.731 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 1050/1194 | Loss: 315.608 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1060/1194 | Loss: 293.696 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1070/1194 | Loss: 270.257 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 1080/1194 | Loss: 306.865 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1090/1194 | Loss: 306.698 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1100/1194 | Loss: 278.544 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 1110/1194 | Loss: 301.138 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1120/1194 | Loss: 300.220 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1130/1194 | Loss: 307.620 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1140/1194 | Loss: 286.394 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1150/1194 | Loss: 312.744 | Accuracy: 0.000\n",
      "[Epoch: 152/200] - Step: 1160/1194 | Loss: 295.031 | Accuracy: 0.100\n",
      "[Epoch: 152/200] - Step: 1170/1194 | Loss: 285.699 | Accuracy: 0.200\n",
      "[Epoch: 152/200] - Step: 1180/1194 | Loss: 287.353 | Accuracy: 0.300\n",
      "[Epoch: 152/200] - Step: 1190/1194 | Loss: 301.211 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 153/200] - Step: 10/1194 | Loss: 291.248 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 20/1194 | Loss: 283.723 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 30/1194 | Loss: 285.674 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 40/1194 | Loss: 304.335 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 50/1194 | Loss: 299.090 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 60/1194 | Loss: 331.898 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 70/1194 | Loss: 313.226 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 80/1194 | Loss: 289.932 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 90/1194 | Loss: 283.386 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 100/1194 | Loss: 296.060 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 110/1194 | Loss: 299.851 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 120/1194 | Loss: 294.099 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 130/1194 | Loss: 300.578 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 140/1194 | Loss: 287.464 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 150/1194 | Loss: 314.856 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 160/1194 | Loss: 300.239 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 170/1194 | Loss: 294.826 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 180/1194 | Loss: 320.112 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 190/1194 | Loss: 270.276 | Accuracy: 0.400\n",
      "[Epoch: 153/200] - Step: 200/1194 | Loss: 309.853 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 210/1194 | Loss: 277.019 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 220/1194 | Loss: 313.514 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 230/1194 | Loss: 290.882 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 240/1194 | Loss: 314.259 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 250/1194 | Loss: 306.847 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 260/1194 | Loss: 282.019 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 270/1194 | Loss: 292.550 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 280/1194 | Loss: 306.101 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 290/1194 | Loss: 287.487 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 300/1194 | Loss: 309.814 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 310/1194 | Loss: 305.039 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 320/1194 | Loss: 302.822 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 330/1194 | Loss: 300.094 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 340/1194 | Loss: 304.338 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 350/1194 | Loss: 282.044 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 360/1194 | Loss: 275.691 | Accuracy: 0.400\n",
      "[Epoch: 153/200] - Step: 370/1194 | Loss: 299.702 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 380/1194 | Loss: 293.501 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 390/1194 | Loss: 300.681 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 400/1194 | Loss: 298.842 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 410/1194 | Loss: 282.793 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 420/1194 | Loss: 289.810 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 430/1194 | Loss: 304.326 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 440/1194 | Loss: 279.205 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 450/1194 | Loss: 298.528 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 460/1194 | Loss: 294.400 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 470/1194 | Loss: 292.022 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 480/1194 | Loss: 299.291 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 490/1194 | Loss: 294.566 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 500/1194 | Loss: 309.836 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 510/1194 | Loss: 288.766 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 520/1194 | Loss: 285.941 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 530/1194 | Loss: 297.502 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 540/1194 | Loss: 291.689 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 550/1194 | Loss: 317.747 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 560/1194 | Loss: 295.760 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 570/1194 | Loss: 300.022 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 580/1194 | Loss: 288.890 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 590/1194 | Loss: 286.922 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 600/1194 | Loss: 295.363 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 610/1194 | Loss: 309.490 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 620/1194 | Loss: 291.688 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 630/1194 | Loss: 304.693 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 640/1194 | Loss: 291.842 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 650/1194 | Loss: 301.843 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 660/1194 | Loss: 270.510 | Accuracy: 0.400\n",
      "[Epoch: 153/200] - Step: 670/1194 | Loss: 313.069 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 680/1194 | Loss: 307.404 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 690/1194 | Loss: 296.107 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 700/1194 | Loss: 306.322 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 710/1194 | Loss: 278.354 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 720/1194 | Loss: 291.183 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 730/1194 | Loss: 289.112 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 740/1194 | Loss: 288.491 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 750/1194 | Loss: 291.923 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 760/1194 | Loss: 303.451 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 770/1194 | Loss: 302.759 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 780/1194 | Loss: 288.705 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 790/1194 | Loss: 283.723 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 800/1194 | Loss: 271.780 | Accuracy: 0.400\n",
      "[Epoch: 153/200] - Step: 810/1194 | Loss: 288.716 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 820/1194 | Loss: 296.120 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 830/1194 | Loss: 290.012 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 840/1194 | Loss: 303.833 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 850/1194 | Loss: 336.874 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 860/1194 | Loss: 297.044 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 870/1194 | Loss: 300.025 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 880/1194 | Loss: 295.391 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 890/1194 | Loss: 300.295 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 900/1194 | Loss: 300.326 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 910/1194 | Loss: 304.411 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 920/1194 | Loss: 295.974 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 930/1194 | Loss: 297.010 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 940/1194 | Loss: 306.672 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 950/1194 | Loss: 276.278 | Accuracy: 0.400\n",
      "[Epoch: 153/200] - Step: 960/1194 | Loss: 291.122 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 970/1194 | Loss: 297.080 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 980/1194 | Loss: 292.030 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 990/1194 | Loss: 280.147 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 1000/1194 | Loss: 306.204 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1010/1194 | Loss: 286.479 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 1020/1194 | Loss: 306.813 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1030/1194 | Loss: 310.382 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1040/1194 | Loss: 300.482 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1050/1194 | Loss: 308.197 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1060/1194 | Loss: 293.431 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 1070/1194 | Loss: 309.178 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1080/1194 | Loss: 317.822 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1090/1194 | Loss: 291.138 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 1100/1194 | Loss: 281.506 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 1110/1194 | Loss: 292.379 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 1120/1194 | Loss: 299.297 | Accuracy: 0.100\n",
      "[Epoch: 153/200] - Step: 1130/1194 | Loss: 305.786 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1140/1194 | Loss: 312.108 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1150/1194 | Loss: 316.358 | Accuracy: 0.000\n",
      "[Epoch: 153/200] - Step: 1160/1194 | Loss: 268.624 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 1170/1194 | Loss: 313.843 | Accuracy: 0.300\n",
      "[Epoch: 153/200] - Step: 1180/1194 | Loss: 286.121 | Accuracy: 0.200\n",
      "[Epoch: 153/200] - Step: 1190/1194 | Loss: 290.789 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 154/200] - Step: 10/1194 | Loss: 294.417 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 20/1194 | Loss: 302.923 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 30/1194 | Loss: 290.417 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 40/1194 | Loss: 303.932 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 50/1194 | Loss: 299.690 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 60/1194 | Loss: 297.402 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 70/1194 | Loss: 270.774 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 80/1194 | Loss: 295.695 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 90/1194 | Loss: 301.992 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 100/1194 | Loss: 294.859 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 110/1194 | Loss: 305.298 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 120/1194 | Loss: 307.952 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 130/1194 | Loss: 296.785 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 140/1194 | Loss: 323.929 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 150/1194 | Loss: 303.460 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 160/1194 | Loss: 314.721 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 170/1194 | Loss: 298.184 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 180/1194 | Loss: 296.605 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 190/1194 | Loss: 303.859 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 200/1194 | Loss: 288.071 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 210/1194 | Loss: 305.564 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 220/1194 | Loss: 298.468 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 230/1194 | Loss: 288.435 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 240/1194 | Loss: 305.558 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 250/1194 | Loss: 295.734 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 260/1194 | Loss: 320.814 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 270/1194 | Loss: 307.444 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 280/1194 | Loss: 299.979 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 290/1194 | Loss: 312.505 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 300/1194 | Loss: 285.937 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 310/1194 | Loss: 297.295 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 320/1194 | Loss: 292.057 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 330/1194 | Loss: 297.366 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 340/1194 | Loss: 294.722 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 350/1194 | Loss: 294.641 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 360/1194 | Loss: 298.441 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 370/1194 | Loss: 308.533 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 380/1194 | Loss: 289.304 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 390/1194 | Loss: 285.100 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 400/1194 | Loss: 287.350 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 410/1194 | Loss: 320.555 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 420/1194 | Loss: 285.303 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 430/1194 | Loss: 309.242 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 440/1194 | Loss: 284.692 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 450/1194 | Loss: 282.463 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 460/1194 | Loss: 306.868 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 470/1194 | Loss: 313.559 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 480/1194 | Loss: 308.692 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 490/1194 | Loss: 324.546 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 500/1194 | Loss: 309.295 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 510/1194 | Loss: 279.460 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 520/1194 | Loss: 268.589 | Accuracy: 0.400\n",
      "[Epoch: 154/200] - Step: 530/1194 | Loss: 279.098 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 540/1194 | Loss: 293.729 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 550/1194 | Loss: 292.623 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 560/1194 | Loss: 292.060 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 570/1194 | Loss: 286.820 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 580/1194 | Loss: 258.576 | Accuracy: 0.500\n",
      "[Epoch: 154/200] - Step: 590/1194 | Loss: 294.073 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 600/1194 | Loss: 305.534 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 610/1194 | Loss: 298.506 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 620/1194 | Loss: 299.966 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 630/1194 | Loss: 294.410 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 640/1194 | Loss: 297.151 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 650/1194 | Loss: 328.558 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 660/1194 | Loss: 304.659 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 670/1194 | Loss: 300.764 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 680/1194 | Loss: 301.878 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 690/1194 | Loss: 301.007 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 700/1194 | Loss: 289.053 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 710/1194 | Loss: 312.749 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 720/1194 | Loss: 289.930 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 730/1194 | Loss: 293.195 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 740/1194 | Loss: 299.881 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 750/1194 | Loss: 285.820 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 760/1194 | Loss: 278.943 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 770/1194 | Loss: 283.185 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 780/1194 | Loss: 282.308 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 790/1194 | Loss: 289.519 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 800/1194 | Loss: 302.405 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 810/1194 | Loss: 285.230 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 820/1194 | Loss: 294.210 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 830/1194 | Loss: 300.432 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 840/1194 | Loss: 293.608 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 850/1194 | Loss: 285.952 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 860/1194 | Loss: 310.019 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 870/1194 | Loss: 304.734 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 880/1194 | Loss: 302.563 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 890/1194 | Loss: 298.840 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 900/1194 | Loss: 296.825 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 910/1194 | Loss: 300.067 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 920/1194 | Loss: 297.537 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 930/1194 | Loss: 279.573 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 940/1194 | Loss: 312.894 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 950/1194 | Loss: 269.063 | Accuracy: 0.400\n",
      "[Epoch: 154/200] - Step: 960/1194 | Loss: 307.642 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 970/1194 | Loss: 283.032 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 980/1194 | Loss: 328.730 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 990/1194 | Loss: 294.556 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1000/1194 | Loss: 279.150 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 1010/1194 | Loss: 294.117 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1020/1194 | Loss: 287.245 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 1030/1194 | Loss: 288.633 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1040/1194 | Loss: 284.891 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 1050/1194 | Loss: 307.921 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 1060/1194 | Loss: 301.161 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1070/1194 | Loss: 297.792 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1080/1194 | Loss: 275.680 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 1090/1194 | Loss: 308.211 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 1100/1194 | Loss: 294.952 | Accuracy: 0.200\n",
      "[Epoch: 154/200] - Step: 1110/1194 | Loss: 300.549 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 1120/1194 | Loss: 287.190 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1130/1194 | Loss: 296.579 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1140/1194 | Loss: 304.331 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 1150/1194 | Loss: 317.371 | Accuracy: 0.000\n",
      "[Epoch: 154/200] - Step: 1160/1194 | Loss: 276.799 | Accuracy: 0.300\n",
      "[Epoch: 154/200] - Step: 1170/1194 | Loss: 296.590 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1180/1194 | Loss: 294.163 | Accuracy: 0.100\n",
      "[Epoch: 154/200] - Step: 1190/1194 | Loss: 303.445 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 155/200] - Step: 10/1194 | Loss: 305.276 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 20/1194 | Loss: 297.364 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 30/1194 | Loss: 292.357 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 40/1194 | Loss: 277.498 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 50/1194 | Loss: 287.238 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 60/1194 | Loss: 289.684 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 70/1194 | Loss: 312.308 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 80/1194 | Loss: 280.999 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 90/1194 | Loss: 279.715 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 100/1194 | Loss: 287.968 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 110/1194 | Loss: 306.408 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 120/1194 | Loss: 298.788 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 130/1194 | Loss: 295.046 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 140/1194 | Loss: 285.599 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 150/1194 | Loss: 292.930 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 160/1194 | Loss: 317.342 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 170/1194 | Loss: 325.400 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 180/1194 | Loss: 312.486 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 190/1194 | Loss: 293.477 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 200/1194 | Loss: 300.623 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 210/1194 | Loss: 296.276 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 220/1194 | Loss: 276.645 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 230/1194 | Loss: 289.254 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 240/1194 | Loss: 278.230 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 250/1194 | Loss: 271.154 | Accuracy: 0.400\n",
      "[Epoch: 155/200] - Step: 260/1194 | Loss: 303.415 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 270/1194 | Loss: 289.822 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 280/1194 | Loss: 308.593 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 290/1194 | Loss: 288.055 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 300/1194 | Loss: 281.837 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 310/1194 | Loss: 308.469 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 320/1194 | Loss: 317.221 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 330/1194 | Loss: 310.508 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 340/1194 | Loss: 301.313 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 350/1194 | Loss: 303.217 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 360/1194 | Loss: 303.391 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 370/1194 | Loss: 302.410 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 380/1194 | Loss: 288.588 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 390/1194 | Loss: 295.593 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 400/1194 | Loss: 295.940 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 410/1194 | Loss: 284.178 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 420/1194 | Loss: 295.227 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 430/1194 | Loss: 294.699 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 440/1194 | Loss: 283.234 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 450/1194 | Loss: 318.602 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 460/1194 | Loss: 325.271 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 470/1194 | Loss: 304.408 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 480/1194 | Loss: 292.233 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 490/1194 | Loss: 298.632 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 500/1194 | Loss: 315.973 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 510/1194 | Loss: 295.030 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 520/1194 | Loss: 292.429 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 530/1194 | Loss: 288.487 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 540/1194 | Loss: 291.975 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 550/1194 | Loss: 291.156 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 560/1194 | Loss: 297.359 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 570/1194 | Loss: 282.125 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 580/1194 | Loss: 284.793 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 590/1194 | Loss: 292.256 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 600/1194 | Loss: 267.352 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 610/1194 | Loss: 300.457 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 620/1194 | Loss: 317.222 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 630/1194 | Loss: 301.135 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 640/1194 | Loss: 298.489 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 650/1194 | Loss: 298.668 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 660/1194 | Loss: 307.371 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 670/1194 | Loss: 289.628 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 680/1194 | Loss: 306.025 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 690/1194 | Loss: 299.123 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 700/1194 | Loss: 291.149 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 710/1194 | Loss: 310.359 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 720/1194 | Loss: 306.935 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 730/1194 | Loss: 296.112 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 740/1194 | Loss: 287.851 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 750/1194 | Loss: 299.417 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 760/1194 | Loss: 294.697 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 770/1194 | Loss: 300.320 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 780/1194 | Loss: 296.275 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 790/1194 | Loss: 279.000 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 800/1194 | Loss: 304.676 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 810/1194 | Loss: 306.458 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 820/1194 | Loss: 305.595 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 830/1194 | Loss: 284.183 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 840/1194 | Loss: 304.664 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 850/1194 | Loss: 275.018 | Accuracy: 0.400\n",
      "[Epoch: 155/200] - Step: 860/1194 | Loss: 299.070 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 870/1194 | Loss: 301.310 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 880/1194 | Loss: 283.402 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 890/1194 | Loss: 300.149 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 900/1194 | Loss: 285.400 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 910/1194 | Loss: 301.520 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 920/1194 | Loss: 327.126 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 930/1194 | Loss: 298.557 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 940/1194 | Loss: 306.785 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 950/1194 | Loss: 307.478 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 960/1194 | Loss: 288.818 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 970/1194 | Loss: 284.569 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 980/1194 | Loss: 296.743 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 990/1194 | Loss: 298.374 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1000/1194 | Loss: 299.217 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1010/1194 | Loss: 308.913 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1020/1194 | Loss: 271.852 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 1030/1194 | Loss: 306.749 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1040/1194 | Loss: 299.426 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 1050/1194 | Loss: 301.346 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1060/1194 | Loss: 288.371 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 1070/1194 | Loss: 298.120 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1080/1194 | Loss: 286.748 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1090/1194 | Loss: 289.912 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 1100/1194 | Loss: 325.856 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1110/1194 | Loss: 302.750 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1120/1194 | Loss: 287.318 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1130/1194 | Loss: 306.858 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1140/1194 | Loss: 311.487 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1150/1194 | Loss: 326.966 | Accuracy: 0.000\n",
      "[Epoch: 155/200] - Step: 1160/1194 | Loss: 290.817 | Accuracy: 0.100\n",
      "[Epoch: 155/200] - Step: 1170/1194 | Loss: 294.597 | Accuracy: 0.200\n",
      "[Epoch: 155/200] - Step: 1180/1194 | Loss: 272.404 | Accuracy: 0.300\n",
      "[Epoch: 155/200] - Step: 1190/1194 | Loss: 286.888 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 156/200] - Step: 10/1194 | Loss: 312.091 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 20/1194 | Loss: 271.378 | Accuracy: 0.400\n",
      "[Epoch: 156/200] - Step: 30/1194 | Loss: 305.854 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 40/1194 | Loss: 320.633 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 50/1194 | Loss: 305.446 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 60/1194 | Loss: 306.940 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 70/1194 | Loss: 291.806 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 80/1194 | Loss: 307.530 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 90/1194 | Loss: 279.233 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 100/1194 | Loss: 297.483 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 110/1194 | Loss: 275.564 | Accuracy: 0.400\n",
      "[Epoch: 156/200] - Step: 120/1194 | Loss: 314.612 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 130/1194 | Loss: 282.086 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 140/1194 | Loss: 289.722 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 150/1194 | Loss: 281.242 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 160/1194 | Loss: 300.586 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 170/1194 | Loss: 302.058 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 180/1194 | Loss: 300.492 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 190/1194 | Loss: 275.367 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 200/1194 | Loss: 286.860 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 210/1194 | Loss: 305.093 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 220/1194 | Loss: 297.108 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 230/1194 | Loss: 327.215 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 240/1194 | Loss: 306.248 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 250/1194 | Loss: 289.151 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 260/1194 | Loss: 327.520 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 270/1194 | Loss: 291.973 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 280/1194 | Loss: 286.481 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 290/1194 | Loss: 301.616 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 300/1194 | Loss: 307.661 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 310/1194 | Loss: 296.431 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 320/1194 | Loss: 310.721 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 330/1194 | Loss: 316.905 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 340/1194 | Loss: 304.329 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 350/1194 | Loss: 293.266 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 360/1194 | Loss: 306.944 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 370/1194 | Loss: 303.019 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 380/1194 | Loss: 300.783 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 390/1194 | Loss: 289.372 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 400/1194 | Loss: 296.647 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 410/1194 | Loss: 299.689 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 420/1194 | Loss: 282.543 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 430/1194 | Loss: 292.833 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 440/1194 | Loss: 279.495 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 450/1194 | Loss: 322.144 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 460/1194 | Loss: 294.248 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 470/1194 | Loss: 291.462 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 480/1194 | Loss: 289.970 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 490/1194 | Loss: 298.358 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 500/1194 | Loss: 285.758 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 510/1194 | Loss: 296.606 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 520/1194 | Loss: 307.512 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 530/1194 | Loss: 300.613 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 540/1194 | Loss: 293.397 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 550/1194 | Loss: 285.854 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 560/1194 | Loss: 277.834 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 570/1194 | Loss: 297.155 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 580/1194 | Loss: 296.832 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 590/1194 | Loss: 295.220 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 600/1194 | Loss: 288.520 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 610/1194 | Loss: 284.903 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 620/1194 | Loss: 279.078 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 630/1194 | Loss: 297.334 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 640/1194 | Loss: 296.335 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 650/1194 | Loss: 287.628 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 660/1194 | Loss: 274.220 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 670/1194 | Loss: 298.852 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 680/1194 | Loss: 300.883 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 690/1194 | Loss: 295.813 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 700/1194 | Loss: 310.125 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 710/1194 | Loss: 342.277 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 720/1194 | Loss: 289.208 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 730/1194 | Loss: 299.122 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 740/1194 | Loss: 293.306 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 750/1194 | Loss: 322.919 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 760/1194 | Loss: 302.472 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 770/1194 | Loss: 297.018 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 780/1194 | Loss: 296.225 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 790/1194 | Loss: 312.238 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 800/1194 | Loss: 307.400 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 810/1194 | Loss: 305.799 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 820/1194 | Loss: 285.662 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 830/1194 | Loss: 288.671 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 840/1194 | Loss: 288.631 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 850/1194 | Loss: 305.971 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 860/1194 | Loss: 307.844 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 870/1194 | Loss: 295.709 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 880/1194 | Loss: 289.104 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 890/1194 | Loss: 283.937 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 900/1194 | Loss: 304.092 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 910/1194 | Loss: 287.578 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 920/1194 | Loss: 294.083 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 930/1194 | Loss: 300.840 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 940/1194 | Loss: 301.262 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 950/1194 | Loss: 301.114 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 960/1194 | Loss: 302.951 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 970/1194 | Loss: 298.298 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 980/1194 | Loss: 288.830 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 990/1194 | Loss: 297.309 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1000/1194 | Loss: 284.084 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1010/1194 | Loss: 286.798 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1020/1194 | Loss: 298.734 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1030/1194 | Loss: 302.128 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1040/1194 | Loss: 290.738 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1050/1194 | Loss: 304.150 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 1060/1194 | Loss: 287.644 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1070/1194 | Loss: 298.732 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1080/1194 | Loss: 273.854 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 1090/1194 | Loss: 271.266 | Accuracy: 0.300\n",
      "[Epoch: 156/200] - Step: 1100/1194 | Loss: 282.246 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1110/1194 | Loss: 285.686 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1120/1194 | Loss: 312.926 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1130/1194 | Loss: 296.561 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1140/1194 | Loss: 307.974 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1150/1194 | Loss: 289.249 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1160/1194 | Loss: 305.069 | Accuracy: 0.100\n",
      "[Epoch: 156/200] - Step: 1170/1194 | Loss: 308.947 | Accuracy: 0.000\n",
      "[Epoch: 156/200] - Step: 1180/1194 | Loss: 288.525 | Accuracy: 0.200\n",
      "[Epoch: 156/200] - Step: 1190/1194 | Loss: 308.168 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 157/200] - Step: 10/1194 | Loss: 300.747 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 20/1194 | Loss: 301.217 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 30/1194 | Loss: 286.403 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 40/1194 | Loss: 302.308 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 50/1194 | Loss: 294.937 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 60/1194 | Loss: 337.047 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 70/1194 | Loss: 292.709 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 80/1194 | Loss: 294.995 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 90/1194 | Loss: 301.876 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 100/1194 | Loss: 277.914 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 110/1194 | Loss: 284.456 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 120/1194 | Loss: 307.260 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 130/1194 | Loss: 281.394 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 140/1194 | Loss: 302.853 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 150/1194 | Loss: 290.752 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 160/1194 | Loss: 301.388 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 170/1194 | Loss: 301.103 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 180/1194 | Loss: 291.605 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 190/1194 | Loss: 285.008 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 200/1194 | Loss: 298.554 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 210/1194 | Loss: 303.519 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 220/1194 | Loss: 287.428 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 230/1194 | Loss: 338.951 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 240/1194 | Loss: 304.050 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 250/1194 | Loss: 299.149 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 260/1194 | Loss: 287.167 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 270/1194 | Loss: 289.493 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 280/1194 | Loss: 300.717 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 290/1194 | Loss: 305.662 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 300/1194 | Loss: 301.935 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 310/1194 | Loss: 301.140 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 320/1194 | Loss: 291.919 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 330/1194 | Loss: 300.328 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 340/1194 | Loss: 315.896 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 350/1194 | Loss: 274.438 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 360/1194 | Loss: 292.044 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 370/1194 | Loss: 305.383 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 380/1194 | Loss: 277.076 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 390/1194 | Loss: 306.009 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 400/1194 | Loss: 294.839 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 410/1194 | Loss: 299.907 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 420/1194 | Loss: 311.755 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 430/1194 | Loss: 297.908 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 440/1194 | Loss: 325.174 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 450/1194 | Loss: 282.952 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 460/1194 | Loss: 290.713 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 470/1194 | Loss: 281.052 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 480/1194 | Loss: 304.209 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 490/1194 | Loss: 291.066 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 500/1194 | Loss: 286.730 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 510/1194 | Loss: 313.594 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 520/1194 | Loss: 294.766 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 530/1194 | Loss: 287.961 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 540/1194 | Loss: 307.876 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 550/1194 | Loss: 308.294 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 560/1194 | Loss: 297.833 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 570/1194 | Loss: 271.888 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 580/1194 | Loss: 295.265 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 590/1194 | Loss: 298.716 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 600/1194 | Loss: 272.290 | Accuracy: 0.400\n",
      "[Epoch: 157/200] - Step: 610/1194 | Loss: 285.955 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 620/1194 | Loss: 299.985 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 630/1194 | Loss: 286.438 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 640/1194 | Loss: 284.575 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 650/1194 | Loss: 311.142 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 660/1194 | Loss: 308.568 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 670/1194 | Loss: 303.214 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 680/1194 | Loss: 303.695 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 690/1194 | Loss: 290.715 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 700/1194 | Loss: 298.983 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 710/1194 | Loss: 297.875 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 720/1194 | Loss: 290.947 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 730/1194 | Loss: 286.036 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 740/1194 | Loss: 295.886 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 750/1194 | Loss: 300.419 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 760/1194 | Loss: 297.045 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 770/1194 | Loss: 283.731 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 780/1194 | Loss: 291.170 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 790/1194 | Loss: 288.234 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 800/1194 | Loss: 300.139 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 810/1194 | Loss: 302.078 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 820/1194 | Loss: 306.358 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 830/1194 | Loss: 302.589 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 840/1194 | Loss: 284.555 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 850/1194 | Loss: 304.108 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 860/1194 | Loss: 281.815 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 870/1194 | Loss: 298.254 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 880/1194 | Loss: 291.393 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 890/1194 | Loss: 290.500 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 900/1194 | Loss: 298.766 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 910/1194 | Loss: 295.883 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 920/1194 | Loss: 283.486 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 930/1194 | Loss: 307.436 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 940/1194 | Loss: 288.159 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 950/1194 | Loss: 290.584 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 960/1194 | Loss: 297.766 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 970/1194 | Loss: 309.047 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 980/1194 | Loss: 304.423 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 990/1194 | Loss: 289.319 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1000/1194 | Loss: 311.837 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1010/1194 | Loss: 317.307 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 1020/1194 | Loss: 288.128 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 1030/1194 | Loss: 274.983 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 1040/1194 | Loss: 275.161 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 1050/1194 | Loss: 282.770 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 1060/1194 | Loss: 300.691 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 1070/1194 | Loss: 296.752 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1080/1194 | Loss: 291.189 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1090/1194 | Loss: 293.437 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1100/1194 | Loss: 313.655 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 1110/1194 | Loss: 326.685 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 1120/1194 | Loss: 277.664 | Accuracy: 0.300\n",
      "[Epoch: 157/200] - Step: 1130/1194 | Loss: 307.668 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 1140/1194 | Loss: 307.497 | Accuracy: 0.000\n",
      "[Epoch: 157/200] - Step: 1150/1194 | Loss: 288.588 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 1160/1194 | Loss: 286.283 | Accuracy: 0.200\n",
      "[Epoch: 157/200] - Step: 1170/1194 | Loss: 301.177 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 1180/1194 | Loss: 315.971 | Accuracy: 0.100\n",
      "[Epoch: 157/200] - Step: 1190/1194 | Loss: 307.055 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 158/200] - Step: 10/1194 | Loss: 299.705 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 20/1194 | Loss: 305.928 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 30/1194 | Loss: 280.180 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 40/1194 | Loss: 303.453 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 50/1194 | Loss: 304.933 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 60/1194 | Loss: 295.902 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 70/1194 | Loss: 291.555 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 80/1194 | Loss: 292.058 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 90/1194 | Loss: 302.936 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 100/1194 | Loss: 283.313 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 110/1194 | Loss: 304.268 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 120/1194 | Loss: 298.357 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 130/1194 | Loss: 304.823 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 140/1194 | Loss: 296.939 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 150/1194 | Loss: 301.466 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 160/1194 | Loss: 290.110 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 170/1194 | Loss: 291.964 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 180/1194 | Loss: 293.524 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 190/1194 | Loss: 307.706 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 200/1194 | Loss: 276.773 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 210/1194 | Loss: 287.565 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 220/1194 | Loss: 314.393 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 230/1194 | Loss: 293.953 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 240/1194 | Loss: 279.154 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 250/1194 | Loss: 295.193 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 260/1194 | Loss: 303.787 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 270/1194 | Loss: 305.288 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 280/1194 | Loss: 304.826 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 290/1194 | Loss: 313.154 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 300/1194 | Loss: 291.946 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 310/1194 | Loss: 281.434 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 320/1194 | Loss: 312.921 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 330/1194 | Loss: 297.793 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 340/1194 | Loss: 305.385 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 350/1194 | Loss: 290.566 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 360/1194 | Loss: 279.298 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 370/1194 | Loss: 281.445 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 380/1194 | Loss: 275.371 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 390/1194 | Loss: 301.966 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 400/1194 | Loss: 300.869 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 410/1194 | Loss: 304.263 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 420/1194 | Loss: 290.752 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 430/1194 | Loss: 300.004 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 440/1194 | Loss: 276.113 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 450/1194 | Loss: 325.095 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 460/1194 | Loss: 286.045 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 470/1194 | Loss: 295.252 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 480/1194 | Loss: 288.260 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 490/1194 | Loss: 313.419 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 500/1194 | Loss: 303.566 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 510/1194 | Loss: 312.940 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 520/1194 | Loss: 296.683 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 530/1194 | Loss: 290.819 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 540/1194 | Loss: 290.178 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 550/1194 | Loss: 289.204 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 560/1194 | Loss: 291.226 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 570/1194 | Loss: 302.201 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 580/1194 | Loss: 304.843 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 590/1194 | Loss: 293.215 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 600/1194 | Loss: 289.039 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 610/1194 | Loss: 301.099 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 620/1194 | Loss: 296.465 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 630/1194 | Loss: 288.033 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 640/1194 | Loss: 301.590 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 650/1194 | Loss: 297.210 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 660/1194 | Loss: 308.638 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 670/1194 | Loss: 298.488 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 680/1194 | Loss: 305.925 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 690/1194 | Loss: 294.595 | Accuracy: 0.400\n",
      "[Epoch: 158/200] - Step: 700/1194 | Loss: 273.944 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 710/1194 | Loss: 316.168 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 720/1194 | Loss: 286.032 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 730/1194 | Loss: 290.530 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 740/1194 | Loss: 321.029 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 750/1194 | Loss: 288.124 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 760/1194 | Loss: 275.586 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 770/1194 | Loss: 295.970 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 780/1194 | Loss: 304.759 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 790/1194 | Loss: 279.363 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 800/1194 | Loss: 308.463 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 810/1194 | Loss: 280.966 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 820/1194 | Loss: 295.619 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 830/1194 | Loss: 297.938 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 840/1194 | Loss: 282.383 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 850/1194 | Loss: 329.535 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 860/1194 | Loss: 297.893 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 870/1194 | Loss: 303.819 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 880/1194 | Loss: 294.476 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 890/1194 | Loss: 279.319 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 900/1194 | Loss: 286.692 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 910/1194 | Loss: 292.630 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 920/1194 | Loss: 287.471 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 930/1194 | Loss: 285.449 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 940/1194 | Loss: 286.668 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 950/1194 | Loss: 319.929 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 960/1194 | Loss: 284.530 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 970/1194 | Loss: 298.359 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 980/1194 | Loss: 290.052 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 990/1194 | Loss: 306.378 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1000/1194 | Loss: 288.032 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1010/1194 | Loss: 348.295 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1020/1194 | Loss: 308.456 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1030/1194 | Loss: 303.353 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1040/1194 | Loss: 299.008 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 1050/1194 | Loss: 279.902 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 1060/1194 | Loss: 287.901 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 1070/1194 | Loss: 311.411 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1080/1194 | Loss: 304.240 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1090/1194 | Loss: 278.632 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 1100/1194 | Loss: 287.347 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1110/1194 | Loss: 289.717 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1120/1194 | Loss: 304.861 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1130/1194 | Loss: 301.742 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1140/1194 | Loss: 307.605 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1150/1194 | Loss: 294.938 | Accuracy: 0.100\n",
      "[Epoch: 158/200] - Step: 1160/1194 | Loss: 315.020 | Accuracy: 0.000\n",
      "[Epoch: 158/200] - Step: 1170/1194 | Loss: 286.373 | Accuracy: 0.300\n",
      "[Epoch: 158/200] - Step: 1180/1194 | Loss: 296.250 | Accuracy: 0.200\n",
      "[Epoch: 158/200] - Step: 1190/1194 | Loss: 324.816 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 159/200] - Step: 10/1194 | Loss: 282.201 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 20/1194 | Loss: 303.034 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 30/1194 | Loss: 308.435 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 40/1194 | Loss: 293.929 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 50/1194 | Loss: 290.193 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 60/1194 | Loss: 289.086 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 70/1194 | Loss: 285.455 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 80/1194 | Loss: 298.469 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 90/1194 | Loss: 297.654 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 100/1194 | Loss: 280.185 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 110/1194 | Loss: 296.895 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 120/1194 | Loss: 298.540 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 130/1194 | Loss: 279.262 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 140/1194 | Loss: 280.021 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 150/1194 | Loss: 295.997 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 160/1194 | Loss: 302.604 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 170/1194 | Loss: 296.792 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 180/1194 | Loss: 287.884 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 190/1194 | Loss: 275.713 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 200/1194 | Loss: 307.876 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 210/1194 | Loss: 309.002 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 220/1194 | Loss: 310.957 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 230/1194 | Loss: 285.291 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 240/1194 | Loss: 285.593 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 250/1194 | Loss: 287.457 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 260/1194 | Loss: 304.020 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 270/1194 | Loss: 278.864 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 280/1194 | Loss: 278.589 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 290/1194 | Loss: 293.046 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 300/1194 | Loss: 305.528 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 310/1194 | Loss: 304.785 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 320/1194 | Loss: 287.086 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 330/1194 | Loss: 305.150 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 340/1194 | Loss: 297.114 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 350/1194 | Loss: 296.293 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 360/1194 | Loss: 289.586 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 370/1194 | Loss: 302.360 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 380/1194 | Loss: 298.673 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 390/1194 | Loss: 297.052 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 400/1194 | Loss: 292.053 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 410/1194 | Loss: 290.979 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 420/1194 | Loss: 301.708 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 430/1194 | Loss: 279.988 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 440/1194 | Loss: 286.350 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 450/1194 | Loss: 257.150 | Accuracy: 0.500\n",
      "[Epoch: 159/200] - Step: 460/1194 | Loss: 294.680 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 470/1194 | Loss: 308.160 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 480/1194 | Loss: 288.917 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 490/1194 | Loss: 295.463 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 500/1194 | Loss: 308.406 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 510/1194 | Loss: 293.244 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 520/1194 | Loss: 300.330 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 530/1194 | Loss: 291.575 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 540/1194 | Loss: 281.962 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 550/1194 | Loss: 306.874 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 560/1194 | Loss: 285.695 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 570/1194 | Loss: 265.374 | Accuracy: 0.400\n",
      "[Epoch: 159/200] - Step: 580/1194 | Loss: 310.922 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 590/1194 | Loss: 308.883 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 600/1194 | Loss: 322.386 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 610/1194 | Loss: 304.180 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 620/1194 | Loss: 304.508 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 630/1194 | Loss: 275.387 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 640/1194 | Loss: 298.305 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 650/1194 | Loss: 305.083 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 660/1194 | Loss: 275.952 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 670/1194 | Loss: 301.918 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 680/1194 | Loss: 312.476 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 690/1194 | Loss: 315.672 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 700/1194 | Loss: 341.515 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 710/1194 | Loss: 275.639 | Accuracy: 0.400\n",
      "[Epoch: 159/200] - Step: 720/1194 | Loss: 290.324 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 730/1194 | Loss: 292.287 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 740/1194 | Loss: 324.239 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 750/1194 | Loss: 311.277 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 760/1194 | Loss: 291.182 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 770/1194 | Loss: 306.785 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 780/1194 | Loss: 270.884 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 790/1194 | Loss: 295.839 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 800/1194 | Loss: 311.293 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 810/1194 | Loss: 289.442 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 820/1194 | Loss: 336.374 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 830/1194 | Loss: 274.461 | Accuracy: 0.400\n",
      "[Epoch: 159/200] - Step: 840/1194 | Loss: 296.395 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 850/1194 | Loss: 304.502 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 860/1194 | Loss: 275.217 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 870/1194 | Loss: 290.587 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 880/1194 | Loss: 293.171 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 890/1194 | Loss: 278.887 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 900/1194 | Loss: 303.654 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 910/1194 | Loss: 306.768 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 920/1194 | Loss: 289.747 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 930/1194 | Loss: 297.868 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 940/1194 | Loss: 294.445 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 950/1194 | Loss: 308.292 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 960/1194 | Loss: 280.169 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 970/1194 | Loss: 312.631 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 980/1194 | Loss: 302.266 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 990/1194 | Loss: 306.406 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1000/1194 | Loss: 280.458 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 1010/1194 | Loss: 305.089 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1020/1194 | Loss: 311.062 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1030/1194 | Loss: 274.958 | Accuracy: 0.300\n",
      "[Epoch: 159/200] - Step: 1040/1194 | Loss: 270.221 | Accuracy: 0.400\n",
      "[Epoch: 159/200] - Step: 1050/1194 | Loss: 303.416 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1060/1194 | Loss: 297.591 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1070/1194 | Loss: 314.911 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1080/1194 | Loss: 302.128 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1090/1194 | Loss: 335.736 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 1100/1194 | Loss: 295.003 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 1110/1194 | Loss: 332.955 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1120/1194 | Loss: 287.513 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 1130/1194 | Loss: 296.368 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1140/1194 | Loss: 306.880 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1150/1194 | Loss: 301.410 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 1160/1194 | Loss: 297.906 | Accuracy: 0.100\n",
      "[Epoch: 159/200] - Step: 1170/1194 | Loss: 317.504 | Accuracy: 0.200\n",
      "[Epoch: 159/200] - Step: 1180/1194 | Loss: 305.387 | Accuracy: 0.000\n",
      "[Epoch: 159/200] - Step: 1190/1194 | Loss: 310.653 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 160/200] - Step: 10/1194 | Loss: 284.594 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 20/1194 | Loss: 290.905 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 30/1194 | Loss: 300.462 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 40/1194 | Loss: 295.206 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 50/1194 | Loss: 303.605 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 60/1194 | Loss: 281.616 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 70/1194 | Loss: 291.910 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 80/1194 | Loss: 295.144 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 90/1194 | Loss: 327.656 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 100/1194 | Loss: 275.793 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 110/1194 | Loss: 306.738 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 120/1194 | Loss: 290.703 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 130/1194 | Loss: 298.180 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 140/1194 | Loss: 307.968 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 150/1194 | Loss: 294.678 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 160/1194 | Loss: 287.663 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 170/1194 | Loss: 287.166 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 180/1194 | Loss: 293.843 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 190/1194 | Loss: 298.940 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 200/1194 | Loss: 294.352 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 210/1194 | Loss: 280.133 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 220/1194 | Loss: 298.726 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 230/1194 | Loss: 310.428 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 240/1194 | Loss: 308.140 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 250/1194 | Loss: 283.799 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 260/1194 | Loss: 285.140 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 270/1194 | Loss: 291.515 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 280/1194 | Loss: 275.534 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 290/1194 | Loss: 294.754 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 300/1194 | Loss: 288.710 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 310/1194 | Loss: 296.146 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 320/1194 | Loss: 270.302 | Accuracy: 0.400\n",
      "[Epoch: 160/200] - Step: 330/1194 | Loss: 300.235 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 340/1194 | Loss: 291.484 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 350/1194 | Loss: 302.818 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 360/1194 | Loss: 311.419 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 370/1194 | Loss: 285.217 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 380/1194 | Loss: 302.817 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 390/1194 | Loss: 300.280 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 400/1194 | Loss: 281.542 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 410/1194 | Loss: 302.936 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 420/1194 | Loss: 274.245 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 430/1194 | Loss: 294.247 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 440/1194 | Loss: 296.101 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 450/1194 | Loss: 288.445 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 460/1194 | Loss: 298.669 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 470/1194 | Loss: 301.636 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 480/1194 | Loss: 299.066 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 490/1194 | Loss: 284.921 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 500/1194 | Loss: 306.702 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 510/1194 | Loss: 274.111 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 520/1194 | Loss: 297.310 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 530/1194 | Loss: 296.539 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 540/1194 | Loss: 303.831 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 550/1194 | Loss: 340.527 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 560/1194 | Loss: 307.246 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 570/1194 | Loss: 302.866 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 580/1194 | Loss: 305.619 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 590/1194 | Loss: 288.572 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 600/1194 | Loss: 291.723 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 610/1194 | Loss: 302.209 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 620/1194 | Loss: 291.275 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 630/1194 | Loss: 281.538 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 640/1194 | Loss: 303.332 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 650/1194 | Loss: 288.694 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 660/1194 | Loss: 294.458 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 670/1194 | Loss: 297.356 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 680/1194 | Loss: 332.059 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 690/1194 | Loss: 288.401 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 700/1194 | Loss: 321.471 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 710/1194 | Loss: 298.938 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 720/1194 | Loss: 313.875 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 730/1194 | Loss: 291.828 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 740/1194 | Loss: 303.595 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 750/1194 | Loss: 299.116 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 760/1194 | Loss: 307.364 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 770/1194 | Loss: 307.008 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 780/1194 | Loss: 292.984 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 790/1194 | Loss: 278.261 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 800/1194 | Loss: 302.513 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 810/1194 | Loss: 304.220 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 820/1194 | Loss: 293.553 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 830/1194 | Loss: 290.602 | Accuracy: 0.300\n",
      "[Epoch: 160/200] - Step: 840/1194 | Loss: 287.779 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 850/1194 | Loss: 283.797 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 860/1194 | Loss: 285.979 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 870/1194 | Loss: 295.397 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 880/1194 | Loss: 288.717 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 890/1194 | Loss: 311.411 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 900/1194 | Loss: 310.058 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 910/1194 | Loss: 281.282 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 920/1194 | Loss: 298.839 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 930/1194 | Loss: 302.567 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 940/1194 | Loss: 290.985 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 950/1194 | Loss: 284.903 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 960/1194 | Loss: 298.668 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 970/1194 | Loss: 296.673 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 980/1194 | Loss: 309.934 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 990/1194 | Loss: 299.587 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1000/1194 | Loss: 296.385 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1010/1194 | Loss: 295.974 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1020/1194 | Loss: 301.424 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1030/1194 | Loss: 288.752 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1040/1194 | Loss: 306.671 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1050/1194 | Loss: 303.929 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1060/1194 | Loss: 290.127 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 1070/1194 | Loss: 306.638 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1080/1194 | Loss: 338.008 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1090/1194 | Loss: 309.923 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1100/1194 | Loss: 294.651 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 1110/1194 | Loss: 300.791 | Accuracy: 0.100\n",
      "[Epoch: 160/200] - Step: 1120/1194 | Loss: 301.763 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1130/1194 | Loss: 292.412 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 1140/1194 | Loss: 309.484 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1150/1194 | Loss: 301.436 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1160/1194 | Loss: 314.953 | Accuracy: 0.200\n",
      "[Epoch: 160/200] - Step: 1170/1194 | Loss: 300.034 | Accuracy: 0.000\n",
      "[Epoch: 160/200] - Step: 1180/1194 | Loss: 274.690 | Accuracy: 0.400\n",
      "[Epoch: 160/200] - Step: 1190/1194 | Loss: 273.394 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 161/200] - Step: 10/1194 | Loss: 307.860 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 20/1194 | Loss: 283.033 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 30/1194 | Loss: 292.151 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 40/1194 | Loss: 289.629 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 50/1194 | Loss: 289.246 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 60/1194 | Loss: 284.803 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 70/1194 | Loss: 306.835 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 80/1194 | Loss: 272.120 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 90/1194 | Loss: 306.693 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 100/1194 | Loss: 307.188 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 110/1194 | Loss: 289.723 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 120/1194 | Loss: 301.025 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 130/1194 | Loss: 339.302 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 140/1194 | Loss: 283.922 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 150/1194 | Loss: 295.272 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 160/1194 | Loss: 305.748 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 170/1194 | Loss: 302.065 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 180/1194 | Loss: 292.064 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 190/1194 | Loss: 297.204 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 200/1194 | Loss: 309.829 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 210/1194 | Loss: 299.331 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 220/1194 | Loss: 284.500 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 230/1194 | Loss: 308.041 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 240/1194 | Loss: 280.355 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 250/1194 | Loss: 278.892 | Accuracy: 0.400\n",
      "[Epoch: 161/200] - Step: 260/1194 | Loss: 314.861 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 270/1194 | Loss: 300.250 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 280/1194 | Loss: 288.292 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 290/1194 | Loss: 280.237 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 300/1194 | Loss: 288.750 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 310/1194 | Loss: 308.970 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 320/1194 | Loss: 293.505 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 330/1194 | Loss: 273.227 | Accuracy: 0.400\n",
      "[Epoch: 161/200] - Step: 340/1194 | Loss: 312.281 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 350/1194 | Loss: 308.563 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 360/1194 | Loss: 299.585 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 370/1194 | Loss: 283.988 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 380/1194 | Loss: 304.512 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 390/1194 | Loss: 286.953 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 400/1194 | Loss: 290.703 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 410/1194 | Loss: 300.015 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 420/1194 | Loss: 286.073 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 430/1194 | Loss: 311.442 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 440/1194 | Loss: 291.948 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 450/1194 | Loss: 294.667 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 460/1194 | Loss: 330.939 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 470/1194 | Loss: 275.014 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 480/1194 | Loss: 308.324 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 490/1194 | Loss: 295.863 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 500/1194 | Loss: 285.972 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 510/1194 | Loss: 313.195 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 520/1194 | Loss: 288.047 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 530/1194 | Loss: 295.321 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 540/1194 | Loss: 301.066 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 550/1194 | Loss: 293.704 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 560/1194 | Loss: 302.244 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 570/1194 | Loss: 296.956 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 580/1194 | Loss: 319.793 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 590/1194 | Loss: 287.575 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 600/1194 | Loss: 305.236 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 610/1194 | Loss: 300.539 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 620/1194 | Loss: 307.567 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 630/1194 | Loss: 295.480 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 640/1194 | Loss: 306.636 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 650/1194 | Loss: 300.984 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 660/1194 | Loss: 284.762 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 670/1194 | Loss: 284.393 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 680/1194 | Loss: 299.014 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 690/1194 | Loss: 294.665 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 700/1194 | Loss: 279.804 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 710/1194 | Loss: 288.291 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 720/1194 | Loss: 290.140 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 730/1194 | Loss: 298.323 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 740/1194 | Loss: 293.394 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 750/1194 | Loss: 314.356 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 760/1194 | Loss: 291.790 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 770/1194 | Loss: 281.848 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 780/1194 | Loss: 299.768 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 790/1194 | Loss: 302.267 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 800/1194 | Loss: 327.439 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 810/1194 | Loss: 290.733 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 820/1194 | Loss: 293.928 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 830/1194 | Loss: 299.343 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 840/1194 | Loss: 299.654 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 850/1194 | Loss: 297.268 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 860/1194 | Loss: 294.938 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 870/1194 | Loss: 301.648 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 880/1194 | Loss: 296.067 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 890/1194 | Loss: 283.049 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 900/1194 | Loss: 297.415 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 910/1194 | Loss: 299.100 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 920/1194 | Loss: 311.394 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 930/1194 | Loss: 303.698 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 940/1194 | Loss: 304.782 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 950/1194 | Loss: 273.592 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 960/1194 | Loss: 270.388 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 970/1194 | Loss: 305.386 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 980/1194 | Loss: 308.966 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 990/1194 | Loss: 307.993 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 1000/1194 | Loss: 305.344 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1010/1194 | Loss: 315.540 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 1020/1194 | Loss: 284.985 | Accuracy: 0.300\n",
      "[Epoch: 161/200] - Step: 1030/1194 | Loss: 284.940 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 1040/1194 | Loss: 288.430 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1050/1194 | Loss: 288.965 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1060/1194 | Loss: 296.367 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1070/1194 | Loss: 297.841 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1080/1194 | Loss: 293.520 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1090/1194 | Loss: 304.557 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1100/1194 | Loss: 301.705 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1110/1194 | Loss: 286.621 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 1120/1194 | Loss: 298.173 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 1130/1194 | Loss: 310.911 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 1140/1194 | Loss: 286.307 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1150/1194 | Loss: 309.508 | Accuracy: 0.000\n",
      "[Epoch: 161/200] - Step: 1160/1194 | Loss: 287.530 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1170/1194 | Loss: 292.744 | Accuracy: 0.200\n",
      "[Epoch: 161/200] - Step: 1180/1194 | Loss: 285.296 | Accuracy: 0.100\n",
      "[Epoch: 161/200] - Step: 1190/1194 | Loss: 299.542 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 162/200] - Step: 10/1194 | Loss: 284.016 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 20/1194 | Loss: 285.884 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 30/1194 | Loss: 260.044 | Accuracy: 0.400\n",
      "[Epoch: 162/200] - Step: 40/1194 | Loss: 287.293 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 50/1194 | Loss: 278.259 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 60/1194 | Loss: 289.997 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 70/1194 | Loss: 306.803 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 80/1194 | Loss: 294.033 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 90/1194 | Loss: 291.617 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 100/1194 | Loss: 306.152 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 110/1194 | Loss: 303.400 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 120/1194 | Loss: 309.865 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 130/1194 | Loss: 299.984 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 140/1194 | Loss: 304.343 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 150/1194 | Loss: 286.544 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 160/1194 | Loss: 282.344 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 170/1194 | Loss: 290.878 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 180/1194 | Loss: 299.683 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 190/1194 | Loss: 296.233 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 200/1194 | Loss: 299.195 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 210/1194 | Loss: 327.202 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 220/1194 | Loss: 303.021 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 230/1194 | Loss: 286.361 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 240/1194 | Loss: 294.311 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 250/1194 | Loss: 311.535 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 260/1194 | Loss: 329.903 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 270/1194 | Loss: 298.436 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 280/1194 | Loss: 287.867 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 290/1194 | Loss: 317.229 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 300/1194 | Loss: 291.639 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 310/1194 | Loss: 283.976 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 320/1194 | Loss: 297.943 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 330/1194 | Loss: 301.777 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 340/1194 | Loss: 314.199 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 350/1194 | Loss: 308.349 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 360/1194 | Loss: 304.190 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 370/1194 | Loss: 278.050 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 380/1194 | Loss: 299.302 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 390/1194 | Loss: 287.324 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 400/1194 | Loss: 293.351 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 410/1194 | Loss: 293.547 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 420/1194 | Loss: 302.566 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 430/1194 | Loss: 307.278 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 440/1194 | Loss: 279.817 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 450/1194 | Loss: 293.505 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 460/1194 | Loss: 282.063 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 470/1194 | Loss: 289.266 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 480/1194 | Loss: 282.428 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 490/1194 | Loss: 305.778 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 500/1194 | Loss: 301.936 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 510/1194 | Loss: 288.117 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 520/1194 | Loss: 287.892 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 530/1194 | Loss: 319.017 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 540/1194 | Loss: 292.273 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 550/1194 | Loss: 299.541 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 560/1194 | Loss: 304.627 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 570/1194 | Loss: 273.297 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 580/1194 | Loss: 309.112 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 590/1194 | Loss: 307.898 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 600/1194 | Loss: 285.520 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 610/1194 | Loss: 294.348 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 620/1194 | Loss: 306.198 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 630/1194 | Loss: 294.599 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 640/1194 | Loss: 301.582 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 650/1194 | Loss: 278.968 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 660/1194 | Loss: 301.328 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 670/1194 | Loss: 311.204 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 680/1194 | Loss: 304.627 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 690/1194 | Loss: 279.536 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 700/1194 | Loss: 310.655 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 710/1194 | Loss: 299.704 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 720/1194 | Loss: 297.184 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 730/1194 | Loss: 303.028 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 740/1194 | Loss: 292.131 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 750/1194 | Loss: 302.682 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 760/1194 | Loss: 300.991 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 770/1194 | Loss: 303.062 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 780/1194 | Loss: 283.286 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 790/1194 | Loss: 304.222 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 800/1194 | Loss: 294.852 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 810/1194 | Loss: 295.330 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 820/1194 | Loss: 274.795 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 830/1194 | Loss: 297.435 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 840/1194 | Loss: 296.635 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 850/1194 | Loss: 297.848 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 860/1194 | Loss: 315.319 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 870/1194 | Loss: 293.005 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 880/1194 | Loss: 298.023 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 890/1194 | Loss: 299.066 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 900/1194 | Loss: 295.601 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 910/1194 | Loss: 293.786 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 920/1194 | Loss: 281.882 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 930/1194 | Loss: 290.342 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 940/1194 | Loss: 308.163 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 950/1194 | Loss: 309.414 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 960/1194 | Loss: 287.108 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 970/1194 | Loss: 303.682 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 980/1194 | Loss: 324.862 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 990/1194 | Loss: 269.140 | Accuracy: 0.400\n",
      "[Epoch: 162/200] - Step: 1000/1194 | Loss: 302.147 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1010/1194 | Loss: 259.055 | Accuracy: 0.500\n",
      "[Epoch: 162/200] - Step: 1020/1194 | Loss: 326.564 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1030/1194 | Loss: 310.192 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 1040/1194 | Loss: 304.450 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1050/1194 | Loss: 289.072 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 1060/1194 | Loss: 299.310 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1070/1194 | Loss: 281.846 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 1080/1194 | Loss: 305.038 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 1090/1194 | Loss: 280.073 | Accuracy: 0.300\n",
      "[Epoch: 162/200] - Step: 1100/1194 | Loss: 269.643 | Accuracy: 0.400\n",
      "[Epoch: 162/200] - Step: 1110/1194 | Loss: 299.362 | Accuracy: 0.200\n",
      "[Epoch: 162/200] - Step: 1120/1194 | Loss: 297.722 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1130/1194 | Loss: 301.791 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 1140/1194 | Loss: 299.224 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1150/1194 | Loss: 301.141 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1160/1194 | Loss: 306.898 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 1170/1194 | Loss: 288.282 | Accuracy: 0.100\n",
      "[Epoch: 162/200] - Step: 1180/1194 | Loss: 306.087 | Accuracy: 0.000\n",
      "[Epoch: 162/200] - Step: 1190/1194 | Loss: 340.847 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 163/200] - Step: 10/1194 | Loss: 299.482 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 20/1194 | Loss: 317.307 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 30/1194 | Loss: 300.146 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 40/1194 | Loss: 283.638 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 50/1194 | Loss: 300.124 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 60/1194 | Loss: 301.279 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 70/1194 | Loss: 292.019 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 80/1194 | Loss: 291.955 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 90/1194 | Loss: 301.908 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 100/1194 | Loss: 299.181 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 110/1194 | Loss: 290.870 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 120/1194 | Loss: 295.241 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 130/1194 | Loss: 302.201 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 140/1194 | Loss: 297.540 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 150/1194 | Loss: 283.339 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 160/1194 | Loss: 299.584 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 170/1194 | Loss: 295.457 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 180/1194 | Loss: 293.529 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 190/1194 | Loss: 297.797 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 200/1194 | Loss: 302.437 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 210/1194 | Loss: 302.902 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 220/1194 | Loss: 304.892 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 230/1194 | Loss: 290.385 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 240/1194 | Loss: 291.134 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 250/1194 | Loss: 295.906 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 260/1194 | Loss: 280.639 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 270/1194 | Loss: 296.647 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 280/1194 | Loss: 309.303 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 290/1194 | Loss: 344.745 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 300/1194 | Loss: 282.326 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 310/1194 | Loss: 308.230 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 320/1194 | Loss: 298.580 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 330/1194 | Loss: 294.722 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 340/1194 | Loss: 302.012 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 350/1194 | Loss: 303.389 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 360/1194 | Loss: 317.956 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 370/1194 | Loss: 290.891 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 380/1194 | Loss: 277.498 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 390/1194 | Loss: 299.033 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 400/1194 | Loss: 307.952 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 410/1194 | Loss: 278.752 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 420/1194 | Loss: 276.884 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 430/1194 | Loss: 290.648 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 440/1194 | Loss: 291.903 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 450/1194 | Loss: 287.122 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 460/1194 | Loss: 306.589 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 470/1194 | Loss: 314.717 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 480/1194 | Loss: 301.928 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 490/1194 | Loss: 302.081 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 500/1194 | Loss: 277.793 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 510/1194 | Loss: 277.384 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 520/1194 | Loss: 292.771 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 530/1194 | Loss: 342.891 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 540/1194 | Loss: 309.978 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 550/1194 | Loss: 302.655 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 560/1194 | Loss: 300.641 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 570/1194 | Loss: 284.875 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 580/1194 | Loss: 281.951 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 590/1194 | Loss: 272.775 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 600/1194 | Loss: 306.275 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 610/1194 | Loss: 298.122 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 620/1194 | Loss: 309.715 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 630/1194 | Loss: 304.155 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 640/1194 | Loss: 296.084 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 650/1194 | Loss: 282.212 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 660/1194 | Loss: 304.007 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 670/1194 | Loss: 312.876 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 680/1194 | Loss: 271.248 | Accuracy: 0.400\n",
      "[Epoch: 163/200] - Step: 690/1194 | Loss: 286.893 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 700/1194 | Loss: 308.242 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 710/1194 | Loss: 281.243 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 720/1194 | Loss: 300.412 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 730/1194 | Loss: 299.851 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 740/1194 | Loss: 303.111 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 750/1194 | Loss: 273.196 | Accuracy: 0.400\n",
      "[Epoch: 163/200] - Step: 760/1194 | Loss: 282.365 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 770/1194 | Loss: 300.536 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 780/1194 | Loss: 295.164 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 790/1194 | Loss: 299.361 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 800/1194 | Loss: 309.056 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 810/1194 | Loss: 318.037 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 820/1194 | Loss: 296.529 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 830/1194 | Loss: 294.409 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 840/1194 | Loss: 287.427 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 850/1194 | Loss: 301.416 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 860/1194 | Loss: 307.411 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 870/1194 | Loss: 283.672 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 880/1194 | Loss: 290.342 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 890/1194 | Loss: 301.114 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 900/1194 | Loss: 308.634 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 910/1194 | Loss: 301.106 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 920/1194 | Loss: 294.167 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 930/1194 | Loss: 283.974 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 940/1194 | Loss: 308.663 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 950/1194 | Loss: 291.462 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 960/1194 | Loss: 270.377 | Accuracy: 0.400\n",
      "[Epoch: 163/200] - Step: 970/1194 | Loss: 308.840 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 980/1194 | Loss: 282.783 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 990/1194 | Loss: 289.217 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1000/1194 | Loss: 285.264 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 1010/1194 | Loss: 307.805 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1020/1194 | Loss: 303.017 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1030/1194 | Loss: 304.528 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1040/1194 | Loss: 300.275 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1050/1194 | Loss: 309.670 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1060/1194 | Loss: 287.401 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1070/1194 | Loss: 312.558 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1080/1194 | Loss: 293.228 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1090/1194 | Loss: 299.560 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 1100/1194 | Loss: 296.003 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1110/1194 | Loss: 278.135 | Accuracy: 0.300\n",
      "[Epoch: 163/200] - Step: 1120/1194 | Loss: 305.786 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1130/1194 | Loss: 300.646 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1140/1194 | Loss: 283.802 | Accuracy: 0.200\n",
      "[Epoch: 163/200] - Step: 1150/1194 | Loss: 294.464 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1160/1194 | Loss: 286.342 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1170/1194 | Loss: 303.717 | Accuracy: 0.000\n",
      "[Epoch: 163/200] - Step: 1180/1194 | Loss: 300.511 | Accuracy: 0.100\n",
      "[Epoch: 163/200] - Step: 1190/1194 | Loss: 300.944 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 164/200] - Step: 10/1194 | Loss: 320.235 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 20/1194 | Loss: 314.724 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 30/1194 | Loss: 294.273 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 40/1194 | Loss: 272.088 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 50/1194 | Loss: 282.272 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 60/1194 | Loss: 299.835 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 70/1194 | Loss: 297.034 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 80/1194 | Loss: 306.571 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 90/1194 | Loss: 300.220 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 100/1194 | Loss: 292.877 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 110/1194 | Loss: 296.597 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 120/1194 | Loss: 292.598 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 130/1194 | Loss: 290.967 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 140/1194 | Loss: 308.130 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 150/1194 | Loss: 295.091 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 160/1194 | Loss: 302.018 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 170/1194 | Loss: 280.385 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 180/1194 | Loss: 294.126 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 190/1194 | Loss: 280.830 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 200/1194 | Loss: 339.771 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 210/1194 | Loss: 305.602 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 220/1194 | Loss: 291.019 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 230/1194 | Loss: 282.338 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 240/1194 | Loss: 284.534 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 250/1194 | Loss: 290.130 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 260/1194 | Loss: 308.930 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 270/1194 | Loss: 299.179 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 280/1194 | Loss: 258.978 | Accuracy: 0.400\n",
      "[Epoch: 164/200] - Step: 290/1194 | Loss: 281.259 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 300/1194 | Loss: 284.315 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 310/1194 | Loss: 296.604 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 320/1194 | Loss: 293.147 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 330/1194 | Loss: 312.079 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 340/1194 | Loss: 289.099 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 350/1194 | Loss: 286.736 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 360/1194 | Loss: 283.241 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 370/1194 | Loss: 306.101 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 380/1194 | Loss: 304.781 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 390/1194 | Loss: 298.909 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 400/1194 | Loss: 310.957 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 410/1194 | Loss: 298.607 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 420/1194 | Loss: 296.212 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 430/1194 | Loss: 312.121 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 440/1194 | Loss: 297.136 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 450/1194 | Loss: 315.658 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 460/1194 | Loss: 289.878 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 470/1194 | Loss: 334.881 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 480/1194 | Loss: 320.348 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 490/1194 | Loss: 285.510 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 500/1194 | Loss: 301.482 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 510/1194 | Loss: 293.761 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 520/1194 | Loss: 286.286 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 530/1194 | Loss: 286.759 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 540/1194 | Loss: 289.792 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 550/1194 | Loss: 306.898 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 560/1194 | Loss: 305.728 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 570/1194 | Loss: 300.384 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 580/1194 | Loss: 288.095 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 590/1194 | Loss: 290.709 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 600/1194 | Loss: 310.923 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 610/1194 | Loss: 303.550 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 620/1194 | Loss: 324.612 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 630/1194 | Loss: 298.927 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 640/1194 | Loss: 279.185 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 650/1194 | Loss: 298.212 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 660/1194 | Loss: 299.793 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 670/1194 | Loss: 304.158 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 680/1194 | Loss: 295.808 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 690/1194 | Loss: 305.165 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 700/1194 | Loss: 304.516 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 710/1194 | Loss: 291.301 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 720/1194 | Loss: 305.647 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 730/1194 | Loss: 294.591 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 740/1194 | Loss: 303.497 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 750/1194 | Loss: 279.670 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 760/1194 | Loss: 311.066 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 770/1194 | Loss: 286.784 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 780/1194 | Loss: 292.233 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 790/1194 | Loss: 319.283 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 800/1194 | Loss: 294.065 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 810/1194 | Loss: 298.253 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 820/1194 | Loss: 300.511 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 830/1194 | Loss: 291.991 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 840/1194 | Loss: 286.342 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 850/1194 | Loss: 303.516 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 860/1194 | Loss: 293.032 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 870/1194 | Loss: 297.419 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 880/1194 | Loss: 295.263 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 890/1194 | Loss: 289.043 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 900/1194 | Loss: 302.262 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 910/1194 | Loss: 321.110 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 920/1194 | Loss: 316.511 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 930/1194 | Loss: 293.591 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 940/1194 | Loss: 284.646 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 950/1194 | Loss: 308.167 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 960/1194 | Loss: 296.978 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 970/1194 | Loss: 299.815 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 980/1194 | Loss: 297.436 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 990/1194 | Loss: 296.833 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1000/1194 | Loss: 302.690 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1010/1194 | Loss: 287.759 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1020/1194 | Loss: 293.371 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1030/1194 | Loss: 291.577 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1040/1194 | Loss: 283.076 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1050/1194 | Loss: 283.626 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 1060/1194 | Loss: 283.633 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1070/1194 | Loss: 304.493 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 1080/1194 | Loss: 305.049 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 1090/1194 | Loss: 290.132 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1100/1194 | Loss: 284.425 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1110/1194 | Loss: 281.617 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1120/1194 | Loss: 306.552 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 1130/1194 | Loss: 302.693 | Accuracy: 0.000\n",
      "[Epoch: 164/200] - Step: 1140/1194 | Loss: 291.735 | Accuracy: 0.100\n",
      "[Epoch: 164/200] - Step: 1150/1194 | Loss: 282.053 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1160/1194 | Loss: 286.910 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1170/1194 | Loss: 285.963 | Accuracy: 0.300\n",
      "[Epoch: 164/200] - Step: 1180/1194 | Loss: 277.457 | Accuracy: 0.200\n",
      "[Epoch: 164/200] - Step: 1190/1194 | Loss: 307.540 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 165/200] - Step: 10/1194 | Loss: 326.382 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 20/1194 | Loss: 275.371 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 30/1194 | Loss: 298.321 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 40/1194 | Loss: 277.453 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 50/1194 | Loss: 321.728 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 60/1194 | Loss: 294.818 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 70/1194 | Loss: 290.171 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 80/1194 | Loss: 277.862 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 90/1194 | Loss: 282.283 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 100/1194 | Loss: 284.430 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 110/1194 | Loss: 307.439 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 120/1194 | Loss: 298.323 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 130/1194 | Loss: 300.082 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 140/1194 | Loss: 268.629 | Accuracy: 0.400\n",
      "[Epoch: 165/200] - Step: 150/1194 | Loss: 299.912 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 160/1194 | Loss: 308.875 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 170/1194 | Loss: 291.106 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 180/1194 | Loss: 288.317 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 190/1194 | Loss: 277.131 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 200/1194 | Loss: 295.805 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 210/1194 | Loss: 304.944 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 220/1194 | Loss: 288.143 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 230/1194 | Loss: 294.342 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 240/1194 | Loss: 286.303 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 250/1194 | Loss: 297.652 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 260/1194 | Loss: 268.771 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 270/1194 | Loss: 314.936 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 280/1194 | Loss: 289.075 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 290/1194 | Loss: 283.575 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 300/1194 | Loss: 297.904 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 310/1194 | Loss: 266.738 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 320/1194 | Loss: 300.606 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 330/1194 | Loss: 285.913 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 340/1194 | Loss: 276.222 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 350/1194 | Loss: 304.939 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 360/1194 | Loss: 293.269 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 370/1194 | Loss: 274.143 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 380/1194 | Loss: 298.799 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 390/1194 | Loss: 295.255 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 400/1194 | Loss: 303.100 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 410/1194 | Loss: 310.266 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 420/1194 | Loss: 287.626 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 430/1194 | Loss: 306.781 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 440/1194 | Loss: 285.035 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 450/1194 | Loss: 300.763 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 460/1194 | Loss: 297.548 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 470/1194 | Loss: 287.371 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 480/1194 | Loss: 299.367 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 490/1194 | Loss: 312.420 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 500/1194 | Loss: 304.681 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 510/1194 | Loss: 308.239 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 520/1194 | Loss: 299.942 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 530/1194 | Loss: 289.031 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 540/1194 | Loss: 317.069 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 550/1194 | Loss: 313.464 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 560/1194 | Loss: 280.674 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 570/1194 | Loss: 272.079 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 580/1194 | Loss: 300.349 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 590/1194 | Loss: 304.743 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 600/1194 | Loss: 274.928 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 610/1194 | Loss: 292.401 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 620/1194 | Loss: 302.059 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 630/1194 | Loss: 303.979 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 640/1194 | Loss: 298.305 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 650/1194 | Loss: 296.532 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 660/1194 | Loss: 292.838 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 670/1194 | Loss: 305.131 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 680/1194 | Loss: 295.132 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 690/1194 | Loss: 283.302 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 700/1194 | Loss: 288.074 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 710/1194 | Loss: 310.066 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 720/1194 | Loss: 285.552 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 730/1194 | Loss: 301.256 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 740/1194 | Loss: 302.980 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 750/1194 | Loss: 346.248 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 760/1194 | Loss: 304.971 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 770/1194 | Loss: 298.027 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 780/1194 | Loss: 297.869 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 790/1194 | Loss: 277.353 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 800/1194 | Loss: 303.181 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 810/1194 | Loss: 315.105 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 820/1194 | Loss: 259.857 | Accuracy: 0.500\n",
      "[Epoch: 165/200] - Step: 830/1194 | Loss: 290.445 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 840/1194 | Loss: 305.095 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 850/1194 | Loss: 282.359 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 860/1194 | Loss: 279.128 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 870/1194 | Loss: 292.637 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 880/1194 | Loss: 314.378 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 890/1194 | Loss: 306.668 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 900/1194 | Loss: 286.748 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 910/1194 | Loss: 309.517 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 920/1194 | Loss: 294.893 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 930/1194 | Loss: 294.001 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 940/1194 | Loss: 283.761 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 950/1194 | Loss: 301.111 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 960/1194 | Loss: 303.333 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 970/1194 | Loss: 300.277 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 980/1194 | Loss: 299.346 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 990/1194 | Loss: 291.562 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 1000/1194 | Loss: 302.167 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1010/1194 | Loss: 298.271 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1020/1194 | Loss: 299.169 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1030/1194 | Loss: 299.694 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1040/1194 | Loss: 308.246 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1050/1194 | Loss: 335.327 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1060/1194 | Loss: 310.666 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1070/1194 | Loss: 323.735 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1080/1194 | Loss: 298.428 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1090/1194 | Loss: 288.601 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1100/1194 | Loss: 290.207 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 1110/1194 | Loss: 341.063 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1120/1194 | Loss: 300.053 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1130/1194 | Loss: 288.215 | Accuracy: 0.300\n",
      "[Epoch: 165/200] - Step: 1140/1194 | Loss: 286.776 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 1150/1194 | Loss: 280.259 | Accuracy: 0.200\n",
      "[Epoch: 165/200] - Step: 1160/1194 | Loss: 292.289 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1170/1194 | Loss: 293.076 | Accuracy: 0.100\n",
      "[Epoch: 165/200] - Step: 1180/1194 | Loss: 310.270 | Accuracy: 0.000\n",
      "[Epoch: 165/200] - Step: 1190/1194 | Loss: 307.427 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 166/200] - Step: 10/1194 | Loss: 304.102 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 20/1194 | Loss: 301.279 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 30/1194 | Loss: 295.153 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 40/1194 | Loss: 307.921 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 50/1194 | Loss: 290.867 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 60/1194 | Loss: 305.445 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 70/1194 | Loss: 278.545 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 80/1194 | Loss: 302.426 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 90/1194 | Loss: 303.186 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 100/1194 | Loss: 294.293 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 110/1194 | Loss: 302.808 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 120/1194 | Loss: 309.914 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 130/1194 | Loss: 294.822 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 140/1194 | Loss: 302.182 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 150/1194 | Loss: 276.157 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 160/1194 | Loss: 298.686 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 170/1194 | Loss: 298.764 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 180/1194 | Loss: 304.311 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 190/1194 | Loss: 294.144 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 200/1194 | Loss: 303.076 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 210/1194 | Loss: 326.637 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 220/1194 | Loss: 300.501 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 230/1194 | Loss: 287.589 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 240/1194 | Loss: 284.470 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 250/1194 | Loss: 290.908 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 260/1194 | Loss: 298.692 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 270/1194 | Loss: 263.562 | Accuracy: 0.500\n",
      "[Epoch: 166/200] - Step: 280/1194 | Loss: 292.198 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 290/1194 | Loss: 286.917 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 300/1194 | Loss: 304.677 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 310/1194 | Loss: 315.502 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 320/1194 | Loss: 274.629 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 330/1194 | Loss: 287.298 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 340/1194 | Loss: 297.312 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 350/1194 | Loss: 294.289 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 360/1194 | Loss: 287.548 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 370/1194 | Loss: 310.697 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 380/1194 | Loss: 283.781 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 390/1194 | Loss: 306.152 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 400/1194 | Loss: 291.080 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 410/1194 | Loss: 258.741 | Accuracy: 0.500\n",
      "[Epoch: 166/200] - Step: 420/1194 | Loss: 302.085 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 430/1194 | Loss: 308.231 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 440/1194 | Loss: 305.586 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 450/1194 | Loss: 286.450 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 460/1194 | Loss: 292.630 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 470/1194 | Loss: 303.258 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 480/1194 | Loss: 288.944 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 490/1194 | Loss: 295.959 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 500/1194 | Loss: 281.195 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 510/1194 | Loss: 293.766 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 520/1194 | Loss: 292.148 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 530/1194 | Loss: 307.092 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 540/1194 | Loss: 291.586 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 550/1194 | Loss: 300.538 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 560/1194 | Loss: 293.428 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 570/1194 | Loss: 305.696 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 580/1194 | Loss: 303.900 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 590/1194 | Loss: 316.878 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 600/1194 | Loss: 308.122 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 610/1194 | Loss: 298.596 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 620/1194 | Loss: 304.708 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 630/1194 | Loss: 264.961 | Accuracy: 0.400\n",
      "[Epoch: 166/200] - Step: 640/1194 | Loss: 281.697 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 650/1194 | Loss: 305.160 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 660/1194 | Loss: 303.654 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 670/1194 | Loss: 305.176 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 680/1194 | Loss: 302.169 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 690/1194 | Loss: 288.478 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 700/1194 | Loss: 298.965 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 710/1194 | Loss: 302.174 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 720/1194 | Loss: 295.727 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 730/1194 | Loss: 302.507 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 740/1194 | Loss: 290.928 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 750/1194 | Loss: 300.963 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 760/1194 | Loss: 289.922 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 770/1194 | Loss: 305.789 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 780/1194 | Loss: 293.825 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 790/1194 | Loss: 295.437 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 800/1194 | Loss: 301.832 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 810/1194 | Loss: 304.529 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 820/1194 | Loss: 295.141 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 830/1194 | Loss: 291.402 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 840/1194 | Loss: 313.688 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 850/1194 | Loss: 293.997 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 860/1194 | Loss: 290.443 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 870/1194 | Loss: 295.662 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 880/1194 | Loss: 299.755 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 890/1194 | Loss: 293.023 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 900/1194 | Loss: 285.010 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 910/1194 | Loss: 309.533 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 920/1194 | Loss: 300.443 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 930/1194 | Loss: 331.344 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 940/1194 | Loss: 289.464 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 950/1194 | Loss: 306.676 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 960/1194 | Loss: 330.046 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 970/1194 | Loss: 278.688 | Accuracy: 0.400\n",
      "[Epoch: 166/200] - Step: 980/1194 | Loss: 295.392 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 990/1194 | Loss: 290.188 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1000/1194 | Loss: 299.375 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1010/1194 | Loss: 292.441 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1020/1194 | Loss: 293.726 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1030/1194 | Loss: 297.415 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1040/1194 | Loss: 306.827 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 1050/1194 | Loss: 321.862 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1060/1194 | Loss: 292.429 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1070/1194 | Loss: 284.465 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1080/1194 | Loss: 288.570 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1090/1194 | Loss: 300.014 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 1100/1194 | Loss: 293.515 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1110/1194 | Loss: 288.477 | Accuracy: 0.200\n",
      "[Epoch: 166/200] - Step: 1120/1194 | Loss: 293.892 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 1130/1194 | Loss: 283.822 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 1140/1194 | Loss: 285.088 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1150/1194 | Loss: 303.021 | Accuracy: 0.100\n",
      "[Epoch: 166/200] - Step: 1160/1194 | Loss: 297.536 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 1170/1194 | Loss: 283.202 | Accuracy: 0.300\n",
      "[Epoch: 166/200] - Step: 1180/1194 | Loss: 308.344 | Accuracy: 0.000\n",
      "[Epoch: 166/200] - Step: 1190/1194 | Loss: 304.399 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 167/200] - Step: 10/1194 | Loss: 311.316 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 20/1194 | Loss: 278.580 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 30/1194 | Loss: 335.694 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 40/1194 | Loss: 303.054 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 50/1194 | Loss: 301.584 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 60/1194 | Loss: 277.548 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 70/1194 | Loss: 291.922 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 80/1194 | Loss: 312.282 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 90/1194 | Loss: 306.270 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 100/1194 | Loss: 294.121 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 110/1194 | Loss: 286.510 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 120/1194 | Loss: 298.763 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 130/1194 | Loss: 294.615 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 140/1194 | Loss: 301.075 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 150/1194 | Loss: 295.971 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 160/1194 | Loss: 304.217 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 170/1194 | Loss: 304.491 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 180/1194 | Loss: 298.805 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 190/1194 | Loss: 288.990 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 200/1194 | Loss: 291.977 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 210/1194 | Loss: 339.803 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 220/1194 | Loss: 292.443 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 230/1194 | Loss: 298.368 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 240/1194 | Loss: 290.986 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 250/1194 | Loss: 297.124 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 260/1194 | Loss: 297.792 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 270/1194 | Loss: 288.155 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 280/1194 | Loss: 291.998 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 290/1194 | Loss: 303.442 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 300/1194 | Loss: 289.029 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 310/1194 | Loss: 291.723 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 320/1194 | Loss: 284.462 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 330/1194 | Loss: 293.563 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 340/1194 | Loss: 304.326 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 350/1194 | Loss: 288.125 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 360/1194 | Loss: 285.095 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 370/1194 | Loss: 298.033 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 380/1194 | Loss: 307.153 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 390/1194 | Loss: 329.816 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 400/1194 | Loss: 294.312 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 410/1194 | Loss: 283.145 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 420/1194 | Loss: 285.182 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 430/1194 | Loss: 294.875 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 440/1194 | Loss: 279.405 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 450/1194 | Loss: 306.120 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 460/1194 | Loss: 294.780 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 470/1194 | Loss: 291.133 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 480/1194 | Loss: 279.898 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 490/1194 | Loss: 285.395 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 500/1194 | Loss: 286.054 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 510/1194 | Loss: 290.909 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 520/1194 | Loss: 294.847 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 530/1194 | Loss: 340.530 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 540/1194 | Loss: 277.922 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 550/1194 | Loss: 312.704 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 560/1194 | Loss: 297.414 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 570/1194 | Loss: 308.826 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 580/1194 | Loss: 293.427 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 590/1194 | Loss: 301.407 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 600/1194 | Loss: 286.635 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 610/1194 | Loss: 308.521 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 620/1194 | Loss: 304.443 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 630/1194 | Loss: 294.001 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 640/1194 | Loss: 294.663 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 650/1194 | Loss: 330.757 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 660/1194 | Loss: 332.956 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 670/1194 | Loss: 302.343 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 680/1194 | Loss: 292.542 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 690/1194 | Loss: 293.886 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 700/1194 | Loss: 301.772 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 710/1194 | Loss: 286.972 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 720/1194 | Loss: 289.284 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 730/1194 | Loss: 284.325 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 740/1194 | Loss: 300.366 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 750/1194 | Loss: 289.067 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 760/1194 | Loss: 286.391 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 770/1194 | Loss: 303.792 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 780/1194 | Loss: 292.174 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 790/1194 | Loss: 277.566 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 800/1194 | Loss: 300.270 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 810/1194 | Loss: 286.287 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 820/1194 | Loss: 294.035 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 830/1194 | Loss: 305.647 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 840/1194 | Loss: 319.252 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 850/1194 | Loss: 312.322 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 860/1194 | Loss: 292.276 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 870/1194 | Loss: 279.204 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 880/1194 | Loss: 293.795 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 890/1194 | Loss: 306.115 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 900/1194 | Loss: 293.676 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 910/1194 | Loss: 296.766 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 920/1194 | Loss: 284.081 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 930/1194 | Loss: 289.404 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 940/1194 | Loss: 307.265 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 950/1194 | Loss: 294.139 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 960/1194 | Loss: 293.059 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 970/1194 | Loss: 296.581 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 980/1194 | Loss: 308.366 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 990/1194 | Loss: 275.415 | Accuracy: 0.400\n",
      "[Epoch: 167/200] - Step: 1000/1194 | Loss: 276.772 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 1010/1194 | Loss: 283.949 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 1020/1194 | Loss: 279.807 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 1030/1194 | Loss: 284.893 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 1040/1194 | Loss: 305.370 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 1050/1194 | Loss: 307.875 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 1060/1194 | Loss: 320.441 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 1070/1194 | Loss: 290.772 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1080/1194 | Loss: 295.695 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1090/1194 | Loss: 297.909 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1100/1194 | Loss: 304.589 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 1110/1194 | Loss: 298.587 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1120/1194 | Loss: 301.114 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1130/1194 | Loss: 284.256 | Accuracy: 0.300\n",
      "[Epoch: 167/200] - Step: 1140/1194 | Loss: 280.993 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 1150/1194 | Loss: 300.859 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1160/1194 | Loss: 288.723 | Accuracy: 0.200\n",
      "[Epoch: 167/200] - Step: 1170/1194 | Loss: 307.718 | Accuracy: 0.100\n",
      "[Epoch: 167/200] - Step: 1180/1194 | Loss: 312.061 | Accuracy: 0.000\n",
      "[Epoch: 167/200] - Step: 1190/1194 | Loss: 291.351 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 168/200] - Step: 10/1194 | Loss: 299.512 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 20/1194 | Loss: 280.334 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 30/1194 | Loss: 295.556 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 40/1194 | Loss: 281.144 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 50/1194 | Loss: 309.500 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 60/1194 | Loss: 309.405 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 70/1194 | Loss: 285.066 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 80/1194 | Loss: 302.280 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 90/1194 | Loss: 336.967 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 100/1194 | Loss: 280.060 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 110/1194 | Loss: 291.266 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 120/1194 | Loss: 297.204 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 130/1194 | Loss: 299.318 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 140/1194 | Loss: 331.052 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 150/1194 | Loss: 296.398 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 160/1194 | Loss: 307.755 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 170/1194 | Loss: 301.492 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 180/1194 | Loss: 290.490 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 190/1194 | Loss: 311.386 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 200/1194 | Loss: 291.852 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 210/1194 | Loss: 303.689 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 220/1194 | Loss: 280.103 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 230/1194 | Loss: 303.852 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 240/1194 | Loss: 314.253 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 250/1194 | Loss: 279.500 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 260/1194 | Loss: 286.991 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 270/1194 | Loss: 299.261 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 280/1194 | Loss: 283.786 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 290/1194 | Loss: 313.297 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 300/1194 | Loss: 302.124 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 310/1194 | Loss: 310.286 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 320/1194 | Loss: 301.184 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 330/1194 | Loss: 286.538 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 340/1194 | Loss: 286.837 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 350/1194 | Loss: 319.495 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 360/1194 | Loss: 302.131 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 370/1194 | Loss: 281.533 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 380/1194 | Loss: 306.772 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 390/1194 | Loss: 293.914 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 400/1194 | Loss: 290.840 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 410/1194 | Loss: 287.018 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 420/1194 | Loss: 283.571 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 430/1194 | Loss: 304.679 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 440/1194 | Loss: 299.349 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 450/1194 | Loss: 294.773 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 460/1194 | Loss: 290.614 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 470/1194 | Loss: 296.076 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 480/1194 | Loss: 286.517 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 490/1194 | Loss: 301.347 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 500/1194 | Loss: 301.518 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 510/1194 | Loss: 291.192 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 520/1194 | Loss: 282.672 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 530/1194 | Loss: 289.410 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 540/1194 | Loss: 286.949 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 550/1194 | Loss: 309.180 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 560/1194 | Loss: 293.307 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 570/1194 | Loss: 331.820 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 580/1194 | Loss: 291.955 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 590/1194 | Loss: 299.538 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 600/1194 | Loss: 290.511 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 610/1194 | Loss: 277.661 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 620/1194 | Loss: 297.068 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 630/1194 | Loss: 297.649 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 640/1194 | Loss: 296.597 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 650/1194 | Loss: 292.652 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 660/1194 | Loss: 297.151 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 670/1194 | Loss: 282.524 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 680/1194 | Loss: 311.376 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 690/1194 | Loss: 285.456 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 700/1194 | Loss: 302.228 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 710/1194 | Loss: 303.229 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 720/1194 | Loss: 290.644 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 730/1194 | Loss: 304.672 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 740/1194 | Loss: 304.747 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 750/1194 | Loss: 296.420 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 760/1194 | Loss: 313.235 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 770/1194 | Loss: 283.729 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 780/1194 | Loss: 276.678 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 790/1194 | Loss: 311.509 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 800/1194 | Loss: 306.102 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 810/1194 | Loss: 324.968 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 820/1194 | Loss: 306.462 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 830/1194 | Loss: 301.496 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 840/1194 | Loss: 302.789 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 850/1194 | Loss: 295.269 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 860/1194 | Loss: 298.086 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 870/1194 | Loss: 281.069 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 880/1194 | Loss: 279.947 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 890/1194 | Loss: 302.888 | Accuracy: 0.400\n",
      "[Epoch: 168/200] - Step: 900/1194 | Loss: 299.637 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 910/1194 | Loss: 291.550 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 920/1194 | Loss: 294.421 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 930/1194 | Loss: 297.764 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 940/1194 | Loss: 286.406 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 950/1194 | Loss: 292.665 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 960/1194 | Loss: 303.763 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 970/1194 | Loss: 284.696 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 980/1194 | Loss: 266.763 | Accuracy: 0.400\n",
      "[Epoch: 168/200] - Step: 990/1194 | Loss: 299.244 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1000/1194 | Loss: 298.008 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1010/1194 | Loss: 301.135 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1020/1194 | Loss: 311.736 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1030/1194 | Loss: 309.613 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1040/1194 | Loss: 304.854 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1050/1194 | Loss: 289.288 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1060/1194 | Loss: 281.032 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1070/1194 | Loss: 300.656 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1080/1194 | Loss: 296.920 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1090/1194 | Loss: 302.605 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1100/1194 | Loss: 272.996 | Accuracy: 0.400\n",
      "[Epoch: 168/200] - Step: 1110/1194 | Loss: 292.988 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1120/1194 | Loss: 304.209 | Accuracy: 0.000\n",
      "[Epoch: 168/200] - Step: 1130/1194 | Loss: 287.615 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1140/1194 | Loss: 280.587 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1150/1194 | Loss: 303.763 | Accuracy: 0.300\n",
      "[Epoch: 168/200] - Step: 1160/1194 | Loss: 288.521 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1170/1194 | Loss: 294.949 | Accuracy: 0.200\n",
      "[Epoch: 168/200] - Step: 1180/1194 | Loss: 292.290 | Accuracy: 0.100\n",
      "[Epoch: 168/200] - Step: 1190/1194 | Loss: 309.153 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 169/200] - Step: 10/1194 | Loss: 297.160 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 20/1194 | Loss: 295.503 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 30/1194 | Loss: 298.492 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 40/1194 | Loss: 297.544 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 50/1194 | Loss: 291.677 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 60/1194 | Loss: 291.867 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 70/1194 | Loss: 312.576 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 80/1194 | Loss: 293.689 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 90/1194 | Loss: 297.232 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 100/1194 | Loss: 312.521 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 110/1194 | Loss: 296.812 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 120/1194 | Loss: 274.866 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 130/1194 | Loss: 287.103 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 140/1194 | Loss: 263.903 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 150/1194 | Loss: 299.248 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 160/1194 | Loss: 299.628 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 170/1194 | Loss: 324.047 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 180/1194 | Loss: 269.640 | Accuracy: 0.400\n",
      "[Epoch: 169/200] - Step: 190/1194 | Loss: 297.369 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 200/1194 | Loss: 329.955 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 210/1194 | Loss: 297.799 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 220/1194 | Loss: 318.705 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 230/1194 | Loss: 286.973 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 240/1194 | Loss: 291.148 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 250/1194 | Loss: 289.846 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 260/1194 | Loss: 287.581 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 270/1194 | Loss: 286.305 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 280/1194 | Loss: 287.055 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 290/1194 | Loss: 317.612 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 300/1194 | Loss: 314.282 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 310/1194 | Loss: 308.140 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 320/1194 | Loss: 296.179 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 330/1194 | Loss: 287.179 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 340/1194 | Loss: 292.143 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 350/1194 | Loss: 273.961 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 360/1194 | Loss: 292.748 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 370/1194 | Loss: 299.959 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 380/1194 | Loss: 296.035 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 390/1194 | Loss: 295.642 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 400/1194 | Loss: 295.816 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 410/1194 | Loss: 287.616 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 420/1194 | Loss: 309.180 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 430/1194 | Loss: 276.885 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 440/1194 | Loss: 262.131 | Accuracy: 0.400\n",
      "[Epoch: 169/200] - Step: 450/1194 | Loss: 296.923 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 460/1194 | Loss: 296.710 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 470/1194 | Loss: 316.111 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 480/1194 | Loss: 323.942 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 490/1194 | Loss: 303.624 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 500/1194 | Loss: 293.984 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 510/1194 | Loss: 294.578 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 520/1194 | Loss: 289.262 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 530/1194 | Loss: 289.426 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 540/1194 | Loss: 290.736 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 550/1194 | Loss: 307.730 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 560/1194 | Loss: 289.040 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 570/1194 | Loss: 293.036 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 580/1194 | Loss: 287.905 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 590/1194 | Loss: 298.171 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 600/1194 | Loss: 274.602 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 610/1194 | Loss: 285.238 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 620/1194 | Loss: 309.408 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 630/1194 | Loss: 297.070 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 640/1194 | Loss: 307.906 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 650/1194 | Loss: 302.077 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 660/1194 | Loss: 312.336 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 670/1194 | Loss: 283.829 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 680/1194 | Loss: 314.978 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 690/1194 | Loss: 295.905 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 700/1194 | Loss: 303.034 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 710/1194 | Loss: 307.136 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 720/1194 | Loss: 308.989 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 730/1194 | Loss: 286.856 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 740/1194 | Loss: 300.361 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 750/1194 | Loss: 311.181 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 760/1194 | Loss: 295.364 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 770/1194 | Loss: 288.054 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 780/1194 | Loss: 311.106 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 790/1194 | Loss: 312.121 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 800/1194 | Loss: 306.381 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 810/1194 | Loss: 291.808 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 820/1194 | Loss: 303.924 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 830/1194 | Loss: 297.931 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 840/1194 | Loss: 298.789 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 850/1194 | Loss: 312.741 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 860/1194 | Loss: 305.889 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 870/1194 | Loss: 292.301 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 880/1194 | Loss: 285.214 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 890/1194 | Loss: 299.818 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 900/1194 | Loss: 289.491 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 910/1194 | Loss: 310.468 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 920/1194 | Loss: 321.974 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 930/1194 | Loss: 306.846 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 940/1194 | Loss: 281.507 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 950/1194 | Loss: 309.666 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 960/1194 | Loss: 302.106 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 970/1194 | Loss: 307.963 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 980/1194 | Loss: 304.074 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 990/1194 | Loss: 294.766 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1000/1194 | Loss: 277.317 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1010/1194 | Loss: 291.519 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1020/1194 | Loss: 301.370 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1030/1194 | Loss: 314.069 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 1040/1194 | Loss: 294.803 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1050/1194 | Loss: 295.332 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 1060/1194 | Loss: 300.082 | Accuracy: 0.000\n",
      "[Epoch: 169/200] - Step: 1070/1194 | Loss: 275.174 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1080/1194 | Loss: 288.893 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1090/1194 | Loss: 298.432 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1100/1194 | Loss: 302.698 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1110/1194 | Loss: 280.955 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1120/1194 | Loss: 301.371 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1130/1194 | Loss: 300.473 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1140/1194 | Loss: 299.031 | Accuracy: 0.100\n",
      "[Epoch: 169/200] - Step: 1150/1194 | Loss: 292.863 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1160/1194 | Loss: 273.650 | Accuracy: 0.300\n",
      "[Epoch: 169/200] - Step: 1170/1194 | Loss: 283.564 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1180/1194 | Loss: 289.780 | Accuracy: 0.200\n",
      "[Epoch: 169/200] - Step: 1190/1194 | Loss: 286.525 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 170/200] - Step: 10/1194 | Loss: 279.464 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 20/1194 | Loss: 291.306 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 30/1194 | Loss: 296.395 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 40/1194 | Loss: 292.169 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 50/1194 | Loss: 297.442 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 60/1194 | Loss: 306.712 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 70/1194 | Loss: 301.824 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 80/1194 | Loss: 309.559 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 90/1194 | Loss: 294.214 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 100/1194 | Loss: 293.087 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 110/1194 | Loss: 279.526 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 120/1194 | Loss: 298.263 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 130/1194 | Loss: 290.343 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 140/1194 | Loss: 296.178 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 150/1194 | Loss: 291.369 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 160/1194 | Loss: 309.280 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 170/1194 | Loss: 280.638 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 180/1194 | Loss: 298.155 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 190/1194 | Loss: 290.937 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 200/1194 | Loss: 306.000 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 210/1194 | Loss: 281.684 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 220/1194 | Loss: 286.757 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 230/1194 | Loss: 291.998 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 240/1194 | Loss: 293.854 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 250/1194 | Loss: 314.877 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 260/1194 | Loss: 296.903 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 270/1194 | Loss: 306.557 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 280/1194 | Loss: 299.450 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 290/1194 | Loss: 318.035 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 300/1194 | Loss: 292.173 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 310/1194 | Loss: 292.204 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 320/1194 | Loss: 313.004 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 330/1194 | Loss: 294.610 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 340/1194 | Loss: 296.459 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 350/1194 | Loss: 302.803 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 360/1194 | Loss: 292.648 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 370/1194 | Loss: 304.523 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 380/1194 | Loss: 278.421 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 390/1194 | Loss: 284.215 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 400/1194 | Loss: 294.331 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 410/1194 | Loss: 294.299 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 420/1194 | Loss: 295.246 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 430/1194 | Loss: 309.630 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 440/1194 | Loss: 278.015 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 450/1194 | Loss: 325.285 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 460/1194 | Loss: 298.572 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 470/1194 | Loss: 291.633 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 480/1194 | Loss: 301.687 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 490/1194 | Loss: 332.054 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 500/1194 | Loss: 289.271 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 510/1194 | Loss: 287.257 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 520/1194 | Loss: 277.367 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 530/1194 | Loss: 307.372 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 540/1194 | Loss: 293.309 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 550/1194 | Loss: 288.338 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 560/1194 | Loss: 282.997 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 570/1194 | Loss: 301.422 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 580/1194 | Loss: 288.014 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 590/1194 | Loss: 295.204 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 600/1194 | Loss: 278.621 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 610/1194 | Loss: 303.560 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 620/1194 | Loss: 299.666 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 630/1194 | Loss: 269.685 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 640/1194 | Loss: 301.220 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 650/1194 | Loss: 305.262 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 660/1194 | Loss: 330.697 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 670/1194 | Loss: 279.077 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 680/1194 | Loss: 297.297 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 690/1194 | Loss: 297.874 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 700/1194 | Loss: 289.223 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 710/1194 | Loss: 298.763 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 720/1194 | Loss: 298.654 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 730/1194 | Loss: 294.810 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 740/1194 | Loss: 294.938 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 750/1194 | Loss: 334.825 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 760/1194 | Loss: 293.338 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 770/1194 | Loss: 294.628 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 780/1194 | Loss: 307.978 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 790/1194 | Loss: 287.650 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 800/1194 | Loss: 288.751 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 810/1194 | Loss: 298.961 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 820/1194 | Loss: 288.854 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 830/1194 | Loss: 281.637 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 840/1194 | Loss: 288.877 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 850/1194 | Loss: 301.306 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 860/1194 | Loss: 295.683 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 870/1194 | Loss: 303.935 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 880/1194 | Loss: 282.898 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 890/1194 | Loss: 309.905 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 900/1194 | Loss: 310.769 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 910/1194 | Loss: 299.350 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 920/1194 | Loss: 293.017 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 930/1194 | Loss: 290.839 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 940/1194 | Loss: 286.177 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 950/1194 | Loss: 292.485 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 960/1194 | Loss: 302.678 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 970/1194 | Loss: 291.841 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 980/1194 | Loss: 305.171 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 990/1194 | Loss: 296.149 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 1000/1194 | Loss: 316.921 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1010/1194 | Loss: 305.155 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1020/1194 | Loss: 298.759 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1030/1194 | Loss: 291.881 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 1040/1194 | Loss: 300.202 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1050/1194 | Loss: 296.438 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1060/1194 | Loss: 290.165 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1070/1194 | Loss: 302.715 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1080/1194 | Loss: 304.937 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1090/1194 | Loss: 279.301 | Accuracy: 0.300\n",
      "[Epoch: 170/200] - Step: 1100/1194 | Loss: 267.002 | Accuracy: 0.400\n",
      "[Epoch: 170/200] - Step: 1110/1194 | Loss: 291.076 | Accuracy: 0.200\n",
      "[Epoch: 170/200] - Step: 1120/1194 | Loss: 309.921 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1130/1194 | Loss: 298.943 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1140/1194 | Loss: 316.293 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1150/1194 | Loss: 294.778 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1160/1194 | Loss: 301.236 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1170/1194 | Loss: 287.441 | Accuracy: 0.100\n",
      "[Epoch: 170/200] - Step: 1180/1194 | Loss: 335.392 | Accuracy: 0.000\n",
      "[Epoch: 170/200] - Step: 1190/1194 | Loss: 308.837 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 171/200] - Step: 10/1194 | Loss: 288.011 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 20/1194 | Loss: 303.173 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 30/1194 | Loss: 289.906 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 40/1194 | Loss: 283.197 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 50/1194 | Loss: 301.364 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 60/1194 | Loss: 324.460 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 70/1194 | Loss: 303.152 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 80/1194 | Loss: 296.142 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 90/1194 | Loss: 305.924 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 100/1194 | Loss: 280.432 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 110/1194 | Loss: 293.030 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 120/1194 | Loss: 284.582 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 130/1194 | Loss: 293.072 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 140/1194 | Loss: 289.863 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 150/1194 | Loss: 287.913 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 160/1194 | Loss: 290.471 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 170/1194 | Loss: 305.547 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 180/1194 | Loss: 298.082 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 190/1194 | Loss: 293.345 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 200/1194 | Loss: 277.447 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 210/1194 | Loss: 330.002 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 220/1194 | Loss: 304.053 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 230/1194 | Loss: 294.104 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 240/1194 | Loss: 302.499 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 250/1194 | Loss: 294.439 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 260/1194 | Loss: 304.452 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 270/1194 | Loss: 291.535 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 280/1194 | Loss: 303.112 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 290/1194 | Loss: 315.873 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 300/1194 | Loss: 297.197 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 310/1194 | Loss: 305.700 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 320/1194 | Loss: 277.572 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 330/1194 | Loss: 304.218 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 340/1194 | Loss: 292.671 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 350/1194 | Loss: 284.808 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 360/1194 | Loss: 302.456 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 370/1194 | Loss: 303.975 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 380/1194 | Loss: 297.129 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 390/1194 | Loss: 286.882 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 400/1194 | Loss: 305.569 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 410/1194 | Loss: 294.089 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 420/1194 | Loss: 291.501 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 430/1194 | Loss: 301.047 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 440/1194 | Loss: 270.904 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 450/1194 | Loss: 285.371 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 460/1194 | Loss: 294.855 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 470/1194 | Loss: 298.125 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 480/1194 | Loss: 308.614 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 490/1194 | Loss: 296.394 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 500/1194 | Loss: 294.880 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 510/1194 | Loss: 296.819 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 520/1194 | Loss: 322.119 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 530/1194 | Loss: 294.420 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 540/1194 | Loss: 306.183 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 550/1194 | Loss: 300.240 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 560/1194 | Loss: 301.901 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 570/1194 | Loss: 286.391 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 580/1194 | Loss: 278.215 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 590/1194 | Loss: 298.075 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 600/1194 | Loss: 304.458 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 610/1194 | Loss: 301.735 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 620/1194 | Loss: 310.068 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 630/1194 | Loss: 280.588 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 640/1194 | Loss: 305.612 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 650/1194 | Loss: 286.307 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 660/1194 | Loss: 282.999 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 670/1194 | Loss: 281.854 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 680/1194 | Loss: 334.247 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 690/1194 | Loss: 299.635 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 700/1194 | Loss: 299.717 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 710/1194 | Loss: 302.652 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 720/1194 | Loss: 300.500 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 730/1194 | Loss: 319.987 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 740/1194 | Loss: 290.079 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 750/1194 | Loss: 293.990 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 760/1194 | Loss: 307.709 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 770/1194 | Loss: 300.424 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 780/1194 | Loss: 296.637 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 790/1194 | Loss: 306.707 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 800/1194 | Loss: 301.085 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 810/1194 | Loss: 294.790 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 820/1194 | Loss: 286.057 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 830/1194 | Loss: 294.253 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 840/1194 | Loss: 305.888 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 850/1194 | Loss: 305.723 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 860/1194 | Loss: 299.739 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 870/1194 | Loss: 282.596 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 880/1194 | Loss: 307.692 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 890/1194 | Loss: 284.859 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 900/1194 | Loss: 296.066 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 910/1194 | Loss: 307.530 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 920/1194 | Loss: 312.018 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 930/1194 | Loss: 300.810 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 940/1194 | Loss: 296.003 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 950/1194 | Loss: 302.841 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 960/1194 | Loss: 296.605 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 970/1194 | Loss: 303.766 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 980/1194 | Loss: 293.443 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 990/1194 | Loss: 298.528 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1000/1194 | Loss: 286.747 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 1010/1194 | Loss: 304.823 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 1020/1194 | Loss: 299.172 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1030/1194 | Loss: 287.732 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1040/1194 | Loss: 283.693 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 1050/1194 | Loss: 287.622 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1060/1194 | Loss: 271.249 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 1070/1194 | Loss: 275.428 | Accuracy: 0.300\n",
      "[Epoch: 171/200] - Step: 1080/1194 | Loss: 289.680 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1090/1194 | Loss: 302.342 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 1100/1194 | Loss: 290.080 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1110/1194 | Loss: 323.319 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 1120/1194 | Loss: 257.143 | Accuracy: 0.500\n",
      "[Epoch: 171/200] - Step: 1130/1194 | Loss: 296.050 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1140/1194 | Loss: 291.274 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 1150/1194 | Loss: 310.862 | Accuracy: 0.000\n",
      "[Epoch: 171/200] - Step: 1160/1194 | Loss: 283.929 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1170/1194 | Loss: 284.341 | Accuracy: 0.100\n",
      "[Epoch: 171/200] - Step: 1180/1194 | Loss: 297.967 | Accuracy: 0.200\n",
      "[Epoch: 171/200] - Step: 1190/1194 | Loss: 306.004 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 172/200] - Step: 10/1194 | Loss: 300.031 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 20/1194 | Loss: 294.609 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 30/1194 | Loss: 302.838 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 40/1194 | Loss: 311.088 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 50/1194 | Loss: 305.269 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 60/1194 | Loss: 301.856 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 70/1194 | Loss: 309.743 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 80/1194 | Loss: 302.559 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 90/1194 | Loss: 301.413 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 100/1194 | Loss: 301.804 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 110/1194 | Loss: 292.106 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 120/1194 | Loss: 294.535 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 130/1194 | Loss: 296.926 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 140/1194 | Loss: 276.923 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 150/1194 | Loss: 277.475 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 160/1194 | Loss: 300.578 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 170/1194 | Loss: 292.498 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 180/1194 | Loss: 297.473 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 190/1194 | Loss: 304.894 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 200/1194 | Loss: 288.347 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 210/1194 | Loss: 260.724 | Accuracy: 0.500\n",
      "[Epoch: 172/200] - Step: 220/1194 | Loss: 305.104 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 230/1194 | Loss: 311.346 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 240/1194 | Loss: 287.038 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 250/1194 | Loss: 319.939 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 260/1194 | Loss: 310.526 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 270/1194 | Loss: 276.921 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 280/1194 | Loss: 280.468 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 290/1194 | Loss: 304.880 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 300/1194 | Loss: 292.894 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 310/1194 | Loss: 293.486 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 320/1194 | Loss: 284.572 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 330/1194 | Loss: 343.886 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 340/1194 | Loss: 290.261 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 350/1194 | Loss: 307.825 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 360/1194 | Loss: 303.893 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 370/1194 | Loss: 267.040 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 380/1194 | Loss: 277.795 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 390/1194 | Loss: 298.969 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 400/1194 | Loss: 295.846 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 410/1194 | Loss: 294.416 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 420/1194 | Loss: 292.970 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 430/1194 | Loss: 327.627 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 440/1194 | Loss: 281.758 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 450/1194 | Loss: 294.107 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 460/1194 | Loss: 279.847 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 470/1194 | Loss: 299.558 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 480/1194 | Loss: 298.739 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 490/1194 | Loss: 295.567 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 500/1194 | Loss: 292.410 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 510/1194 | Loss: 291.979 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 520/1194 | Loss: 307.646 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 530/1194 | Loss: 326.238 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 540/1194 | Loss: 288.153 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 550/1194 | Loss: 283.514 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 560/1194 | Loss: 295.117 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 570/1194 | Loss: 314.384 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 580/1194 | Loss: 276.535 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 590/1194 | Loss: 312.361 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 600/1194 | Loss: 296.676 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 610/1194 | Loss: 305.833 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 620/1194 | Loss: 312.048 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 630/1194 | Loss: 268.377 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 640/1194 | Loss: 287.306 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 650/1194 | Loss: 293.457 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 660/1194 | Loss: 289.582 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 670/1194 | Loss: 302.486 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 680/1194 | Loss: 280.540 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 690/1194 | Loss: 291.961 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 700/1194 | Loss: 295.600 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 710/1194 | Loss: 297.772 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 720/1194 | Loss: 281.778 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 730/1194 | Loss: 309.149 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 740/1194 | Loss: 295.803 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 750/1194 | Loss: 295.489 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 760/1194 | Loss: 309.951 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 770/1194 | Loss: 300.756 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 780/1194 | Loss: 301.386 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 790/1194 | Loss: 294.967 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 800/1194 | Loss: 307.181 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 810/1194 | Loss: 290.614 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 820/1194 | Loss: 299.447 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 830/1194 | Loss: 292.665 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 840/1194 | Loss: 290.503 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 850/1194 | Loss: 287.791 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 860/1194 | Loss: 317.355 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 870/1194 | Loss: 306.455 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 880/1194 | Loss: 304.725 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 890/1194 | Loss: 298.603 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 900/1194 | Loss: 306.673 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 910/1194 | Loss: 310.568 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 920/1194 | Loss: 291.151 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 930/1194 | Loss: 292.959 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 940/1194 | Loss: 289.049 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 950/1194 | Loss: 305.439 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 960/1194 | Loss: 295.205 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 970/1194 | Loss: 301.443 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 980/1194 | Loss: 293.896 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 990/1194 | Loss: 288.599 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 1000/1194 | Loss: 283.656 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 1010/1194 | Loss: 307.192 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1020/1194 | Loss: 302.168 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1030/1194 | Loss: 308.939 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1040/1194 | Loss: 296.819 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1050/1194 | Loss: 291.950 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1060/1194 | Loss: 303.806 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1070/1194 | Loss: 299.251 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1080/1194 | Loss: 306.199 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1090/1194 | Loss: 280.324 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 1100/1194 | Loss: 297.793 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1110/1194 | Loss: 296.917 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1120/1194 | Loss: 297.061 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1130/1194 | Loss: 303.152 | Accuracy: 0.000\n",
      "[Epoch: 172/200] - Step: 1140/1194 | Loss: 280.143 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 1150/1194 | Loss: 279.169 | Accuracy: 0.300\n",
      "[Epoch: 172/200] - Step: 1160/1194 | Loss: 297.878 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1170/1194 | Loss: 289.130 | Accuracy: 0.200\n",
      "[Epoch: 172/200] - Step: 1180/1194 | Loss: 293.415 | Accuracy: 0.100\n",
      "[Epoch: 172/200] - Step: 1190/1194 | Loss: 305.182 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 173/200] - Step: 10/1194 | Loss: 296.291 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 20/1194 | Loss: 294.885 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 30/1194 | Loss: 298.964 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 40/1194 | Loss: 301.300 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 50/1194 | Loss: 291.312 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 60/1194 | Loss: 298.483 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 70/1194 | Loss: 292.458 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 80/1194 | Loss: 299.101 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 90/1194 | Loss: 287.798 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 100/1194 | Loss: 294.288 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 110/1194 | Loss: 300.667 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 120/1194 | Loss: 316.578 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 130/1194 | Loss: 321.995 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 140/1194 | Loss: 277.968 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 150/1194 | Loss: 308.342 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 160/1194 | Loss: 285.978 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 170/1194 | Loss: 284.710 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 180/1194 | Loss: 310.797 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 190/1194 | Loss: 291.147 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 200/1194 | Loss: 280.380 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 210/1194 | Loss: 298.688 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 220/1194 | Loss: 288.036 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 230/1194 | Loss: 305.541 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 240/1194 | Loss: 296.242 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 250/1194 | Loss: 272.574 | Accuracy: 0.400\n",
      "[Epoch: 173/200] - Step: 260/1194 | Loss: 295.679 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 270/1194 | Loss: 299.709 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 280/1194 | Loss: 292.536 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 290/1194 | Loss: 309.093 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 300/1194 | Loss: 302.407 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 310/1194 | Loss: 304.118 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 320/1194 | Loss: 304.983 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 330/1194 | Loss: 325.918 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 340/1194 | Loss: 281.452 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 350/1194 | Loss: 297.303 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 360/1194 | Loss: 280.761 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 370/1194 | Loss: 294.948 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 380/1194 | Loss: 298.012 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 390/1194 | Loss: 285.257 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 400/1194 | Loss: 290.280 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 410/1194 | Loss: 310.947 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 420/1194 | Loss: 290.260 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 430/1194 | Loss: 296.951 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 440/1194 | Loss: 277.436 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 450/1194 | Loss: 290.556 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 460/1194 | Loss: 257.380 | Accuracy: 0.600\n",
      "[Epoch: 173/200] - Step: 470/1194 | Loss: 312.707 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 480/1194 | Loss: 296.921 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 490/1194 | Loss: 295.202 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 500/1194 | Loss: 263.860 | Accuracy: 0.400\n",
      "[Epoch: 173/200] - Step: 510/1194 | Loss: 319.029 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 520/1194 | Loss: 277.804 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 530/1194 | Loss: 300.021 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 540/1194 | Loss: 288.158 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 550/1194 | Loss: 306.305 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 560/1194 | Loss: 301.918 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 570/1194 | Loss: 304.004 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 580/1194 | Loss: 310.294 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 590/1194 | Loss: 304.706 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 600/1194 | Loss: 302.405 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 610/1194 | Loss: 272.145 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 620/1194 | Loss: 289.565 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 630/1194 | Loss: 314.429 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 640/1194 | Loss: 285.769 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 650/1194 | Loss: 292.347 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 660/1194 | Loss: 299.310 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 670/1194 | Loss: 295.212 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 680/1194 | Loss: 291.054 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 690/1194 | Loss: 301.654 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 700/1194 | Loss: 293.561 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 710/1194 | Loss: 297.625 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 720/1194 | Loss: 321.403 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 730/1194 | Loss: 284.764 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 740/1194 | Loss: 293.764 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 750/1194 | Loss: 303.098 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 760/1194 | Loss: 327.483 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 770/1194 | Loss: 297.583 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 780/1194 | Loss: 287.702 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 790/1194 | Loss: 292.863 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 800/1194 | Loss: 312.444 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 810/1194 | Loss: 312.371 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 820/1194 | Loss: 317.016 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 830/1194 | Loss: 292.384 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 840/1194 | Loss: 299.587 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 850/1194 | Loss: 302.782 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 860/1194 | Loss: 280.865 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 870/1194 | Loss: 305.159 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 880/1194 | Loss: 286.584 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 890/1194 | Loss: 290.798 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 900/1194 | Loss: 301.473 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 910/1194 | Loss: 305.430 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 920/1194 | Loss: 296.309 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 930/1194 | Loss: 285.437 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 940/1194 | Loss: 283.606 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 950/1194 | Loss: 311.857 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 960/1194 | Loss: 294.790 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 970/1194 | Loss: 303.833 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 980/1194 | Loss: 303.057 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 990/1194 | Loss: 310.957 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1000/1194 | Loss: 283.634 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 1010/1194 | Loss: 283.644 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 1020/1194 | Loss: 309.557 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1030/1194 | Loss: 296.977 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 1040/1194 | Loss: 290.264 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1050/1194 | Loss: 308.031 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 1060/1194 | Loss: 309.175 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 1070/1194 | Loss: 267.572 | Accuracy: 0.400\n",
      "[Epoch: 173/200] - Step: 1080/1194 | Loss: 327.265 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1090/1194 | Loss: 297.835 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1100/1194 | Loss: 291.942 | Accuracy: 0.200\n",
      "[Epoch: 173/200] - Step: 1110/1194 | Loss: 279.201 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 1120/1194 | Loss: 279.184 | Accuracy: 0.300\n",
      "[Epoch: 173/200] - Step: 1130/1194 | Loss: 305.425 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 1140/1194 | Loss: 300.061 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1150/1194 | Loss: 295.890 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1160/1194 | Loss: 302.255 | Accuracy: 0.000\n",
      "[Epoch: 173/200] - Step: 1170/1194 | Loss: 292.553 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1180/1194 | Loss: 298.271 | Accuracy: 0.100\n",
      "[Epoch: 173/200] - Step: 1190/1194 | Loss: 307.889 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 174/200] - Step: 10/1194 | Loss: 299.226 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 20/1194 | Loss: 276.527 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 30/1194 | Loss: 296.758 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 40/1194 | Loss: 294.756 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 50/1194 | Loss: 295.464 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 60/1194 | Loss: 291.189 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 70/1194 | Loss: 310.289 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 80/1194 | Loss: 285.284 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 90/1194 | Loss: 292.801 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 100/1194 | Loss: 340.477 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 110/1194 | Loss: 291.658 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 120/1194 | Loss: 307.824 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 130/1194 | Loss: 301.077 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 140/1194 | Loss: 292.795 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 150/1194 | Loss: 295.741 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 160/1194 | Loss: 330.833 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 170/1194 | Loss: 297.886 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 180/1194 | Loss: 302.595 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 190/1194 | Loss: 279.084 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 200/1194 | Loss: 307.525 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 210/1194 | Loss: 317.406 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 220/1194 | Loss: 307.664 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 230/1194 | Loss: 308.820 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 240/1194 | Loss: 294.676 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 250/1194 | Loss: 274.137 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 260/1194 | Loss: 286.141 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 270/1194 | Loss: 295.763 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 280/1194 | Loss: 295.346 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 290/1194 | Loss: 303.557 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 300/1194 | Loss: 262.505 | Accuracy: 0.600\n",
      "[Epoch: 174/200] - Step: 310/1194 | Loss: 313.246 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 320/1194 | Loss: 301.374 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 330/1194 | Loss: 292.120 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 340/1194 | Loss: 283.104 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 350/1194 | Loss: 277.959 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 360/1194 | Loss: 302.210 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 370/1194 | Loss: 316.202 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 380/1194 | Loss: 326.502 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 390/1194 | Loss: 307.605 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 400/1194 | Loss: 299.979 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 410/1194 | Loss: 304.738 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 420/1194 | Loss: 287.802 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 430/1194 | Loss: 292.341 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 440/1194 | Loss: 309.426 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 450/1194 | Loss: 281.061 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 460/1194 | Loss: 297.098 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 470/1194 | Loss: 308.984 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 480/1194 | Loss: 296.650 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 490/1194 | Loss: 305.319 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 500/1194 | Loss: 299.945 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 510/1194 | Loss: 298.001 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 520/1194 | Loss: 302.261 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 530/1194 | Loss: 293.776 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 540/1194 | Loss: 289.588 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 550/1194 | Loss: 326.424 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 560/1194 | Loss: 296.919 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 570/1194 | Loss: 300.004 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 580/1194 | Loss: 287.868 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 590/1194 | Loss: 305.953 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 600/1194 | Loss: 279.858 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 610/1194 | Loss: 296.245 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 620/1194 | Loss: 287.711 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 630/1194 | Loss: 281.299 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 640/1194 | Loss: 297.166 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 650/1194 | Loss: 312.792 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 660/1194 | Loss: 300.125 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 670/1194 | Loss: 298.979 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 680/1194 | Loss: 279.500 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 690/1194 | Loss: 271.573 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 700/1194 | Loss: 281.033 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 710/1194 | Loss: 291.924 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 720/1194 | Loss: 291.005 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 730/1194 | Loss: 291.874 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 740/1194 | Loss: 299.185 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 750/1194 | Loss: 291.744 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 760/1194 | Loss: 293.314 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 770/1194 | Loss: 287.666 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 780/1194 | Loss: 295.335 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 790/1194 | Loss: 298.990 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 800/1194 | Loss: 297.478 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 810/1194 | Loss: 302.406 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 820/1194 | Loss: 297.547 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 830/1194 | Loss: 305.358 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 840/1194 | Loss: 284.077 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 850/1194 | Loss: 284.286 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 860/1194 | Loss: 295.316 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 870/1194 | Loss: 307.998 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 880/1194 | Loss: 298.548 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 890/1194 | Loss: 300.407 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 900/1194 | Loss: 311.567 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 910/1194 | Loss: 295.888 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 920/1194 | Loss: 281.660 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 930/1194 | Loss: 295.570 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 940/1194 | Loss: 283.952 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 950/1194 | Loss: 298.919 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 960/1194 | Loss: 291.971 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 970/1194 | Loss: 283.014 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 980/1194 | Loss: 283.567 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 990/1194 | Loss: 307.266 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1000/1194 | Loss: 302.609 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1010/1194 | Loss: 310.849 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1020/1194 | Loss: 300.186 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1030/1194 | Loss: 300.497 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1040/1194 | Loss: 301.347 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1050/1194 | Loss: 285.238 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 1060/1194 | Loss: 303.429 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1070/1194 | Loss: 291.656 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1080/1194 | Loss: 295.838 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1090/1194 | Loss: 280.462 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 1100/1194 | Loss: 315.103 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1110/1194 | Loss: 290.641 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 1120/1194 | Loss: 293.843 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 1130/1194 | Loss: 292.076 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 1140/1194 | Loss: 298.398 | Accuracy: 0.100\n",
      "[Epoch: 174/200] - Step: 1150/1194 | Loss: 296.279 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1160/1194 | Loss: 276.980 | Accuracy: 0.300\n",
      "[Epoch: 174/200] - Step: 1170/1194 | Loss: 317.180 | Accuracy: 0.000\n",
      "[Epoch: 174/200] - Step: 1180/1194 | Loss: 287.698 | Accuracy: 0.200\n",
      "[Epoch: 174/200] - Step: 1190/1194 | Loss: 303.706 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 175/200] - Step: 10/1194 | Loss: 295.969 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 20/1194 | Loss: 307.756 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 30/1194 | Loss: 306.829 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 40/1194 | Loss: 272.676 | Accuracy: 0.400\n",
      "[Epoch: 175/200] - Step: 50/1194 | Loss: 304.862 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 60/1194 | Loss: 280.677 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 70/1194 | Loss: 284.611 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 80/1194 | Loss: 305.225 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 90/1194 | Loss: 289.572 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 100/1194 | Loss: 305.647 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 110/1194 | Loss: 283.259 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 120/1194 | Loss: 281.608 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 130/1194 | Loss: 297.369 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 140/1194 | Loss: 288.475 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 150/1194 | Loss: 316.975 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 160/1194 | Loss: 287.130 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 170/1194 | Loss: 297.271 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 180/1194 | Loss: 296.105 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 190/1194 | Loss: 288.127 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 200/1194 | Loss: 310.719 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 210/1194 | Loss: 274.011 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 220/1194 | Loss: 290.922 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 230/1194 | Loss: 278.179 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 240/1194 | Loss: 287.403 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 250/1194 | Loss: 312.029 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 260/1194 | Loss: 288.435 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 270/1194 | Loss: 294.444 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 280/1194 | Loss: 293.628 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 290/1194 | Loss: 285.297 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 300/1194 | Loss: 315.332 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 310/1194 | Loss: 327.631 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 320/1194 | Loss: 312.988 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 330/1194 | Loss: 297.128 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 340/1194 | Loss: 302.327 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 350/1194 | Loss: 292.253 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 360/1194 | Loss: 310.237 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 370/1194 | Loss: 280.103 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 380/1194 | Loss: 286.218 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 390/1194 | Loss: 305.967 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 400/1194 | Loss: 276.742 | Accuracy: 0.400\n",
      "[Epoch: 175/200] - Step: 410/1194 | Loss: 304.493 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 420/1194 | Loss: 303.640 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 430/1194 | Loss: 307.252 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 440/1194 | Loss: 296.465 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 450/1194 | Loss: 294.067 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 460/1194 | Loss: 305.405 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 470/1194 | Loss: 305.951 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 480/1194 | Loss: 287.395 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 490/1194 | Loss: 304.102 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 500/1194 | Loss: 297.019 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 510/1194 | Loss: 304.506 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 520/1194 | Loss: 304.604 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 530/1194 | Loss: 319.368 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 540/1194 | Loss: 278.894 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 550/1194 | Loss: 306.156 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 560/1194 | Loss: 292.107 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 570/1194 | Loss: 282.658 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 580/1194 | Loss: 302.871 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 590/1194 | Loss: 306.937 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 600/1194 | Loss: 291.969 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 610/1194 | Loss: 281.265 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 620/1194 | Loss: 301.674 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 630/1194 | Loss: 297.084 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 640/1194 | Loss: 293.235 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 650/1194 | Loss: 302.830 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 660/1194 | Loss: 315.492 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 670/1194 | Loss: 297.215 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 680/1194 | Loss: 273.080 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 690/1194 | Loss: 302.301 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 700/1194 | Loss: 317.114 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 710/1194 | Loss: 294.006 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 720/1194 | Loss: 289.902 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 730/1194 | Loss: 285.208 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 740/1194 | Loss: 292.823 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 750/1194 | Loss: 293.219 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 760/1194 | Loss: 299.391 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 770/1194 | Loss: 304.832 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 780/1194 | Loss: 292.364 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 790/1194 | Loss: 298.685 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 800/1194 | Loss: 308.225 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 810/1194 | Loss: 286.825 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 820/1194 | Loss: 296.067 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 830/1194 | Loss: 294.026 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 840/1194 | Loss: 284.697 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 850/1194 | Loss: 301.280 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 860/1194 | Loss: 294.146 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 870/1194 | Loss: 296.376 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 880/1194 | Loss: 274.072 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 890/1194 | Loss: 305.187 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 900/1194 | Loss: 323.662 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 910/1194 | Loss: 287.166 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 920/1194 | Loss: 275.799 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 930/1194 | Loss: 285.580 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 940/1194 | Loss: 306.826 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 950/1194 | Loss: 303.455 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 960/1194 | Loss: 339.648 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 970/1194 | Loss: 288.147 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 980/1194 | Loss: 295.867 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 990/1194 | Loss: 300.076 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1000/1194 | Loss: 308.699 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1010/1194 | Loss: 295.411 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1020/1194 | Loss: 301.153 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 1030/1194 | Loss: 278.482 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 1040/1194 | Loss: 289.986 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1050/1194 | Loss: 269.426 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 1060/1194 | Loss: 294.390 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1070/1194 | Loss: 310.308 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 1080/1194 | Loss: 313.608 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 1090/1194 | Loss: 291.904 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 1100/1194 | Loss: 311.030 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 1110/1194 | Loss: 291.516 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1120/1194 | Loss: 284.017 | Accuracy: 0.300\n",
      "[Epoch: 175/200] - Step: 1130/1194 | Loss: 309.055 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1140/1194 | Loss: 291.571 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 1150/1194 | Loss: 295.965 | Accuracy: 0.200\n",
      "[Epoch: 175/200] - Step: 1160/1194 | Loss: 307.286 | Accuracy: 0.000\n",
      "[Epoch: 175/200] - Step: 1170/1194 | Loss: 310.022 | Accuracy: 0.100\n",
      "[Epoch: 175/200] - Step: 1180/1194 | Loss: 275.366 | Accuracy: 0.400\n",
      "[Epoch: 175/200] - Step: 1190/1194 | Loss: 300.978 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 176/200] - Step: 10/1194 | Loss: 299.055 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 20/1194 | Loss: 296.670 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 30/1194 | Loss: 297.429 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 40/1194 | Loss: 293.647 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 50/1194 | Loss: 343.274 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 60/1194 | Loss: 289.252 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 70/1194 | Loss: 283.975 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 80/1194 | Loss: 318.247 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 90/1194 | Loss: 287.932 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 100/1194 | Loss: 334.100 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 110/1194 | Loss: 274.468 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 120/1194 | Loss: 284.907 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 130/1194 | Loss: 271.856 | Accuracy: 0.400\n",
      "[Epoch: 176/200] - Step: 140/1194 | Loss: 290.157 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 150/1194 | Loss: 293.352 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 160/1194 | Loss: 281.229 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 170/1194 | Loss: 295.016 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 180/1194 | Loss: 295.898 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 190/1194 | Loss: 302.316 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 200/1194 | Loss: 300.293 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 210/1194 | Loss: 296.761 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 220/1194 | Loss: 307.736 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 230/1194 | Loss: 307.360 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 240/1194 | Loss: 302.832 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 250/1194 | Loss: 304.310 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 260/1194 | Loss: 290.937 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 270/1194 | Loss: 312.684 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 280/1194 | Loss: 308.959 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 290/1194 | Loss: 289.984 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 300/1194 | Loss: 287.848 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 310/1194 | Loss: 301.304 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 320/1194 | Loss: 291.179 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 330/1194 | Loss: 294.626 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 340/1194 | Loss: 301.490 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 350/1194 | Loss: 300.339 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 360/1194 | Loss: 287.609 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 370/1194 | Loss: 321.709 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 380/1194 | Loss: 296.599 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 390/1194 | Loss: 290.005 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 400/1194 | Loss: 289.730 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 410/1194 | Loss: 287.923 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 420/1194 | Loss: 280.873 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 430/1194 | Loss: 313.435 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 440/1194 | Loss: 299.609 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 450/1194 | Loss: 296.010 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 460/1194 | Loss: 302.168 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 470/1194 | Loss: 268.759 | Accuracy: 0.400\n",
      "[Epoch: 176/200] - Step: 480/1194 | Loss: 306.985 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 490/1194 | Loss: 304.004 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 500/1194 | Loss: 310.703 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 510/1194 | Loss: 306.893 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 520/1194 | Loss: 297.617 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 530/1194 | Loss: 304.104 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 540/1194 | Loss: 291.354 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 550/1194 | Loss: 281.762 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 560/1194 | Loss: 300.041 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 570/1194 | Loss: 281.920 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 580/1194 | Loss: 284.846 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 590/1194 | Loss: 298.173 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 600/1194 | Loss: 329.029 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 610/1194 | Loss: 298.450 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 620/1194 | Loss: 272.787 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 630/1194 | Loss: 301.638 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 640/1194 | Loss: 287.635 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 650/1194 | Loss: 285.555 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 660/1194 | Loss: 290.887 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 670/1194 | Loss: 282.705 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 680/1194 | Loss: 307.463 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 690/1194 | Loss: 326.098 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 700/1194 | Loss: 282.862 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 710/1194 | Loss: 285.702 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 720/1194 | Loss: 303.992 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 730/1194 | Loss: 296.299 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 740/1194 | Loss: 294.789 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 750/1194 | Loss: 310.088 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 760/1194 | Loss: 301.804 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 770/1194 | Loss: 295.931 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 780/1194 | Loss: 293.157 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 790/1194 | Loss: 284.163 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 800/1194 | Loss: 284.262 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 810/1194 | Loss: 297.316 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 820/1194 | Loss: 306.268 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 830/1194 | Loss: 290.345 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 840/1194 | Loss: 326.491 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 850/1194 | Loss: 297.566 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 860/1194 | Loss: 285.819 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 870/1194 | Loss: 293.228 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 880/1194 | Loss: 300.714 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 890/1194 | Loss: 307.262 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 900/1194 | Loss: 292.073 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 910/1194 | Loss: 310.065 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 920/1194 | Loss: 279.813 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 930/1194 | Loss: 304.911 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 940/1194 | Loss: 324.703 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 950/1194 | Loss: 283.961 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 960/1194 | Loss: 297.687 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 970/1194 | Loss: 299.036 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 980/1194 | Loss: 286.041 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 990/1194 | Loss: 297.447 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1000/1194 | Loss: 307.083 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 1010/1194 | Loss: 288.193 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 1020/1194 | Loss: 295.497 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 1030/1194 | Loss: 290.558 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 1040/1194 | Loss: 285.306 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1050/1194 | Loss: 301.942 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1060/1194 | Loss: 305.115 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 1070/1194 | Loss: 290.036 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1080/1194 | Loss: 292.344 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1090/1194 | Loss: 301.274 | Accuracy: 0.000\n",
      "[Epoch: 176/200] - Step: 1100/1194 | Loss: 296.267 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1110/1194 | Loss: 285.106 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 1120/1194 | Loss: 290.329 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1130/1194 | Loss: 288.287 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1140/1194 | Loss: 302.121 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1150/1194 | Loss: 302.868 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1160/1194 | Loss: 300.137 | Accuracy: 0.100\n",
      "[Epoch: 176/200] - Step: 1170/1194 | Loss: 288.115 | Accuracy: 0.300\n",
      "[Epoch: 176/200] - Step: 1180/1194 | Loss: 287.822 | Accuracy: 0.200\n",
      "[Epoch: 176/200] - Step: 1190/1194 | Loss: 291.097 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 177/200] - Step: 10/1194 | Loss: 307.064 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 20/1194 | Loss: 291.490 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 30/1194 | Loss: 307.233 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 40/1194 | Loss: 309.056 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 50/1194 | Loss: 291.501 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 60/1194 | Loss: 293.411 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 70/1194 | Loss: 309.859 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 80/1194 | Loss: 297.352 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 90/1194 | Loss: 283.691 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 100/1194 | Loss: 276.934 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 110/1194 | Loss: 280.898 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 120/1194 | Loss: 294.009 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 130/1194 | Loss: 290.283 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 140/1194 | Loss: 296.344 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 150/1194 | Loss: 301.189 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 160/1194 | Loss: 298.635 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 170/1194 | Loss: 294.614 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 180/1194 | Loss: 297.915 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 190/1194 | Loss: 303.421 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 200/1194 | Loss: 280.034 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 210/1194 | Loss: 288.320 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 220/1194 | Loss: 303.764 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 230/1194 | Loss: 306.182 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 240/1194 | Loss: 293.139 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 250/1194 | Loss: 302.532 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 260/1194 | Loss: 295.954 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 270/1194 | Loss: 273.981 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 280/1194 | Loss: 338.018 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 290/1194 | Loss: 306.832 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 300/1194 | Loss: 272.384 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 310/1194 | Loss: 316.370 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 320/1194 | Loss: 278.547 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 330/1194 | Loss: 312.080 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 340/1194 | Loss: 299.279 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 350/1194 | Loss: 282.691 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 360/1194 | Loss: 305.079 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 370/1194 | Loss: 275.066 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 380/1194 | Loss: 299.749 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 390/1194 | Loss: 309.418 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 400/1194 | Loss: 286.969 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 410/1194 | Loss: 333.768 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 420/1194 | Loss: 302.496 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 430/1194 | Loss: 307.846 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 440/1194 | Loss: 298.540 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 450/1194 | Loss: 287.241 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 460/1194 | Loss: 285.143 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 470/1194 | Loss: 301.423 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 480/1194 | Loss: 295.375 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 490/1194 | Loss: 301.929 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 500/1194 | Loss: 325.385 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 510/1194 | Loss: 275.822 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 520/1194 | Loss: 304.077 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 530/1194 | Loss: 297.691 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 540/1194 | Loss: 295.436 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 550/1194 | Loss: 281.408 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 560/1194 | Loss: 304.013 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 570/1194 | Loss: 284.477 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 580/1194 | Loss: 299.025 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 590/1194 | Loss: 272.938 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 600/1194 | Loss: 298.150 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 610/1194 | Loss: 307.520 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 620/1194 | Loss: 304.586 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 630/1194 | Loss: 283.894 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 640/1194 | Loss: 287.336 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 650/1194 | Loss: 277.942 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 660/1194 | Loss: 274.568 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 670/1194 | Loss: 272.291 | Accuracy: 0.400\n",
      "[Epoch: 177/200] - Step: 680/1194 | Loss: 341.949 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 690/1194 | Loss: 300.174 | Accuracy: 0.400\n",
      "[Epoch: 177/200] - Step: 700/1194 | Loss: 298.278 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 710/1194 | Loss: 299.490 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 720/1194 | Loss: 281.459 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 730/1194 | Loss: 315.148 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 740/1194 | Loss: 297.564 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 750/1194 | Loss: 280.822 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 760/1194 | Loss: 277.384 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 770/1194 | Loss: 294.239 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 780/1194 | Loss: 309.881 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 790/1194 | Loss: 297.823 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 800/1194 | Loss: 305.706 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 810/1194 | Loss: 295.365 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 820/1194 | Loss: 296.547 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 830/1194 | Loss: 298.784 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 840/1194 | Loss: 329.411 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 850/1194 | Loss: 297.894 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 860/1194 | Loss: 299.995 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 870/1194 | Loss: 288.844 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 880/1194 | Loss: 283.345 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 890/1194 | Loss: 295.747 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 900/1194 | Loss: 314.575 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 910/1194 | Loss: 296.692 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 920/1194 | Loss: 306.615 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 930/1194 | Loss: 289.888 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 940/1194 | Loss: 290.543 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 950/1194 | Loss: 310.700 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 960/1194 | Loss: 295.896 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 970/1194 | Loss: 301.854 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 980/1194 | Loss: 286.882 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 990/1194 | Loss: 300.647 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 1000/1194 | Loss: 299.105 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1010/1194 | Loss: 285.383 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 1020/1194 | Loss: 295.891 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 1030/1194 | Loss: 285.731 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 1040/1194 | Loss: 302.850 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1050/1194 | Loss: 290.723 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1060/1194 | Loss: 300.340 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1070/1194 | Loss: 283.109 | Accuracy: 0.300\n",
      "[Epoch: 177/200] - Step: 1080/1194 | Loss: 288.981 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 1090/1194 | Loss: 297.534 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1100/1194 | Loss: 298.277 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1110/1194 | Loss: 305.299 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 1120/1194 | Loss: 304.920 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 1130/1194 | Loss: 308.278 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1140/1194 | Loss: 306.147 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 1150/1194 | Loss: 303.847 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1160/1194 | Loss: 282.382 | Accuracy: 0.200\n",
      "[Epoch: 177/200] - Step: 1170/1194 | Loss: 293.968 | Accuracy: 0.000\n",
      "[Epoch: 177/200] - Step: 1180/1194 | Loss: 301.077 | Accuracy: 0.100\n",
      "[Epoch: 177/200] - Step: 1190/1194 | Loss: 300.104 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 178/200] - Step: 10/1194 | Loss: 300.001 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 20/1194 | Loss: 304.962 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 30/1194 | Loss: 289.239 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 40/1194 | Loss: 289.203 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 50/1194 | Loss: 280.199 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 60/1194 | Loss: 307.055 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 70/1194 | Loss: 319.759 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 80/1194 | Loss: 292.495 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 90/1194 | Loss: 295.618 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 100/1194 | Loss: 316.917 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 110/1194 | Loss: 289.891 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 120/1194 | Loss: 306.231 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 130/1194 | Loss: 304.746 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 140/1194 | Loss: 293.420 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 150/1194 | Loss: 273.501 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 160/1194 | Loss: 303.593 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 170/1194 | Loss: 281.138 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 180/1194 | Loss: 294.207 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 190/1194 | Loss: 278.025 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 200/1194 | Loss: 290.525 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 210/1194 | Loss: 302.595 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 220/1194 | Loss: 277.872 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 230/1194 | Loss: 295.948 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 240/1194 | Loss: 291.938 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 250/1194 | Loss: 291.109 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 260/1194 | Loss: 296.613 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 270/1194 | Loss: 314.381 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 280/1194 | Loss: 298.588 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 290/1194 | Loss: 294.156 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 300/1194 | Loss: 305.682 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 310/1194 | Loss: 297.822 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 320/1194 | Loss: 306.044 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 330/1194 | Loss: 296.297 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 340/1194 | Loss: 300.450 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 350/1194 | Loss: 295.312 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 360/1194 | Loss: 290.733 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 370/1194 | Loss: 296.329 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 380/1194 | Loss: 313.279 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 390/1194 | Loss: 278.289 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 400/1194 | Loss: 288.333 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 410/1194 | Loss: 300.611 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 420/1194 | Loss: 287.633 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 430/1194 | Loss: 330.170 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 440/1194 | Loss: 291.503 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 450/1194 | Loss: 295.672 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 460/1194 | Loss: 296.061 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 470/1194 | Loss: 305.830 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 480/1194 | Loss: 286.409 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 490/1194 | Loss: 286.137 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 500/1194 | Loss: 304.254 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 510/1194 | Loss: 286.756 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 520/1194 | Loss: 298.310 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 530/1194 | Loss: 294.372 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 540/1194 | Loss: 300.876 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 550/1194 | Loss: 305.103 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 560/1194 | Loss: 292.624 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 570/1194 | Loss: 271.451 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 580/1194 | Loss: 281.120 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 590/1194 | Loss: 278.129 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 600/1194 | Loss: 297.904 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 610/1194 | Loss: 279.471 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 620/1194 | Loss: 295.346 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 630/1194 | Loss: 293.997 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 640/1194 | Loss: 315.845 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 650/1194 | Loss: 292.508 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 660/1194 | Loss: 310.749 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 670/1194 | Loss: 310.233 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 680/1194 | Loss: 286.058 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 690/1194 | Loss: 302.840 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 700/1194 | Loss: 295.558 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 710/1194 | Loss: 304.713 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 720/1194 | Loss: 288.024 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 730/1194 | Loss: 301.441 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 740/1194 | Loss: 297.747 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 750/1194 | Loss: 309.757 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 760/1194 | Loss: 285.718 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 770/1194 | Loss: 298.169 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 780/1194 | Loss: 303.244 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 790/1194 | Loss: 290.725 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 800/1194 | Loss: 287.332 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 810/1194 | Loss: 301.751 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 820/1194 | Loss: 302.826 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 830/1194 | Loss: 287.442 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 840/1194 | Loss: 292.010 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 850/1194 | Loss: 325.703 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 860/1194 | Loss: 289.883 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 870/1194 | Loss: 295.402 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 880/1194 | Loss: 273.652 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 890/1194 | Loss: 289.629 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 900/1194 | Loss: 282.502 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 910/1194 | Loss: 278.282 | Accuracy: 0.300\n",
      "[Epoch: 178/200] - Step: 920/1194 | Loss: 314.295 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 930/1194 | Loss: 309.973 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 940/1194 | Loss: 289.021 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 950/1194 | Loss: 280.171 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 960/1194 | Loss: 299.789 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 970/1194 | Loss: 292.666 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 980/1194 | Loss: 314.940 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 990/1194 | Loss: 322.825 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1000/1194 | Loss: 295.780 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1010/1194 | Loss: 317.534 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1020/1194 | Loss: 289.364 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1030/1194 | Loss: 327.280 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1040/1194 | Loss: 284.132 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 1050/1194 | Loss: 295.293 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1060/1194 | Loss: 307.610 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1070/1194 | Loss: 343.669 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1080/1194 | Loss: 309.216 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1090/1194 | Loss: 292.146 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 1100/1194 | Loss: 298.659 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1110/1194 | Loss: 296.596 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1120/1194 | Loss: 295.366 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1130/1194 | Loss: 307.460 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1140/1194 | Loss: 287.235 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 1150/1194 | Loss: 297.703 | Accuracy: 0.000\n",
      "[Epoch: 178/200] - Step: 1160/1194 | Loss: 289.262 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1170/1194 | Loss: 292.308 | Accuracy: 0.200\n",
      "[Epoch: 178/200] - Step: 1180/1194 | Loss: 288.590 | Accuracy: 0.100\n",
      "[Epoch: 178/200] - Step: 1190/1194 | Loss: 285.736 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 179/200] - Step: 10/1194 | Loss: 294.264 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 20/1194 | Loss: 312.464 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 30/1194 | Loss: 295.067 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 40/1194 | Loss: 299.663 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 50/1194 | Loss: 278.472 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 60/1194 | Loss: 322.053 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 70/1194 | Loss: 270.062 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 80/1194 | Loss: 327.118 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 90/1194 | Loss: 302.727 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 100/1194 | Loss: 286.328 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 110/1194 | Loss: 302.973 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 120/1194 | Loss: 293.082 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 130/1194 | Loss: 294.059 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 140/1194 | Loss: 292.289 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 150/1194 | Loss: 294.126 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 160/1194 | Loss: 282.968 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 170/1194 | Loss: 291.424 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 180/1194 | Loss: 302.554 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 190/1194 | Loss: 302.460 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 200/1194 | Loss: 304.319 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 210/1194 | Loss: 304.344 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 220/1194 | Loss: 288.906 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 230/1194 | Loss: 294.999 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 240/1194 | Loss: 284.623 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 250/1194 | Loss: 299.697 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 260/1194 | Loss: 296.943 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 270/1194 | Loss: 308.195 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 280/1194 | Loss: 254.490 | Accuracy: 0.500\n",
      "[Epoch: 179/200] - Step: 290/1194 | Loss: 295.424 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 300/1194 | Loss: 317.844 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 310/1194 | Loss: 291.460 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 320/1194 | Loss: 305.929 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 330/1194 | Loss: 345.662 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 340/1194 | Loss: 297.783 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 350/1194 | Loss: 297.649 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 360/1194 | Loss: 288.382 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 370/1194 | Loss: 294.949 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 380/1194 | Loss: 331.850 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 390/1194 | Loss: 298.911 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 400/1194 | Loss: 290.654 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 410/1194 | Loss: 297.257 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 420/1194 | Loss: 281.512 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 430/1194 | Loss: 298.135 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 440/1194 | Loss: 282.899 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 450/1194 | Loss: 282.005 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 460/1194 | Loss: 292.581 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 470/1194 | Loss: 299.132 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 480/1194 | Loss: 290.868 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 490/1194 | Loss: 307.535 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 500/1194 | Loss: 303.367 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 510/1194 | Loss: 300.197 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 520/1194 | Loss: 304.331 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 530/1194 | Loss: 294.806 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 540/1194 | Loss: 282.951 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 550/1194 | Loss: 285.854 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 560/1194 | Loss: 300.032 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 570/1194 | Loss: 308.162 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 580/1194 | Loss: 289.123 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 590/1194 | Loss: 290.301 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 600/1194 | Loss: 295.667 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 610/1194 | Loss: 287.710 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 620/1194 | Loss: 293.222 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 630/1194 | Loss: 315.289 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 640/1194 | Loss: 298.991 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 650/1194 | Loss: 294.810 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 660/1194 | Loss: 282.944 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 670/1194 | Loss: 290.740 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 680/1194 | Loss: 305.697 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 690/1194 | Loss: 305.377 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 700/1194 | Loss: 302.497 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 710/1194 | Loss: 295.340 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 720/1194 | Loss: 306.802 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 730/1194 | Loss: 288.419 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 740/1194 | Loss: 287.120 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 750/1194 | Loss: 298.580 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 760/1194 | Loss: 302.984 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 770/1194 | Loss: 286.604 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 780/1194 | Loss: 316.321 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 790/1194 | Loss: 309.436 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 800/1194 | Loss: 306.273 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 810/1194 | Loss: 279.037 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 820/1194 | Loss: 297.197 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 830/1194 | Loss: 295.657 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 840/1194 | Loss: 292.737 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 850/1194 | Loss: 278.863 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 860/1194 | Loss: 309.876 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 870/1194 | Loss: 286.055 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 880/1194 | Loss: 300.899 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 890/1194 | Loss: 295.042 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 900/1194 | Loss: 308.402 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 910/1194 | Loss: 282.125 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 920/1194 | Loss: 285.694 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 930/1194 | Loss: 299.858 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 940/1194 | Loss: 306.062 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 950/1194 | Loss: 295.027 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 960/1194 | Loss: 299.114 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 970/1194 | Loss: 288.061 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 980/1194 | Loss: 292.479 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 990/1194 | Loss: 289.572 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1000/1194 | Loss: 292.020 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1010/1194 | Loss: 304.810 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 1020/1194 | Loss: 316.787 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 1030/1194 | Loss: 297.899 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1040/1194 | Loss: 306.003 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1050/1194 | Loss: 298.011 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1060/1194 | Loss: 283.582 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 1070/1194 | Loss: 297.017 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1080/1194 | Loss: 296.701 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1090/1194 | Loss: 315.959 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 1100/1194 | Loss: 287.482 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1110/1194 | Loss: 285.427 | Accuracy: 0.300\n",
      "[Epoch: 179/200] - Step: 1120/1194 | Loss: 289.277 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1130/1194 | Loss: 283.314 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1140/1194 | Loss: 299.314 | Accuracy: 0.000\n",
      "[Epoch: 179/200] - Step: 1150/1194 | Loss: 290.159 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 1160/1194 | Loss: 320.924 | Accuracy: 0.100\n",
      "[Epoch: 179/200] - Step: 1170/1194 | Loss: 284.522 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 1180/1194 | Loss: 282.936 | Accuracy: 0.200\n",
      "[Epoch: 179/200] - Step: 1190/1194 | Loss: 305.097 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 180/200] - Step: 10/1194 | Loss: 299.046 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 20/1194 | Loss: 280.669 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 30/1194 | Loss: 288.684 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 40/1194 | Loss: 311.531 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 50/1194 | Loss: 298.801 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 60/1194 | Loss: 309.854 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 70/1194 | Loss: 295.229 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 80/1194 | Loss: 288.969 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 90/1194 | Loss: 279.349 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 100/1194 | Loss: 303.356 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 110/1194 | Loss: 307.160 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 120/1194 | Loss: 332.820 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 130/1194 | Loss: 320.210 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 140/1194 | Loss: 299.587 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 150/1194 | Loss: 279.723 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 160/1194 | Loss: 308.442 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 170/1194 | Loss: 281.435 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 180/1194 | Loss: 306.422 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 190/1194 | Loss: 291.795 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 200/1194 | Loss: 308.087 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 210/1194 | Loss: 307.175 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 220/1194 | Loss: 288.121 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 230/1194 | Loss: 287.893 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 240/1194 | Loss: 292.090 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 250/1194 | Loss: 296.340 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 260/1194 | Loss: 300.471 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 270/1194 | Loss: 305.542 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 280/1194 | Loss: 303.225 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 290/1194 | Loss: 304.403 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 300/1194 | Loss: 274.579 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 310/1194 | Loss: 298.045 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 320/1194 | Loss: 310.084 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 330/1194 | Loss: 290.467 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 340/1194 | Loss: 303.378 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 350/1194 | Loss: 292.073 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 360/1194 | Loss: 302.976 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 370/1194 | Loss: 278.392 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 380/1194 | Loss: 290.841 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 390/1194 | Loss: 299.143 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 400/1194 | Loss: 301.142 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 410/1194 | Loss: 303.041 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 420/1194 | Loss: 296.564 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 430/1194 | Loss: 290.684 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 440/1194 | Loss: 288.772 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 450/1194 | Loss: 301.835 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 460/1194 | Loss: 284.195 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 470/1194 | Loss: 290.508 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 480/1194 | Loss: 311.487 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 490/1194 | Loss: 327.497 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 500/1194 | Loss: 296.255 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 510/1194 | Loss: 282.542 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 520/1194 | Loss: 298.142 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 530/1194 | Loss: 287.379 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 540/1194 | Loss: 301.998 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 550/1194 | Loss: 283.295 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 560/1194 | Loss: 295.188 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 570/1194 | Loss: 287.594 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 580/1194 | Loss: 310.475 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 590/1194 | Loss: 304.616 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 600/1194 | Loss: 298.150 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 610/1194 | Loss: 292.211 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 620/1194 | Loss: 288.926 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 630/1194 | Loss: 315.448 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 640/1194 | Loss: 314.073 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 650/1194 | Loss: 284.946 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 660/1194 | Loss: 294.724 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 670/1194 | Loss: 298.836 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 680/1194 | Loss: 299.736 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 690/1194 | Loss: 319.515 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 700/1194 | Loss: 292.745 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 710/1194 | Loss: 284.282 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 720/1194 | Loss: 300.021 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 730/1194 | Loss: 308.280 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 740/1194 | Loss: 271.137 | Accuracy: 0.400\n",
      "[Epoch: 180/200] - Step: 750/1194 | Loss: 299.005 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 760/1194 | Loss: 302.096 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 770/1194 | Loss: 276.982 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 780/1194 | Loss: 281.203 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 790/1194 | Loss: 290.605 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 800/1194 | Loss: 291.254 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 810/1194 | Loss: 308.423 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 820/1194 | Loss: 280.585 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 830/1194 | Loss: 305.220 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 840/1194 | Loss: 304.793 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 850/1194 | Loss: 294.249 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 860/1194 | Loss: 298.286 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 870/1194 | Loss: 291.906 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 880/1194 | Loss: 287.105 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 890/1194 | Loss: 294.445 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 900/1194 | Loss: 335.459 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 910/1194 | Loss: 283.182 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 920/1194 | Loss: 312.818 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 930/1194 | Loss: 304.238 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 940/1194 | Loss: 296.655 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 950/1194 | Loss: 299.966 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 960/1194 | Loss: 293.821 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 970/1194 | Loss: 331.490 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 980/1194 | Loss: 291.060 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 990/1194 | Loss: 293.478 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1000/1194 | Loss: 337.514 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 1010/1194 | Loss: 276.174 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 1020/1194 | Loss: 289.535 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1030/1194 | Loss: 283.086 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 1040/1194 | Loss: 291.529 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 1050/1194 | Loss: 307.725 | Accuracy: 0.000\n",
      "[Epoch: 180/200] - Step: 1060/1194 | Loss: 289.608 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1070/1194 | Loss: 281.128 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 1080/1194 | Loss: 301.128 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1090/1194 | Loss: 297.290 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 1100/1194 | Loss: 301.095 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1110/1194 | Loss: 300.341 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1120/1194 | Loss: 278.792 | Accuracy: 0.300\n",
      "[Epoch: 180/200] - Step: 1130/1194 | Loss: 281.888 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1140/1194 | Loss: 284.159 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 1150/1194 | Loss: 287.348 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1160/1194 | Loss: 304.897 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1170/1194 | Loss: 284.856 | Accuracy: 0.200\n",
      "[Epoch: 180/200] - Step: 1180/1194 | Loss: 294.246 | Accuracy: 0.100\n",
      "[Epoch: 180/200] - Step: 1190/1194 | Loss: 294.594 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 181/200] - Step: 10/1194 | Loss: 275.432 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 20/1194 | Loss: 296.913 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 30/1194 | Loss: 294.040 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 40/1194 | Loss: 282.296 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 50/1194 | Loss: 306.451 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 60/1194 | Loss: 288.062 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 70/1194 | Loss: 275.889 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 80/1194 | Loss: 287.767 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 90/1194 | Loss: 307.207 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 100/1194 | Loss: 307.059 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 110/1194 | Loss: 303.476 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 120/1194 | Loss: 286.291 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 130/1194 | Loss: 293.821 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 140/1194 | Loss: 295.941 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 150/1194 | Loss: 282.655 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 160/1194 | Loss: 306.155 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 170/1194 | Loss: 278.073 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 180/1194 | Loss: 293.453 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 190/1194 | Loss: 304.985 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 200/1194 | Loss: 293.920 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 210/1194 | Loss: 298.667 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 220/1194 | Loss: 287.421 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 230/1194 | Loss: 304.580 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 240/1194 | Loss: 285.444 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 250/1194 | Loss: 309.226 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 260/1194 | Loss: 270.339 | Accuracy: 0.400\n",
      "[Epoch: 181/200] - Step: 270/1194 | Loss: 276.315 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 280/1194 | Loss: 309.570 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 290/1194 | Loss: 282.441 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 300/1194 | Loss: 292.625 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 310/1194 | Loss: 286.148 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 320/1194 | Loss: 309.871 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 330/1194 | Loss: 292.526 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 340/1194 | Loss: 303.123 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 350/1194 | Loss: 305.694 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 360/1194 | Loss: 303.727 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 370/1194 | Loss: 266.947 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 380/1194 | Loss: 304.918 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 390/1194 | Loss: 306.099 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 400/1194 | Loss: 298.113 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 410/1194 | Loss: 308.859 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 420/1194 | Loss: 283.612 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 430/1194 | Loss: 297.650 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 440/1194 | Loss: 290.260 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 450/1194 | Loss: 306.061 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 460/1194 | Loss: 285.840 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 470/1194 | Loss: 291.659 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 480/1194 | Loss: 284.431 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 490/1194 | Loss: 324.129 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 500/1194 | Loss: 295.405 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 510/1194 | Loss: 301.511 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 520/1194 | Loss: 294.120 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 530/1194 | Loss: 274.563 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 540/1194 | Loss: 290.993 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 550/1194 | Loss: 287.552 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 560/1194 | Loss: 293.190 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 570/1194 | Loss: 325.100 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 580/1194 | Loss: 300.162 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 590/1194 | Loss: 305.509 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 600/1194 | Loss: 295.280 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 610/1194 | Loss: 291.786 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 620/1194 | Loss: 280.687 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 630/1194 | Loss: 304.652 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 640/1194 | Loss: 304.672 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 650/1194 | Loss: 286.637 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 660/1194 | Loss: 312.816 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 670/1194 | Loss: 278.762 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 680/1194 | Loss: 305.005 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 690/1194 | Loss: 297.928 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 700/1194 | Loss: 309.137 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 710/1194 | Loss: 289.107 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 720/1194 | Loss: 296.146 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 730/1194 | Loss: 303.381 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 740/1194 | Loss: 298.388 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 750/1194 | Loss: 288.730 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 760/1194 | Loss: 279.513 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 770/1194 | Loss: 287.573 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 780/1194 | Loss: 310.952 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 790/1194 | Loss: 306.764 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 800/1194 | Loss: 314.249 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 810/1194 | Loss: 299.882 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 820/1194 | Loss: 282.032 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 830/1194 | Loss: 283.203 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 840/1194 | Loss: 289.618 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 850/1194 | Loss: 293.925 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 860/1194 | Loss: 295.196 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 870/1194 | Loss: 278.031 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 880/1194 | Loss: 338.837 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 890/1194 | Loss: 292.714 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 900/1194 | Loss: 296.086 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 910/1194 | Loss: 296.250 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 920/1194 | Loss: 337.969 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 930/1194 | Loss: 323.085 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 940/1194 | Loss: 285.069 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 950/1194 | Loss: 297.489 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 960/1194 | Loss: 321.710 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 970/1194 | Loss: 325.773 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 980/1194 | Loss: 314.876 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 990/1194 | Loss: 297.033 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 1000/1194 | Loss: 296.346 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1010/1194 | Loss: 272.219 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 1020/1194 | Loss: 303.856 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1030/1194 | Loss: 289.651 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1040/1194 | Loss: 297.401 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1050/1194 | Loss: 300.396 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1060/1194 | Loss: 298.537 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1070/1194 | Loss: 279.258 | Accuracy: 0.300\n",
      "[Epoch: 181/200] - Step: 1080/1194 | Loss: 301.504 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1090/1194 | Loss: 296.207 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1100/1194 | Loss: 292.506 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 1110/1194 | Loss: 297.040 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1120/1194 | Loss: 295.343 | Accuracy: 0.200\n",
      "[Epoch: 181/200] - Step: 1130/1194 | Loss: 308.882 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 1140/1194 | Loss: 296.437 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1150/1194 | Loss: 306.668 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 1160/1194 | Loss: 287.396 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1170/1194 | Loss: 312.521 | Accuracy: 0.000\n",
      "[Epoch: 181/200] - Step: 1180/1194 | Loss: 289.299 | Accuracy: 0.100\n",
      "[Epoch: 181/200] - Step: 1190/1194 | Loss: 318.799 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 182/200] - Step: 10/1194 | Loss: 301.945 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 20/1194 | Loss: 304.882 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 30/1194 | Loss: 303.899 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 40/1194 | Loss: 295.694 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 50/1194 | Loss: 287.614 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 60/1194 | Loss: 297.223 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 70/1194 | Loss: 283.610 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 80/1194 | Loss: 311.289 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 90/1194 | Loss: 297.013 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 100/1194 | Loss: 299.321 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 110/1194 | Loss: 299.435 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 120/1194 | Loss: 325.663 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 130/1194 | Loss: 309.037 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 140/1194 | Loss: 307.099 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 150/1194 | Loss: 297.587 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 160/1194 | Loss: 306.150 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 170/1194 | Loss: 304.678 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 180/1194 | Loss: 313.583 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 190/1194 | Loss: 295.587 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 200/1194 | Loss: 272.603 | Accuracy: 0.500\n",
      "[Epoch: 182/200] - Step: 210/1194 | Loss: 291.934 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 220/1194 | Loss: 284.635 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 230/1194 | Loss: 293.546 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 240/1194 | Loss: 289.500 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 250/1194 | Loss: 292.761 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 260/1194 | Loss: 297.464 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 270/1194 | Loss: 280.382 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 280/1194 | Loss: 292.557 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 290/1194 | Loss: 287.029 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 300/1194 | Loss: 293.663 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 310/1194 | Loss: 328.476 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 320/1194 | Loss: 289.492 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 330/1194 | Loss: 291.420 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 340/1194 | Loss: 278.475 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 350/1194 | Loss: 292.731 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 360/1194 | Loss: 291.232 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 370/1194 | Loss: 304.136 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 380/1194 | Loss: 316.382 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 390/1194 | Loss: 280.566 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 400/1194 | Loss: 278.192 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 410/1194 | Loss: 293.616 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 420/1194 | Loss: 293.820 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 430/1194 | Loss: 298.239 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 440/1194 | Loss: 296.805 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 450/1194 | Loss: 303.583 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 460/1194 | Loss: 302.946 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 470/1194 | Loss: 293.936 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 480/1194 | Loss: 291.469 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 490/1194 | Loss: 307.123 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 500/1194 | Loss: 290.750 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 510/1194 | Loss: 293.654 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 520/1194 | Loss: 288.909 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 530/1194 | Loss: 308.327 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 540/1194 | Loss: 312.589 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 550/1194 | Loss: 301.051 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 560/1194 | Loss: 308.915 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 570/1194 | Loss: 267.050 | Accuracy: 0.400\n",
      "[Epoch: 182/200] - Step: 580/1194 | Loss: 301.379 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 590/1194 | Loss: 295.104 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 600/1194 | Loss: 283.331 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 610/1194 | Loss: 284.769 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 620/1194 | Loss: 287.688 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 630/1194 | Loss: 293.235 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 640/1194 | Loss: 278.191 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 650/1194 | Loss: 292.229 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 660/1194 | Loss: 294.232 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 670/1194 | Loss: 305.271 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 680/1194 | Loss: 311.411 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 690/1194 | Loss: 308.438 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 700/1194 | Loss: 282.293 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 710/1194 | Loss: 307.596 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 720/1194 | Loss: 299.105 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 730/1194 | Loss: 299.400 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 740/1194 | Loss: 309.328 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 750/1194 | Loss: 291.989 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 760/1194 | Loss: 306.586 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 770/1194 | Loss: 297.170 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 780/1194 | Loss: 276.742 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 790/1194 | Loss: 301.972 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 800/1194 | Loss: 285.731 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 810/1194 | Loss: 297.871 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 820/1194 | Loss: 302.227 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 830/1194 | Loss: 305.862 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 840/1194 | Loss: 299.141 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 850/1194 | Loss: 304.741 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 860/1194 | Loss: 297.274 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 870/1194 | Loss: 310.301 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 880/1194 | Loss: 309.408 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 890/1194 | Loss: 299.366 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 900/1194 | Loss: 307.194 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 910/1194 | Loss: 339.402 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 920/1194 | Loss: 283.272 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 930/1194 | Loss: 297.085 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 940/1194 | Loss: 288.439 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 950/1194 | Loss: 283.381 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 960/1194 | Loss: 295.326 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 970/1194 | Loss: 302.131 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 980/1194 | Loss: 297.830 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 990/1194 | Loss: 300.410 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 1000/1194 | Loss: 310.800 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 1010/1194 | Loss: 284.315 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 1020/1194 | Loss: 293.129 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1030/1194 | Loss: 301.864 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1040/1194 | Loss: 276.997 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 1050/1194 | Loss: 303.417 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 1060/1194 | Loss: 301.876 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 1070/1194 | Loss: 283.356 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 1080/1194 | Loss: 302.567 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1090/1194 | Loss: 285.805 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 1100/1194 | Loss: 295.712 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1110/1194 | Loss: 273.307 | Accuracy: 0.400\n",
      "[Epoch: 182/200] - Step: 1120/1194 | Loss: 297.217 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 1130/1194 | Loss: 274.368 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 1140/1194 | Loss: 278.627 | Accuracy: 0.300\n",
      "[Epoch: 182/200] - Step: 1150/1194 | Loss: 292.114 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1160/1194 | Loss: 282.349 | Accuracy: 0.200\n",
      "[Epoch: 182/200] - Step: 1170/1194 | Loss: 336.632 | Accuracy: 0.100\n",
      "[Epoch: 182/200] - Step: 1180/1194 | Loss: 303.075 | Accuracy: 0.000\n",
      "[Epoch: 182/200] - Step: 1190/1194 | Loss: 311.661 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 183/200] - Step: 10/1194 | Loss: 278.050 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 20/1194 | Loss: 303.667 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 30/1194 | Loss: 279.641 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 40/1194 | Loss: 308.810 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 50/1194 | Loss: 274.935 | Accuracy: 0.400\n",
      "[Epoch: 183/200] - Step: 60/1194 | Loss: 303.751 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 70/1194 | Loss: 324.493 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 80/1194 | Loss: 297.724 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 90/1194 | Loss: 293.945 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 100/1194 | Loss: 294.638 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 110/1194 | Loss: 284.895 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 120/1194 | Loss: 324.894 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 130/1194 | Loss: 273.356 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 140/1194 | Loss: 313.920 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 150/1194 | Loss: 289.367 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 160/1194 | Loss: 290.128 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 170/1194 | Loss: 296.048 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 180/1194 | Loss: 297.944 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 190/1194 | Loss: 295.555 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 200/1194 | Loss: 280.147 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 210/1194 | Loss: 293.475 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 220/1194 | Loss: 301.428 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 230/1194 | Loss: 304.381 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 240/1194 | Loss: 291.047 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 250/1194 | Loss: 296.357 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 260/1194 | Loss: 292.145 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 270/1194 | Loss: 293.323 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 280/1194 | Loss: 286.539 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 290/1194 | Loss: 311.278 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 300/1194 | Loss: 284.554 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 310/1194 | Loss: 284.532 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 320/1194 | Loss: 312.414 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 330/1194 | Loss: 312.692 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 340/1194 | Loss: 291.148 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 350/1194 | Loss: 301.590 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 360/1194 | Loss: 294.175 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 370/1194 | Loss: 294.779 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 380/1194 | Loss: 286.137 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 390/1194 | Loss: 289.842 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 400/1194 | Loss: 277.737 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 410/1194 | Loss: 312.210 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 420/1194 | Loss: 286.958 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 430/1194 | Loss: 282.828 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 440/1194 | Loss: 309.986 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 450/1194 | Loss: 307.598 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 460/1194 | Loss: 307.171 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 470/1194 | Loss: 298.501 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 480/1194 | Loss: 285.207 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 490/1194 | Loss: 288.856 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 500/1194 | Loss: 293.416 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 510/1194 | Loss: 307.792 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 520/1194 | Loss: 321.927 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 530/1194 | Loss: 297.485 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 540/1194 | Loss: 296.176 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 550/1194 | Loss: 299.302 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 560/1194 | Loss: 295.037 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 570/1194 | Loss: 271.681 | Accuracy: 0.400\n",
      "[Epoch: 183/200] - Step: 580/1194 | Loss: 272.967 | Accuracy: 0.400\n",
      "[Epoch: 183/200] - Step: 590/1194 | Loss: 302.853 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 600/1194 | Loss: 302.907 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 610/1194 | Loss: 297.505 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 620/1194 | Loss: 305.281 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 630/1194 | Loss: 290.732 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 640/1194 | Loss: 295.191 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 650/1194 | Loss: 292.424 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 660/1194 | Loss: 301.170 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 670/1194 | Loss: 333.380 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 680/1194 | Loss: 289.680 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 690/1194 | Loss: 283.555 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 700/1194 | Loss: 322.876 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 710/1194 | Loss: 300.427 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 720/1194 | Loss: 282.719 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 730/1194 | Loss: 303.253 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 740/1194 | Loss: 310.067 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 750/1194 | Loss: 304.081 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 760/1194 | Loss: 306.416 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 770/1194 | Loss: 301.970 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 780/1194 | Loss: 281.374 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 790/1194 | Loss: 282.287 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 800/1194 | Loss: 288.425 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 810/1194 | Loss: 289.272 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 820/1194 | Loss: 306.856 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 830/1194 | Loss: 300.691 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 840/1194 | Loss: 329.324 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 850/1194 | Loss: 296.781 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 860/1194 | Loss: 310.808 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 870/1194 | Loss: 293.664 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 880/1194 | Loss: 292.638 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 890/1194 | Loss: 289.580 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 900/1194 | Loss: 283.065 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 910/1194 | Loss: 290.703 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 920/1194 | Loss: 311.806 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 930/1194 | Loss: 298.269 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 940/1194 | Loss: 307.528 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 950/1194 | Loss: 302.578 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 960/1194 | Loss: 302.901 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 970/1194 | Loss: 295.240 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 980/1194 | Loss: 287.261 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 990/1194 | Loss: 293.547 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 1000/1194 | Loss: 283.671 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 1010/1194 | Loss: 302.146 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1020/1194 | Loss: 287.503 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 1030/1194 | Loss: 285.087 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 1040/1194 | Loss: 284.215 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1050/1194 | Loss: 301.754 | Accuracy: 0.200\n",
      "[Epoch: 183/200] - Step: 1060/1194 | Loss: 296.405 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1070/1194 | Loss: 299.569 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1080/1194 | Loss: 305.373 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1090/1194 | Loss: 311.358 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1100/1194 | Loss: 295.256 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1110/1194 | Loss: 302.741 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1120/1194 | Loss: 283.186 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1130/1194 | Loss: 296.745 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1140/1194 | Loss: 276.928 | Accuracy: 0.300\n",
      "[Epoch: 183/200] - Step: 1150/1194 | Loss: 292.340 | Accuracy: 0.100\n",
      "[Epoch: 183/200] - Step: 1160/1194 | Loss: 309.901 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1170/1194 | Loss: 306.272 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1180/1194 | Loss: 310.808 | Accuracy: 0.000\n",
      "[Epoch: 183/200] - Step: 1190/1194 | Loss: 291.841 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 184/200] - Step: 10/1194 | Loss: 308.170 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 20/1194 | Loss: 287.837 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 30/1194 | Loss: 298.908 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 40/1194 | Loss: 285.842 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 50/1194 | Loss: 312.759 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 60/1194 | Loss: 310.324 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 70/1194 | Loss: 331.140 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 80/1194 | Loss: 285.652 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 90/1194 | Loss: 290.152 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 100/1194 | Loss: 284.641 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 110/1194 | Loss: 290.915 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 120/1194 | Loss: 302.757 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 130/1194 | Loss: 302.247 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 140/1194 | Loss: 295.847 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 150/1194 | Loss: 295.545 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 160/1194 | Loss: 283.345 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 170/1194 | Loss: 308.519 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 180/1194 | Loss: 329.826 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 190/1194 | Loss: 283.146 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 200/1194 | Loss: 296.461 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 210/1194 | Loss: 312.526 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 220/1194 | Loss: 300.303 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 230/1194 | Loss: 292.800 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 240/1194 | Loss: 286.942 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 250/1194 | Loss: 296.974 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 260/1194 | Loss: 300.302 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 270/1194 | Loss: 298.569 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 280/1194 | Loss: 305.797 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 290/1194 | Loss: 265.466 | Accuracy: 0.400\n",
      "[Epoch: 184/200] - Step: 300/1194 | Loss: 291.364 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 310/1194 | Loss: 285.520 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 320/1194 | Loss: 279.716 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 330/1194 | Loss: 310.610 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 340/1194 | Loss: 292.901 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 350/1194 | Loss: 296.988 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 360/1194 | Loss: 292.958 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 370/1194 | Loss: 297.331 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 380/1194 | Loss: 303.657 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 390/1194 | Loss: 298.685 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 400/1194 | Loss: 284.179 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 410/1194 | Loss: 295.497 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 420/1194 | Loss: 300.337 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 430/1194 | Loss: 325.701 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 440/1194 | Loss: 301.297 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 450/1194 | Loss: 288.216 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 460/1194 | Loss: 311.172 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 470/1194 | Loss: 294.512 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 480/1194 | Loss: 302.401 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 490/1194 | Loss: 293.511 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 500/1194 | Loss: 309.587 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 510/1194 | Loss: 289.084 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 520/1194 | Loss: 297.182 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 530/1194 | Loss: 303.440 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 540/1194 | Loss: 311.662 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 550/1194 | Loss: 291.507 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 560/1194 | Loss: 285.016 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 570/1194 | Loss: 285.052 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 580/1194 | Loss: 288.578 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 590/1194 | Loss: 287.449 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 600/1194 | Loss: 304.336 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 610/1194 | Loss: 293.118 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 620/1194 | Loss: 299.897 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 630/1194 | Loss: 298.781 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 640/1194 | Loss: 298.762 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 650/1194 | Loss: 280.588 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 660/1194 | Loss: 265.284 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 670/1194 | Loss: 295.709 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 680/1194 | Loss: 298.701 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 690/1194 | Loss: 275.735 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 700/1194 | Loss: 309.808 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 710/1194 | Loss: 300.666 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 720/1194 | Loss: 297.562 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 730/1194 | Loss: 269.249 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 740/1194 | Loss: 274.144 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 750/1194 | Loss: 303.398 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 760/1194 | Loss: 309.499 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 770/1194 | Loss: 304.449 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 780/1194 | Loss: 295.834 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 790/1194 | Loss: 301.983 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 800/1194 | Loss: 309.457 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 810/1194 | Loss: 299.207 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 820/1194 | Loss: 283.564 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 830/1194 | Loss: 305.205 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 840/1194 | Loss: 290.152 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 850/1194 | Loss: 279.057 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 860/1194 | Loss: 311.813 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 870/1194 | Loss: 295.124 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 880/1194 | Loss: 328.403 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 890/1194 | Loss: 285.078 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 900/1194 | Loss: 306.319 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 910/1194 | Loss: 290.726 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 920/1194 | Loss: 296.226 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 930/1194 | Loss: 300.384 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 940/1194 | Loss: 297.545 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 950/1194 | Loss: 273.495 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 960/1194 | Loss: 303.236 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 970/1194 | Loss: 307.937 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 980/1194 | Loss: 276.329 | Accuracy: 0.400\n",
      "[Epoch: 184/200] - Step: 990/1194 | Loss: 307.809 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1000/1194 | Loss: 314.256 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1010/1194 | Loss: 297.527 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1020/1194 | Loss: 309.783 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1030/1194 | Loss: 294.293 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 1040/1194 | Loss: 282.835 | Accuracy: 0.200\n",
      "[Epoch: 184/200] - Step: 1050/1194 | Loss: 306.076 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1060/1194 | Loss: 295.936 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1070/1194 | Loss: 267.584 | Accuracy: 0.500\n",
      "[Epoch: 184/200] - Step: 1080/1194 | Loss: 296.689 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1090/1194 | Loss: 302.755 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1100/1194 | Loss: 290.015 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1110/1194 | Loss: 304.055 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1120/1194 | Loss: 304.193 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1130/1194 | Loss: 298.753 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1140/1194 | Loss: 302.885 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1150/1194 | Loss: 299.302 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1160/1194 | Loss: 311.432 | Accuracy: 0.300\n",
      "[Epoch: 184/200] - Step: 1170/1194 | Loss: 300.363 | Accuracy: 0.100\n",
      "[Epoch: 184/200] - Step: 1180/1194 | Loss: 302.325 | Accuracy: 0.000\n",
      "[Epoch: 184/200] - Step: 1190/1194 | Loss: 280.719 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 185/200] - Step: 10/1194 | Loss: 295.640 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 20/1194 | Loss: 299.413 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 30/1194 | Loss: 294.845 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 40/1194 | Loss: 303.777 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 50/1194 | Loss: 286.248 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 60/1194 | Loss: 298.373 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 70/1194 | Loss: 308.414 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 80/1194 | Loss: 278.246 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 90/1194 | Loss: 299.997 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 100/1194 | Loss: 307.687 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 110/1194 | Loss: 308.197 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 120/1194 | Loss: 292.611 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 130/1194 | Loss: 308.609 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 140/1194 | Loss: 301.573 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 150/1194 | Loss: 297.676 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 160/1194 | Loss: 296.660 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 170/1194 | Loss: 311.592 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 180/1194 | Loss: 282.981 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 190/1194 | Loss: 316.120 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 200/1194 | Loss: 277.949 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 210/1194 | Loss: 306.333 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 220/1194 | Loss: 300.027 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 230/1194 | Loss: 302.425 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 240/1194 | Loss: 301.870 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 250/1194 | Loss: 297.612 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 260/1194 | Loss: 271.972 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 270/1194 | Loss: 294.841 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 280/1194 | Loss: 290.570 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 290/1194 | Loss: 302.141 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 300/1194 | Loss: 289.902 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 310/1194 | Loss: 300.406 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 320/1194 | Loss: 342.938 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 330/1194 | Loss: 298.699 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 340/1194 | Loss: 311.627 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 350/1194 | Loss: 315.240 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 360/1194 | Loss: 306.854 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 370/1194 | Loss: 322.104 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 380/1194 | Loss: 289.703 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 390/1194 | Loss: 300.317 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 400/1194 | Loss: 303.622 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 410/1194 | Loss: 302.535 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 420/1194 | Loss: 310.987 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 430/1194 | Loss: 305.999 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 440/1194 | Loss: 285.715 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 450/1194 | Loss: 290.666 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 460/1194 | Loss: 292.514 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 470/1194 | Loss: 297.400 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 480/1194 | Loss: 287.134 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 490/1194 | Loss: 275.382 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 500/1194 | Loss: 289.281 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 510/1194 | Loss: 298.086 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 520/1194 | Loss: 299.724 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 530/1194 | Loss: 283.621 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 540/1194 | Loss: 285.359 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 550/1194 | Loss: 299.094 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 560/1194 | Loss: 292.318 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 570/1194 | Loss: 276.073 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 580/1194 | Loss: 278.991 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 590/1194 | Loss: 279.328 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 600/1194 | Loss: 301.962 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 610/1194 | Loss: 292.274 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 620/1194 | Loss: 298.036 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 630/1194 | Loss: 285.318 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 640/1194 | Loss: 295.109 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 650/1194 | Loss: 290.986 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 660/1194 | Loss: 301.805 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 670/1194 | Loss: 277.633 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 680/1194 | Loss: 290.021 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 690/1194 | Loss: 302.711 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 700/1194 | Loss: 294.820 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 710/1194 | Loss: 290.416 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 720/1194 | Loss: 297.267 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 730/1194 | Loss: 286.755 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 740/1194 | Loss: 279.384 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 750/1194 | Loss: 304.512 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 760/1194 | Loss: 288.037 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 770/1194 | Loss: 297.469 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 780/1194 | Loss: 269.154 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 790/1194 | Loss: 290.936 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 800/1194 | Loss: 325.141 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 810/1194 | Loss: 284.901 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 820/1194 | Loss: 320.574 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 830/1194 | Loss: 303.936 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 840/1194 | Loss: 270.474 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 850/1194 | Loss: 311.689 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 860/1194 | Loss: 309.317 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 870/1194 | Loss: 265.083 | Accuracy: 0.400\n",
      "[Epoch: 185/200] - Step: 880/1194 | Loss: 291.525 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 890/1194 | Loss: 275.452 | Accuracy: 0.300\n",
      "[Epoch: 185/200] - Step: 900/1194 | Loss: 314.476 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 910/1194 | Loss: 286.608 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 920/1194 | Loss: 287.199 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 930/1194 | Loss: 284.808 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 940/1194 | Loss: 285.818 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 950/1194 | Loss: 305.835 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 960/1194 | Loss: 305.740 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 970/1194 | Loss: 292.765 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 980/1194 | Loss: 291.216 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 990/1194 | Loss: 295.540 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1000/1194 | Loss: 285.456 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 1010/1194 | Loss: 299.823 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1020/1194 | Loss: 292.516 | Accuracy: 0.200\n",
      "[Epoch: 185/200] - Step: 1030/1194 | Loss: 302.051 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1040/1194 | Loss: 293.435 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1050/1194 | Loss: 318.295 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1060/1194 | Loss: 308.752 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1070/1194 | Loss: 296.636 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1080/1194 | Loss: 309.217 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1090/1194 | Loss: 331.461 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1100/1194 | Loss: 299.191 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1110/1194 | Loss: 305.907 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1120/1194 | Loss: 290.171 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1130/1194 | Loss: 293.792 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1140/1194 | Loss: 296.844 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1150/1194 | Loss: 301.264 | Accuracy: 0.100\n",
      "[Epoch: 185/200] - Step: 1160/1194 | Loss: 310.174 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1170/1194 | Loss: 302.610 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1180/1194 | Loss: 295.843 | Accuracy: 0.000\n",
      "[Epoch: 185/200] - Step: 1190/1194 | Loss: 302.955 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 186/200] - Step: 10/1194 | Loss: 320.495 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 20/1194 | Loss: 303.023 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 30/1194 | Loss: 289.160 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 40/1194 | Loss: 301.742 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 50/1194 | Loss: 292.147 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 60/1194 | Loss: 284.867 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 70/1194 | Loss: 315.468 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 80/1194 | Loss: 290.643 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 90/1194 | Loss: 303.929 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 100/1194 | Loss: 291.597 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 110/1194 | Loss: 284.794 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 120/1194 | Loss: 284.080 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 130/1194 | Loss: 290.664 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 140/1194 | Loss: 299.577 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 150/1194 | Loss: 298.737 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 160/1194 | Loss: 297.635 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 170/1194 | Loss: 300.539 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 180/1194 | Loss: 293.881 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 190/1194 | Loss: 296.116 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 200/1194 | Loss: 287.981 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 210/1194 | Loss: 313.737 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 220/1194 | Loss: 298.017 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 230/1194 | Loss: 284.462 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 240/1194 | Loss: 286.374 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 250/1194 | Loss: 282.765 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 260/1194 | Loss: 287.156 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 270/1194 | Loss: 307.942 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 280/1194 | Loss: 308.590 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 290/1194 | Loss: 298.800 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 300/1194 | Loss: 290.876 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 310/1194 | Loss: 293.406 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 320/1194 | Loss: 286.547 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 330/1194 | Loss: 309.113 | Accuracy: 0.300\n",
      "[Epoch: 186/200] - Step: 340/1194 | Loss: 294.486 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 350/1194 | Loss: 284.421 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 360/1194 | Loss: 298.706 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 370/1194 | Loss: 295.331 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 380/1194 | Loss: 276.338 | Accuracy: 0.400\n",
      "[Epoch: 186/200] - Step: 390/1194 | Loss: 311.065 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 400/1194 | Loss: 301.121 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 410/1194 | Loss: 307.512 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 420/1194 | Loss: 298.061 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 430/1194 | Loss: 313.573 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 440/1194 | Loss: 281.318 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 450/1194 | Loss: 279.560 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 460/1194 | Loss: 292.168 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 470/1194 | Loss: 283.213 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 480/1194 | Loss: 288.871 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 490/1194 | Loss: 306.866 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 500/1194 | Loss: 323.677 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 510/1194 | Loss: 285.714 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 520/1194 | Loss: 300.142 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 530/1194 | Loss: 302.383 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 540/1194 | Loss: 290.867 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 550/1194 | Loss: 272.200 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 560/1194 | Loss: 301.741 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 570/1194 | Loss: 285.416 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 580/1194 | Loss: 285.321 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 590/1194 | Loss: 279.855 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 600/1194 | Loss: 306.533 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 610/1194 | Loss: 306.609 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 620/1194 | Loss: 302.764 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 630/1194 | Loss: 289.852 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 640/1194 | Loss: 284.212 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 650/1194 | Loss: 303.370 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 660/1194 | Loss: 320.595 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 670/1194 | Loss: 305.285 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 680/1194 | Loss: 302.427 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 690/1194 | Loss: 295.925 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 700/1194 | Loss: 282.197 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 710/1194 | Loss: 282.856 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 720/1194 | Loss: 312.373 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 730/1194 | Loss: 316.543 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 740/1194 | Loss: 289.976 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 750/1194 | Loss: 291.422 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 760/1194 | Loss: 296.836 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 770/1194 | Loss: 287.788 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 780/1194 | Loss: 283.607 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 790/1194 | Loss: 309.725 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 800/1194 | Loss: 310.545 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 810/1194 | Loss: 295.456 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 820/1194 | Loss: 302.522 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 830/1194 | Loss: 312.147 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 840/1194 | Loss: 304.434 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 850/1194 | Loss: 306.297 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 860/1194 | Loss: 301.582 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 870/1194 | Loss: 306.804 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 880/1194 | Loss: 314.329 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 890/1194 | Loss: 308.710 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 900/1194 | Loss: 301.793 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 910/1194 | Loss: 285.445 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 920/1194 | Loss: 275.148 | Accuracy: 0.300\n",
      "[Epoch: 186/200] - Step: 930/1194 | Loss: 294.840 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 940/1194 | Loss: 337.270 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 950/1194 | Loss: 299.945 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 960/1194 | Loss: 289.205 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 970/1194 | Loss: 299.581 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 980/1194 | Loss: 290.552 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 990/1194 | Loss: 306.492 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 1000/1194 | Loss: 281.728 | Accuracy: 0.300\n",
      "[Epoch: 186/200] - Step: 1010/1194 | Loss: 302.439 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1020/1194 | Loss: 305.371 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1030/1194 | Loss: 289.943 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 1040/1194 | Loss: 287.788 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1050/1194 | Loss: 279.151 | Accuracy: 0.300\n",
      "[Epoch: 186/200] - Step: 1060/1194 | Loss: 294.560 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1070/1194 | Loss: 299.697 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1080/1194 | Loss: 288.878 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 1090/1194 | Loss: 289.921 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1100/1194 | Loss: 284.136 | Accuracy: 0.200\n",
      "[Epoch: 186/200] - Step: 1110/1194 | Loss: 293.285 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1120/1194 | Loss: 321.051 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1130/1194 | Loss: 311.259 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 1140/1194 | Loss: 305.612 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 1150/1194 | Loss: 291.787 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1160/1194 | Loss: 305.772 | Accuracy: 0.000\n",
      "[Epoch: 186/200] - Step: 1170/1194 | Loss: 289.957 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1180/1194 | Loss: 294.775 | Accuracy: 0.100\n",
      "[Epoch: 186/200] - Step: 1190/1194 | Loss: 280.480 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 187/200] - Step: 10/1194 | Loss: 291.874 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 20/1194 | Loss: 305.852 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 30/1194 | Loss: 296.279 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 40/1194 | Loss: 309.999 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 50/1194 | Loss: 313.948 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 60/1194 | Loss: 310.803 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 70/1194 | Loss: 290.246 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 80/1194 | Loss: 355.037 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 90/1194 | Loss: 288.474 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 100/1194 | Loss: 288.453 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 110/1194 | Loss: 280.569 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 120/1194 | Loss: 284.792 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 130/1194 | Loss: 294.142 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 140/1194 | Loss: 299.985 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 150/1194 | Loss: 282.992 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 160/1194 | Loss: 309.026 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 170/1194 | Loss: 297.033 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 180/1194 | Loss: 305.684 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 190/1194 | Loss: 295.978 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 200/1194 | Loss: 302.456 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 210/1194 | Loss: 282.606 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 220/1194 | Loss: 303.003 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 230/1194 | Loss: 305.431 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 240/1194 | Loss: 300.957 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 250/1194 | Loss: 307.925 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 260/1194 | Loss: 304.664 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 270/1194 | Loss: 286.091 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 280/1194 | Loss: 276.378 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 290/1194 | Loss: 292.350 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 300/1194 | Loss: 281.568 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 310/1194 | Loss: 291.436 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 320/1194 | Loss: 306.305 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 330/1194 | Loss: 300.691 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 340/1194 | Loss: 292.564 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 350/1194 | Loss: 299.352 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 360/1194 | Loss: 290.750 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 370/1194 | Loss: 294.540 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 380/1194 | Loss: 308.292 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 390/1194 | Loss: 304.126 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 400/1194 | Loss: 297.292 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 410/1194 | Loss: 312.290 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 420/1194 | Loss: 297.162 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 430/1194 | Loss: 298.261 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 440/1194 | Loss: 309.913 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 450/1194 | Loss: 282.906 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 460/1194 | Loss: 291.222 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 470/1194 | Loss: 289.756 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 480/1194 | Loss: 289.042 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 490/1194 | Loss: 304.520 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 500/1194 | Loss: 303.361 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 510/1194 | Loss: 291.023 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 520/1194 | Loss: 311.638 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 530/1194 | Loss: 286.180 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 540/1194 | Loss: 286.985 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 550/1194 | Loss: 335.111 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 560/1194 | Loss: 283.030 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 570/1194 | Loss: 287.818 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 580/1194 | Loss: 289.022 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 590/1194 | Loss: 286.929 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 600/1194 | Loss: 309.047 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 610/1194 | Loss: 296.046 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 620/1194 | Loss: 338.093 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 630/1194 | Loss: 307.510 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 640/1194 | Loss: 281.275 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 650/1194 | Loss: 281.564 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 660/1194 | Loss: 306.080 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 670/1194 | Loss: 283.558 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 680/1194 | Loss: 282.947 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 690/1194 | Loss: 307.422 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 700/1194 | Loss: 306.159 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 710/1194 | Loss: 300.144 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 720/1194 | Loss: 284.413 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 730/1194 | Loss: 309.298 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 740/1194 | Loss: 302.136 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 750/1194 | Loss: 300.132 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 760/1194 | Loss: 298.810 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 770/1194 | Loss: 287.702 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 780/1194 | Loss: 300.483 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 790/1194 | Loss: 282.477 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 800/1194 | Loss: 277.290 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 810/1194 | Loss: 318.457 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 820/1194 | Loss: 290.249 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 830/1194 | Loss: 285.788 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 840/1194 | Loss: 294.833 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 850/1194 | Loss: 287.340 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 860/1194 | Loss: 299.770 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 870/1194 | Loss: 288.483 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 880/1194 | Loss: 285.640 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 890/1194 | Loss: 286.694 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 900/1194 | Loss: 285.519 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 910/1194 | Loss: 309.494 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 920/1194 | Loss: 265.009 | Accuracy: 0.400\n",
      "[Epoch: 187/200] - Step: 930/1194 | Loss: 276.332 | Accuracy: 0.300\n",
      "[Epoch: 187/200] - Step: 940/1194 | Loss: 298.503 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 950/1194 | Loss: 286.886 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 960/1194 | Loss: 287.056 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 970/1194 | Loss: 310.257 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 980/1194 | Loss: 303.655 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 990/1194 | Loss: 311.169 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1000/1194 | Loss: 303.346 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1010/1194 | Loss: 287.641 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1020/1194 | Loss: 306.993 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1030/1194 | Loss: 301.187 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1040/1194 | Loss: 299.150 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1050/1194 | Loss: 296.810 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1060/1194 | Loss: 309.424 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1070/1194 | Loss: 301.615 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1080/1194 | Loss: 288.123 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1090/1194 | Loss: 297.974 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 1100/1194 | Loss: 289.508 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1110/1194 | Loss: 305.053 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1120/1194 | Loss: 267.692 | Accuracy: 0.400\n",
      "[Epoch: 187/200] - Step: 1130/1194 | Loss: 292.650 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1140/1194 | Loss: 289.283 | Accuracy: 0.100\n",
      "[Epoch: 187/200] - Step: 1150/1194 | Loss: 320.350 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1160/1194 | Loss: 287.367 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 1170/1194 | Loss: 310.229 | Accuracy: 0.000\n",
      "[Epoch: 187/200] - Step: 1180/1194 | Loss: 286.348 | Accuracy: 0.200\n",
      "[Epoch: 187/200] - Step: 1190/1194 | Loss: 289.876 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 188/200] - Step: 10/1194 | Loss: 290.007 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 20/1194 | Loss: 291.791 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 30/1194 | Loss: 310.429 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 40/1194 | Loss: 325.779 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 50/1194 | Loss: 292.364 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 60/1194 | Loss: 285.937 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 70/1194 | Loss: 285.078 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 80/1194 | Loss: 293.116 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 90/1194 | Loss: 298.990 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 100/1194 | Loss: 287.741 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 110/1194 | Loss: 307.015 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 120/1194 | Loss: 318.866 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 130/1194 | Loss: 300.313 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 140/1194 | Loss: 273.973 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 150/1194 | Loss: 295.127 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 160/1194 | Loss: 277.635 | Accuracy: 0.400\n",
      "[Epoch: 188/200] - Step: 170/1194 | Loss: 307.582 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 180/1194 | Loss: 274.632 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 190/1194 | Loss: 307.176 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 200/1194 | Loss: 282.819 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 210/1194 | Loss: 311.668 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 220/1194 | Loss: 291.366 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 230/1194 | Loss: 305.352 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 240/1194 | Loss: 293.943 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 250/1194 | Loss: 302.089 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 260/1194 | Loss: 287.460 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 270/1194 | Loss: 299.180 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 280/1194 | Loss: 292.168 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 290/1194 | Loss: 310.718 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 300/1194 | Loss: 306.575 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 310/1194 | Loss: 309.563 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 320/1194 | Loss: 303.429 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 330/1194 | Loss: 298.675 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 340/1194 | Loss: 285.479 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 350/1194 | Loss: 307.071 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 360/1194 | Loss: 291.447 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 370/1194 | Loss: 310.957 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 380/1194 | Loss: 328.117 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 390/1194 | Loss: 302.648 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 400/1194 | Loss: 298.137 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 410/1194 | Loss: 278.978 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 420/1194 | Loss: 305.228 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 430/1194 | Loss: 303.015 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 440/1194 | Loss: 295.965 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 450/1194 | Loss: 273.835 | Accuracy: 0.400\n",
      "[Epoch: 188/200] - Step: 460/1194 | Loss: 295.380 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 470/1194 | Loss: 280.833 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 480/1194 | Loss: 291.639 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 490/1194 | Loss: 300.159 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 500/1194 | Loss: 306.479 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 510/1194 | Loss: 286.242 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 520/1194 | Loss: 306.770 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 530/1194 | Loss: 313.447 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 540/1194 | Loss: 274.447 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 550/1194 | Loss: 297.543 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 560/1194 | Loss: 295.440 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 570/1194 | Loss: 306.759 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 580/1194 | Loss: 318.750 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 590/1194 | Loss: 283.423 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 600/1194 | Loss: 286.064 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 610/1194 | Loss: 300.588 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 620/1194 | Loss: 313.025 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 630/1194 | Loss: 301.010 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 640/1194 | Loss: 307.886 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 650/1194 | Loss: 285.497 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 660/1194 | Loss: 309.409 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 670/1194 | Loss: 296.770 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 680/1194 | Loss: 302.689 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 690/1194 | Loss: 296.175 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 700/1194 | Loss: 292.693 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 710/1194 | Loss: 290.086 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 720/1194 | Loss: 325.397 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 730/1194 | Loss: 290.858 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 740/1194 | Loss: 295.775 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 750/1194 | Loss: 291.038 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 760/1194 | Loss: 297.697 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 770/1194 | Loss: 308.925 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 780/1194 | Loss: 312.251 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 790/1194 | Loss: 293.692 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 800/1194 | Loss: 288.542 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 810/1194 | Loss: 306.882 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 820/1194 | Loss: 288.458 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 830/1194 | Loss: 298.446 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 840/1194 | Loss: 319.617 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 850/1194 | Loss: 302.750 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 860/1194 | Loss: 293.666 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 870/1194 | Loss: 293.907 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 880/1194 | Loss: 284.335 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 890/1194 | Loss: 286.776 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 900/1194 | Loss: 295.072 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 910/1194 | Loss: 292.628 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 920/1194 | Loss: 271.818 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 930/1194 | Loss: 285.635 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 940/1194 | Loss: 285.210 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 950/1194 | Loss: 274.564 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 960/1194 | Loss: 286.660 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 970/1194 | Loss: 293.641 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 980/1194 | Loss: 334.458 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 990/1194 | Loss: 292.534 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1000/1194 | Loss: 295.858 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1010/1194 | Loss: 305.936 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1020/1194 | Loss: 282.705 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 1030/1194 | Loss: 293.675 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1040/1194 | Loss: 301.244 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1050/1194 | Loss: 294.497 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1060/1194 | Loss: 286.097 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 1070/1194 | Loss: 283.417 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1080/1194 | Loss: 307.108 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1090/1194 | Loss: 315.776 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1100/1194 | Loss: 289.210 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 1110/1194 | Loss: 305.340 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1120/1194 | Loss: 292.239 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1130/1194 | Loss: 282.742 | Accuracy: 0.300\n",
      "[Epoch: 188/200] - Step: 1140/1194 | Loss: 298.956 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1150/1194 | Loss: 281.940 | Accuracy: 0.100\n",
      "[Epoch: 188/200] - Step: 1160/1194 | Loss: 304.114 | Accuracy: 0.000\n",
      "[Epoch: 188/200] - Step: 1170/1194 | Loss: 308.299 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 1180/1194 | Loss: 278.882 | Accuracy: 0.200\n",
      "[Epoch: 188/200] - Step: 1190/1194 | Loss: 285.600 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 189/200] - Step: 10/1194 | Loss: 295.101 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 20/1194 | Loss: 276.157 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 30/1194 | Loss: 294.539 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 40/1194 | Loss: 271.146 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 50/1194 | Loss: 305.594 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 60/1194 | Loss: 271.092 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 70/1194 | Loss: 275.014 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 80/1194 | Loss: 306.049 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 90/1194 | Loss: 295.080 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 100/1194 | Loss: 320.652 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 110/1194 | Loss: 310.730 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 120/1194 | Loss: 293.026 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 130/1194 | Loss: 295.678 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 140/1194 | Loss: 280.418 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 150/1194 | Loss: 305.105 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 160/1194 | Loss: 303.180 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 170/1194 | Loss: 308.086 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 180/1194 | Loss: 316.253 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 190/1194 | Loss: 293.541 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 200/1194 | Loss: 286.853 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 210/1194 | Loss: 298.281 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 220/1194 | Loss: 314.129 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 230/1194 | Loss: 307.192 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 240/1194 | Loss: 285.370 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 250/1194 | Loss: 278.514 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 260/1194 | Loss: 287.938 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 270/1194 | Loss: 305.844 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 280/1194 | Loss: 291.230 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 290/1194 | Loss: 299.395 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 300/1194 | Loss: 308.543 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 310/1194 | Loss: 319.472 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 320/1194 | Loss: 297.958 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 330/1194 | Loss: 291.504 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 340/1194 | Loss: 314.798 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 350/1194 | Loss: 297.100 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 360/1194 | Loss: 284.889 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 370/1194 | Loss: 301.395 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 380/1194 | Loss: 295.322 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 390/1194 | Loss: 309.151 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 400/1194 | Loss: 277.857 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 410/1194 | Loss: 286.451 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 420/1194 | Loss: 298.488 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 430/1194 | Loss: 294.531 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 440/1194 | Loss: 290.162 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 450/1194 | Loss: 291.168 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 460/1194 | Loss: 309.053 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 470/1194 | Loss: 327.855 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 480/1194 | Loss: 275.569 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 490/1194 | Loss: 297.202 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 500/1194 | Loss: 293.318 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 510/1194 | Loss: 308.598 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 520/1194 | Loss: 295.673 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 530/1194 | Loss: 301.951 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 540/1194 | Loss: 276.983 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 550/1194 | Loss: 309.211 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 560/1194 | Loss: 286.130 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 570/1194 | Loss: 291.587 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 580/1194 | Loss: 276.347 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 590/1194 | Loss: 304.937 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 600/1194 | Loss: 295.988 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 610/1194 | Loss: 302.796 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 620/1194 | Loss: 304.653 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 630/1194 | Loss: 310.058 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 640/1194 | Loss: 286.172 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 650/1194 | Loss: 309.392 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 660/1194 | Loss: 285.921 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 670/1194 | Loss: 307.709 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 680/1194 | Loss: 305.054 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 690/1194 | Loss: 291.962 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 700/1194 | Loss: 295.861 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 710/1194 | Loss: 277.303 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 720/1194 | Loss: 295.993 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 730/1194 | Loss: 307.018 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 740/1194 | Loss: 295.298 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 750/1194 | Loss: 295.148 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 760/1194 | Loss: 297.347 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 770/1194 | Loss: 279.087 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 780/1194 | Loss: 297.741 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 790/1194 | Loss: 314.835 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 800/1194 | Loss: 290.885 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 810/1194 | Loss: 278.653 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 820/1194 | Loss: 290.847 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 830/1194 | Loss: 319.788 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 840/1194 | Loss: 282.869 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 850/1194 | Loss: 288.618 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 860/1194 | Loss: 309.494 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 870/1194 | Loss: 305.819 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 880/1194 | Loss: 300.468 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 890/1194 | Loss: 288.471 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 900/1194 | Loss: 306.305 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 910/1194 | Loss: 311.405 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 920/1194 | Loss: 281.404 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 930/1194 | Loss: 311.816 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 940/1194 | Loss: 294.269 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 950/1194 | Loss: 286.332 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 960/1194 | Loss: 291.145 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 970/1194 | Loss: 305.125 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 980/1194 | Loss: 287.118 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 990/1194 | Loss: 316.152 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 1000/1194 | Loss: 281.213 | Accuracy: 0.300\n",
      "[Epoch: 189/200] - Step: 1010/1194 | Loss: 299.445 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1020/1194 | Loss: 310.894 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1030/1194 | Loss: 304.330 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1040/1194 | Loss: 284.993 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 1050/1194 | Loss: 299.758 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1060/1194 | Loss: 282.854 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 1070/1194 | Loss: 309.119 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1080/1194 | Loss: 302.765 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1090/1194 | Loss: 310.764 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1100/1194 | Loss: 290.862 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1110/1194 | Loss: 286.959 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 1120/1194 | Loss: 301.676 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1130/1194 | Loss: 297.712 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1140/1194 | Loss: 308.325 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1150/1194 | Loss: 276.246 | Accuracy: 0.200\n",
      "[Epoch: 189/200] - Step: 1160/1194 | Loss: 303.313 | Accuracy: 0.000\n",
      "[Epoch: 189/200] - Step: 1170/1194 | Loss: 300.733 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1180/1194 | Loss: 308.105 | Accuracy: 0.100\n",
      "[Epoch: 189/200] - Step: 1190/1194 | Loss: 281.610 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 190/200] - Step: 10/1194 | Loss: 292.773 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 20/1194 | Loss: 276.838 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 30/1194 | Loss: 305.373 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 40/1194 | Loss: 289.969 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 50/1194 | Loss: 289.257 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 60/1194 | Loss: 299.436 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 70/1194 | Loss: 320.759 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 80/1194 | Loss: 303.793 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 90/1194 | Loss: 310.674 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 100/1194 | Loss: 289.310 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 110/1194 | Loss: 282.398 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 120/1194 | Loss: 294.580 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 130/1194 | Loss: 297.227 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 140/1194 | Loss: 319.267 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 150/1194 | Loss: 305.612 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 160/1194 | Loss: 313.312 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 170/1194 | Loss: 303.087 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 180/1194 | Loss: 303.552 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 190/1194 | Loss: 285.641 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 200/1194 | Loss: 303.428 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 210/1194 | Loss: 293.475 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 220/1194 | Loss: 308.707 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 230/1194 | Loss: 308.222 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 240/1194 | Loss: 319.638 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 250/1194 | Loss: 311.471 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 260/1194 | Loss: 270.643 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 270/1194 | Loss: 291.596 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 280/1194 | Loss: 295.210 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 290/1194 | Loss: 292.650 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 300/1194 | Loss: 294.280 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 310/1194 | Loss: 279.190 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 320/1194 | Loss: 288.598 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 330/1194 | Loss: 298.488 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 340/1194 | Loss: 312.080 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 350/1194 | Loss: 302.085 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 360/1194 | Loss: 303.736 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 370/1194 | Loss: 301.343 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 380/1194 | Loss: 274.631 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 390/1194 | Loss: 314.895 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 400/1194 | Loss: 290.706 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 410/1194 | Loss: 295.566 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 420/1194 | Loss: 286.572 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 430/1194 | Loss: 309.513 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 440/1194 | Loss: 294.143 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 450/1194 | Loss: 298.067 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 460/1194 | Loss: 300.953 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 470/1194 | Loss: 287.572 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 480/1194 | Loss: 306.430 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 490/1194 | Loss: 296.469 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 500/1194 | Loss: 291.299 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 510/1194 | Loss: 283.248 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 520/1194 | Loss: 281.508 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 530/1194 | Loss: 300.388 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 540/1194 | Loss: 307.730 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 550/1194 | Loss: 291.566 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 560/1194 | Loss: 303.055 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 570/1194 | Loss: 315.408 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 580/1194 | Loss: 283.698 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 590/1194 | Loss: 290.388 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 600/1194 | Loss: 298.707 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 610/1194 | Loss: 299.481 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 620/1194 | Loss: 290.936 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 630/1194 | Loss: 296.588 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 640/1194 | Loss: 303.505 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 650/1194 | Loss: 291.215 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 660/1194 | Loss: 293.746 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 670/1194 | Loss: 297.359 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 680/1194 | Loss: 309.806 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 690/1194 | Loss: 298.091 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 700/1194 | Loss: 293.215 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 710/1194 | Loss: 300.302 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 720/1194 | Loss: 301.705 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 730/1194 | Loss: 312.201 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 740/1194 | Loss: 299.406 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 750/1194 | Loss: 298.717 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 760/1194 | Loss: 297.164 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 770/1194 | Loss: 306.195 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 780/1194 | Loss: 279.407 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 790/1194 | Loss: 293.370 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 800/1194 | Loss: 294.642 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 810/1194 | Loss: 280.561 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 820/1194 | Loss: 293.337 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 830/1194 | Loss: 285.403 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 840/1194 | Loss: 317.805 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 850/1194 | Loss: 301.864 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 860/1194 | Loss: 292.040 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 870/1194 | Loss: 301.868 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 880/1194 | Loss: 295.079 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 890/1194 | Loss: 296.000 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 900/1194 | Loss: 299.097 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 910/1194 | Loss: 308.486 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 920/1194 | Loss: 285.396 | Accuracy: 0.300\n",
      "[Epoch: 190/200] - Step: 930/1194 | Loss: 280.800 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 940/1194 | Loss: 293.497 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 950/1194 | Loss: 274.003 | Accuracy: 0.400\n",
      "[Epoch: 190/200] - Step: 960/1194 | Loss: 300.623 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 970/1194 | Loss: 288.112 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 980/1194 | Loss: 299.989 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 990/1194 | Loss: 297.886 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1000/1194 | Loss: 292.378 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1010/1194 | Loss: 288.133 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1020/1194 | Loss: 296.545 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1030/1194 | Loss: 305.109 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1040/1194 | Loss: 294.759 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1050/1194 | Loss: 298.616 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1060/1194 | Loss: 284.903 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1070/1194 | Loss: 293.488 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1080/1194 | Loss: 285.349 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1090/1194 | Loss: 299.899 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 1100/1194 | Loss: 292.190 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1110/1194 | Loss: 296.038 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1120/1194 | Loss: 302.939 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1130/1194 | Loss: 285.950 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1140/1194 | Loss: 301.607 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 1150/1194 | Loss: 295.876 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1160/1194 | Loss: 291.226 | Accuracy: 0.100\n",
      "[Epoch: 190/200] - Step: 1170/1194 | Loss: 281.037 | Accuracy: 0.200\n",
      "[Epoch: 190/200] - Step: 1180/1194 | Loss: 309.564 | Accuracy: 0.000\n",
      "[Epoch: 190/200] - Step: 1190/1194 | Loss: 323.178 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 191/200] - Step: 10/1194 | Loss: 302.062 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 20/1194 | Loss: 288.097 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 30/1194 | Loss: 312.164 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 40/1194 | Loss: 293.122 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 50/1194 | Loss: 295.799 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 60/1194 | Loss: 303.031 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 70/1194 | Loss: 297.078 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 80/1194 | Loss: 284.027 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 90/1194 | Loss: 295.100 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 100/1194 | Loss: 317.255 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 110/1194 | Loss: 287.268 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 120/1194 | Loss: 291.769 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 130/1194 | Loss: 306.652 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 140/1194 | Loss: 307.435 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 150/1194 | Loss: 294.316 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 160/1194 | Loss: 316.335 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 170/1194 | Loss: 306.937 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 180/1194 | Loss: 294.496 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 190/1194 | Loss: 289.481 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 200/1194 | Loss: 315.390 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 210/1194 | Loss: 310.335 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 220/1194 | Loss: 297.529 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 230/1194 | Loss: 297.883 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 240/1194 | Loss: 296.686 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 250/1194 | Loss: 304.255 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 260/1194 | Loss: 306.361 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 270/1194 | Loss: 292.530 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 280/1194 | Loss: 271.745 | Accuracy: 0.400\n",
      "[Epoch: 191/200] - Step: 290/1194 | Loss: 296.341 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 300/1194 | Loss: 301.946 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 310/1194 | Loss: 290.744 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 320/1194 | Loss: 284.571 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 330/1194 | Loss: 275.874 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 340/1194 | Loss: 308.934 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 350/1194 | Loss: 288.120 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 360/1194 | Loss: 298.573 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 370/1194 | Loss: 310.592 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 380/1194 | Loss: 291.563 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 390/1194 | Loss: 298.952 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 400/1194 | Loss: 291.159 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 410/1194 | Loss: 303.755 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 420/1194 | Loss: 305.225 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 430/1194 | Loss: 274.074 | Accuracy: 0.400\n",
      "[Epoch: 191/200] - Step: 440/1194 | Loss: 298.821 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 450/1194 | Loss: 273.955 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 460/1194 | Loss: 277.508 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 470/1194 | Loss: 291.739 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 480/1194 | Loss: 302.148 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 490/1194 | Loss: 293.356 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 500/1194 | Loss: 284.212 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 510/1194 | Loss: 318.340 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 520/1194 | Loss: 297.212 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 530/1194 | Loss: 287.169 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 540/1194 | Loss: 290.852 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 550/1194 | Loss: 288.759 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 560/1194 | Loss: 301.551 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 570/1194 | Loss: 309.417 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 580/1194 | Loss: 290.045 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 590/1194 | Loss: 286.447 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 600/1194 | Loss: 284.220 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 610/1194 | Loss: 289.624 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 620/1194 | Loss: 298.211 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 630/1194 | Loss: 271.101 | Accuracy: 0.500\n",
      "[Epoch: 191/200] - Step: 640/1194 | Loss: 308.289 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 650/1194 | Loss: 306.367 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 660/1194 | Loss: 287.534 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 670/1194 | Loss: 293.206 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 680/1194 | Loss: 285.200 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 690/1194 | Loss: 292.608 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 700/1194 | Loss: 309.004 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 710/1194 | Loss: 310.614 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 720/1194 | Loss: 302.769 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 730/1194 | Loss: 294.057 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 740/1194 | Loss: 286.601 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 750/1194 | Loss: 312.055 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 760/1194 | Loss: 300.248 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 770/1194 | Loss: 299.587 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 780/1194 | Loss: 314.401 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 790/1194 | Loss: 266.094 | Accuracy: 0.400\n",
      "[Epoch: 191/200] - Step: 800/1194 | Loss: 289.132 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 810/1194 | Loss: 284.869 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 820/1194 | Loss: 287.982 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 830/1194 | Loss: 306.211 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 840/1194 | Loss: 291.834 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 850/1194 | Loss: 281.494 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 860/1194 | Loss: 293.629 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 870/1194 | Loss: 264.783 | Accuracy: 0.400\n",
      "[Epoch: 191/200] - Step: 880/1194 | Loss: 293.229 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 890/1194 | Loss: 299.989 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 900/1194 | Loss: 288.099 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 910/1194 | Loss: 365.453 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 920/1194 | Loss: 297.730 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 930/1194 | Loss: 289.510 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 940/1194 | Loss: 298.334 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 950/1194 | Loss: 275.895 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 960/1194 | Loss: 293.501 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 970/1194 | Loss: 297.704 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 980/1194 | Loss: 320.199 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 990/1194 | Loss: 312.952 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1000/1194 | Loss: 305.720 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1010/1194 | Loss: 301.522 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1020/1194 | Loss: 309.989 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1030/1194 | Loss: 290.998 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1040/1194 | Loss: 286.666 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 1050/1194 | Loss: 299.218 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1060/1194 | Loss: 304.843 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1070/1194 | Loss: 310.536 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1080/1194 | Loss: 278.497 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 1090/1194 | Loss: 304.455 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1100/1194 | Loss: 306.869 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1110/1194 | Loss: 291.462 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1120/1194 | Loss: 298.182 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1130/1194 | Loss: 293.845 | Accuracy: 0.000\n",
      "[Epoch: 191/200] - Step: 1140/1194 | Loss: 285.452 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1150/1194 | Loss: 329.435 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1160/1194 | Loss: 318.064 | Accuracy: 0.200\n",
      "[Epoch: 191/200] - Step: 1170/1194 | Loss: 281.274 | Accuracy: 0.300\n",
      "[Epoch: 191/200] - Step: 1180/1194 | Loss: 302.228 | Accuracy: 0.100\n",
      "[Epoch: 191/200] - Step: 1190/1194 | Loss: 296.994 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 192/200] - Step: 10/1194 | Loss: 303.230 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 20/1194 | Loss: 285.318 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 30/1194 | Loss: 309.787 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 40/1194 | Loss: 308.816 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 50/1194 | Loss: 308.500 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 60/1194 | Loss: 271.867 | Accuracy: 0.400\n",
      "[Epoch: 192/200] - Step: 70/1194 | Loss: 291.240 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 80/1194 | Loss: 302.975 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 90/1194 | Loss: 300.861 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 100/1194 | Loss: 300.566 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 110/1194 | Loss: 282.867 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 120/1194 | Loss: 302.640 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 130/1194 | Loss: 304.404 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 140/1194 | Loss: 288.117 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 150/1194 | Loss: 284.684 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 160/1194 | Loss: 304.513 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 170/1194 | Loss: 283.168 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 180/1194 | Loss: 297.950 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 190/1194 | Loss: 289.355 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 200/1194 | Loss: 306.598 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 210/1194 | Loss: 295.596 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 220/1194 | Loss: 290.352 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 230/1194 | Loss: 300.251 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 240/1194 | Loss: 291.570 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 250/1194 | Loss: 294.816 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 260/1194 | Loss: 309.264 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 270/1194 | Loss: 297.320 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 280/1194 | Loss: 335.425 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 290/1194 | Loss: 288.108 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 300/1194 | Loss: 286.791 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 310/1194 | Loss: 290.591 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 320/1194 | Loss: 293.265 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 330/1194 | Loss: 283.122 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 340/1194 | Loss: 302.856 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 350/1194 | Loss: 304.713 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 360/1194 | Loss: 277.932 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 370/1194 | Loss: 288.878 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 380/1194 | Loss: 319.099 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 390/1194 | Loss: 304.382 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 400/1194 | Loss: 299.841 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 410/1194 | Loss: 302.930 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 420/1194 | Loss: 304.452 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 430/1194 | Loss: 292.982 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 440/1194 | Loss: 299.206 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 450/1194 | Loss: 279.793 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 460/1194 | Loss: 297.396 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 470/1194 | Loss: 313.698 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 480/1194 | Loss: 300.408 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 490/1194 | Loss: 292.928 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 500/1194 | Loss: 291.476 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 510/1194 | Loss: 303.864 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 520/1194 | Loss: 298.880 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 530/1194 | Loss: 307.227 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 540/1194 | Loss: 291.455 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 550/1194 | Loss: 279.334 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 560/1194 | Loss: 290.029 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 570/1194 | Loss: 287.502 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 580/1194 | Loss: 286.819 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 590/1194 | Loss: 291.498 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 600/1194 | Loss: 295.213 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 610/1194 | Loss: 273.871 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 620/1194 | Loss: 293.788 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 630/1194 | Loss: 298.741 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 640/1194 | Loss: 297.203 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 650/1194 | Loss: 306.039 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 660/1194 | Loss: 266.895 | Accuracy: 0.400\n",
      "[Epoch: 192/200] - Step: 670/1194 | Loss: 289.976 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 680/1194 | Loss: 310.097 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 690/1194 | Loss: 278.124 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 700/1194 | Loss: 275.444 | Accuracy: 0.400\n",
      "[Epoch: 192/200] - Step: 710/1194 | Loss: 309.428 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 720/1194 | Loss: 306.461 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 730/1194 | Loss: 299.241 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 740/1194 | Loss: 290.778 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 750/1194 | Loss: 280.053 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 760/1194 | Loss: 353.103 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 770/1194 | Loss: 301.234 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 780/1194 | Loss: 279.329 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 790/1194 | Loss: 309.429 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 800/1194 | Loss: 301.609 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 810/1194 | Loss: 295.721 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 820/1194 | Loss: 324.845 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 830/1194 | Loss: 303.558 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 840/1194 | Loss: 302.089 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 850/1194 | Loss: 289.683 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 860/1194 | Loss: 297.330 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 870/1194 | Loss: 288.353 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 880/1194 | Loss: 296.936 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 890/1194 | Loss: 291.757 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 900/1194 | Loss: 297.256 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 910/1194 | Loss: 269.651 | Accuracy: 0.400\n",
      "[Epoch: 192/200] - Step: 920/1194 | Loss: 285.151 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 930/1194 | Loss: 276.766 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 940/1194 | Loss: 296.400 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 950/1194 | Loss: 297.130 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 960/1194 | Loss: 289.855 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 970/1194 | Loss: 298.588 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 980/1194 | Loss: 305.337 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 990/1194 | Loss: 314.057 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1000/1194 | Loss: 297.077 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 1010/1194 | Loss: 284.698 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 1020/1194 | Loss: 284.448 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 1030/1194 | Loss: 330.195 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1040/1194 | Loss: 295.908 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1050/1194 | Loss: 349.199 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1060/1194 | Loss: 298.349 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1070/1194 | Loss: 308.504 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1080/1194 | Loss: 287.464 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 1090/1194 | Loss: 300.646 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 1100/1194 | Loss: 308.385 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1110/1194 | Loss: 299.492 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 1120/1194 | Loss: 303.183 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1130/1194 | Loss: 280.466 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 1140/1194 | Loss: 296.910 | Accuracy: 0.200\n",
      "[Epoch: 192/200] - Step: 1150/1194 | Loss: 302.445 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1160/1194 | Loss: 300.003 | Accuracy: 0.100\n",
      "[Epoch: 192/200] - Step: 1170/1194 | Loss: 307.892 | Accuracy: 0.000\n",
      "[Epoch: 192/200] - Step: 1180/1194 | Loss: 268.054 | Accuracy: 0.300\n",
      "[Epoch: 192/200] - Step: 1190/1194 | Loss: 304.046 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 193/200] - Step: 10/1194 | Loss: 302.499 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 20/1194 | Loss: 297.105 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 30/1194 | Loss: 286.638 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 40/1194 | Loss: 299.256 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 50/1194 | Loss: 284.697 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 60/1194 | Loss: 304.691 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 70/1194 | Loss: 304.437 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 80/1194 | Loss: 314.221 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 90/1194 | Loss: 295.527 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 100/1194 | Loss: 285.594 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 110/1194 | Loss: 287.545 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 120/1194 | Loss: 291.565 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 130/1194 | Loss: 292.272 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 140/1194 | Loss: 288.646 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 150/1194 | Loss: 286.499 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 160/1194 | Loss: 332.535 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 170/1194 | Loss: 284.113 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 180/1194 | Loss: 306.359 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 190/1194 | Loss: 291.822 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 200/1194 | Loss: 293.840 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 210/1194 | Loss: 319.614 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 220/1194 | Loss: 300.959 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 230/1194 | Loss: 310.842 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 240/1194 | Loss: 292.562 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 250/1194 | Loss: 287.962 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 260/1194 | Loss: 291.744 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 270/1194 | Loss: 297.271 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 280/1194 | Loss: 277.585 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 290/1194 | Loss: 286.494 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 300/1194 | Loss: 298.699 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 310/1194 | Loss: 304.536 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 320/1194 | Loss: 290.959 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 330/1194 | Loss: 306.958 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 340/1194 | Loss: 289.934 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 350/1194 | Loss: 308.644 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 360/1194 | Loss: 297.037 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 370/1194 | Loss: 310.816 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 380/1194 | Loss: 289.681 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 390/1194 | Loss: 306.534 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 400/1194 | Loss: 294.115 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 410/1194 | Loss: 292.659 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 420/1194 | Loss: 296.877 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 430/1194 | Loss: 295.695 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 440/1194 | Loss: 299.598 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 450/1194 | Loss: 297.189 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 460/1194 | Loss: 291.289 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 470/1194 | Loss: 307.605 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 480/1194 | Loss: 309.256 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 490/1194 | Loss: 291.928 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 500/1194 | Loss: 307.887 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 510/1194 | Loss: 276.114 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 520/1194 | Loss: 285.108 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 530/1194 | Loss: 302.674 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 540/1194 | Loss: 290.333 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 550/1194 | Loss: 298.025 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 560/1194 | Loss: 293.250 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 570/1194 | Loss: 294.100 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 580/1194 | Loss: 307.829 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 590/1194 | Loss: 291.858 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 600/1194 | Loss: 303.690 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 610/1194 | Loss: 292.696 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 620/1194 | Loss: 307.545 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 630/1194 | Loss: 297.859 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 640/1194 | Loss: 289.704 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 650/1194 | Loss: 298.923 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 660/1194 | Loss: 286.832 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 670/1194 | Loss: 303.666 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 680/1194 | Loss: 310.873 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 690/1194 | Loss: 290.419 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 700/1194 | Loss: 298.155 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 710/1194 | Loss: 294.398 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 720/1194 | Loss: 295.278 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 730/1194 | Loss: 291.022 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 740/1194 | Loss: 296.367 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 750/1194 | Loss: 279.802 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 760/1194 | Loss: 297.057 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 770/1194 | Loss: 287.219 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 780/1194 | Loss: 310.180 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 790/1194 | Loss: 298.118 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 800/1194 | Loss: 303.258 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 810/1194 | Loss: 292.115 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 820/1194 | Loss: 284.778 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 830/1194 | Loss: 298.244 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 840/1194 | Loss: 258.211 | Accuracy: 0.400\n",
      "[Epoch: 193/200] - Step: 850/1194 | Loss: 321.956 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 860/1194 | Loss: 275.963 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 870/1194 | Loss: 274.431 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 880/1194 | Loss: 292.035 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 890/1194 | Loss: 297.499 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 900/1194 | Loss: 296.816 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 910/1194 | Loss: 303.477 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 920/1194 | Loss: 315.083 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 930/1194 | Loss: 295.248 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 940/1194 | Loss: 301.865 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 950/1194 | Loss: 285.605 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 960/1194 | Loss: 294.705 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 970/1194 | Loss: 307.000 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 980/1194 | Loss: 295.656 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 990/1194 | Loss: 307.717 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1000/1194 | Loss: 290.302 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 1010/1194 | Loss: 326.330 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1020/1194 | Loss: 281.894 | Accuracy: 0.300\n",
      "[Epoch: 193/200] - Step: 1030/1194 | Loss: 307.563 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1040/1194 | Loss: 285.111 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 1050/1194 | Loss: 304.643 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1060/1194 | Loss: 300.192 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1070/1194 | Loss: 300.230 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1080/1194 | Loss: 294.307 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1090/1194 | Loss: 312.075 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1100/1194 | Loss: 298.107 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1110/1194 | Loss: 300.658 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1120/1194 | Loss: 290.591 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1130/1194 | Loss: 306.718 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1140/1194 | Loss: 303.217 | Accuracy: 0.000\n",
      "[Epoch: 193/200] - Step: 1150/1194 | Loss: 296.688 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1160/1194 | Loss: 292.184 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1170/1194 | Loss: 279.343 | Accuracy: 0.200\n",
      "[Epoch: 193/200] - Step: 1180/1194 | Loss: 295.985 | Accuracy: 0.100\n",
      "[Epoch: 193/200] - Step: 1190/1194 | Loss: 302.827 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 194/200] - Step: 10/1194 | Loss: 294.069 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 20/1194 | Loss: 284.629 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 30/1194 | Loss: 301.424 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 40/1194 | Loss: 291.472 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 50/1194 | Loss: 281.027 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 60/1194 | Loss: 295.016 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 70/1194 | Loss: 289.743 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 80/1194 | Loss: 300.242 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 90/1194 | Loss: 289.750 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 100/1194 | Loss: 300.283 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 110/1194 | Loss: 289.357 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 120/1194 | Loss: 319.149 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 130/1194 | Loss: 298.774 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 140/1194 | Loss: 294.114 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 150/1194 | Loss: 277.196 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 160/1194 | Loss: 286.433 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 170/1194 | Loss: 282.030 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 180/1194 | Loss: 313.012 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 190/1194 | Loss: 300.900 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 200/1194 | Loss: 303.501 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 210/1194 | Loss: 306.204 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 220/1194 | Loss: 299.184 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 230/1194 | Loss: 297.157 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 240/1194 | Loss: 272.777 | Accuracy: 0.400\n",
      "[Epoch: 194/200] - Step: 250/1194 | Loss: 325.304 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 260/1194 | Loss: 331.048 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 270/1194 | Loss: 281.391 | Accuracy: 0.300\n",
      "[Epoch: 194/200] - Step: 280/1194 | Loss: 304.416 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 290/1194 | Loss: 314.192 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 300/1194 | Loss: 287.865 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 310/1194 | Loss: 307.343 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 320/1194 | Loss: 302.902 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 330/1194 | Loss: 287.523 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 340/1194 | Loss: 286.889 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 350/1194 | Loss: 284.783 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 360/1194 | Loss: 295.539 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 370/1194 | Loss: 299.940 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 380/1194 | Loss: 311.483 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 390/1194 | Loss: 286.891 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 400/1194 | Loss: 299.372 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 410/1194 | Loss: 304.118 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 420/1194 | Loss: 300.394 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 430/1194 | Loss: 298.856 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 440/1194 | Loss: 306.558 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 450/1194 | Loss: 305.275 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 460/1194 | Loss: 295.164 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 470/1194 | Loss: 297.477 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 480/1194 | Loss: 307.776 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 490/1194 | Loss: 304.494 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 500/1194 | Loss: 301.054 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 510/1194 | Loss: 293.205 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 520/1194 | Loss: 301.495 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 530/1194 | Loss: 303.930 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 540/1194 | Loss: 306.700 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 550/1194 | Loss: 288.442 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 560/1194 | Loss: 291.739 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 570/1194 | Loss: 282.183 | Accuracy: 0.300\n",
      "[Epoch: 194/200] - Step: 580/1194 | Loss: 292.888 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 590/1194 | Loss: 296.335 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 600/1194 | Loss: 282.845 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 610/1194 | Loss: 303.270 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 620/1194 | Loss: 294.282 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 630/1194 | Loss: 305.538 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 640/1194 | Loss: 299.472 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 650/1194 | Loss: 285.610 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 660/1194 | Loss: 304.919 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 670/1194 | Loss: 289.745 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 680/1194 | Loss: 304.157 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 690/1194 | Loss: 278.549 | Accuracy: 0.300\n",
      "[Epoch: 194/200] - Step: 700/1194 | Loss: 309.937 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 710/1194 | Loss: 288.203 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 720/1194 | Loss: 300.700 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 730/1194 | Loss: 282.873 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 740/1194 | Loss: 291.707 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 750/1194 | Loss: 317.131 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 760/1194 | Loss: 280.553 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 770/1194 | Loss: 280.106 | Accuracy: 0.300\n",
      "[Epoch: 194/200] - Step: 780/1194 | Loss: 280.267 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 790/1194 | Loss: 289.950 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 800/1194 | Loss: 297.935 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 810/1194 | Loss: 302.722 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 820/1194 | Loss: 294.515 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 830/1194 | Loss: 297.324 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 840/1194 | Loss: 261.272 | Accuracy: 0.500\n",
      "[Epoch: 194/200] - Step: 850/1194 | Loss: 299.094 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 860/1194 | Loss: 293.968 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 870/1194 | Loss: 282.428 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 880/1194 | Loss: 308.066 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 890/1194 | Loss: 282.128 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 900/1194 | Loss: 299.172 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 910/1194 | Loss: 298.085 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 920/1194 | Loss: 295.654 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 930/1194 | Loss: 291.892 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 940/1194 | Loss: 296.741 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 950/1194 | Loss: 295.550 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 960/1194 | Loss: 304.617 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 970/1194 | Loss: 327.829 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 980/1194 | Loss: 290.946 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 990/1194 | Loss: 306.598 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1000/1194 | Loss: 272.594 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1010/1194 | Loss: 306.720 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1020/1194 | Loss: 327.953 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 1030/1194 | Loss: 319.010 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1040/1194 | Loss: 289.587 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1050/1194 | Loss: 303.915 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1060/1194 | Loss: 301.193 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 1070/1194 | Loss: 296.661 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 1080/1194 | Loss: 280.970 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1090/1194 | Loss: 287.070 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1100/1194 | Loss: 309.857 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1110/1194 | Loss: 309.277 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1120/1194 | Loss: 315.635 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1130/1194 | Loss: 289.305 | Accuracy: 0.000\n",
      "[Epoch: 194/200] - Step: 1140/1194 | Loss: 285.071 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1150/1194 | Loss: 291.080 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1160/1194 | Loss: 290.289 | Accuracy: 0.200\n",
      "[Epoch: 194/200] - Step: 1170/1194 | Loss: 296.088 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 1180/1194 | Loss: 292.580 | Accuracy: 0.100\n",
      "[Epoch: 194/200] - Step: 1190/1194 | Loss: 302.973 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 195/200] - Step: 10/1194 | Loss: 299.631 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 20/1194 | Loss: 326.324 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 30/1194 | Loss: 301.844 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 40/1194 | Loss: 278.779 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 50/1194 | Loss: 306.611 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 60/1194 | Loss: 299.953 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 70/1194 | Loss: 302.256 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 80/1194 | Loss: 306.302 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 90/1194 | Loss: 290.878 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 100/1194 | Loss: 297.332 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 110/1194 | Loss: 299.319 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 120/1194 | Loss: 306.931 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 130/1194 | Loss: 306.266 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 140/1194 | Loss: 298.327 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 150/1194 | Loss: 288.243 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 160/1194 | Loss: 310.649 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 170/1194 | Loss: 271.940 | Accuracy: 0.400\n",
      "[Epoch: 195/200] - Step: 180/1194 | Loss: 276.609 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 190/1194 | Loss: 307.490 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 200/1194 | Loss: 293.086 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 210/1194 | Loss: 299.166 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 220/1194 | Loss: 296.403 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 230/1194 | Loss: 322.893 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 240/1194 | Loss: 304.471 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 250/1194 | Loss: 299.368 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 260/1194 | Loss: 312.249 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 270/1194 | Loss: 285.692 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 280/1194 | Loss: 300.127 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 290/1194 | Loss: 290.873 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 300/1194 | Loss: 277.414 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 310/1194 | Loss: 300.972 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 320/1194 | Loss: 304.041 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 330/1194 | Loss: 293.499 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 340/1194 | Loss: 300.233 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 350/1194 | Loss: 286.152 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 360/1194 | Loss: 301.024 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 370/1194 | Loss: 287.263 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 380/1194 | Loss: 306.303 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 390/1194 | Loss: 286.858 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 400/1194 | Loss: 301.631 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 410/1194 | Loss: 287.837 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 420/1194 | Loss: 289.896 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 430/1194 | Loss: 307.382 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 440/1194 | Loss: 288.007 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 450/1194 | Loss: 287.988 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 460/1194 | Loss: 293.054 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 470/1194 | Loss: 300.158 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 480/1194 | Loss: 291.894 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 490/1194 | Loss: 312.774 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 500/1194 | Loss: 289.165 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 510/1194 | Loss: 293.181 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 520/1194 | Loss: 298.531 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 530/1194 | Loss: 280.256 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 540/1194 | Loss: 298.354 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 550/1194 | Loss: 302.636 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 560/1194 | Loss: 291.990 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 570/1194 | Loss: 285.349 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 580/1194 | Loss: 288.107 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 590/1194 | Loss: 301.172 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 600/1194 | Loss: 296.677 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 610/1194 | Loss: 293.656 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 620/1194 | Loss: 309.271 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 630/1194 | Loss: 296.694 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 640/1194 | Loss: 317.311 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 650/1194 | Loss: 309.013 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 660/1194 | Loss: 301.018 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 670/1194 | Loss: 305.802 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 680/1194 | Loss: 299.379 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 690/1194 | Loss: 283.377 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 700/1194 | Loss: 294.171 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 710/1194 | Loss: 304.974 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 720/1194 | Loss: 310.740 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 730/1194 | Loss: 305.662 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 740/1194 | Loss: 264.418 | Accuracy: 0.400\n",
      "[Epoch: 195/200] - Step: 750/1194 | Loss: 285.446 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 760/1194 | Loss: 298.946 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 770/1194 | Loss: 267.340 | Accuracy: 0.400\n",
      "[Epoch: 195/200] - Step: 780/1194 | Loss: 302.421 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 790/1194 | Loss: 311.259 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 800/1194 | Loss: 301.249 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 810/1194 | Loss: 294.148 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 820/1194 | Loss: 298.062 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 830/1194 | Loss: 290.176 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 840/1194 | Loss: 326.821 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 850/1194 | Loss: 299.637 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 860/1194 | Loss: 294.809 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 870/1194 | Loss: 268.733 | Accuracy: 0.400\n",
      "[Epoch: 195/200] - Step: 880/1194 | Loss: 304.952 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 890/1194 | Loss: 299.140 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 900/1194 | Loss: 283.414 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 910/1194 | Loss: 302.091 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 920/1194 | Loss: 291.303 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 930/1194 | Loss: 290.153 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 940/1194 | Loss: 284.194 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 950/1194 | Loss: 299.526 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 960/1194 | Loss: 308.608 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 970/1194 | Loss: 276.235 | Accuracy: 0.300\n",
      "[Epoch: 195/200] - Step: 980/1194 | Loss: 300.092 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 990/1194 | Loss: 288.488 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1000/1194 | Loss: 351.510 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1010/1194 | Loss: 294.722 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 1020/1194 | Loss: 300.969 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1030/1194 | Loss: 288.336 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1040/1194 | Loss: 302.904 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1050/1194 | Loss: 300.338 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 1060/1194 | Loss: 288.406 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1070/1194 | Loss: 306.330 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1080/1194 | Loss: 310.320 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1090/1194 | Loss: 297.573 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1100/1194 | Loss: 289.812 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 1110/1194 | Loss: 276.550 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1120/1194 | Loss: 289.318 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1130/1194 | Loss: 293.117 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1140/1194 | Loss: 297.848 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1150/1194 | Loss: 296.785 | Accuracy: 0.100\n",
      "[Epoch: 195/200] - Step: 1160/1194 | Loss: 287.830 | Accuracy: 0.200\n",
      "[Epoch: 195/200] - Step: 1170/1194 | Loss: 311.301 | Accuracy: 0.000\n",
      "[Epoch: 195/200] - Step: 1180/1194 | Loss: 270.137 | Accuracy: 0.400\n",
      "[Epoch: 195/200] - Step: 1190/1194 | Loss: 294.258 | Accuracy: 0.100\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 196/200] - Step: 10/1194 | Loss: 293.311 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 20/1194 | Loss: 301.569 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 30/1194 | Loss: 267.287 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 40/1194 | Loss: 290.332 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 50/1194 | Loss: 305.615 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 60/1194 | Loss: 289.947 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 70/1194 | Loss: 290.019 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 80/1194 | Loss: 297.674 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 90/1194 | Loss: 316.922 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 100/1194 | Loss: 300.865 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 110/1194 | Loss: 333.373 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 120/1194 | Loss: 292.867 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 130/1194 | Loss: 286.474 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 140/1194 | Loss: 301.445 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 150/1194 | Loss: 287.627 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 160/1194 | Loss: 298.943 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 170/1194 | Loss: 275.236 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 180/1194 | Loss: 292.445 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 190/1194 | Loss: 301.853 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 200/1194 | Loss: 304.902 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 210/1194 | Loss: 301.276 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 220/1194 | Loss: 275.870 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 230/1194 | Loss: 302.024 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 240/1194 | Loss: 311.684 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 250/1194 | Loss: 299.506 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 260/1194 | Loss: 305.871 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 270/1194 | Loss: 288.198 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 280/1194 | Loss: 316.138 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 290/1194 | Loss: 300.490 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 300/1194 | Loss: 279.842 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 310/1194 | Loss: 295.050 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 320/1194 | Loss: 300.010 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 330/1194 | Loss: 290.886 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 340/1194 | Loss: 287.717 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 350/1194 | Loss: 310.319 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 360/1194 | Loss: 298.301 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 370/1194 | Loss: 292.126 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 380/1194 | Loss: 314.826 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 390/1194 | Loss: 312.195 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 400/1194 | Loss: 284.574 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 410/1194 | Loss: 273.333 | Accuracy: 0.400\n",
      "[Epoch: 196/200] - Step: 420/1194 | Loss: 303.592 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 430/1194 | Loss: 297.402 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 440/1194 | Loss: 287.017 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 450/1194 | Loss: 297.120 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 460/1194 | Loss: 299.087 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 470/1194 | Loss: 300.959 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 480/1194 | Loss: 319.847 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 490/1194 | Loss: 290.117 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 500/1194 | Loss: 305.980 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 510/1194 | Loss: 300.601 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 520/1194 | Loss: 303.355 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 530/1194 | Loss: 295.300 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 540/1194 | Loss: 319.593 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 550/1194 | Loss: 308.090 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 560/1194 | Loss: 293.030 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 570/1194 | Loss: 298.049 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 580/1194 | Loss: 286.148 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 590/1194 | Loss: 303.315 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 600/1194 | Loss: 304.804 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 610/1194 | Loss: 281.603 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 620/1194 | Loss: 332.715 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 630/1194 | Loss: 284.100 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 640/1194 | Loss: 300.058 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 650/1194 | Loss: 309.522 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 660/1194 | Loss: 293.204 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 670/1194 | Loss: 291.808 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 680/1194 | Loss: 300.334 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 690/1194 | Loss: 296.845 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 700/1194 | Loss: 315.882 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 710/1194 | Loss: 332.413 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 720/1194 | Loss: 295.225 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 730/1194 | Loss: 290.723 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 740/1194 | Loss: 295.760 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 750/1194 | Loss: 300.136 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 760/1194 | Loss: 298.977 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 770/1194 | Loss: 290.638 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 780/1194 | Loss: 291.495 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 790/1194 | Loss: 290.306 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 800/1194 | Loss: 297.433 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 810/1194 | Loss: 303.901 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 820/1194 | Loss: 269.883 | Accuracy: 0.400\n",
      "[Epoch: 196/200] - Step: 830/1194 | Loss: 292.889 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 840/1194 | Loss: 301.343 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 850/1194 | Loss: 285.853 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 860/1194 | Loss: 293.311 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 870/1194 | Loss: 301.122 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 880/1194 | Loss: 310.736 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 890/1194 | Loss: 288.591 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 900/1194 | Loss: 312.428 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 910/1194 | Loss: 302.026 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 920/1194 | Loss: 291.038 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 930/1194 | Loss: 294.592 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 940/1194 | Loss: 302.043 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 950/1194 | Loss: 287.596 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 960/1194 | Loss: 275.509 | Accuracy: 0.300\n",
      "[Epoch: 196/200] - Step: 970/1194 | Loss: 299.267 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 980/1194 | Loss: 302.005 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 990/1194 | Loss: 278.525 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1000/1194 | Loss: 293.742 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1010/1194 | Loss: 291.292 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1020/1194 | Loss: 294.013 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1030/1194 | Loss: 299.054 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 1040/1194 | Loss: 280.454 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1050/1194 | Loss: 292.505 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1060/1194 | Loss: 296.680 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1070/1194 | Loss: 283.038 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1080/1194 | Loss: 313.449 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 1090/1194 | Loss: 298.191 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1100/1194 | Loss: 270.223 | Accuracy: 0.400\n",
      "[Epoch: 196/200] - Step: 1110/1194 | Loss: 288.004 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1120/1194 | Loss: 300.090 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 1130/1194 | Loss: 299.250 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1140/1194 | Loss: 295.629 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1150/1194 | Loss: 286.323 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1160/1194 | Loss: 292.604 | Accuracy: 0.200\n",
      "[Epoch: 196/200] - Step: 1170/1194 | Loss: 308.209 | Accuracy: 0.000\n",
      "[Epoch: 196/200] - Step: 1180/1194 | Loss: 289.873 | Accuracy: 0.100\n",
      "[Epoch: 196/200] - Step: 1190/1194 | Loss: 272.689 | Accuracy: 0.300\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 197/200] - Step: 10/1194 | Loss: 293.166 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 20/1194 | Loss: 295.360 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 30/1194 | Loss: 294.391 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 40/1194 | Loss: 293.993 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 50/1194 | Loss: 291.637 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 60/1194 | Loss: 301.550 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 70/1194 | Loss: 299.126 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 80/1194 | Loss: 300.176 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 90/1194 | Loss: 289.445 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 100/1194 | Loss: 292.231 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 110/1194 | Loss: 300.201 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 120/1194 | Loss: 297.024 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 130/1194 | Loss: 288.405 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 140/1194 | Loss: 313.209 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 150/1194 | Loss: 340.537 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 160/1194 | Loss: 305.255 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 170/1194 | Loss: 277.532 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 180/1194 | Loss: 289.286 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 190/1194 | Loss: 309.716 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 200/1194 | Loss: 280.786 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 210/1194 | Loss: 311.725 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 220/1194 | Loss: 278.754 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 230/1194 | Loss: 308.782 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 240/1194 | Loss: 293.364 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 250/1194 | Loss: 296.881 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 260/1194 | Loss: 269.456 | Accuracy: 0.400\n",
      "[Epoch: 197/200] - Step: 270/1194 | Loss: 288.192 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 280/1194 | Loss: 292.170 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 290/1194 | Loss: 303.264 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 300/1194 | Loss: 288.989 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 310/1194 | Loss: 277.499 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 320/1194 | Loss: 287.553 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 330/1194 | Loss: 289.234 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 340/1194 | Loss: 293.228 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 350/1194 | Loss: 278.113 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 360/1194 | Loss: 340.357 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 370/1194 | Loss: 289.574 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 380/1194 | Loss: 299.489 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 390/1194 | Loss: 281.023 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 400/1194 | Loss: 291.971 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 410/1194 | Loss: 304.743 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 420/1194 | Loss: 300.579 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 430/1194 | Loss: 280.282 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 440/1194 | Loss: 301.300 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 450/1194 | Loss: 292.893 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 460/1194 | Loss: 282.361 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 470/1194 | Loss: 305.368 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 480/1194 | Loss: 300.671 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 490/1194 | Loss: 287.746 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 500/1194 | Loss: 298.762 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 510/1194 | Loss: 301.346 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 520/1194 | Loss: 288.272 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 530/1194 | Loss: 309.840 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 540/1194 | Loss: 280.898 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 550/1194 | Loss: 291.504 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 560/1194 | Loss: 314.587 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 570/1194 | Loss: 317.594 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 580/1194 | Loss: 295.101 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 590/1194 | Loss: 305.152 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 600/1194 | Loss: 304.357 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 610/1194 | Loss: 290.477 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 620/1194 | Loss: 330.802 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 630/1194 | Loss: 294.919 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 640/1194 | Loss: 287.960 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 650/1194 | Loss: 299.009 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 660/1194 | Loss: 302.506 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 670/1194 | Loss: 296.405 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 680/1194 | Loss: 293.766 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 690/1194 | Loss: 307.473 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 700/1194 | Loss: 287.178 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 710/1194 | Loss: 299.273 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 720/1194 | Loss: 288.245 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 730/1194 | Loss: 305.543 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 740/1194 | Loss: 306.895 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 750/1194 | Loss: 291.536 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 760/1194 | Loss: 308.916 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 770/1194 | Loss: 295.036 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 780/1194 | Loss: 284.379 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 790/1194 | Loss: 293.377 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 800/1194 | Loss: 310.615 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 810/1194 | Loss: 301.504 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 820/1194 | Loss: 330.170 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 830/1194 | Loss: 290.845 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 840/1194 | Loss: 312.672 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 850/1194 | Loss: 295.872 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 860/1194 | Loss: 279.423 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 870/1194 | Loss: 304.521 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 880/1194 | Loss: 291.639 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 890/1194 | Loss: 283.354 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 900/1194 | Loss: 300.418 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 910/1194 | Loss: 266.205 | Accuracy: 0.400\n",
      "[Epoch: 197/200] - Step: 920/1194 | Loss: 293.885 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 930/1194 | Loss: 305.524 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 940/1194 | Loss: 291.140 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 950/1194 | Loss: 301.725 | Accuracy: 0.200\n",
      "[Epoch: 197/200] - Step: 960/1194 | Loss: 309.687 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 970/1194 | Loss: 298.112 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 980/1194 | Loss: 281.165 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 990/1194 | Loss: 302.652 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1000/1194 | Loss: 302.563 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1010/1194 | Loss: 300.067 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1020/1194 | Loss: 283.478 | Accuracy: 0.500\n",
      "[Epoch: 197/200] - Step: 1030/1194 | Loss: 295.649 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1040/1194 | Loss: 295.577 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 1050/1194 | Loss: 299.929 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1060/1194 | Loss: 297.045 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1070/1194 | Loss: 302.933 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 1080/1194 | Loss: 297.567 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 1090/1194 | Loss: 327.077 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1100/1194 | Loss: 290.514 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1110/1194 | Loss: 292.028 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1120/1194 | Loss: 301.439 | Accuracy: 0.000\n",
      "[Epoch: 197/200] - Step: 1130/1194 | Loss: 291.516 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1140/1194 | Loss: 298.214 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1150/1194 | Loss: 289.765 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1160/1194 | Loss: 281.875 | Accuracy: 0.300\n",
      "[Epoch: 197/200] - Step: 1170/1194 | Loss: 296.278 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1180/1194 | Loss: 290.928 | Accuracy: 0.100\n",
      "[Epoch: 197/200] - Step: 1190/1194 | Loss: 289.466 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 198/200] - Step: 10/1194 | Loss: 289.500 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 20/1194 | Loss: 310.335 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 30/1194 | Loss: 282.045 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 40/1194 | Loss: 293.179 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 50/1194 | Loss: 304.494 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 60/1194 | Loss: 313.473 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 70/1194 | Loss: 294.284 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 80/1194 | Loss: 329.658 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 90/1194 | Loss: 288.761 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 100/1194 | Loss: 272.704 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 110/1194 | Loss: 305.217 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 120/1194 | Loss: 291.300 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 130/1194 | Loss: 274.663 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 140/1194 | Loss: 287.295 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 150/1194 | Loss: 333.829 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 160/1194 | Loss: 290.681 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 170/1194 | Loss: 301.158 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 180/1194 | Loss: 276.365 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 190/1194 | Loss: 295.375 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 200/1194 | Loss: 307.276 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 210/1194 | Loss: 298.252 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 220/1194 | Loss: 276.282 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 230/1194 | Loss: 303.277 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 240/1194 | Loss: 298.766 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 250/1194 | Loss: 289.206 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 260/1194 | Loss: 300.508 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 270/1194 | Loss: 297.744 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 280/1194 | Loss: 297.890 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 290/1194 | Loss: 303.147 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 300/1194 | Loss: 295.919 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 310/1194 | Loss: 298.837 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 320/1194 | Loss: 320.076 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 330/1194 | Loss: 281.460 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 340/1194 | Loss: 287.847 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 350/1194 | Loss: 281.031 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 360/1194 | Loss: 299.821 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 370/1194 | Loss: 307.357 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 380/1194 | Loss: 284.393 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 390/1194 | Loss: 306.140 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 400/1194 | Loss: 307.677 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 410/1194 | Loss: 279.765 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 420/1194 | Loss: 295.445 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 430/1194 | Loss: 289.554 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 440/1194 | Loss: 287.327 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 450/1194 | Loss: 298.508 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 460/1194 | Loss: 291.014 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 470/1194 | Loss: 289.024 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 480/1194 | Loss: 300.013 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 490/1194 | Loss: 296.753 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 500/1194 | Loss: 290.368 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 510/1194 | Loss: 314.811 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 520/1194 | Loss: 301.953 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 530/1194 | Loss: 272.491 | Accuracy: 0.400\n",
      "[Epoch: 198/200] - Step: 540/1194 | Loss: 301.823 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 550/1194 | Loss: 293.345 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 560/1194 | Loss: 331.123 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 570/1194 | Loss: 284.567 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 580/1194 | Loss: 283.058 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 590/1194 | Loss: 295.803 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 600/1194 | Loss: 281.502 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 610/1194 | Loss: 280.323 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 620/1194 | Loss: 286.629 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 630/1194 | Loss: 281.131 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 640/1194 | Loss: 314.226 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 650/1194 | Loss: 299.228 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 660/1194 | Loss: 301.676 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 670/1194 | Loss: 282.437 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 680/1194 | Loss: 307.039 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 690/1194 | Loss: 282.006 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 700/1194 | Loss: 304.819 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 710/1194 | Loss: 281.190 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 720/1194 | Loss: 303.128 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 730/1194 | Loss: 291.924 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 740/1194 | Loss: 294.004 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 750/1194 | Loss: 286.177 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 760/1194 | Loss: 303.624 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 770/1194 | Loss: 294.748 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 780/1194 | Loss: 298.465 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 790/1194 | Loss: 346.628 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 800/1194 | Loss: 289.556 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 810/1194 | Loss: 299.017 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 820/1194 | Loss: 278.792 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 830/1194 | Loss: 313.923 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 840/1194 | Loss: 296.806 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 850/1194 | Loss: 331.422 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 860/1194 | Loss: 285.798 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 870/1194 | Loss: 303.440 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 880/1194 | Loss: 304.380 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 890/1194 | Loss: 313.652 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 900/1194 | Loss: 294.419 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 910/1194 | Loss: 310.654 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 920/1194 | Loss: 304.866 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 930/1194 | Loss: 288.577 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 940/1194 | Loss: 309.759 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 950/1194 | Loss: 303.110 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 960/1194 | Loss: 309.128 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 970/1194 | Loss: 311.919 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 980/1194 | Loss: 282.466 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 990/1194 | Loss: 273.162 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 1000/1194 | Loss: 294.028 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1010/1194 | Loss: 291.141 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 1020/1194 | Loss: 303.980 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1030/1194 | Loss: 311.212 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1040/1194 | Loss: 290.470 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1050/1194 | Loss: 308.394 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1060/1194 | Loss: 297.317 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1070/1194 | Loss: 306.606 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1080/1194 | Loss: 310.010 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1090/1194 | Loss: 291.071 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1100/1194 | Loss: 309.863 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1110/1194 | Loss: 274.347 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 1120/1194 | Loss: 279.108 | Accuracy: 0.300\n",
      "[Epoch: 198/200] - Step: 1130/1194 | Loss: 287.974 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1140/1194 | Loss: 297.220 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1150/1194 | Loss: 287.812 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1160/1194 | Loss: 282.964 | Accuracy: 0.200\n",
      "[Epoch: 198/200] - Step: 1170/1194 | Loss: 294.553 | Accuracy: 0.100\n",
      "[Epoch: 198/200] - Step: 1180/1194 | Loss: 311.350 | Accuracy: 0.000\n",
      "[Epoch: 198/200] - Step: 1190/1194 | Loss: 287.107 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 199/200] - Step: 10/1194 | Loss: 328.467 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 20/1194 | Loss: 277.417 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 30/1194 | Loss: 292.269 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 40/1194 | Loss: 291.392 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 50/1194 | Loss: 322.273 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 60/1194 | Loss: 311.313 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 70/1194 | Loss: 277.377 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 80/1194 | Loss: 308.437 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 90/1194 | Loss: 289.924 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 100/1194 | Loss: 304.974 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 110/1194 | Loss: 292.422 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 120/1194 | Loss: 302.560 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 130/1194 | Loss: 279.760 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 140/1194 | Loss: 302.438 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 150/1194 | Loss: 307.262 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 160/1194 | Loss: 316.608 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 170/1194 | Loss: 295.024 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 180/1194 | Loss: 283.872 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 190/1194 | Loss: 299.973 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 200/1194 | Loss: 306.819 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 210/1194 | Loss: 276.422 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 220/1194 | Loss: 283.606 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 230/1194 | Loss: 270.738 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 240/1194 | Loss: 297.058 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 250/1194 | Loss: 313.674 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 260/1194 | Loss: 299.759 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 270/1194 | Loss: 283.821 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 280/1194 | Loss: 293.117 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 290/1194 | Loss: 282.641 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 300/1194 | Loss: 311.208 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 310/1194 | Loss: 297.438 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 320/1194 | Loss: 273.423 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 330/1194 | Loss: 287.390 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 340/1194 | Loss: 278.769 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 350/1194 | Loss: 283.484 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 360/1194 | Loss: 290.866 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 370/1194 | Loss: 298.826 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 380/1194 | Loss: 303.853 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 390/1194 | Loss: 311.735 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 400/1194 | Loss: 286.322 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 410/1194 | Loss: 312.558 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 420/1194 | Loss: 295.533 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 430/1194 | Loss: 301.040 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 440/1194 | Loss: 298.176 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 450/1194 | Loss: 290.481 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 460/1194 | Loss: 298.637 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 470/1194 | Loss: 285.873 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 480/1194 | Loss: 283.183 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 490/1194 | Loss: 303.437 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 500/1194 | Loss: 297.685 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 510/1194 | Loss: 324.290 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 520/1194 | Loss: 296.231 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 530/1194 | Loss: 291.831 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 540/1194 | Loss: 300.376 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 550/1194 | Loss: 289.691 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 560/1194 | Loss: 295.561 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 570/1194 | Loss: 298.122 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 580/1194 | Loss: 292.245 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 590/1194 | Loss: 312.997 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 600/1194 | Loss: 294.412 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 610/1194 | Loss: 295.710 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 620/1194 | Loss: 302.589 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 630/1194 | Loss: 306.197 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 640/1194 | Loss: 265.749 | Accuracy: 0.400\n",
      "[Epoch: 199/200] - Step: 650/1194 | Loss: 304.881 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 660/1194 | Loss: 317.874 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 670/1194 | Loss: 301.503 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 680/1194 | Loss: 303.904 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 690/1194 | Loss: 320.500 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 700/1194 | Loss: 304.570 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 710/1194 | Loss: 304.329 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 720/1194 | Loss: 299.749 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 730/1194 | Loss: 286.790 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 740/1194 | Loss: 291.143 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 750/1194 | Loss: 301.655 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 760/1194 | Loss: 278.424 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 770/1194 | Loss: 279.829 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 780/1194 | Loss: 300.277 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 790/1194 | Loss: 298.795 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 800/1194 | Loss: 282.559 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 810/1194 | Loss: 302.327 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 820/1194 | Loss: 302.865 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 830/1194 | Loss: 284.123 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 840/1194 | Loss: 283.169 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 850/1194 | Loss: 308.317 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 860/1194 | Loss: 292.720 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 870/1194 | Loss: 303.896 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 880/1194 | Loss: 296.381 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 890/1194 | Loss: 291.870 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 900/1194 | Loss: 275.986 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 910/1194 | Loss: 275.145 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 920/1194 | Loss: 302.199 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 930/1194 | Loss: 297.420 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 940/1194 | Loss: 287.156 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 950/1194 | Loss: 303.540 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 960/1194 | Loss: 344.357 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 970/1194 | Loss: 284.468 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 980/1194 | Loss: 300.443 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 990/1194 | Loss: 296.622 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1000/1194 | Loss: 289.316 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 1010/1194 | Loss: 292.145 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1020/1194 | Loss: 307.857 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1030/1194 | Loss: 298.520 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1040/1194 | Loss: 313.672 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1050/1194 | Loss: 296.453 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1060/1194 | Loss: 314.253 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1070/1194 | Loss: 300.725 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1080/1194 | Loss: 313.640 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1090/1194 | Loss: 307.753 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1100/1194 | Loss: 295.534 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1110/1194 | Loss: 307.423 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1120/1194 | Loss: 289.474 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1130/1194 | Loss: 275.969 | Accuracy: 0.300\n",
      "[Epoch: 199/200] - Step: 1140/1194 | Loss: 297.124 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1150/1194 | Loss: 293.466 | Accuracy: 0.100\n",
      "[Epoch: 199/200] - Step: 1160/1194 | Loss: 290.487 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1170/1194 | Loss: 290.502 | Accuracy: 0.200\n",
      "[Epoch: 199/200] - Step: 1180/1194 | Loss: 312.238 | Accuracy: 0.000\n",
      "[Epoch: 199/200] - Step: 1190/1194 | Loss: 286.468 | Accuracy: 0.200\n",
      "Accuracy:  0.10491803278688525\n",
      "[Epoch: 200/200] - Step: 10/1194 | Loss: 279.864 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 20/1194 | Loss: 278.441 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 30/1194 | Loss: 305.772 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 40/1194 | Loss: 278.626 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 50/1194 | Loss: 289.593 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 60/1194 | Loss: 293.534 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 70/1194 | Loss: 316.157 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 80/1194 | Loss: 312.242 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 90/1194 | Loss: 265.088 | Accuracy: 0.400\n",
      "[Epoch: 200/200] - Step: 100/1194 | Loss: 312.526 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 110/1194 | Loss: 293.264 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 120/1194 | Loss: 281.282 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 130/1194 | Loss: 314.071 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 140/1194 | Loss: 284.828 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 150/1194 | Loss: 302.765 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 160/1194 | Loss: 304.015 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 170/1194 | Loss: 292.614 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 180/1194 | Loss: 317.126 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 190/1194 | Loss: 312.705 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 200/1194 | Loss: 295.780 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 210/1194 | Loss: 306.970 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 220/1194 | Loss: 280.721 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 230/1194 | Loss: 277.043 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 240/1194 | Loss: 301.437 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 250/1194 | Loss: 290.291 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 260/1194 | Loss: 287.513 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 270/1194 | Loss: 295.584 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 280/1194 | Loss: 282.310 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 290/1194 | Loss: 302.964 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 300/1194 | Loss: 337.805 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 310/1194 | Loss: 294.677 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 320/1194 | Loss: 307.579 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 330/1194 | Loss: 293.836 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 340/1194 | Loss: 308.144 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 350/1194 | Loss: 287.778 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 360/1194 | Loss: 287.045 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 370/1194 | Loss: 305.806 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 380/1194 | Loss: 283.108 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 390/1194 | Loss: 299.849 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 400/1194 | Loss: 297.991 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 410/1194 | Loss: 298.599 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 420/1194 | Loss: 288.741 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 430/1194 | Loss: 312.791 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 440/1194 | Loss: 293.035 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 450/1194 | Loss: 301.152 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 460/1194 | Loss: 295.780 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 470/1194 | Loss: 279.897 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 480/1194 | Loss: 306.673 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 490/1194 | Loss: 295.903 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 500/1194 | Loss: 287.980 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 510/1194 | Loss: 287.987 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 520/1194 | Loss: 290.804 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 530/1194 | Loss: 307.793 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 540/1194 | Loss: 324.235 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 550/1194 | Loss: 302.144 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 560/1194 | Loss: 315.168 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 570/1194 | Loss: 290.684 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 580/1194 | Loss: 309.544 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 590/1194 | Loss: 293.508 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 600/1194 | Loss: 291.530 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 610/1194 | Loss: 277.157 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 620/1194 | Loss: 291.369 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 630/1194 | Loss: 286.884 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 640/1194 | Loss: 272.892 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 650/1194 | Loss: 318.709 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 660/1194 | Loss: 301.846 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 670/1194 | Loss: 306.775 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 680/1194 | Loss: 303.918 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 690/1194 | Loss: 288.422 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 700/1194 | Loss: 291.737 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 710/1194 | Loss: 291.956 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 720/1194 | Loss: 293.720 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 730/1194 | Loss: 289.077 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 740/1194 | Loss: 271.144 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 750/1194 | Loss: 303.119 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 760/1194 | Loss: 299.214 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 770/1194 | Loss: 298.304 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 780/1194 | Loss: 295.435 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 790/1194 | Loss: 333.728 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 800/1194 | Loss: 284.661 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 810/1194 | Loss: 295.598 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 820/1194 | Loss: 297.745 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 830/1194 | Loss: 307.995 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 840/1194 | Loss: 297.768 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 850/1194 | Loss: 297.626 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 860/1194 | Loss: 304.598 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 870/1194 | Loss: 297.341 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 880/1194 | Loss: 278.576 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 890/1194 | Loss: 301.263 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 900/1194 | Loss: 302.934 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 910/1194 | Loss: 280.912 | Accuracy: 0.300\n",
      "[Epoch: 200/200] - Step: 920/1194 | Loss: 330.651 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 930/1194 | Loss: 296.969 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 940/1194 | Loss: 293.691 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 950/1194 | Loss: 286.674 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 960/1194 | Loss: 304.286 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 970/1194 | Loss: 298.075 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 980/1194 | Loss: 298.581 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 990/1194 | Loss: 296.307 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1000/1194 | Loss: 268.532 | Accuracy: 0.500\n",
      "[Epoch: 200/200] - Step: 1010/1194 | Loss: 306.681 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1020/1194 | Loss: 297.132 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 1030/1194 | Loss: 282.305 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 1040/1194 | Loss: 292.097 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 1050/1194 | Loss: 282.700 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1060/1194 | Loss: 298.600 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1070/1194 | Loss: 315.881 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1080/1194 | Loss: 301.275 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1090/1194 | Loss: 284.979 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 1100/1194 | Loss: 300.475 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1110/1194 | Loss: 309.265 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1120/1194 | Loss: 294.043 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1130/1194 | Loss: 300.964 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1140/1194 | Loss: 288.591 | Accuracy: 0.200\n",
      "[Epoch: 200/200] - Step: 1150/1194 | Loss: 304.683 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1160/1194 | Loss: 291.473 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1170/1194 | Loss: 306.426 | Accuracy: 0.000\n",
      "[Epoch: 200/200] - Step: 1180/1194 | Loss: 287.155 | Accuracy: 0.100\n",
      "[Epoch: 200/200] - Step: 1190/1194 | Loss: 318.930 | Accuracy: 0.000\n",
      "Accuracy:  0.10491803278688525\n",
      "Training completed in:  41.79318867971611  hours\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/br-python/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1049\n",
      "Precision: 0.0110\n",
      "Recall: 0.1049\n",
      "F1 Score: 0.0199\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0-10       0.00      0.00      0.00         0\n",
      "       10-20       0.00      0.00      0.00         0\n",
      "       20-30       0.00      0.00      0.00         0\n",
      "       30-40       0.00      0.00      0.00         4\n",
      "       40-50       0.00      0.00      0.00        22\n",
      "       50-60       0.00      0.00      0.00        13\n",
      "       60-70       0.00      0.00      0.00        12\n",
      "       70-80       0.00      0.00      0.00        20\n",
      "       80-90       0.00      0.00      0.00        14\n",
      "      90-100       0.00      0.00      0.00         8\n",
      "     100-110       0.00      0.00      0.00        17\n",
      "     110-120       0.00      0.00      0.00        11\n",
      "     120-130       0.00      0.00      0.00        10\n",
      "     130-140       0.00      0.00      0.00         9\n",
      "     140-150       0.00      0.00      0.00        10\n",
      "     150-160       0.00      0.00      0.00        16\n",
      "     160-170       0.00      0.00      0.00        15\n",
      "     170-180       0.00      0.00      0.00        10\n",
      "     180-190       0.00      0.00      0.00        15\n",
      "     190-200       0.00      0.00      0.00        15\n",
      "     200-210       0.00      0.00      0.00        21\n",
      "     210-220       0.00      0.00      0.00        22\n",
      "     220-230       0.10      1.00      0.19        32\n",
      "     230-240       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.10      0.10      0.10       305\n",
      "   macro avg       0.00      0.04      0.01       305\n",
      "weighted avg       0.01      0.10      0.02       305\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAALnCAYAAABFk+LMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzde1xU5eIu8GdEGJGbMMTAmBcMLBFDRDMw846iYpaZRtvEC0pYinexMnTvwFvWLm/bMjUzcRdplpewn4kZWIhiedmWhbdkQuSiIg4X5/zhYeXiOggya96e7/msz/n5rjXrWc/0O+fj67tmLZXRaDSCiIiIiIhIAE3MfQFEREREREQNhRMcIiIiIiISBic4REREREQkDE5wiIiIiIhIGJzgEBERERGRMDjBISIiIiIiYXCCQ0REREREwuAEh4iIiIiIhMEJDhERERERCYMTHCKiBvLTTz9h3Lhx8PT0RLNmzWBvb48uXbpg6dKlyM3Nva/Zx44dQ69eveDk5ASVSoV33nmnwTNUKhViY2Mb/Ly12bhxI1QqFVQqFQ4cOFBpv9FohJeXF1QqFXr37n1PGatXr8bGjRvr9JkDBw5Ue01ERGQ+Tc19AUREInj//fcRFRWFhx9+GLNnz4aPjw9KSkpw5MgRrF27Fqmpqdi+fft9yx8/fjwKCwuRkJAAZ2dntG3btsEzUlNT8eCDDzb4eU3l4OCA9evXV5rEJCcn47fffoODg8M9n3v16tVwdXVFeHi4yZ/p0qULUlNT4ePjc8+5RETU8DjBISKqp9TUVLz00ksYMGAAduzYAbVaLe0bMGAAZs6cib17997Xazhx4gQiIiIQEhJy3zIef/zx+3ZuU4waNQpbtmzBqlWr4OjoKI2vX78egYGBuHbtWqNcR0lJCVQqFRwdHc3+nRARUWW8RY2IqJ7i4uKgUqmwbt062eSmnI2NDYYNGyb9+fbt21i6dCkeeeQRqNVquLm54cUXX8SlS5dkn+vduzd8fX2RlpaGnj17onnz5mjXrh0WL16M27dvA/jr9q3S0lKsWbNGupULAGJjY6X/+W7lnzl37pw0tn//fvTu3RsajQa2trZo3bo1RowYgZs3b0rHVHWL2okTJ/DUU0/B2dkZzZo1Q+fOnbFp0ybZMeW3cm3duhWvvvoqdDodHB0d0b9/f5w5c8a0LxnA888/DwDYunWrNFZQUIDExESMHz++ys8sXLgQ3bt3h4uLCxwdHdGlSxesX78eRqNROqZt27Y4efIkkpOTpe+vfAWs/No3b96MmTNnomXLllCr1Th79mylW9RycnLQqlUrBAUFoaSkRDr/qVOnYGdnhzFjxpjclYiI7h0nOERE9VBWVob9+/cjICAArVq1MukzL730EubOnYsBAwZg586d+Oc//4m9e/ciKCgIOTk5smP1ej1eeOEF/OMf/8DOnTsREhKCmJgYfPzxxwCAIUOGIDU1FQDw7LPPIjU1Vfqzqc6dO4chQ4bAxsYGH374Ifbu3YvFixfDzs4OxcXF1X7uzJkzCAoKwsmTJ/Huu+/i888/h4+PD8LDw7F06dJKx8+fPx/nz5/HBx98gHXr1uHXX39FaGgoysrKTLpOR0dHPPvss/jwww+lsa1bt6JJkyYYNWpUtd0mT56M//73v/j888/xzDPP4JVXXsE///lP6Zjt27ejXbt28Pf3l76/ircTxsTE4MKFC1i7di2+/PJLuLm5VcpydXVFQkIC0tLSMHfuXADAzZs3MXLkSLRu3Rpr1641qScREdUPb1EjIqqHnJwc3Lx5E56eniYd/7///Q/r1q1DVFQU3nvvPWnc398f3bt3x9tvv40333xTGr969Sp2796Nxx57DADQv39/HDhwAJ988glefPFFPPDAA3jggQcAAFqt9p5umUpPT8etW7ewbNky+Pn5SeNhYWE1fi42NhbFxcX49ttvpcnd4MGDkZ+fj4ULF2Ly5MlwcnKSjvfx8ZEmZgBgZWWF5557DmlpaSZf9/jx49GnTx+cPHkSHTt2xIcffoiRI0dW+/ubDRs2SP/z7du30bt3bxiNRvz73//G66+/DpVKBX9/f9ja2tZ4y9lDDz2ETz/9tNbr69GjB958803MnTsXTz75JHbs2IHMzEz88MMPsLOzM6kjERHVD1dwiIga0bfffgsAlX7M/thjj6FDhw74v//7P9m4u7u7NLkp9+ijj+L8+fMNdk2dO3eGjY0NJk2ahE2bNuH333836XP79+9Hv379Kq1chYeH4+bNm5VWku6+TQ+40wNAnbr06tULDz30ED788EP8/PPPSEtLq/b2tPJr7N+/P5ycnGBlZQVra2ssWLAAV69eRXZ2tsm5I0aMMPnY2bNnY8iQIXj++eexadMmvPfee+jUqZPJnyciovrhBIeIqB5cXV3RvHlzZGZmmnT81atXAQAeHh6V9ul0Oml/OY1GU+k4tVqNoqKie7jaqj300EP45ptv4ObmhilTpuChhx7CQw89hH//+981fu7q1avV9ijff7eKXcp/r1SXLiqVCuPGjcPHH3+MtWvXon379ujZs2eVx/74448IDg4GcOcpd99//z3S0tLw6quv1jm3qp41XWN4eDhu3boFd3d3/vaGiKiRcYJDRFQPVlZW6NevH9LT0ys9JKAq5X/Jz8rKqrTv8uXLcHV1bbBra9asGQDAYDDIxiv+zgcAevbsiS+//BIFBQU4fPgwAgMDER0djYSEhGrPr9Foqu0BoEG73C08PBw5OTlYu3Ytxo0bV+1xCQkJsLa2xldffYXnnnsOQUFB6Nq16z1lVvWwhupkZWVhypQp6Ny5M65evYpZs2bdUyYREd0bTnCIiOopJiYGRqMRERERVf4ov6SkBF9++SUAoG/fvgAg+y0KAKSlpeH06dPo169fg11X+ZPAfvrpJ9l4+bVUxcrKCt27d8eqVasAAEePHq322H79+mH//v3ShKbcRx99hObNm9+3Ryi3bNkSs2fPRmhoKMaOHVvtcSqVCk2bNoWVlZU0VlRUhM2bN1c6tqFWxcrKyvD8889DpVJhz549iI+Px3vvvYfPP/+83ucmIiLT8CEDRET1FBgYiDVr1iAqKgoBAQF46aWX0LFjR5SUlODYsWNYt24dfH19ERoaiocffhiTJk3Ce++9hyZNmiAkJATnzp3D66+/jlatWmH69OkNdl2DBw+Gi4sLJkyYgEWLFqFp06bYuHEjLl68KDtu7dq12L9/P4YMGYLWrVvj1q1b0pPK+vfvX+3533jjDXz11Vfo06cPFixYABcXF2zZsgW7du3C0qVLZQ8YaGiLFy+u9ZghQ4ZgxYoVCAsLw6RJk3D16lUsX768ykd5d+rUCQkJCdi2bRvatWuHZs2a3dPvZt544w189913SEpKgru7O2bOnInk5GRMmDAB/v7+Jj+MgoiI7h0nOEREDSAiIgKPPfYY3n77bSxZsgR6vR7W1tZo3749wsLC8PLLL0vHrlmzBg899BDWr1+PVatWwcnJCYMGDUJ8fHyVv7m5V46Ojti7dy+io6Pxj3/8Ay1atMDEiRMREhKCiRMnSsd17twZSUlJeOONN6DX62Fvbw9fX1/s3LlT+g1LVR5++GGkpKRg/vz5mDJlCoqKitChQwds2LCh0kMUzKFv37748MMPsWTJEoSGhqJly5aIiIiAm5sbJkyYIDt24cKFyMrKQkREBK5fv442bdrI3hNkin379iE+Ph6vv/66bCVu48aN8Pf3x6hRo3Do0CHY2Ng0RD0iIqqGynj3286IiIiIiIgsGH+DQ0REREREwuAEh4iIiIiIhMEJDhERERERCYMTHCIiIiIiEgYnOEREREREJAxOcIiIiIiISBic4BARERERkTD4ok8FuFVq7isgIiIiopo0U/Dfmm39X679oPuk6NhKs2VXhys4REREREQkDAXPRYmIiIiIqFYqrlncjd8GEREREREJgys4RERERESWTKUy9xUoCldwiIiIiIhIGJzgEBERERGRMP5WE5zVq1fD09MTzZo1Q0BAAL777rsaj1+3bh169+4NR0dHqFQq5OfnVzomLy8PY8aMgZOTE5ycnDBmzJgqj2tI27ZuQUhwX3Tz74TRI5/B0fQjFpsjUhfmKDtHpC7MUXaOSF2Yo+wckbqImNOoVE3MtymQMq/qPti2bRuio6Px6quv4tixY+jZsydCQkJw4cKFaj9z8+ZNDBo0CPPnz6/2mLCwMGRkZGDv3r3Yu3cvMjIyMGbMmPtRAQCwd89uLF0cj4hJL2HbZzvQpUsAoiZHIOvyZYvLEakLc5SdI1IX5ig7R6QuzFF2jkhdRMwh81IZjUajuS+iMXTv3h1dunTBmjVrpLEOHTpg+PDhiI+Pr/GzBw4cQJ8+fZCXl4cWLVpI46dPn4aPjw8OHz6M7t27AwAOHz6MwMBA/O9//8PDDz9s0rXV5UWfL4weiQ4+PnhtwUJpbHhoCPr07Y9p02eafiIF5IjUhTnKzhGpC3OUnSNSF+YoO0ekLpaSo+gXfXabYbbsorQVZsuuzt9iBae4uBjp6ekIDg6WjQcHByMlJeWez5uamgonJydpcgMAjz/+OJycnOp13uqUFBfj9KmTCAx6QjYeGNQDxzOOWVSOSF2Yo+wckbowR9k5InVhjrJzROoiYg6Zn4Lnog0nJycHZWVl0Gq1snGtVgu9Xn/P59Xr9XBzc6s07ubmVu15DQYDDAaDbMxopYZara41Ly8/D2VlZdBoNLJxjcYVOTlX6nDl5s8RqQtzlJ0jUhfmKDtHpC7MUXaOSF1EzCHz+1us4JRTVXhGuNFohEqlQlxcHOzt7aWtpt/l1HbOu89blfj4eOmBBOXbsiU13yJnao+G1hg5InVhjrJzROrCHGXniNSFOcrOEamLiDmNig8ZkPlbrOC4urrCysqq0qpKdnY2tFotIiMj8dxzz0njOp3OpPO6u7vjzz//rDR+5cqVSqtF5WJiYjBjhvw+SaNV7as3AODcwhlWVlbIycmRjefmXoVG42rSOZSSI1IX5ig7R6QuzFF2jkhdmKPsHJG6iJhD5qfMaVcDs7GxQUBAAPbt2ycb37dvH4KCguDi4gIvLy9pa9rUtHlfYGAgCgoK8OOPP0pjP/zwAwoKChAUFFTlZ9RqNRwdHWWbKbenAYC1jQ06+HTE4ZTvZeOHU1Lg19nfpHMoJUekLsxRdo5IXZij7ByRujBH2TkidRExxyxUKvNtCvS3WMEBgBkzZmDMmDHo2rUrAgMDsW7dOly4cAGRkZHVfkav10Ov1+Ps2bMAgJ9//hkODg5o3bo1XFxc0KFDBwwaNAgRERH4z3/+AwCYNGkShg4davIT1OpqzNhxeHXeHPj4+sLPzx+Jn25DVlYWRo4abXE5InVhjrJzROrCHGXniNSFOcrOEamLiDlkXn+bCc6oUaNw9epVLFq0CFlZWfD19cXu3bvRpk2baj+zdu1aLFz412MEn3zySQDAhg0bEB4eDgDYsmULpk6dKj2hbdiwYVi5cuV96zEoZDAK8vOwbs1qXLmSDS/v9li1dh10upYWlyNSF+YoO0ekLsxRdo5IXZij7ByRuoiY0+gU+lsYc/nbvAdHyeryHhwiIiIianyKfg/O43PNll10eInZsqvD6R4REREREQlDwXNRIiIiIiKqlUJ/7G8uXMEhIiIiIiJhcAWHiIiIiMiS8SEDMvw2iIiIiIhIGJzgEBERERGRMHiLGhERERGRJeNDBmS4gkNERERERMLgCg4RERERkSXjQwZk+G0QEREREZEwuIJDRERERGTJ+BscGa7gEBERERGRMDjBISIiIiIiYfAWNSIiIiIiS8aHDMjw2yAiIiIiImEIMcE5ePAgQkNDodPpoFKpsGPHDtl+o9GI2NhY6HQ62Nraonfv3jh58mSN5zx37hwmTJgAT09P2Nra4qGHHsIbb7yB4uJi2XEXLlxAaGgo7Ozs4OrqiqlTp1Y6pqFt27oFIcF90c2/E0aPfAZH049YbI5IXZij7ByRujBH2TkidWGOsnNE6iJiTqNSNTHfpkDKvKo6KiwshJ+fH1auXFnl/qVLl2LFihVYuXIl0tLS4O7ujgEDBuD69evVnvN///sfbt++jf/85z84efIk3n77baxduxbz58+XjikrK8OQIUNQWFiIQ4cOISEhAYmJiZg5c2aDdyy3d89uLF0cj4hJL2HbZzvQpUsAoiZHIOvyZYvLEakLc5SdI1IX5ig7R6QuzFF2jkhdRMyhqq1ZswaPPvooHB0d4ejoiMDAQOzZs0fafy+LElVRGY1GY0NeuLmpVCps374dw4cPB3Dni9LpdIiOjsbcuXMBAAaDAVqtFkuWLMHkyZNNPveyZcuwZs0a/P777wCAPXv2YOjQobh48SJ0Oh0AICEhAeHh4cjOzoajo6NJ571Vanq/F0aPRAcfH7y2YKE0Njw0BH369se06Q03sWqMHJG6MEfZOSJ1YY6yc0Tqwhxl54jUxVJymin4l+u2vRaZLbsoeYHJx3755ZewsrKCl5cXAGDTpk1YtmwZjh07ho4dO2LJkiV48803sXHjRrRv3x7/+te/cPDgQZw5cwYODg4m5wixglOTzMxM6PV6BAcHS2NqtRq9evVCSkpKnc5VUFAAFxcX6c+pqanw9fWVJjcAMHDgQBgMBqSnp9f/4isoKS7G6VMnERj0hGw8MKgHjmccs6gckbowR9k5InVhjrJzROrCHGXniNRFxByzaKIy31YHoaGhGDx4MNq3b4/27dvjzTffhL29PQ4fPgyj0Yh33nkHr776Kp555hn4+vpi06ZNuHnzJj755JO6fR11OtoC6fV6AIBWq5WNa7VaaZ8pfvvtN7z33nuIjIyUnbvieZ2dnWFjY1PtuQ0GA65duybbDAaDSdeQl5+HsrIyaDQa2bhG44qcnCsmd1FCjkhdmKPsHJG6MEfZOSJ1YY6yc0TqImLO3829/t22rKwMCQkJKCwsRGBgYIMuSgg/wSmnqvCGV6PRKI1FRkbC3t5e2iq6fPkyBg0ahJEjR2LixIk1nrfiuSuKj4+Hk5OTbFu2JL7BujSkxsgRqQtzlJ0jUhfmKDtHpC7MUXaOSF1EzGlUZnzIQFV/t42Pr/7vtj///DPs7e2hVqsRGRmJ7du3w8fHp8EWJYC/wXtw3N3dAdxZbfHw8JDGs7OzpS9w0aJFmDVrVpWfv3z5Mvr06YPAwECsW7eu0rl/+OEH2VheXh5KSkoq/ccpFxMTgxkzZsjGjFZqk7o4t3CGlZUVcnJyZOO5uVeh0biadA6l5IjUhTnKzhGpC3OUnSNSF+YoO0ekLiLm/N1U9Xdbtbr6v9s+/PDDyMjIQH5+PhITEzF27FgkJydL+xtiAir8Co6npyfc3d2xb98+aay4uBjJyckICgoCALi5ucHLy0vayv3xxx/o3bs3unTpgg0bNqBJE/nXFRgYiBMnTiArK0saS0pKglqtRkBAQJXXo1arpSdHlG81/S/B3axtbNDBpyMOp3wvGz+ckgK/zv4mnUMpOSJ1YY6yc0Tqwhxl54jUhTnKzhGpi4g5fzd1/butjY0NvLy80LVrV8THx8PPzw///ve/ZYsSd7t7UcJUQqzg3LhxA2fPnpX+nJmZiYyMDLi4uKB169aIjo5GXFwcvL294e3tjbi4ODRv3hxhYWHVnvPy5cvo3bs3WrdujeXLl+PKlb/uzSz/DxAcHAwfHx+MGTMGy5YtQ25uLmbNmoWIiAiTn6BWV2PGjsOr8+bAx9cXfn7+SPx0G7KysjBy1GiLyxGpC3OUnSNSF+YoO0ekLsxRdo5IXUTMaXQWfIud0WiEwWCQLUr4+9+ZcJYvSixZsqRO5xRignPkyBH06dNH+nP5MtnYsWOxceNGzJkzB0VFRYiKikJeXh66d++OpKSkGh83l5SUhLNnz+Ls2bN48MEHZfvKn6xtZWWFXbt2ISoqCj169ICtrS3CwsKwfPny+9DyjkEhg1GQn4d1a1bjypVseHm3x6q166DTtbS4HJG6MEfZOSJ1YY6yc0Tqwhxl54jURcQcqtr8+fMREhKCVq1a4fr160hISMCBAwewd+9eqFSqe1qUqIpw78GxRHV5Dw4RERERNT5Fvwen/2KzZRd9M8/kYydMmID/+7//Q1ZWFpycnPDoo49i7ty5GDBgAIA7iwgLFy7Ef/7zH2lRYtWqVfD19a3TNXGCowCc4BAREREpGyc4VavLBKexKPg/FRERERER1cqCf4NzPwj/FDUiIiIiIvr74ASHiIiIiIiEwVvUiIiIiIgsmYprFnfjt0FERERERMLgCg4RERERkSXjQwZkuIJDRERERETC4ASHiIiIiIiEwVvUiIiIiIgsGR8yIMNvg4iIiIiIhMEVHCIiIiIiS8aHDMhwBYeIiIiIiITBFRwiIiIiIkvG3+DIWPy3ER8fj27dusHBwQFubm4YPnw4zpw5IzvGaDQiNjYWOp0Otra26N27N06ePFnruYcNG4bWrVujWbNm8PDwwJgxY3D58mXZMRcuXEBoaCjs7Ozg6uqKqVOnori4uEE7VrRt6xaEBPdFN/9OGD3yGRxNP2KxOSJ1YY6yc0Tqwhxl54jUhTnKzhGpi4g5ZD4WP8FJTk7GlClTcPjwYezbtw+lpaUIDg5GYWGhdMzSpUuxYsUKrFy5EmlpaXB3d8eAAQNw/fr1Gs/dp08f/Pe//8WZM2eQmJiI3377Dc8++6y0v6ysDEOGDEFhYSEOHTqEhIQEJCYmYubMmfet7949u7F0cTwiJr2EbZ/tQJcuAYiaHIGsChMvS8gRqQtzlJ0jUhfmKDtHpC7MUXaOSF1EzCHzUhmNRqO5L6IhXblyBW5ubkhOTsaTTz4Jo9EInU6H6OhozJ07FwBgMBig1WqxZMkSTJ482eRz79y5E8OHD4fBYIC1tTX27NmDoUOH4uLFi9DpdACAhIQEhIeHIzs7G46Ojiad91ap6f1eGD0SHXx88NqChdLY8NAQ9OnbH9OmN9zEqjFyROrCHGXniNSFOcrOEakLc5SdI1IXS8lppuAfdtgOedds2UW7ppotuzoWv4JTUUFBAQDAxcUFAJCZmQm9Xo/g4GDpGLVajV69eiElJcXk8+bm5mLLli0ICgqCtbU1ACA1NRW+vr7S5AYABg4cCIPBgPT09IaoI1NSXIzTp04iMOgJ2XhgUA8czzhmUTkidWGOsnNE6sIcZeeI1IU5ys4RqYuIOWR+Qk1wjEYjZsyYgSeeeAK+vr4AAL1eDwDQarWyY7VarbSvJnPnzoWdnR00Gg0uXLiAL774Qtqn1+srndfZ2Rk2NjYmnbuu8vLzUFZWBo1GIxvXaFyRk3PFonJE6sIcZeeI1IU5ys4RqQtzlJ0jUhcRc8xC1cR8mwIp86ru0csvv4yffvoJW7durbRPVeH54EajURqLjIyEvb29tN1t9uzZOHbsGJKSkmBlZYUXX3wRd9/VV/G8Fc9dkcFgwLVr12SbwWCoU8+aujSkxsgRqQtzlJ0jUhfmKDtHpC7MUXaOSF1EzCHzEWaC88orr2Dnzp349ttv8eCDD0rj7u7uAFBpRSU7O1tafVm0aBEyMjKk7W6urq5o3749BgwYgISEBOzevRuHDx+Wzl3xvHl5eSgpKam0slMuPj4eTk5Osm3ZkniTOjq3cIaVlRVycnJk47m5V6HRuJp0DqXkiNSFOcrOEakLc5SdI1IX5ig7R6QuIuaQ+Vn8BMdoNOLll1/G559/jv3798PT01O239PTE+7u7ti3b580VlxcjOTkZAQFBQEA3Nzc4OXlJW01ZQGQVlwCAwNx4sQJZGVlScckJSVBrVYjICCgynPExMSgoKBAts2eG2NSV2sbG3Tw6YjDKd/Lxg+npMCvs79J51BKjkhdmKPsHJG6MEfZOSJ1YY6yc0TqImKOWfAWNRkFPw/CNFOmTMEnn3yCL774Ag4ODtKKipOTE2xtbaFSqRAdHY24uDh4e3vD29sbcXFxaN68OcLCwqo9748//ogff/wRTzzxBJydnfH7779jwYIFeOihhxAYGAgACA4Oho+PD8aMGYNly5YhNzcXs2bNQkRERLVPUFOr1VCr1bKxujxFbczYcXh13hz4+PrCz88fiZ9uQ1ZWFkaOGm36SRSSI1IX5ig7R6QuzFF2jkhdmKPsHJG6iJhD5mXxE5w1a9YAAHr37i0b37BhA8LDwwEAc+bMQVFREaKiopCXl4fu3bsjKSkJDg4O1Z7X1tYWn3/+Od544w0UFhbCw8MDgwYNQkJCgjRBsbKywq5duxAVFYUePXrA1tYWYWFhWL58+X3pCgCDQgajID8P69asxpUr2fDybo9Va9dBp2tpcTkidWGOsnNE6sIcZeeI1IU5ys4RqYuIOY2OvyGSEe49OJaoLis4RERERNT4FP0enGFrzJZdtPMls2VXR8H/qYiIiIiIqFYK/S2MufDbICIiIiIiYXCCQ0REREREwuAtakRERERElowPGZDhCg4REREREQmDKzhERERERJaMDxmQ4bdBRERERETC4ASHiIiIiIiEwVvUiIiIiOi+yMq/1Sg5Hi2aNUqOYvEhAzJcwSEiIiIiImFwBYeIiIiIyIKpuIIjwxUcIiIiIiISBldwiIiIiIgsGFdw5LiCQ0REREREwuAEh4iIiIiIhGHxE5w1a9bg0UcfhaOjIxwdHREYGIg9e/ZI+41GI2JjY6HT6WBra4vevXvj5MmTJp/fYDCgc+fOUKlUyMjIkO27cOECQkNDYWdnB1dXV0ydOhXFxcUNVa1a27ZuQUhwX3Tz74TRI5/B0fQjFpsjUhfmKDtHpC7MUXaOSF2Yo+wckbrcLeGj9RjUww9r31l6X87f2H0ahcqMmwJZ/ATnwQcfxOLFi3HkyBEcOXIEffv2xVNPPSVNYpYuXYoVK1Zg5cqVSEtLg7u7OwYMGIDr16+bdP45c+ZAp9NVGi8rK8OQIUNQWFiIQ4cOISEhAYmJiZg5c2aD9qto757dWLo4HhGTXsK2z3agS5cARE2OQNblyxaXI1IX5ig7R6QuzFF2jkhdmKPsHJG63O3M6RPYs/MzeHq1vy/nb+w+ZB4qo9FoNPdFNDQXFxcsW7YM48ePh06nQ3R0NObOnQvgzoqMVqvFkiVLMHny5BrPs2fPHsyYMQOJiYno2LEjjh07hs6dO0v7hg4diosXL0oToISEBISHhyM7OxuOjo4mX++tUtO7vTB6JDr4+OC1BQulseGhIejTtz+mTW+4yVVj5IjUhTnKzhGpC3OUnSNSF+YoO8dSutTlRZ9FN2/i5fGjMGXmq9i66X085PUwIqPnmPRZU1/0WZ8+zRT8aC775zaaLfvGf8PNll0di1/BuVtZWRkSEhJQWFiIwMBAZGZmQq/XIzg4WDpGrVajV69eSElJqfFcf/75JyIiIrB582Y0b9680v7U1FT4+vrKVncGDhwIg8GA9PT0hit1l5LiYpw+dRKBQU/IxgODeuB4xjGLyhGpC3OUnSNSF+YoO0ekLsxRdo5IXe626q04PBb4JLp0e7zBzw00fh8yHwXPRU33888/IzAwELdu3YK9vT22b98OHx8faRKj1Wplx2u1Wpw/f77a8xmNRoSHhyMyMhJdu3bFuXPnKh2j1+srndfZ2Rk2NjbQ6/XVnttgMMBgMMjzrNRQq9W11URefh7Kysqg0Whk4xqNK3JyrtT6eVM1Ro5IXZij7ByRujBH2TkidWGOsnNE6lLuwDd7cPaX03j3g08a9Lx3a8w+ZF5CrOA8/PDDyMjIwOHDh/HSSy9h7NixOHXqlLS/4rPBjUajNBYZGQl7e3tpA4D33nsP165dQ0xMTI25VT1z/O5zVyU+Ph5OTk6ybdmSeJO71tanITVGjkhdmKPsHJG6MEfZOSJ1YY6yc0TpcuVPPda+sxRzFsTBxoR/8K2vxvreGpNKpTLbpkRCrODY2NjAy8sLANC1a1ekpaXh3//+t/S7G71eDw8PD+n47OxsafVl0aJFmDVrlux8+/fvx+HDhyutqnTt2hUvvPACNm3aBHd3d/zwww+y/Xl5eSgpKam0snO3mJgYzJgxQzZmtDLt/zE7t3CGlZUVcnJyZOO5uVeh0biadA6l5IjUhTnKzhGpC3OUnSNSF+YoO0ekLgDw65lTyM/LxcsTnpfGbpeV4URGOnZ+noAvv02DlZVVvXMaqw+ZnxArOBUZjUYYDAZ4enrC3d0d+/btk/YVFxcjOTkZQUFBAAA3Nzd4eXlJGwC8++67OH78ODIyMpCRkYHdu3cDALZt24Y333wTABAYGIgTJ04gKytLOndSUhLUajUCAgKqvTa1Wi090rp8M+X2NACwtrFBB5+OOJzyvWz8cEoK/Dr7m3QOpeSI1IU5ys4RqQtzlJ0jUhfmKDtHpC4A0DmgO9Zu/gyrN26TNu9HOqJP8GCs3ritQSY3QOP1MQeu4MhZ/ArO/PnzERISglatWuH69etISEjAgQMHsHfvXqhUKkRHRyMuLg7e3t7w9vZGXFwcmjdvjrCwsGrP2bp1a9mfy29de+ihh/Dggw8CAIKDg+Hj44MxY8Zg2bJlyM3NxaxZsxAREVGnJ6jV1Zix4/DqvDnw8fWFn58/Ej/dhqysLIwcNdrickTqwhxl54jUhTnKzhGpC3OUnSNSl+Z2dmjbzls21szWFo6OLSqN11djfW9kXhY/wfnzzz8xZswYZGVlwcnJCY8++ij27t2LAQMGALjzHpuioiJERUUhLy8P3bt3R1JSEhwcHOqVa2VlhV27diEqKgo9evSAra0twsLCsHz58oaoVa1BIYNRkJ+HdWtW48qVbHh5t8eqteug07W0uByRujBH2TkidWGOsnNE6sIcZeeI1KUxidannFJXUsxFyPfgWJq6vAeHiIiIyFLU5T049WHqe3DqQ8nvwXF6frPZsgu2jjFbdnWE/A0OERERERH9PSl4LkpERERERLXiHWoyXMEhIiIiIiJhcAWHiIiIiMiC8SEDclzBISIiIiIiYXCCQ0REREREwuAtakREREREFoy3qMlxgkNERERE98WI1SmNkpMyv2+j5JBl4ASHiIiIiMiCcQVHjr/BISIiIiIiYXAFh4iIiIjIgnEFR44rOEREREREJAxOcIiIiIiISBi8RY2IiIiIyJLxDjUZruAQEREREZEwhJvgxMfHQ6VSITo6WhozGo2IjY2FTqeDra0tevfujZMnT9Z6rrZt20KlUsm2efPmyY65cOECQkNDYWdnB1dXV0ydOhXFxcUNXUtm29YtCAnui27+nTB65DM4mn7EYnNE6sIcZeeI1IU5ys4RqQtzlJ1jqV3G9WiDzRO64ru5T+KbmU/grec6oY2mubS/aRMVpvZ7CNsmP4bv5/XC19N7YNFTHeBqb1PfKgAa73trTBX/vtqYmxIJNcFJS0vDunXr8Oijj8rGly5dihUrVmDlypVIS0uDu7s7BgwYgOvXr9d6zkWLFiErK0vaXnvtNWlfWVkZhgwZgsLCQhw6dAgJCQlITEzEzJkzG7xbub17dmPp4nhETHoJ2z7bgS5dAhA1OQJZly9bXI5IXZij7ByRujBH2TkidWGOsnMsuUtAmxb475FLGPthOl76OANNm6iw+oXOaGZ956+lzayb4BEPB3zw3TmEvZ+GWf/9GW00zfHO6EdrObN5+pDyqIxGo9HcF9EQbty4gS5dumD16tX417/+hc6dO+Odd96B0WiETqdDdHQ05s6dCwAwGAzQarVYsmQJJk+eXO0527Zti+joaNlq0N327NmDoUOH4uLFi9DpdACAhIQEhIeHIzs7G46OjiZd+61S03u+MHokOvj44LUFC6Wx4aEh6NO3P6ZNb7iJVWPkiNSFOcrOEakLc5SdI1IX5ig7x1K6BMXtr/WYFs2tsX9WT0zceBRHL+RXeYyPzgEfT+yGwe98D/01Q6X9KfP71poD1K9PMwX/ct01PMFs2TkbR5stuzrCrOBMmTIFQ4YMQf/+/WXjmZmZ0Ov1CA4OlsbUajV69eqFlJSUWs+7ZMkSaDQadO7cGW+++abs9rPU1FT4+vpKkxsAGDhwIAwGA9LT0xuglVxJcTFOnzqJwKAnZOOBQT1wPOOYReWI1IU5ys4RqQtzlJ0jUhfmKDtHpC4A4KC+M3MoKCqp9hh7dVPcNhpxvS7/KlxBY/UxB96iJqfguajpEhIScPToUaSlpVXap9frAQBarVY2rtVqcf78+RrPO23aNHTp0gXOzs748ccfERMTg8zMTHzwwQfSuSue19nZGTY2NlJuRQaDAQaD/F8ejFZqqNXqmksCyMvPQ1lZGTQajWxco3FFTs6VWj9vqsbIEakLc5SdI1IX5ig7R6QuzFF2jkhdAGBGsBeOXcjHb1cKq9xvY9UEU/s9hL0//4nC4rJ7zmmsPmR+Fr+Cc/HiRUybNg0ff/wxmjVrVu1xFWeYRqNRGouMjIS9vb20lZs+fTp69eqFRx99FBMnTsTatWuxfv16XL16tdrzVjx3RfHx8XBycpJty5bE16lzTV0aUmPkiNSFOcrOEakLc5SdI1IX5ig7R4Qu80Law1trj5jEqh/+1LSJCvEjOkKlUiF+95kGyWys760xcQVHzuJXcNLT05GdnY2AgABprKysDAcPHsTKlStx5syd/8eg1+vh4eEhHZOdnS2tvixatAizZs2qNevxxx8HAJw9exYajQbu7u744YcfZMfk5eWhpKSk0spOuZiYGMyYMUM2ZrSqffUGAJxbOMPKygo5OTmy8dzcq9BoXE06h1JyROrCHGXniNSFOcrOEakLc5SdI0qXOYO88WR7V0zcdBTZ1yv/rqZpExUWP+uLli2aYfLmY/VavQEa73sj87P4FZx+/frh559/RkZGhrR17doVL7zwAjIyMtCuXTu4u7tj37590meKi4uRnJyMoKAgAICbmxu8vLykrTrHjt25P7N8ohQYGIgTJ04gKytLOiYpKQlqtVo24bqbWq2Go6OjbDPl9jQAsLaxQQefjjic8r1s/HBKCvw6+5t0DqXkiNSFOcrOEakLc5SdI1IX5ig7R4Qucwe1R99H3DB58zFczr9VaX/55Ka1iy0iP85AQdG9//amXGN9b2R+Fr+C4+DgAF9fX9mYnZ0dNBqNNB4dHY24uDh4e3vD29sbcXFxaN68OcLCwqo9b2pqKg4fPow+ffrAyckJaWlpmD59OoYNG4bWrVsDAIKDg+Hj44MxY8Zg2bJlyM3NxaxZsxAREWHyE9TqaszYcXh13hz4+PrCz88fiZ9uQ1ZWFkaOatgnWDRGjkhdmKPsHJG6MEfZOSJ1YY6ycyy5y7yQ9gjppMX0bT/jpqEMGrs777e5YSiFofQ2rFQqLB3pi0fcHTAt4SdYqVTSMQVFJSi9fe8PAG6s763RKfNOMbOx+AmOKebMmYOioiJERUUhLy8P3bt3R1JSEhwcHKr9jFqtxrZt27Bw4UIYDAa0adMGERERmDNnjnSMlZUVdu3ahaioKPTo0QO2trYICwvD8uXL71uXQSGDUZCfh3VrVuPKlWx4ebfHqrXroNO1tLgckbowR9k5InVhjrJzROrCHGXnWHKX57o9CAD4YGwX2fgbX5zCl8f1cHNUo/fDDwAAtk1+THZMxKajSD+ff8/ZjfW9kXkJ8x4cS1aPJx4SERERKZYp78FpCKa+B6c+lPweHO3ET82W/ecHI82WXR2L/w0OERERERFROQXPRYmIiIiIqDZKfVyzuXAFh4iIiIiIhMEJDhERERERCYO3qBERERERWTDeoibHFRwiIiIiIhIGV3CIiIiIiCwYV3DkOMEhIiIiovsivK+nuS+B/oZ4ixoREREREQmDKzhERERERJaMd6jJcAWHiIiIiIjuu/j4eHTr1g0ODg5wc3PD8OHDcebMGdkx4eHhUKlUsu3xxx+vUw4nOEREREREFqzihKAxt7pITk7GlClTcPjwYezbtw+lpaUIDg5GYWGh7LhBgwYhKytL2nbv3l2nHN6iRkRERERE98RgMMBgMMjG1Go11Gp1pWP37t0r+/OGDRvg5uaG9PR0PPnkk7LPu7u73/M1cQWHiIiIiMiCmXMFJz4+Hk5OTrItPj7epOsuKCgAALi4uMjGDxw4ADc3N7Rv3x4RERHIzs6u0/dh8ROc2NjYSl/03TM+o9GI2NhY6HQ62Nraonfv3jh58qRJ5961axe6d+8OW1tbuLq64plnnpHtv3DhAkJDQ2FnZwdXV1dMnToVxcXFDdqvKtu2bkFIcF908++E0SOfwdH0IxabI1IX5ig7R6QuzFF2jkhdmKPsHEvtcvnMz9j17hvYMCMMqyYMwu9HU2T7f/xiM7a8OhH/eekpfPDKs/hi+Tzof/9fvTLv1ljf299FTEwMCgoKZFtMTEytnzMajZgxYwaeeOIJ+Pr6SuMhISHYsmUL9u/fj7feegtpaWno27dvpVWimlj8BAcAOnbsKLtP7+eff5b2LV26FCtWrMDKlSuRlpYGd3d3DBgwANevX6/xnImJiRgzZgzGjRuH48eP4/vvv0dYWJi0v6ysDEOGDEFhYSEOHTqEhIQEJCYmYubMmfetJwDs3bMbSxfHI2LSS9j22Q506RKAqMkRyLp82eJyROrCHGXniNSFOcrOEakLc5SdY8ldSopvQfOgJ558IarK/S20D+LJF6IwetFaPD1vORxctfhyxXwUXc+/58xyjfW9/Z2o1Wo4OjrKtqpuT6vo5Zdfxk8//YStW7fKxkeNGoUhQ4bA19cXoaGh2LNnD3755Rfs2rXL5GtSGY1GY52bKEhsbCx27NiBjIyMSvuMRiN0Oh2io6Mxd+5cAHfuE9RqtViyZAkmT55c5TlLS0vRtm1bLFy4EBMmTKjymD179mDo0KG4ePEidDodACAhIQHh4eHIzs6Go6OjyR1ulZp8KF4YPRIdfHzw2oKF0tjw0BD06dsf06Y33OSqMXJE6sIcZeeI1IU5ys4RqQtzlJ1jKV3WHc6scf+qCYMQMmUB2nUJqvaY4qJCvP/yCAybGY9WPv5VHjPpcdNeKFqfPs0U/Mv1VlO+MFv2xVVP1fkzr7zyCnbs2IGDBw/C07P2/3be3t6YOHGi9Pf52gixgvPrr79Cp9PB09MTo0ePxu+//w4AyMzMhF6vR3BwsHSsWq1Gr169kJKSUt3pcPToUfzxxx9o0qQJ/P394eHhgZCQENmtbampqfD19ZUmNwAwcOBAGAwGpKen34eWQElxMU6fOonAoCdk44FBPXA845hF5YjUhTnKzhGpC3OUnSNSF+YoO0ekLrUpKy3ByeQ9sLG1g2urdvU6lxL6/N0ZjUa8/PLL+Pzzz7F//36TJjdXr17FxYsX4eHhYXKOgueipunevTs++ugjtG/fHn/++Sf+9a9/ISgoCCdPnoRerwcAaLVa2We0Wi3Onz9f7TnLJ0ixsbFYsWIF2rZti7feegu9evXCL7/8AhcXF+j1+krndXZ2ho2NjZTb0PLy81BWVgaNRiMb12hckZNzxaJyROrCHGXniNSFOcrOEakLc5SdI1KX6pw7/gO+/k88SosNsHNywbCZcbB1cKrXOc3Z576zkBd9TpkyBZ988gm++OILODg4SH9ndnJygq2tLW7cuIHY2FiMGDECHh4eOHfuHObPnw9XV1c8/fTTJudY/ApOSEgIRowYgU6dOqF///7S/XmbNm2Sjqn4jG6j0SiNRUZGwt7eXtoA4Pbt2wCAV199FSNGjEBAQAA2bNgAlUqFTz/9tNrzVjx3VQwGA65duybb6vKjqdr6NKTGyBGpC3OUnSNSF+YoO0ekLsxRdo5IXSpq+YgfRr2xGiNiVqC1bwC+XhuHm9fyG+Tc5uhDd6xZswYFBQXo3bs3PDw8pG3btm0AACsrK/z888946qmn0L59e4wdOxbt27dHamoqHBwcTM6x+AlORXZ2dujUqRN+/fVX6WlqFVdUsrOzpdWXRYsWISMjQ9oASEtgPj4+0mfUajXatWuHCxcuAADc3d0rnTcvLw8lJSWVVnbuVtWj9JYtMe1Res4tnGFlZYWcnBzZeG7uVWg0riadQyk5InVhjrJzROrCHGXniNSFOcrOEalLdazVzdBCq4P7Qx3Qd9wMNGlihdPf7a39gzUwZx+6w2g0VrmFh4cDAGxtbfH1118jOzsbxcXFOH/+PDZu3IhWrVrVKUe4CY7BYMDp06fh4eEBT09PuLu7Y9++fdL+4uJiJCcnIyjozo/Z3Nzc4OXlJW0AEBAQALVajTNnzkifKykpwblz59CmTRsAQGBgIE6cOIGsrCzpmKSkJKjVagQEBFR7fVU9Sm/23NofpQcA1jY26ODTEYdTvpeNH05JgV/nqn90dy8aI0ekLsxRdo5IXZij7ByRujBH2TkidTGVEUaUlZbU6xxK6tPQzPkeHCWy+N/gzJo1C6GhoWjdujWys7Pxr3/9C9euXcPYsWOhUqkQHR2NuLg4eHt7w9vbG3FxcWjevLnskc8VOTo6IjIyEm+88QZatWqFNm3aYNmyZQCAkSNHAgCCg4Ph4+ODMWPGYNmyZcjNzcWsWbMQERFR4xPUqnqza12eojZm7Di8Om8OfHx94efnj8RPtyErKwsjR402/SQKyRGpC3OUnSNSF+YoO0ekLsxRdo4ldym+VYSC7L8ey3wtR48rF35DMzsHNLN3xJGvtsKz8+No7uQCQ+E1/PztVyjMzcFDXXsqsg8pj8VPcC5duoTnn38eOTk5eOCBB/D444/j8OHD0krLnDlzUFRUhKioKOTl5aF79+5ISkqq9T6+ZcuWoWnTphgzZgyKiorQvXt37N+/H87OzgDu3CO4a9cuREVFoUePHrC1tUVYWBiWL19+X/sOChmMgvw8rFuzGleuZMPLuz1WrV0Hna6lxeWI1IU5ys4RqQtzlJ0jUhfmKDvHkrtcOfcLdiz763G/329bBwB4JKg/er04Ffn6i9i7+hsU3biGZnYOcPNsj6fnLYemZdv61mm0762xKXUlxVws/j04IqjLCg4RERGRpajtPTgNxdT34NSHkt+D02bql2bLPv9uqNmyq6Pg/1RERERERFQbruDICfeQASIiIiIi+vviBIeIiIiIiITBW9SIiIiIiCwYb1GT4woOEREREREJgys4RERERESWjAs4MlzBISIiIiIiYXCCQ0REREREwuAtakRERER0X9irrcx9CX8LfMiAHFdwiIiIiIhIGFzBISIiIiKyYFzBkeMKDhERERERCYMrOEREREREFowLOHJcwSEiIiIiImFwgkNERERERMIQYoLzxx9/4B//+Ac0Gg2aN2+Ozp07Iz09XdpvNBoRGxsLnU4HW1tb9O7dGydPnqzxnAcOHIBKpapyS0tLk467cOECQkNDYWdnB1dXV0ydOhXFxcX3rSsAbNu6BSHBfdHNvxNGj3wGR9OPWGyOSF2Yo+wckbowR9k5InVhjrJzLLXLxf/9hM/eeh2rXh6FJf8YgF+OfC/tKystxYGE97F+XgRWTAjFqpdH4au1S3A9L6e+NSSN9b01pur+ztoYmxJZ/AQnLy8PPXr0gLW1Nfbs2YNTp07hrbfeQosWLaRjli5dihUrVmDlypVIS0uDu7s7BgwYgOvXr1d73qCgIGRlZcm2iRMnom3btujatSsAoKysDEOGDEFhYSEOHTqEhIQEJCYmYubMmfet7949u7F0cTwiJr2EbZ/tQJcuAYiaHIGsy5ctLkekLsxRdo5IXZij7ByRujBH2TmW3KXYcAturduh/9iXK+0rLTZAf+4sgob/A2P/uRrDo99AbtYlfL5iQX1qSBrreyPzUhmNRqO5L6I+5s2bh++//x7fffddlfuNRiN0Oh2io6Mxd+5cAIDBYIBWq8WSJUswefJkk3JKSkrw4IMP4uWXX8brr78OANizZw+GDh2KixcvQqfTAQASEhIQHh6O7OxsODo6mnTuW6UmHQYAeGH0SHTw8cFrCxZKY8NDQ9Cnb39Mm95wE6vGyBGpC3OUnSNSF+YoO0ekLsxRdo6ldPnk2IUa9y/5xwA8HR2L9l17VHtM1m9n8NEbL+Old7bA0dWtymPC/FvXei1A/fo0U/CjudrP2Wu27F+WDjJbdnUsfgVn586d6Nq1K0aOHAk3Nzf4+/vj/fffl/ZnZmZCr9cjODhYGlOr1ejVqxdSUlLqlJOTk4Pw8HBpLDU1Fb6+vtLkBgAGDhwIg8Egu0WuoZQUF+P0qZMIDHpCNh4Y1APHM45ZVI5IXZij7ByRujBH2TkidWGOsnNE6mIKQ1EhoFJB3dyuXudRSh+6/yx+gvP7779jzZo18Pb2xtdff43IyEhMnToVH330EQBAr9cDALRarexzWq1W2meK9evXY+DAgWjVqpU0ptfrK53X2dkZNjY21Z7bYDDg2rVrss1gMJh0DXn5eSgrK4NGo5GNazSuyMm5YnIXJeSI1IU5ys4RqQtzlJ0jUhfmKDtHpC61KS0uRvK2D+AT2LfeExwl9KHGYfETnNu3b6NLly6Ii4uDv78/Jk+ejIiICKxZs0Z2XMUfQRmNRmksMjIS9vb20lbRpUuX8PXXX2PChAmV9lX146q7z11RfHw8nJycZNuyJfEm962tS0NqjByRujBH2TkidWGOsnNE6sIcZeeI1KUqZaWl2LnqTRhvGxEc/kqDnddcfe4nPmRAzuInOB4eHvDx8ZGNdejQARcu3Lnn093dHQAqrahkZ2dLqy+LFi1CRkaGtFW0YcMGaDQaDBs2TDbu7u5e6bx5eXkoKSmptLJTLiYmBgUFBbJt9twYk7o6t3CGlZUVcnLkTxLJzb0KjcbVpHMoJUekLsxRdo5IXZij7ByRujBH2TkidalOWWkpvnjvX8i/oseoeUvqvXoDmLcPNS6Ln+D06NEDZ86ckY398ssvaNOmDQDA09MT7u7u2Ldvn7S/uLgYycnJCAoKAgC4ubnBy8tL2u5mNBqxYcMGvPjii7C2tpbtCwwMxIkTJ5CVlSWNJSUlQa1WIyAgoMrrVavVcHR0lG1qtdqkrtY2Nujg0xGHU76XjR9OSYFfZ3+TzqGUHJG6MEfZOSJ1YY6yc0Tqwhxl54jUpSrlk5u8P//A6HlLYOtg2kObamOuPo1BpTLfpkQKfh6EaaZPn46goCDExcXhueeew48//oh169Zh3bp1AO4s2UVHRyMuLg7e3t7w9vZGXFwcmjdvjrCwsFrPv3//fmRmZlZ5e1pwcDB8fHwwZswYLFu2DLm5uZg1axYiIiJMfoJaXY0ZOw6vzpsDH19f+Pn5I/HTbcjKysLIUaMtLkekLsxRdo5IXZij7ByRujBH2TmW3KX4VhHy/vxD+nPBFT3+PH8WtnaOsHfWYMe7i/DnubN4duY/cfv2bdzIzwUA2No7wKqpdXWnNVsfUh6Ln+B069YN27dvR0xMDBYtWgRPT0+88847eOGFF6Rj5syZg6KiIkRFRSEvLw/du3dHUlISHBwcaj3/+vXrERQUhA4dOlTaZ2VlhV27diEqKgo9evSAra0twsLCsHz58gbteLdBIYNRkJ+HdWtW48qVbHh5t8eqteug07W0uByRujBH2TkidWGOsnNE6sIcZedYchf9779ga9ws6c/7t6wFAPj2HIAnnnkRZ4+mAgA2vBop+9zz85ejtY/fPecCjfe9NbYmTRS6lGImFv8eHBHU5T04RERERJaitvfgNBRT34NTH0p+D47P/CSzZZ+KC679oEZm8b/BISIiIiIiKqfguSgREREREdVGqT/2Nxeu4BARERERkTC4gkNEREREZMGU+sJNc+EKDhERERERCYMTHCIiIiIiEgZvUSMiIiIismC8Q02OExwiIiIiui8+Tv2jUXIa4z04ZDk4wSEiIiIismB8yIAcf4NDRERERETC4AoOEREREZEF4wqOHFdwiIiIiIhIGJzgEBERERGRMHiLGhERERGRBeMdanJcwSEiIiIiImFY/ASnbdu2UKlUlbYpU6YAAIxGI2JjY6HT6WBra4vevXvj5MmTtZ73l19+wVNPPQVXV1c4OjqiR48e+Pbbb2XHXLhwAaGhobCzs4OrqyumTp2K4uLi+9Lzbtu2bkFIcF908++E0SOfwdH0IxabI1IX5ig7R6QuzFF2jkhdmKPsHEvt8nxXHVaP6oSvIh9D4sSuWDTkYbRq0azScWO7P4j/jg/AnqjuWPGMD9q62NYrt1xjfW+Nqaq/CzfWpkQWP8FJS0tDVlaWtO3btw8AMHLkSADA0qVLsWLFCqxcuRJpaWlwd3fHgAEDcP369RrPO2TIEJSWlmL//v1IT09H586dMXToUOj1egBAWVkZhgwZgsLCQhw6dAgJCQlITEzEzJkz72vfvXt2Y+nieERMegnbPtuBLl0CEDU5AlmXL1tcjkhdmKPsHJG6MEfZOSJ1YY6ycyy5i19LJ3zxkx4v//dnzN5xClZNVFg63AfNmv7119LRATo86++B95Iz8VLCT8i9WYKlw31ga12/v7o21vdG5qUyGo1Gc19EQ4qOjsZXX32FX3/9FQCg0+kQHR2NuXPnAgAMBgO0Wi2WLFmCyZMnV3mOnJwcPPDAAzh48CB69uwJALh+/TocHR3xzTffoF+/ftizZw+GDh2KixcvQqfTAQASEhIQHh6O7OxsODo6mnzNt0pN7/fC6JHo4OOD1xYslMaGh4agT9/+mDa94SZXjZEjUhfmKDtHpC7MUXaOSF2Yo+wcS+kyeHVqrcc42TbF9ohuiP7sBH66fOcfoD+dEIDEjCwkpN+ZeFhbqZA4sSvWfX8eX53IrnSO3VGB971PMwX/ct1/4X6zZR97o6/Zsqtj8Ss4dysuLsbHH3+M8ePHQ6VSITMzE3q9HsHBwdIxarUavXr1QkpKSrXn0Wg06NChAz766CMUFhaitLQU//nPf6DVahEQEAAASE1Nha+vrzS5AYCBAwfCYDAgPT39vvQrKS7G6VMnERj0hGw8MKgHjmccs6gckbowR9k5InVhjrJzROrCHGXniNQFAOxs7swcrv3/f/H1cFRDY2eDIxfy/7qWMiOO/3ENHT0c7jmnsfqYg0plvk2JFDwXrbsdO3YgPz8f4eHhACDdTqbVamXHabVanD9/vtrzqFQq7Nu3D0899RQcHBzQpEkTaLVa7N27Fy1atJDOXfG8zs7OsLGxkXKrYjAYYDAYZGNGKzXUanWt/fLy81BWVgaNRiMb12hckZNzpdbPm6oxckTqwhxl54jUhTnKzhGpC3OUnSNSFwCI6tkGP/1xDedyiwAALs2t7+TfLJFfz80SaB1q//tSdRqrD5mfUCs469evR0hIiGxVBaj8dlej0SiNRUZGwt7eXtrK90dFRcHNzQ3fffcdfvzxRzz11FMYOnQosrKyqj1vxXNXJT4+Hk5OTrJt2ZL4OvWsqU9DaowckbowR9k5InVhjrJzROrCHGXniNBlam9PtHNtjn99/WulfRV/RKEC0BC/q2is760x8SEDcsKs4Jw/fx7ffPMNPv/8c2nM3d0dwJ3VFg8PD2k8OztbWn1ZtGgRZs2aJTvX/v378dVXXyEvL0/6Lc3q1auxb98+bNq0CfPmzYO7uzt++OEH2efy8vJQUlJSaWXnbjExMZgxY4ZszGhl2r9GOLdwhpWVFXJycmTjublXodG4mnQOpeSI1IU5ys4RqQtzlJ0jUhfmKDtHlC6v9GqLIE9nRCeeRM6Nv55Cm/v/V25c7Kyl/xkAWjS3Rt7Ne39abWN9b2R+wqzgbNiwAW5ubhgyZIg05unpCXd3d+nJasCd3+kkJycjKCgIAODm5gYvLy9pA4CbN28CAJo0kX89TZo0we3btwEAgYGBOHHihGxFJykpCWq1WvqdTlXUajUcHR1lmym3pwGAtY0NOvh0xOGU72Xjh1NS4NfZ36RzKCVHpC7MUXaOSF2Yo+wckbowR9k5InSZ2ssTPR/SYObnp6C/Jr91P+uaAVcLixHQqoU01rSJCn4tHXEyq+an4Naksb43Mj8hVnBu376NDRs2YOzYsWja9K9KKpUK0dHRiIuLg7e3N7y9vREXF4fmzZsjLCys2vMFBgbC2dkZY8eOxYIFC2Bra4v3338fmZmZ0gQqODgYPj4+GDNmDJYtW4bc3FzMmjULERERdXqCWl2NGTsOr86bAx9fX/j5+SPx023IysrCyFGjLS5HpC7MUXaOSF2Yo+wckbowR9k5ltxlWm9P9HvYFa99dQY3S8rg/P9/c1NoKENx2Z1/SE7MyMIL3Vrij/xbuJRfhBe6PYhbJbfxf2dyajq1WfoogULvFDMbISY433zzDS5cuIDx48dX2jdnzhwUFRUhKioKeXl56N69O5KSkuDgUP1TOFxdXbF37168+uqr6Nu3L0pKStCxY0d88cUX8PPzAwBYWVlh165diIqKQo8ePWBra4uwsDAsX778vvUEgEEhg1GQn4d1a1bjypVseHm3x6q166DTtbS4HJG6MEfZOSJ1YY6yc0Tqwhxl51hyl6cevfMTgndGdJSNL9l3Fl+fvvNj/4T0y1A3bYJpfTzhoG6K03/ewJwdp1BUcvvey6DxvjcyL+Heg2OJ6vIeHCIiIiJLYcp7cBqCqe/BqQ8lvwen25sHzJad9mpvs2VXR5jf4BARERERESl4LkpERERERLXhb3DkuIJDRERERETC4ASHiIiIiIiEwVvUiIiIiIgsmIr3qMlwBYeIiIiIiITBFRwiIiIiIgvGBRw5TnCIiIiI6L7o1/EBc18C/Q3xFjUiIiIiIhIGV3CIiIiIiCwYHzIgxxUcIiIiIiISBldwiIiIiIgsGBdw5LiCQ0REREREwuAKDhERERGRBeNvcOQsfgWntLQUr732Gjw9PWFra4t27dph0aJFuH37tnSM0WhEbGwsdDodbG1t0bt3b5w8ebLWcx89ehQDBgxAixYtoNFoMGnSJNy4cUN2zIULFxAaGgo7Ozu4urpi6tSpKC4ubvCed9u2dQtCgvuim38njB75DI6mH7HYHJG6MEfZOSJ1YY6yc0Tqwhxl51hqlz9/PYH9qxfi05gx+ChqCC5kpFZ7bOon7+GjqCE4tX9HvTLv1ljfG5mPxU9wlixZgrVr12LlypU4ffo0li5dimXLluG9996Tjlm6dClWrFiBlStXIi0tDe7u7hgwYACuX79e7XkvX76M/v37w8vLCz/88AP27t2LkydPIjw8XDqmrKwMQ4YMQWFhIQ4dOoSEhAQkJiZi5syZ963v3j27sXRxPCImvYRtn+1Aly4BiJocgazLly0uR6QuzFF2jkhdmKPsHJG6MEfZOZbcpbT4Fpwf9MRjz0XWeNyFjFTknDsDWyfNPWdV1FjfG5mXymg0Gs19EfUxdOhQaLVarF+/XhobMWIEmjdvjs2bN8NoNEKn0yE6Ohpz584FABgMBmi1WixZsgSTJ0+u8rzr1q3D66+/jqysLDRpcmcemJGRAX9/f/z666/w8vLCnj17MHToUFy8eBE6nQ4AkJCQgPDwcGRnZ8PR0dGkDrdKTe/7wuiR6ODjg9cWLJTGhoeGoE/f/pg2veEmVo2RI1IX5ig7R6QuzFF2jkhdmKPsHEvp8lby2Rr3fxQ1BL0nvYbWnQNl4zfzc7B76Qz0f/mf+L/VsejQ9yn49B1e7Xlm9vKq9VqA+vVppuAfdjyx/DuzZR+a1dNs2dWx+BWcJ554Av/3f/+HX375BQBw/PhxHDp0CIMHDwYAZGZmQq/XIzg4WPqMWq1Gr169kJKSUu15DQYDbGxspMkNANja2gIADh06BABITU2Fr6+vNLkBgIEDB8JgMCA9Pb3hSv5/JcXFOH3qJAKDnpCNBwb1wPGMYxaVI1IX5ig7R6QuzFF2jkhdmKPsHJG6VMV4+zYObXwLHfuPQAtdmwY7r7n6UOOz+AnO3Llz8fzzz+ORRx6BtbU1/P39ER0djeeffx4AoNfrAQBarVb2Oa1WK+2rSt++faHX67Fs2TIUFxcjLy8P8+fPBwBkZWVJ5654XmdnZ9jY2NR47nuVl5+HsrIyaDTypVqNxhU5OVcsKkekLsxRdo5IXZij7ByRujBH2TkidanKiaTPoGpihUf6DGvQ85qrT2NQqVRm25TI4ic427Ztw8cff4xPPvkER48exaZNm7B8+XJs2rRJdlzF/wBGo1Eai4yMhL29vbQBQMeOHbFp0ya89dZbaN68Odzd3dGuXTtotVpYWVlVe96K567IYDDg2rVrss1gMNSpc01dGlJj5IjUhTnKzhGpC3OUnSNSF+YoO0ekLuWuXvgVpw98gR4vTr9vGY3Zh8zD4ic4s2fPxrx58zB69Gh06tQJY8aMwfTp0xEfHw8AcHd3B4BKKyrZ2dnS6suiRYuQkZEhbeXCwsKg1+vxxx9/4OrVq4iNjcWVK1fg6ekpnbviefPy8lBSUlJpZadcfHw8nJycZNuyJfEmdXVu4QwrKyvk5OTIxnNzr0KjcTXpHErJEakLc5SdI1IX5ig7R6QuzFF2jkhdKvrz7Encul6AxNfCsfnlUGx+ORSFudlIT1yPxNfG1evc5uhD5mHxE5ybN2/KficDAFZWVtJjoj09PeHu7o59+/ZJ+4uLi5GcnIygoCAAgJubG7y8vKStIq1WC3t7e2zbtg3NmjXDgAEDAACBgYE4ceKEdMsaACQlJUGtViMgIKDK642JiUFBQYFsmz03xqSu1jY26ODTEYdTvpeNH05JgV9nf5POoZQckbowR9k5InVhjrJzROrCHGXniNSlonaP9UXoqysxdP570mbrpIHPgGfQ/5V/1uvc5ujTWHiLmpyCnwdhmtDQULz55pto3bo1OnbsiGPHjmHFihUYP348gDv/waOjoxEXFwdvb294e3sjLi4OzZs3R1hYWI3nXrlyJYKCgmBvb499+/Zh9uzZWLx4MVq0aAEACA4Oho+PD8aMGYNly5YhNzcXs2bNQkRERLVPUFOr1VCr1bKxujxFbczYcXh13hz4+PrCz88fiZ9uQ1ZWFkaOGm36SRSSI1IX5ig7R6QuzFF2jkhdmKPsHEvuUnKrCNev/PVY5htX9ci9+Bts7Bxg7+KGZvbyv0M1sbKCraMznLQP3nNmucb63si8LH6C89577+H1119HVFQUsrOzodPpMHnyZCxYsEA6Zs6cOSgqKkJUVBTy8vLQvXt3JCUlwcHBocZz//jjj3jjjTdw48YNPPLII/jPf/6DMWPGSPutrKywa9cuREVFoUePHrC1tUVYWBiWL19+3/oOChmMgvw8rFuzGleuZMPLuz1WrV0Hna6lxeWI1IU5ys4RqQtzlJ0jUhfmKDvHkrtcvfArkt756+6VI4kfAAAeerwferw4o97XXJPG+t4am0IXUszG4t+DI4K6rOAQERERWYra3oPTUEx9D059KPk9OL3e/r72g+6T5Ok9zJZdHQX/pyIiIiIiotoo9bcw5mLxDxkgIiIiIiIqxwkOEREREREJg7eoERERERFZMN6hJscVHCIiIiIiuu/i4+PRrVs3ODg4wM3NDcOHD8eZM2dkxxiNRsTGxkKn08HW1ha9e/fGyZMn65TDCQ4RERERkQWzlBd9JicnY8qUKTh8+DD27duH0tJSBAcHo7CwUDpm6dKlWLFiBVauXIm0tDS4u7tjwIABuH79usk5vEWNiIiIiIjuu71798r+vGHDBri5uSE9PR1PPvkkjEYj3nnnHbz66qt45plnAACbNm2CVqvFJ598gsmTJ5uUwxUcIiIiIiK6JwaDAdeuXZNtBoPBpM8WFBQAAFxcXAAAmZmZ0Ov1CA4Olo5Rq9Xo1asXUlJSTL4mruAQERER0X3Rt42ruS/hb8GcDxmIj4/HwoULZWNvvPEGYmNja/yc0WjEjBkz8MQTT8DX1xcAoNfrAQBarVZ2rFarxfnz502+Jk5wiIiIiIjonsTExGDGjBmyMbVaXevnXn75Zfz00084dOhQpX0Vf9tjNBrr9HsfTnCIiIiIiCxYEzMu4ajVapMmNHd75ZVXsHPnThw8eBAPPvigNO7u7g7gzkqOh4eHNJ6dnV1pVacm/A0OERERERHdd0ajES+//DI+//xz7N+/H56enrL9np6ecHd3x759+6Sx4uJiJCcnIygoyOQcruAQEREREVkwS3nR55QpU/DJJ5/giy++gIODg/SbGycnJ9ja2kKlUiE6OhpxcXHw9vaGt7c34uLi0Lx5c4SFhZmcwwkOERERERHdd2vWrAEA9O7dWza+YcMGhIeHAwDmzJmDoqIiREVFIS8vD927d0dSUhIcHBxMzlEZjUZjQ1003Ztbpea+AiIiIqKGd+xcfqPk+Ldtcd8zmil4WSB41WGzZSdNedxs2dVR/G9wrl+/jujoaLRp0wa2trYICgpCWlqatN9oNCI2NhY6nQ62trbo3bs3Tp48Wet533zzTQQFBaF58+Zo0aJFlcdcuHABoaGhsLOzg6urK6ZOnYri4mLZMT///DN69eoFW1tbtGzZEosWLcL9njNu27oFIcF90c2/E0aPfAZH049YbI5IXZij7ByRujBH2TkidWGOsnNE6VJWVorEj9Zi1vjhiHj6Scwe/zS++OQD3L59u0FzyjXW99aYVCqV2TYlUvwEZ+LEidi3bx82b96Mn3/+GcHBwejfvz/++OMPAMDSpUuxYsUKrFy5EmlpaXB3d8eAAQNw/fr1Gs9bXFyMkSNH4qWXXqpyf1lZGYYMGYLCwkIcOnQICQkJSExMxMyZM6Vjrl27hgEDBkCn0yEtLQ3vvfceli9fjhUrVjTcF1DB3j27sXRxPCImvYRtn+1Aly4BiJocgazLly0uR6QuzFF2jkhdmKPsHJG6MEfZOSJ12fXpZny753P8I3IW4tYm4LnxL2PP51vwzZf/bbCMco31vZF5KfoWtaKiIjg4OOCLL77AkCFDpPHOnTtj6NCh+Oc//wmdTofo6GjMnTsXwJ23qWq1WixZsgSTJ0+uNWPjxo2Ijo5Gfn6+bHzPnj0YOnQoLl68CJ1OBwBISEhAeHg4srOz4ejoiDVr1iAmJgZ//vmn9Hi8xYsX47333sOlS5dMntXW5Ra1F0aPRAcfH7y24K8XKg0PDUGfvv0xbfrMGj5ZN42RI1IX5ig7R6QuzFF2jkhdmKPsHEvpYsotam/HzoBjCxdMiH5NGnvvzbmwUTfD5FkLa/jkX0y9Ra0+fZR8i1rImh/Mlr3npe5my66OoldwSktLUVZWhmbNmsnGbW1tcejQIWRmZkKv1yM4OFjap1ar0atXL6SkpNQrOzU1Fb6+vtLkBgAGDhwIg8GA9PR06ZhevXrJnv09cOBAXL58GefOnatXflVKiotx+tRJBAY9IRsPDOqB4xnHLCpHpC7MUXaOSF2Yo+wckbowR9k5InUBAG8fP5w6fgT6Py4AAC78/gt+PXUcfl1NfyywKRqrD5mfgueigIODAwIDA/HPf/4THTp0gFarxdatW/HDDz/A29tberRcxRf/aLVanD9/vl7Zer2+0nmdnZ1hY2Mj5er1erRt27ZSdvm+is/2Bu6sMBkMBtmY0cq0FyTl5eehrKwMGo1GNq7RuCIn50qtnzdVY+SI1IU5ys4RqQtzlJ0jUhfmKDtHpC4AMGTkiyi6eQMxk59DkyZNcPv2bYx4MRKP9x7YYBlA4/Uh81P0Cg4AbN68GUajES1btoRarca7776LsLAwWFlZScdUvBXMaDRKY5GRkbC3t5e2uqjqFrO7z11ddnWfBYD4+Hg4OTnJtmVL4ut1XRWvqaE0Ro5IXZij7ByRujBH2TkidWGOsnNE6fLDwX1I/XYvJs9ehNh3P8LEGQuw5/MtOPTNrgbLuFtjfW+NiQ8ZkFP0Cg4APPTQQ0hOTkZhYSGuXbsGDw8PjBo1SnrTKXBntcTDw0P6THZ2trSSsmjRIsyaNavOue7u7vjhB/n9jHl5eSgpKZHO7e7uLq3m3J0NVF5VKhcTE4MZM2bIxoxWta/eAIBzC2dYWVkhJydHNp6bexUajatJ51BKjkhdmKPsHJG6MEfZOSJ1YY6yc0TqAgD//fA9DB75Ih7vdecnB63aeuFqth5ffboJT/QfUsunTddYfcj8FL+CU87Ozg4eHh7Iy8vD119/jaeeekqa5Ozbt086rri4GMnJyQgKunPfppubG7y8vKTNVIGBgThx4gSysrKksaSkJKjVagQEBEjHHDx4UPbo6KSkJOh0ukq3rpVTq9VwdHSUbabcngYA1jY26ODTEYdTvpeNH05JgV9nf5O7KSFHpC7MUXaOSF2Yo+wckbowR9k5InUBAIPhFpqo5H8lbdKkCYwN/JjoxupjDiqV+TYlUvwKztdffw2j0YiHH34YZ8+exezZs/Hwww9j3LhxUKlUiI6ORlxcHLy9veHt7Y24uDg0b94cYWFhNZ73woULyM3NxYULF1BWVoaMjAwAgJeXF+zt7REcHAwfHx+MGTMGy5YtQ25uLmbNmoWIiAg4OjoCAMLCwrBw4UKEh4dj/vz5+PXXXxEXF4cFCxbctyW7MWPH4dV5c+Dj6ws/P38kfroNWVlZGDlqtMXliNSFOcrOEakLc5SdI1IX5ig7R6QunR/riS+3bYDLA1q0bNMOF377BV9v34qeA0IbLKNcY31vZF6Kn+AUFBQgJiYGly5dgouLC0aMGIE333wT1tbWAIA5c+agqKgIUVFRyMvLQ/fu3ZGUlAQHB4caz7tgwQJs2rRJ+rO//52Z+7fffovevXvDysoKu3btQlRUFHr06AFbW1uEhYVh+fLl0mecnJywb98+TJkyBV27doWzszNmzJhR6Ra0hjQoZDAK8vOwbs1qXLmSDS/v9li1dh10upYWlyNSF+YoO0ekLsxRdo5IXZij7ByRuvwjciY+//g/2Lx6Ga4V5KGFiyt6hzyNp56f0GAZ5Rrre2tsKih0KcVMFP0enL+LurwHh4iIiMhSmPIenIZg6ntw6kPJ78EZ+p80s2V/Nbmb2bKrYzG/wSEiIiIiIqqNgueiRERERERUmya8Q02GKzhERERERCQMruAQEREREVkwpb5w01y4gkNERERERMLgBIeIiIiIiITBW9SIiIiIiCwY71CT4wSHiIiIiO6LdUcuNkrOmkZ4Dw5ZDk5wiIiIiIgsWBMu4cjwNzhERERERCQMruAQEREREVkwLuDIcQWHiIiIiIiEwQkOEREREREJg7eoERERERFZMBXvUZPhCg4REREREQnDrBOcgwcPIjQ0FDqdDiqVCjt27JDtNxqNiI2NhU6ng62tLXr37o2TJ0/KjjEYDHjllVfg6uoKOzs7DBs2DJcuXao1e9q0aQgICIBarUbnzp0r7b916xbCw8PRqVMnNG3aFMOHD6/yPMnJyQgICECzZs3Qrl07rF271tT692zb1i0ICe6Lbv6dMHrkMziafsRic0Tqwhxl54jUhTnKzhGpC3OUnWOpXdo/0BzTerbBiqcewYbRneDf0lG2f8PoTlVugx5xrVduucb63hqTSmW+TYnMOsEpLCyEn58fVq5cWeX+pUuXYsWKFVi5ciXS0tLg7u6OAQMG4Pr169Ix0dHR2L59OxISEnDo0CHcuHEDQ4cORVlZWY3ZRqMR48ePx6hRo6rcX1ZWBltbW0ydOhX9+/ev8pjMzEwMHjwYPXv2xLFjxzB//nxMnToViYmJJn4Ddbd3z24sXRyPiEkvYdtnO9ClSwCiJkcg6/Jli8sRqQtzlJ0jUhfmKDtHpC7MUXaOJXdRN22Ci/m3sCW96nNM23Fatq3/4RJuG41Iv1hwz5nlGut7I/NSGY1Go7kvArhz7+D27dullRKj0QidTofo6GjMnTsXwJ3VGq1WiyVLlmDy5MkoKCjAAw88gM2bN0sTlcuXL6NVq1bYvXs3Bg4cWGtubGwsduzYgYyMjGqPCQ8PR35+fqUVprlz52Lnzp04ffq0NBYZGYnjx48jNTXV5O63Sk0+FC+MHokOPj54bcFCaWx4aAj69O2PadNnmn4iBeSI1IU5ys4RqQtzlJ0jUhfmKDvHUrq89NnPNe7fMLoT3v3uPI79ca3aY155ojWaWVth2beZ1R6z5tlOtV4LUL8+zRT8y/WRG4+aLfvT8C5my66OYn+Dk5mZCb1ej+DgYGlMrVajV69eSElJAQCkp6ejpKREdoxOp4Ovr690zP2UmpoqywaAgQMH4siRIygpKWnwvJLiYpw+dRKBQU/IxgODeuB4xjGLyhGpC3OUnSNSF+YoO0ekLsxRdo5IXWrjqG6KR3WO+O733HqfSwl97pcmKpXZNiVS7FxUr9cDALRarWxcq9Xi/Pnz0jE2NjZwdnaudEz55+/3NVZ1faWlpcjJyYGHh0elzxgMBhgMBtmY0UoNtVpda15efh7Kysqg0Whk4xqNK3JyrtxDA/PliNSFOcrOEakLc5SdI1IX5ig7R6Qutenh2QK3Sspw5GL1KzymUkIfahyKXcEpV/Gxd0ajsdZH4d19TEhICOzt7WFvb4+OHTs2yvVVNV4uPj4eTk5Osm3Zkvh6Z96PxwM2Ro5IXZij7ByRujBH2TkidWGOsnNE6lKdnu2ccfh8PkpvN9wvKszZ535RmXFTIsWu4Li7uwO4s0py90pIdna2tGri7u6O4uJi5OXlyVZxsrOzERQUBAD44IMPUFRUBACwtrZu8GusuFKUnZ2Npk2bVvrXgXIxMTGYMWOGbMxoVfvqDQA4t3CGlZUVcnJyZOO5uVeh0TTMk0UaK0ekLsxRdo5IXZij7ByRujBH2TkidamJ9wPN4eHYDGtSLjbI+czdhxqPYldwPD094e7ujn379kljxcXFSE5OliYvAQEBsLa2lh2TlZWFEydOSMe0bNkSXl5e8PLyQps2bRr0GgMDA2XZAJCUlISuXbtWO5lSq9VwdHSUbabcngYA1jY26ODTEYdTvpeNH05JgV9n/3srYaYckbowR9k5InVhjrJzROrCHGXniNSlJk+2c0Fm7k1czL/VIOczdx9qPGZdwblx4wbOnj0r/TkzMxMZGRlwcXFB69atER0djbi4OHh7e8Pb2xtxcXFo3rw5wsLCAABOTk6YMGECZs6cCY1GAxcXF8yaNQudOnWq9tHO5c6ePYsbN25Ar9ejqKhIeoqaj48PbGxsAACnTp1CcXExcnNzcf36demY8vfmREZGYuXKlZgxYwYiIiKQmpqK9evXY+vWrQ37Rd1lzNhxeHXeHPj4+sLPzx+Jn25DVlYWRo4abXE5InVhjrJzROrCHGXniNSFOcrOseQu6qZN4GZvI/35ATtrtGrRDIXFZci9eechTc2aNkG3Vk5IOJZV7w53a6zvrbFZ+i12Dc2sE5wjR46gT58+0p/Lb90aO3YsNm7ciDlz5qCoqAhRUVHIy8tD9+7dkZSUBAcHB+kzb7/9Npo2bYrnnnsORUVF6NevHzZu3AgrK6sasydOnIjk5GTpz/7+d2bumZmZaNu2LQBg8ODB0gMN7j6m/Hc2np6e2L17N6ZPn45Vq1ZBp9Ph3XffxYgRI+rxrdRsUMhgFOTnYd2a1bhyJRte3u2xau066HQtLS5HpC7MUXaOSF2Yo+wckbowR9k5ltylrYst5vVtJ/35+S46AMChzDys/+HOy9q7t3ECAPxwIf/eL74KjfW9kXkp5j04f2d1eQ8OERERkaWo7T04DcXU9+DUh5Lfg/PC5gyzZW8Z09ls2dVR7G9wiIiIiIiI6krBc1EiIiIiIqoNf4MjxxUcIiIiIiISBic4REREREQkDN6iRkRERERkwXiHmhxXcIiIiIiISBhcwSEiIiIismB8yIAcJzhEREREdF8MetjF3JdAf0O8RY2IiIiIiITBFRwiIiIiIgvWhHeoyXAFh4iIiIiIhMEVHCIiIiIiC8aHDMhxBYeIiIiIiITBFRwiIiIiIgvG9Rs5s67gHDx4EKGhodDpdFCpVNixY4ds/+eff46BAwfC1dUVKpUKGRkZlc5hMBjwyiuvwNXVFXZ2dhg2bBguXbpUa/a0adMQEBAAtVqNzp07V9p/4MABPPXUU/Dw8ICdnR06d+6MLVu2VDouOTkZAQEBaNasGdq1a4e1a9eaWv+ebdu6BSHBfdHNvxNGj3wGR9OPWGyOSF2Yo+wckbowR9k5InVhjrJzLLXLudPH8fHS+Vj20kgsGN0Xp9MOyfaf+vEgNsXNweKI4Vgwui+yzp2tV15FjfW9kfmYdYJTWFgIPz8/rFy5str9PXr0wOLFi6s9R3R0NLZv346EhAQcOnQIN27cwNChQ1FWVlZjttFoxPjx4zFq1Kgq96ekpODRRx9FYmIifvrpJ4wfPx4vvvgivvzyS+mYzMxMDB48GD179sSxY8cwf/58TJ06FYmJiSa0vzd79+zG0sXxiJj0ErZ9tgNdugQganIEsi5ftrgckbowR9k5InVhjrJzROrCHGXnWHKX4lu34N7mIQwZ90q1+1s/7IsBz0fcc0Z1Gut7I/NSGY1Go7kvArjz46jt27dj+PDhlfadO3cOnp6eOHbsmGy1paCgAA888AA2b94sTVQuX76MVq1aYffu3Rg4cGCtubGxsdixY0eVq0MVDRkyBFqtFh9++CEAYO7cudi5cydOnz4tHRMZGYnjx48jNTW11vOVu1Vq8qF4YfRIdPDxwWsLFkpjw0ND0Kdvf0ybPtP0EykgR6QuzFF2jkhdmKPsHJG6MEfZOZbS5Yuf/6hx/4LRffH8zEXo0O2JSvvysvV4e2oYXlq8Dh5tvWo8z1OdWtZ6LUD9+jRT8A87Jm47YbbsD0b5mi27Ohb9kIH09HSUlJQgODhYGtPpdPD19UVKSkqD5xUUFMDF5a838qampsqyAWDgwIE4cuQISkpKGjy/pLgYp0+dRGCQ/P8TCAzqgeMZxywqR6QuzFF2jkhdmKPsHJG6MEfZOSJ1aUyi9aHqWfQER6/Xw8bGBs7OzrJxrVYLvV7foFmfffYZ0tLSMG7cOFm+VqutlF1aWoqcnJwGzQeAvPw8lJWVQaPRyMY1Glfk5FyxqByRujBH2TkidWGOsnNE6sIcZeeI1KUxidbnbiqV+TYlsugJTnWMRqP0PPCQkBDY29vD3t4eHTt2vKfzHThwAOHh4Xj//fcrnaPic8fL7/ir7nnkBoMB165dk20Gg6FO11NV5v14/nlj5IjUhTnKzhGpC3OUnSNSF+YoO0ekLo1JtD5U2T1NcDZv3owePXpAp9Ph/PnzAIB33nkHX3zxRYNeXG3c3d1RXFyMvLw82Xh2dra0svLBBx8gIyMDGRkZ2L17d50zkpOTERoaihUrVuDFF1+slF9xpSg7OxtNmzat9K8D5eLj4+Hk5CTbli2JN+lanFs4w8rKqtLqUG7uVWg0rnVoZf4ckbowR9k5InVhjrJzROrCHGXniNSlMYnWh6pX5wnOmjVrMGPGDAwePBj5+fnS08patGiBd955p6Gvr0YBAQGwtrbGvn37pLGsrCycOHECQUFBAICWLVvCy8sLXl5eaNOmTZ3Of+DAAQwZMgSLFy/GpEmTKu0PDAyUZQNAUlISunbtCmtr6yrPGRMTg4KCAtk2e26MSddjbWODDj4dcTjle9n44ZQU+HX2N7GVMnJE6sIcZeeI1IU5ys4RqQtzlJ0jUpfGJFqfu6lUKrNtSlTn50G89957eP/99zF8+HDZ45u7du2KWbNm1elcN27cwNmzfz3bPDMzExkZGXBxcUHr1q2Rm5uLCxcu4PL/f3TfmTNnANxZOXF3d4eTkxMmTJiAmTNnQqPRwMXFBbNmzUKnTp3Qv3//GrPPnj2LGzduQK/Xo6ioSHqKmo+PD2xsbKTJzbRp0zBixAhppcbGxkZ60EBkZCRWrlyJGTNmICIiAqmpqVi/fj22bt1aba5arYZarZaN1eUpamPGjsOr8+bAx9cXfn7+SPx0G7KysjBy1GjTT6KQHJG6MEfZOSJ1YY6yc0Tqwhxl51hyF8OtIuTq/3q6Wl52FrLOnYWtvQNauGpx88Y1FORk43renZWWnMsXAQD2LVzg0MKlynOasw8pT50nOJmZmfD3rzzLVavVKCwsrNO5jhw5gj59+kh/njFjBgBg7Nix2LhxI3bu3Cn7Uf/o0Xf+l++NN95AbGwsAODtt99G06ZN8dxzz6GoqAj9+vXDxo0bYWVlVWP2xIkTkZycLP25vFNmZibatm2LjRs34ubNm4iPj0d8/F+3kPXq1QsHDhwAAHh6emL37t2YPn06Vq1aBZ1Oh3fffRcjRoyo0/dQF4NCBqMgPw/r1qzGlSvZ8PJuj1Vr10GnM+3xiErKEakLc5SdI1IX5ig7R6QuzFF2jiV3ufzbGWz45wzpz3s3rwEAdH5yIJ6JmoszR1Kwfe1Saf+n7/4TANB7xIvoOzL8nnOBxvveGptCF1LMps7vwfHx8UF8fDyeeuopODg44Pjx42jXrh3effddbNq0Cenp6ffrWoVVlxUcIiIiIktR23twGoqp78GpDyW/B2fyZyfNlv2fZ+/tIV73U53/U82ePRtTpkzBrVu3YDQa8eOPP2Lr1q2Ij4/HBx98cD+ukYiIiIiIqtGESzgydZ7gjBs3DqWlpZgzZw5u3ryJsLAwtGzZEv/+97+lW8iIiIiIiIjM4Z4W2yIiIhAREYGcnBzcvn0bbm5uDX1dREREREREdVavuwldXfnMcCIiIiIic+IdanJ1nuB4enrW+Mzr33//vV4XREREREREdK/qPMGJjo6W/bmkpATHjh3D3r17MXv27Ia6LiIiIiIiMoFSX7hpLnWe4EybNq3K8VWrVuHIkSP1viAiIiIiIqJ71aShThQSEoLExMSGOh0REREREVGdNdgriz777DO4uLg01OmIiIiIyMI1b6rgt2MKpMFWLARR5/+t8/f3l93nZzQaodfrceXKFaxevbpBL46IiIiIiKgu6jzBGT58uOzPTZo0wQMPPIDevXvjkUceaajrIiIiIiIiE/AhA3J1muCUlpaibdu2GDhwINzd3e/XNREREREREd2TOt2y17RpU7z00kswGAz363qIiIiIiKgOmqjMtylRnX+T1L17dxw7dux+XAsREREREVG91Pk3OFFRUZg5cyYuXbqEgIAA2NnZyfY/+uijDXZxREREREREdWHyCs748eNx7do1jBo1CpmZmZg6dSp69OiBzp07w9/fX/q/6+LgwYMIDQ2FTqeDSqXCjh07pH0lJSWYO3cuOnXqBDs7O+h0Orz44ou4fPmy7BwGgwGvvPIKXF1dYWdnh2HDhuHSpUu1Zk+bNg0BAQFQq9Xo3Llzpf1nzpxBnz59oNVq0axZM7Rr1w6vvfYaSkpKZMclJycjICBAOmbt2rV1+g7uxbatWxAS3Bfd/Dth9MhncDT9/rxgtTFyROrCHGXniNSFOcrOEakLc5SdY6ldfjuVgfXx87Ao4mnMevZJnPjxO9l+o9GIr7d9iEURT2NeWH+sXjAV+ouZ9cq8W2N9b42Jt6jJmTzB2bRpE27duoXMzMxK2++//y7933VRWFgIPz8/rFy5stK+mzdv4ujRo3j99ddx9OhRfP755/jll18wbNgw2XHR0dHYvn07EhIScOjQIdy4cQNDhw5FWVlZjdlGoxHjx4/HqFGjqtxvbW2NF198EUlJSThz5gzeeecdvP/++3jjjTekYzIzMzF48GD07NkTx44dw/z58zF16tT7+sLTvXt2Y+nieERMegnbPtuBLl0CEDU5AlkVJn6WkCNSF+YoO0ekLsxRdo5IXZij7BxL7lJ86xZ0bR/C0xOiq9z/7Y5PcPCr/+LpCdGYtngdHFu4YN2iGbhVdPOeM8s11vdG5qUyGo1GUw5s0qQJ9Ho93Nzc7s+FqFTYvn17pcdQ3y0tLQ2PPfYYzp8/j9atW6OgoAAPPPAANm/eLE1ULl++jFatWmH37t0YOHBgrbmxsbHYsWMHMjIyaj12xowZSEtLw3ff3fmXhrlz52Lnzp04ffq0dExkZCSOHz+O1NTUWs9X7lapyYfihdEj0cHHB68tWCiNDQ8NQZ++/TFt+kzTT6SAHJG6MEfZOSJ1YY6yc0Tqwhxl51hKl32n/6xx/6xnn0T4nDfh+1hPAHf+AXpRxNPoOWQk+j79AgCgtKQYsROGY8g/JiMw+KkqzzOgg/a+92mm4HeWzvzyjNmy3wp92GzZ1anTQwbM/YztgoICqFQqtGjRAgCQnp6OkpISBAcHS8fodDr4+voiJSWlQbPPnj2LvXv3olevXtJYamqqLBsABg4ciCNHjlS6la0hlBQX4/SpkwgMekI2HhjUA8czGu7BD42RI1IX5ig7R6QuzFF2jkhdmKPsHJG6VJSbnYXr+bl42K+bNNbU2gYP+fjh3JkT9Tq3OfqQedRpLtq+fftaJzm5ubn1uqDq3Lp1C/PmzUNYWBgcHR0BAHq9HjY2NnB2dpYdq9VqodfrGyQ3KCgIR48ehcFgwKRJk7Bo0SJpn16vh1Yr/xcDrVaL0tJS5OTkwMPDo9L5DAZDpcdsG63UUKvVtV5LXn4eysrKoNFoZOMajStycq7UpZbZc0Tqwhxl54jUhTnKzhGpC3OUnSNSl4qu510FANi3cJGN27dwQd6V+v3dzhx9yDzqNMFZuHAhnJyc7te1VKukpASjR4/G7du3sXr16lqPNxqN0kQsJCREuqWsTZs2OHnyZJ2yt23bhuvXr+P48eOYPXs2li9fjjlz5kj7K074yu/4q24iGB8fj4ULF8rGXn39Dby2INbka6oq836srjVGjkhdmKPsHJG6MEfZOSJ1YY6yc0TqUjmzwkADZpqjz/2m1B/7m0udJjijR4++b7/BqU5JSQmee+45ZGZmYv/+/dLqDQC4u7ujuLgYeXl5slWc7OxsBAUFAQA++OADFBUVAbjz4IC6atWqFQDAx8cHZWVlmDRpEmbOnAkrKyu4u7tXWinKzs5G06ZNK/3rQLmYmBjMmDFDNma0qn31BgCcWzjDysoKOTk5svHc3KvQaFxNraSIHJG6MEfZOSJ1YY6yc0Tqwhxl54jUpSIH5zt/f7qelwtH578ybhTkwd7JubqPmcQcfcg8TP4NjjlmtuWTm19//RXffPNNpUlDQEAArK2tsW/fPmksKysLJ06ckCY4LVu2hJeXF7y8vNCmTZt6XY/RaERJSYm0ShMYGCjLBoCkpCR07dq12smUWq2Go6OjbDPl9jQAsLaxQQefjjic8r1s/HBKCvw61+0R3ebOEakLc5SdI1IX5ig7R6QuzFF2jkhdKnJx84BDCxf88tNfj24uLSnBb6eOo+3DvvU6tzn6NBaVynybEpm8gmPiw9bq5MaNGzh79qz058zMTGRkZMDFxQU6nQ7PPvssjh49iq+++gplZWXSaomLiwtsbGzg5OSECRMmYObMmdBoNHBxccGsWbPQqVMn9O/fv8bss2fP4saNG9Dr9SgqKpKeoubj4wMbGxts2bIF1tbW6NSpE9RqNdLT0xETE4NRo0ahadM7X1tkZCRWrlyJGTNmICIiAqmpqVi/fj22bt3a4N9VuTFjx+HVeXPg4+sLPz9/JH66DVlZWRg5arTF5YjUhTnKzhGpC3OUnSNSF+YoO8eSuxiKbiJH/4f059w/s/BH5q9obu8I5we06DlkJP7v84/h6vEgXD0exP7PP4aNWg3/ngMU2YdMd/DgQSxbtgzp6enIysqq9ATl8PBwbNq0SfaZ7t274/Dhw3XKMXmCc/v27Tqd2BRHjhxBnz59pD+X37o1duxYxMbGYufOnQBQ6UWc3377LXr37g0AePvtt9G0aVM899xzKCoqQr9+/bBx40ZYWVnVmD1x4kQkJydLfy5/SWlmZibatm2Lpk2bYsmSJfjll19gNBrRpk0bTJkyBdOnT5c+4+npid27d2P69OlYtWoVdDod3n33XYwYMeKev5PaDAoZjIL8PKxbsxpXrmTDy7s9Vq1dB52upcXliNSFOcrOEakLc5SdI1IX5ig7x5K7XPztDNbGTpP+vHPTnfchdu09CKNfno8+w8NQUmzA5++vQFHhDbT27oCI199CM9vmiuyjBE2UupRSQfk7MMeNG1ft35cHDRqEDRs2SH+2sbGpc47J78Gh+6cu78EhIiIishS1vQenoZj6Hpz6UPJ7cObt/sVs2YsHt7+nz1X1Dszw8HDk5+djx44d9bqmOr0Hh4iIiIiIqJzBYMC1a9dkW8VXotTFgQMH4Obmhvbt2yMiIgLZ2dl1PgcnOEREREREFqyJGbf4+Hg4OTnJtvj4+HvqERISgi1btmD//v146623kJaWhr59+9Z5wqTgxTYiIiIiIlKyql6BYuoTgisaNWqU9D/7+vqia9euaNOmDXbt2oVnnnnG5PNwgkNEREREZMHM+YwBtVp9zxOa2nh4eKBNmzb49ddf6/Q53qJGRERERESKc/XqVVy8eBEeHh51+hxXcIiIiIiI6L6r6R2YLi4uiI2NxYgRI+Dh4YFz585h/vz5cHV1xdNPP12nHE5wiIiIiIgsmKW8B6emd2CuWbMGP//8Mz766CPk5+fDw8MDffr0wbZt2+Dg4FCnHE5wiIiIiOi+aG5d84vX6e+ld+/eqOkVnF9//XWD5HCCQ0RERERkwSxkAafR8CEDREREREQkDK7gEBERERFZsCZcwZHhCg4REREREQmDExwiIiIiIhIGb1EjIiIiIrJglvKY6MbCFRwiIiIiIhKGWSc4Bw8eRGhoKHQ6HVQqFXbs2CHbHxsbi0ceeQR2dnZwdnZG//798cMPP8iOMRgMeOWVV+Dq6go7OzsMGzYMly5dqjV72rRpCAgIgFqtRufOnWs89uzZs3BwcECLFi0q7UtOTkZAQACaNWuGdu3aYe3atbVm19e2rVsQEtwX3fw7YfTIZ3A0/YjF5ojUhTnKzhGpC3OUnSNSF+YoO0ekLrduFuLTD97BaxOfwbSRfbBszmSc+/V0g+cAjfe9NSaVynybEpl1glNYWAg/Pz+sXLmyyv3t27fHypUr8fPPP+PQoUNo27YtgoODceXKFemY6OhobN++HQkJCTh06BBu3LiBoUOHoqysrMZso9GI8ePHY9SoUTUeV1JSgueffx49e/astC8zMxODBw9Gz549cezYMcyfPx9Tp05FYmKiCe3vzd49u7F0cTwiJr2EbZ/tQJcuAYiaHIGsy5ctLkekLsxRdo5IXZij7ByRujBH2TkidQGAj1cuxv8y0jB2+gK8+u5mdPB/DO8umIb8q1dq/3AdNFYfMi+VsabXiTYilUqF7du3Y/jw4dUec+3aNTg5OeGbb75Bv379UFBQgAceeACbN2+WJiqXL19Gq1atsHv3bgwcOLDW3NjYWOzYsQMZGRlV7p87dy4uX76Mfv36ITo6Gvn5+bJ9O3fuxOnTf/0LQ2RkJI4fP47U1FSTegPArVKTD8ULo0eig48PXluwUBobHhqCPn37Y9r0maafSAE5InVhjrJzROrCHGXniNSFOcrOsZQu35/NqfWYYoMBM0YPwORXF6NT1yBpPC56LHy79sCwf0yq9Rw9vFxrPQaoX59mCv7l+j+/OWu27Nf7e5ktuzoW8xuc4uJirFu3Dk5OTvDz8wMApKeno6SkBMHBwdJxOp0Ovr6+SElJqXfm/v378emnn2LVqlVV7k9NTZVlA8DAgQNx5MgRlJSU1Du/opLiYpw+dRKBQU/IxgODeuB4xjGLyhGpC3OUnSNSF+YoO0ekLsxRdo5IXQDgdlkpbt8ug7W1jWzc2kaN307/1GA5jdXHHJqozLcpkYLnond89dVXGD16NG7evAkPDw/s27cPrq53Zul6vR42NjZwdnaWfUar1UKv19cr9+rVqwgPD8fHH38MR0fHKo/R6/XQarWVsktLS5GTkwMPD49KnzEYDDAYDLIxo5UaarW61mvKy89DWVkZNBqNbFyjcUVOTsMt4TZGjkhdmKPsHJG6MEfZOSJ1YY6yc0TqAgDNmtvB82Ff7PnvRrg/2AaOLVyQ9t03OPfLKTzg8WCD5TRWHzI/xa/g9OnTBxkZGUhJScGgQYPw3HPPITs7u8bPGI1GqP7/r55CQkJgb28Pe3t7dOzY0eTciIgIhIWF4cknn6zxOFWFX1eV3/FXcbxcfHw8nJycZNuyJfEmX1d1mdXl1Udj5IjUhTnKzhGpC3OUnSNSF+YoO0ekLuHTX4fRaMT88cMx9dk+OPDVp+j65AA0aWLVoDlA431vjUllxv+jRIpfwbGzs4OXlxe8vLzw+OOPw9vbG+vXr0dMTAzc3d1RXFyMvLw82SpOdnY2goLu3MP5wQcfoKioCABgbW1tcu7+/fuxc+dOLF++HMCd/+W/ffs2mjZtinXr1mH8+PFwd3evtFKUnZ2Npk2bVvrXgXIxMTGYMWOGbMxoVfvqDQA4t3CGlZUVcnLk97Pm5l6FRmPavadKyRGpC3OUnSNSF+YoO0ekLsxRdo5IXco94PEgZsStguFWEW7dLISTiys+WPo6NNrKd8Pcq8bsQ+al+BWcioxGo3SLV0BAAKytrbFv3z5pf1ZWFk6cOCFNcFq2bClNkNq0aWNyTmpqKjIyMqRt0aJFcHBwQEZGBp5++mkAQGBgoCwbAJKSktC1a9dqJ1NqtRqOjo6yzZTb0wDA2sYGHXw64nDK97Lxwykp8Ovsb3I3JeSI1IU5ys4RqQtzlJ0jUhfmKDtHpC4VqZvZwsnFFTdvXMPpjB/h173yU2zvlTn6kHmYdQXnxo0bOHv2r6c+ZGZmIiMjAy4uLtBoNHjzzTcxbNgweHh44OrVq1i9ejUuXbqEkSNHAgCcnJwwYcIEzJw5ExqNBi4uLpg1axY6deqE/v3715h99uxZ3LhxA3q9HkVFRdJT1Hx8fGBjY4MOHTrIjj9y5AiaNGkCX19faSwyMhIrV67EjBkzEBERgdTUVKxfvx5bt25toG+osjFjx+HVeXPg4+sLPz9/JH66DVlZWRg5arTF5YjUhTnKzhGpC3OUnSNSF+YoO0ekLgBw6ugPMMIIbcvWuJJ1Cds3roJW1xqB/YY0aE5j9WlsSv2xv7mYdYJz5MgR9OnTR/pz+a1bY8eOxdq1a/G///0PmzZtQk5ODjQaDbp164bvvvtO9luat99+G02bNsVzzz2HoqIi9OvXDxs3boSVVc33bE6cOBHJycnSn/3978zcMzMz0bZtW5Ou39PTE7t378b06dOxatUq6HQ6vPvuuxgxYoSpX0GdDQoZjIL8PKxbsxpXrmTDy7s9Vq1dB52upcXliNSFOcrOEakLc5SdI1IX5ig7R6QuAFB08wa+2LwW+TlX0NzBEf6BvTDsH5Nh1bRh/6raWH3IvBTzHpy/s7q8B4eIiIjIUpjyHpyGYOp7cOpDye/BWfrtb2bLntPnIbNlV8fifoNDRERERERUHQXPRYmIiIiIqDaW/pjrhsYVHCIiIiIiEgYnOEREREREJAzeokZEREREZMH4mGg5ruAQEREREZEwuIJDRERERGTB+IwBOU5wiIiIiOi+uFlSZu5LoL8h3qJGRERERETC4AoOEREREZEFa8J71GS4gkNERERERMLgCg4RERERkQXjY6LluIJDRERERETC4AoOEREREZEF409w5My6gnPw4EGEhoZCp9NBpVJhx44d1R47efJkqFQqvPPOO7Jxg8GAV155Ba6urrCzs8OwYcNw6dKlWrOnTZuGgIAAqNVqdO7cudL+c+fOQaVSVdr27t0rOy45ORkBAQFo1qwZ2rVrh7Vr15pSvV62bd2CkOC+6ObfCaNHPoOj6UcsNkekLsxRdo5IXZij7ByRujBH2TmW2uW3UxlYHz8PiyKexqxnn8SJH7+T7Tcajfh624dYFPE05oX1x+oFU6G/mFmvzLs11vdG5mPWCU5hYSH8/PywcuXKGo/bsWMHfvjhB+h0ukr7oqOjsX37diQkJODQoUO4ceMGhg4dirKymp+7bjQaMX78eIwaNarG47755htkZWVJW9++faV9mZmZGDx4MHr27Iljx45h/vz5mDp1KhITE2s8Z33s3bMbSxfHI2LSS9j22Q506RKAqMkRyLp82eJyROrCHGXniNSFOcrOEakLc5SdY8ldim/dgq7tQ3h6QnSV+7/d8QkOfvVfPD0hGtMWr4NjCxesWzQDt4pu3nNmucb63si8VEaj0WjuiwAAlUqF7du3Y/jw4bLxP/74A927d8fXX3+NIUOGIDo6GtHR0QCAgoICPPDAA9i8ebM0Ubl8+TJatWqF3bt3Y+DAgbXmxsbGYseOHcjIyJCNnzt3Dp6enjh27FiVKzwAMHfuXOzcuROnT5+WxiIjI3H8+HGkpqaa3P1WqcmH4oXRI9HBxwevLVgojQ0PDUGfvv0xbfpM00+kgByRujBH2TkidWGOsnNE6sIcZedYSpd9p/+scf+sZ59E+Jw34ftYTwB3/gF6UcTT6DlkJPo+/QIAoLSkGLEThmPIPyYjMPipKs8zoIP2vvdppuAfdqz6/pzZsqf0aGu27Ooo+iEDt2/fxpgxYzB79mx07Nix0v709HSUlJQgODhYGtPpdPD19UVKSkqDXMOwYcPg5uaGHj164LPPPpPtS01NlWUDwMCBA3HkyBGUlJQ0SP7dSoqLcfrUSQQGPSEbDwzqgeMZxywqR6QuzFF2jkhdmKPsHJG6MEfZOSJ1qSg3OwvX83PxsF83aayptQ0e8vHDuTMn6nVuc/Qh81D0BGfJkiVo2rQppk6dWuV+vV4PGxsbODs7y8a1Wi30en29su3t7bFixQp89tln2L17N/r164dRo0bh448/luVrtfJ/MdBqtSgtLUVOTk698quSl5+HsrIyaDQa2bhG44qcnCsWlSNSF+YoO0ekLsxRdo5IXZij7ByRulR0Pe8qAMC+hYts3L6FC67n59br3Obo01hUKvNtSqTYxbb09HT8+9//xtGjR6Gq47dnNBqlz4SEhOC77+78eK1NmzY4efKkSedwdXXF9OnTpT937doVeXl5WLp0Kf7xj39I4xWvrfyOv+qu2WAwwGAwyD9jpYZarTbpuqrLrOt3pJQckbowR9k5InVhjrJzROrCHGXniNSlcmaFgQbMNEcfalyKXcH57rvvkJ2djdatW6Np06Zo2rQpzp8/j5kzZ6Jt27YAAHd3dxQXFyMvL0/22ezsbGll5YMPPkBGRgYyMjKwe/fuel3T448/jl9//VX6s7u7e6WVouzsbDRt2rTSvw6Ui4+Ph5OTk2xbtiTepHznFs6wsrKqtDqUm3sVGo1rHduYN0ekLsxRdo5IXZij7ByRujBH2TkidanIwfnO35+u58lXa24U5MHeybmqj5jMHH3IPBQ7wRkzZgx++uknaXKSkZEBnU6H2bNn4+uvvwYABAQEwNraGvv27ZM+l5WVhRMnTiAoKAgA0LJlS3h5ecHLywtt2rSp1zUdO3YMHh4e0p8DAwNl2QCQlJSErl27wtrauspzxMTEoKCgQLbNnhtjUr61jQ06+HTE4ZTvZeOHU1Lg19m/jm3MmyNSF+YoO0ekLsxRdo5IXZij7ByRulTk4uYBhxYu+OWnvx7dXFpSgt9OHUfbh33rdW5z9GksTVTm25TIrLeo3bhxA2fPnpX+nJmZiYyMDLi4uKB169aVVkGsra3h7u6Ohx9+GADg5OSECRMmYObMmdBoNHBxccGsWbPQqVMn9O/fv8bss2fP4saNG9Dr9SgqKpKeoubj4wMbGxts2rQJ1tbW8Pf3R5MmTfDll1/i3XffxZIlS6RzREZGYuXKlZgxYwYiIiKQmpqK9evXY+vWrdXmqtWVb0ery1PUxowdh1fnzYGPry/8/PyR+Ok2ZGVlYeSo0aafRCE5InVhjrJzROrCHGXniNSFOcrOseQuhqKbyNH/If05988s/JH5K5rbO8L5AS16DhmJ//v8Y7h6PAhXjwex//OPYaNWw7/nAEX2IeUx6wTnyJEj6NOnj/TnGTNmAADGjh2LjRs3mnSOt99+G02bNsVzzz2HoqIi9OvXDxs3boSVlVWNn5s4cSKSk5OlP/v735m5Z2ZmSrfA/etf/8L58+dhZWWF9u3b48MPP5T9/sbT0xO7d+/G9OnTsWrVKuh0Orz77rsYMWKESdd+LwaFDEZBfh7WrVmNK1ey4eXdHqvWroNO19LickTqwhxl54jUhTnKzhGpC3OUnWPJXS7+dgZrY6dJf9656c77ELv2HoTRL89Hn+FhKCk24PP3V6Co8AZae3dAxOtvoZltc0X2UYIm/A2RjGLeg/N3VpcVHCIiIiJLUdt7cBqKqe/BqQ8lvwdn3eHzZsue9Hj9fgJyPyj4PxUREREREdWGCzhyin3IABERERERUV1xgkNERERERMLgLWpERERERBaMDxmQ4woOEREREREJgys4REREREQWjAs4clzBISIiIiIiYXCCQ0REREREwuAtakRERER0X+w9m9soOY3xok8l44qFHL8PIiIiIiISBldwiIiIiIgsmIpPGZDhCg4REREREQmDKzhERERERBaM6zdyXMEhIiIiIiJhcIJDRERERETCMOsE5+DBgwgNDYVOp4NKpcKOHTtk+8PDw6FSqWTb448/LjvGYDDglVdegaurK+zs7DBs2DBcunSp1uxp06YhICAAarUanTt3rvIYo9GI5cuXo3379lCr1WjVqhXi4uJkxyQnJyMgIADNmjVDu3btsHbt2jp9B/di29YtCAnui27+nTB65DM4mn7EYnNE6sIcZeeI1IU5ys4RqQtzlJ1jqV28NLaIfPxBvDnIC6ue7oBHPewrHaN1sMHkxx/E8qHt8dbQ9pjVqy2cbRvmlxWN9b01piYqldk2JTLrBKewsBB+fn5YuXJltccMGjQIWVlZ0rZ7927Z/ujoaGzfvh0JCQk4dOgQbty4gaFDh6KsrKzGbKPRiPHjx2PUqFHVHjNt2jR88MEHWL58Of73v//hyy+/xGOPPSbtz8zMxODBg9GzZ08cO3YM8+fPx9SpU5GYmGjiN1B3e/fsxtLF8YiY9BK2fbYDXboEIGpyBLIuX7a4HJG6MEfZOSJ1YY6yc0Tqwhxl51hyF5umTXCpwID//vRnlftd7awx48k2+PN6Md757jzi9mdiz/9yUFJmvOfMco31vZF5qYxGY/3/t6UBqFQqbN++HcOHD5fGwsPDkZ+fX2llp1xBQQEeeOABbN68WZqoXL58Ga1atcLu3bsxcODAWnNjY2OxY8cOZGRkyMZPnz6NRx99FCdOnMDDDz9c5Wfnzp2LnTt34vTp09JYZGQkjh8/jtTU1Fqzy90qNflQvDB6JDr4+OC1BQulseGhIejTtz+mTZ9p+okUkCNSF+YoO0ekLsxRdo5IXZij7BxL6TLzy9M17l/1dAf85/BF/JR1Qxob102H27eBTemmTzreCu1g0nH16dNMwY/m2pJe+91L98sLAQ+aLbs6iv8NzoEDB+Dm5ob27dsjIiIC2dnZ0r709HSUlJQgODhYGtPpdPD19UVKSkq9cr/88ku0a9cOX331FTw9PdG2bVtMnDgRubl/vZE3NTVVlg0AAwcOxJEjR1BSUlKv/KqUFBfj9KmTCAx6QjYeGNQDxzOOWVSOSF2Yo+wckbowR9k5InVhjrJzROpSkQqAr9Yef94oxpSgVlg82Buze7Wt8ja2ujJHHzIPRU9wQkJCsGXLFuzfvx9vvfUW0tLS0LdvXxgMBgCAXq+HjY0NnJ2dZZ/TarXQ6/X1yv79999x/vx5fPrpp/joo4+wceNGpKen49lnn5WO0ev10Gq1lbJLS0uRk5NT5XkNBgOuXbsm28r71CYvPw9lZWXQaDSycY3GFTk5V+rY0Lw5InVhjrJzROrCHGXniNSFOcrOEalLRQ5qKzSztkJwew1O/VmIld9fQEbWdUR0fxBemub1Orc5+pB5KHqCM2rUKAwZMgS+vr4IDQ3Fnj178Msvv2DXrl01fs5oNEpvdA0JCYG9vT3s7e3RsWNHk7Nv374Ng8GAjz76CD179kTv3r2xfv16fPvttzhz5ox0XMU3x5bf8VfdG2Xj4+Ph5OQk25YtiTf5uqrLvB9vsG2MHJG6MEfZOSJ1YY6yc0Tqwhxl54jUpWLWT1nX8e1vubhUYMC+X67ihP4Genq2aNCMcvezT2NRqcy3KZGC7yaszMPDA23atMGvv/4KAHB3d0dxcTHy8vJkqzj/r707D2viWv8A/g0JYQfZBKKIWLSCUEC0Cq6ggrii1rWtUBGldUerRa1a71W0trUqLnVv3VesVmpdUKwFW0FARSpacUGIgAIKYtjO7w9/5BoBRROTyfT93Gee52bOZL55B6Rzcmbm5OXlwcfHBwCwceNGlJWVAQB0dXVfK0skEqFVq1bydc7Oz67vvHPnDt59913Y2trWGinKy8uDSCSq9e1AjcjISERERCisY0K9Bn0m80bmEAqFtUaHHj58AEtLqwbtgys5fKqFcridw6daKIfbOXyqhXK4ncOnWl5UIqtEVTWD9LHi1S3SxzK8o+QIjibqIZrB6RGcFz148AB3796FnZ0dAMDLywu6uro4ceKEfJvc3FxcuXJF3sFp0qQJnJyc4OTkBAcHhwZnderUCZWVlfjnn3/k6zIzMwFAvh9vb2+FbAA4fvw42rVrV29nSk9PD6ampgqLnl7DOji6YjGcXdrgfMIfCuvPJyTA3cOzwbVxIYdPtVAOt3P4VAvlcDuHT7VQDrdz+FTLi6oYcLuwDDbGiudGjY318PCJcvc3a6IedXlxWhV1Llyk0RGckpIS3LhxQ/46KysLqampsLCwgIWFBRYsWIAhQ4bAzs4Ot27dwuzZs2FlZYVBgwYBAMzMzBAaGorp06fD0tISFhYWmDFjBtzc3NCzZ8+XZt+4cQMlJSWQSqUoKyuTP0XNxcUFYrEYPXv2RNu2bTFmzBh8//33qK6uxoQJE9CrVy/5qE54eDiio6MRERGBsLAwJCYmYtOmTdi1a9fbOWAAPg7+BHO+mAkXV1e4u3viwL49yM3NxdDhI7Quh0+1UA63c/hUC+VwO4dPtVAOt3O0uRY9oQDWxmL5a0tDMZqa6aG0vAqFZZU4ef0hxrzfBNcfPMH1/FK42BjDzdYYK87d5mQ9hHs02sFJSkqCr6+v/HXNpVvBwcFYu3YtLl++jJ9++glFRUWws7ODr68v9uzZAxMTE/l7li9fDpFIhGHDhqGsrAw9evTA1q1bIRQKX5o9duxYxMfHy197ej7ruWdlZaF58+bQ0dHBkSNHMGnSJHTt2hVGRkYIDAzEt99+K3+Po6MjYmNjMW3aNKxevRoSiQQrV67EkCFDVHJ86tI7sA+Kiwqxfu0a5OfnwallK6xetx4SSROty+FTLZTD7Rw+1UI53M7hUy2Uw+0cba6lmbkBpnb531U1H7z37IFN528XYdvFXKTlPsbu1Fz4t7LC0PdskPe4HBv/ysY/D8o4WQ8XaNUlWWrAmXlw/s1eZx4cQgghhBBt8ap5cFSlofPgKIPL8+DsSbmnsezhntzrHFKHjxBCCCGEEMIbHO6LEkIIIYQQQl6Fqzf7awqN4BBCCCGEEEJ4g0ZwCCGEEEII0WI0fqOIRnAIIYQQQgghvEEdHEIIIYQQQghv0CVqhBBCCCGEaDF6yIAi6uAQQgghhJC3wkTv5ROvE/I2UAeHEEIIIYQQLUb3nCii40EIIYQQQgjhDRrBIYQQQgghRIvRPTiKaASHEEIIIYQQwhvUwSGEEEIIIYTwBl2iRgghhBBCiBajC9QU0QgOIYQQQgghhDc02sE5e/Ys+vfvD4lEAoFAgEOHDtXaJiMjAwMGDICZmRlMTEzQsWNH3LlzR94uk8kwadIkWFlZwcjICAMGDEB2dvYrs6dMmQIvLy/o6enBw8OjVvuCBQsgEAhqLUZGRgrbxcfHw8vLC/r6+mjRogXWrVv32sfhde3ZtQOB/n5o7+mGEUMH42Jyktbm8KkWyuF2Dp9qoRxu5/CpFsrhdo621lLwzxUkbliIX+cHI2Zaf+RcTlRoT965HDHT+issZ76foVTm89R13NRJINDcwkUa7eCUlpbC3d0d0dHRdbb/888/6Ny5M1q3bo0zZ84gLS0NX375JfT19eXbTJ06FTExMdi9ezfOnTuHkpIS9OvXD1VVVS/NZoxhzJgxGD58eJ3tM2bMQG5ursLi4uKCoUOHyrfJyspCnz590KVLF6SkpGD27NmYPHkyDhw48AZHo2GO/RqLr5dEIWzcp9iz/xDatvXCZ+PDkJuTo3U5fKqFcridw6daKIfbOXyqhXK4naPNtVSWP4VZE0e8N2R8vdvYtG6LwK9+ki8+YfPfOO956jpupG6vGtxgjGHBggWQSCQwMDBA9+7dkZ6e/to5AsYYU9FnVopAIEBMTAyCgoLk60aMGAFdXV1s27atzvcUFxfD2toa27Ztk3dUcnJyYG9vj9jYWAQEBLwyd8GCBTh06BBSU1Nful1aWho8PDxw9uxZdOnSBQAwa9YsHD58GBkZGfLtwsPDkZaWhsTExPp2VcvTygZvig9HDIWziwvmzvtKvi6ofyB8/XpiyrTpDd8RB3L4VAvlcDuHT7VQDrdz+FQL5XA7R1tqWXA886XtMdP6o8OY2ZC4ecvXJe9cjoqyUnQMndvgz7nAv1WDtlOmHn0O37n+82WpxrIHutk2eNtff/0Vf/zxB9q2bYshQ4bUOvdfunQpFi1ahK1bt6JVq1b473//i7Nnz+LatWswMTFpcA5n78Gprq7G0aNH0apVKwQEBKBx48bo0KGDQk8vOTkZFRUV8Pf3l6+TSCRwdXVFQkKCSj/Pxo0b0apVK3nnBgASExMVsgEgICAASUlJqKioUGk+AFSUlyPjajq8fTorrPf26YS01BStyuFTLZTD7Rw+1UI53M7hUy2Uw+0cPtVSn4IbV3D0y49wfPF4XNyzCrLHRUrvU5P1vG06EGhseR2BgYH473//i8GDB9dqY4zh+++/x5w5czB48GC4urrixx9/xJMnT7Bz587XPB4clZeXh5KSEixZsgS9e/fG8ePHMWjQIAwePBjx8fEAAKlUCrFYDHNzc4X32tjYQCpVXU9WJpNhx44dCA0NVVgvlUphY2NTK7uyshIFBQX17uvRo0cKi0wma9DnKCwqRFVVFSwtLRXWW1paoaAg/zUq0nwOn2qhHG7n8KkWyuF2Dp9qoRxu5/CplrrYOLdDu4+mo8tni+A2IBRFd67j9zVzUFWp3JfHmqqH75Q5t31eVlYWpFKpwuCBnp4eunXr9toDF5zt4FRXVwMABg4ciGnTpsHDwwNffPEF+vXr98ob+Rlj8hldAwMDYWxsDGNjY7Rp0+aNPsvBgwfx+PFjjB49ulbbizPH1lzxV9+MslFRUTAzM1NYli2Neq3PU1fm25jBVh05fKqFcridw6daKIfbOXyqhXK4ncOnWp7X1LMLbNu0h6mdA+xc34fPuAUoyc+B9OoFlexf3fWogyYfMlDXuW1U1Oud2wKQD07UNXjwugMXnL2a0MrKCiKRCC4uLgrrnZ2dce7cOQCAra0tysvLUVhYqDCKk5eXBx8fHwDPLi0rKysDAOjq6r7RZ9m4cSP69esHW1vFawxtbW1rHfC8vDyIRKJa3w7UiIyMREREhMI6JtRr0Ocwb2QOoVBYa3To4cMHsLS0atA+uJLDp1ooh9s5fKqFcridw6daKIfbOXyqpSH0zSxgaG6N0nzlHgTAlXr4pq5zWz29hp3b1kUVHVDOjuCIxWK0b98e165dU1ifmZkJBwcHAICXlxd0dXVx4sQJeXtubi6uXLki7+A0adIETk5OcHJykr/vdWRlZeH06dO1Lk8DAG9vb4VsADh+/DjatWtXb2dKT08PpqamCktDfwl0xWI4u7TB+YQ/FNafT0iAu4dnAyviRg6faqEcbufwqRbK4XYOn2qhHG7n8KmWhpCVPkJZUQH0TS2U2g9X6uEbZc5tn1czkFDX4MGLozqvotERnJKSEty4cUP+OisrC6mpqbCwsECzZs3w+eefY/jw4ejatSt8fX1x7NgxHDlyBGfOnAEAmJmZITQ0FNOnT4elpSUsLCwwY8YMuLm5oWfPni/NvnHjBkpKSiCVSlFWViZ/ipqLiwvEYrF8u82bN8POzg6BgYG19hEeHo7o6GhEREQgLCwMiYmJ2LRpE3bt2qX8wanHx8GfYM4XM+Hi6gp3d08c2LcHubm5GDp8hNbl8KkWyuF2Dp9qoRxu5/CpFsrhdo4211IpK0NJQa789ZMH91F07ybEhsYQG5og49hOSNw7Qd/UHE8e5uHq0Z8gNjKFnVtHTtbDBYLXvNmfixwdHWFra4sTJ07A0/NZh7O8vBzx8fFYunTpa+1Lox2cpKQk+Pr6yl/XDG8FBwdj69atGDRoENatW4eoqChMnjwZ7777Lg4cOIDOnf/39Ivly5dDJBJh2LBhKCsrQ48ePbB161YIhcKXZo8dO1b+sAIA8gOZlZWF5s2bA3h2H9DWrVsREhJS5/4cHR0RGxuLadOmYfXq1ZBIJFi5ciWGDBnyxsfkVXoH9kFxUSHWr12D/Pw8OLVshdXr1kMiaaJ1OXyqhXK4ncOnWiiH2zl8qoVyuJ2jzbUU3r2Bc6tny19f/nkTAKBZez94fPAZHuXexp2k06goK4W+qTmsndzQfvRM6OobcrIe0nCvGtyYOnUqFi9ejJYtW6Jly5ZYvHgxDA0NMWrUqNfK4cw8OP9mrzMPDiGEEEKItnjVPDgqy2ngPDjK4PI8OLHpeRrL7tOmcYO3PXPmjMLgRo2awQ3GGL766iv88MMPKCwsRIcOHbB69Wq4urq+1meiDg4HUAeHEEIIIXxEHRz10JYOjrpw+EdFCCGEEEIIeZXXnXCT7zj7FDVCCCGEEEIIeV3UwSGEEEIIIYTwBl2iRgghhBBCiBZ7zXkweY9GcAghhBBCCCG8QSM4hBBCCCGEaDEawVFEHRxCCCGEEPJWdLI30/RHIP9CdIkaIYQQQgghhDdoBIcQQgghhBAtJqB5cBTQCA4hhBBCCCGEN2gEhxBCCCGEEC2mQwM4CmgEhxBCCCGEEMIbNIJDCCGEEEKIFqN7cBRpdATn7Nmz6N+/PyQSCQQCAQ4dOqTQLhAI6lyWLVsm30Ymk2HSpEmwsrKCkZERBgwYgOzs7FdmT5kyBV5eXtDT04OHh0ed2/z222/o2LEjTExMYG1tjSFDhiArK0thm/j4eHh5eUFfXx8tWrTAunXrXvs4vK49u3Yg0N8P7T3dMGLoYFxMTtLaHD7VQjnczuFTLZTD7Rw+1UI53M7R1lr+uZqKTVFfYGHYIMz4oCuu/PW7QjtjDL/t2YyFYYPwxaieWDNvMqR3s+rZ2+tT13EjmqPRDk5paSnc3d0RHR1dZ3tubq7CsnnzZggEAgwZMkS+zdSpUxETE4Pdu3fj3LlzKCkpQb9+/VBVVfXSbMYYxowZg+HDh9fZfvPmTQwcOBB+fn5ITU3Fb7/9hoKCAgwePFi+TVZWFvr06YMuXbogJSUFs2fPxuTJk3HgwIE3OBoNc+zXWHy9JAph4z7Fnv2H0LatFz4bH4bcnByty+FTLZTD7Rw+1UI53M7hUy2Uw+0cba6l/OlTSJq/g0GhU+tsP31oJ87+sheDQqdiypL1MG1kgfULI/C07MkbZ9ZQ13EjmiVgjDFNfwjg2WhNTEwMgoKC6t0mKCgIjx8/xqlTpwAAxcXFsLa2xrZt2+QdlZycHNjb2yM2NhYBAQGvzF2wYAEOHTqE1NRUhfX79+/HyJEjIZPJoKPzrB945MgRDBw4EDKZDLq6upg1axYOHz6MjIwM+fvCw8ORlpaGxMTEBtf+tLLBm+LDEUPh7OKCufO+kq8L6h8IX7+emDJtesN3xIEcPtVCOdzO4VMtlMPtHD7VQjncztGWWk5k3H9p+4wPuiJk5iK4vt8FwLMvoBeGDUKXvkPhN+hDAEBlRTkWhAah70fj4e0/sM799HK2eev16HP4xo7T1x5oLNv3XUuNZddHax4ycP/+fRw9ehShoaHydcnJyaioqIC/v798nUQigaurKxISEpTKa9euHYRCIbZs2YKqqioUFxdj27Zt8Pf3h66uLgAgMTFRIRsAAgICkJSUhIqKCqXy61JRXo6Mq+nw9umssN7bpxPSUlO0KodPtVAOt3P4VAvlcDuHT7VQDrdz+FTLix7m5eJx0UO8695evk6kK8Y7Lu64de2KUvvWRD1EM7Smg/Pjjz/CxMRE4RIxqVQKsVgMc3NzhW1tbGwglUqVymvevDmOHz+O2bNnQ09PD40aNUJ2djZ2796tkG9jo/iNgY2NDSorK1FQUKBUfl0KiwpRVVUFS0vFnrKlpRUKCvK1KodPtVAOt3P4VAvlcDuHT7VQDrdz+FTLix4XPhuJMG5kobDeuJEFHhc9VGrfmqhHXQQa/B8XaU0HZ/Pmzfjwww+hr6//ym0ZYxAInh3wwMBAGBsbw9jYGG3atGlwnlQqxdixYxEcHIwLFy4gPj4eYrEYH3zwAZ6/qq8m5/nsutbXkMlkePTokcIik8ka/Lnqy6wvTxnqyOFTLZTD7Rw+1UI53M7hUy2Uw+0cPtVSO/OFFSrM1EQ9RL20ooPz+++/49q1axg7dqzCeltbW5SXl6OwsFBhfV5ennxkZePGjUhNTUVqaipiY2MbnLl69WqYmpri66+/hqenJ7p27Yrt27fj1KlT+PPPP+X5L44U5eXlQSQS1fp2oEZUVBTMzMwUlmVLoxr0mcwbmUMoFNYaHXr48AEsLa0aXBsXcvhUC+VwO4dPtVAOt3P4VAvlcDuHT7W8yMT82fnT40LF0ZqS4kIYm5nX9ZYG00Q9RDO0ooOzadMmeHl5wd3dXWG9l5cXdHV1ceLECfm63NxcXLlyBT4+PgCAJk2awMnJCU5OTnBwcGhw5pMnTyAUChXW1byurq4GAHh7eytkA8Dx48fRrl07+X06L4qMjERxcbHC8vmsyAZ9Jl2xGM4ubXA+4Q+F9ecTEuDu4dmgfXAlh0+1UA63c/hUC+VwO4dPtVAOt3P4VMuLLBrbwaSRBTIv/e/RzZUVFfjnahqav+uq1L41UY+66Ag0t3CRRp8HUVJSghs3bshfZ2VlITU1FRYWFmjWrBkA4NGjR9i3bx++/fbbWu83MzNDaGgopk+fDktLS1hYWGDGjBlwc3NDz549X5p948YNlJSUQCqVoqysTP4UNRcXF4jFYvTt2xfLly/HwoULMXLkSDx+/BizZ8+Gg4MDPD2f/SMIDw9HdHQ0IiIiEBYWhsTERGzatAm7du2qN1dPTw96enoK617nKWofB3+COV/MhIurK9zdPXFg3x7k5uZi6PARDd8JR3L4VAvlcDuHT7VQDrdz+FQL5XA7R5trkZU9QYH0nvz1w/u5uJd1HYbGpjC3tkGXvkNx6uB2WNk1hZVdU8Qd3A6xnh48u/TiZD2EezTawUlKSoKvr6/8dUREBAAgODgYW7duBQDs3r0bjDGMHDmyzn0sX74cIpEIw4YNQ1lZGXr06IGtW7fWGn150dixYxEfHy9/XdNpycrKQvPmzeHn54edO3fi66+/xtdffw1DQ0N4e3vj2LFjMDAwAAA4OjoiNjYW06ZNw+rVqyGRSLBy5UqFeXpUrXdgHxQXFWL92jXIz8+DU8tWWL1uPSSSJlqXw6daKIfbOXyqhXK4ncOnWiiH2znaXMvdf65h3YIp8teHf3w2H2K77r0xYuJs+AaNQkW5DAc3fIey0hI0a+mMsC+/hb6BISfr4QKu3uyvKZyZB+ff7HVGcAghhBBCtMWr5sFRlYbOg6MMLs+D83tm4as3eku6tFLu3qi3gcM/KkIIIYQQQsir0EPgFGnFQwYIIYQQQgghpCGog0MIIYQQQgjhDbpEjRBCCCGEEC1GV6gpohEcQgghhBBCCG/QCA4hhBBCCCFaTIeeMqCARnAIIYQQQgghvEEdHEIIIYQQQghv0CVqhBBCCCHkrfjjbrFactQx0SeX0QVqimgEhxBCCCGEEMIbNIJDCCGEEEKINqMhHAU0gkMIIYQQQgjhDRrBIYQQQgghRIsJaAhHAY3gEEIIIYQQQniDOjiEEEIIIYQQ3tBoB+fs2bPo378/JBIJBAIBDh06pNBeUlKCiRMnomnTpjAwMICzszPWrl2rsI1MJsOkSZNgZWUFIyMjDBgwANnZ2a/MnjJlCry8vKCnpwcPD486t9m7dy88PDxgaGgIBwcHLFu2rNY28fHx8PLygr6+Plq0aIF169Y1uP43tWfXDgT6+6G9pxtGDB2Mi8lJWpvDp1ooh9s5fKqFcridw6daKIfbOdpaS8E/V5C4YSF+nR+MmGn9kXM5UaE9eedyxEzrr7Cc+X6GUpnPU9dxUyeBQHMLF2m0g1NaWgp3d3dER0fX2T5t2jQcO3YM27dvR0ZGBqZNm4ZJkybh559/lm8zdepUxMTEYPfu3Th37hxKSkrQr18/VFVVvTSbMYYxY8Zg+PDhdbb/+uuv+PDDDxEeHo4rV65gzZo1+O677xQ+a1ZWFvr06YMuXbogJSUFs2fPxuTJk3HgwIE3OBoNc+zXWHy9JAph4z7Fnv2H0LatFz4bH4bcnByty+FTLZTD7Rw+1UI53M7hUy2Uw+0cba6lsvwpzJo44r0h4+vdxqZ1WwR+9ZN88Qmb/8Z5z1PXcSOaJWCMMU1/CAAQCASIiYlBUFCQfJ2rqyuGDx+OL7/8Ur7Oy8sLffr0wX/+8x8UFxfD2toa27Ztk3dUcnJyYG9vj9jYWAQEBLwyd8GCBTh06BBSU1MV1o8aNQoVFRXYt2+ffN3333+Pb7/9Fnfu3IFAIMCsWbNw+PBhZGRkyLcJDw9HWloaEhMVv414maeVDd4UH44YCmcXF8yd95V8XVD/QPj69cSUadMbviMO5PCpFsrhdg6faqEcbufwqRbK4XaOttSy4HjmS9tjpvVHhzGzIXHzlq9L3rkcFWWl6Bg6t8Gfc4F/qwZtp0w9+hx+NNeFm+qZULUu7VuYaSy7Ppy+B6dz5844fPgw7t27B8YYTp8+jczMTHnHJTk5GRUVFfD395e/RyKRwNXVFQkJCUply2Qy6OvrK6wzMDBAdnY2bt++DQBITExUyAaAgIAAJCUloaKiQqn8ulSUlyPjajq8fTorrPf26YS01BStyuFTLZTD7Rw+1UI53M7hUy2Uw+0cPtVSn4IbV3D0y49wfPF4XNyzCrLHRUrvU5P1EPXidAdn5cqVcHFxQdOmTSEWi9G7d2+sWbMGnTs/+8WUSqUQi8UwNzdXeJ+NjQ2kUqlS2QEBATh48CBOnTqF6upqZGZm4vvvvwcA5ObmyvNtbGxqZVdWVqKgoKDO/cpkMjx69EhhkclkDfpMhUWFqKqqgqWlpcJ6S0srFBTkv2aFms3hUy2Uw+0cPtVCOdzO4VMtlMPtHD7VUhcb53Zo99F0dPlsEdwGhKLoznX8vmYOqiqV+/JYU/UQ9eN8B+f8+fM4fPgwkpOT8e233+Kzzz7DyZMnX/o+xhgE/3/XU2BgIIyNjWFsbIw2bdo0ODssLAwTJ05Ev379IBaL0bFjR4wYMQIAIBQK5dsJXri7quaKvxfX14iKioKZmZnCsmxpVIM/V32Z9eUpQx05fKqFcridw6daKIfbOXyqhXK4ncOnWp7X1LMLbNu0h6mdA+xc34fPuAUoyc+B9OoFlexf3fWohUCDCwdx9mrCsrIyzJ49GzExMejbty8A4L333kNqaiq++eYb9OzZE7a2tigvL0dhYaHCKE5eXh58fHwAABs3bkRZWRkAQFdXt8H5AoEAS5cuxeLFiyGVSmFtbY1Tp04BAJo3bw4AsLW1rTVSlJeXB5FIVOvbgRqRkZGIiIhQWMeEeg36TOaNzCEUCmuNDj18+ACWllYN2gdXcvhUC+VwO4dPtVAOt3P4VAvlcDuHT7U0hL6ZBQzNrVGar9yDALhSD3n7ODuCU1FRgYqKCujoKH5EoVCI6upqAM8eOKCrq4sTJ07I23Nzc3HlyhV5B6dJkyZwcnKCk5MTHBwcXvtzCIVCNGnSBGKxGLt27YK3tzcaN24MAPD29lbIBoDjx4+jXbt29Xam9PT0YGpqqrDo6TWsg6MrFsPZpQ3OJ/yhsP58QgLcPTxfuzZN5vCpFsrhdg6faqEcbufwqRbK4XYOn2ppCFnpI5QVFUDf1EKp/XClnrdBoMH/cZFGR3BKSkpw48YN+eusrCykpqbCwsICzZo1Q7du3fD555/DwMAADg4OiI+Px08//YTvvvsOAGBmZobQ0FBMnz4dlpaWsLCwwIwZM+Dm5oaePXu+NPvGjRsoKSmBVCpFWVmZ/ClqLi4uEIvFKCgowP79+9G9e3c8ffoUW7Zswb59+xAfHy/fR3h4OKKjoxEREYGwsDAkJiZi06ZN2LVrl+oP1v/7OPgTzPliJlxcXeHu7okD+/YgNzcXQ4eP0LocPtVCOdzO4VMtlMPtHD7VQjncztHmWiplZSgpyJW/fvLgPoru3YTY0BhiQxNkHNsJiXsn6Jua48nDPFw9+hPERqawc+vIyXoI92i0g5OUlARfX1/565pLt4KDg7F161bs3r0bkZGR+PDDD/Hw4UM4ODhg0aJFCA8Pl79n+fLlEIlEGDZsGMrKytCjRw9s3bpV4T6ZuowdO1ahs+Lp+aznnpWVJb8E7ccff8SMGTPAGIO3tzfOnDmD999/X/4eR0dHxMbGYtq0aVi9ejUkEglWrlyJIUOGKH1s6tM7sA+Kiwqxfu0a5OfnwallK6xetx4SSROty+FTLZTD7Rw+1UI53M7hUy2Uw+0cba6l8O4NnFs9W/768s+bAADN2vvB44PP8Cj3Nu4knUZFWSn0Tc1h7eSG9qNnQlffkJP1cIG230KkapyZB+ff7HXmwSGEEEII0RavmgdHZTkNnAdHGVyeByf51iONZXs1N9VYdn04ew8OIYQQQgghhLwuDvdFCSGEEEIIIa9CV6gpohEcQgghhBBCCG/QCA4hhBBCCCHajIZwFNAIDiGEEEIIIYQ3qINDCCGEEEII4Q26RI0QQgghhBAtJqBr1BTQCA4hhBBCCCGEN2gEhxBCCCGEEC0moAEcBTSCQwghhBBCCOENGsEhhBBCCCFEi9EAjiIawSGEEEIIIYTwBnVwCCGEEEIIIbxBl6gRQgghhBCizegaNQU0gkMIIYQQQgjhDY12cM6ePYv+/ftDIpFAIBDg0KFDCu33799HSEgIJBIJDA0N0bt3b1y/fl1hG5lMhkmTJsHKygpGRkYYMGAAsrOzX5qblpaGkSNHwt7eHgYGBnB2dsaKFStqbXf58mV069YNBgYGaNKkCRYuXAjGmMI28fHx8PLygr6+Plq0aIF169a92cF4DXt27UCgvx/ae7phxNDBuJicpLU5fKqFcridw6daKIfbOXyqhXK4naOttRT8cwWJGxbi1/nBiJnWHzmXExXak3cuR8y0/grLme9nKJX5PHUdN3USaPB/XKTRDk5paSnc3d0RHR1dq40xhqCgINy8eRM///wzUlJS4ODggJ49e6K0tFS+3dSpUxETE4Pdu3fj3LlzKCkpQb9+/VBVVVVvbnJyMqytrbF9+3akp6djzpw5iIyMVPgcjx49Qq9evSCRSHDhwgWsWrUK33zzDb777jv5NllZWejTpw+6dOmClJQUzJ49G5MnT8aBAwdUdIRqO/ZrLL5eEoWwcZ9iz/5DaNvWC5+ND0NuTo7W5fCpFsrhdg6faqEcbufwqRbK4XaONtdSWf4UZk0c8d6Q8fVuY9O6LQK/+km++ITNf+O856nruBHNErAXhyQ0RCAQICYmBkFBQQCAzMxMvPvuu7hy5QratGkDAKiqqkLjxo2xdOlSjB07FsXFxbC2tsa2bdswfPhwAEBOTg7s7e0RGxuLgICABudPmDABGRkZiIuLAwCsXbsWkZGRuH//PvT09AAAS5YswapVq5CdnQ2BQIBZs2bh8OHDyMjIkO8nPDwcaWlpSExMrDOnLk8rG7wpPhwxFM4uLpg77yv5uqD+gfD164kp06Y3fEccyOFTLZTD7Rw+1UI53M7hUy2Uw+0cballwfHMl7bHTOuPDmNmQ+LmLV+XvHM5KspK0TF0boM/5wL/Vg3aTpl69Dl85/qluyUay37P3lhj2fXh7D04MpkMAKCvry9fJxQKIRaLce7cOQDPRmIqKirg7+8v30YikcDV1RUJCQmvlVdcXAwLCwv568TERHTr1k3euQGAgIAA5OTk4NatW/Jtns+u2SYpKQkVFRWvld8QFeXlyLiaDm+fzgrrvX06IS01Raty+FQL5XA7h0+1UA63c/hUC+VwO4dPtdSn4MYVHP3yIxxfPB4X96yC7HGR0vvUZD1vm0CguYWLONvBad26NRwcHBAZGYnCwkKUl5djyZIlkEqlyM3NBQBIpVKIxWKYm5srvNfGxgZSqbTBWYmJidi7dy/Gj//fUKlUKoWNjU2t/da0vWybyspKFBQU1Jklk8nw6NEjhaWmM/cqhUWFqKqqgqWlpcJ6S0srFBTkN2gfXMnhUy2Uw+0cPtVCOdzO4VMtlMPtHD7VUhcb53Zo99F0dPlsEdwGhKLoznX8vmYOqiqV+/JYU/UQ9eNsB0dXVxcHDhxAZmYmLCwsYGhoiDNnziAwMBBCofCl72WMQfD/XcrAwEAYGxvD2NhYfqnb89LT0zFw4EDMmzcPvXr1UmgTvNAtrbma7/n1DdnmeVFRUTAzM1NYli2Nemk9L6ors748Zagjh0+1UA63c/hUC+VwO4dPtVAOt3P4VMvzmnp2gW2b9jC1c4Cd6/vwGbcAJfk5kF69oJL9q7sedRBocOEiDl9NCHh5eSE1NRXFxcUoLy+HtbU1OnTogHbt2gEAbG1tUV5ejsLCQoVRnLy8PPj4+AAANm7ciLKyMgDPOk3Pu3r1Kvz8/BAWFoa5cxWv87S1ta01CpSXlwfgfyM59W0jEolqfTtQIzIyEhEREQrrmFCvzm1fZN7IHEKhsNbo0MOHD2BpadWgfXAlh0+1UA63c/hUC+VwO4dPtVAOt3P4VEtD6JtZwNDcGqX5yj0IgCv1kLePsyM4zzMzM4O1tTWuX7+OpKQkDBw4EMCzDpCuri5OnDgh3zY3NxdXrlyRd3CaNGkCJycnODk5wcHBQb5deno6fH19ERwcjEWLFtXK9Pb2xtmzZ1FeXi5fd/z4cUgkEjRv3ly+zfPZNdu0a9euVmeqhp6eHkxNTRWW5+/zeRldsRjOLm1wPuEPhfXnExLg7uHZoH1wJYdPtVAOt3P4VAvlcDuHT7VQDrdz+FRLQ8hKH6GsqAD6phav3vgluFIPefs0OoJTUlKCGzduyF9nZWUhNTUVFhYWaNasGfbt2wdra2s0a9YMly9fxpQpUxAUFCS/sd/MzAyhoaGYPn06LC0tYWFhgRkzZsDNzQ09e/asN7emc+Pv74+IiAj5KIxQKIS1tTUAYNSoUfjqq68QEhKC2bNn4/r161i8eDHmzZsnH8YMDw9HdHQ0IiIiEBYWhsTERGzatAm7du16W4cMHwd/gjlfzISLqyvc3T1xYN8e5ObmYujwEVqXw6daKIfbOXyqhXK4ncOnWiiH2znaXEulrAwlBbny108e3EfRvZsQGxpDbGiCjGM7IXHvBH1Tczx5mIerR3+C2MgUdm4dOVkPJ3D1WjEN0WgHJykpCb6+vvLXNZduBQcHY+vWrcjNzUVERATu378POzs7jB49Gl9++aXCPpYvXw6RSIRhw4ahrKwMPXr0wNatW196n86+ffuQn5+PHTt2YMeOHfL1Dg4O8iekmZmZ4cSJE5gwYQLatWsHc3NzREREKFxe5ujoiNjYWEybNg2rV6+GRCLBypUrMWTIEFUcnjr1DuyD4qJCrF+7Bvn5eXBq2Qqr162HRNJE63L4VAvlcDuHT7VQDrdz+FQL5XA7R5trKbx7A+dWz5a/vvzzJgBAs/Z+8PjgMzzKvY07SadRUVYKfVNzWDu5of3omdDVN+RkPYR7ODMPzr/Z68yDQwghhBCiLV41D47Kcho4D44yuDwPTvq9Uo1lt2lipLHs+mjFPTiEEEIIIYQQ0hAc7osSQgghhBBCXkXLn3KtcjSCQwghhBBCCOEN6uAQQgghhBBCeIMuUSOEEEIIIUSL0RVqimgEhxBCCCGEEMIbNIJDCCGEEEKINqMhHAXUwSGEEEIIIW/F2StS9QSpYR4coj3oEjVCCCGEEEIIb9AIDiGEEEIIIVpMQNeoKaARHEIIIYQQQshbt2DBAggEAoXF1tZW5Tk0gkMIIYQQQogWE2jRAE6bNm1w8uRJ+WuhUKjyDOrgEEIIIYQQQt6ITCaDTCZTWKenpwc9Pb06txeJRG9l1OZ5dIkaIYQQQgghWkygwSUqKgpmZmYKS1RUVL2f9fr165BIJHB0dMSIESNw8+ZNVR4KABru4ERFRaF9+/YwMTFB48aNERQUhGvXrilswxjDggULIJFIYGBggO7duyM9PV1hG5lMhkmTJsHKygpGRkYYMGAAsrOzX5qdlpaGkSNHwt7eHgYGBnB2dsaKFSsUtnn69ClCQkLg5uYGkUiEoKCgOvcVHx8PLy8v6Ovro0WLFli3bt3rH4zXsGfXDgT6+6G9pxtGDB2Mi8lJWpvDp1ooh9s5fKqFcridw6daKIfbOdpay8cd7LHpY0+cmOqDoxM6YskgFzSzMFDYpltLSywf6orYid5ImNkVLRsbKZX5PHUdt3+LyMhIFBcXKyyRkZF1btuhQwf89NNP+O2337BhwwZIpVL4+PjgwYMHKv1MGu3gxMfHY8KECTh//jxOnDiByspK+Pv7o7S0VL7N119/je+++w7R0dG4cOECbG1t0atXLzx+/Fi+zdSpUxETE4Pdu3fj3LlzKCkpQb9+/VBVVVVvdnJyMqytrbF9+3akp6djzpw5iIyMRHR0tHybqqoqGBgYYPLkyejZs2ed+8nKykKfPn3QpUsXpKSkYPbs2Zg8eTIOHDiggiNU27FfY/H1kiiEjfsUe/YfQtu2XvhsfBhyc3K0LodPtVAOt3P4VAvlcDuHT7VQDrdztLkWT3szHEjJwbhtqZiy9zKEOgJ8P9QN+rr/Oy010BXi0r1HWHs2SxVlyKnruP2b6OnpwdTUVGGp7/K0wMBADBkyBG5ubujZsyeOHj0KAPjxxx9V+pkEjDGm0j0qIT8/H40bN0Z8fDy6du0KxhgkEgmmTp2KWbNmAXg2WmNjY4OlS5di/PjxKC4uhrW1NbZt24bhw4cDAHJycmBvb4/Y2FgEBAQ0OH/ChAnIyMhAXFxcrbaQkBAUFRXh0KFDCutnzZqFw4cPIyMjQ74uPDwcaWlpSExMbFDu08oGf0R8OGIonF1cMHfeV/J1Qf0D4evXE1OmTW/4jjiQw6daKIfbOXyqhXK4ncOnWiiH2znaUovfd2dfuU0jA13ETvLGZzvTkJpdrNBma6qHg+EdELw1GdfzSuvZAxAX0fWVOYBy9ehz+M71zPtPNJbdysZQqff36tULTk5OWLt2rYo+EcfuwSkufvZLbWFhAeDZ6IhUKoW/v798Gz09PXTr1g0JCQkAno3EVFRUKGwjkUjg6uoq3+Z18muyGyoxMVEhGwACAgKQlJSEioqK19rXq1SUlyPjajq8fTorrPf26YS01BStyuFTLZTD7Rw+1UI53M7hUy2Uw+0cPtUCAEZ6z56i9eipas+bXqSuekjDyWQyZGRkwM7OTqX75UwHhzGGiIgIdO7cGa6urgAAqVQKALCxsVHY1sbGRt4mlUohFothbm5e7zYNkZiYiL1792L8+PGv9bmlUmmdn6+yshIFBQWvta9XKSwqRFVVFSwtLRXWW1paoaAgX6ty+FQL5XA7h0+1UA63c/hUC+VwO4dPtQDAZL93kHq3GDcL3u4ohLrq0QSBBv/3OmbMmIH4+HhkZWXhzz//xAcffIBHjx4hODhYpceDM4NtEydOxKVLl3Du3LlabYIXHu7NGKu17kXPbxMYGIjff/8dAODg4FDrIQXp6ekYOHAg5s2bh169er32Z6/r89W1Hqj7UXpMWP+j9Bqa96rj8SbUkcOnWiiH2zl8qoVyuJ3Dp1ooh9s5fKhlek8nOFkbIXxHqkr21xDqOm6ktuzsbIwcORIFBQWwtrZGx44dcf78eTg4OKg0hxMdnEmTJuHw4cM4e/YsmjZtKl9f84xsqVSqMHSVl5cnHzWxtbVFeXk5CgsLFUZx8vLy4OPjAwDYuHEjysrKAAC6uroK2VevXoWfnx/CwsIwd+7c1/7stra2tUaK8vLyIBKJan1DADx7ctxXX32lsG7Ol/Mxd96CV2aZNzKHUCisNTL08OEDWFpavfZn12QOn2qhHG7n8KkWyuF2Dp9qoRxu5/Cllmk93kFnJ0t8tisN+SXlSu/vVdR13Ej9du/erZYcjV6ixhjDxIkTcfDgQcTFxcHR0VGh3dHREba2tjhx4oR8XXl5OeLj4+WdFy8vL+jq6ipsk5ubiytXrsi3adKkCZycnODk5KTQQ0xPT4evry+Cg4OxaNGiN6rB29tbIRsAjh8/jnbt2tXqTAF1P0rv81l1P0rvRbpiMZxd2uB8wh8K688nJMDdw/ONPr+mcvhUC+VwO4dPtVAOt3P4VAvlcDuHD7VE9HwH3VtZYdKeNOQWP1VqXw2lruOmCQKB5hYu0ugIzoQJE7Bz5078/PPPMDExkY+EmJmZwcDAAAKBAFOnTsXixYvRsmVLtGzZEosXL4ahoSFGjRol3zY0NBTTp0+HpaUlLCwsMGPGDPnj5+pT07nx9/dHRESEPFsoFMLa2lq+3dWrV1FeXo6HDx/i8ePHSE1NBQB4eHgAePbEtOjoaERERCAsLAyJiYnYtGkTdu3aVWduXTO7vs5T1D4O/gRzvpgJF1dXuLt74sC+PcjNzcXQ4SMavhOO5PCpFsrhdg6faqEcbufwqRbK4XaONtcyo5cTejk3xqyYdDwpr4KF0bMvhEtkVSivrAYAmOiLYGuqBytjMQCgmcWzJ3U9KC3Hw9I3fxiBuo4b0SyNdnBqHgfXvXt3hfVbtmxBSEgIAGDmzJkoKyvDZ599hsLCQnTo0AHHjx+HiYmJfPvly5dDJBJh2LBhKCsrQ48ePbB161YIhcJ6s/ft24f8/Hzs2LEDO3bskK93cHDArVu35K/79OmD27dvy197ej7r4dfcZ+Po6IjY2FhMmzYNq1evhkQiwcqVKzFkyJA3Oiav0juwD4qLCrF+7Rrk5+fBqWUrrF63HhJJE63L4VMtlMPtHD7VQjnczuFTLZTD7RxtrmWwpwQAsGaku8L6/8ZeQ+yV+wCALk6WmNvnXXnbfwY4AwA2/XEbm/64jTelruOmbhwdSNEYTs2D82/1OiM4hBBCCCHaoiHz4KhCQ+fBUQaX58H5J69MY9nvNDbQWHZ9OPyjIoQQQgghhLwSDeEo4Mw8OIQQQgghhBCiLOrgEEIIIYQQQniDLlEjhBBCCCFEiwnoGjUFNIJDCCGEEEII4Q0awSGEEEIIIUSLcXXCTU2hERxCCCGEEEIIb1AHhxBCCCGEEMIbdIkaIYQQQgh5K57SbOZqQVeoKaIRHEIIIYQQQghv0AgOIYQQQggh2oyGcBTQCA4hhBBCCCGEN2gEhxBCCCGEEC1GE30qohEcQgghhBBCCG9QB4cQQgghhBDCGxrt4ERFRaF9+/YwMTFB48aNERQUhGvXrilsc/DgQQQEBMDKygoCgQCpqam19iOTyTBp0iRYWVnByMgIAwYMQHZ29kuz09LSMHLkSNjb28PAwADOzs5YsWKFwjZnzpzBwIEDYWdnByMjI3h4eGDHjh219hUfHw8vLy/o6+ujRYsWWLdu3esfjNewZ9cOBPr7ob2nG0YMHYyLyUlam8OnWiiH2zl8qoVyuJ3Dp1ooh9s52lrLJ50csC20HX6f1RUnp3fGt8Pc4GBpKG8X6Qgwucc72DP+ffzxRTf8Nq0TFg50hpWxWNlSAKjvuKmTQKC5hYs02sGJj4/HhAkTcP78eZw4cQKVlZXw9/dHaWmpfJvS0lJ06tQJS5YsqXc/U6dORUxMDHbv3o1z586hpKQE/fr1Q1VVVb3vSU5OhrW1NbZv34709HTMmTMHkZGRiI6Olm+TkJCA9957DwcOHMClS5cwZswYjB49GkeOHJFvk5WVhT59+qBLly5ISUnB7NmzMXnyZBw4cEDJo1O3Y7/G4uslUQgb9yn27D+Etm298Nn4MOTm5GhdDp9qoRxu5/CpFsrhdg6faqEcbudocy1eDo2wNykbwZuT8en2VIh0BFjzoQf0dZ+dlurr6qC1nQk2/n4LozZcwIy9l+FgaYjvR7zHyXoI9wgYY0zTH6JGfn4+GjdujPj4eHTt2lWh7datW3B0dERKSgo8PDzk64uLi2FtbY1t27Zh+PDhAICcnBzY29sjNjYWAQEBDc6fMGECMjIyEBcXV+82ffv2hY2NDTZv3gwAmDVrFg4fPoyMjAz5NuHh4UhLS0NiYmKDcl9nDqwPRwyFs4sL5s77Sr4uqH8gfP16Ysq06Q3fEQdy+FQL5XA7h0+1UA63c/hUC+VwO0dbavFZXP85VY1GhrqIm9EFY7dexMU7RXVu4yIxwfax7dHn+z8gfSSr1Z4w2++VOYBy9ehz+NFcdx/WPibqYm+hp7Hs+nDqHpzi4mIAgIWFRYPfk5ycjIqKCvj7+8vXSSQSuLq6IiEh4bXzX5X94jaJiYkK2QAQEBCApKQkVFRUvFb+q1SUlyPjajq8fTorrPf26YS01BStyuFTLZTD7Rw+1UI53M7hUy2Uw+0cPtUCACZ6z3oOxWX1nzcZ64lQzRgev863wi9QVz1E8zjTF2WMISIiAp07d4arq2uD3yeVSiEWi2Fubq6w3sbGBlKptMH7SUxMxN69e3H06NF6t9m/fz8uXLiAH374QSHfxsamVnZlZSUKCgpgZ2en0CaTySCTKfaymVAPenqv7v0WFhWiqqoKlpaWCustLa1QUJD/yvc3lDpy+FQL5XA7h0+1UA63c/hUC+VwO4dPtQBAhL8TUu4U4Z/80jrbxUIdTO7xDo5dvo/S8vpvP3gVddVDNI8zIzgTJ07EpUuXsGvXLpXsjzEGwf/f+RQYGAhjY2MYGxujTZs2tbZNT0/HwIEDMW/ePPTq1avO/Z05cwYhISHYsGFDrX0IXrjDquaqvxfXA88erGBmZqawLFsa9Vq11ZVXV5ay1JHDp1ooh9s5fKqFcridw6daKIfbOXyo5YvAVmhpY4zIA+l1tot0BIga0gYCgQBRsdfq3OZ1qeu4qRM9ZEARJ0ZwJk2ahMOHD+Ps2bNo2rTpa73X1tYW5eXlKCwsVBjFycvLg4+PDwBg48aNKCsrAwDo6uoqvP/q1avw8/NDWFgY5s6dW2dGfHw8+vfvj++++w6jR4+ulf/iSFFeXh5EIlGtbwgAIDIyEhEREQrrmLBh1y6aNzKHUChEQUGBwvqHDx/A0tKqQfvgSg6faqEcbufwqRbK4XYOn2qhHG7n8KWWmb1bomsrK4z98SLyHte+h0SkI8CSD1zRpJE+xm9LUWr0BlDfcSOap9ERHMYYJk6ciIMHDyIuLg6Ojo6vvQ8vLy/o6urixIkT8nW5ubm4cuWKvIPTpEkTODk5wcnJCQ4ODvLt0tPT4evri+DgYCxatKjO/Z85cwZ9+/bFkiVLMG7cuFrt3t7eCtkAcPz4cbRr165WZwoA9PT0YGpqqrA05PI0ANAVi+Hs0gbnE/5QWH8+IQHuHp4N2gdXcvhUC+VwO4dPtVAOt3P4VAvlcDuHD7XM6t0Kfq0bY/y2FOQUPa3VXtO5aWZhgPDtqSgue/N7b2qo67hphkCDC/dodARnwoQJ2LlzJ37++WeYmJjIR0LMzMxgYGAAAHj48CHu3LmDnP9/fF/NPDm2trawtbWFmZkZQkNDMX36dFhaWsLCwgIzZsyAm5sbevbsWW92TefG398fERER8myhUAhra2sA/+vcTJkyBUOGDJFvIxaL5Q8aCA8PR3R0NCIiIhAWFobExERs2rRJZZfavejj4E8w54uZcHF1hbu7Jw7s24Pc3FwMHT5C63L4VAvlcDuHT7VQDrdz+FQL5XA7R5tr+SKwFQLdbDBtz2U8kVXB0ujZ/DYlskrIKqshFAjw9VBXtLY1wZTdlyAUCOTbFJdVoLL6zR8ArK7jRjRLox2ctWvXAgC6d++usH7Lli0ICQkBABw+fBiffPKJvG3EiGe/gPPnz8eCBQsAAMuXL4dIJMKwYcNQVlaGHj16YOvWrRAKhfVm79u3D/n5+dixY4fC5J0ODg64desWAGDr1q148uQJoqKiEBX1v/tkunXrhjNnzgAAHB0dERsbi2nTpmH16tWQSCRYuXIlhgwZ8iaH5JV6B/ZBcVEh1q9dg/z8PDi1bIXV69ZDImmidTl8qoVyuJ3Dp1ooh9s5fKqFcrido821DGv/7HaEjcFtFdbP//kqjqRJ0dhUD93fffZl857x7ytsE/bjRSTfLnrjbHUdN3Xj6r0wmsKpeXD+rZR44iEhhBBCCGc1ZB4cVWjoPDjK4PI8OPeKyjWW3aSRWGPZ9eHMU9QIIYQQQgghRFkc7osSQgghhBBCXoWuUFNEIziEEEIIIYQQ3qARHEIIIYQQQrQYPWRAEY3gEEIIIYQQQniDOjiEEEIIIYQQ3qBL1AghhBBCCNFiAnrMgALq4BBCCCGEkLciI+ageoLUMA8O0R7UwSGEEEIIIUSb0QCOAroHhxBCCCGEEMIbNIJDCCGEEEKIFqMBHEU0gkMIIYQQQgjhDergEEIIIYQQQniDLlEjhBBCCCFEiwnoGjUFNIJDCCGEEEII4Q2NdnCioqLQvn17mJiYoHHjxggKCsK1a9fk7RUVFZg1axbc3NxgZGQEiUSC0aNHIycnR2E/MpkMkyZNgpWVFYyMjDBgwABkZ2e/NDstLQ0jR46Evb09DAwM4OzsjBUrVihsc+3aNfj6+sLGxgb6+vpo0aIF5s6di4qKCoXt4uPj4eXlJd9m3bp1Sh6Zl9uzawcC/f3Q3tMNI4YOxsXkJK3N4VMtlMPtHD7VQjnczuFTLZTD7RxtrSVsaGf8tScS939fhvu/L8OZH6fDv5MLAEAk0sF/Jw/Ehb2zUZDwLW4eX4SN//kYdtZmqigFgPqOmzoJNPg/LtJoByc+Ph4TJkzA+fPnceLECVRWVsLf3x+lpaUAgCdPnuDixYv48ssvcfHiRRw8eBCZmZkYMGCAwn6mTp2KmJgY7N69G+fOnUNJSQn69euHqqqqerOTk5NhbW2N7du3Iz09HXPmzEFkZCSio6Pl2+jq6mL06NE4fvw4rl27hu+//x4bNmzA/Pnz5dtkZWWhT58+6NKlC1JSUjB79mxMnjwZBw4cUPHReubYr7H4ekkUwsZ9ij37D6FtWy98Nj4MuS90+rQhh0+1UA63c/hUC+VwO4dPtVAOt3O0uZZ794vw5aqf0enDZej04TKc+SsT+5aPg3MLWxjqi+HhbI8lG36F98ilGDF9A1o2a4x934/nbD2EewSMMabpD1EjPz8fjRs3Rnx8PLp27VrnNhcuXMD777+P27dvo1mzZiguLoa1tTW2bduG4cOHAwBycnJgb2+P2NhYBAQENDh/woQJyMjIQFxcXL3bRERE4MKFC/j9998BALNmzcLhw4eRkZEh3yY8PBxpaWlITExsUO7TygZ/RHw4YiicXVwwd95X8nVB/QPh69cTU6ZNb/iOOJDDp1ooh9s5fKqFcridw6daKIfbOdpSi3n7iQ3KuXdmKWZ/fwg/Hqp97uTl0gzndsxEq8AvcVdaWOf7Cy9E17n+RcrUo8/hO9fzH7/GyaSKWZtw78Bw6h6c4uJiAICFhcVLtxEIBGjUqBGAZyMxFRUV8Pf3l28jkUjg6uqKhISE185/WfaNGzdw7NgxdOvWTb4uMTFRIRsAAgICkJSUVOtSNmVVlJcj42o6vH06K6z39umEtNQUrcrhUy2Uw+0cPtVCOdzO4VMtlMPtHD7VoqMjwNAALxgZiPHnpaw6tzE1MUB1dTWKHpcplaWu46YRAg0uHMSZLhdjDBEREejcuTNcXV3r3Obp06f44osvMGrUKJiamgIApFIpxGIxzM3NFba1sbGBVCptcH5iYiL27t2Lo0eP1mrz8fHBxYsXIZPJMG7cOCxcuFDeJpVKYWNjUyu7srISBQUFsLOzU2iTyWSQyWSKtQv1oKen98rPWFhUiKqqKlhaWiqst7S0QkFB/ivf31DqyOFTLZTD7Rw+1UI53M7hUy2Uw+0cPtTSxkmCMz9Oh75YhJIyGYZP34C/b9Y+b9MTi/CfyQOx59ckPC59qlSmuo4b0TzOjOBMnDgRly5dwq5du+psr6iowIgRI1BdXY01a9a8cn+MMQj+/5l5gYGBMDY2hrGxMdq0aVNr2/T0dAwcOBDz5s1Dr169arXv2bMHFy9exM6dO3H06FF88803Cu2CF57NV3PV34vrgWcPVjAzM1NYli2NemU9r8qrK0tZ6sjhUy2Uw+0cPtVCOdzO4VMtlMPtHG2uJfPWfXQYEYVuwd9iw75z2LDwY7RuYauwjUikg21LPoGOQIApUXuVynueuo6bOtEAjiJOjOBMmjQJhw8fxtmzZ9G0adNa7RUVFRg2bBiysrIQFxcnH70BAFtbW5SXl6OwsFBhFCcvLw8+Pj4AgI0bN6Ks7Nmwpq6ursK+r169Cj8/P4SFhWHu3Ll1fj57e3sAgIuLC6qqqjBu3DhMnz4dQqEQtra2tUaK8vLyIBKJan1DAACRkZGIiIhQWMeErx69AQDzRuYQCoUoKChQWP/w4QNYWlo1aB9cyeFTLZTD7Rw+1UI53M7hUy2Uw+0cPtRSUVmFm3ef7ffi1TvwatMME0Z2x6RFuwE869zsWBoKhyaWCBy3SunRG0B9x41onkZHcBhjmDhxIg4ePIi4uDg4OjrW2qamc3P9+nWcPHmyVqfBy8sLurq6OHHihHxdbm4urly5Iu/gNGnSBE5OTnBycoKDg4N8u/T0dPj6+iI4OBiLFi1q8GeuqKiQj9J4e3srZAPA8ePH0a5du1qdKQDQ09ODqampwtKQy9MAQFcshrNLG5xP+ENh/fmEBLh7eDZoH1zJ4VMtlMPtHD7VQjnczuFTLZTD7Rw+1VJDAAH0xM++d6/p3LzTzBp9w6PxsLhUJRnqrIdolkZHcCZMmICdO3fi559/homJiXwkxMzMDAYGBqisrMQHH3yAixcv4pdffkFVVZV8GwsLC4jFYpiZmSE0NBTTp0+HpaUlLCwsMGPGDLi5uaFnz571Ztd0bvz9/RERESHfr1AohLW1NQBgx44d0NXVhZubG/T09JCcnIzIyEgMHz4cItGzQxceHo7o6GhEREQgLCwMiYmJ2LRpU72X2inr4+BPMOeLmXBxdYW7uycO7NuD3NxcDB0+Quty+FQL5XA7h0+1UA63c/hUC+VwO0eba/lqYn8c/+Mq7koLYWKkj6EBXujariUGTFgDoVAHO5eNhWdrewyesg5CHQFsLE0AAA+Ln6Cisv4pQDRVDxdo+RV2KqfRDs7atWsBAN27d1dYv2XLFoSEhCA7OxuHDx8GAHh4eChsc/r0afn7li9fDpFIhGHDhqGsrAw9evTA1q1bIRQK683et28f8vPzsWPHDuzYsUO+3sHBAbdu3QIAiEQiLF26FJmZmWCMwcHBARMmTMC0adPk2zs6OiI2NhbTpk3D6tWrIZFIsHLlSgwZMuQNj8rL9Q7sg+KiQqxfuwb5+XlwatkKq9eth0TSROty+FQL5XA7h0+1UA63c/hUC+VwO0eba2lsaYJN/x0NWytTFJc8xZXr9zBgwhrE/fk3mtlZoH/39wAAf+2JVHif/9gV+D35OufqIdzDqXlw/q1eZx4cQgghhBBt0dB5cJTV0HlwlMHleXAelio3sqUMC6P6BxQ0hTNPUSOEEEIIIYQQZXG4L0oIIYQQQgh5FboHRxGN4BBCCCGEEEJ4gzo4hBBCCCGEEN6gDg4hhBBCCCGEN6iDQwghhBBCCOENesgAIYQQQgghWoweMqCIOjiEEEIIIeSt+GXXAk1/BPIvRJeoEUIIIYQQQniDRnAIIYQQQgjRYgLQNWrPoxEcQgghhBBCCG/QCA4hhBBCCCFajB4yoIhGcAghhBBCCCG8QSM4hBBCCCGEaDEawFGk0RGcqKgotG/fHiYmJmjcuDGCgoJw7do1hW0WLFiA1q1bw8jICObm5ujZsyf+/PNPhW1kMhkmTZoEKysrGBkZYcCAAcjOzn5pdlpaGkaOHAl7e3sYGBjA2dkZK1asqHf7GzduwMTEBI0aNarVFh8fDy8vL+jr66NFixZYt25dww/CG9izawcC/f3Q3tMNI4YOxsXkJK3N4VMtlMPtHD7VQjnczuFTLZTD7Rw+1fL0SSn2bfwec8cOxpShvlg2czxuXc9QeQ6gvuNGNEejHZz4+HhMmDAB58+fx4kTJ1BZWQl/f3+UlpbKt2nVqhWio6Nx+fJlnDt3Ds2bN4e/vz/y8/Pl20ydOhUxMTHYvXs3zp07h5KSEvTr1w9VVVX1ZicnJ8Pa2hrbt29Heno65syZg8jISERHR9fatqKiAiNHjkSXLl1qtWVlZaFPnz7o0qULUlJSMHv2bEyePBkHDhxQ8ujU7divsfh6SRTCxn2KPfsPoW1bL3w2Pgy5OTlal8OnWiiH2zl8qoVyuJ3Dp1ooh9s5fKoFALZHL8HfqRcQPG0e5qzcBmfP97Fy3hQUPch/9Ztfg7rqIZolYIwxTX+IGvn5+WjcuDHi4+PRtWvXOrd59OgRzMzMcPLkSfTo0QPFxcWwtrbGtm3bMHz4cABATk4O7O3tERsbi4CAgAbnT5gwARkZGYiLi1NYP2vWLOTk5KBHjx6YOnUqioqKFNoOHz6MjIz/fcsQHh6OtLQ0JCYmNij3aWWDPyI+HDEUzi4umDvvK/m6oP6B8PXriSnTpjd8RxzI4VMtlMPtHD7VQjnczuFTLZTD7RxtqeWPGwWv3KZcJkPEiF4YP2cJ3Nr5yNcvnhoM13adMOCjca/cRycnq1duAyhXjz6Hb+x4LKvWWLaJHvdu6efUJyouLgYAWFhY1NleXl6O9evXw8zMDO7u7gCejcRUVFTA399fvp1EIoGrqysSEhJeO//F7Li4OOzbtw+rV6+u8z2JiYkK2QAQEBCApKQkVFRUvFb+q1SUlyPjajq8fTorrPf26YS01BStyuFTLZTD7Rw+1UI53M7hUy2Uw+0cPtUCANVVlaiuroKurlhhva5YD/9kXFJZjrrqIZrHmb4oYwwRERHo3LkzXF1dFdp++eUXjBgxAk+ePIGdnR1OnDgBK6tnPXWpVAqxWAxzc3OF99jY2EAqlTY4PzExEXv37sXRo0fl6x48eICQkBBs374dpqamdb5PKpXCxsamVnZlZSUKCgpgZ2fX4M/wKoVFhaiqqoKlpaXCektLKxQUqG4IVx05fKqFcridw6daKIfbOXyqhXK4ncOnWgBA39AIju+64te9W2Hb1AGmjSxw4feTuJV5FdZ2TVWWo656NIEm+lTEmRGciRMn4tKlS9i1a1etNl9fX6SmpiIhIQG9e/fGsGHDkJeX99L9McYg+P+HggcGBsLY2BjGxsZo06ZNrW3T09MxcOBAzJs3D7169ZKvDwsLw6hRo+q9XK6G4IWHj9dc9ffieuDZAxEePXqksMhkspfuvyF5dWUpSx05fKqFcridw6daKIfbOXyqhXK4ncOnWkKmfQnGGGaPCcLkD3xx5pd9aNe1F3R0hCrNAdR33IjmcKKDM2nSJBw+fBinT59G06a1e+pGRkZwcnJCx44dsWnTJohEImzatAkAYGtri/LychQWFiq8Jy8vTz6ysnHjRqSmpiI1NRWxsbEK2129ehV+fn4ICwvD3LlzFdri4uLwzTffQCQSQSQSITQ0FMXFxRCJRNi8ebM8/8WRory8PIhEolrfEADPnhxnZmamsCxbGtWg42TeyBxCoRAFBYrXsz58+ACWlg279pQrOXyqhXK4ncOnWiiH2zl8qoVyuJ3Dp1pqWNs1RcTi1Vi+5yQWbTqIWd9sRFVlJSxtVHcljDrrIZql0Q4OYwwTJ07EwYMHERcXB0dHxwa/r2bUw8vLC7q6ujhx4oS8PTc3F1euXIGPz7Mb1Zo0aQInJyc4OTnBwcFBvl16ejp8fX0RHByMRYsW1cpJTEyUd4xSU1OxcOFCmJiYIDU1FYMGDQIAeHt7K2QDwPHjx9GuXTvo6urW2mdkZCSKi4sVls9nRTaobl2xGM4ubXA+4Q+F9ecTEuDu4dmgfXAlh0+1UA63c/hUC+VwO4dPtVAOt3P4VMuL9PQNYGZhhSclj5CR+hfcO9R+gu2b0kQ96iIQaG7hIo3egzNhwgTs3LkTP//8M0xMTOQjIWZmZjAwMEBpaSkWLVqEAQMGwM7ODg8ePMCaNWuQnZ2NoUOHyrcNDQ3F9OnTYWlpCQsLC8yYMQNubm7o2bNnvdk1nRt/f39ERETIs4VCIaytrQEAzs7OCu9JSkqCjo6Owj1C4eHhiI6ORkREBMLCwpCYmIhNmzbVeakdAOjp6UFPT09h3es8Re3j4E8w54uZcHF1hbu7Jw7s24Pc3FwMHT6i4TvhSA6faqEcbufwqRbK4XYOn2qhHG7n8KkWALh68U8wMNg0aYb83GzEbF0NG0kzePfoq9IcddVDNEujHZy1a9cCALp3766wfsuWLQgJCYFQKMTff/+NH3/8EQUFBbC0tET79u3x+++/K9xLs3z5cohEIgwbNgxlZWXo0aMHtm7dCqGw/us29+3bh/z8fOzYsQM7duyQr3dwcMCtW7caXIOjoyNiY2Mxbdo0rF69GhKJBCtXrsSQIUMavI/X0TuwD4qLCrF+7Rrk5+fBqWUrrF63HhJJE63L4VMtlMPtHD7VQjnczuFTLZTD7Rw+1QIAZU9K8PO2dSgqyIehiSk8vbthwEfjIRSp9lRVXfWoG0cHUjSGU/Pg/Fu9zggOIYQQQoi2aMg8OKrQ0HlwlMHleXCelGvudN5QzL3uFYd/VIQQQgghhJBX4l4fQ6M48RQ1QgghhBBCCFEF6uAQQgghhBBCeIMuUSOEEEIIIUSLCegaNQU0gkMIIYQQQghRmzVr1sDR0RH6+vrw8vLC77//rtL9UweHEEIIIYQQLaZNE33u2bMHU6dOxZw5c5CSkoIuXbogMDAQd+7cUd3xoMdEax49JpoQQgghfESPiVYPTZ5Lvu5x6dChA9q2bSufDxMAnJ2dERQUhKioKJV8JhrBIYQQQgghhLwRmUyGR48eKSwymazObcvLy5GcnAx/f3+F9f7+/khISFDdh2JE6zx9+pTNnz+fPX36lHL+pTl8qoVyuJ3Dp1ooh9s5fKqFcrido65a/i3mz5/PACgs8+fPr3Pbe/fuMQDsjz/+UFi/aNEi1qpVK5V9JrpETQs9evQIZmZmKC4uhqmpKeX8C3P4VAvlcDuHT7VQDrdz+FQL5XA7R121/FvIZLJaIzZ6enrQ09OrtW1OTg6aNGmChIQEeHt7y9cvWrQI27Ztw99//62Sz8ThqwkJIYQQQgghXFZfZ6YuVlZWEAqFkEqlCuvz8vJgY2Ojss9E9+AQQgghhBBC3jqxWAwvLy+cOHFCYf2JEyfg4+OjshwawSGEEEIIIYSoRUREBD7++GO0a9cO3t7eWL9+Pe7cuYPw8HCVZVAHRwvp6elh/vz5DR4OpBz+5fCpFsrhdg6faqEcbufwqRbK4XaOumohdRs+fDgePHiAhQsXIjc3F66uroiNjYWDg4PKMughA4QQQgghhBDeoHtwCCGEEEIIIbxBHRxCCCGEEEIIb1AHhxBCCCGEEMIb1MEhhBBCCCGE8AZ1cAghhBBCCCG8QY+JJhpRUlKC5ORkSKVSCAQC2NjYwMvLC8bGxpr+aK+NT7UAVI8ybt++rZCjykdeEkLI86qqqlBQUACBQABLS0sIhULK4UAG4Qbq4GiJ69evIyEhQeHkycfHBy1btlR51ts8IaysrMT06dOxYcMGPH36FGKxGIwxVFRUQF9fH+PGjcOyZcugq6urgkr4VQvAr3redsdDnfUsX74c3333HXJyclDz5H2BQACJRILp06dj6tSpSmc8j08nHJTD3QzK4WZOTEwMvvnmGyQlJaGyshIAIBKJ0K5dO3z++ecICgqiHA1kEI5hhNOKiorYgAEDmEAgYI0aNWKtWrViLVu2ZI0aNWI6Ojps4MCBrLi4WCVZFRUVbPLkyczAwIAJBAKmp6fHxGIxEwgEzMDAgE2ZMoWVl5crlTF58mTWpEkTtnv3blZYWChfX1hYyHbv3s3s7e3ZlClTlCuE8asWxvhVjzpqYUx99SxcuJCZmpqyJUuWsJSUFJaTk8Pu3bvHUlJS2JIlS5iZmRn7z3/+o3QOY4wdPHiQ+fj4MLFYzHR0dJiOjg4Ti8XMx8eHxcTEqCSDcridw6daKOf1rVu3jonFYhYeHs5iYmJYQkIC++OPP1hMTAwLDw9nenp6bP369ZSjgVoIt1AHh+M+/vhj5ubmxs6fP1+r7fz58+y9995jo0ePVkmWOk4Irays2KlTp+ptP3nyJLOyslIqgzF+1cIYv+pRV8dDXfU0bdr0pScuBw8eZBKJROkcPp1wUA53MyiH2znvvPMO27hxY73tmzZtYi1atFAqg2856qqFcAt1cDjOzMyszs5NjcTERGZmZqaSLHWcEBoZGbG0tLR621NSUpiRkZFSGYzxqxbG+FWPujoe6qrHwMCAXb16td72K1euMAMDA6Vz+HTCQTnczaAcbufo6+uzv//+u972jIwMpq+vr1QG33LUVQvhFnqKmhYQCARv1Pa6ysrKYGVlVW+7paUlysrKlMrw9fVFREQE7t+/X6vt/v37mDlzJvz8/JTKAPhVC8CvetRRC6C+et5//30sWrRIfl338yorK7F48WK8//77Sufcu3cPnTt3rrfdx8cHOTk5lMPjHD7VQjlvpk2bNli/fn297Rs2bECbNm2UyuBbjrpqIRyj6R4WebmPPvqIvffee+zChQu12i5cuMA8PDzYxx9/rJKsfv36sR49ejCpVFqrTSqVsl69erH+/fsrlXHnzh3m6urKRCIR8/DwYAEBAax3797Mw8ODiUQi9t5777G7d+8qlcEYv2phjF/1qKMWxtRXz6VLl5itrS0zNzdnQUFBbPz48Sw8PJwFBQUxCwsLZmdnx65cuaJ0jpeXF4uIiKi3PSIignl5eVEOj3P4VAvlvJkzZ84wIyMj5uLiwqZOncqioqLYkiVL2NSpU1mbNm2YsbExO3v2rFIZfMtRVy2EWwSM/f8jfwgnFRUVYeTIkfjtt9/QqFEjNG7cGAKBAPfv30dxcTECAgKwc+dONGrUSOmsu3fvok+fPvj777/h6uoKGxsbCAQCSKVSXLlyBS4uLjh69CiaNm2qVE51dTV+++03nD9/HlKpFABga2sLb29v+Pv7Q0dH+YFFPtUC8KseddUCqO/n8/jxY2zfvr3OnFGjRsHU1FTpjPj4ePTt2xcODg7w9/dXOG4nTpzA7du3ERsbiy5dulAOT3P4VAvlvLlbt25h7dq1df69CQ8PR/PmzZXaPx9z1FUL4Q7q4GiJv//+G4mJibX+YbZu3VqlOeo6IVQHPtUC8KsePtWiTnw64aAc7mZQDvdzCCEvRx0cohFVVVUK8wL8+eefkMlk8Pb2Vum8MepWWFiIGzduwM7OTiUjEOqUnJwMLy8vTX8Mlbt58ybOnTuH3NxcCIVCtGjRAj179lTJqMrzXpzXx9bWFm3bttXaCVIJIURT2LOHYL3VL7u2bt2KQYMGwczM7K1lEA3S3NVxRBUePnzIfvzxR01/jAbLyclhnTp1YkKhkHXt2pU9fPiQ9e3blwkEAiYQCFirVq1YTk7OW8sPCQlh9+7dU8m+IiMjWWlpKWOMsfLychYWFsZ0dHSYQCBgOjo6bNCgQaysrEwlWS8qLCxk69evZ3PnzmUbNmxgRUVFSu9TIBCwFi1asEWLFrHs7GwVfMr63b9/n8XFxcnncJJKpWzp0qUsKiqKXbp0SSUZJSUl7IMPPpD/buno6DBbW1smFAqZsbExi46OVkmOuub1+beorq5mVVVVbz1ny5YtKvl3o2mZmZns5MmT7Pr165r+KG+ssrJS4fWff/7JEhMT2dOnT1Wedfv2bXb+/Hl24cIFlp+fr/L917h16xY7f/48+/PPP9mtW7feWs6LUlNTmY6Ojkr29csvv7DQ0FD2+eef13pS5MOHD5mvr6/SGRUVFWzOnDmsa9eubN68eYwxxr7++mtmaGjIxGIxGz16NJPJZErn1EVXV/elT8Ak2o06OFpOlX/MysvL2eeff87eeecd1r59e7Z582aFdqlUqnTWxx9/zHx8fNjhw4fZ8OHDmY+PD+vSpQvLzs5md+7cYV26dGETJkxQKoMxxtLS0upcdHV1WUxMjPy1MnR0dNj9+/cZY4wtWrSIWVtbswMHDrB79+6xI0eOsCZNmrCFCxcqXQtjjA0ZMoQdOHCAMcZYeno6s7KyYtbW1qxDhw7MxsaG2draKv2HWiAQsLCwMGZjY8NEIhHr27cvi4mJqXXyoazTp08zIyMjJhAImJ2dHUtLS2NNmzZlLVu2ZO+++y7T09Njv/32m9I548aNY506dWKpqans77//ZkOGDGEzZ85kpaWlbNOmTczQ0JDt2LFD6Rx1Tvj6MnRi83pUfXLz22+/sYqKCvnrHTt2MHd3d2ZoaMjeeecdtmLFCqUzoqKi5I9Yf/jwIfPz81PowPfu3Vvhd/BNGRsbszFjxrA//vhD6X29TFZWFmvbti0TCoWsT58+rLi4mPXs2VNeU4sWLdi1a9dUkrV69WrWrFkz+eSbNUunTp1YUlKSSjIYY+y7775jTZs2lX/ZVfOzadq0KVu+fLnKcuqTmprKBAKB0vvZsWMHEwqFrG/fvqxz585MX1+fbd++Xd6uivMBxhibO3cus7GxYREREczFxYWFh4cze3t7tn37dvbTTz+xpk2bsqVLlyqVYW5uXuciEAiYmZmZ/DXhF+rgcFxxcfFLl99//11lJzXz589nNjY2bNmyZWzOnDnMzMyMjRs3Tt4ulUqV/sNpZ2fHEhMTGWOMPXjwgAkEAnby5El5e1xcnErmI6j5j0rNf2CeX54fZVE2o6aD4+HhwTZt2qTQvmfPHubs7KxURg0rKyuWmZnJGGMsMDCQjRo1Sn7yV15ezkJDQ5m/v79SGTX1VFRUsP3797M+ffowoVDIbGxs2MyZM186j8Dr6NSpE5swYQJ7/PgxW7ZsGWvatKlCp3bGjBnMx8dH6RwrKyuFE5eHDx8yfX19+ahbdHQ08/DwUEmOuiZ8fRk6sambuk5unv/CY//+/UwoFLJJkyaxHTt2sOnTpzM9PT22c+dOpTKaNWsm/2Jm7NixzNPTk128eJGVlZWx1NRU1rFjRxYaGqp0LQKBgLVp04YJBALWunVr9s0338hrU6UhQ4awbt26sSNHjrBhw4axTp06se7du7Ps7GyWk5PDAgICWFBQkNI5y5YtY3Z2duz7779n69atY87OzmzhwoXs119/ZR9//DEzNDSs80mlr2vhwoXM1NSULVmyhKWkpLCcnBx27949lpKSwpYsWcLMzMzYf/7zH6UyBg0a9NLFz89PJf8+PT092cqVK+Wv9+3bx4yNjeXz/Kjq70CLFi3YkSNHGGOMXb9+neno6LDdu3fL2/fu3ctcXV2VyjA2NmZ9+/ZlW7dulS9btmxhQqGQLVq0SL6O8At1cDiu5kS8vkUVJ+o1nJyc5H9oGGPsxo0brGXLliwkJIRVV1er5A+avr4+u3Pnjvy1kZGRwqUVt2/fVsmkiO7u7qxv374sIyOD3bp1i926dYtlZWUxkUjETpw4IV+nDIFAwPLy8hhjjFlaWrLLly8rtGdlZTFDQ0OlMmoYGBiwGzduMMaedRIvXryo0H7t2jWlJ3x9vsNWIzs7my1cuJC1aNGC6ejosC5duiiVwRhjpqam8loqKiqYSCRiKSkp8vbMzEyVTF7bqFEjeaeQsWcdQZFIJP+ZZWZmqmRyN3VNKEonNm9GXSc3z//76dSpk3xUqsayZctY+/btlcrQ09OT/91q3rw5i4+PV2hPSkpidnZ2SmUw9r9aUlNT2cSJE5mFhQUTi8Vs8ODBLDY2llVXVyudwRhj1tbW8n/7RUVFTCAQsN9//13enpyczGxsbJTOad68OYuNjZW/vnbtGrO0tJSPuE2ePJn16tVL6ZymTZuymJiYetsPHjzIJBKJUhkikYgFBgaykJCQOpcBAwao5N+nkZERu3nzpsK606dPMxMTE7Z27VqV/R148ZxAX1+fZWRkyF/fvHmTmZiYKJVx/fp11r59ezZ69Gj2+PFj+XqRSMTS09OV2jfhLnpUEceZmJggKioKcXFxdS4vm7zqdd27dw+urq7y1++88w7OnDmDxMREfPzxx6iqqlI6o3HjxsjNzZW/njhxIiwsLOSvCwsLYWRkpHTOX3/9BScnJwwZMgQPHz6Eg4OD/Ok1EokEDg4OcHBwUDpnw4YNWLlyJfT09FBYWKjQVlxcDD09PaUzAOC9995DXFwcgGdP5Ll9+7ZC++3bt2FgYKBURl2TxjZp0gRffvkl/vnnHxw/fhz29vZKZQCAWCzG06dPAQDl5eWorq6WvwaeTQSqigdNtG/fHitWrJC/XrFiBaytrWFtbQ3g2UMBVPEAAHVNKHrkyBE8ffoUZmZmdS6qephBZmYm+vXrJ3/9wQcf4MiRI5g2bRrWrVunkgwAyMnJgbu7OwDAyckJYrFY/hoA2rVrV+v3/E2kpKQgLy8PcXFxGDJkCIKDgxESEgKBQICgoCAEBwcjODhY6ZznXb9+HQMHDlRYN2DAAGRmZiq1XwcHB1y5cgXAs3+vIpFIoV0oFKK0tFSpjOe5u7tj1apVyM3NxdatW1FcXIx+/fqhWbNmmDdvntL7r/l9Bp79t04oFMLExETebmpqiidPniidk5eXB2dnZ/nrli1bori4GPn5+QCAMWPGIDExUemcBw8e4N133623vVWrVrX+O/G6nJ2dMWTIEGzZsqXO5auvvlJq/zVMTU1r/U3r3r07jhw5gs8//xyrVq1SSY6ZmRmKiorkr9u2bavwOyCTyZSe0NzJyQkJCQmwtbWFh4cH/vjjD6X2R7SEpntY5OW6d+/+0ss0VHVZCmOMOTo6KlwuVuPevXusVatWrGfPnkp/YzNgwAD2/fff19seHR3N/Pz8lMp4XmxsLGvatClbvHgxq6qqUuk3Ng4ODqx58+by5cW6li9fzjp27KiSrF9++YVZWFiwLVu2sC1btrDmzZuzjRs3sj/++INt3ryZ2dvbs88//1ypjLpGcN6GgQMHsn79+rFz586xcePGsXbt2rG+ffuykpISVlpayj744APWu3dvpXOSk5OZhYUFs7W1Zc2aNWNisZjt2rVL3h4dHc1Gjx6tdI66JhR1c3OTj6LUJSUlRSXfqD5/Genzzpw5w4yNjdmcOXNUkmNjY6PwQAkfHx+Fh1tkZGQwU1NTpXMYezZSOHPmTPbOO++wc+fOMcZU/+2tQCBgp0+fZmlpaczBwaHWJU8ZGRnM2NhYqYxly5YxZ2dndv36dfbtt98yb29v+WjozZs3Wffu3dkHH3ygVAZjipfbvSgrK4vNnTuX2dvbK53TsWNHNnfuXMYYY5s3b2Y2Njbsiy++kLcvXLhQJRNwenh4sPXr18tfnzp1ihkaGspHov7++2+lRwkYY6xbt27sww8/VLgXq0ZFRQUbNWoU69atm1IZISEh7LPPPqu3/erVq6x58+ZKZTD27O/0i6OQNWruo1TF3wFfX9+XjqDu3btXJb8DNU6dOsWaNWvGIiMjma6uLo3g8Bh1cDhu/fr1L705VSqVsgULFqgkKzQ0lI0ZM6bOtuzsbObk5KSyy+Hq89dff9W61EtZUqmUBQYGss6dO6t1SDoxMbHWpWTK2L9/f62bVwUCAdPX12dTp05V+mEAZ86cqfM/zKqWmZnJnJyc5Nf537t3jw0YMICJRCImEomYtbU1S05OVklWTk4OW79+PVu1atVb/blXVVWx2NhYNm/ePDZu3Dg2btw4Nm/ePPbrr7+q7IlgdGKjvLd5cvPifX8vfuGxc+dO5uLionTOpEmTmK6uLmvdujXT19dnOjo6TCwWMx0dHdauXTuWm5urdEZDvuxQxWVqx44dY/r6+kwsFjMDAwN29uxZ1qpVK9a+fXvWsWNHJhQK2Z49e5TO2bNnD9PV1WXDhg1jo0ePZsbGxgodqXXr1jFvb2+lcy5dusRsbW2Zubk5CwoKYuPHj2fh4eEsKCiIWVhYMDs7O3blyhWlMp4+fSq/j/BtOnPmDFu8eHG97adPn2YhISFK51y7dq3WpXDP27Fjh0p+B55XUFDABg0axBo1aqSye0sJ99A8OETu9u3b+PvvvxEQEFBne25uLo4fP67yyznUZeXKlTh9+jRWrVqldXPU1KiqqsLFixdx8+ZNVFdXw87ODl5eXgpD+triwYMHsLS0lL8+deoUysrK4O3trbCePCOTyVBVVQVDQ8O3mhMfH4+EhARERkbW2X7mzBn8+OOP2LJli1I5mZmZ0NXVhaOjY53tO3fuhEgkwrBhw5TKedGDBw8QFhaG06dP4/z58y+9pOh1vHg5nbGxscLv8U8//QQAGD16tNJZGRkZ+OWXXxT+DnTq1Ak9e/ZU+nIeAPjqq6/w+eefv/XfNQDIysrCxYsX0a5dOzg4OOD+/ftYvXo1njx5gr59+8LX11clOb/++iu2b98OmUyGgIAAhIWFydsePHgAACr5u/P48WNs3769zok+R40apfL5twghdaMOjhbKzs6GRCLhzWzvpqamSE1NRYsWLTT9UZTGp1oAqkcVSktLkZycjK5du6otkxBCCPk348cZ8r+Mi4sLbt26pZYsU1NT3Lx5861mqKuPzadaAH7Vo45aAPX+fGrcuHFDZd9Cv0xlZSXu3LlDOf/inIqKCt7UwsccVVmzZg169uyJYcOGyR8+U6OgoEBlX+DwKUddtRDuoA6OFlLnSRqfBvj4VAvAr3r4VIumpKen13u5F+X8O3KuXr3Km1q0Nedtn0ivXLkSn3/+OVq3bg09PT306dMHUVFR8vaqqiqVPH2QTznqqoVwi+jVmxDydn300Ue8uS6ZT7UAVE9DPP+Y87qo4vHqhBDuW7lyJSIjI/HJJ5+guLgYffr0wfz58+X3s6niRPqHH37Ahg0bMGrUKADAZ599hqCgIJSVlWHhwoVK18DHHHXVQriFOjhaaPbs2a88qVIVdZzgrl279q3uvwafagH4VY+6OlJvox6ZTIZPP/0Ubm5udbbfvn1bJXNTtG3b9qXtZWVlSmdQDrdz+FQLH3PUcSKdlZUFHx8f+Wtvb2/ExcWhR48eqKiowNSpUylHAxmEe6iDowWys7Oxdu1aJCQkQCqVQiAQ4Pjx4/Dx8UF4eLhKJl+sz9s4ISwtLcXOnTsV6rGxsUGnTp0wcuRIlUz0WRc+1QLwq5631ZFSRz0eHh6wt7ev9+mCaWlpKungXL16FSNGjKj3Uprc3FylJ5KkHG7n8KkWPuao40TaysoKd+/elU9cDQBt2rRBXFwc/Pz8cO/ePaUz+JajrloIt9BT1Dju3LlzCAwMhL29Pfz9/WFjYwPGGPLy8nDixAncvXsXv/76Kzp16qSSvLd9Qnj16lX06tULT548Qbdu3RTqiY+Ph5GREY4fPw4XFxeqhcf1qKPjoa56Fi9ejIqKCsyfP7/O9rt372LevHlKP1a5Xbt2CA0Nxaefflpne2pqKry8vJS+JI5yuJvDp1r4mNOsWTPs2LEDXbp0UVh/9epV+Pn5wd/fHzt27FAqZ9SoUWjcuDG+//77Wm3p6enw9fXFgwcPlK6FTznqqoVwC43gcNy0adMwduxYLF++vN72qVOn4sKFC0pnvXhC2KxZM/kJ4eeff44FCxYofUI4YcIEdO3aFT/++CPEYrFCW3l5OUJCQjBhwgScPn2aankOn+pRRy2A+uqZPXv2S9vt7e2V7twAQOfOnXHt2rV6201MTFTyKGrK4W4On2rha86BAwdqdXBcXFxw6tQplTxN8YsvvkBycnKdbW3atMHp06exf/9+ylFzBuEeGsHhOAMDA6SmptY7Gd3ff/8NT09PlVxD7OvrC1tb25eeEObm5ip1QmhoaIikpKR6T16vXLmC999/H0+ePHnjDIBftQD8qkcdtQDq/fkQQsilS5eQnJyMTz75pM729PR07N+/v97RXkKI6tBjojnOzs4OCQkJ9bYnJibCzs5OJVl//vknvvzyy1onnQAgFosxe/Zs/Pnnn0plmJub4/r16/W237hxA+bm5kplAPyqBeBXPeqoBVDvz+dF6prXhxDCHe+99169nRvg2WjB2+jcuLm54e7duyrfL59z1FUL0Rzq4HDcjBkzEB4ejokTJ+Lnn3/G+fPn8eeff+Lnn3/GxIkT8emnn2LmzJkqyVLHCWFYWBiCg4PxzTffIC0tDVKpFPfv30daWhq++eYbjBkzBuPHj1cqA+BXLQC/6lFXx0OdP58XqWtgnE8nHJTD3QzK4XbOrVu3UFFR8VYz+JajrlqIBjHCebt372YdOnRgIpGICQQCJhAImEgkYh06dGB79uxRWc78+fOZmZkZW7ZsGUtNTWW5ublMKpWy1NRUtmzZMmZubs6++uorpXOWLFnC7OzsmEAgYDo6OkxHR4cJBAJmZ2fHli5dqoJK+FULY/yqR121MKa+n8+LjI2N2T///PPW9k85lKPODMrhdg6falFXjrpqIZpDHRwtUl5eznJyclhOTg4rLy9/KxnqPCG8efMmS0hIYAkJCezmzZsq3Tdjmqvlbf3RpJ/Nm3vb9bwoPDyc5efnv/UcPp1wUA53MyiH2zmBgYEsJyfnrWbwLUddtRDNoYcMkDplZWVBKpUCAGxtbeudP0AbqLsWsViMtLQ0ODs7v5X908+G1OjTpw82bdqksvvwKEf7cvhUC+UQQlSFOjikwe7evYv58+dj8+bNSu2nrKwMycnJsLCwqPWEq6dPn2Lv3r0YPXq0UhkAkJGRgfPnz8PHxwfvvvsu/v77b6xYsQIymQwfffQR/Pz8lNp/REREnetXrFiBjz76CJaWlgCA7777TqmcuhQWFuLHH3/E9evXIZFIMHr0aKUnfE1JSUGjRo3knYzt27dj7dq1uHPnDhwcHDBx4kSMGDFC6c8+adIkDBs2rNajVN+GVatWISkpCX379sWwYcOwbds2REVFobq6GoMHD8bChQshEin/tHxNTvhKCPl3YYzh5MmTdf696dGjBwQCAeVoIINwC3VwSIOlpaWhbdu2Sk2GlZmZCX9/f9y5cwcCgQBdunTBrl275N9u3b9/HxKJROkJt44dO4aBAwfC2NgYT548QUxMDEaPHg13d3cwxhAfH4/ffvtNqU6Ojo4O3N3d0ahRI4X18fHxaNeuHYyMjCAQCBAXF6dULQAgkUhw+fJlWFpaIisrC506dQJjDG5ubsjIyMDjx49x/vx5tG7d+o0z2rZti2+//Ra+vr7YuHEjJk+ejLCwMDg7O+PatWvYuHEjVqxYgTFjxihVi46ODgQCAd555x2EhoYiODgYtra2Su2zLv/5z3+wbNky+Pv7448//sDUqVOxbNkyTJs2DTo6Oli+fDk+/fRTfPXVV0rlqHOCVD6dcFAOdzMoh7s59+7dQ79+/XD58mW4uroq/L25cuUK3N3dcfjwYTRp0oRy1FwL4Rg1XQpHtMDPP//80mX58uVMR0dHqYygoCDWr18/lp+fz65fv8769+/PHB0d2e3btxljjEmlUqUzGGPM29ubzZkzhzHG2K5du5i5uTmbPXu2vH327NmsV69eSmUsXryYOTo6slOnTimsF4lELD09Xal9v0ggELD79+8zxhgbMWIE6969OystLWWMMfb06VPWr18/9sEHHyiVYWhoKP85eHp6sh9++EGhfceOHczFxUWpDMae1XLy5Ek2ZcoUZmVlxXR1ddmAAQPYkSNHWFVVldL7r9GiRQt24MABxhhjqampTCgUsu3bt8vbDx48yJycnJTO6d69OxsxYgSTyWS12mQyGRs5ciTr3r270jnZ2dnMw8ODCYVC5u7uzvz9/VmvXr2Yu7s7EwqFrG3btiw7O5tyeJzDp1oo580MGDCA+fn51Xn/SE5ODvPz82MDBw5UKoNvOeqqhXALdXCIXM0N3zVPaqtrUbbz0bhxY3bp0iWFdZ999hlr1qwZ++eff1TWwTE1NWXXr19njDFWVVXFRCIRS05OlrdfvnyZ2djYKJ3z119/sVatWrHp06fLH/zwtjs4dXWqzp8/z5o2bapUhqWlJUtKSmKMPfs5paamKrTfuHGDGRgYKJXBmGIt5eXlbM+ePSwgIIAJhUImkUjY7Nmz5T87ZRgYGMg7bIwxpqury65cuSJ/fevWLWZoaKiSnJf9vC9fvqyS48anEw7K4W4G5XA7x8jIqNbf5uddvHiRGRkZKZXBtxx11UK4hTo4RE4ikbCYmJh621NSUpTufJiYmLCrV6/WWj9x4kTWtGlTdvbsWZV3cBir/SSbW7duMX19faVzGGPs8ePHbPTo0ey9995jly5dYrq6um+lg5OXl8cYe/Zzev5EnTHGsrKymJ6enlIZH330EQsNDWWMMTZ06FA2d+5chfbFixczNzc3pTIYU+zgPO/27dts/vz5zMHBQSW/A46OjuzXX39ljDGWmZnJdHR02N69e+XtR48eZc2bN1c6RyKRsEOHDtXbHhMTwyQSidI5fDrhoBzuZlAOt3OsrKxYXFxcve2nTp1iVlZWSmXwLUddtRBuoYk+iZyXlxcuXrxYb7tAIFB6AsPWrVsjKSmp1vpVq1Zh4MCBGDBggFL7r9G8eXPcuHFD/joxMRHNmjWTv757967KnmpjbGyMH3/8EZGRkejVq5fS9w/Vp0ePHmjbti0ePXqEzMxMhbY7d+7AyspKqf0vXboUp06dQrdu3WBvb49vv/0WXbp0wbhx49CtWzcsWLAAS5YsUSrjZZo1a4YFCxYgKysLx44dU3p/o0aNwujRoxEWFoaAgADMmjULM2bMwLp16/DDDz8gPDwcgwYNUjpHXROKGhgY4OHDh/W2FxYWwsDAgHJ4nMOnWijnzYwYMQLBwcHYv38/iouL5euLi4uxf/9+fPLJJxg1apRSGXzLUVcthGM03cMi3HH27Fn5N951KSkpYWfOnFEqY/HixSwwMLDe9k8//ZQJBAKlMhhjbO3ateyXX36pt3327Nny0QpVunv3Ljt06BArKSlR6X4XLFigsBw7dkyhfcaMGWzEiBFK5xQWFrJZs2YxFxcXpq+vz8RiMXNwcGCjRo1iFy5cUHr/jDHWvHlzVlBQoJJ9vUxlZSX773//y/r168eWLFnCGHt2P5a9vT2ztLRkISEhKvs5qWNen4kTJzJ7e3u2b98+VlRUJF9fVFTE9u3bx5o1a8YmT55MOTzO4VMtlPNmZDIZCw8PZ2KxmOno6DB9fX2mr6/PdHR0mFgsZp9++mmd9wP+m3PUVQvhFurgEEKIirzNCUX5dMJBOdzNoBzu5zDGWHFxMTt16hTbuXMn27lzJ4uLi2PFxcUq2feLOXFxcbzIUVcthBvoMdGEEKKkIc6byAAAEhZJREFU3NxcrF27FufOnUNubi6EQiEcHR0RFBSEkJAQCIVClWU9evQISUlJuH//PoBnE6R6eXnB1NRUZRk1OcnJyQoTsVION3L4VAtfc9Txb5QQUj/q4BBCiBKSkpLQs2dPODo6wsDAAH/++Sc+/PBDlJeX47fffoOzszN+++03mJiYaPqjEkJ4gAsTC9+/fx8//PAD5s2bp5L9ZWdno1GjRjA2NlZYX1FRgcTERHTt2lWp/T948ACXLl2Cu7s7LCwsUFBQgE2bNkEmk2Ho0KFwdnZWav+Ee6iDQwghSujcuTN69eqF+fPnAwC2b9+O6OhonD9/HoWFhfDz80PXrl2xYsUKpbPoxObNaPLkpkWLFvjtt9/QsmVLle+7oqICR48exfXr12FnZ4dBgwap5HcgOzsb+vr68geX/P7771i3bh3u3LkDBwcHTJgwAd7e3krnfPvtt/jggw/g4OCg9L5e5ciRI0hKSkLv3r3h7e2NuLg4fPPNN6iursbgwYMxbtw4leSUlZVh165ddY7m9ujRQ+n9q3Ni4ZdRxcTfwLPR74EDByI5ORkCgQAffvghVq9eLf97oIrJv//66y/4+/vj0aNHaNSoEU6cOIGhQ4dCJBKBMYZ79+7h3LlzaNu2rVK1EG6hDg4hhCjB0NAQV65cQYsWLQAA1dXV0NfXx927d2FjY4MTJ04gJCQE9+7dUyqHTmzejLpOblauXFnn+oiICMycORO2trYAgMmTJ79xho+PD2JjY9GoUSPk5+fDz88PmZmZcHBwwN27d9G4cWMkJCQoPSO7j48PvvzySwQGBuLnn3/G4MGD0a9fPzg7OyMzMxO//PILDh48iH79+imVo6OjAx0dHfj6+mLs2LEYNGgQxGKxUvusy7p16zBp0iS4u7vj+vXrWLNmDT799FMMHz4cQqEQP/30E6KiojBlyhSlcm7cuIGePXuipKQEYrEYUqkUffr0QUFBAZKSkjB48GDs3LkTIpHojTN8fX1ha2uLH3/8sdaxKi8vR0hICHJzc3H69Gmlarl06dJL2//++2+MHDlS6X+fwcHByMzMxKpVq1BUVITIyEgwxnDixAmYm5vj/v37sLOzQ3V19Rtn9OrVC82bN8d3332HH374AStWrEDv3r2xYcMGAMDYsWPx4MEDxMTEKFUL4RiN3PlDCCE84eDgwM6dOyd/nZOTwwQCAXvy5Alj7NkcRaqYc6l79+5sxIgRdd6kLJPJ2MiRI1n37t2VzklLS3vpsmfPHpXMUzR69GjWsWNHduHCBXbixAnWrl075uXlxR4+fMgYY0wqlarkiYo9e/ZkY8eOZY8ePWLLli1jTZs2ZWPHjpW3h4aGsqCgIKVzBAIBa9q0KWvevLnCIhAIWJMmTVjz5s2Zo6Oj0hk1c0iFhYUxDw8PlpubyxhjrKCggPn4+LAxY8YoXYuJiQnLyspijDHWoUMH+VMIa6xatYp5enoqnSMQCNiWLVvYwIEDma6uLrO0tGRTpkxhly9fVnrfz3N2dmbr169njDEWFxfH9PX12erVq+XtW7ZsYc7OzkrnBAYGsvHjx7OqqirGGGNRUVHyp4ZmZmay5s2bs/nz5yuVoa6JhV828XfNelX8HZBIJOzPP/+Uv3769CkbOHAg8/DwYA8ePFDJ5N/m5uby+ffKy8uZjo6OQubFixdZkyZNlMog3EMdHEIIUcKUKVOYq6sr+/XXX1lcXBzz9fVV6GgcO3aMvfPOO0rn0InNm1HXyc24ceOYh4dHrYmMRSKRyib+fb6D06pVq1qPwj99+rRKJq81MzNjaWlpjDHGGjduLP//NW7cuMEMDQ2Vznm+nvv377OlS5ey1q1bMx0dHda+fXu2fv169ujRI6VzDAwM2O3bt+WvdXV1FTpRWVlZKqnH0NCQZWZmyl/LZDKmq6srfyz+oUOHlP75qGtiYSsrK7Zp0yZ269atOpejR4+q5N+nkZGRwjFjjLGKigoWFBQknzxb2RwjIyN5h52x2hN/3759W2UTfxPuoIk+CSFECf/973/h4uKC/v37o0ePHpDJZNi8ebO8XSAQICoqSukcc3NzXL9+vd72GzduwNzcXOkcS0tLbNiwAVlZWbWWmzdv4pdfflE6A3g2yd7zn1dPTw/79+9H8+bN4evri7y8PJXklJeXyydX1NXVhaGhocKkuJaWlnjw4IHSOT/88APmz5+PgIAAREdHK72/+ggEAgBAUVERHB0dFdocHR2Rm5urdEa3bt2wa9cuAICnpyfOnDmj0H769GmlL4N7UePGjTFz5kxkZGTgzJkzcHFxwbRp01QyIbOlpSVu374NAMjJyUFlZSXu3Lkjb799+zYsLCyUzmnUqBEeP34sf/3kyRNUVlbKLyV77733lP75qGtiYS8vL+Tk5MDBwaHOpUmTJkpP/A08u0ftxcvhRCIR9u3bhxYtWih9GSQA2Nvb4+bNm/LXu3fvVvi9ys3NVXqibMI9b34hKCGEEBgbG2PPnj14+vQpKisra90s7+/vr5KcmhObuXPnolevXrCxsYFAIIBUKsWJEyewePFiTJ06Vemc509s6lJUVKTSE5vnb76vObEZOnSoSk5sgP+d3DRv3hzA2z25CQoKQvv27TF69GgcPXoUW7ZsUcl+nxcSEgI9PT1UVFTg9u3bCvdc5ebmolGjRkpnLFmyBF26dEFOTg46d+6MOXPm4MKFC3B2dsa1a9ewZ88erFu3Tumcms7ai7p06YIuXbpg5cqV2LNnj9I5AwcORGhoKIKDg3H48GGMHj0a06dPh46ODgQCAT7//HOV/Dvt1asXIiIisG7dOujp6SEyMhIeHh7yJyjeuXMHjRs3VipjwYIFMDAwwHfffYeZM2fKjyFjDLa2tvjiiy8wc+ZMpWsZP348SktL621v1qyZSn6/AwMDsX79egwZMkRhfc3fgiFDhiA7O1upjBEjRih8YdK3b1+F9sOHD+P9999XKoNwkIZHkAghhDTQkiVLmJ2dnfwysZpLxuzs7NjSpUtVknHw4EG2bdu2etsfPnzItm7dqnTOzJkzmb+/f51tFRUVbMCAASq5B2fBggVs165d9bbPnj2bDR48WOmc51VXV7PFixczW1tbJhQKVXaJWkhIiMKyd+9ehfYZM2awgIAAlWTduHGDjRgxgpmYmMgvUdTV1WU+Pj4sJiZGJRnPX6L2NpWUlLCxY8cyV1dXFh4ezsrLy9myZcuYWCxmAoGAde/eXSWf4/79+6xjx47yf5/NmzdnFy9elLfv27ePrVy5UumcGm9zYmF1qaioeOlkm5WVlezWrVtv9TOUlpayp0+fvtUMon70FDVCCNEyWVlZCpMVvnipkjaorKzEkydP6p38sKqqCtnZ2W/9EcJPnjyBUCiEnp6eyvednJyMc+fOYfTo0Sq5fPBVSktLIRQKoa+vr7J9sv9/Ul91dTWsrKygq6ursn1r2tOnT1FRUaHyOaquX78OmUyG1q1bK/XENELIm6N7cAghRMs4OjrC29sb3t7e8s7N3bt3MWbMmLeeraockUj00pndc3Jy8NVXXymd8yoPHjzAp59++lb27eXlhSlTpsDc3FwtP5+HDx/is88+U+k+a+ZasrOzk3dutO13rT76+vowMTFReU7Lli3h6upaq3OjqpyysjKcO3cOV69erdX29OlT/PTTT0pn8C1HXbUQDtHwCBIhhBAVSE1NVclTjShHe3P4VAvl1O3atWvMwcFBfhlct27dWE5OjrxdVU8f5FOOumoh3EJjp4QQogUOHz780vbnnxJEOfzM4VMtlPNmZs2aBTc3NyQlJaGoqAgRERHo1KkTzpw5g2bNmim9fz7mqKsWwi10Dw4hhGiBmic+vexPtkAgUHpmccrhbg6faqGcN2NjY4OTJ0/Czc1Nvm7ChAn45ZdfcPr0aRgZGUEikShdC59y1FUL4Ra6B4cQQrSAnZ0dDhw4gOrq6jqXixcvUg7Pc/hUC+W8mbKyslr39qxevRoDBgxAt27dkJmZqXQG33LUVQvhFurgEEKIFvDy8nrpCdKrvjmmHO3P4VMtlPNmWrdujaSkpFrrV61ahYEDB2LAgAFK7Z+POeqqhXAL3YNDCCFa4PPPP3/pxHtOTk44ffo05fA4h0+1UM6bGTRoEHbt2oWPP/64Vlt0dDSqq6tVMgkrn3LUVQvhFroHhxBCCCGEEMIbdIkaIYQQQgghhDeog0MIIYQQQgjhDergEEIIIYQQQniDOjiEEEIIIYQQ3qAODiGEEKUsWLAAHh4e8tchISEICgpS++e4desWBAIBUlNT1Z5NCCGEO6iDQwghPBUSEgKBQACBQABdXV20aNECM2bMeOmjbFVhxYoV2Lp1a4O2pU4JIYQQVaN5cAghhMd69+6NLVu2oKKiAr///jvGjh2L0tJSrF27VmG7iooK6OrqqiTTzMxMJfshhBBC3gSN4BBCCI/p6enB1tYW9vb2GDVqFD788EMcOnRIflnZ5s2b0aJFC+jp6YExhuLiYowbNw6NGzeGqakp/Pz8kJaWprDPJUuWwMbGBiYmJggNDcXTp08V2l+8RK26uhpLly6Fk5MT9PT00KxZMyxatAgA4OjoCADw9PSEQCBA9+7d5e/bsmULnJ2doa+vj9atW2PNmjUKOX/99Rc8PT2hr6+Pdu3aISUlRYVHjhBCiLaiERxCCPkXMTAwQEVFBQDgxo0b2Lt3Lw4cOAChUAgA6Nu3LywsLBAbGwszMzP88MMP6NGjBzIzM2FhYYG9e/di/vz5WL16Nbp06YJt27Zh5cqVaNGiRb2ZkZGR2LBhA5YvX47OnTsjNzcXf//9N4BnnZT3338fJ0+eRJs2bSAWiwEAGzZswPz58xEdHQ1PT0+kpKQgLCwMRkZGCA4ORmlpKfr16wc/Pz9s374dWVlZmDJlyls+eoQQQrQBdXAIIeRf4q+//sLOnTvRo0cPAEB5eTm2bdsGa2trAEBcXBwuX76MvLw86OnpAQC++eYbHDp0CPv378e4cePw/fffY8yYMRg7diwA4L///S9OnjxZaxSnxuPHj7FixQpER0cjODgYAPDOO++gc+fOACDPtrS0hK2trfx9//nPf/Dtt99i8ODBAJ6N9Fy9ehU//PADgoODsWPHDlRVVWHz5s0wNDREmzZtkJ2djU8//VTVh40QQoiWoUvUCCGEx3755RcYGxtDX18f3t7e6Nq1K1atWgUAcHBwkHcwACA5ORklJSWwtLSEsbGxfMnKysI///wDAMjIyIC3t7dCxouvn5eRkQGZTCbvVDVEfn4+7t69i9DQUIXP8d///lfhc7i7u8PQ0LBBn4MQQsi/B43gEEIIj/n6+mLt2rXQ1dWFRCJReJCAkZGRwrbV1dWws7PDmTNnau2nUaNGb5RvYGDw2u+prq4G8OwytQ4dOii01VxKxxh7o89DCCGE/6iDQwghPGZkZAQnJ6cGbdu2bVtIpVKIRCI0b968zm2cnZ1x/vx5jB49Wr7u/Pnz9e6zZcuWMDAwwKlTp+SXtT2v5p6bqqoq+TobGxs0adIEN2/exIcffljnfl1cXLBt2zaUlZXJO1Ev+xyEEEL+PegSNUIIIQCAnj17wtvbG0FBQfjtt99w69YtJCQkYO7cuUhKSgIATJkyBZs3b8bmzZuRmZmJ+fPnIz09vd596uvrY9asWZg5cyZ++ukn/PPPPzh//jw2bdoEAGjcuDEMDAxw7Ngx3L9/H8XFxQCeTR4aFRWFFStWIDMzE5cvX8aWLVvw3XffAQBGjRoFHR0dhIaG4urVq4iNjcU333zzlo8QIYQQbUAdHEIIIQAAgUCA2NhYdO3aFWPGjEGrVq0wYsQI3Lp1CzY2NgCA4cOHY968eZg1axa8vLxw+/btV97Y/+WXX2L69OmYN28enJ2dMXz4cOTl5QEARCIRVq5ciR9++AESiQQDBw4EAIwdOxYbN27E1q1b4ebmhm7dumHr1q3yx0obGxvjyJEjuHr1Kjw9PTFnzhwsXbr0LR4dQggh2kLA6EJmQgghhBBCCE/QCA4hhBBCCCGEN6iDQwghhBBCCOEN6uAQQgghhBBCeIM6OIQQQgghhBDeoA4OIYQQQgghhDeog0MIIYQQQgjhDergEEIIIYQQQniDOjiEEEIIIYQQ3qAODiGEEEIIIYQ3qINDCCGEEEII4Q3q4BBCCCGEEEJ44/8AznFJyBSJfb0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "    # Let's build our model\n",
    "    train(200,device,net)\n",
    "    print('Finished Training')\n",
    "\n",
    "    #Epochごとのlossの保存\n",
    "    #torch.save(net, \"./result/\"+casename+\"/\"+casename+\".pt\")\n",
    "    # 保存网络中的参数, 速度快，占空间少\n",
    "    #torch.save(net.state_dict(),'case-1-p.pt')\n",
    "    #--------------------------------------------------\n",
    "    #针对上面一般的保存方法，加载的方法分别是：\n",
    "    # model_dict=torch.load(PATH)\n",
    "    # model_dict=model.load_state_dict(torch.load(PATH))\n",
    "    # Test which classes performed well\n",
    "    valid(net, device, valid_loader, classes)\n",
    "    # Let's load the model we just created and test the accuracy per label\n",
    "    # model = net()\n",
    "    # path = \"myFirstModel.pth\"\n",
    "    # model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed in:  0.34280201501678675  seconds\n",
      "[22] tensor([18])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "net.to(device)\n",
    "net.eval()\n",
    "predictions = []\n",
    "label1 = []\n",
    "dataiter=iter(valid_loader)\n",
    "images, label0 = dataiter.__next__()\n",
    "\n",
    "start_time = time.process_time()\n",
    "with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"Prediction completed in: \", (end_time - start_time), \" seconds\")\n",
    "\n",
    "print(predictions, label0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
